{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd65eba3",
   "metadata": {},
   "source": [
    "# Package loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5f46ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "import os\n",
    "import json\n",
    "import argparse\n",
    "import time\n",
    "import ipdb\n",
    "import spacy\n",
    "import torch\n",
    "import optuna\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import deque\n",
    "\n",
    "import torch.optim as optim\n",
    "from torchtext import data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transformers import RobertaTokenizer, BertModel, TransfoXLTokenizer, TransfoXLModel, AdamW\n",
    "from transformers import BigBirdTokenizer, BigBirdForSequenceClassification\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import LongformerTokenizer, LongformerForSequenceClassification\n",
    "from transformers import XLNetTokenizer, XLNetForSequenceClassification\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37d5fbf",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbce3248-9abd-4b6d-a58c-2ac38d499618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_path = \"/nfs/home/kabenamualus/Research/task-dataset-metric-extraction/data/paperwithcode/5Neg10unk/twofoldwithunk/fold1/train.tsv\"\n",
    "# valid_path = \"/nfs/home/kabenamualus/Research/task-dataset-metric-extraction/data/paperwithcode/5Neg10unk/twofoldwithunk/fold1/dev.tsv\"\n",
    "\n",
    "train_path = \"/nfs/home/kabenamualus/Research/task-dataset-metric-extraction/data/paperwithcode/new/60Neg800unk/twofoldwithunk/fold1/train.tsv\"\n",
    "valid_path = \"/nfs/home/kabenamualus/Research/task-dataset-metric-extraction/data/paperwithcode/new/60Neg800unk/twofoldwithunk/fold1/dev.tsv\"\n",
    "\n",
    "\n",
    "N_EPOCHS = 3\n",
    "model_name = \"XLNet\"\n",
    "max_input_len = 512\n",
    "output_path = \"/nfs/home/kabenamualus/Research/task-dataset-metric-extraction/data/paperwithcode/new/60Neg800unk/twofoldwithunk/fold1/\"\n",
    "bs = 16\n",
    "\n",
    "processors = {\n",
    "      \"Bert\": [BertTokenizer, BertForSequenceClassification, \"bert-base-uncased\"],\n",
    "      \"SciBert\": [BertTokenizer, BertForSequenceClassification, \"allenai/scibert_scivocab_uncased\"],\n",
    "      \"XLNet\": [XLNetTokenizer, XLNetForSequenceClassification, \"xlnet-base-cased\"],\n",
    "      \"BigBird\": [BigBirdTokenizer, BigBirdForSequenceClassification, \"google/bigbird-roberta-base\"],\n",
    "      \"Longformer\": [LongformerTokenizer, LongformerForSequenceClassification, \"allenai/longformer-base-4096\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b8bebdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_path, \n",
    "                    sep=\"\\t\", names=[\"label\", \"title\", \"TDM\", \"Context\"])\n",
    "\n",
    "valid_df = pd.read_csv(valid_path, \n",
    "                   sep=\"\\t\", names=[\"label\", \"title\", \"TDM\", \"Context\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "204784d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>TDM</th>\n",
       "      <th>Context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>1810.02575v1.pdf</td>\n",
       "      <td>Semantic Segmentation; Nighttime Driving; mIoU</td>\n",
       "      <td>Dark Model Adaptation: Semantic Image Segmenta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>1810.02575v1.pdf</td>\n",
       "      <td>Extractive Text Summarization; DebateSum; ROUGE-L</td>\n",
       "      <td>Dark Model Adaptation: Semantic Image Segmenta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>1810.02575v1.pdf</td>\n",
       "      <td>Action Recognition; Something-Something V1; To...</td>\n",
       "      <td>Dark Model Adaptation: Semantic Image Segmenta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>1810.02575v1.pdf</td>\n",
       "      <td>Multi-Object Tracking; MOTS20; sMOTSA</td>\n",
       "      <td>Dark Model Adaptation: Semantic Image Segmenta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>1810.02575v1.pdf</td>\n",
       "      <td>Continuous Control; PyBullet Ant; Return</td>\n",
       "      <td>Dark Model Adaptation: Semantic Image Segmenta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label             title                                                TDM  \\\n",
       "0   True  1810.02575v1.pdf     Semantic Segmentation; Nighttime Driving; mIoU   \n",
       "1  False  1810.02575v1.pdf  Extractive Text Summarization; DebateSum; ROUGE-L   \n",
       "2  False  1810.02575v1.pdf  Action Recognition; Something-Something V1; To...   \n",
       "3  False  1810.02575v1.pdf              Multi-Object Tracking; MOTS20; sMOTSA   \n",
       "4  False  1810.02575v1.pdf           Continuous Control; PyBullet Ant; Return   \n",
       "\n",
       "                                             Context  \n",
       "0  Dark Model Adaptation: Semantic Image Segmenta...  \n",
       "1  Dark Model Adaptation: Semantic Image Segmenta...  \n",
       "2  Dark Model Adaptation: Semantic Image Segmenta...  \n",
       "3  Dark Model Adaptation: Semantic Image Segmenta...  \n",
       "4  Dark Model Adaptation: Semantic Image Segmenta...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fa48e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>TDM</th>\n",
       "      <th>Context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>1707.03497v2.pdf</td>\n",
       "      <td>Atari Games; Atari 2600 Seaquest; Score</td>\n",
       "      <td>Value Prediction Network This paper proposes a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>1707.03497v2.pdf</td>\n",
       "      <td>Atari Games; Atari 2600 Amidar; Score</td>\n",
       "      <td>Value Prediction Network This paper proposes a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>1707.03497v2.pdf</td>\n",
       "      <td>Atari Games; Atari 2600 Krull; Score</td>\n",
       "      <td>Value Prediction Network This paper proposes a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>1707.03497v2.pdf</td>\n",
       "      <td>Atari Games; Atari 2600 Alien; Score</td>\n",
       "      <td>Value Prediction Network This paper proposes a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>1707.03497v2.pdf</td>\n",
       "      <td>Atari Games; Atari 2600 Enduro; Score</td>\n",
       "      <td>Value Prediction Network This paper proposes a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label             title                                      TDM  \\\n",
       "0   True  1707.03497v2.pdf  Atari Games; Atari 2600 Seaquest; Score   \n",
       "1   True  1707.03497v2.pdf    Atari Games; Atari 2600 Amidar; Score   \n",
       "2   True  1707.03497v2.pdf     Atari Games; Atari 2600 Krull; Score   \n",
       "3   True  1707.03497v2.pdf     Atari Games; Atari 2600 Alien; Score   \n",
       "4   True  1707.03497v2.pdf    Atari Games; Atari 2600 Enduro; Score   \n",
       "\n",
       "                                             Context  \n",
       "0  Value Prediction Network This paper proposes a...  \n",
       "1  Value Prediction Network This paper proposes a...  \n",
       "2  Value Prediction Network This paper proposes a...  \n",
       "3  Value Prediction Network This paper proposes a...  \n",
       "4  Value Prediction Network This paper proposes a...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565e0a19",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb005179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<cls> <sep> <pad> <unk>\n"
     ]
    }
   ],
   "source": [
    "if model_name in processors.keys():\n",
    "    selected_processor = processors[model_name]\n",
    "else:\n",
    "    print(f\"Model not available check selected model only {list(processors.keys())} as supported\")\n",
    "    quit()\n",
    "\n",
    "if model_name == \"SciBert\":\n",
    "    tokenizer = selected_processor[0].from_pretrained(\"bert-base-uncased\")\n",
    "else:\n",
    "    tokenizer = selected_processor[0].from_pretrained(selected_processor[2])\n",
    "\n",
    "init_token = tokenizer.cls_token\n",
    "eos_token = tokenizer.sep_token\n",
    "pad_token = tokenizer.pad_token\n",
    "unk_token = tokenizer.unk_token\n",
    "\n",
    "print(init_token, eos_token, pad_token, unk_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c465a271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 4 5 0\n"
     ]
    }
   ],
   "source": [
    "init_token_idx = tokenizer.convert_tokens_to_ids(init_token)\n",
    "eos_token_idx = tokenizer.convert_tokens_to_ids(eos_token)\n",
    "pad_token_idx = tokenizer.convert_tokens_to_ids(pad_token)\n",
    "unk_token_idx = tokenizer.convert_tokens_to_ids(unk_token)\n",
    "\n",
    "print(init_token_idx, eos_token_idx, pad_token_idx, unk_token_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ce90231-6e38-4b67-852d-b3ea6d6a57cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.max_model_input_sizes[selected_processor[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "041a1bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximun sequence lenght 512\n"
     ]
    }
   ],
   "source": [
    "if model_name == \"SciBert\":\n",
    "    max_input_length = tokenizer.max_model_input_sizes[\"bert-base-uncased\"]\n",
    "else:\n",
    "    max_input_length = tokenizer.max_model_input_sizes[selected_processor[2]]\n",
    "\n",
    "if not max_input_length:\n",
    "    max_input_length = max_input_len\n",
    "\n",
    "print(f\"Maximun sequence lenght {max_input_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0350f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformersNLI(Dataset):\n",
    "    def __init__(self, tokenizer, max_input_length):\n",
    "        self.label_dict = {'True': 0, 'False': 1} # Default {'entailment': 0, 'contradiction': 1, 'neutral': 2}\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_input_length = max_input_length        \n",
    "        \n",
    "    def _truncate_seq_pair(self, tokens_a, tokens_b, max_length):\n",
    "        \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n",
    "\n",
    "        # This is a simple heuristic which will always truncate the longer sequence\n",
    "        # one token at a time. This makes more sense than truncating an equal percent\n",
    "        # of tokens from each, since if one sequence is very short then each token\n",
    "        # that's truncated likely contains more information than a longer sequence.\n",
    "        while True:\n",
    "            total_length = len(tokens_a) + len(tokens_b)\n",
    "            if total_length <= max_length:\n",
    "                break\n",
    "            if len(tokens_a) > len(tokens_b):\n",
    "                tokens_a.pop()\n",
    "            else:\n",
    "                tokens_b.pop()\n",
    "        \n",
    "    def load_data(self, df):\n",
    "        MAX_LEN = self.max_input_length\n",
    "        token_ids = []\n",
    "        mask_ids = []\n",
    "        seg_ids = []\n",
    "        y = []\n",
    "\n",
    "        premise_list = df['TDM'].to_list()           # df['sentence1'].to_list()\n",
    "        hypothesis_list = df['Context'].to_list()    # df['sentence2'].to_list()\n",
    "        label_list = df['label'].to_list()           # df['gold_label'].to_list()\n",
    "\n",
    "        for (premise, hypothesis, label) in tqdm(zip(premise_list, hypothesis_list, label_list), total=len(label_list)):\n",
    "            premise_id = self.tokenizer.encode(premise, add_special_tokens = False)\n",
    "            hypothesis_id = self.tokenizer.encode(hypothesis, add_special_tokens = False)\n",
    "            # ignore the warning as the ong sequence issuw is taken care of here \n",
    "            self._truncate_seq_pair(premise_id, hypothesis_id, MAX_LEN-3) # -3 to account for the special characters \n",
    "            \n",
    "            pair_token_ids = [self.tokenizer.cls_token_id] + premise_id \\\n",
    "                            + [self.tokenizer.sep_token_id] + hypothesis_id \\\n",
    "                            + [self.tokenizer.sep_token_id]\n",
    "            premise_len = len(premise_id)\n",
    "            hypothesis_len = len(hypothesis_id)\n",
    "\n",
    "            segment_ids = torch.tensor([0] * (premise_len + 2) + [1] * (hypothesis_len + 1))  # sentence 0 and sentence 1\n",
    "            attention_mask_ids = torch.tensor([1] * (premise_len + hypothesis_len + 3))  # mask padded values\n",
    "\n",
    "            token_ids.append(torch.tensor(pair_token_ids))\n",
    "            seg_ids.append(segment_ids)\n",
    "            mask_ids.append(attention_mask_ids)\n",
    "            # we have str(label) to have the key work proprely \n",
    "            y.append(self.label_dict[str(label)]) # y.append(self.label_dict[label]) \n",
    "            \n",
    "        token_ids = pad_sequence(token_ids, batch_first=True)\n",
    "        mask_ids = pad_sequence(mask_ids, batch_first=True)\n",
    "        seg_ids = pad_sequence(seg_ids, batch_first=True)\n",
    "        y = torch.tensor(y)\n",
    "        dataset = TensorDataset(token_ids, mask_ids, seg_ids, y)\n",
    "\n",
    "        print(len(dataset))\n",
    "\n",
    "        return dataset\n",
    "\n",
    "    def get_train_data(self, train_df, batch_size=32, shuffle=True):\n",
    "        train_data = self.load_data(train_df)\n",
    "                    \n",
    "        train_loader = DataLoader(\n",
    "            train_data,\n",
    "            shuffle=shuffle,\n",
    "            batch_size=batch_size\n",
    "            )\n",
    "\n",
    "        return train_loader\n",
    "\n",
    "    def get_valid_data(self, valid_df, batch_size=32, shuffle=True):\n",
    "        valid_data = self.load_data(valid_df)\n",
    "                    \n",
    "        valid_loader = DataLoader(\n",
    "            valid_data,\n",
    "            shuffle=shuffle,\n",
    "            batch_size=batch_size\n",
    "            )\n",
    "\n",
    "        return valid_loader\n",
    "\n",
    "    def get_inference_data(self, test_df, batch_size=32, shuffle=False):\n",
    "        test_data = self.load_data(test_df)\n",
    "                    \n",
    "        test_loader = DataLoader(\n",
    "            test_data,\n",
    "            shuffle=shuffle,\n",
    "            batch_size=batch_size\n",
    "            )\n",
    "\n",
    "        return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbe36ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "TDM_dataset = TransformersNLI(tokenizer, max_input_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6312bbb1-5ba4-47ae-a767-0e0d770f504a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader = TDM_dataset.get_train_data(train_df, batch_size=bs, shuffle=True)\n",
    "# valid_loader = TDM_dataset.get_valid_data(valid_df, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33467dbe-6cc5-490b-894f-75b4264fa2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256008/256008 [13:04<00:00, 326.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256008\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(f'{output_path}train_loader_{bs}_seq_{max_input_length}.pth'):\n",
    "    train_loader = torch.load(f'{output_path}train_loader_{bs}_seq_{max_input_length}.pth')\n",
    "else:\n",
    "    train_loader = TDM_dataset.get_train_data(train_df, batch_size=bs, shuffle=True)\n",
    "    # Save dataloader\n",
    "    torch.save(train_loader, f'{output_path}train_loader_{bs}_seq_{max_input_length}.pth')\n",
    "\n",
    "if os.path.exists(f'{output_path}valid_loader_{bs}_seq_{max_input_length}.pth'):\n",
    "    valid_loader = torch.load(f'{output_path}valid_loader_{bs}_seq_{max_input_length}.pth')\n",
    "else:\n",
    "    valid_loader = TDM_dataset.get_valid_data(valid_df, batch_size=bs, shuffle=True)\n",
    "    # Save dataloader\n",
    "    torch.save(valid_loader, f'{output_path}valid_loader_{bs}_seq_{max_input_length}.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c407a6-8d2f-4f30-95a7-4b33f2264046",
   "metadata": {},
   "source": [
    "## Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b5008d2-0b45-4411-a353-1898dab4690b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.bias', 'lm_loss.weight']\n",
      "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.weight', 'sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "model = selected_processor[1].from_pretrained(\n",
    "                                selected_processor[2], num_labels=2)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model = nn.DataParallel(model)\n",
    "else:\n",
    "    print(f\"Device: {device}\")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "param_optimizer = list(model.named_parameters())\n",
    "\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "    'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "    'weight_decay_rate': 0.0}\n",
    "]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5, correct_bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7042ca2-8334-4f6f-bdaf-b2fa6d084def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 117,310,466 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb4e40ec-47a1-4a9c-9d7b-8eb6114ce843",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "75ee35c0-656e-49e5-b792-e2415e101cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, epoch):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    train_loss = AverageMeter()\n",
    "    train_acc = AverageMeter()\n",
    "    train_macro_p = AverageMeter()\n",
    "    train_macro_r = AverageMeter()\n",
    "    train_macro_f1 = AverageMeter()\n",
    "    train_micro_p = AverageMeter()\n",
    "    train_micro_r = AverageMeter()\n",
    "    train_micro_f1 = AverageMeter()\n",
    "    \n",
    "    for batch_idx, (pair_token_ids, mask_ids, seg_ids, y) in tqdm(enumerate(iterator), total=len(iterator)):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        pair_token_ids = pair_token_ids.to(device)\n",
    "        mask_ids = mask_ids.to(device)\n",
    "        seg_ids = seg_ids.to(device)\n",
    "        labels = y.to(device)\n",
    "#         ipdb.set_trace()\n",
    "\n",
    "#         loss, prediction = model(pair_token_ids, \n",
    "#                             token_type_ids=seg_ids, \n",
    "#                             attention_mask=mask_ids, \n",
    "#                             labels=labels).values()          \n",
    "        \n",
    "        outputs = model(pair_token_ids, \n",
    "                        token_type_ids=seg_ids, \n",
    "                        attention_mask=mask_ids, \n",
    "                        labels=labels)\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        prediction = outputs.logits\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "                \n",
    "        prediction = torch.log_softmax(prediction, dim=1).argmax(dim=1)\n",
    "\n",
    "        train_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/len(labels)) # accuracy_score(labels.cpu(), prediction.cpu())\n",
    "        train_loss.update(loss.item())  \n",
    "        train_macro_p.update(precision_score(labels.cpu(), prediction.cpu(), average ='macro'))\n",
    "        train_macro_r.update(recall_score(labels.cpu(), prediction.cpu(), average ='macro'))\n",
    "        train_macro_f1.update(f1_score(labels.cpu(), prediction.cpu(), average ='macro'))\n",
    "        train_micro_p.update(precision_score(labels.cpu(), prediction.cpu(), average ='micro'))\n",
    "        train_micro_r.update(recall_score(labels.cpu(), prediction.cpu(), average ='micro'))\n",
    "        train_micro_f1.update(f1_score(labels.cpu(), prediction.cpu(), average ='micro'))\n",
    "        \n",
    "        if (batch_idx + 1) % 1000 == 0:\n",
    "            print(f\"[epoch {epoch+1}] [iter {(batch_idx + 1)}/{len(iterator)}]\")\n",
    "            print('------------------------------------------------------------')\n",
    "            print(f\"Train Accuracy Score: {train_acc.avg}; Train loss : {train_loss.avg}\")\n",
    "            print(f\"Macro Precision: {train_macro_p.avg}; Macro Recall : {train_macro_r.avg}; Macro F1 : {train_macro_f1.avg}\")\n",
    "            print(f\"Micro Precision: {train_micro_p.avg}; Micro Recall : {train_micro_r.avg}; Micro F1 : {train_micro_f1.avg}\")\n",
    "            print('------------------------------------------------------------')\n",
    "            \n",
    "    return train_loss.avg, train_acc.avg, train_macro_p.avg, train_macro_r.avg, train_macro_f1.avg, train_micro_p.avg, train_micro_r.avg, train_micro_f1.avg\n",
    "\n",
    "\n",
    "def evaluate(model, iterator, optimizer):\n",
    "        \n",
    "    model.eval()\n",
    "    val_loss = AverageMeter()\n",
    "    val_acc = AverageMeter()\n",
    "    val_macro_p = AverageMeter()\n",
    "    val_macro_r = AverageMeter()\n",
    "    val_macro_f1 = AverageMeter()\n",
    "    val_micro_p = AverageMeter()\n",
    "    val_micro_r = AverageMeter()\n",
    "    val_micro_f1 = AverageMeter()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch_idx, (pair_token_ids, mask_ids, seg_ids, y) in tqdm(enumerate(iterator), total=len(iterator)):\n",
    "#             optimizer.zero_grad()\n",
    "            pair_token_ids = pair_token_ids.to(device)\n",
    "            mask_ids = mask_ids.to(device)\n",
    "            seg_ids = seg_ids.to(device)\n",
    "            labels = y.to(device)\n",
    "\n",
    "            outputs = model(pair_token_ids, \n",
    "                        token_type_ids=seg_ids, \n",
    "                        attention_mask=mask_ids, \n",
    "                        labels=labels)\n",
    "            \n",
    "            loss = outputs.loss\n",
    "            prediction = outputs.logits\n",
    "\n",
    "            prediction = torch.log_softmax(prediction, dim=1).argmax(dim=1)\n",
    "\n",
    "            val_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/len(labels)) # accuracy_score(labels.cpu(), prediction.cpu())\n",
    "            val_macro_p.update(precision_score(labels.cpu(), prediction.cpu(), average ='macro'))\n",
    "            val_macro_r.update(recall_score(labels.cpu(), prediction.cpu(), average ='macro'))\n",
    "            val_macro_f1.update(f1_score(labels.cpu(), prediction.cpu(), average ='macro'))\n",
    "            val_micro_p.update(precision_score(labels.cpu(), prediction.cpu(), average ='micro'))\n",
    "            val_micro_r.update(recall_score(labels.cpu(), prediction.cpu(), average ='micro'))\n",
    "            val_micro_f1.update(f1_score(labels.cpu(), prediction.cpu(), average ='micro'))\n",
    "            val_loss.update(loss.item())        \n",
    "\n",
    "    \n",
    "    val_macro_avg_p, val_macro_avg_r, val_macro_avg_f1 = val_macro_p.avg, val_macro_r.avg, val_macro_f1.avg \n",
    "    val_micro_avg_p, val_micro_avg_r, val_micro_avg_f1 = val_micro_p.avg, val_micro_r.avg, val_micro_f1.avg \n",
    "\n",
    "    print('------------------------------------------------------------')\n",
    "    print(f\"Validation Accuracy Score : {val_acc.avg}; Vadidation loss : {val_loss.avg}\")\n",
    "    print(f\"Macro Precision : {val_macro_avg_p}; Macro Recall : {val_macro_avg_r}; Macro F1 : {val_macro_avg_f1}\")\n",
    "    print(f\"Micro Precision : {val_micro_avg_p}; Micro Recall : {val_micro_avg_r}; Micro F1 : {val_micro_avg_f1}\")\n",
    "    print('------------------------------------------------------------')\n",
    "    \n",
    "    return val_loss.avg, val_acc.avg, val_macro_avg_p, val_macro_avg_r, val_macro_avg_f1, val_micro_avg_p, val_micro_avg_r, val_micro_avg_f1\n",
    "\n",
    "def predict_TDM_from_pdf(model, tokenizer, iterator, output_path):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch_idx, (pair_token_ids, mask_ids, seg_ids, y) in tqdm(enumerate(iterator), total=len(iterator)):\n",
    "            pair_token_ids = pair_token_ids.to(device)\n",
    "            mask_ids = mask_ids.to(device)\n",
    "            seg_ids = seg_ids.to(device)\n",
    "            labels = y.to(device)\n",
    "\n",
    "            outputs = model(pair_token_ids, \n",
    "                        token_type_ids=seg_ids, \n",
    "                        attention_mask=mask_ids, \n",
    "                        labels=labels)\n",
    "        \n",
    "            loss = outputs.loss\n",
    "            prediction = outputs.logits\n",
    "\n",
    "            prediction_scalled = torch.sigmoid(prediction)\n",
    "            \n",
    "            with open(f\"{output_path}test_results.tsv\", \"a+\", encoding=\"utf-8\") as text_file:\n",
    "                for true, false in prediction_scalled.cpu():\n",
    "                    text_file.write(str(true.item())+\"\\t\"+str(false.item())+\"\\n\")\n",
    "\n",
    "def get_top_n_prediction_label(path_to_test_file, path_to_prediction_file, output_path, n = 5):\n",
    "    \"\"\"\n",
    "    This function return the label with the highest proba\n",
    "    \"\"\"\n",
    "    top5 = deque()\n",
    "    with open(f\"{path_to_test_file}\") as f:\n",
    "        txt_test_files = f.read().splitlines()\n",
    "    with open(f\"{path_to_prediction_file}\") as f:\n",
    "        txt_prediction_files = f.read().splitlines()\n",
    "    \n",
    "    for example, prediction in zip(txt_test_files, txt_prediction_files):\n",
    "        true_prob, false_prob = prediction.split(\"\\t\")\n",
    "        true_prob, false_prob = float(true_prob), float(false_prob)\n",
    "        if true_prob > false_prob:\n",
    "            label = example.split(\"\\t\")[2]\n",
    "            top5.append((label, true_prob))\n",
    "    results = deque(sorted(top5, key=lambda x: x[1] if x else x, reverse=False), n)\n",
    "    with open(f\"{output_path}test_top_{n}_tdm.tsv\", \"w+\", encoding=\"utf-8\") as text_file:\n",
    "        for tdm in results:\n",
    "            text_file.write(f\"{tdm[0]}\\t{tdm[1]}\\n\")\n",
    "    return results\n",
    "\n",
    "def write_evaluation_result(val_macro_avg_p, val_macro_avg_r, val_macro_avg_f1, val_micro_avg_p, val_micro_avg_r, val_micro_avg_f1, output_path):\n",
    "    with open(f\"{output_path}evaluation_tdm_results.tsv\", \"w+\", encoding=\"utf-8\") as text_file:\n",
    "        text_file.write(f\"Macro P\\tMacro R\\t Macro F1\\t Micro P\\t Micro R\\t Micro F1\\n\")\n",
    "        text_file.write(f\"{val_macro_avg_p}\\t{val_macro_avg_r}\\t{val_macro_avg_f1}\\t{val_micro_avg_p}\\t{val_micro_avg_r}\\t{val_micro_avg_f1}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "612082ba-34db-4655-9570-5d54663b903b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5067b33e-a8ea-4535-a322-5fccbd6be18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/6779 [00:01<43:50,  2.58it/s]/nfs/home/kabenamualus/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "  0%|          | 5/6779 [00:01<43:57,  2.57it/s]/nfs/home/kabenamualus/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "  0%|          | 20/6779 [00:07<47:04,  2.39it/s]/nfs/home/kabenamualus/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "  0%|          | 25/6779 [00:09<43:07,  2.61it/s]/nfs/home/kabenamualus/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "  1%|          | 40/6779 [00:15<44:27,  2.53it/s]/nfs/home/kabenamualus/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "  1%|          | 47/6779 [00:18<47:53,  2.34it/s]/nfs/home/kabenamualus/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "  1%|          | 51/6779 [00:20<45:39,  2.46it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-6e825f60c2ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#     train_loss, train_acc, train_macro_avg_p, train_macro_avg_r, train_macro_avg_f1, train_micro_avg_p, train_micro_avg_r, train_micro_avg_f1 = train(model, train_loader, optimizer, epoch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_macro_avg_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_macro_avg_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_macro_avg_f1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_micro_avg_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_micro_avg_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_micro_avg_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-1f1f50c18b57>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, iterator, optimizer)\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0mval_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# accuracy_score(labels.cpu(), prediction.cpu())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m             \u001b[0mval_macro_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m'macro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mval_macro_r\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m'macro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_valid_loss = 0.30 #float('inf')\n",
    "best_valid_f1 = 0.5\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "#     train_loss, train_acc, train_macro_avg_p, train_macro_avg_r, train_macro_avg_f1, train_micro_avg_p, train_micro_avg_r, train_micro_avg_f1 = train(model, train_loader, optimizer, epoch)\n",
    "    valid_loss, valid_acc, val_macro_avg_p, val_macro_avg_r, val_macro_avg_f1, val_micro_avg_p, val_micro_avg_r, val_micro_avg_f1 = evaluate(model, valid_loader, optimizer)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} Final | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print('------------------------------------------------------------')\n",
    "    print(f\"Train Accuracy Score: {train_acc}; Train loss : {train_loss}\")\n",
    "    print(f\"Macro Precision: {train_macro_avg_p}; Macro Recall : {train_macro_avg_r}; Macro F1 : {train_macro_avg_f1}\")\n",
    "    print(f\"Micro Precision: {train_micro_avg_p}; Micro Recall : {train_micro_avg_r}; Micro F1 : {train_micro_avg_f1}\")\n",
    "    print('------------------------------------------------------------')\n",
    "    \n",
    "    valid_metric_avg = (val_macro_avg_p + val_macro_avg_r + val_macro_avg_f1+val_micro_avg_p + val_micro_avg_r + val_micro_avg_f1)/6\n",
    "    \n",
    "    \n",
    "    \n",
    "    if valid_metric_avg > best_valid_metric_avg : #and abs(valid_loss - best_valid_loss) < 1e-1\n",
    "        best_valid_metric_avg = valid_metric_avg\n",
    "        print('Saving Model ...')\n",
    "        torch.save(model.state_dict(), f'{output_path}Model_{model_name}_avg_metric_{str(best_valid_metric_avg)[:4]}.pt')\n",
    "        print('****************************************************************************')\n",
    "        print('best record: [epoch %d], [val loss %.5f], [val acc %.5f], [val avg. metric %.5f]' % (epoch, valid_loss, valid_acc, valid_metric_avg))\n",
    "        print(f\"Macro Precision : {val_macro_avg_p}; Macro Recall : {val_macro_avg_r}; Macro F1 : {val_macro_avg_f1}\")\n",
    "        print(f\"Micro Precision : {val_micro_avg_p}; Micro Recall : {val_micro_avg_r}; Micro F1 : {val_micro_avg_f1}\")\n",
    "        print('****************************************************************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cd9eb3-24f6-4036-9f8b-0a25fd60a873",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "We'll then use the model to test the sentiment of some sequences. We tokenize the input sequence, trim it down to the maximum length, add the special tokens to either side, convert it to a tensor, add a fake batch dimension and then pass it through our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd499fd-ee3b-4909-bbc5-9f5af8c7c5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the best model\n",
    "model.load_state_dict(torch.load('Model_f1_0.93.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e64d764-527a-4d51-836f-04e003c89b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>TDM</th>\n",
       "      <th>Context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>1203.1005v3.pdf</td>\n",
       "      <td>Single Image Deraining; Rain100H; PSNR</td>\n",
       "      <td>Sparse Subspace Clustering: Algorithm, Theory,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>1203.1005v3.pdf</td>\n",
       "      <td>Question Answering; YahooCQA; P@1</td>\n",
       "      <td>Sparse Subspace Clustering: Algorithm, Theory,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>1203.1005v3.pdf</td>\n",
       "      <td>Atari Games; Atari 2600 Private Eye; Score</td>\n",
       "      <td>Sparse Subspace Clustering: Algorithm, Theory,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>1203.1005v3.pdf</td>\n",
       "      <td>Speech Recognition; MediaSpeech; WER for Turkish</td>\n",
       "      <td>Sparse Subspace Clustering: Algorithm, Theory,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>1203.1005v3.pdf</td>\n",
       "      <td>3D Point Cloud Classification; ModelNet40; Mea...</td>\n",
       "      <td>Sparse Subspace Clustering: Algorithm, Theory,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label            title                                                TDM  \\\n",
       "0   True  1203.1005v3.pdf             Single Image Deraining; Rain100H; PSNR   \n",
       "1   True  1203.1005v3.pdf                  Question Answering; YahooCQA; P@1   \n",
       "2   True  1203.1005v3.pdf         Atari Games; Atari 2600 Private Eye; Score   \n",
       "3   True  1203.1005v3.pdf   Speech Recognition; MediaSpeech; WER for Turkish   \n",
       "4   True  1203.1005v3.pdf  3D Point Cloud Classification; ModelNet40; Mea...   \n",
       "\n",
       "                                             Context  \n",
       "0  Sparse Subspace Clustering: Algorithm, Theory,...  \n",
       "1  Sparse Subspace Clustering: Algorithm, Theory,...  \n",
       "2  Sparse Subspace Clustering: Algorithm, Theory,...  \n",
       "3  Sparse Subspace Clustering: Algorithm, Theory,...  \n",
       "4  Sparse Subspace Clustering: Algorithm, Theory,...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_df = pd.read_csv(\"../data/paperwithcode/new/60Neg800unk/twofoldwithunk/fold1/test_results.tsv\", \n",
    "#                    sep=\"\\t\", names=[\"true\", \"false\"])\n",
    "\n",
    "test_df = pd.read_csv(\"../data/paperwithcode/new/jar/10Neg20unk/testOutput.tsv\", \n",
    "                   sep=\"\\t\", names=[\"label\", \"title\", \"TDM\", \"Context\"])\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d81d25ea-3635-4d9b-81e6-bf116431e900",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2655/2655 [00:39<00:00, 67.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2655\n"
     ]
    }
   ],
   "source": [
    "test_loader = TDM_dataset.get_inference_data(test_df, batch_size=16, shuffle=False) # this shuffle should be false to preserve the order "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c7891d91-b5e2-4696-8ad3-fb0de3a3ef32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = iter(test_loader)\n",
    "# sample.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dab4f06-470a-4fa3-92d6-3852f579b6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict_TDM_from_pdf(model, tokenizer, sentence):\n",
    "#     model.eval()\n",
    "#     tokens = tokenizer.tokenize(sentence)\n",
    "#     tokens = tokens[:max_input_length-2]\n",
    "#     indexed = [init_token_idx] + tokenizer.convert_tokens_to_ids(tokens) + [eos_token_idx]\n",
    "#     tensor = torch.LongTensor(indexed).to(device)\n",
    "#     tensor = tensor.unsqueeze(0)\n",
    "#     prediction = torch.sigmoid(model(tensor))\n",
    "#     return prediction.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "762f6352-d446-481b-bcb0-b4b2971329d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_TDM_from_pdf(model, tokenizer, iterator):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch_idx, (pair_token_ids, mask_ids, seg_ids, y) in tqdm(enumerate(iterator), total=len(iterator)):\n",
    "            pair_token_ids = pair_token_ids.to(device)\n",
    "            mask_ids = mask_ids.to(device)\n",
    "            seg_ids = seg_ids.to(device)\n",
    "            labels = y.to(device)\n",
    "\n",
    "            loss, prediction = model(pair_token_ids, \n",
    "                                 token_type_ids=seg_ids, \n",
    "                                 attention_mask=mask_ids, \n",
    "                                 labels=labels).values()\n",
    "\n",
    "            prediction_scalled = torch.sigmoid(prediction)\n",
    "            \n",
    "            with open(\"test_results.tsv\", \"a+\", encoding=\"utf-8\") as text_file:\n",
    "                for true, false in prediction_scalled.cpu():\n",
    "                    text_file.write(str(true.item())+\"\\t\"+str(false.item())+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4c6f79b9-1a81-4f46-9e61-3481124bc3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 166/166 [00:31<00:00,  5.35it/s]\n"
     ]
    }
   ],
   "source": [
    "predict_TDM_from_pdf(model, tokenizer, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b7940ca5-e2ea-49ef-bf52-33381d919850",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "def get_top_n_prediction_label(path_to_test_file, path_to_prediction_file, n = 5):\n",
    "    \"\"\"\n",
    "    This function return the label with the highest proba\n",
    "    \"\"\"\n",
    "    top5 = deque()\n",
    "    with open(f\"{path_to_test_file}\") as f:\n",
    "        txt_test_files = f.read().splitlines()\n",
    "    with open(f\"{path_to_prediction_file}\") as f:\n",
    "        txt_prediction_files = f.read().splitlines()\n",
    "    \n",
    "    highest = 0\n",
    "    for example, prediction in zip(txt_test_files, txt_prediction_files):\n",
    "        true_prob, false_prob = prediction.split(\"\\t\")\n",
    "        true_prob, false_prob = float(true_prob), float(false_prob)\n",
    "        if true_prob > false_prob:\n",
    "            label = example.split(\"\\t\")[2]\n",
    "            highest = true_prob\n",
    "            top5.append((label, true_prob))\n",
    "    return deque(sorted(top5, key=lambda x: x[1] if x else x, reverse=False), n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1bca4393-e4a3-48d7-bec5-b798421c4e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([('Image Clustering; Extended Yale-B; Accuracy', 0.8984434008598328)])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_n_prediction_label(\n",
    "    path_to_test_file=\"../data/paperwithcode/new/jar/10Neg20unk/testOutput.tsv\",\n",
    "    path_to_prediction_file=\"test_results.tsv\", \n",
    "    n = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e575f45a-904d-48b0-ba9d-a9df520e8799",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
