{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df255ac4",
   "metadata": {},
   "source": [
    "# Package loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19c78d49",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "/nfs/home/kabenamualus/.local/lib/python3.7/site-packages/torchtext/_torchtext.so: undefined symbol: _ZNK3c104Type14isSubtypeOfExtERKSt10shared_ptrIS0_EPSo",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6cd4bafac958>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torchtext/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexperimental\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlegacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torchtext/experimental/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0m__all__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'datasets'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'transforms'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'models'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torchtext/experimental/transforms.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_torchtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRegexTokenizer\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mRegexTokenizerPybind\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_torchtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentencePiece\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mSentencePiecePybind\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: /nfs/home/kabenamualus/.local/lib/python3.7/site-packages/torchtext/_torchtext.so: undefined symbol: _ZNK3c104Type14isSubtypeOfExtERKSt10shared_ptrIS0_EPSo"
     ]
    }
   ],
   "source": [
    "# Imports \n",
    "import os\n",
    "import json\n",
    "import argparse\n",
    "import time\n",
    "import ipdb\n",
    "import spacy\n",
    "import torch\n",
    "import optuna\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import deque\n",
    "\n",
    "import torch.optim as optim\n",
    "from torchtext import data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transformers import RobertaTokenizer, BertModel, TransfoXLTokenizer, TransfoXLModel, AdamW\n",
    "from transformers import BigBirdTokenizer, BigBirdForSequenceClassification\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import LongformerTokenizer, LongformerForSequenceClassification\n",
    "from transformers import XLNetTokenizer, XLNetForSequenceClassification\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113a12e9-683a-40da-b0aa-60630d756811",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90d22c6",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11392036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_path = \"/nfs/home/kabenamualus/Research/task-dataset-metric-extraction/data/paperwithcode/5Neg10unk/twofoldwithunk/fold1/train.tsv\"\n",
    "# valid_path = \"/nfs/home/kabenamualus/Research/task-dataset-metric-extraction/data/paperwithcode/5Neg10unk/twofoldwithunk/fold1/dev.tsv\"\n",
    "\n",
    "# train_path = \"/nfs/home/kabenamualus/Research/task-dataset-metric-extraction/data/paperwithcode/new/60Neg800unk/twofoldwithunk/fold1/train.tsv\"\n",
    "# valid_path = \"/nfs/home/kabenamualus/Research/task-dataset-metric-extraction/data/paperwithcode/new/60Neg800unk/twofoldwithunk/fold1/dev.tsv\"\n",
    "\n",
    "N_EPOCHS = 3\n",
    "bs = 4\n",
    "model_name = \"Longformer\" #\"SciBert\"\n",
    "max_input_len = 512\n",
    "\n",
    "train_path = \"/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/pwc_latex_text/pwc_latex_5_10_10000/twofoldwithunk/fold1/train.tsv\"\n",
    "valid_path = \"/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/pwc_latex_text/pwc_latex_5_10_10000/twofoldwithunk/fold1/dev.tsv\"\n",
    "output_path = f\"/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/pwc_latex_text/pwc_latex_5_10_10000/twofoldwithunk/fold1/{model_name}/\"\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "# model_pt_path = \"/nfs/home/kabenamualus/Research/task-dataset-metric-extraction/data/ibm/exp/few-shot-setup/NLP-TDMS/paperVersion/torch/SciBert/Model_SciBert_avg_metric_0.9001.pt\"\n",
    "\n",
    "\n",
    "# output_path = \"/nfs/home/kabenamualus/Research/task-dataset-metric-extraction/data/paperwithcode/new/60Neg800unk/twofoldwithunk/fold1/\"\n",
    "\n",
    "\n",
    "processors = {\n",
    "      \"Bert\": [BertTokenizer, BertForSequenceClassification, \"bert-base-uncased\"],\n",
    "      \"SciBert\": [BertTokenizer, BertForSequenceClassification, \"allenai/scibert_scivocab_uncased\"],\n",
    "      \"XLNet\": [XLNetTokenizer, XLNetForSequenceClassification, \"xlnet-base-cased\"],\n",
    "      \"BigBird\": [BigBirdTokenizer, BigBirdForSequenceClassification, \"google/bigbird-roberta-base\"],\n",
    "      \"Longformer\": [LongformerTokenizer, LongformerForSequenceClassification, \"allenai/longformer-base-4096\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18b01242",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_path, \n",
    "                    sep=\"\\t\", names=[\"label\", \"title\", \"TDM\", \"Context\"])\n",
    "\n",
    "valid_df = pd.read_csv(valid_path, \n",
    "                   sep=\"\\t\", names=[\"label\", \"title\", \"TDM\", \"Context\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42801266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>TDM</th>\n",
       "      <th>Context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>1810.02575v1.pdf</td>\n",
       "      <td>Semantic Segmentation; Nighttime Driving; mIoU</td>\n",
       "      <td>Dark Model Adaptation: Semantic Image Segmenta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>1810.02575v1.pdf</td>\n",
       "      <td>Relation Extraction; DocRED; Ign F1</td>\n",
       "      <td>Dark Model Adaptation: Semantic Image Segmenta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>1810.02575v1.pdf</td>\n",
       "      <td>Text Classification; 20NEWS; Accuracy</td>\n",
       "      <td>Dark Model Adaptation: Semantic Image Segmenta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>1810.02575v1.pdf</td>\n",
       "      <td>Synthetic-to-Real Translation; Syn2Real-C; Acc...</td>\n",
       "      <td>Dark Model Adaptation: Semantic Image Segmenta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>1810.02575v1.pdf</td>\n",
       "      <td>Node Classification; Cora; Validation</td>\n",
       "      <td>Dark Model Adaptation: Semantic Image Segmenta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label             title                                                TDM  \\\n",
       "0   True  1810.02575v1.pdf     Semantic Segmentation; Nighttime Driving; mIoU   \n",
       "1  False  1810.02575v1.pdf                Relation Extraction; DocRED; Ign F1   \n",
       "2  False  1810.02575v1.pdf              Text Classification; 20NEWS; Accuracy   \n",
       "3  False  1810.02575v1.pdf  Synthetic-to-Real Translation; Syn2Real-C; Acc...   \n",
       "4  False  1810.02575v1.pdf              Node Classification; Cora; Validation   \n",
       "\n",
       "                                             Context  \n",
       "0  Dark Model Adaptation: Semantic Image Segmenta...  \n",
       "1  Dark Model Adaptation: Semantic Image Segmenta...  \n",
       "2  Dark Model Adaptation: Semantic Image Segmenta...  \n",
       "3  Dark Model Adaptation: Semantic Image Segmenta...  \n",
       "4  Dark Model Adaptation: Semantic Image Segmenta...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b94de188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>TDM</th>\n",
       "      <th>Context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>1707.03497v2.pdf</td>\n",
       "      <td>Atari Games; Atari 2600 Seaquest; Score</td>\n",
       "      <td>Value Prediction Network This paper proposes a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>1707.03497v2.pdf</td>\n",
       "      <td>Atari Games; Atari 2600 Amidar; Score</td>\n",
       "      <td>Value Prediction Network This paper proposes a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>1707.03497v2.pdf</td>\n",
       "      <td>Atari Games; Atari 2600 Krull; Score</td>\n",
       "      <td>Value Prediction Network This paper proposes a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>1707.03497v2.pdf</td>\n",
       "      <td>Atari Games; Atari 2600 Alien; Score</td>\n",
       "      <td>Value Prediction Network This paper proposes a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>1707.03497v2.pdf</td>\n",
       "      <td>Atari Games; Atari 2600 Enduro; Score</td>\n",
       "      <td>Value Prediction Network This paper proposes a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label             title                                      TDM  \\\n",
       "0   True  1707.03497v2.pdf  Atari Games; Atari 2600 Seaquest; Score   \n",
       "1   True  1707.03497v2.pdf    Atari Games; Atari 2600 Amidar; Score   \n",
       "2   True  1707.03497v2.pdf     Atari Games; Atari 2600 Krull; Score   \n",
       "3   True  1707.03497v2.pdf     Atari Games; Atari 2600 Alien; Score   \n",
       "4   True  1707.03497v2.pdf    Atari Games; Atari 2600 Enduro; Score   \n",
       "\n",
       "                                             Context  \n",
       "0  Value Prediction Network This paper proposes a...  \n",
       "1  Value Prediction Network This paper proposes a...  \n",
       "2  Value Prediction Network This paper proposes a...  \n",
       "3  Value Prediction Network This paper proposes a...  \n",
       "4  Value Prediction Network This paper proposes a...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3088c298",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5059de50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> </s> <pad> <unk>\n"
     ]
    }
   ],
   "source": [
    "if model_name in processors.keys():\n",
    "    selected_processor = processors[model_name]\n",
    "else:\n",
    "    print(f\"Model not available check selected model only {list(processors.keys())} as supported\")\n",
    "    quit()\n",
    "\n",
    "if model_name == \"SciBert\":\n",
    "    tokenizer = selected_processor[0].from_pretrained(\"bert-base-uncased\")\n",
    "else:\n",
    "    tokenizer = selected_processor[0].from_pretrained(selected_processor[2])\n",
    "\n",
    "init_token = tokenizer.cls_token\n",
    "eos_token = tokenizer.sep_token\n",
    "pad_token = tokenizer.pad_token\n",
    "unk_token = tokenizer.unk_token\n",
    "\n",
    "print(init_token, eos_token, pad_token, unk_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11bb3a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2 1 3\n"
     ]
    }
   ],
   "source": [
    "init_token_idx = tokenizer.convert_tokens_to_ids(init_token)\n",
    "eos_token_idx = tokenizer.convert_tokens_to_ids(eos_token)\n",
    "pad_token_idx = tokenizer.convert_tokens_to_ids(pad_token)\n",
    "unk_token_idx = tokenizer.convert_tokens_to_ids(unk_token)\n",
    "\n",
    "print(init_token_idx, eos_token_idx, pad_token_idx, unk_token_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc9e348b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096\n",
      "Maximun sequence lenght 4096\n"
     ]
    }
   ],
   "source": [
    "if model_name == \"SciBert\":\n",
    "    max_input_length = tokenizer.max_model_input_sizes[\"bert-base-uncased\"]\n",
    "else:\n",
    "    max_input_length = tokenizer.max_model_input_sizes[selected_processor[2]]\n",
    "    \n",
    "print(max_input_length)\n",
    "\n",
    "if not max_input_length:\n",
    "    max_input_length = max_input_len\n",
    "\n",
    "print(f\"Maximun sequence lenght {max_input_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71f0bb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformersNLI(Dataset):\n",
    "    def __init__(self, tokenizer, max_input_length):\n",
    "        self.label_dict = {'True': 0, 'False': 1} # Default {'entailment': 0, 'contradiction': 1, 'neutral': 2}\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_input_length = max_input_length        \n",
    "        \n",
    "    def _truncate_seq_pair(self, tokens_a, tokens_b, max_length):\n",
    "        \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n",
    "\n",
    "        # This is a simple heuristic which will always truncate the longer sequence\n",
    "        # one token at a time. This makes more sense than truncating an equal percent\n",
    "        # of tokens from each, since if one sequence is very short then each token\n",
    "        # that's truncated likely contains more information than a longer sequence.\n",
    "        while True:\n",
    "            total_length = len(tokens_a) + len(tokens_b)\n",
    "            if total_length <= max_length:\n",
    "                break\n",
    "            if len(tokens_a) > len(tokens_b):\n",
    "                tokens_a.pop()\n",
    "            else:\n",
    "                tokens_b.pop()\n",
    "        \n",
    "    def load_data(self, df):\n",
    "        MAX_LEN = self.max_input_length\n",
    "        token_ids = []\n",
    "        mask_ids = []\n",
    "        seg_ids = []\n",
    "        y = []\n",
    "\n",
    "        premise_list = df['TDM'].to_list()           # df['sentence1'].to_list()\n",
    "        hypothesis_list = df['Context'].to_list()    # df['sentence2'].to_list()\n",
    "        label_list = df['label'].to_list()           # df['gold_label'].to_list()\n",
    "\n",
    "        for (premise, hypothesis, label) in tqdm(zip(premise_list, hypothesis_list, label_list), total=len(label_list)):\n",
    "            premise_id = self.tokenizer.encode(premise, add_special_tokens = False)\n",
    "            hypothesis_id = self.tokenizer.encode(hypothesis, add_special_tokens = False)\n",
    "            # ignore the warning as the ong sequence issuw is taken care of here \n",
    "            self._truncate_seq_pair(premise_id, hypothesis_id, MAX_LEN-3) # -3 to account for the special characters \n",
    "            \n",
    "            pair_token_ids = [self.tokenizer.cls_token_id] + premise_id \\\n",
    "                            + [self.tokenizer.sep_token_id] + hypothesis_id \\\n",
    "                            + [self.tokenizer.sep_token_id]\n",
    "            premise_len = len(premise_id)\n",
    "            hypothesis_len = len(hypothesis_id)\n",
    "\n",
    "            segment_ids = torch.tensor([0] * (premise_len + 2) + [1] * (hypothesis_len + 1))  # sentence 0 and sentence 1\n",
    "            attention_mask_ids = torch.tensor([1] * (premise_len + hypothesis_len + 3))  # mask padded values\n",
    "\n",
    "            token_ids.append(torch.tensor(pair_token_ids))\n",
    "            seg_ids.append(segment_ids)\n",
    "            mask_ids.append(attention_mask_ids)\n",
    "            # we have str(label) to have the key work proprely \n",
    "            y.append(self.label_dict[str(label)]) # y.append(self.label_dict[label]) \n",
    "            \n",
    "        token_ids = pad_sequence(token_ids, batch_first=True)\n",
    "        mask_ids = pad_sequence(mask_ids, batch_first=True)\n",
    "        seg_ids = pad_sequence(seg_ids, batch_first=True)\n",
    "        y = torch.tensor(y)\n",
    "        dataset = TensorDataset(token_ids, mask_ids, seg_ids, y)\n",
    "\n",
    "        print(len(dataset))\n",
    "\n",
    "        return dataset\n",
    "\n",
    "    def get_train_data(self, train_df, batch_size=32, shuffle=True):\n",
    "        train_data = self.load_data(train_df)\n",
    "                    \n",
    "        train_loader = DataLoader(\n",
    "            train_data,\n",
    "            shuffle=shuffle,\n",
    "            batch_size=batch_size\n",
    "            )\n",
    "\n",
    "        return train_loader\n",
    "\n",
    "    def get_valid_data(self, valid_df, batch_size=32, shuffle=True):\n",
    "        valid_data = self.load_data(valid_df)\n",
    "                    \n",
    "        valid_loader = DataLoader(\n",
    "            valid_data,\n",
    "            shuffle=shuffle,\n",
    "            batch_size=batch_size\n",
    "            )\n",
    "\n",
    "        return valid_loader\n",
    "\n",
    "    def get_inference_data(self, test_df, batch_size=32, shuffle=False):\n",
    "        test_data = self.load_data(test_df)\n",
    "                    \n",
    "        test_loader = DataLoader(\n",
    "            test_data,\n",
    "            shuffle=shuffle,\n",
    "            batch_size=batch_size\n",
    "            )\n",
    "\n",
    "        return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53939aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "TDM_dataset = TransformersNLI(tokenizer, max_input_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d941f31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader = TDM_dataset.get_train_data(train_df, batch_size=bs, shuffle=True)\n",
    "# valid_loader = TDM_dataset.get_valid_data(valid_df, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99e62165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if os.path.exists(f'{output_path}train_loader_{bs}_seq_{max_input_length}.pth'):\n",
    "#     train_loader = torch.load(f'{output_path}train_loader_{bs}_seq_{max_input_length}.pth')\n",
    "# else:\n",
    "#     train_loader = TDM_dataset.get_train_data(train_df, batch_size=bs, shuffle=True)\n",
    "#     # Save dataloader\n",
    "#     torch.save(train_loader, f'{output_path}train_loader_{bs}_seq_{max_input_length}.pth')\n",
    "\n",
    "# if os.path.exists(f'{output_path}valid_loader_{bs}_seq_{max_input_length}.pth'):\n",
    "#     valid_loader = torch.load(f'{output_path}valid_loader_{bs}_seq_{max_input_length}.pth')\n",
    "# else:\n",
    "#     valid_loader = TDM_dataset.get_valid_data(valid_df, batch_size=bs, shuffle=True)\n",
    "#     # Save dataloader\n",
    "#     torch.save(valid_loader, f'{output_path}valid_loader_{bs}_seq_{max_input_length}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94fae731-cf1a-4b05-b011-92d98b240e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(f'{output_path}train_loader_{bs}_seq_{max_input_length}.pth'):\n",
    "    train_loader = torch.load(f'{output_path}train_loader_{bs}_seq_{max_input_length}.pth')\n",
    "    # os.remove(f'{output_path}train_loader_{bs}_seq_{max_input_length}.pth')\n",
    "else:\n",
    "    train_loader = TDM_dataset.get_train_data(train_df, batch_size=bs, shuffle=True)\n",
    "    # Save dataloader\n",
    "    torch.save(train_loader, f'{output_path}train_loader_{bs}_seq_{max_input_length}.pth')\n",
    "\n",
    "if os.path.exists(f'{output_path}valid_loader_{bs}_seq_{max_input_length}.pth'):\n",
    "    valid_loader = torch.load(f'{output_path}valid_loader_{bs}_seq_{max_input_length}.pth')\n",
    "#     os.remove(f'{output_path}valid_loader_{bs}_seq_{max_input_length}.pth')\n",
    "# else:\n",
    "#     valid_loader = TDM_dataset.get_valid_data(valid_df, batch_size=bs, shuffle=True)\n",
    "#     # Save dataloader\n",
    "#     torch.save(valid_loader, f'{output_path}valid_loader_{bs}_seq_{max_input_length}.pth')\n",
    "\n",
    "# train_loader = TDM_dataset.get_train_data(train_df, batch_size=bs, shuffle=True)\n",
    "# valid_loader = TDM_dataset.get_valid_data(valid_df, batch_size=bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fa177de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if os.path.exists(f'{output_path}train_loader_{bs}_seq_{max_input_length}.pth'):\n",
    "#     train_loader = torch.load(f'{output_path}train_loader_{bs}_seq_{max_input_length}.pth')\n",
    "#     # os.remove(f'{output_path}train_loader_{bs}_seq_{max_input_length}.pth')\n",
    "# else:\n",
    "#     train_loader = TDM_dataset.get_train_data(train_df, batch_size=bs, shuffle=True)\n",
    "#     # Save dataloader\n",
    "#     torch.save(train_loader, f'{output_path}train_loader_{bs}_seq_{max_input_length}.pth')\n",
    "\n",
    "# if os.path.exists(f'{output_path}valid_loader_{bs}_seq_{max_input_length}.pth'):\n",
    "#     # valid_loader = torch.load(f'{output_path}valid_loader_{bs}_seq_{max_input_length}.pth')\n",
    "#     os.remove(f'{output_path}valid_loader_{bs}_seq_{max_input_length}.pth')\n",
    "# # else:\n",
    "# #     valid_loader = TDM_dataset.get_valid_data(valid_df, batch_size=bs, shuffle=True)\n",
    "# #     # Save dataloader\n",
    "# #     torch.save(valid_loader, f'{output_path}valid_loader_{bs}_seq_{max_input_length}.pth')\n",
    "\n",
    "# # train_loader = TDM_dataset.get_train_data(train_df, batch_size=bs, shuffle=True)\n",
    "# valid_loader = TDM_dataset.get_valid_data(valid_df, batch_size=bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06874545",
   "metadata": {},
   "source": [
    "## Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86f863ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "model = selected_processor[1].from_pretrained(\n",
    "                                selected_processor[2], num_labels=2)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model = nn.DataParallel(model)\n",
    "else:\n",
    "    print(f\"Device: {device}\")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "param_optimizer = list(model.named_parameters())\n",
    "\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "    'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "    'weight_decay_rate': 0.0}\n",
    "]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5, correct_bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f232b75-c187-4b5a-8c49-a1eebad24c5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8fe9d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 148,660,994 trainable parameters\n",
      "The model has 0 non-trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return (sum(p.numel() for p in model.parameters() if p.requires_grad), sum(p.numel() for p in model.parameters() if not p.requires_grad))\n",
    "\n",
    "print(f'The model has {count_parameters(model)[0]:,} trainable parameters')\n",
    "print(f'The model has {count_parameters(model)[1]:,} non-trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b5990d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd8d2ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, epoch):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    train_loss = AverageMeter()\n",
    "    train_acc = AverageMeter()\n",
    "    train_macro_p = AverageMeter()\n",
    "    train_macro_r = AverageMeter()\n",
    "    train_macro_f1 = AverageMeter()\n",
    "    train_micro_p = AverageMeter()\n",
    "    train_micro_r = AverageMeter()\n",
    "    train_micro_f1 = AverageMeter()\n",
    "    \n",
    "    for batch_idx, (pair_token_ids, mask_ids, seg_ids, y) in tqdm(enumerate(iterator), total=len(iterator)):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        pair_token_ids = pair_token_ids.to(device)\n",
    "        mask_ids = mask_ids.to(device)\n",
    "        seg_ids = seg_ids.to(device)\n",
    "        labels = y.to(device)\n",
    "        \n",
    "\n",
    "#         loss, prediction = model(pair_token_ids, \n",
    "#                             token_type_ids=seg_ids, \n",
    "#                             attention_mask=mask_ids, \n",
    "#                             labels=labels).values()          \n",
    "#         ipdb.set_trace()\n",
    "        \n",
    "        model.resize_token_embeddings(len(tokenizer))\n",
    "        \n",
    "        outputs = model(pair_token_ids, \n",
    "                        token_type_ids=seg_ids, \n",
    "                        attention_mask=mask_ids, \n",
    "                        labels=labels)\n",
    "        ipdb.set_trace()\n",
    "        loss = outputs.loss\n",
    "        prediction = outputs.logits\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "                \n",
    "        prediction = torch.log_softmax(prediction, dim=1).argmax(dim=1)\n",
    "\n",
    "        train_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/len(labels)) # accuracy_score(labels.cpu(), prediction.cpu())\n",
    "        train_loss.update(loss.item())  \n",
    "        train_macro_p.update(precision_score(labels.cpu(), prediction.cpu(), average ='macro'))\n",
    "        train_macro_r.update(recall_score(labels.cpu(), prediction.cpu(), average ='macro'))\n",
    "        train_macro_f1.update(f1_score(labels.cpu(), prediction.cpu(), average ='macro'))\n",
    "        train_micro_p.update(precision_score(labels.cpu(), prediction.cpu(), average ='micro'))\n",
    "        train_micro_r.update(recall_score(labels.cpu(), prediction.cpu(), average ='micro'))\n",
    "        train_micro_f1.update(f1_score(labels.cpu(), prediction.cpu(), average ='micro'))\n",
    "        \n",
    "        if (batch_idx + 1) % 1000 == 0:\n",
    "            print(f\"[epoch {epoch+1}] [iter {(batch_idx + 1)}/{len(iterator)}]\")\n",
    "            print('------------------------------------------------------------')\n",
    "            print(f\"Train Accuracy Score: {train_acc.avg}; Train loss : {train_loss.avg}\")\n",
    "            print(f\"Macro Precision: {train_macro_p.avg}; Macro Recall : {train_macro_r.avg}; Macro F1 : {train_macro_f1.avg}\")\n",
    "            print(f\"Micro Precision: {train_micro_p.avg}; Micro Recall : {train_micro_r.avg}; Micro F1 : {train_micro_f1.avg}\")\n",
    "            print('------------------------------------------------------------')\n",
    "            \n",
    "    return train_loss.avg, train_acc.avg, train_macro_p.avg, train_macro_r.avg, train_macro_f1.avg, train_micro_p.avg, train_micro_r.avg, train_micro_f1.avg\n",
    "\n",
    "\n",
    "def evaluate(model, iterator, optimizer):\n",
    "        \n",
    "    model.eval()\n",
    "    val_loss = AverageMeter()\n",
    "    val_acc = AverageMeter()\n",
    "    val_macro_p = AverageMeter()\n",
    "    val_macro_r = AverageMeter()\n",
    "    val_macro_f1 = AverageMeter()\n",
    "    val_micro_p = AverageMeter()\n",
    "    val_micro_r = AverageMeter()\n",
    "    val_micro_f1 = AverageMeter()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch_idx, (pair_token_ids, mask_ids, seg_ids, y) in tqdm(enumerate(iterator), total=len(iterator)):\n",
    "#             optimizer.zero_grad()\n",
    "            pair_token_ids = pair_token_ids.to(device)\n",
    "            mask_ids = mask_ids.to(device)\n",
    "            seg_ids = seg_ids.to(device)\n",
    "            labels = y.to(device)\n",
    "\n",
    "            outputs = model(pair_token_ids, \n",
    "                        token_type_ids=seg_ids, \n",
    "                        attention_mask=mask_ids, \n",
    "                        labels=labels)\n",
    "            \n",
    "            loss = outputs.loss\n",
    "            prediction = outputs.logits\n",
    "\n",
    "            prediction = torch.log_softmax(prediction, dim=1).argmax(dim=1)\n",
    "            \n",
    "            ipdb.set_trace()\n",
    "\n",
    "            val_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/len(labels)) # accuracy_score(labels.cpu(), prediction.cpu())\n",
    "            val_macro_p.update(precision_score(labels.cpu(), prediction.cpu(), average ='macro'))\n",
    "            val_macro_r.update(recall_score(labels.cpu(), prediction.cpu(), average ='macro'))\n",
    "            val_macro_f1.update(f1_score(labels.cpu(), prediction.cpu(), average ='macro'))\n",
    "            val_micro_p.update(precision_score(labels.cpu(), prediction.cpu(), average ='micro'))\n",
    "            val_micro_r.update(recall_score(labels.cpu(), prediction.cpu(), average ='micro'))\n",
    "            val_micro_f1.update(f1_score(labels.cpu(), prediction.cpu(), average ='micro'))\n",
    "            val_loss.update(loss.item())        \n",
    "\n",
    "    \n",
    "    val_macro_avg_p, val_macro_avg_r, val_macro_avg_f1 = val_macro_p.avg, val_macro_r.avg, val_macro_f1.avg \n",
    "    val_micro_avg_p, val_micro_avg_r, val_micro_avg_f1 = val_micro_p.avg, val_micro_r.avg, val_micro_f1.avg \n",
    "\n",
    "    print('------------------------------------------------------------')\n",
    "    print(f\"Validation Accuracy Score : {val_acc.avg}; Vadidation loss : {val_loss.avg}\")\n",
    "    print(f\"Macro Precision : {val_macro_avg_p}; Macro Recall : {val_macro_avg_r}; Macro F1 : {val_macro_avg_f1}\")\n",
    "    print(f\"Micro Precision : {val_micro_avg_p}; Micro Recall : {val_micro_avg_r}; Micro F1 : {val_micro_avg_f1}\")\n",
    "    print('------------------------------------------------------------')\n",
    "    \n",
    "    return val_loss.avg, val_acc.avg, val_macro_avg_p, val_macro_avg_r, val_macro_avg_f1, val_micro_avg_p, val_micro_avg_r, val_micro_avg_f1\n",
    "\n",
    "def predict_TDM_from_pdf(model, tokenizer, iterator, output_path):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch_idx, (pair_token_ids, mask_ids, seg_ids, y) in tqdm(enumerate(iterator), total=len(iterator)):\n",
    "            pair_token_ids = pair_token_ids.to(device)\n",
    "            mask_ids = mask_ids.to(device)\n",
    "            seg_ids = seg_ids.to(device)\n",
    "            labels = y.to(device)\n",
    "\n",
    "            outputs = model(pair_token_ids, \n",
    "                        token_type_ids=seg_ids, \n",
    "                        attention_mask=mask_ids, \n",
    "                        labels=labels)\n",
    "        \n",
    "            loss = outputs.loss\n",
    "            prediction = outputs.logits\n",
    "\n",
    "            prediction_scalled = torch.sigmoid(prediction)\n",
    "            \n",
    "            with open(f\"{output_path}test_results.tsv\", \"a+\", encoding=\"utf-8\") as text_file:\n",
    "                for true, false in prediction_scalled.cpu():\n",
    "                    text_file.write(str(true.item())+\"\\t\"+str(false.item())+\"\\n\")\n",
    "\n",
    "def get_top_n_prediction_label(path_to_test_file, path_to_prediction_file, output_path, n = 5):\n",
    "    \"\"\"\n",
    "    This function return the label with the highest proba\n",
    "    \"\"\"\n",
    "    top5 = deque()\n",
    "    with open(f\"{path_to_test_file}\") as f:\n",
    "        txt_test_files = f.read().splitlines()\n",
    "    with open(f\"{path_to_prediction_file}\") as f:\n",
    "        txt_prediction_files = f.read().splitlines()\n",
    "    \n",
    "    for example, prediction in zip(txt_test_files, txt_prediction_files):\n",
    "        true_prob, false_prob = prediction.split(\"\\t\")\n",
    "        true_prob, false_prob = float(true_prob), float(false_prob)\n",
    "        if true_prob > false_prob:\n",
    "            label = example.split(\"\\t\")[2]\n",
    "            top5.append((label, true_prob))\n",
    "    results = deque(sorted(top5, key=lambda x: x[1] if x else x, reverse=False), n)\n",
    "    with open(f\"{output_path}test_top_{n}_tdm.tsv\", \"w+\", encoding=\"utf-8\") as text_file:\n",
    "        for tdm in results:\n",
    "            text_file.write(f\"{tdm[0]}\\t{tdm[1]}\\n\")\n",
    "    return results\n",
    "\n",
    "def write_evaluation_result(val_macro_avg_p, val_macro_avg_r, val_macro_avg_f1, val_micro_avg_p, val_micro_avg_r, val_micro_avg_f1, output_path):\n",
    "    with open(f\"{output_path}evaluation_tdm_results.tsv\", \"w+\", encoding=\"utf-8\") as text_file:\n",
    "        text_file.write(f\"Macro P\\tMacro R\\t Macro F1\\t Micro P\\t Micro R\\t Micro F1\\n\")\n",
    "        text_file.write(f\"{val_macro_avg_p}\\t{val_macro_avg_r}\\t{val_macro_avg_f1}\\t{val_micro_avg_p}\\t{val_micro_avg_r}\\t{val_micro_avg_f1}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dfb3f927",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a1550c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10032 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "best_valid_loss = 0.30 #float('inf')\n",
    "best_valid_f1 = 0.5\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc, train_macro_avg_p, train_macro_avg_r, train_macro_avg_f1, train_micro_avg_p, train_micro_avg_r, train_micro_avg_f1 = train(model, train_loader, optimizer, epoch)\n",
    "    valid_loss, valid_acc, val_macro_avg_p, val_macro_avg_r, val_macro_avg_f1, val_micro_avg_p, val_micro_avg_r, val_micro_avg_f1 = evaluate(model, valid_loader, optimizer)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} Final | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print('------------------------------------------------------------')\n",
    "    print(f\"Train Accuracy Score: {train_acc}; Train loss : {train_loss}\")\n",
    "    print(f\"Macro Precision: {train_macro_avg_p}; Macro Recall : {train_macro_avg_r}; Macro F1 : {train_macro_avg_f1}\")\n",
    "    print(f\"Micro Precision: {train_micro_avg_p}; Micro Recall : {train_micro_avg_r}; Micro F1 : {train_micro_avg_f1}\")\n",
    "    print('------------------------------------------------------------')\n",
    "    \n",
    "    valid_metric_avg = (val_macro_avg_p + val_macro_avg_r + val_macro_avg_f1+val_micro_avg_p + val_micro_avg_r + val_micro_avg_f1)/6\n",
    "    \n",
    "    \n",
    "    \n",
    "    if valid_metric_avg > best_valid_metric_avg : #and abs(valid_loss - best_valid_loss) < 1e-1\n",
    "        best_valid_metric_avg = valid_metric_avg\n",
    "        print('Saving Model ...')\n",
    "        torch.save(model.state_dict(), f'{output_path}Model_{model_name}_avg_metric_{str(best_valid_metric_avg)[:4]}.pt')\n",
    "        print('****************************************************************************')\n",
    "        print('best record: [epoch %d], [val loss %.5f], [val acc %.5f], [val avg. metric %.5f]' % (epoch, valid_loss, valid_acc, valid_metric_avg))\n",
    "        print(f\"Macro Precision : {val_macro_avg_p}; Macro Recall : {val_macro_avg_r}; Macro F1 : {val_macro_avg_f1}\")\n",
    "        print(f\"Micro Precision : {val_micro_avg_p}; Micro Recall : {val_micro_avg_r}; Micro F1 : {val_micro_avg_f1}\")\n",
    "        print('****************************************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192b9782-89cd-4f71-8cb0-786e36a99cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_token_ids, \n",
    "                        token_type_ids=seg_ids, \n",
    "                        attention_mask=mask_ids, \n",
    "                        labels=labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c5c899",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "We'll then use the model to test the sentiment of some sequences. We tokenize the input sequence, trim it down to the maximum length, add the special tokens to either side, convert it to a tensor, add a fake batch dimension and then pass it through our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0882eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pt_path = \"/nfs/home/kabenamualus/Research/task-dataset-metric-extraction/data/ibm/exp/few-shot-setup/NLP-TDMS/paperVersion/torch/SciBert/Model_SciBert_avg_metric_0.9001.pt\"\n",
    "# model_pt_path = \"/nfs/home/kabenamualus/Research/task-dataset-metric-extraction/data/paperwithcode/new/60Neg800unk/twofoldwithunk/fold1/Model_SciBert_avg_metric_0.95.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16df2ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the best model\n",
    "# model.load_state_dict(torch.load('Model_f1_0.93.pt'))\n",
    "model.load_state_dict(torch.load(model_pt_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2815a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loss, valid_acc, val_macro_avg_p, val_macro_avg_r, val_macro_avg_f1, val_micro_avg_p, val_micro_avg_r, val_micro_avg_f1 = evaluate(model, valid_loader, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c667c4ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b12314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df = pd.read_csv(\"../data/paperwithcode/new/60Neg800unk/twofoldwithunk/fold1/test_results.tsv\", \n",
    "#                    sep=\"\\t\", names=[\"true\", \"false\"])\n",
    "\n",
    "# test_df = pd.read_csv(\"../data/paperwithcode/new/jar/10Neg20unk/testOutput.tsv\", \n",
    "#                    sep=\"\\t\", names=[\"label\", \"title\", \"TDM\", \"Context\"])\n",
    "\n",
    "test_df = valid_df\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421dc383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loader = TDM_dataset.get_inference_data(test_df, batch_size=16, shuffle=False) # this shuffle should be false to preserve the order "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf9dc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(valid_path) as f:\n",
    "    list_prediction_inputs = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d1cdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_prediction_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e57073d",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_text = list_prediction_inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210f8d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da85cbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_review = tokenizer.encode_plus(\n",
    "  list_prediction_inputs[-200],\n",
    "  max_length=max_input_length,\n",
    "  add_special_tokens=True,\n",
    "  return_token_type_ids=False,\n",
    "  pad_to_max_length=True,\n",
    "  return_attention_mask=True,\n",
    "  return_tensors='pt',\n",
    ")\n",
    "\n",
    "input_ids = encoded_review['input_ids'].to(device)\n",
    "attention_mask = encoded_review['attention_mask'].to(device)\n",
    "\n",
    "outputs = model(input_ids, attention_mask)\n",
    "\n",
    "prediction_scalled = torch.sigmoid(outputs.logits)\n",
    "# _, prediction = torch.max(output, dim=1)\n",
    "# print(f'Review text: {review_text}')\n",
    "\n",
    "print(f'Output  : {prediction_scalled}')\n",
    "print(f'Outputs logits  : {outputs.logits}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02356c98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90add3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = iter(test_loader)\n",
    "# sample.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54c6726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict_TDM_from_pdf(model, tokenizer, sentence):\n",
    "#     model.eval()\n",
    "#     tokens = tokenizer.tokenize(sentence)\n",
    "#     tokens = tokens[:max_input_length-2]\n",
    "#     indexed = [init_token_idx] + tokenizer.convert_tokens_to_ids(tokens) + [eos_token_idx]\n",
    "#     tensor = torch.LongTensor(indexed).to(device)\n",
    "#     tensor = tensor.unsqueeze(0)\n",
    "#     prediction = torch.sigmoid(model(tensor))\n",
    "#     return prediction.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9066e9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_TDM_from_pdf(model, tokenizer, iterator):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch_idx, (pair_token_ids, mask_ids, seg_ids, y) in tqdm(enumerate(iterator), total=len(iterator)):\n",
    "            pair_token_ids = pair_token_ids.to(device)\n",
    "            mask_ids = mask_ids.to(device)\n",
    "            seg_ids = seg_ids.to(device)\n",
    "            labels = y.to(device)\n",
    "\n",
    "            loss, prediction = model(pair_token_ids, \n",
    "                                 token_type_ids=seg_ids, \n",
    "                                 attention_mask=mask_ids, \n",
    "                                 labels=labels).values()\n",
    "\n",
    "            prediction_scalled = torch.sigmoid(prediction)\n",
    "            \n",
    "            with open(\"test_results.tsv\", \"a+\", encoding=\"utf-8\") as text_file:\n",
    "                for true, false in prediction_scalled.cpu():\n",
    "                    text_file.write(str(true.item())+\"\\t\"+str(false.item())+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45fec68",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_TDM_from_pdf(model, tokenizer, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f67f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "def get_top_n_prediction_label(path_to_test_file, path_to_prediction_file, n = 5):\n",
    "    \"\"\"\n",
    "    This function return the label with the highest proba\n",
    "    \"\"\"\n",
    "    top5 = deque()\n",
    "    with open(f\"{path_to_test_file}\") as f:\n",
    "        txt_test_files = f.read().splitlines()\n",
    "    with open(f\"{path_to_prediction_file}\") as f:\n",
    "        txt_prediction_files = f.read().splitlines()\n",
    "    \n",
    "    highest = 0\n",
    "    for example, prediction in zip(txt_test_files, txt_prediction_files):\n",
    "        true_prob, false_prob = prediction.split(\"\\t\")\n",
    "        true_prob, false_prob = float(true_prob), float(false_prob)\n",
    "        if true_prob > false_prob:\n",
    "            label = example.split(\"\\t\")[2]\n",
    "            highest = true_prob\n",
    "            top5.append((label, true_prob))\n",
    "    return deque(sorted(top5, key=lambda x: x[1] if x else x, reverse=False), n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061d79eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_top_n_prediction_label(\n",
    "    path_to_test_file=\"../data/paperwithcode/new/jar/10Neg20unk/testOutput.tsv\",\n",
    "    path_to_prediction_file=\"test_results.tsv\", \n",
    "    n = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152dfc00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
