{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stats in Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import ipdb, os, re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selected Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "New_train_csv = \"/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/pwc_ibm_150_5_10_10000/10Neg10000unk/twofoldwithunk/fold1/train.tsv\"\n",
    "New_test_csv = \"/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/pwc_ibm_150_5_10_10000/10Neg10000unk/twofoldwithunk/fold1/dev.tsv\"\n",
    "\n",
    "New_trainOutput_csv = \"/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/pwc_ibm_150_5_10_10000/10Neg10000unk/trainOutput.tsv\"\n",
    "\n",
    "IBM_train_csv = \"~/Research/task-dataset-metric-nli-extraction/data/ibm/exp/few-shot-setup/NLP-TDMS/paperVersion/train.tsv\"\n",
    "IBM_test_csv = \"~/Research/task-dataset-metric-nli-extraction/data/ibm/exp/few-shot-setup/NLP-TDMS/paperVersion/test.tsv\"\n",
    "\n",
    "Old_train_csv = \"/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/other/pwc_ibm_150_5_10_800/twofoldwithunk/fold1/train.tsv\"\n",
    "Old_test_csv = \"/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/other/pwc_ibm_150_5_10_800/twofoldwithunk/fold1/dev.tsv\"\n",
    "\n",
    "IBM_train_csv = \"/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/ibm/exp/zero-shot-setup/NLP-TDMS/train.tsv\"\n",
    "IBM_test_csv = \"/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/ibm/exp/zero-shot-setup/NLP-TDMS/test.tsv\"\n",
    "\n",
    "# New_train_csv = IBM_train_csv\n",
    "# New_test_csv = IBM_test_csv\n",
    "\n",
    "# New_train_csv =Old_train_csv\n",
    "# New_test_csv = Old_test_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_New = pd.read_csv(New_train_csv, \n",
    "                    sep=\"\\t\", names=[\"label\", \"title\", \"TDM\", \"Context\"])\n",
    "\n",
    "test_New = pd.read_csv(New_test_csv, \n",
    "                    sep=\"\\t\", names=[\"label\", \"title\", \"TDM\", \"Context\"])\n",
    "\n",
    "trainOutput_New = pd.read_csv(New_trainOutput_csv, \n",
    "                    sep=\"\\t\", names=[\"label\", \"title\", \"TDM\", \"Context\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>TDM</th>\n",
       "      <th>Context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>1707.03497v2.pdf</td>\n",
       "      <td>Atari Games; Atari 2600 Seaquest; Score</td>\n",
       "      <td>Value Prediction Network This paper proposes a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>1707.03497v2.pdf</td>\n",
       "      <td>Atari Games; Atari 2600 Amidar; Score</td>\n",
       "      <td>Value Prediction Network This paper proposes a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>1707.03497v2.pdf</td>\n",
       "      <td>Atari Games; Atari 2600 Krull; Score</td>\n",
       "      <td>Value Prediction Network This paper proposes a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>1707.03497v2.pdf</td>\n",
       "      <td>Atari Games; Atari 2600 Alien; Score</td>\n",
       "      <td>Value Prediction Network This paper proposes a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>1707.03497v2.pdf</td>\n",
       "      <td>Atari Games; Atari 2600 Enduro; Score</td>\n",
       "      <td>Value Prediction Network This paper proposes a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label             title                                      TDM  \\\n",
       "0   True  1707.03497v2.pdf  Atari Games; Atari 2600 Seaquest; Score   \n",
       "1   True  1707.03497v2.pdf    Atari Games; Atari 2600 Amidar; Score   \n",
       "2   True  1707.03497v2.pdf     Atari Games; Atari 2600 Krull; Score   \n",
       "3   True  1707.03497v2.pdf     Atari Games; Atari 2600 Alien; Score   \n",
       "4   True  1707.03497v2.pdf    Atari Games; Atari 2600 Enduro; Score   \n",
       "\n",
       "                                             Context  \n",
       "0  Value Prediction Network This paper proposes a...  \n",
       "1  Value Prediction Network This paper proposes a...  \n",
       "2  Value Prediction Network This paper proposes a...  \n",
       "3  Value Prediction Network This paper proposes a...  \n",
       "4  Value Prediction Network This paper proposes a...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_New.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_unique_tdm = set(train_New[train_New.label==True].TDM.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_unique_tdm = set(test_New[test_New.label==True].TDM.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique TDM train: 1792\n",
      "unique TDM test: 1557\n"
     ]
    }
   ],
   "source": [
    "print(f\"unique TDM train: {len(train_unique_tdm)}\")\n",
    "print(f\"unique TDM test: {len(test_unique_tdm)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_tdm_check(left, right, mode=\"Train\"):\n",
    "    count = 0\n",
    "    count_set = set()\n",
    "    for tdm in left:\n",
    "        if tdm not in right:\n",
    "            count_set.add(tdm)\n",
    "            count  += 1\n",
    "    print(f\"Missing TDM {mode}: {count}\")\n",
    "    return count_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Zero-shoot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_zero_shoot(train, test, output_path=\"/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/pwc_ibm_150_5_10_500/10Neg500unk_shot/zero_shot_twofoldwithunk/fold1/\"):\n",
    "    \n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "        \n",
    "    unique_sets_train = set(train[train.label==True].TDM.to_list())\n",
    "    unique_sets_test = set(test[test.label==True].TDM.to_list())\n",
    "        \n",
    "    print(f\"Len unique TDM Train: {len(unique_sets_train)}.\")\n",
    "    print(f\"Len unique TDM Test: {len(unique_sets_test)}.\")\n",
    "    \n",
    "    print(f\"Size Train df before: {len(train)}.\")\n",
    "    print(f\"Size Train df before: {len(test)}.\")\n",
    "    \n",
    "    for label in unique_sets_train:\n",
    "        index_to_drop = test[(test.TDM ==label) & (test.label==True)].index\n",
    "        test.drop(index_to_drop, axis=0, inplace=True)\n",
    "        \n",
    "    for label in unique_sets_test:\n",
    "        index_to_drop = train[(train.TDM ==label) & (train.label==True)].index\n",
    "        train.drop(index_to_drop, axis=0, inplace=True)\n",
    "        \n",
    "    train.to_csv(f\"{output_path}train.tsv\", \n",
    "                              header=False, index=False, sep=\"\\t\")    \n",
    "    test.to_csv(f\"{output_path}dev.tsv\", \n",
    "                              header=False, index=False, sep=\"\\t\")\n",
    "    \n",
    "    unique_sets_train = set(train[train.label==True].TDM.to_list())\n",
    "    unique_sets_test = set(test[test.label==True].TDM.to_list())\n",
    "    \n",
    "    print(f\"Len unique TDM Train: {len(unique_sets_train)}.\")\n",
    "    print(f\"Len unique TDM Test: {len(unique_sets_test)}.\")\n",
    "    \n",
    "    print(f\"Size Train df After: {len(train)}.\")\n",
    "    print(f\"Size Test df After: {len(test)}.\")\n",
    "    \n",
    "    print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_zero_shoot(trainOutput_New, split=0.8, output_path=\"/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/pwc_ibm_150_5_10_500/10Neg500unk_shot/zero_shot_twofoldwithunk/fold1/\"):\n",
    "    \n",
    "#     if not os.path.exists(output_path):\n",
    "#         os.makedirs(output_path)\n",
    "        \n",
    "#     unique_sets = set(trainOutput_New[trainOutput_New.label==True].TDM.to_list())\n",
    "#     train_split_tdm, test_split_tdm = train_test_split(list(unique_sets), train_size=split)\n",
    "    \n",
    "#     print(f\"Len unique TDM {len(unique_sets)}.\")\n",
    "    \n",
    "#     Zero_shoot_train_New = pd.DataFrame().reindex_like(trainOutput_New).dropna()\n",
    "#     Zero_shoot_test_New = pd.DataFrame().reindex_like(trainOutput_New).dropna()\n",
    "    \n",
    "#     for label in train_split_tdm:\n",
    "#         Zero_shoot_train_New = Zero_shoot_train_New.merge(trainOutput_New[(trainOutput_New.TDM==label) & (trainOutput_New.TDM==label)], how='outer')\n",
    "        \n",
    "#     for label in test_split_tdm:\n",
    "#         Zero_shoot_test_New = Zero_shoot_test_New.merge(trainOutput_New[trainOutput_New.TDM==label], how='outer')\n",
    "        \n",
    "#     Zero_shoot_train_New.to_csv(f\"{output_path}train.tsv\", \n",
    "#                               header=False, index=False, sep=\"\\t\")\n",
    "    \n",
    "#     print(f\"Len train dataset {len(Zero_shoot_train_New)}.\")\n",
    "    \n",
    "#     Zero_shoot_test_New.to_csv(f\"{output_path}dev.tsv\", \n",
    "#                               header=False, index=False, sep=\"\\t\")\n",
    "    \n",
    "#     print(f\"Len test dataset {len(Zero_shoot_test_New)}.\")\n",
    "    \n",
    "#     print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = \"/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/pwc_ibm_150_5_10_10000/10Neg10000unk/zero_shot_2_twofoldwithunk/fold1/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_zero_shoot(trainOutput_New=trainOutput_New, split=0.8, \n",
    "#                   output_path=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len unique TDM Train: 1792.\n",
      "Len unique TDM Test: 1557.\n",
      "Size Train df before: 52154.\n",
      "Size Train df before: 22426.\n",
      "Len unique TDM Train: 294.\n",
      "Len unique TDM Test: 59.\n",
      "Size Train df After: 38608.\n",
      "Size Test df After: 16165.\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "create_zero_shoot(train=train_New, test=test_New, \n",
    "                  output_path=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing TDM Test: 0\n"
     ]
    }
   ],
   "source": [
    "tdm_in_test_not_train = unique_tdm_check(left=New_test_csv, right=New_train_csv, mode=\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing TDM Train: 0\n"
     ]
    }
   ],
   "source": [
    "tdm_in_train_not_test = unique_tdm_check(left=New_train_csv, right=New_test_csv, mode=\"Train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "New_train_csv = \"/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/pwc_ibm_150_5_10_10000/10Neg10000unk/twofoldwithunk/fold2/train.tsv\"\n",
    "New_test_csv = \"/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/pwc_ibm_150_5_10_10000/10Neg10000unk/twofoldwithunk/fold2/dev.tsv\"\n",
    "\n",
    "train_New = pd.read_csv(New_train_csv, \n",
    "                    sep=\"\\t\", names=[\"label\", \"title\", \"TDM\", \"Context\"])\n",
    "\n",
    "test_New = pd.read_csv(New_test_csv, \n",
    "                    sep=\"\\t\", names=[\"label\", \"title\", \"TDM\", \"Context\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = \"/nfs/home/kabenamualus/Research/task-dataset-metric-nli-extraction/data/pwc_ibm_150_5_10_10000/10Neg10000unk/zero_shot_2_twofoldwithunk/fold2/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len unique TDM Train: 1821.\n",
      "Len unique TDM Test: 1542.\n",
      "Size Train df before: 52315.\n",
      "Size Train df before: 22265.\n",
      "Len unique TDM Train: 309.\n",
      "Len unique TDM Test: 30.\n",
      "Size Train df After: 38649.\n",
      "Size Test df After: 16131.\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# create_zero_shoot(trainOutput_New=trainOutput_New, split=0.8, \n",
    "#                   output_path=output)\n",
    "create_zero_shoot(train=train_New, test=test_New, \n",
    "                  output_path=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "New_train_csv = f\"{output}train.tsv\"\n",
    "New_test_csv = f\"{output}dev.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing TDM Test: 0\n"
     ]
    }
   ],
   "source": [
    "tdm_in_test_not_train = unique_tdm_check(left=New_test_csv, right=New_train_csv, mode=\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing TDM Train: 0\n"
     ]
    }
   ],
   "source": [
    "tdm_in_train_not_test = unique_tdm_check(left=New_train_csv, right=New_test_csv, mode=\"Train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enforce seen TDM in both train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique TDM train: 96\n",
      "unique TDM test: 63\n"
     ]
    }
   ],
   "source": [
    "print(f\"unique TDM train: {len(train_unique_tdm)}\")\n",
    "print(f\"unique TDM test: {len(test_unique_tdm)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing TDM Test: 63\n"
     ]
    }
   ],
   "source": [
    "tdm_in_test_not_train = unique_tdm_check(left=test_unique_tdm, right=train_unique_tdm, mode=\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing TDM Train: 96\n"
     ]
    }
   ],
   "source": [
    "tdm_in_train_not_test = unique_tdm_check(left=train_unique_tdm, right=test_unique_tdm, mode=\"Train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20160"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_New)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17388"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_New)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>TDM</th>\n",
       "      <th>Context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14199</th>\n",
       "      <td>True</td>\n",
       "      <td>2007.00916v1.pdf</td>\n",
       "      <td>Fact-based Text Editing; WebEdit; ADD</td>\n",
       "      <td>Fact-based Text Editing We propose a novel tex...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label             title                                    TDM  \\\n",
       "14199   True  2007.00916v1.pdf  Fact-based Text Editing; WebEdit; ADD   \n",
       "\n",
       "                                                 Context  \n",
       "14199  Fact-based Text Editing We propose a novel tex...  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_New[(test_New.TDM==\"Fact-based Text Editing; WebEdit; ADD\") & (test_New.label==True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>TDM</th>\n",
       "      <th>Context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [label, title, TDM, Context]\n",
       "Index: []"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_New[(train_New.TDM==\"Fact-based Text Editing; WebEdit; ADD\") & (train_New.label==True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
