[{"caption":"Method \n\nTrain Acc Test Acc #Parameters \n\nLexicalized Classifier (Bowman et al., 2015) \n99.7 \n78.2 \n-\n\n300D LSTM RNN encoders (Bowman et al., 2016) \n83.9 \n80.6 \n3.0M \n1024D pretrained GRU encoders (Vendrov et al., 2015)  98.8 \n81.4 \n15.0M \n300D tree-based CNN encoders (Mou et al., 2015)  83.3 \n82.1 \n3.5M \n300D SPINN-PI encoders (Bowman et al., 2016)  89.2 \n83.2 \n3.7M \n\n100D LSTM with attention (Rockt채schel et al., 2016)  85.3 \n83.5 \n252K \n300D mLSTM (Wang and Jiang, 2016)  92.0 \n86.1 \n1.9M \n450D LSTMN with deep attention fusion (Cheng et al., 2016)  88.5 \n86.3 \n3.4M \n\nOur approach (vanilla) \n89.5 \n86.3 \n382K \nOur approach with intra-sentence attention \n90.5 \n86.8 \n582K \n\nTable 1: Train/test accuracies on the SNLI dataset and number of parameters (excluding embeddings) for each approach. \n\n","rows":["450D LSTMN with deep attention fusion ( Cheng et al . , 2016 )","Our approach with intra - sentence attention","1024D pretrained GRU encoders ( Vendrov et al . , 2015 )","300D SPINN - PI encoders ( Bowman et al . , 2016 )","300D mLSTM ( Wang and Jiang , 2016 )","300D LSTM RNN encoders ( Bowman et al . , 2016 )","Lexicalized Classifier ( Bowman et al . , 2015 )","Our approach ( vanilla )","100D LSTM with attention ( Rockt채schel et al . , 2016 )","300D tree - based CNN encoders ( Mou et al . , 2015 )"],"columns":["#Parameters","Test Acc","Train Acc"],"mergedAllColumns":["382K","252K","-"],"numberCells":[{"number":"86.3","isBolded":false,"associatedRows":["Our approach ( vanilla )"],"associatedColumns":["Test Acc"],"associatedMergedColumns":["252K"]},{"number":"1.9M","isBolded":false,"associatedRows":["300D mLSTM ( Wang and Jiang , 2016 )"],"associatedColumns":["#Parameters"],"associatedMergedColumns":["252K"]},{"number":"86.3","isBolded":false,"associatedRows":["450D LSTMN with deep attention fusion ( Cheng et al . , 2016 )"],"associatedColumns":["Test Acc"],"associatedMergedColumns":["252K"]},{"number":"90.5","isBolded":false,"associatedRows":["Our approach with intra - sentence attention"],"associatedColumns":["Train Acc"],"associatedMergedColumns":["382K"]},{"number":"99.7","isBolded":false,"associatedRows":["Lexicalized Classifier ( Bowman et al . , 2015 )"],"associatedColumns":["Train Acc"],"associatedMergedColumns":[]},{"number":"15.0M","isBolded":false,"associatedRows":["1024D pretrained GRU encoders ( Vendrov et al . , 2015 )"],"associatedColumns":["#Parameters"],"associatedMergedColumns":["-"]},{"number":"85.3","isBolded":false,"associatedRows":["100D LSTM with attention ( Rockt채schel et al . , 2016 )"],"associatedColumns":["Train Acc"],"associatedMergedColumns":["-"]},{"number":"83.2","isBolded":false,"associatedRows":["300D SPINN - PI encoders ( Bowman et al . , 2016 )"],"associatedColumns":["Test Acc"],"associatedMergedColumns":["-"]},{"number":"3.5M","isBolded":false,"associatedRows":["300D tree - based CNN encoders ( Mou et al . , 2015 )"],"associatedColumns":["#Parameters"],"associatedMergedColumns":["-"]},{"number":"83.9","isBolded":false,"associatedRows":["300D LSTM RNN encoders ( Bowman et al . , 2016 )"],"associatedColumns":["Train Acc"],"associatedMergedColumns":["-"]},{"number":"82.1","isBolded":false,"associatedRows":["300D tree - based CNN encoders ( Mou et al . , 2015 )"],"associatedColumns":["Test Acc"],"associatedMergedColumns":["-"]},{"number":"88.5","isBolded":false,"associatedRows":["450D LSTMN with deep attention fusion ( Cheng et al . , 2016 )"],"associatedColumns":["Train Acc"],"associatedMergedColumns":["252K"]},{"number":"3.4M","isBolded":false,"associatedRows":["450D LSTMN with deep attention fusion ( Cheng et al . , 2016 )"],"associatedColumns":["#Parameters"],"associatedMergedColumns":["252K"]},{"number":"78.2","isBolded":false,"associatedRows":["Lexicalized Classifier ( Bowman et al . , 2015 )"],"associatedColumns":["Test Acc"],"associatedMergedColumns":[]},{"number":"89.5","isBolded":false,"associatedRows":["Our approach ( vanilla )"],"associatedColumns":["Train Acc"],"associatedMergedColumns":["252K"]},{"number":"83.3","isBolded":false,"associatedRows":["300D tree - based CNN encoders ( Mou et al . , 2015 )"],"associatedColumns":["Train Acc"],"associatedMergedColumns":["-"]},{"number":"81.4","isBolded":false,"associatedRows":["1024D pretrained GRU encoders ( Vendrov et al . , 2015 )"],"associatedColumns":["Test Acc"],"associatedMergedColumns":["-"]},{"number":"89.2","isBolded":false,"associatedRows":["300D SPINN - PI encoders ( Bowman et al . , 2016 )"],"associatedColumns":["Train Acc"],"associatedMergedColumns":["-"]},{"number":"3.7M","isBolded":false,"associatedRows":["300D SPINN - PI encoders ( Bowman et al . , 2016 )"],"associatedColumns":["#Parameters"],"associatedMergedColumns":["-"]},{"number":"98.8","isBolded":false,"associatedRows":["1024D pretrained GRU encoders ( Vendrov et al . , 2015 )"],"associatedColumns":["Train Acc"],"associatedMergedColumns":["-"]},{"number":"92.0","isBolded":false,"associatedRows":["300D mLSTM ( Wang and Jiang , 2016 )"],"associatedColumns":["Train Acc"],"associatedMergedColumns":["252K"]},{"number":"86.1","isBolded":false,"associatedRows":["300D mLSTM ( Wang and Jiang , 2016 )"],"associatedColumns":["Test Acc"],"associatedMergedColumns":["252K"]},{"number":"3.0M","isBolded":false,"associatedRows":["300D LSTM RNN encoders ( Bowman et al . , 2016 )"],"associatedColumns":["#Parameters"],"associatedMergedColumns":["-"]},{"number":"86.8","isBolded":true,"associatedRows":["Our approach with intra - sentence attention"],"associatedColumns":["Test Acc"],"associatedMergedColumns":["382K"]},{"number":"80.6","isBolded":false,"associatedRows":["300D LSTM RNN encoders ( Bowman et al . , 2016 )"],"associatedColumns":["Test Acc"],"associatedMergedColumns":["-"]},{"number":"83.5","isBolded":false,"associatedRows":["100D LSTM with attention ( Rockt채schel et al . , 2016 )"],"associatedColumns":["Test Acc"],"associatedMergedColumns":["-"]}]},{"caption":"Table 2: Breakdown of accuracy with respect to classes on SNLI \n\ndevelopment set. N\u003dneutral, E\u003dentailment, C\u003dcontradiction. \n\n","rows":["Our approach w / intra att .","Our approach ( vanilla )","Wang and Jiang ( 2016 )","Bowman et al . ( 2016 )"],"columns":["C","E","N"],"mergedAllColumns":[],"numberCells":[{"number":"87.4","isBolded":false,"associatedRows":["Wang and Jiang ( 2016 )"],"associatedColumns":["C"],"associatedMergedColumns":[]},{"number":"91.3","isBolded":false,"associatedRows":["Our approach ( vanilla )"],"associatedColumns":["E"],"associatedMergedColumns":[]},{"number":"92.1","isBolded":false,"associatedRows":["Our approach w / intra att ."],"associatedColumns":["E"],"associatedMergedColumns":[]},{"number":"81.6","isBolded":false,"associatedRows":["Wang and Jiang ( 2016 )"],"associatedColumns":["N"],"associatedMergedColumns":[]},{"number":"91.6","isBolded":false,"associatedRows":["Wang and Jiang ( 2016 )"],"associatedColumns":["E"],"associatedMergedColumns":[]},{"number":"80.6","isBolded":false,"associatedRows":["Bowman et al . ( 2016 )"],"associatedColumns":["N"],"associatedMergedColumns":[]},{"number":"86.7","isBolded":false,"associatedRows":["Our approach w / intra att ."],"associatedColumns":["C"],"associatedMergedColumns":[]},{"number":"85.5","isBolded":false,"associatedRows":["Bowman et al . ( 2016 )"],"associatedColumns":["C"],"associatedMergedColumns":[]},{"number":"83.6","isBolded":false,"associatedRows":["Our approach ( vanilla )"],"associatedColumns":["N"],"associatedMergedColumns":[]},{"number":"88.2","isBolded":false,"associatedRows":["Bowman et al . ( 2016 )"],"associatedColumns":["E"],"associatedMergedColumns":[]},{"number":"85.8","isBolded":false,"associatedRows":["Our approach ( vanilla )"],"associatedColumns":["C"],"associatedMergedColumns":[]},{"number":"83.7","isBolded":false,"associatedRows":["Our approach w / intra att ."],"associatedColumns":["N"],"associatedMergedColumns":[]}]}]