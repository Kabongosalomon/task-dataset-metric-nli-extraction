[{"caption":"Table 1: The comparison of different loss functions method. \nModels are trained in mini-train and evaluated on mini-val. \n\n","rows":["dist - CE Loss [ 24 ]","Concurrent Softmax Loss","Softmax Loss","BCE Loss","Co - BCE Loss [ 1 ]"],"columns":["mAP"],"mergedAllColumns":[],"numberCells":[{"number":"56.58","isBolded":true,"associatedRows":["Concurrent Softmax Loss"],"associatedColumns":["mAP"],"associatedMergedColumns":[]},{"number":"55.90","isBolded":false,"associatedRows":["dist - CE Loss [ 24 ]"],"associatedColumns":["mAP"],"associatedMergedColumns":[]},{"number":"38.16","isBolded":false,"associatedRows":["Softmax Loss"],"associatedColumns":["mAP"],"associatedMergedColumns":[]},{"number":"54.29","isBolded":false,"associatedRows":["BCE Loss"],"associatedColumns":["mAP"],"associatedMergedColumns":[]},{"number":"55.45","isBolded":false,"associatedRows":["Softmax Loss"],"associatedColumns":["mAP"],"associatedMergedColumns":[]},{"number":"39.14","isBolded":true,"associatedRows":["Concurrent Softmax Loss"],"associatedColumns":["mAP"],"associatedMergedColumns":[]},{"number":"55.74","isBolded":false,"associatedRows":["Co - BCE Loss [ 1 ]"],"associatedColumns":["mAP"],"associatedMergedColumns":[]},{"number":"50.18","isBolded":false,"associatedRows":["Concurrent Softmax Loss"],"associatedColumns":["mAP"],"associatedMergedColumns":[]}]},{"caption":"Table 2: The effectiveness of concurrent softmax during \ntesting. Models are trained in mini-train and evaluated on \nmini-val. \n\n","rows":["dist - CE Loss [ 24 ]","Concurrent Softmax Loss","Softmax Loss","BCE Loss","Co - BCE Loss [ 1 ]"],"columns":["mAP"],"mergedAllColumns":[],"numberCells":[{"number":"54.29","isBolded":false,"associatedRows":["BCE Loss"],"associatedColumns":["mAP"],"associatedMergedColumns":[]},{"number":"50.18","isBolded":false,"associatedRows":["Concurrent Softmax Loss"],"associatedColumns":["mAP"],"associatedMergedColumns":[]},{"number":"55.45","isBolded":false,"associatedRows":["Softmax Loss"],"associatedColumns":["mAP"],"associatedMergedColumns":[]},{"number":"56.58","isBolded":true,"associatedRows":["Concurrent Softmax Loss"],"associatedColumns":["mAP"],"associatedMergedColumns":[]},{"number":"55.74","isBolded":false,"associatedRows":["Co - BCE Loss [ 1 ]"],"associatedColumns":["mAP"],"associatedMergedColumns":[]},{"number":"38.16","isBolded":false,"associatedRows":["Softmax Loss"],"associatedColumns":["mAP"],"associatedMergedColumns":[]},{"number":"55.90","isBolded":false,"associatedRows":["dist - CE Loss [ 24 ]"],"associatedColumns":["mAP"],"associatedMergedColumns":[]},{"number":"39.14","isBolded":true,"associatedRows":["Concurrent Softmax Loss"],"associatedColumns":["mAP"],"associatedMergedColumns":[]}]},{"caption":"Table 3: The comparison of different sampling methods. \nModels are trained in mini-train and evaluated on mini-val. \n\n","rows":["Class - aware Sampling [ 10 ]","Effective Number [ 6 ]","Soft - balance","Non - balance","-","ples , so that non - balance training only achieves"],"columns":["λ","mAP"],"mergedAllColumns":[],"numberCells":[{"number":"38.16","isBolded":false,"associatedRows":["Non - balance","-"],"associatedColumns":["mAP"],"associatedMergedColumns":[]},{"number":"57.04","isBolded":true,"associatedRows":["Soft - balance","-"],"associatedColumns":["mAP"],"associatedMergedColumns":[]},{"number":"52.41","isBolded":false,"associatedRows":["Class - aware Sampling [ 10 ]","-"],"associatedColumns":["mAP"],"associatedMergedColumns":[]},{"number":"0.3","isBolded":false,"associatedRows":["Class - aware Sampling [ 10 ]"],"associatedColumns":["λ"],"associatedMergedColumns":[]},{"number":"56.19","isBolded":false,"associatedRows":["Class - aware Sampling [ 10 ]","-"],"associatedColumns":["mAP"],"associatedMergedColumns":[]},{"number":"38.16mAP.","isBolded":false,"associatedRows":["ples , so that non - balance training only achieves"],"associatedColumns":["mAP"],"associatedMergedColumns":[]},{"number":"55.45","isBolded":false,"associatedRows":["Class - aware Sampling [ 10 ]","-"],"associatedColumns":["mAP"],"associatedMergedColumns":[]},{"number":"0.5","isBolded":false,"associatedRows":["Class - aware Sampling [ 10 ]"],"associatedColumns":["λ"],"associatedMergedColumns":[]},{"number":"45.72","isBolded":false,"associatedRows":["Effective Number [ 6 ]","-"],"associatedColumns":["mAP"],"associatedMergedColumns":[]},{"number":"1.5","isBolded":false,"associatedRows":["Effective Number [ 6 ]"],"associatedColumns":["λ"],"associatedMergedColumns":[]},{"number":"1.0","isBolded":false,"associatedRows":["Effective Number [ 6 ]"],"associatedColumns":["λ"],"associatedMergedColumns":[]},{"number":"0.7","isBolded":false,"associatedRows":["Soft - balance"],"associatedColumns":["λ"],"associatedMergedColumns":[]},{"number":"50.69","isBolded":false,"associatedRows":["Class - aware Sampling [ 10 ]","-"],"associatedColumns":["mAP"],"associatedMergedColumns":[]},{"number":"55.45","isBolded":false,"associatedRows":["Class - aware Sampling [ 10 ]","-"],"associatedColumns":["mAP"],"associatedMergedColumns":[]}]},{"caption":"Table 4: The effect of training scheduler. The λ of the soft-\nbalance is set to 0.7. Non-balance I14 denotes the model \nof epoch 14 trained with non-balance strategy from Im-\nageNet pretrain. Non-balance S20 denotes the model of \nepoch 20 trained with non-balance strategy from scratch. \nSoft-balance  *  means that concurrent softmax is adopted in \nboth training and testing stage. Models are trained on full-\ntrain and evaluated on full-val. \n\n","rows":["11","14","Class - aware","16","Non - balance I14","Non - balance S20","Non - balance","Scratch","Soft - balance *","7","Soft - balance","14+7","Sampling","20+7","20","ImageNet"],"columns":["mAP"],"mergedAllColumns":[],"numberCells":[{"number":"64.68","isBolded":false,"associatedRows":["Class - aware","ImageNet","7"],"associatedColumns":["mAP"],"associatedMergedColumns":[]},{"number":"65.92","isBolded":false,"associatedRows":["Soft - balance *","Non - balance S20","20+7"],"associatedColumns":["mAP"],"associatedMergedColumns":[]},{"number":"59.12","isBolded":false,"associatedRows":["Non - balance","ImageNet","11"],"associatedColumns":["mAP"],"associatedMergedColumns":[]},{"number":"67.09","isBolded":true,"associatedRows":["Soft - balance","Non - balance S20","20+7"],"associatedColumns":["mAP"],"associatedMergedColumns":[]},{"number":"59.85","isBolded":false,"associatedRows":["Non - balance","ImageNet","14"],"associatedColumns":["mAP"],"associatedMergedColumns":[]},{"number":"60.70","isBolded":false,"associatedRows":["Non - balance","Scratch","20"],"associatedColumns":["mAP"],"associatedMergedColumns":[]},{"number":"65.60","isBolded":false,"associatedRows":["Sampling","Non - balance I14","14+7"],"associatedColumns":["mAP"],"associatedMergedColumns":[]},{"number":"62.85","isBolded":false,"associatedRows":["Class - aware","ImageNet","14"],"associatedColumns":["mAP"],"associatedMergedColumns":[]},{"number":"56.06","isBolded":false,"associatedRows":["Non - balance","ImageNet","7"],"associatedColumns":["mAP"],"associatedMergedColumns":[]},{"number":"68.23","isBolded":true,"associatedRows":["Soft - balance *","Non - balance S20","20+7"],"associatedColumns":["mAP"],"associatedMergedColumns":[]},{"number":"59.95","isBolded":false,"associatedRows":["Non - balance","ImageNet","16"],"associatedColumns":["mAP"],"associatedMergedColumns":[]}]},{"caption":"Table 5: Results with bells and whistles on Open Images \npublic test-challenge set. \n\n","rows":["+Soft - balance","Ours","2018 2nd [ 10 ]","mAP of","+Class - aware Sampling","+Ensemble","softmax , the model achieves","2018 3rd","Baseline ( ResNeXt - 152 )","+Concurrent Softmax Loss","training and testing as our baseline which achieves","2018 1st [ 1 ]","+Other Tricks","+Hybrid Training Scheduler","boosted to"],"columns":["The final mAP on Open Images public test - challenge set is","Table 5 .","and heavier head , we achieve a best single model with a","We train a ResNeXt - 152 FPN with multi - scale","Public Test","Methods"],"mergedAllColumns":["With the help of proposed concurrent","EfficientNet - B7 with various tricks for model ensembling .","try on the public test - challenge set last year , as detailed in","mAP . After using class - aware balance , the performance is","and the hybrid training scheduler lead to mAP gains of"],"numberCells":[{"number":"62.34","isBolded":false,"associatedRows":["+Other Tricks"],"associatedColumns":["and heavier head , we achieve a best single model with a","Public Test"],"associatedMergedColumns":["EfficientNet - B7 with various tricks for model ensembling ."]},{"number":"67.17","isBolded":true,"associatedRows":["+Ensemble"],"associatedColumns":["and heavier head , we achieve a best single model with a","Public Test"],"associatedMergedColumns":["EfficientNet - B7 with various tricks for model ensembling ."]},{"number":"62.34.","isBolded":false,"associatedRows":["+Concurrent Softmax Loss","mAP of"],"associatedColumns":["and heavier head , we achieve a best single model with a"],"associatedMergedColumns":[]},{"number":"53.88","isBolded":false,"associatedRows":["training and testing as our baseline which achieves"],"associatedColumns":["and heavier head , we achieve a best single model with a","Public Test","We train a ResNeXt - 152 FPN with multi - scale"],"associatedMergedColumns":["try on the public test - challenge set last year , as detailed in"]},{"number":"58.60","isBolded":false,"associatedRows":["+Concurrent Softmax Loss"],"associatedColumns":["and heavier head , we achieve a best single model with a","Public Test"],"associatedMergedColumns":["EfficientNet - B7 with various tricks for model ensembling ."]},{"number":"59.86","isBolded":false,"associatedRows":["+Soft - balance"],"associatedColumns":["and heavier head , we achieve a best single model with a","Public Test"],"associatedMergedColumns":["EfficientNet - B7 with various tricks for model ensembling ."]},{"number":"1.26and","isBolded":false,"associatedRows":[],"associatedColumns":["and heavier head , we achieve a best single model with a","Methods","Table 5 ."],"associatedMergedColumns":["and the hybrid training scheduler lead to mAP gains of"]},{"number":"67.17.","isBolded":false,"associatedRows":["2018 1st [ 1 ]"],"associatedColumns":["and heavier head , we achieve a best single model with a","The final mAP on Open Images public test - challenge set is"],"associatedMergedColumns":["EfficientNet - B7 with various tricks for model ensembling ."]},{"number":"62.16","isBolded":false,"associatedRows":["2018 2nd [ 10 ]"],"associatedColumns":["and heavier head , we achieve a best single model with a","Public Test"],"associatedMergedColumns":["EfficientNet - B7 with various tricks for model ensembling ."]},{"number":"60.90","isBolded":false,"associatedRows":["+Hybrid Training Scheduler"],"associatedColumns":["and heavier head , we achieve a best single model with a","Public Test"],"associatedMergedColumns":["EfficientNet - B7 with various tricks for model ensembling ."]},{"number":"58.60mAP.Thesoft-balance","isBolded":false,"associatedRows":["softmax , the model achieves"],"associatedColumns":["and heavier head , we achieve a best single model with a","Public Test","We train a ResNeXt - 152 FPN with multi - scale"],"associatedMergedColumns":["With the help of proposed concurrent"]},{"number":"67.17","isBolded":true,"associatedRows":["Ours"],"associatedColumns":["and heavier head , we achieve a best single model with a","Public Test"],"associatedMergedColumns":["EfficientNet - B7 with various tricks for model ensembling ."]},{"number":"55.81","isBolded":false,"associatedRows":["2018 1st [ 1 ]"],"associatedColumns":["and heavier head , we achieve a best single model with a","Public Test"],"associatedMergedColumns":["EfficientNet - B7 with various tricks for model ensembling ."]},{"number":"60.90","isBolded":true,"associatedRows":["Ours"],"associatedColumns":["and heavier head , we achieve a best single model with a","Public Test"],"associatedMergedColumns":["EfficientNet - B7 with various tricks for model ensembling ."]},{"number":"53.88","isBolded":false,"associatedRows":["Baseline ( ResNeXt - 152 )"],"associatedColumns":["and heavier head , we achieve a best single model with a","Public Test"],"associatedMergedColumns":["EfficientNet - B7 with various tricks for model ensembling ."]},{"number":"57.56","isBolded":false,"associatedRows":["+Class - aware Sampling"],"associatedColumns":["and heavier head , we achieve a best single model with a","Public Test"],"associatedMergedColumns":["EfficientNet - B7 with various tricks for model ensembling ."]},{"number":"61.70","isBolded":false,"associatedRows":["2018 3rd"],"associatedColumns":["and heavier head , we achieve a best single model with a","Public Test"],"associatedMergedColumns":["EfficientNet - B7 with various tricks for model ensembling ."]},{"number":"57.56.","isBolded":false,"associatedRows":["boosted to"],"associatedColumns":["and heavier head , we achieve a best single model with a","Methods","We train a ResNeXt - 152 FPN with multi - scale"],"associatedMergedColumns":["mAP . After using class - aware balance , the performance is"]},{"number":"62.88","isBolded":false,"associatedRows":["2018 1st [ 1 ]"],"associatedColumns":["and heavier head , we achieve a best single model with a","Public Test"],"associatedMergedColumns":["EfficientNet - B7 with various tricks for model ensembling ."]},{"number":"1.04points,respectively.","isBolded":false,"associatedRows":["Ours"],"associatedColumns":["and heavier head , we achieve a best single model with a","Methods","We train a ResNeXt - 152 FPN with multi - scale"],"associatedMergedColumns":["and the hybrid training scheduler lead to mAP gains of"]}]},{"caption":"Methods \nEnsemble Public Test \n2018 1st [1]  55.81 \nOurs \n60.90 \n2018 1st [1]   62.88 \n2018 2nd [10]   62.16 \n2018 3rd \n\n61.70 \nOurs \n\n67.17 \nBaseline (ResNeXt-152) \n53.88 \n+Class-aware Sampling \n57.56 \n+Concurrent Softmax Loss \n58.60 \n+Soft-balance \n59.86 \n+Hybrid Training Scheduler \n60.90 \n+Other Tricks \n62.34 \n+Ensemble \n\n67.17 \n\ntry on the public test-challenge set last year, as detailed in \nTable 5. We train a ResNeXt-152 FPN with multi-scale \ntraining and testing as our baseline which achieves 53.88 \nmAP. After using class-aware balance, the performance is \nboosted to 57.56. With the help of proposed concurrent \nsoftmax, the model achieves 58.60 mAP. The soft-balance \nand the hybrid training scheduler lead to mAP gains of \n1.26 and 1.04 points, respectively. By further using other \ntricks including data augmentation, loss function search, \n\nand heavier head, we achieve a best single model with a \nmAP of 62.34. We use ResNeXt-101, ResNeXt-152, and \nEfficientNet-B7 with various tricks for model ensembling. \nThe final mAP on Open Images public test-challenge set is \n67.17. \n\n","rows":["( b ) Class - aware Sampling ( blue ) versus Soft - balance with λ \u003d","\u003d"],"columns":["500"],"mergedAllColumns":[],"numberCells":[{"number":"0.2","isBolded":false,"associatedRows":[],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"0.7","isBolded":false,"associatedRows":["\u003d"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"0.7(orange)sortedbythenumberofimagesformostfrequent100","isBolded":true,"associatedRows":["( b ) Class - aware Sampling ( blue ) versus Soft - balance with λ \u003d"],"associatedColumns":["500"],"associatedMergedColumns":[]},{"number":"0.6","isBolded":false,"associatedRows":["( b ) Class - aware Sampling ( blue ) versus Soft - balance with λ \u003d"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"0.7","isBolded":false,"associatedRows":["\u003d","\u003d"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"1.0","isBolded":false,"associatedRows":["( b ) Class - aware Sampling ( blue ) versus Soft - balance with λ \u003d"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"0.0","isBolded":false,"associatedRows":[],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"0.0","isBolded":false,"associatedRows":["( b ) Class - aware Sampling ( blue ) versus Soft - balance with λ \u003d"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"0.2","isBolded":false,"associatedRows":["( b ) Class - aware Sampling ( blue ) versus Soft - balance with λ \u003d","\u003d"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"0.8","isBolded":false,"associatedRows":["( b ) Class - aware Sampling ( blue ) versus Soft - balance with λ \u003d"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"0.6","isBolded":false,"associatedRows":[],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"1.0","isBolded":false,"associatedRows":["\u003d"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"0.4","isBolded":false,"associatedRows":[],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"1.0","isBolded":false,"associatedRows":[],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"0.4","isBolded":false,"associatedRows":["( b ) Class - aware Sampling ( blue ) versus Soft - balance with λ \u003d"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"1.0","isBolded":false,"associatedRows":["( b ) Class - aware Sampling ( blue ) versus Soft - balance with λ \u003d","\u003d","\u003d"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"0.8","isBolded":false,"associatedRows":[],"associatedColumns":[],"associatedMergedColumns":[]}]}]