[{"caption":"Table 1: Number of tokens in every used dataset. \n\n","rows":[],"columns":[],"mergedAllColumns":[],"numberCells":[]},{"caption":"ing 1.9M words (Pennington et al., 2014). Note \nthat, these embeddings are also updated during \nfine-tuning. For biLSTM (token-level feature ex-\ntractor), we set the number of units of the pre-\ntrained branch to 200 and experimented our ap-\nproach with k added random-units, with k ∈ \n{50, 100, 150, 200}. For the normalisation, we \nused 2 -norm. Finally, in all experiments, training \nwas performed using SGD with momentum and \nmini-batches of 8 sentences. Evidently, all the hy-\nperparameters have been cross-validated. \n\n3.2 Datasets \nFor the source-dataset, we used the Penn-Tree-\nBank (PTB) of Wall Street Journal (WSJ), a large \nEnglish dataset containing 1.2M+ tokens from the \nnewswire domain annotated with the PTB tag-\nset. Regarding the target-datasets, we used three \ndatasets in the Tweets domain: TPoS (Ritter et al., \n2011), annotated with 40 tags ; ARK (Owoputi \net al., 2013) containing 25 coarse tags; and the re-\ncent TweeBank (Liu et al., 2018) containing 17 \ntags (PTB universal tag-set). The number of to-\nkens in the datasets are given in Table 1. \n\n","rows":[],"columns":[],"mergedAllColumns":[],"numberCells":[]},{"caption":"Table 2: Comparison of our method to state-of-the-art (top) and baselines (bottom) in terms of token-level accuracy \n(in %) on 3 Tweets datasets. Note that, baselines are more fairly comparable to our method. In the second and last \ncolumns, we respectively highlighted the number of parameters and the average performance on the 3 datasets. \n\n","rows":["Random - 400","PretRand ( Ours )","n / a","Random - 200","Ensemble Model ( 2 rand )","2×","Ensemble Model ( 1 pret + 1 rand )","1×","Standard fine - tuning"],"columns":["n / a"],"mergedAllColumns":[],"numberCells":[{"number":"91.56","isBolded":true,"associatedRows":["PretRand ( Ours )","2×"],"associatedColumns":["n / a"],"associatedMergedColumns":[]},{"number":"91.56","isBolded":false,"associatedRows":["Random - 200","1×"],"associatedColumns":["n / a"],"associatedMergedColumns":[]},{"number":"87.76","isBolded":false,"associatedRows":["Random - 200","1×"],"associatedColumns":["n / a"],"associatedMergedColumns":[]},{"number":"92.59","isBolded":false,"associatedRows":["Standard fine - tuning","1×"],"associatedColumns":["n / a"],"associatedMergedColumns":[]},{"number":"93.24","isBolded":true,"associatedRows":["PretRand ( Ours )","2×"],"associatedColumns":["n / a"],"associatedMergedColumns":[]},{"number":"1.02×","isBolded":true,"associatedRows":["PretRand ( Ours )"],"associatedColumns":["n / a"],"associatedMergedColumns":[]},{"number":"91.73","isBolded":false,"associatedRows":["Ensemble Model ( 2 rand )","2×"],"associatedColumns":["n / a"],"associatedMergedColumns":[]},{"number":"91.20","isBolded":false,"associatedRows":["Random - 200","1×"],"associatedColumns":["n / a"],"associatedMergedColumns":[]},{"number":"91.41","isBolded":false,"associatedRows":["Ensemble Model ( 1 pret + 1 rand )","2×"],"associatedColumns":["n / a"],"associatedMergedColumns":[]},{"number":"91.72","isBolded":false,"associatedRows":["Standard fine - tuning","1×"],"associatedColumns":["n / a"],"associatedMergedColumns":[]},{"number":"88.32","isBolded":false,"associatedRows":["Random - 200","1×"],"associatedColumns":["n / a"],"associatedMergedColumns":[]},{"number":"92.85","isBolded":false,"associatedRows":["Ensemble Model ( 1 pret + 1 rand )","2×"],"associatedColumns":["n / a"],"associatedMergedColumns":[]},{"number":"90.38","isBolded":false,"associatedRows":["Random - 400","1×"],"associatedColumns":["n / a"],"associatedMergedColumns":[]},{"number":"92.99","isBolded":false,"associatedRows":["Standard fine - tuning","1×"],"associatedColumns":["n / a"],"associatedMergedColumns":[]},{"number":"89.01","isBolded":false,"associatedRows":["Random - 400","1×"],"associatedColumns":["n / a"],"associatedMergedColumns":[]},{"number":"1.03×","isBolded":true,"associatedRows":["Random - 400"],"associatedColumns":["n / a"],"associatedMergedColumns":[]},{"number":"91.79","isBolded":false,"associatedRows":["Standard fine - tuning","1×"],"associatedColumns":["n / a"],"associatedMergedColumns":[]},{"number":"88.8","isBolded":false,"associatedRows":["Ensemble Model ( 2 rand )","2×"],"associatedColumns":["n / a"],"associatedMergedColumns":[]},{"number":"89.20","isBolded":false,"associatedRows":["Ensemble Model ( 2 rand )","2×"],"associatedColumns":["n / a"],"associatedMergedColumns":[]},{"number":"88.61","isBolded":false,"associatedRows":["Ensemble Model ( 1 pret + 1 rand )","2×"],"associatedColumns":["n / a"],"associatedMergedColumns":[]},{"number":"90.99","isBolded":false,"associatedRows":["Random - 400","1×"],"associatedColumns":["n / a"],"associatedMergedColumns":[]},{"number":"92.57","isBolded":false,"associatedRows":["Ensemble Model ( 1 pret + 1 rand )","2×"],"associatedColumns":["n / a"],"associatedMergedColumns":[]},{"number":"91.04","isBolded":false,"associatedRows":["Ensemble Model ( 1 pret + 1 rand )","2×"],"associatedColumns":["n / a"],"associatedMergedColumns":[]},{"number":"90.7","isBolded":false,"associatedRows":["Standard fine - tuning","1×"],"associatedColumns":["n / a"],"associatedMergedColumns":[]},{"number":"91.46","isBolded":true,"associatedRows":["PretRand ( Ours )","2×"],"associatedColumns":["n / a"],"associatedMergedColumns":[]},{"number":"93.77","isBolded":true,"associatedRows":["PretRand ( Ours )","2×"],"associatedColumns":["n / a"],"associatedMergedColumns":[]},{"number":"92.8","isBolded":false,"associatedRows":["Ensemble Model ( 1 pret + 1 rand )","n / a"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"91.08","isBolded":false,"associatedRows":["Ensemble Model ( 1 pret + 1 rand )","n / a"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"89.90","isBolded":false,"associatedRows":["Random - 200","1×"],"associatedColumns":["n / a"],"associatedMergedColumns":[]},{"number":"90.67","isBolded":false,"associatedRows":["Random - 200","1×"],"associatedColumns":["n / a"],"associatedMergedColumns":[]},{"number":"90.92","isBolded":false,"associatedRows":["Ensemble Model ( 1 pret + 1 rand )","n / a"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"92.05","isBolded":false,"associatedRows":["Ensemble Model ( 2 rand )","2×"],"associatedColumns":["n / a"],"associatedMergedColumns":[]},{"number":"94.95","isBolded":true,"associatedRows":["PretRand ( Ours )","2×"],"associatedColumns":["n / a"],"associatedMergedColumns":[]},{"number":"94.51","isBolded":true,"associatedRows":["PretRand ( Ours )","2×"],"associatedColumns":["n / a"],"associatedMergedColumns":[]},{"number":"91.36","isBolded":false,"associatedRows":["Ensemble Model ( 2 rand )","2×"],"associatedColumns":["n / a"],"associatedMergedColumns":[]},{"number":"88.89","isBolded":false,"associatedRows":["Random - 400","1×"],"associatedColumns":["n / a"],"associatedMergedColumns":[]},{"number":"90.96","isBolded":false,"associatedRows":["Standard fine - tuning","1×"],"associatedColumns":["n / a"],"associatedMergedColumns":[]},{"number":"91.63","isBolded":false,"associatedRows":["Random - 400","1×"],"associatedColumns":["n / a"],"associatedMergedColumns":[]},{"number":"91.38","isBolded":false,"associatedRows":["Random - 400","1×"],"associatedColumns":["n / a"],"associatedMergedColumns":[]},{"number":"89.77","isBolded":false,"associatedRows":["Ensemble Model ( 1 pret + 1 rand )","2×"],"associatedColumns":["n / a"],"associatedMergedColumns":[]},{"number":"90.62","isBolded":false,"associatedRows":["Ensemble Model ( 2 rand )","2×"],"associatedColumns":["n / a"],"associatedMergedColumns":[]}]},{"caption":"Table 3: Ablation study, Token level accuracy (in %) \nwhen progressively ablating PretRand components. \n\n","rows":["PretRand","- learnVect","- l2 norm","- random"],"columns":["the","dev - set","Avg","training - set","sizes","TPoS","TweeBank )","Performances","ArK","different","TweeBank"],"mergedAllColumns":["++","tween our PretRand and standard fine - tuning ."],"numberCells":[{"number":"94.59","isBolded":false,"associatedRows":["- learnVect"],"associatedColumns":["dev - set","sizes","TweeBank"],"associatedMergedColumns":["tween our PretRand and standard fine - tuning ."]},{"number":"90.97","isBolded":false,"associatedRows":["- random"],"associatedColumns":["Performances","different","TPoS"],"associatedMergedColumns":["tween our PretRand and standard fine - tuning ."]},{"number":"93.38","isBolded":false,"associatedRows":["- l2 norm"],"associatedColumns":["dev - set","sizes","TweeBank"],"associatedMergedColumns":["++"]},{"number":"92.08","isBolded":false,"associatedRows":["- l2 norm"],"associatedColumns":["TweeBank )","the","Avg"],"associatedMergedColumns":["++"]},{"number":"93.11","isBolded":false,"associatedRows":["- random"],"associatedColumns":["Performances","training - set","ArK"],"associatedMergedColumns":["tween our PretRand and standard fine - tuning ."]},{"number":"91.46","isBolded":true,"associatedRows":["PretRand"],"associatedColumns":["Performances","different","TPoS"],"associatedMergedColumns":["tween our PretRand and standard fine - tuning ."]},{"number":"93.77","isBolded":true,"associatedRows":["PretRand"],"associatedColumns":["Performances","training - set","ArK"],"associatedMergedColumns":["tween our PretRand and standard fine - tuning ."]},{"number":"93.46","isBolded":false,"associatedRows":["- learnVect"],"associatedColumns":["Performances","training - set","ArK"],"associatedMergedColumns":["tween our PretRand and standard fine - tuning ."]},{"number":"94.13","isBolded":false,"associatedRows":["- random"],"associatedColumns":["dev - set","sizes","TweeBank"],"associatedMergedColumns":["tween our PretRand and standard fine - tuning ."]},{"number":"93.10","isBolded":false,"associatedRows":["- learnVect"],"associatedColumns":["TweeBank )","the","Avg"],"associatedMergedColumns":["tween our PretRand and standard fine - tuning ."]},{"number":"92.11","isBolded":false,"associatedRows":["- l2 norm"],"associatedColumns":["Performances","training - set","ArK"],"associatedMergedColumns":["++"]},{"number":"93.39","isBolded":true,"associatedRows":["PretRand"],"associatedColumns":["TweeBank )","the","Avg"],"associatedMergedColumns":["tween our PretRand and standard fine - tuning ."]},{"number":"91.25","isBolded":false,"associatedRows":["- learnVect"],"associatedColumns":["Performances","different","TPoS"],"associatedMergedColumns":["tween our PretRand and standard fine - tuning ."]},{"number":"92.73","isBolded":false,"associatedRows":["- random"],"associatedColumns":["TweeBank )","the","Avg"],"associatedMergedColumns":["tween our PretRand and standard fine - tuning ."]},{"number":"90.76","isBolded":false,"associatedRows":["- l2 norm"],"associatedColumns":["Performances","different","TPoS"],"associatedMergedColumns":["++"]},{"number":"94.95","isBolded":true,"associatedRows":["PretRand"],"associatedColumns":["dev - set","sizes","TweeBank"],"associatedMergedColumns":["tween our PretRand and standard fine - tuning ."]}]}]