[{"caption":"Table 1: Results of PEGASUS LARGE and PEGASUS BASE on all downstream datasets compared with the previous SOTA, \nwhich are fetched from ","rows":["numbers within"],"columns":[") . Best ROUGE numbers on each dataset and"],"mergedAllColumns":[],"numberCells":[{"number":"0.15ofthebestnumbersarebolded.","isBolded":false,"associatedRows":["numbers within"],"associatedColumns":[") . Best ROUGE numbers on each dataset and"],"associatedMergedColumns":[]}]},{"caption":"Table 2: A comparison of PEGASUS LARGE with other pretrained models on XSum, CNN/DailyMail and Gigaword. Best \nROUGE numbers and numbers within 0.15 of the best numbers are bolded. \n\n","rows":["input \u003d","Multi - News are well beyond","observed in training up to L"],"columns":["R1 / R2 / RL","PubMed ,","T5 ( Raffel et al . , 2019 )","UniLM ( Dong et al . , 2019 )","BERTShare ( Rothe et al . , 2019 )","BART ( Lewis et al . , 2019 )","PEGASUSLARGE ( HugeNews )","MASS ( Song et al . , 2019 )","-","arXiv ,","α , when fine - tuning PEGASUS LARGE on each downstream","This would present a problem for position em -","PEGASUSLARGE ( C4 )"],"mergedAllColumns":["average input length in BIGPATENT , arXiv , PubMed and","when fine - tuning PEGASUS LARGE beyond the input lengths"],"numberCells":[{"number":"1024tokens,furtherscalingup","isBolded":false,"associatedRows":["Multi - News are well beyond"],"associatedColumns":["R1 / R2 / RL","BERTShare ( Rothe et al . , 2019 )","MASS ( Song et al . , 2019 )","-","BART ( Lewis et al . , 2019 )","-","PEGASUSLARGE ( C4 )","PEGASUSLARGE ( HugeNews )","α , when fine - tuning PEGASUS LARGE on each downstream","PubMed ,","This would present a problem for position em -"],"associatedMergedColumns":["average input length in BIGPATENT , arXiv , PubMed and"]},{"number":"1024tokens.","isBolded":true,"associatedRows":["observed in training up to L","input \u003d"],"associatedColumns":["R1 / R2 / RL","BERTShare ( Rothe et al . , 2019 )","MASS ( Song et al . , 2019 )","UniLM ( Dong et al . , 2019 )","BART ( Lewis et al . , 2019 )","T5 ( Raffel et al . , 2019 )","PEGASUSLARGE ( C4 )","PEGASUSLARGE ( HugeNews )","α , when fine - tuning PEGASUS LARGE on each downstream","arXiv ,","This would present a problem for position em -"],"associatedMergedColumns":["when fine - tuning PEGASUS LARGE beyond the input lengths"]}]},{"caption":"Table C.1: Hyperparamters of the pre-training and fine-tuning stages reported in section 6. The hyperparameters of \nfine-tuning PEGASUS LARGE were decided by grid search while others were decided by empirically default commonly used \nvalues. Max input/target tokens correspond to L input and L target in Section 6. \n\nPre-training (default unless otherwise specified in section 6) \n\nModel \nLearning \nrate \n\nLabel \nsmoothing \nNum of steps \nBatch size \nObjective \nCorpus \nMax input \ntokens \n\nMax target \ntokens \nPEGASUSBASE \n0.1 \n0.0 \n500k \n256 \nInd-Orig \nc4 \n512 \n256 \nPEGASUSLARGE \n0.1 \n0.0 \n500k \n8192 \nInd-Orig \nc4 or HugeNews \n512 \n256 \n\nFine-tuning of PEGASUS BASE in Figure 3, 4, 5, B.1 and Table 1 \n\nDataset \nLearning \nrate \n\nLabel \nsmoothing \nNum of steps \nBatch size \nBeam size \nBeam alpha \nMax input \ntokens \n\nMax target \ntokens \nXSum \n5e-4 \n0.1 \n50k \n256 \n1 \n-\n512 \n64 \nCNN/DailyMail \n5e-4 \n0.1 \n50k \n256 \n1 \n-\n512 \n128 \nNEWSROOM \n5e-4 \n0.1 \n50k \n256 \n1 \n-\n512 \n128 \nMulti-News \n5e-4 \n0.1 \n50k \n256 \n1 \n-\n512 \n256 \nWikiHow \n5e-4 \n0.1 \n50k \n256 \n1 \n-\n512 \n256 \nReddit TIFU \n5e-4 \n0.1 \n50k \n256 \n1 \n-\n512 \n128 \nBIGPATENT \n0.01 \n0.1 \n300k \n256 \n1 \n-\n512 \n256 \narXiv \n5e-4 \n0.1 \n50k \n256 \n1 \n-\n512 \n256 \nPubMed \n5e-4 \n0.1 \n50k \n256 \n1 \n-\n512 \n256 \nGigaword \n5e-4 \n0.1 \n50k \n256 \n1 \n-\n128 \n32 \nAESLC \n5e-4 \n0.1 \n50k \n256 \n1 \n-\n512 \n32 \nBillSum \n5e-4 \n0.1 \n50k \n256 \n1 \n-\n512 \n256 \n\nTransformer BASE in Table 1 \n\nDataset \nLearning \nrate \n\nLabel \nsmoothing \nNum of steps \nBatch size \nBeam size \nBeam alpha \nMax input \ntokens \n\nMax target \ntokens \nBIGPATENT \n0.01 \n0.1 \n300k \n256 \n1 \n-\n512 \n256 \nAESLC \n5e-4 \n0.1 \n300k \n256 \n1 \n-\n512 \n32 \nOthers \n5e-3 \n0.1 \n300k \n256 \n1 \n-\nSame as PEGASUSBASE \n\nFine-tuning of PEGASUS LARGE in Table 1 and 2 \n\nDataset \nLearning \nrate \n\nLabel \nsmoothing \nNum of steps \nBatch size \nBeam size \nBeam alpha \nMax input \ntokens \n\nMax target \ntokens \nXSum(C4) \n1e-4 \n0.1 \n130k \n256 \n8 \n0.8 \n512 \n64 \nXSum(HugeNews) \n1e-4 \n0.1 \n80k \n256 \n8 \n0.8 \n512 \n64 \nCNN/DailyMail(C4) \n5e-5 \n0.1 \n220k \n256 \n8 \n0.8 \n1024 \n128 \nCNN/DailyMail(HugeNews) \n5e-5 \n0.1 \n170k \n256 \n8 \n0.9 \n1024 \n128 \nNEWSROOM \n4e-4 \n0.1 \n104k \n256 \n8 \n0.8 \n512 \n128 \nMulti-News \n5e-5 \n0.1 \n80k \n256 \n8 \n0.9 \n1024 \n256 \nWikiHow \n8e-4 \n0.1 \n50k \n256 \n8 \n0.6 \n512 \n256 \nReddit TIFU \n1e-4 \n0.1 \n12k \n256 \n8 \n0.6 \n512 \n128 \nBIGPATENT \n5e-3 \n0.1 \n300k \n256 \n8 \n0.7 \n1024 \n256 \narXiv \n8e-4 \n0.1 \n74k \n256 \n8 \n0.8 \n1024 \n256 \nPubMed \n2e-4 \n0.1 \n100k \n256 \n8 \n0.8 \n1024 \n256 \nGigaword \n8e-4 \n0.1 \n90k \n256 \n8 \n0.6 \n128 \n32 \nAESLC \n2e-4 \n0.1 \n16k \n256 \n8 \n0.6 \n512 \n32 \nBillSum \n2e-4 \n0.1 \n100k \n256 \n8 \n0.8 \n1024 \n256 \n\nFine-tuning of PEGASUS LARGE in Figure 6 \n\nDataset \nLearning \nrate \n\nLabel \nsmoothing \nNum of steps \nBatch size \nBeam size \nBeam alpha \nMax input \ntokens \n\nMax target \ntokens \nall \n5e-4 \n0.1 \n2k \n256 \n1 \n-\nSame as PEGASUSBASE \n","rows":["XSum ( C4 )","104k","BillSum","PubMed","100k","500k","1e - 4","CNN / DailyMail","BASE in Figure 3 , 4 , 5 ,","WikiHow","all","8e - 4","2e - 4","Multi - News","-","74k","50k","XSum ( HugeNews )","c4","1","90k","1024","arXiv","8","BIGPATENT","Ind - Orig","5e - 5","5e - 4","5e - 3","8192","4e - 4","130k","300k","PEGASUSLARGE","Reddit TIFU","AESLC","Gigaword","CNN / DailyMail ( C4 )","PEGASUSBASE","Others","CNN / DailyMail ( HugeNews )","16k","12k","c4 or HugeNews","220k","80k","170k","NEWSROOM","2k","XSum","Fine - tuning of PEGASUS"],"columns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Beam alpha","Num of steps","Dataset","Max input","Label","Same as PEGASUSBASE","-","Corpus","Learning","Objective","1","rate","Model","Batch size","tokens","Max target","smoothing","The hyperparameters of"],"mergedAllColumns":["Pre - training ( default unless otherwise specified in section 6 )","LARGE in Table 1 and 2","BASE in Table 1","LARGE in Figure 6","64","32"],"numberCells":[{"number":"128","isBolded":false,"associatedRows":["Gigaword","8e - 4","90k","BASE in Figure 3 , 4 , 5 ,","8","-"],"associatedColumns":["The hyperparameters of","Max input","Corpus","tokens","Max input","Beam alpha","tokens","Max input","Beam alpha","tokens","Same as PEGASUSBASE","Max input","Beam alpha","tokens"],"associatedMergedColumns":["64"]},{"number":"0.1","isBolded":false,"associatedRows":["PEGASUSLARGE"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Learning","Model","rate"],"associatedMergedColumns":["Pre - training ( default unless otherwise specified in section 6 )"]},{"number":"256","isBolded":false,"associatedRows":["Gigaword","5e - 4","50k"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Batch size","smoothing","Label","Batch size","smoothing"],"associatedMergedColumns":["64"]},{"number":"0.1","isBolded":false,"associatedRows":["WikiHow","8e - 4"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Num of steps","smoothing","Label","Num of steps","smoothing","Label","Num of steps","smoothing","1","Label","Num of steps","smoothing"],"associatedMergedColumns":["64"]},{"number":"256","isBolded":false,"associatedRows":["BillSum","2e - 4","100k"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Batch size","smoothing","Label","Batch size","smoothing","Label","Batch size","smoothing","1","Label","Batch size","smoothing"],"associatedMergedColumns":["32"]},{"number":"256","isBolded":false,"associatedRows":["Multi - News","5e - 4","50k"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Batch size","smoothing","Label","Batch size","smoothing"],"associatedMergedColumns":["64"]},{"number":"256","isBolded":false,"associatedRows":["BIGPATENT","5e - 4","300k"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Batch size","smoothing","Label","Batch size","smoothing"],"associatedMergedColumns":["64"]},{"number":"0.9","isBolded":false,"associatedRows":["Multi - News","5e - 5","80k","BASE in Figure 3 , 4 , 5 ,","8"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Max input","Corpus","tokens","Max input","Beam alpha","tokens","Max input","Beam alpha","tokens","-","Max input","Beam alpha","tokens"],"associatedMergedColumns":["64"]},{"number":"256","isBolded":false,"associatedRows":["WikiHow","8e - 4","50k","BASE in Figure 3 , 4 , 5 ,","8","-","1024"],"associatedColumns":["The hyperparameters of","Max target","Corpus","tokens","Max target","Beam alpha","tokens","Max target","Beam alpha","tokens","Same as PEGASUSBASE","Max target","Beam alpha","tokens"],"associatedMergedColumns":["64"]},{"number":"0.6","isBolded":false,"associatedRows":["WikiHow","8e - 4","50k","BASE in Figure 3 , 4 , 5 ,","8"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Max input","Corpus","tokens","Max input","Beam alpha","tokens","Max input","Beam alpha","tokens","-","Max input","Beam alpha","tokens"],"associatedMergedColumns":["64"]},{"number":"256","isBolded":false,"associatedRows":["BIGPATENT","5e - 3","300k"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Batch size","smoothing","Label","Batch size","smoothing","Label","Batch size","smoothing","1","Label","Batch size","smoothing"],"associatedMergedColumns":["64"]},{"number":"256","isBolded":false,"associatedRows":["Reddit TIFU","5e - 4","50k"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Batch size","smoothing","Label","Batch size","smoothing"],"associatedMergedColumns":["64"]},{"number":"0.6","isBolded":false,"associatedRows":["Gigaword","8e - 4","90k","BASE in Figure 3 , 4 , 5 ,","8"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Max input","Corpus","tokens","Max input","Beam alpha","tokens","Max input","Beam alpha","tokens","-","Max input","Beam alpha","tokens"],"associatedMergedColumns":["64"]},{"number":"128","isBolded":false,"associatedRows":["CNN / DailyMail ( C4 )","5e - 5","220k","BASE in Figure 3 , 4 , 5 ,","8","-","1024"],"associatedColumns":["The hyperparameters of","Max target","Corpus","tokens","Max target","Beam alpha","tokens","Max target","Beam alpha","tokens","Same as PEGASUSBASE","Max target","Beam alpha","tokens"],"associatedMergedColumns":["64"]},{"number":"256","isBolded":false,"associatedRows":["PubMed","2e - 4","100k"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Batch size","smoothing","Label","Batch size","smoothing","Label","Batch size","smoothing","1","Label","Batch size","smoothing"],"associatedMergedColumns":["64"]},{"number":"128","isBolded":false,"associatedRows":["NEWSROOM","5e - 4","50k","BASE in Figure 3 , 4 , 5 ,","1","-","1024"],"associatedColumns":["The hyperparameters of","Max target","Corpus","tokens","Max target","Beam alpha","tokens"],"associatedMergedColumns":["64"]},{"number":"256","isBolded":false,"associatedRows":["BillSum","5e - 4","50k","BASE in Figure 3 , 4 , 5 ,","1","-","1024"],"associatedColumns":["The hyperparameters of","Max target","Corpus","tokens","Max target","Beam alpha","tokens"],"associatedMergedColumns":["32"]},{"number":"512","isBolded":false,"associatedRows":["NEWSROOM","5e - 4","50k","BASE in Figure 3 , 4 , 5 ,","1","-"],"associatedColumns":["The hyperparameters of","Max input","Corpus","tokens","Max input","Beam alpha","tokens"],"associatedMergedColumns":["64"]},{"number":"256","isBolded":false,"associatedRows":["BIGPATENT","5e - 4","300k","BASE in Figure 3 , 4 , 5 ,","1","-","1024"],"associatedColumns":["The hyperparameters of","Max target","Corpus","tokens","Max target","Beam alpha","tokens"],"associatedMergedColumns":["64"]},{"number":"512","isBolded":false,"associatedRows":["BillSum","5e - 4","50k","BASE in Figure 3 , 4 , 5 ,","1","-"],"associatedColumns":["The hyperparameters of","Max input","Corpus","tokens","Max input","Beam alpha","tokens"],"associatedMergedColumns":["32"]},{"number":"B.1andTable1","isBolded":true,"associatedRows":["PEGASUSLARGE","5e - 4","Fine - tuning of PEGASUS","BASE in Figure 3 , 4 , 5 ,"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Max input","Objective","tokens"],"associatedMergedColumns":["Pre - training ( default unless otherwise specified in section 6 )"]},{"number":"256","isBolded":false,"associatedRows":["Multi - News","5e - 5","80k","BASE in Figure 3 , 4 , 5 ,","8","-","1024"],"associatedColumns":["The hyperparameters of","Max target","Corpus","tokens","Max target","Beam alpha","tokens","Max target","Beam alpha","tokens","Same as PEGASUSBASE","Max target","Beam alpha","tokens"],"associatedMergedColumns":["64"]},{"number":"0.1","isBolded":false,"associatedRows":["Reddit TIFU","5e - 4"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Num of steps","smoothing","Label","Num of steps","smoothing"],"associatedMergedColumns":["64"]},{"number":"256","isBolded":false,"associatedRows":["Multi - News","5e - 4","50k","BASE in Figure 3 , 4 , 5 ,","1","-","1024"],"associatedColumns":["The hyperparameters of","Max target","Corpus","tokens","Max target","Beam alpha","tokens"],"associatedMergedColumns":["64"]},{"number":"512","isBolded":false,"associatedRows":["XSum ( C4 )","1e - 4","130k","BASE in Figure 3 , 4 , 5 ,","8","-"],"associatedColumns":["The hyperparameters of","Max input","Corpus","tokens","Max input","Beam alpha","tokens","Max input","Beam alpha","tokens","Same as PEGASUSBASE","Max input","Beam alpha","tokens"],"associatedMergedColumns":["LARGE in Table 1 and 2"]},{"number":"0.1","isBolded":false,"associatedRows":["AESLC","2e - 4"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Num of steps","smoothing","Label","Num of steps","smoothing","Label","Num of steps","smoothing","1","Label","Num of steps","smoothing"],"associatedMergedColumns":["32"]},{"number":"0.6","isBolded":false,"associatedRows":["AESLC","2e - 4","16k","BASE in Figure 3 , 4 , 5 ,","8"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Max input","Corpus","tokens","Max input","Beam alpha","tokens","Max input","Beam alpha","tokens","-","Max input","Beam alpha","tokens"],"associatedMergedColumns":["32"]},{"number":"256","isBolded":false,"associatedRows":["BIGPATENT","5e - 3","300k","BASE in Figure 3 , 4 , 5 ,","8","-","1024"],"associatedColumns":["The hyperparameters of","Max target","Corpus","tokens","Max target","Beam alpha","tokens","Max target","Beam alpha","tokens","Same as PEGASUSBASE","Max target","Beam alpha","tokens"],"associatedMergedColumns":["64"]},{"number":"512","isBolded":false,"associatedRows":["WikiHow","5e - 4","50k","BASE in Figure 3 , 4 , 5 ,","1","-"],"associatedColumns":["The hyperparameters of","Max input","Corpus","tokens","Max input","Beam alpha","tokens"],"associatedMergedColumns":["64"]},{"number":"256","isBolded":false,"associatedRows":["AESLC","5e - 4","300k"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Batch size","smoothing","Label","Batch size","smoothing","Label","Batch size","smoothing"],"associatedMergedColumns":["BASE in Table 1"]},{"number":"256","isBolded":false,"associatedRows":["WikiHow","8e - 4","50k"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Batch size","smoothing","Label","Batch size","smoothing","Label","Batch size","smoothing","1","Label","Batch size","smoothing"],"associatedMergedColumns":["64"]},{"number":"0.1","isBolded":false,"associatedRows":["CNN / DailyMail ( C4 )","5e - 5"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Num of steps","smoothing","Label","Num of steps","smoothing","Label","Num of steps","smoothing","1","Label","Num of steps","smoothing"],"associatedMergedColumns":["64"]},{"number":"256","isBolded":false,"associatedRows":["PEGASUSBASE","5e - 4","500k"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Batch size","smoothing"],"associatedMergedColumns":["Pre - training ( default unless otherwise specified in section 6 )"]},{"number":"256","isBolded":false,"associatedRows":["BIGPATENT","5e - 4","300k"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Batch size","smoothing","Label","Batch size","smoothing","Label","Batch size","smoothing"],"associatedMergedColumns":["BASE in Table 1"]},{"number":"0.1","isBolded":false,"associatedRows":["Reddit TIFU","1e - 4"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Num of steps","smoothing","Label","Num of steps","smoothing","Label","Num of steps","smoothing","1","Label","Num of steps","smoothing"],"associatedMergedColumns":["64"]},{"number":"128","isBolded":false,"associatedRows":["NEWSROOM","4e - 4","104k","BASE in Figure 3 , 4 , 5 ,","8","-","1024"],"associatedColumns":["The hyperparameters of","Max target","Corpus","tokens","Max target","Beam alpha","tokens","Max target","Beam alpha","tokens","Same as PEGASUSBASE","Max target","Beam alpha","tokens"],"associatedMergedColumns":["64"]},{"number":"128","isBolded":false,"associatedRows":["CNN / DailyMail ( HugeNews )","5e - 5","170k","BASE in Figure 3 , 4 , 5 ,","8","-","1024"],"associatedColumns":["The hyperparameters of","Max target","Corpus","tokens","Max target","Beam alpha","tokens","Max target","Beam alpha","tokens","Same as PEGASUSBASE","Max target","Beam alpha","tokens"],"associatedMergedColumns":["64"]},{"number":"512","isBolded":false,"associatedRows":["BIGPATENT","5e - 4","300k","BASE in Figure 3 , 4 , 5 ,","1","-"],"associatedColumns":["The hyperparameters of","Max input","Corpus","tokens","Max input","Beam alpha","tokens"],"associatedMergedColumns":["64"]},{"number":"512","isBolded":false,"associatedRows":["WikiHow","8e - 4","50k","BASE in Figure 3 , 4 , 5 ,","8","-"],"associatedColumns":["The hyperparameters of","Max input","Corpus","tokens","Max input","Beam alpha","tokens","Max input","Beam alpha","tokens","Same as PEGASUSBASE","Max input","Beam alpha","tokens"],"associatedMergedColumns":["64"]},{"number":"256","isBolded":false,"associatedRows":["CNN / DailyMail","5e - 4","50k"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Batch size","smoothing","Label","Batch size","smoothing"],"associatedMergedColumns":["64"]},{"number":"0.1","isBolded":false,"associatedRows":["Gigaword","5e - 4"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Num of steps","smoothing","Label","Num of steps","smoothing"],"associatedMergedColumns":["64"]},{"number":"256","isBolded":false,"associatedRows":["PEGASUSLARGE","5e - 4","500k","8192","Ind - Orig","c4 or HugeNews","1024"],"associatedColumns":["The hyperparameters of","Max target","Corpus","tokens"],"associatedMergedColumns":["Pre - training ( default unless otherwise specified in section 6 )"]},{"number":"0.7","isBolded":false,"associatedRows":["BIGPATENT","5e - 3","300k","BASE in Figure 3 , 4 , 5 ,","8"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Max input","Corpus","tokens","Max input","Beam alpha","tokens","Max input","Beam alpha","tokens","-","Max input","Beam alpha","tokens"],"associatedMergedColumns":["64"]},{"number":"256","isBolded":false,"associatedRows":["BillSum","2e - 4","100k","BASE in Figure 3 , 4 , 5 ,","8","-","1024"],"associatedColumns":["The hyperparameters of","Max target","Corpus","tokens","Max target","Beam alpha","tokens","Max target","Beam alpha","tokens","Same as PEGASUSBASE","Max target","Beam alpha","tokens"],"associatedMergedColumns":["32"]},{"number":"256","isBolded":false,"associatedRows":["PubMed","5e - 4","50k"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Batch size","smoothing","Label","Batch size","smoothing"],"associatedMergedColumns":["64"]},{"number":"0.1","isBolded":false,"associatedRows":["CNN / DailyMail ( HugeNews )","5e - 5"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Num of steps","smoothing","Label","Num of steps","smoothing","Label","Num of steps","smoothing","1","Label","Num of steps","smoothing"],"associatedMergedColumns":["64"]},{"number":"0.8","isBolded":false,"associatedRows":["CNN / DailyMail ( C4 )","5e - 5","220k","BASE in Figure 3 , 4 , 5 ,","8"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Max input","Corpus","tokens","Max input","Beam alpha","tokens","Max input","Beam alpha","tokens","-","Max input","Beam alpha","tokens"],"associatedMergedColumns":["64"]},{"number":"0.1","isBolded":false,"associatedRows":["BIGPATENT","5e - 4"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Num of steps","smoothing","Label","Num of steps","smoothing","Label","Num of steps","smoothing"],"associatedMergedColumns":["BASE in Table 1"]},{"number":"0.1","isBolded":false,"associatedRows":["BIGPATENT","5e - 4"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Num of steps","smoothing","Label","Num of steps","smoothing"],"associatedMergedColumns":["64"]},{"number":"0.01","isBolded":false,"associatedRows":["BIGPATENT"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Learning","Model","rate","Learning","Dataset","rate","Learning","Dataset","rate"],"associatedMergedColumns":["BASE in Table 1"]},{"number":"128","isBolded":false,"associatedRows":["Reddit TIFU","1e - 4","12k","BASE in Figure 3 , 4 , 5 ,","8","-","1024"],"associatedColumns":["The hyperparameters of","Max target","Corpus","tokens","Max target","Beam alpha","tokens","Max target","Beam alpha","tokens","Same as PEGASUSBASE","Max target","Beam alpha","tokens"],"associatedMergedColumns":["64"]},{"number":"0.1","isBolded":false,"associatedRows":["XSum","5e - 4"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Num of steps","smoothing","Label","Num of steps","smoothing"],"associatedMergedColumns":["Pre - training ( default unless otherwise specified in section 6 )"]},{"number":"256","isBolded":false,"associatedRows":["Multi - News","5e - 5","80k"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Batch size","smoothing","Label","Batch size","smoothing","Label","Batch size","smoothing","1","Label","Batch size","smoothing"],"associatedMergedColumns":["64"]},{"number":"512","isBolded":false,"associatedRows":["Reddit TIFU","1e - 4","12k","BASE in Figure 3 , 4 , 5 ,","8","-"],"associatedColumns":["The hyperparameters of","Max input","Corpus","tokens","Max input","Beam alpha","tokens","Max input","Beam alpha","tokens","Same as PEGASUSBASE","Max input","Beam alpha","tokens"],"associatedMergedColumns":["64"]},{"number":"256","isBolded":false,"associatedRows":["PubMed","2e - 4","100k","BASE in Figure 3 , 4 , 5 ,","8","-","1024"],"associatedColumns":["The hyperparameters of","Max target","Corpus","tokens","Max target","Beam alpha","tokens","Max target","Beam alpha","tokens","Same as PEGASUSBASE","Max target","Beam alpha","tokens"],"associatedMergedColumns":["64"]},{"number":"256","isBolded":false,"associatedRows":["arXiv","5e - 4","50k","BASE in Figure 3 , 4 , 5 ,","1","-","1024"],"associatedColumns":["The hyperparameters of","Max target","Corpus","tokens","Max target","Beam alpha","tokens"],"associatedMergedColumns":["64"]},{"number":"512","isBolded":false,"associatedRows":["AESLC","2e - 4","16k","BASE in Figure 3 , 4 , 5 ,","8","-"],"associatedColumns":["The hyperparameters of","Max input","Corpus","tokens","Max input","Beam alpha","tokens","Max input","Beam alpha","tokens","Same as PEGASUSBASE","Max input","Beam alpha","tokens"],"associatedMergedColumns":["32"]},{"number":"0.1","isBolded":false,"associatedRows":["PubMed","5e - 4"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Num of steps","smoothing","Label","Num of steps","smoothing"],"associatedMergedColumns":["64"]},{"number":"256","isBolded":false,"associatedRows":["BIGPATENT","5e - 4","300k","BASE in Figure 3 , 4 , 5 ,","1","-","1024"],"associatedColumns":["The hyperparameters of","Max target","Corpus","tokens","Max target","Beam alpha","tokens","Max target","Beam alpha","tokens"],"associatedMergedColumns":["BASE in Table 1"]},{"number":"0.1","isBolded":false,"associatedRows":["CNN / DailyMail","5e - 4"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Num of steps","smoothing","Label","Num of steps","smoothing"],"associatedMergedColumns":["64"]},{"number":"512","isBolded":false,"associatedRows":["PEGASUSBASE","5e - 4","500k","BASE in Figure 3 , 4 , 5 ,","Ind - Orig","c4"],"associatedColumns":["The hyperparameters of","Max input","Corpus","tokens"],"associatedMergedColumns":["Pre - training ( default unless otherwise specified in section 6 )"]},{"number":"512","isBolded":false,"associatedRows":["arXiv","5e - 4","50k","BASE in Figure 3 , 4 , 5 ,","1","-"],"associatedColumns":["The hyperparameters of","Max input","Corpus","tokens","Max input","Beam alpha","tokens"],"associatedMergedColumns":["64"]},{"number":"0.1","isBolded":false,"associatedRows":["Multi - News","5e - 5"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Num of steps","smoothing","Label","Num of steps","smoothing","Label","Num of steps","smoothing","1","Label","Num of steps","smoothing"],"associatedMergedColumns":["64"]},{"number":"0.8","isBolded":false,"associatedRows":["XSum ( C4 )","1e - 4","130k","BASE in Figure 3 , 4 , 5 ,","8"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Max input","Corpus","tokens","Max input","Beam alpha","tokens","Max input","Beam alpha","tokens","-","Max input","Beam alpha","tokens"],"associatedMergedColumns":["LARGE in Table 1 and 2"]},{"number":"0.1","isBolded":false,"associatedRows":["PEGASUSBASE"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Learning","Model","rate"],"associatedMergedColumns":["Pre - training ( default unless otherwise specified in section 6 )"]},{"number":"512","isBolded":false,"associatedRows":["Multi - News","5e - 4","50k","BASE in Figure 3 , 4 , 5 ,","1","-"],"associatedColumns":["The hyperparameters of","Max input","Corpus","tokens","Max input","Beam alpha","tokens"],"associatedMergedColumns":["64"]},{"number":"256","isBolded":false,"associatedRows":["WikiHow","5e - 4","50k"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Batch size","smoothing","Label","Batch size","smoothing"],"associatedMergedColumns":["64"]},{"number":"0.0","isBolded":false,"associatedRows":["PEGASUSLARGE","5e - 4"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Num of steps","smoothing"],"associatedMergedColumns":["Pre - training ( default unless otherwise specified in section 6 )"]},{"number":"256","isBolded":false,"associatedRows":["PubMed","5e - 4","50k","BASE in Figure 3 , 4 , 5 ,","1","-","1024"],"associatedColumns":["The hyperparameters of","Max target","Corpus","tokens","Max target","Beam alpha","tokens"],"associatedMergedColumns":["64"]},{"number":"0.6","isBolded":false,"associatedRows":["Reddit TIFU","1e - 4","12k","BASE in Figure 3 , 4 , 5 ,","8"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Max input","Corpus","tokens","Max input","Beam alpha","tokens","Max input","Beam alpha","tokens","-","Max input","Beam alpha","tokens"],"associatedMergedColumns":["64"]},{"number":"0.8","isBolded":false,"associatedRows":["BillSum","2e - 4","100k","BASE in Figure 3 , 4 , 5 ,","8"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Max input","Corpus","tokens","Max input","Beam alpha","tokens","Max input","Beam alpha","tokens","-","Max input","Beam alpha","tokens"],"associatedMergedColumns":["32"]},{"number":"0.9","isBolded":false,"associatedRows":["CNN / DailyMail ( HugeNews )","5e - 5","170k","BASE in Figure 3 , 4 , 5 ,","8"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Max input","Corpus","tokens","Max input","Beam alpha","tokens","Max input","Beam alpha","tokens","-","Max input","Beam alpha","tokens"],"associatedMergedColumns":["64"]},{"number":"0.8","isBolded":false,"associatedRows":["NEWSROOM","4e - 4","104k","BASE in Figure 3 , 4 , 5 ,","8"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Max input","Corpus","tokens","Max input","Beam alpha","tokens","Max input","Beam alpha","tokens","-","Max input","Beam alpha","tokens"],"associatedMergedColumns":["64"]},{"number":"0.1","isBolded":false,"associatedRows":["all","5e - 4"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Num of steps","smoothing","Label","Num of steps","smoothing","Label","Num of steps","smoothing","1","Label","Num of steps","smoothing","Label","Num of steps","smoothing"],"associatedMergedColumns":["LARGE in Figure 6"]},{"number":"256","isBolded":false,"associatedRows":["BillSum","5e - 4","50k"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Batch size","smoothing","Label","Batch size","smoothing"],"associatedMergedColumns":["32"]},{"number":"256","isBolded":false,"associatedRows":["arXiv","8e - 4","74k","BASE in Figure 3 , 4 , 5 ,","8","-","1024"],"associatedColumns":["The hyperparameters of","Max target","Corpus","tokens","Max target","Beam alpha","tokens","Max target","Beam alpha","tokens","Same as PEGASUSBASE","Max target","Beam alpha","tokens"],"associatedMergedColumns":["64"]},{"number":"256","isBolded":false,"associatedRows":["arXiv","5e - 4","50k"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Batch size","smoothing","Label","Batch size","smoothing"],"associatedMergedColumns":["64"]},{"number":"128","isBolded":false,"associatedRows":["CNN / DailyMail","5e - 4","50k","BASE in Figure 3 , 4 , 5 ,","1","-","1024"],"associatedColumns":["The hyperparameters of","Max target","Corpus","tokens","Max target","Beam alpha","tokens"],"associatedMergedColumns":["64"]},{"number":"256","isBolded":false,"associatedRows":["all","5e - 4","2k"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Batch size","smoothing","Label","Batch size","smoothing","Label","Batch size","smoothing","1","Label","Batch size","smoothing","Label","Batch size","smoothing"],"associatedMergedColumns":["LARGE in Figure 6"]},{"number":"0.1","isBolded":false,"associatedRows":["Others","5e - 3"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Num of steps","smoothing","Label","Num of steps","smoothing","Label","Num of steps","smoothing"],"associatedMergedColumns":["32"]},{"number":"256","isBolded":false,"associatedRows":["XSum","5e - 4","50k"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Batch size","smoothing","Label","Batch size","smoothing"],"associatedMergedColumns":["Pre - training ( default unless otherwise specified in section 6 )"]},{"number":"0.1","isBolded":false,"associatedRows":["BIGPATENT","5e - 3"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Num of steps","smoothing","Label","Num of steps","smoothing","Label","Num of steps","smoothing","1","Label","Num of steps","smoothing"],"associatedMergedColumns":["64"]},{"number":"0.1","isBolded":false,"associatedRows":["BillSum","2e - 4"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Num of steps","smoothing","Label","Num of steps","smoothing","Label","Num of steps","smoothing","1","Label","Num of steps","smoothing"],"associatedMergedColumns":["32"]},{"number":"0.1","isBolded":false,"associatedRows":["WikiHow","5e - 4"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Num of steps","smoothing","Label","Num of steps","smoothing"],"associatedMergedColumns":["64"]},{"number":"0.1","isBolded":false,"associatedRows":["arXiv","8e - 4"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Num of steps","smoothing","Label","Num of steps","smoothing","Label","Num of steps","smoothing","1","Label","Num of steps","smoothing"],"associatedMergedColumns":["64"]},{"number":"0.1","isBolded":false,"associatedRows":["XSum ( C4 )","1e - 4"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Num of steps","smoothing","Label","Num of steps","smoothing","Label","Num of steps","smoothing","1","Label","Num of steps","smoothing"],"associatedMergedColumns":["LARGE in Table 1 and 2"]},{"number":"512","isBolded":false,"associatedRows":["XSum ( HugeNews )","1e - 4","80k","BASE in Figure 3 , 4 , 5 ,","8","-"],"associatedColumns":["The hyperparameters of","Max input","Corpus","tokens","Max input","Beam alpha","tokens","Max input","Beam alpha","tokens","Same as PEGASUSBASE","Max input","Beam alpha","tokens"],"associatedMergedColumns":["64"]},{"number":"256","isBolded":false,"associatedRows":["AESLC","2e - 4","16k"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Batch size","smoothing","Label","Batch size","smoothing","Label","Batch size","smoothing","1","Label","Batch size","smoothing"],"associatedMergedColumns":["32"]},{"number":"512","isBolded":false,"associatedRows":["PEGASUSLARGE","5e - 4","500k","8192","Ind - Orig","c4 or HugeNews"],"associatedColumns":["The hyperparameters of","Max input","Corpus","tokens"],"associatedMergedColumns":["Pre - training ( default unless otherwise specified in section 6 )"]},{"number":"0.1","isBolded":false,"associatedRows":["Multi - News","5e - 4"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Num of steps","smoothing","Label","Num of steps","smoothing"],"associatedMergedColumns":["64"]},{"number":"256","isBolded":false,"associatedRows":["WikiHow","5e - 4","50k","BASE in Figure 3 , 4 , 5 ,","1","-","1024"],"associatedColumns":["The hyperparameters of","Max target","Corpus","tokens","Max target","Beam alpha","tokens"],"associatedMergedColumns":["64"]},{"number":"0.1","isBolded":false,"associatedRows":["Gigaword","8e - 4"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Num of steps","smoothing","Label","Num of steps","smoothing","Label","Num of steps","smoothing","1","Label","Num of steps","smoothing"],"associatedMergedColumns":["64"]},{"number":"256","isBolded":false,"associatedRows":["AESLC","5e - 4","50k"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Batch size","smoothing","Label","Batch size","smoothing"],"associatedMergedColumns":["32"]},{"number":"512","isBolded":false,"associatedRows":["AESLC","5e - 4","50k","BASE in Figure 3 , 4 , 5 ,","1","-"],"associatedColumns":["The hyperparameters of","Max input","Corpus","tokens","Max input","Beam alpha","tokens"],"associatedMergedColumns":["32"]},{"number":"512","isBolded":false,"associatedRows":["AESLC","5e - 4","300k","BASE in Figure 3 , 4 , 5 ,","1","-"],"associatedColumns":["The hyperparameters of","Max input","Corpus","tokens","Max input","Beam alpha","tokens","Max input","Beam alpha","tokens"],"associatedMergedColumns":["BASE in Table 1"]},{"number":"256","isBolded":false,"associatedRows":["NEWSROOM","4e - 4","104k"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Batch size","smoothing","Label","Batch size","smoothing","Label","Batch size","smoothing","1","Label","Batch size","smoothing"],"associatedMergedColumns":["64"]},{"number":"0.1","isBolded":false,"associatedRows":["XSum ( HugeNews )","1e - 4"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Num of steps","smoothing","Label","Num of steps","smoothing","Label","Num of steps","smoothing","1","Label","Num of steps","smoothing"],"associatedMergedColumns":["64"]},{"number":"128","isBolded":false,"associatedRows":["Reddit TIFU","5e - 4","50k","BASE in Figure 3 , 4 , 5 ,","1","-","1024"],"associatedColumns":["The hyperparameters of","Max target","Corpus","tokens","Max target","Beam alpha","tokens"],"associatedMergedColumns":["64"]},{"number":"512","isBolded":false,"associatedRows":["Reddit TIFU","5e - 4","50k","BASE in Figure 3 , 4 , 5 ,","1","-"],"associatedColumns":["The hyperparameters of","Max input","Corpus","tokens","Max input","Beam alpha","tokens"],"associatedMergedColumns":["64"]},{"number":"512","isBolded":false,"associatedRows":["NEWSROOM","4e - 4","104k","BASE in Figure 3 , 4 , 5 ,","8","-"],"associatedColumns":["The hyperparameters of","Max input","Corpus","tokens","Max input","Beam alpha","tokens","Max input","Beam alpha","tokens","Same as PEGASUSBASE","Max input","Beam alpha","tokens"],"associatedMergedColumns":["64"]},{"number":"256","isBolded":false,"associatedRows":["CNN / DailyMail ( C4 )","5e - 5","220k"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Batch size","smoothing","Label","Batch size","smoothing","Label","Batch size","smoothing","1","Label","Batch size","smoothing"],"associatedMergedColumns":["64"]},{"number":"512","isBolded":false,"associatedRows":["PubMed","5e - 4","50k","BASE in Figure 3 , 4 , 5 ,","1","-"],"associatedColumns":["The hyperparameters of","Max input","Corpus","tokens","Max input","Beam alpha","tokens"],"associatedMergedColumns":["64"]},{"number":"0.0","isBolded":false,"associatedRows":["PEGASUSBASE","5e - 4"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Num of steps","smoothing"],"associatedMergedColumns":["Pre - training ( default unless otherwise specified in section 6 )"]},{"number":"0.1","isBolded":false,"associatedRows":["NEWSROOM","4e - 4"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Num of steps","smoothing","Label","Num of steps","smoothing","Label","Num of steps","smoothing","1","Label","Num of steps","smoothing"],"associatedMergedColumns":["64"]},{"number":"256","isBolded":false,"associatedRows":["PEGASUSBASE","5e - 4","500k","BASE in Figure 3 , 4 , 5 ,","Ind - Orig","c4","1024"],"associatedColumns":["The hyperparameters of","Max target","Corpus","tokens"],"associatedMergedColumns":["Pre - training ( default unless otherwise specified in section 6 )"]},{"number":"256","isBolded":false,"associatedRows":["Others","5e - 3","300k"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Batch size","smoothing","Label","Batch size","smoothing","Label","Batch size","smoothing"],"associatedMergedColumns":["32"]},{"number":"256","isBolded":false,"associatedRows":["XSum ( C4 )","1e - 4","130k"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Batch size","smoothing","Label","Batch size","smoothing","Label","Batch size","smoothing","1","Label","Batch size","smoothing"],"associatedMergedColumns":["LARGE in Table 1 and 2"]},{"number":"256","isBolded":false,"associatedRows":["CNN / DailyMail ( HugeNews )","5e - 5","170k"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Batch size","smoothing","Label","Batch size","smoothing","Label","Batch size","smoothing","1","Label","Batch size","smoothing"],"associatedMergedColumns":["64"]},{"number":"0.1","isBolded":false,"associatedRows":["NEWSROOM","5e - 4"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Num of steps","smoothing","Label","Num of steps","smoothing"],"associatedMergedColumns":["64"]},{"number":"256","isBolded":false,"associatedRows":["XSum ( HugeNews )","1e - 4","80k"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Batch size","smoothing","Label","Batch size","smoothing","Label","Batch size","smoothing","1","Label","Batch size","smoothing"],"associatedMergedColumns":["64"]},{"number":"256","isBolded":false,"associatedRows":["Gigaword","8e - 4","90k"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Batch size","smoothing","Label","Batch size","smoothing","Label","Batch size","smoothing","1","Label","Batch size","smoothing"],"associatedMergedColumns":["64"]},{"number":"0.1","isBolded":false,"associatedRows":["arXiv","5e - 4"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Num of steps","smoothing","Label","Num of steps","smoothing"],"associatedMergedColumns":["64"]},{"number":"256","isBolded":false,"associatedRows":["NEWSROOM","5e - 4","50k"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Batch size","smoothing","Label","Batch size","smoothing"],"associatedMergedColumns":["64"]},{"number":"0.1","isBolded":false,"associatedRows":["AESLC","5e - 4"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Num of steps","smoothing","Label","Num of steps","smoothing","Label","Num of steps","smoothing"],"associatedMergedColumns":["BASE in Table 1"]},{"number":"256","isBolded":false,"associatedRows":["Reddit TIFU","1e - 4","12k"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Batch size","smoothing","Label","Batch size","smoothing","Label","Batch size","smoothing","1","Label","Batch size","smoothing"],"associatedMergedColumns":["64"]},{"number":"0.1","isBolded":false,"associatedRows":["AESLC","5e - 4"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Num of steps","smoothing","Label","Num of steps","smoothing"],"associatedMergedColumns":["32"]},{"number":"128","isBolded":false,"associatedRows":["Gigaword","5e - 4","50k","BASE in Figure 3 , 4 , 5 ,","1","-"],"associatedColumns":["The hyperparameters of","Max input","Corpus","tokens","Max input","Beam alpha","tokens"],"associatedMergedColumns":["64"]},{"number":"512","isBolded":false,"associatedRows":["CNN / DailyMail","5e - 4","50k","BASE in Figure 3 , 4 , 5 ,","1","-"],"associatedColumns":["The hyperparameters of","Max input","Corpus","tokens","Max input","Beam alpha","tokens"],"associatedMergedColumns":["64"]},{"number":"512","isBolded":false,"associatedRows":["XSum","5e - 4","50k","BASE in Figure 3 , 4 , 5 ,","1","-"],"associatedColumns":["The hyperparameters of","Max input","Corpus","tokens","Max input","Beam alpha","tokens"],"associatedMergedColumns":["Pre - training ( default unless otherwise specified in section 6 )"]},{"number":"256","isBolded":false,"associatedRows":["arXiv","8e - 4","74k"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Batch size","smoothing","Label","Batch size","smoothing","Label","Batch size","smoothing","1","Label","Batch size","smoothing"],"associatedMergedColumns":["64"]},{"number":"0.1","isBolded":false,"associatedRows":["BillSum","5e - 4"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Num of steps","smoothing","Label","Num of steps","smoothing"],"associatedMergedColumns":["32"]},{"number":"0.8","isBolded":false,"associatedRows":["arXiv","8e - 4","74k","BASE in Figure 3 , 4 , 5 ,","8"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Max input","Corpus","tokens","Max input","Beam alpha","tokens","Max input","Beam alpha","tokens","-","Max input","Beam alpha","tokens"],"associatedMergedColumns":["64"]},{"number":"0.1","isBolded":false,"associatedRows":["PubMed","2e - 4"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Label","Num of steps","smoothing","Label","Num of steps","smoothing","Label","Num of steps","smoothing","1","Label","Num of steps","smoothing"],"associatedMergedColumns":["64"]},{"number":"512","isBolded":false,"associatedRows":["BIGPATENT","5e - 4","300k","BASE in Figure 3 , 4 , 5 ,","1","-"],"associatedColumns":["The hyperparameters of","Max input","Corpus","tokens","Max input","Beam alpha","tokens","Max input","Beam alpha","tokens"],"associatedMergedColumns":["BASE in Table 1"]},{"number":"0.8","isBolded":false,"associatedRows":["XSum ( HugeNews )","1e - 4","80k","BASE in Figure 3 , 4 , 5 ,","8"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Max input","Corpus","tokens","Max input","Beam alpha","tokens","Max input","Beam alpha","tokens","-","Max input","Beam alpha","tokens"],"associatedMergedColumns":["64"]},{"number":"0.01","isBolded":false,"associatedRows":["BIGPATENT"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Learning","Model","rate","Learning","Dataset","rate"],"associatedMergedColumns":["64"]},{"number":"0.8","isBolded":false,"associatedRows":["PubMed","2e - 4","100k","BASE in Figure 3 , 4 , 5 ,","8"],"associatedColumns":["Hyperparamters of the pre - training and fine - tuning stages reported in section 6 .","Max input","Corpus","tokens","Max input","Beam alpha","tokens","Max input","Beam alpha","tokens","-","Max input","Beam alpha","tokens"],"associatedMergedColumns":["64"]}]},{"caption":"Table E.1: The ROUGE1-F1, ROUGE2-F1 and ROUGEL-F1 scores of low resource summarization reported in Figure 6 \nalong with previous SOTA in Table 1. With 100 examples, PEGASUS LARGE beats previous SOTA on ROUGE2-F1 metrics \non BIGPATENT, Reddit TIFU, and BillSum dataset. With 1000 examples, PEGASUS LARGE beats previous SOTA metrics \non Multi-News, WikiHow, Reddit TIFU, BigPatent, AESLC and BillSum. \n\n","rows":["Dataset","0 examples","10 examples"],"columns":["on Multi - News , WikiHow , Reddit TIFU , BigPatent , AESLC and BillSum ."],"mergedAllColumns":[],"numberCells":[{"number":"100examples","isBolded":false,"associatedRows":["Dataset","0 examples","10 examples"],"associatedColumns":["on Multi - News , WikiHow , Reddit TIFU , BigPatent , AESLC and BillSum ."],"associatedMergedColumns":[]}]}]