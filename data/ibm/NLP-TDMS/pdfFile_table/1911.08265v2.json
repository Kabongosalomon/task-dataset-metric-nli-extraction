[{"caption":"Agent \n\nMedian \nMean \nEnv. Frames Training Time Training Steps \n\nApe-X [18] \n434.1% \n1695.6% \n22.8B \n5 days \n8.64M \nR2D2 [21] \n1920.6% \n4024.9% \n37.5B \n5 days \n2.16M \nMuZero \n2041.1% 4999.2% \n20.0B \n12 hours \n1M \n\nIMPALA [9] \n191.8% \n957.6% \n200M \n-\n-\nRainbow [17] \n231.1% \n-\n200M \n10 days \n-\nUNREAL a [19] \n250% a \n880% a \n250M \n-\n-\nLASER [36] \n431% \n-\n200M \n-\n-\nMuZero Reanalyze \n731.1% \n2168.9% \n200M \n12 hours \n1M \n\nTable 1: Comparison of MuZero against previous agents in Atari. We compare separately against agents \ntrained in large (top) and small (bottom) data settings; all agents other than MuZero used model-free RL techniques. \nMean and median scores are given, compared to human testers. The best results are highlighted in bold. MuZero \nsets a new state of the art in both settings. a Hyper-parameters were tuned per game. \n\n","rows":["5 days","MuZero","Rainbow [ 17 ]","Ape - X [ 18 ]","IMPALA [ 9 ]","MuZero Reanalyze","R2D2 [ 21 ]"],"columns":["Mean","a","Training Steps","Env . Frames","Median","12 hours","431%","200M","880% a","-","250%"],"mergedAllColumns":[],"numberCells":[{"number":"4999.2%","isBolded":true,"associatedRows":["MuZero"],"associatedColumns":["Mean"],"associatedMergedColumns":[]},{"number":"191.8%","isBolded":false,"associatedRows":["IMPALA [ 9 ]"],"associatedColumns":["Median","12 hours"],"associatedMergedColumns":[]},{"number":"2168.9%","isBolded":true,"associatedRows":["MuZero Reanalyze"],"associatedColumns":["Mean","12 hours","200M","-","880% a","-"],"associatedMergedColumns":[]},{"number":"1695.6%","isBolded":false,"associatedRows":["Ape - X [ 18 ]"],"associatedColumns":["Mean"],"associatedMergedColumns":[]},{"number":"731.1%","isBolded":true,"associatedRows":["MuZero Reanalyze"],"associatedColumns":["Median","12 hours","200M","-","a","250%","431%"],"associatedMergedColumns":[]},{"number":"4024.9%","isBolded":false,"associatedRows":["R2D2 [ 21 ]"],"associatedColumns":["Mean"],"associatedMergedColumns":[]},{"number":"1920.6%","isBolded":false,"associatedRows":["R2D2 [ 21 ]"],"associatedColumns":["Median"],"associatedMergedColumns":[]},{"number":"2.16M","isBolded":false,"associatedRows":["R2D2 [ 21 ]","5 days"],"associatedColumns":["Training Steps"],"associatedMergedColumns":[]},{"number":"20.0B","isBolded":false,"associatedRows":["MuZero"],"associatedColumns":["Env . Frames"],"associatedMergedColumns":[]},{"number":"22.8B","isBolded":false,"associatedRows":["Ape - X [ 18 ]"],"associatedColumns":["Env . Frames"],"associatedMergedColumns":[]},{"number":"37.5B","isBolded":false,"associatedRows":["R2D2 [ 21 ]"],"associatedColumns":["Env . Frames"],"associatedMergedColumns":[]},{"number":"434.1%","isBolded":false,"associatedRows":["Ape - X [ 18 ]"],"associatedColumns":["Median"],"associatedMergedColumns":[]},{"number":"231.1%","isBolded":false,"associatedRows":["Rainbow [ 17 ]"],"associatedColumns":["Median","12 hours","200M"],"associatedMergedColumns":[]},{"number":"2041.1%","isBolded":true,"associatedRows":["MuZero"],"associatedColumns":["Median"],"associatedMergedColumns":[]},{"number":"8.64M","isBolded":false,"associatedRows":["Ape - X [ 18 ]","5 days"],"associatedColumns":["Training Steps"],"associatedMergedColumns":[]},{"number":"957.6%","isBolded":false,"associatedRows":["IMPALA [ 9 ]"],"associatedColumns":["Mean","12 hours"],"associatedMergedColumns":[]}]}]