[{"caption":"Table 1. Single model perplexity on validation and test sets for the Penn Treebank language modeling task. Parameter numbers with  ‡ \nare estimates based upon our understanding of the model and with reference to ","rows":["Grave et al . ( 2016 ) - LSTM + continuous cache pointer","6M ‡","AWD - LSTM - 3 - layer LSTM ( tied ) + continuous cache pointer","Inan et al . ( 2016 ) - Variational LSTM ( tied ) + augmented loss","2M ‡","24M","66M","Merity et al . ( 2016 ) - Pointer Sentinel - LSTM","54M","20M","Mikolov \u0026 Zweig ( 2012 ) - KN - 5","−","Zilly et al . ( 2016 ) - Variational RHN ( tied )","Zaremba et al . ( 2014 ) - LSTM ( large )","Gal \u0026 Ghahramani ( 2016 ) - Variational LSTM ( large , MC )","Mikolov \u0026 Zweig ( 2012 ) - RNN","Zoph \u0026 Le ( 2016 ) - NAS Cell ( tied )","Grave et al . ( 2016 ) - LSTM","Zaremba et al . ( 2014 ) - LSTM ( medium )","19M","Mikolov \u0026 Zweig ( 2012 ) - RNN - LDA","Mikolov \u0026 Zweig ( 2012 ) - RNN - LDA + KN - 5 + cache","Gal \u0026 Ghahramani ( 2016 ) - Variational LSTM ( medium , MC )","25M","23M","7M ‡","Mikolov \u0026 Zweig ( 2012 ) - KN5 + cache","9M ‡","21M","Gal \u0026 Ghahramani ( 2016 ) - Variational LSTM ( large )","Melis et al . ( 2017 ) - 4 - layer skip connection LSTM ( tied )","51M","AWD - LSTM - 3 - layer LSTM ( tied )","Gal \u0026 Ghahramani ( 2016 ) - Variational LSTM ( medium )","Kim et al . ( 2016 ) - CharCNN"],"columns":["Validation","Test"],"mergedAllColumns":[],"numberCells":[{"number":"82.3","isBolded":false,"associatedRows":["Grave et al . ( 2016 ) - LSTM","−","−"],"associatedColumns":["Test"],"associatedMergedColumns":[]},{"number":"78.6±","isBolded":false,"associatedRows":["Gal \u0026 Ghahramani ( 2016 ) - Variational LSTM ( medium , MC )","20M","−"],"associatedColumns":["Test"],"associatedMergedColumns":[]},{"number":"60.9","isBolded":false,"associatedRows":["Melis et al . ( 2017 ) - 4 - layer skip connection LSTM ( tied )","24M"],"associatedColumns":["Validation"],"associatedMergedColumns":[]},{"number":"72.1","isBolded":false,"associatedRows":["Grave et al . ( 2016 ) - LSTM + continuous cache pointer","−","−"],"associatedColumns":["Test"],"associatedMergedColumns":[]},{"number":"72.4","isBolded":false,"associatedRows":["Merity et al . ( 2016 ) - Pointer Sentinel - LSTM","21M"],"associatedColumns":["Validation"],"associatedMergedColumns":[]},{"number":"65.4","isBolded":false,"associatedRows":["Zilly et al . ( 2016 ) - Variational RHN ( tied )","23M","−"],"associatedColumns":["Test"],"associatedMergedColumns":[]},{"number":"52.8","isBolded":false,"associatedRows":["AWD - LSTM - 3 - layer LSTM ( tied ) + continuous cache pointer","24M","−"],"associatedColumns":["Test"],"associatedMergedColumns":[]},{"number":"125.7","isBolded":false,"associatedRows":["Mikolov \u0026 Zweig ( 2012 ) - KN5 + cache","2M ‡","−"],"associatedColumns":["Test"],"associatedMergedColumns":[]},{"number":"60.0","isBolded":false,"associatedRows":["AWD - LSTM - 3 - layer LSTM ( tied )","24M"],"associatedColumns":["Validation"],"associatedMergedColumns":[]},{"number":"124.7","isBolded":false,"associatedRows":["Mikolov \u0026 Zweig ( 2012 ) - RNN","6M ‡","−"],"associatedColumns":["Test"],"associatedMergedColumns":[]},{"number":"86.2","isBolded":false,"associatedRows":["Zaremba et al . ( 2014 ) - LSTM ( medium )","20M"],"associatedColumns":["Validation"],"associatedMergedColumns":[]},{"number":"75.2±","isBolded":false,"associatedRows":["Gal \u0026 Ghahramani ( 2016 ) - Variational LSTM ( large )","66M","−"],"associatedColumns":["Test"],"associatedMergedColumns":[]},{"number":"68.5","isBolded":false,"associatedRows":["Inan et al . ( 2016 ) - Variational LSTM ( tied ) + augmented loss","51M","−"],"associatedColumns":["Test"],"associatedMergedColumns":[]},{"number":"67.9","isBolded":false,"associatedRows":["Zilly et al . ( 2016 ) - Variational RHN ( tied )","23M"],"associatedColumns":["Validation"],"associatedMergedColumns":[]},{"number":"0.3","isBolded":false,"associatedRows":["Gal \u0026 Ghahramani ( 2016 ) - Variational LSTM ( large )","66M","−"],"associatedColumns":["Validation"],"associatedMergedColumns":[]},{"number":"73.2","isBolded":false,"associatedRows":["Inan et al . ( 2016 ) - Variational LSTM ( tied ) + augmented loss","24M","−"],"associatedColumns":["Test"],"associatedMergedColumns":[]},{"number":"64.0","isBolded":false,"associatedRows":["Zoph \u0026 Le ( 2016 ) - NAS Cell ( tied )","25M","−"],"associatedColumns":["Test"],"associatedMergedColumns":[]},{"number":"141.2","isBolded":false,"associatedRows":["Mikolov \u0026 Zweig ( 2012 ) - KN - 5","2M ‡","−"],"associatedColumns":["Test"],"associatedMergedColumns":[]},{"number":"78.4","isBolded":false,"associatedRows":["Zaremba et al . ( 2014 ) - LSTM ( large )","66M","−"],"associatedColumns":["Test"],"associatedMergedColumns":[]},{"number":"57.3","isBolded":false,"associatedRows":["AWD - LSTM - 3 - layer LSTM ( tied )","24M","−"],"associatedColumns":["Test"],"associatedMergedColumns":[]},{"number":"75.7","isBolded":false,"associatedRows":["Inan et al . ( 2016 ) - Variational LSTM ( tied ) + augmented loss","24M"],"associatedColumns":["Validation"],"associatedMergedColumns":[]},{"number":"70.9","isBolded":false,"associatedRows":["Merity et al . ( 2016 ) - Pointer Sentinel - LSTM","21M","−"],"associatedColumns":["Test"],"associatedMergedColumns":[]},{"number":"71.1","isBolded":false,"associatedRows":["Inan et al . ( 2016 ) - Variational LSTM ( tied ) + augmented loss","51M"],"associatedColumns":["Validation"],"associatedMergedColumns":[]},{"number":"77.9±","isBolded":false,"associatedRows":["Gal \u0026 Ghahramani ( 2016 ) - Variational LSTM ( large )","66M"],"associatedColumns":["Validation"],"associatedMergedColumns":[]},{"number":"0.2","isBolded":false,"associatedRows":["Gal \u0026 Ghahramani ( 2016 ) - Variational LSTM ( large )","66M","−"],"associatedColumns":["Test"],"associatedMergedColumns":[]},{"number":"73.4±","isBolded":false,"associatedRows":["Gal \u0026 Ghahramani ( 2016 ) - Variational LSTM ( large , MC )","66M","−"],"associatedColumns":["Test"],"associatedMergedColumns":[]},{"number":"0.1","isBolded":false,"associatedRows":["Gal \u0026 Ghahramani ( 2016 ) - Variational LSTM ( medium , MC )","20M","−"],"associatedColumns":["Test"],"associatedMergedColumns":[]},{"number":"79.7±","isBolded":false,"associatedRows":["Gal \u0026 Ghahramani ( 2016 ) - Variational LSTM ( medium )","20M","−"],"associatedColumns":["Test"],"associatedMergedColumns":[]},{"number":"62.4","isBolded":false,"associatedRows":["Zoph \u0026 Le ( 2016 ) - NAS Cell ( tied )","54M","−"],"associatedColumns":["Test"],"associatedMergedColumns":[]},{"number":"58.3","isBolded":false,"associatedRows":["Melis et al . ( 2017 ) - 4 - layer skip connection LSTM ( tied )","24M","−"],"associatedColumns":["Test"],"associatedMergedColumns":[]},{"number":"0.1","isBolded":false,"associatedRows":["Gal \u0026 Ghahramani ( 2016 ) - Variational LSTM ( medium )","20M","−"],"associatedColumns":["Test"],"associatedMergedColumns":[]},{"number":"82.7","isBolded":false,"associatedRows":["Zaremba et al . ( 2014 ) - LSTM ( medium )","20M","−"],"associatedColumns":["Test"],"associatedMergedColumns":[]},{"number":"53.9","isBolded":false,"associatedRows":["AWD - LSTM - 3 - layer LSTM ( tied ) + continuous cache pointer","24M"],"associatedColumns":["Validation"],"associatedMergedColumns":[]},{"number":"0.0","isBolded":false,"associatedRows":["Gal \u0026 Ghahramani ( 2016 ) - Variational LSTM ( large , MC )","66M","−"],"associatedColumns":["Test"],"associatedMergedColumns":[]},{"number":"113.7","isBolded":false,"associatedRows":["Mikolov \u0026 Zweig ( 2012 ) - RNN - LDA","7M ‡","−"],"associatedColumns":["Test"],"associatedMergedColumns":[]},{"number":"81.9±","isBolded":false,"associatedRows":["Gal \u0026 Ghahramani ( 2016 ) - Variational LSTM ( medium )","20M"],"associatedColumns":["Validation"],"associatedMergedColumns":[]},{"number":"78.9","isBolded":false,"associatedRows":["Kim et al . ( 2016 ) - CharCNN","19M","−"],"associatedColumns":["Test"],"associatedMergedColumns":[]},{"number":"92.0","isBolded":false,"associatedRows":["Mikolov \u0026 Zweig ( 2012 ) - RNN - LDA + KN - 5 + cache","9M ‡","−"],"associatedColumns":["Test"],"associatedMergedColumns":[]},{"number":"82.2","isBolded":false,"associatedRows":["Zaremba et al . ( 2014 ) - LSTM ( large )","66M"],"associatedColumns":["Validation"],"associatedMergedColumns":[]},{"number":"0.2","isBolded":false,"associatedRows":["Gal \u0026 Ghahramani ( 2016 ) - Variational LSTM ( medium )","20M","−"],"associatedColumns":["Validation"],"associatedMergedColumns":[]}]},{"caption":"Table 2. Single model perplexity over WikiText-2. Models noting tied use weight tying on the embedding and softmax weights. Our \nmodel, AWD-LSTM, stands for ASGD Weight-Dropped LSTM. ","rows":["Grave et al . ( 2016 ) - LSTM","Grave et al . ( 2016 ) - LSTM + continuous cache pointer","Melis et al . ( 2017 ) - 2 - layer skip connection LSTM ( tied )","−","Inan et al . ( 2016 ) - Variational LSTM ( tied ) ( h \u003d 650 )","Inan et al . ( 2016 ) - Variational LSTM ( tied ) ( h \u003d 650 ) + augmented loss","AWD - LSTM - 3 - layer LSTM ( tied ) + continuous cache pointer","28M","Melis et al . ( 2017 ) - 1 - layer LSTM ( tied )","AWD - LSTM - 3 - layer LSTM ( tied )","24M","33M"],"columns":["Validation","Test"],"mergedAllColumns":[],"numberCells":[{"number":"68.9","isBolded":false,"associatedRows":["Grave et al . ( 2016 ) - LSTM + continuous cache pointer","−","−"],"associatedColumns":["Test"],"associatedMergedColumns":[]},{"number":"53.8","isBolded":false,"associatedRows":["AWD - LSTM - 3 - layer LSTM ( tied ) + continuous cache pointer","33M"],"associatedColumns":["Validation"],"associatedMergedColumns":[]},{"number":"65.9","isBolded":false,"associatedRows":["Melis et al . ( 2017 ) - 1 - layer LSTM ( tied )","24M","−"],"associatedColumns":["Test"],"associatedMergedColumns":[]},{"number":"65.9","isBolded":false,"associatedRows":["Melis et al . ( 2017 ) - 2 - layer skip connection LSTM ( tied )","24M","−"],"associatedColumns":["Test"],"associatedMergedColumns":[]},{"number":"65.8","isBolded":false,"associatedRows":["AWD - LSTM - 3 - layer LSTM ( tied )","33M","−"],"associatedColumns":["Test"],"associatedMergedColumns":[]},{"number":"99.3","isBolded":false,"associatedRows":["Grave et al . ( 2016 ) - LSTM","−","−"],"associatedColumns":["Test"],"associatedMergedColumns":[]},{"number":"92.3","isBolded":false,"associatedRows":["Inan et al . ( 2016 ) - Variational LSTM ( tied ) ( h \u003d 650 )","28M"],"associatedColumns":["Validation"],"associatedMergedColumns":[]},{"number":"69.3","isBolded":false,"associatedRows":["Melis et al . ( 2017 ) - 1 - layer LSTM ( tied )","24M"],"associatedColumns":["Validation"],"associatedMergedColumns":[]},{"number":"69.1","isBolded":false,"associatedRows":["Melis et al . ( 2017 ) - 2 - layer skip connection LSTM ( tied )","24M"],"associatedColumns":["Validation"],"associatedMergedColumns":[]},{"number":"87.0","isBolded":false,"associatedRows":["Inan et al . ( 2016 ) - Variational LSTM ( tied ) ( h \u003d 650 ) + augmented loss","28M","−"],"associatedColumns":["Test"],"associatedMergedColumns":[]},{"number":"91.5","isBolded":false,"associatedRows":["Inan et al . ( 2016 ) - Variational LSTM ( tied ) ( h \u003d 650 ) + augmented loss","28M"],"associatedColumns":["Validation"],"associatedMergedColumns":[]},{"number":"52.0","isBolded":false,"associatedRows":["AWD - LSTM - 3 - layer LSTM ( tied ) + continuous cache pointer","33M","−"],"associatedColumns":["Test"],"associatedMergedColumns":[]},{"number":"68.6","isBolded":false,"associatedRows":["AWD - LSTM - 3 - layer LSTM ( tied )","33M"],"associatedColumns":["Validation"],"associatedMergedColumns":[]},{"number":"87.7","isBolded":false,"associatedRows":["Inan et al . ( 2016 ) - Variational LSTM ( tied ) ( h \u003d 650 )","28M","−"],"associatedColumns":["Test"],"associatedMergedColumns":[]}]},{"caption":"Table 3. We compute the sum of the total dif-\nference in the loss function value (i.e., log perplexity) be-\ntween the LSTM-only and LSTM-with-cache models for \nthe target words in the validation portion of the WikiText-2 \ndata set. We present results for the sum of the difference as \nopposed to the mean since the latter undesirably overem-\nphasizes infrequently occurring words for which the cache \nhelps significantly and ignores frequently occurring words \nfor which the cache provides modest improvements that cu-\nmulatively make a strong contribution. \n\n","rows":["4178","Starr","Blythe","5816","1338","that","1215","234","11540","4048","92","Cooke","879","9857","97","54","3690","\"","in","12481",")",",","161","-","Japanese","Hu",".","mill","Hedgehog","Mississippi","as","at","2279","1101","Pagan","\u003d","Richmond","67","29","for","Sonic","Churchill","German","\u003cunk\u003e","3381","137","2884","and","of","by","Asahi","72","74","75","on","33","5251","a","35","39","7632","2540","was","1176","1252","181","Burma","\u003ceos\u003e","Meridian","the","with","101","Australian","1365","1485","108","to","43"],"columns":["∆loss"],"mergedAllColumns":[],"numberCells":[{"number":"-107.95","isBolded":false,"associatedRows":["was","2279"],"associatedColumns":["∆loss"],"associatedMergedColumns":[]},{"number":"285.58","isBolded":false,"associatedRows":["by","1252","Hu","43"],"associatedColumns":["∆loss"],"associatedMergedColumns":[]},{"number":"-342.01","isBolded":false,"associatedRows":["\u003d","2884"],"associatedColumns":["∆loss"],"associatedMergedColumns":[]},{"number":"-216.42","isBolded":false,"associatedRows":["\u003ceos\u003e","3690"],"associatedColumns":["∆loss"],"associatedMergedColumns":[]},{"number":"554.95","isBolded":false,"associatedRows":["to","4048","Blythe","97"],"associatedColumns":["∆loss"],"associatedMergedColumns":[]},{"number":"241.59","isBolded":false,"associatedRows":["for","1215","Mississippi","72"],"associatedColumns":["∆loss"],"associatedMergedColumns":[]},{"number":"231.11","isBolded":false,"associatedRows":["at","879","Cooke","33"],"associatedColumns":["∆loss"],"associatedMergedColumns":[]},{"number":"241.23","isBolded":false,"associatedRows":["on","1485","German","108"],"associatedColumns":["∆loss"],"associatedMergedColumns":[]},{"number":"-87.68","isBolded":false,"associatedRows":["for","1215"],"associatedColumns":["∆loss"],"associatedMergedColumns":[]},{"number":"682.15","isBolded":false,"associatedRows":["\u003d","2884","-","67"],"associatedColumns":["∆loss"],"associatedMergedColumns":[]},{"number":"-696.45","isBolded":false,"associatedRows":[".","7632"],"associatedColumns":["∆loss"],"associatedMergedColumns":[]},{"number":"-81.55","isBolded":false,"associatedRows":["on","1485"],"associatedColumns":["∆loss"],"associatedMergedColumns":[]},{"number":"-209.97","isBolded":false,"associatedRows":["the","12481"],"associatedColumns":["∆loss"],"associatedMergedColumns":[]},{"number":"266.48","isBolded":false,"associatedRows":["was","2279","Hedgehog","29"],"associatedColumns":["∆loss"],"associatedMergedColumns":[]},{"number":"263.65","isBolded":false,"associatedRows":[")","1101","Burma","35"],"associatedColumns":["∆loss"],"associatedMergedColumns":[]},{"number":"-93.01","isBolded":false,"associatedRows":["with","1176"],"associatedColumns":["∆loss"],"associatedMergedColumns":[]},{"number":"366.36","isBolded":false,"associatedRows":["the","12481","Australian","234"],"associatedColumns":["∆loss"],"associatedMergedColumns":[]},{"number":"-149.78","isBolded":false,"associatedRows":["a","3381"],"associatedColumns":["∆loss"],"associatedMergedColumns":[]},{"number":"316.24","isBolded":false,"associatedRows":["\"","2540","Asahi","39"],"associatedColumns":["∆loss"],"associatedMergedColumns":[]},{"number":"-687.49","isBolded":false,"associatedRows":[",","9857"],"associatedColumns":["∆loss"],"associatedMergedColumns":[]},{"number":"-59.86","isBolded":false,"associatedRows":["at","879"],"associatedColumns":["∆loss"],"associatedMergedColumns":[]},{"number":"-118.09","isBolded":false,"associatedRows":["that","1365"],"associatedColumns":["∆loss"],"associatedMergedColumns":[]},{"number":"-113.05","isBolded":false,"associatedRows":["by","1252"],"associatedColumns":["∆loss"],"associatedMergedColumns":[]},{"number":"849.43","isBolded":false,"associatedRows":["of","5816","Churchill","137"],"associatedColumns":["∆loss"],"associatedMergedColumns":[]},{"number":"543.85","isBolded":false,"associatedRows":["in","4178","Sonic","75"],"associatedColumns":["∆loss"],"associatedMergedColumns":[]},{"number":"416.52","isBolded":false,"associatedRows":["and","5251","Starr","74"],"associatedColumns":["∆loss"],"associatedMergedColumns":[]},{"number":"-365.21","isBolded":false,"associatedRows":["of","5816"],"associatedColumns":["∆loss"],"associatedMergedColumns":[]},{"number":"-215.38","isBolded":false,"associatedRows":["and","5251"],"associatedColumns":["∆loss"],"associatedMergedColumns":[]},{"number":"295.97","isBolded":false,"associatedRows":["that","1365","Japanese","181"],"associatedColumns":["∆loss"],"associatedMergedColumns":[]},{"number":"-283.10","isBolded":false,"associatedRows":["to","4048"],"associatedColumns":["∆loss"],"associatedMergedColumns":[]},{"number":"-127.99","isBolded":false,"associatedRows":["\"","2540"],"associatedColumns":["∆loss"],"associatedMergedColumns":[]},{"number":"5047.34","isBolded":false,"associatedRows":[".","7632","\u003cunk\u003e","11540"],"associatedColumns":["∆loss"],"associatedMergedColumns":[]},{"number":"237.76","isBolded":false,"associatedRows":["as","1338","mill","67"],"associatedColumns":["∆loss"],"associatedMergedColumns":[]},{"number":"1057.78","isBolded":false,"associatedRows":[",","9857","Meridian","161"],"associatedColumns":["∆loss"],"associatedMergedColumns":[]},{"number":"429.18","isBolded":false,"associatedRows":["\u003ceos\u003e","3690","Richmond","101"],"associatedColumns":["∆loss"],"associatedMergedColumns":[]},{"number":"-222.94","isBolded":false,"associatedRows":["in","4178"],"associatedColumns":["∆loss"],"associatedMergedColumns":[]},{"number":"-94.74","isBolded":false,"associatedRows":[")","1101"],"associatedColumns":["∆loss"],"associatedMergedColumns":[]},{"number":"-77.05","isBolded":false,"associatedRows":["as","1338"],"associatedColumns":["∆loss"],"associatedMergedColumns":[]},{"number":"365.19","isBolded":false,"associatedRows":["a","3381","Pagan","54"],"associatedColumns":["∆loss"],"associatedMergedColumns":[]},{"number":"260.88","isBolded":false,"associatedRows":["with","1176","29","92"],"associatedColumns":["∆loss"],"associatedMergedColumns":[]}]},{"caption":"Table 4. Model ablations for our best LSTM models reporting results over the validation and test set on Penn Treebank and WikiText-2. \nAblations are split into optimization and regularization variants, sorted according to the achieved validation perplexity on WikiText-2. \n\n","rows":["- fine - tuning","- weight - dropping","- variable sequence lengths","- embedding dropout","- full sized embedding","- NT - ASGD","AWD - LSTM ( tied )","- weight decay","- AR / TAR"],"columns":["Validation","WT2","Test","PTB"],"mergedAllColumns":[],"numberCells":[{"number":"60.3","isBolded":false,"associatedRows":["- AR / TAR"],"associatedColumns":["PTB","Test"],"associatedMergedColumns":[]},{"number":"63.7","isBolded":false,"associatedRows":["- NT - ASGD"],"associatedColumns":["PTB","Test"],"associatedMergedColumns":[]},{"number":"63.7","isBolded":false,"associatedRows":["- weight decay"],"associatedColumns":["PTB","Validation"],"associatedMergedColumns":[]},{"number":"70.7","isBolded":false,"associatedRows":["- full sized embedding"],"associatedColumns":["WT2","Test"],"associatedMergedColumns":[]},{"number":"71.1","isBolded":false,"associatedRows":["- weight - dropping"],"associatedColumns":["PTB","Validation"],"associatedMergedColumns":[]},{"number":"58.8","isBolded":true,"associatedRows":["- fine - tuning"],"associatedColumns":["PTB","Test"],"associatedMergedColumns":[]},{"number":"69.3","isBolded":false,"associatedRows":["- variable sequence lengths"],"associatedColumns":["WT2","Validation"],"associatedMergedColumns":[]},{"number":"57.3","isBolded":true,"associatedRows":["AWD - LSTM ( tied )"],"associatedColumns":["PTB","Test"],"associatedMergedColumns":[]},{"number":"68.1","isBolded":false,"associatedRows":["- embedding dropout"],"associatedColumns":["WT2","Test"],"associatedMergedColumns":[]},{"number":"70.1","isBolded":false,"associatedRows":["- AR / TAR"],"associatedColumns":["WT2","Test"],"associatedMergedColumns":[]},{"number":"61.0","isBolded":false,"associatedRows":["- weight decay"],"associatedColumns":["PTB","Test"],"associatedMergedColumns":[]},{"number":"74.9","isBolded":false,"associatedRows":["- weight - dropping"],"associatedColumns":["WT2","Test"],"associatedMergedColumns":[]},{"number":"60.0","isBolded":true,"associatedRows":["AWD - LSTM ( tied )"],"associatedColumns":["PTB","Validation"],"associatedMergedColumns":[]},{"number":"69.7","isBolded":false,"associatedRows":["- NT - ASGD"],"associatedColumns":["WT2","Test"],"associatedMergedColumns":[]},{"number":"68.6","isBolded":false,"associatedRows":["AWD - LSTM ( tied )"],"associatedColumns":["WT2","Validation"],"associatedMergedColumns":[]},{"number":"65.1","isBolded":false,"associatedRows":["- embedding dropout"],"associatedColumns":["PTB","Validation"],"associatedMergedColumns":[]},{"number":"62.7","isBolded":false,"associatedRows":["- AR / TAR"],"associatedColumns":["PTB","Validation"],"associatedMergedColumns":[]},{"number":"73.2","isBolded":false,"associatedRows":["- AR / TAR"],"associatedColumns":["WT2","Validation"],"associatedMergedColumns":[]},{"number":"71.9","isBolded":false,"associatedRows":["- weight decay"],"associatedColumns":["WT2","Validation"],"associatedMergedColumns":[]},{"number":"60.7","isBolded":true,"associatedRows":["- fine - tuning"],"associatedColumns":["PTB","Validation"],"associatedMergedColumns":[]},{"number":"68.0","isBolded":false,"associatedRows":["- full sized embedding"],"associatedColumns":["PTB","Validation"],"associatedMergedColumns":[]},{"number":"65.6","isBolded":false,"associatedRows":["- full sized embedding"],"associatedColumns":["PTB","Test"],"associatedMergedColumns":[]},{"number":"78.4","isBolded":false,"associatedRows":["- weight - dropping"],"associatedColumns":["WT2","Validation"],"associatedMergedColumns":[]},{"number":"58.9","isBolded":false,"associatedRows":["- variable sequence lengths"],"associatedColumns":["PTB","Test"],"associatedMergedColumns":[]},{"number":"71.1","isBolded":false,"associatedRows":["- embedding dropout"],"associatedColumns":["WT2","Validation"],"associatedMergedColumns":[]},{"number":"66.3","isBolded":false,"associatedRows":["- NT - ASGD"],"associatedColumns":["PTB","Validation"],"associatedMergedColumns":[]},{"number":"73.7","isBolded":false,"associatedRows":["- full sized embedding"],"associatedColumns":["WT2","Validation"],"associatedMergedColumns":[]},{"number":"68.7","isBolded":false,"associatedRows":["- weight decay"],"associatedColumns":["WT2","Test"],"associatedMergedColumns":[]},{"number":"68.9","isBolded":false,"associatedRows":["- weight - dropping"],"associatedColumns":["PTB","Test"],"associatedMergedColumns":[]},{"number":"62.7","isBolded":false,"associatedRows":["- embedding dropout"],"associatedColumns":["PTB","Test"],"associatedMergedColumns":[]},{"number":"66.0","isBolded":true,"associatedRows":["- fine - tuning"],"associatedColumns":["WT2","Test"],"associatedMergedColumns":[]},{"number":"73.3","isBolded":false,"associatedRows":["- NT - ASGD"],"associatedColumns":["WT2","Validation"],"associatedMergedColumns":[]},{"number":"61.3","isBolded":false,"associatedRows":["- variable sequence lengths"],"associatedColumns":["PTB","Validation"],"associatedMergedColumns":[]},{"number":"66.2","isBolded":false,"associatedRows":["- variable sequence lengths"],"associatedColumns":["WT2","Test"],"associatedMergedColumns":[]},{"number":"69.1","isBolded":true,"associatedRows":["- fine - tuning"],"associatedColumns":["WT2","Validation"],"associatedMergedColumns":[]},{"number":"65.8","isBolded":false,"associatedRows":["AWD - LSTM ( tied )"],"associatedColumns":["WT2","Test"],"associatedMergedColumns":[]}]}]