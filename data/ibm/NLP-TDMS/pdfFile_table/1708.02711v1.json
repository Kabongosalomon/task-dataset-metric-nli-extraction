[{"caption":"Non-linear activations: ReLU \n61.63 ±0.21 \n78.48 \n41.15 \n54.39 \n32.57 \nNon-linear activations: tanh \n61.74 ±0.44 \n79.20 \n40.92 \n54.13 \n33.10 \nNon-linear activations: gated ReLU \n62.44 ±0.07 \n79.33 \n42.12 \n55.13 \n33.52 \nHidden states of dimension 256 \n62.80 ±0.05 \n79.62 \n42.46 \n55.53 \n34.12 \nHidden states of dimension 384 \n63.12 ±0.11 \n80.06 \n42.89 \n55.74 \n34.54 \nHidden states of dimension 768 \n63.12 ±0.11 \n80.06 \n42.89 \n55.74 \n34.54 \nHidden states of dimension 1024 \n63.02 ±0.55 \n79.88 \n42.68 \n55.73 \n34.34 \nHidden states of dimension 1280 \n *  \n63.37 ±0.21 \n80.40 \n43.02 \n55.96 \n34.76 \nMini-batch size (reference: 512 training questions) \n\n128 Training questions \n62.38 ±0.08 \n79.70 \n42.29 \n54.67 \n34.01 \n256 Training questions \n *  \n63.17 ±0.09 \n80.22 \n42.94 \n55.72 \n34.71 \n384 Training questions \n *  \n63.20 ±0.04 \n80.21 \n43.08 \n55.75 \n34.61 \n768 Training questions \n62.99 ±0.12 \n79.84 \n42.61 \n55.73 \n34.40 \n\nTable 1. Ablations of a single network, evaluated on the VQA v2 validation set. We evaluate variations of our best \"reference\" \nmodel (first row), and show that it corresponds to a local optimum in the space of architectures and hyperparameters. Every \nrow corresponds to one variation of that reference model. We train each variation with three different random seeds and \nreport averages and standard deviations (±). \n\n","rows":["ResNet - 200 7×7 features , 2 heads , sigmoid normalization","w img","300 - dimensional GloVe ; bag - of - words ( average )","ResNet - 200 7×7 features , 2 heads , softmax normalization","Sigmoid output , w text","Image features from bottom - up attention , 1 head , sigmoid normalization","Keep answers with \u003e200 training occurrences , N \u003d 278","300 - dimensional GloVe ; 1 - layer backward GRU","Keep answers with \u003e6 training occurrences , N \u003d 3 , 793","384 Training questions","100 - dimensional GloVe ; forward GRU","300 - dimensional GloVe ; bag - of - words ( sum )","768 Training questions","200 - dimensional GloVe ; forward GRU","randomly initialized , w img","Image features from bottom - up attention , K\u003d36","ResNet - 200 7×7 features , 1 head , sigmoid normalization","*","ResNet - 200 global features ( K\u003d1 , i . e . without image attention ) )","Keep answers with \u003e10 training occurrences , N \u003d 2 , 748","Hidden states of dimension 1024","ResNet - 200 features downsampled to 7×7 ( K\u003d49 )","randomly shuffled","Hidden states of dimension 768","randomly initialized ,","Non - linear activations : ReLU","Discard training questions without answers of score\u003d1 . 0","256 Training questions","randomly shuffled ,","Keep answers with \u003e14 training occurrences , N \u003d 2 , 160","ResNet - 200 features 14×14 ( K\u003d196 ) )","pretrained ,","Non - linear activations : tanh","Keep answers with \u003e12 training occurrences , N \u003d 2 , 418","300 - dimensional GloVe randomly shuffled ; 1 - layer forward GRU","randomly initialized","Hidden states of dimension 256","Random shuffling of training data","Image features from bottom - up attention , 2 heads , softmax normalization","Image features from bottom - up attention , 2 heads , sigmoid normalization","Word embeddings learned from random initialization ; 1 - layer forward GRU","Softmax output , w text","300 - dimensional GloVe ; 2 - layer forward GRU","ResNet - 200 7×7 features , 1 head , softmax normalization","Non - linear activations : gated ReLU","Hidden states of dimension 1280","Without extra training data from Visual Genome","Keep answers with \u003e20 training occurrences , N \u003d 1 , 656","Reference model","pretrained","Keep answers with \u003e16 training occurrences , N \u003d 1 , 961","Hidden states of dimension 384","128 Training questions"],"columns":["All","Numbers","pretrained","VQA Score","Accuracy over","balanced pairs","VQA v2 validation","Yes / no","Other","o"],"mergedAllColumns":["Question embedding ( reference : 300 - dimensional GloVe word embeddings , 1 - layer forward GRU )","Image features ( reference : image features from bottom - up attention , adaptive K )","General architecture ( reference : gated tanh non - linear activations , hidden states of dimension 512 )","Mini - batch size ( reference : 512 training questions )","Training data ( reference : with Visual Genome data ; shuffling keeps balanced pairs in the same minibatches )","Image attention ( reference : image features from bottom - up attention , 1 attention head , softmax normalization )","Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"],"numberCells":[{"number":"54.67","isBolded":false,"associatedRows":["128 Training questions","w img","pretrained","randomly shuffled","*"],"associatedColumns":["VQA v2 validation","Accuracy over","Other","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["Mini - batch size ( reference : 512 training questions )"]},{"number":"25.93","isBolded":false,"associatedRows":["ResNet - 200 global features ( K\u003d1 , i . e . without image attention ) )","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","balanced pairs"],"associatedMergedColumns":["Image features ( reference : image features from bottom - up attention , adaptive K )"]},{"number":"34.12","isBolded":false,"associatedRows":["Hidden states of dimension 256","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","balanced pairs","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["General architecture ( reference : gated tanh non - linear activations , hidden states of dimension 512 )"]},{"number":"62.91","isBolded":false,"associatedRows":["Image features from bottom - up attention , 2 heads , sigmoid normalization","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["Image attention ( reference : image features from bottom - up attention , 1 attention head , softmax normalization )"]},{"number":"±0.10","isBolded":false,"associatedRows":["ResNet - 200 7×7 features , 1 head , softmax normalization","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["Image attention ( reference : image features from bottom - up attention , 1 attention head , softmax normalization )"]},{"number":"78.48","isBolded":false,"associatedRows":["Non - linear activations : ReLU","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Yes / no","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["General architecture ( reference : gated tanh non - linear activations , hidden states of dimension 512 )"]},{"number":"42.87","isBolded":false,"associatedRows":["Reference model","Word embeddings learned from random initialization ; 1 - layer forward GRU","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Numbers"],"associatedMergedColumns":[]},{"number":"29.49","isBolded":false,"associatedRows":["ResNet - 200 7×7 features , 1 head , softmax normalization","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","balanced pairs"],"associatedMergedColumns":["Image attention ( reference : image features from bottom - up attention , 1 attention head , softmax normalization )"]},{"number":"±0.30","isBolded":false,"associatedRows":["ResNet - 200 7×7 features , 2 heads , sigmoid normalization","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["Image attention ( reference : image features from bottom - up attention , 1 attention head , softmax normalization )"]},{"number":"62.29","isBolded":false,"associatedRows":["300 - dimensional GloVe ; 2 - layer forward GRU","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["Question embedding ( reference : 300 - dimensional GloVe word embeddings , 1 - layer forward GRU )"]},{"number":"±0.14","isBolded":false,"associatedRows":["Image features from bottom - up attention , K\u003d36","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["Image features ( reference : image features from bottom - up attention , adaptive K )"]},{"number":"62.64","isBolded":false,"associatedRows":["Sigmoid output , w text","randomly shuffled ,","w img","pretrained","randomly shuffled","*"],"associatedColumns":["VQA v2 validation","VQA Score","All","pretrained","o","o","o"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"42.26","isBolded":false,"associatedRows":["Sigmoid output , w text","randomly shuffled ,","w img","pretrained","randomly shuffled","*"],"associatedColumns":["VQA v2 validation","VQA Score","Numbers","pretrained","o","o","o"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"63.12","isBolded":false,"associatedRows":["Hidden states of dimension 768","w img","pretrained","randomly shuffled","*"],"associatedColumns":["VQA v2 validation","VQA Score","All","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["General architecture ( reference : gated tanh non - linear activations , hidden states of dimension 512 )"]},{"number":"36.39","isBolded":false,"associatedRows":["ResNet - 200 global features ( K\u003d1 , i . e . without image attention ) )","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Numbers"],"associatedMergedColumns":["Image features ( reference : image features from bottom - up attention , adaptive K )"]},{"number":"33.52","isBolded":false,"associatedRows":["Non - linear activations : gated ReLU","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","balanced pairs","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["General architecture ( reference : gated tanh non - linear activations , hidden states of dimension 512 )"]},{"number":"55.74","isBolded":false,"associatedRows":["Hidden states of dimension 384","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","Other","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["General architecture ( reference : gated tanh non - linear activations , hidden states of dimension 512 )"]},{"number":"±0.11","isBolded":false,"associatedRows":["Hidden states of dimension 768","w img","pretrained","randomly shuffled","*"],"associatedColumns":["VQA v2 validation","VQA Score","All","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["General architecture ( reference : gated tanh non - linear activations , hidden states of dimension 512 )"]},{"number":"33.56","isBolded":false,"associatedRows":["300 - dimensional GloVe ; 2 - layer forward GRU","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","balanced pairs"],"associatedMergedColumns":["Question embedding ( reference : 300 - dimensional GloVe word embeddings , 1 - layer forward GRU )"]},{"number":"34.26","isBolded":false,"associatedRows":["Sigmoid output , w text","pretrained ,","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","balanced pairs","pretrained","o","o","o","o"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"55.13","isBolded":false,"associatedRows":["Non - linear activations : gated ReLU","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","Other","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["General architecture ( reference : gated tanh non - linear activations , hidden states of dimension 512 )"]},{"number":"79.57","isBolded":false,"associatedRows":["300 - dimensional GloVe ; 1 - layer backward GRU","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Yes / no"],"associatedMergedColumns":["Question embedding ( reference : 300 - dimensional GloVe word embeddings , 1 - layer forward GRU )"]},{"number":"55.73","isBolded":false,"associatedRows":["Random shuffling of training data","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","Other"],"associatedMergedColumns":["Training data ( reference : with Visual Genome data ; shuffling keeps balanced pairs in the same minibatches )"]},{"number":"59.35","isBolded":false,"associatedRows":["ResNet - 200 7×7 features , 1 head , softmax normalization","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["Image attention ( reference : image features from bottom - up attention , 1 attention head , softmax normalization )"]},{"number":"80.45","isBolded":false,"associatedRows":["Keep answers with \u003e14 training occurrences , N \u003d 2 , 160","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Yes / no"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"80.06","isBolded":false,"associatedRows":["Hidden states of dimension 384","w img","pretrained","randomly shuffled","*"],"associatedColumns":["VQA v2 validation","VQA Score","Yes / no","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["General architecture ( reference : gated tanh non - linear activations , hidden states of dimension 512 )"]},{"number":"34.34","isBolded":false,"associatedRows":["Hidden states of dimension 1024","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","balanced pairs","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["General architecture ( reference : gated tanh non - linear activations , hidden states of dimension 512 )"]},{"number":"42.94","isBolded":false,"associatedRows":["256 Training questions","w img","pretrained","randomly shuffled","*"],"associatedColumns":["VQA v2 validation","VQA Score","Numbers","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["Mini - batch size ( reference : 512 training questions )"]},{"number":"±0.21","isBolded":false,"associatedRows":["Hidden states of dimension 1280","w img","pretrained","randomly shuffled","*"],"associatedColumns":["VQA v2 validation","VQA Score","All","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["General architecture ( reference : gated tanh non - linear activations , hidden states of dimension 512 )"]},{"number":"43.02","isBolded":false,"associatedRows":["Keep answers with \u003e10 training occurrences , N \u003d 2 , 748","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Numbers"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"42.39","isBolded":false,"associatedRows":["300 - dimensional GloVe ; 1 - layer backward GRU","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Numbers"],"associatedMergedColumns":["Question embedding ( reference : 300 - dimensional GloVe word embeddings , 1 - layer forward GRU )"]},{"number":"77.34","isBolded":false,"associatedRows":["ResNet - 200 7×7 features , 1 head , softmax normalization","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Yes / no"],"associatedMergedColumns":["Image attention ( reference : image features from bottom - up attention , 1 attention head , softmax normalization )"]},{"number":"54.44","isBolded":false,"associatedRows":["Without extra training data from Visual Genome","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","Other"],"associatedMergedColumns":["Training data ( reference : with Visual Genome data ; shuffling keeps balanced pairs in the same minibatches )"]},{"number":"29.43","isBolded":false,"associatedRows":["ResNet - 200 7×7 features , 2 heads , softmax normalization","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","balanced pairs"],"associatedMergedColumns":["Image attention ( reference : image features from bottom - up attention , 1 attention head , softmax normalization )"]},{"number":"43.99","isBolded":false,"associatedRows":["Image features from bottom - up attention , 2 heads , sigmoid normalization","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Numbers"],"associatedMergedColumns":["Image attention ( reference : image features from bottom - up attention , 1 attention head , softmax normalization )"]},{"number":"63.37","isBolded":false,"associatedRows":["Hidden states of dimension 1280","w img","pretrained","randomly shuffled","*"],"associatedColumns":["VQA v2 validation","VQA Score","All","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["General architecture ( reference : gated tanh non - linear activations , hidden states of dimension 512 )"]},{"number":"63.27","isBolded":false,"associatedRows":["Keep answers with \u003e14 training occurrences , N \u003d 2 , 160","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"34.61","isBolded":false,"associatedRows":["384 Training questions","w img","pretrained","randomly shuffled","*"],"associatedColumns":["VQA v2 validation","Accuracy over","balanced pairs","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["Mini - batch size ( reference : 512 training questions )"]},{"number":"79.82","isBolded":false,"associatedRows":["Sigmoid output , w text","randomly shuffled ,","w img","pretrained","randomly shuffled","*"],"associatedColumns":["VQA v2 validation","VQA Score","Yes / no","pretrained","o","o","o"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"34.62","isBolded":false,"associatedRows":["Discard training questions without answers of score\u003d1 . 0","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","balanced pairs"],"associatedMergedColumns":["Training data ( reference : with Visual Genome data ; shuffling keeps balanced pairs in the same minibatches )"]},{"number":"37.99","isBolded":false,"associatedRows":["ResNet - 200 7×7 features , 1 head , sigmoid normalization","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Numbers"],"associatedMergedColumns":["Image attention ( reference : image features from bottom - up attention , 1 attention head , softmax normalization )"]},{"number":"±0.14","isBolded":false,"associatedRows":["ResNet - 200 global features ( K\u003d1 , i . e . without image attention ) )","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["Image features ( reference : image features from bottom - up attention , adaptive K )"]},{"number":"80.21","isBolded":false,"associatedRows":["Keep answers with \u003e20 training occurrences , N \u003d 1 , 656","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Yes / no"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"42.29","isBolded":false,"associatedRows":["128 Training questions","w img","pretrained","randomly shuffled","*"],"associatedColumns":["VQA v2 validation","VQA Score","Numbers","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["Mini - batch size ( reference : 512 training questions )"]},{"number":"62.15","isBolded":false,"associatedRows":["Image features from bottom - up attention , 1 head , sigmoid normalization","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["Image attention ( reference : image features from bottom - up attention , 1 attention head , softmax normalization )"]},{"number":"80.23","isBolded":false,"associatedRows":["Keep answers with \u003e6 training occurrences , N \u003d 3 , 793","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Yes / no"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"52.32","isBolded":false,"associatedRows":["Softmax output , w text","pretrained ,","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","Other","pretrained","o"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"41.15","isBolded":false,"associatedRows":["Non - linear activations : ReLU","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Numbers","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["General architecture ( reference : gated tanh non - linear activations , hidden states of dimension 512 )"]},{"number":"42.90","isBolded":false,"associatedRows":["Discard training questions without answers of score\u003d1 . 0","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Numbers"],"associatedMergedColumns":["Training data ( reference : with Visual Genome data ; shuffling keeps balanced pairs in the same minibatches )"]},{"number":"79.88","isBolded":false,"associatedRows":["Hidden states of dimension 1024","w img","pretrained","randomly shuffled","*"],"associatedColumns":["VQA v2 validation","VQA Score","Yes / no","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["General architecture ( reference : gated tanh non - linear activations , hidden states of dimension 512 )"]},{"number":"63.15","isBolded":false,"associatedRows":["Reference model","Word embeddings learned from random initialization ; 1 - layer forward GRU","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":[]},{"number":"62.96","isBolded":false,"associatedRows":["200 - dimensional GloVe ; forward GRU","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["Question embedding ( reference : 300 - dimensional GloVe word embeddings , 1 - layer forward GRU )"]},{"number":"76.42","isBolded":false,"associatedRows":["ResNet - 200 7×7 features , 2 heads , sigmoid normalization","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Yes / no"],"associatedMergedColumns":["Image attention ( reference : image features from bottom - up attention , 1 attention head , softmax normalization )"]},{"number":"33.10","isBolded":false,"associatedRows":["Non - linear activations : tanh","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","balanced pairs","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["General architecture ( reference : gated tanh non - linear activations , hidden states of dimension 512 )"]},{"number":"63.04","isBolded":false,"associatedRows":["Sigmoid output , w text","pretrained ,","w img","pretrained","randomly shuffled","*"],"associatedColumns":["VQA v2 validation","VQA Score","All","pretrained","o","o","o","o","o"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"79.80","isBolded":false,"associatedRows":["Image features from bottom - up attention , 2 heads , softmax normalization","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Yes / no"],"associatedMergedColumns":["Image attention ( reference : image features from bottom - up attention , 1 attention head , softmax normalization )"]},{"number":"40.92","isBolded":false,"associatedRows":["Non - linear activations : tanh","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Numbers","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["General architecture ( reference : gated tanh non - linear activations , hidden states of dimension 512 )"]},{"number":"54.67","isBolded":false,"associatedRows":["300 - dimensional GloVe ; bag - of - words ( average )","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","Other"],"associatedMergedColumns":["Question embedding ( reference : 300 - dimensional GloVe word embeddings , 1 - layer forward GRU )"]},{"number":"55.27","isBolded":false,"associatedRows":["Image features from bottom - up attention , 2 heads , sigmoid normalization","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","Other"],"associatedMergedColumns":["Image attention ( reference : image features from bottom - up attention , 1 attention head , softmax normalization )"]},{"number":"54.41","isBolded":false,"associatedRows":["300 - dimensional GloVe ; bag - of - words ( sum )","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","Other"],"associatedMergedColumns":["Question embedding ( reference : 300 - dimensional GloVe word embeddings , 1 - layer forward GRU )"]},{"number":"62.16","isBolded":false,"associatedRows":["300 - dimensional GloVe randomly shuffled ; 1 - layer forward GRU","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["Question embedding ( reference : 300 - dimensional GloVe word embeddings , 1 - layer forward GRU )"]},{"number":"55.66","isBolded":false,"associatedRows":["Keep answers with \u003e20 training occurrences , N \u003d 1 , 656","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","Other"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"37.74","isBolded":false,"associatedRows":["ResNet - 200 7×7 features , 1 head , softmax normalization","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Numbers"],"associatedMergedColumns":["Image attention ( reference : image features from bottom - up attention , 1 attention head , softmax normalization )"]},{"number":"±0.55","isBolded":false,"associatedRows":["Hidden states of dimension 1024","w img","pretrained","randomly shuffled","*"],"associatedColumns":["VQA v2 validation","VQA Score","All","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["General architecture ( reference : gated tanh non - linear activations , hidden states of dimension 512 )"]},{"number":"55.51","isBolded":false,"associatedRows":["100 - dimensional GloVe ; forward GRU","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","Other"],"associatedMergedColumns":["Question embedding ( reference : 300 - dimensional GloVe word embeddings , 1 - layer forward GRU )"]},{"number":"62.48","isBolded":false,"associatedRows":["Without extra training data from Visual Genome","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["Training data ( reference : with Visual Genome data ; shuffling keeps balanced pairs in the same minibatches )"]},{"number":"34.66","isBolded":false,"associatedRows":["Reference model","Word embeddings learned from random initialization ; 1 - layer forward GRU","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","balanced pairs"],"associatedMergedColumns":[]},{"number":"79.83","isBolded":false,"associatedRows":["Sigmoid output , w text","randomly shuffled ,","w img","pretrained","*"],"associatedColumns":["VQA v2 validation","VQA Score","Yes / no","pretrained","o","o","o","o","o","o","o"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"±0.08","isBolded":false,"associatedRows":["Keep answers with \u003e14 training occurrences , N \u003d 2 , 160","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"±0.99","isBolded":false,"associatedRows":["Sigmoid output , w text","randomly initialized ,","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All","pretrained","o","o"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"43.17","isBolded":false,"associatedRows":["Keep answers with \u003e12 training occurrences , N \u003d 2 , 418","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Numbers"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"34.54","isBolded":false,"associatedRows":["Random shuffling of training data","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","balanced pairs"],"associatedMergedColumns":["Training data ( reference : with Visual Genome data ; shuffling keeps balanced pairs in the same minibatches )"]},{"number":"63.10","isBolded":false,"associatedRows":["Image features from bottom - up attention , 2 heads , softmax normalization","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["Image attention ( reference : image features from bottom - up attention , 1 attention head , softmax normalization )"]},{"number":"62.94","isBolded":false,"associatedRows":["Sigmoid output , w text","pretrained ,","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All","pretrained","o","o","o","o"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"77.05","isBolded":false,"associatedRows":["ResNet - 200 7×7 features , 1 head , sigmoid normalization","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Yes / no"],"associatedMergedColumns":["Image attention ( reference : image features from bottom - up attention , 1 attention head , softmax normalization )"]},{"number":"79.92","isBolded":false,"associatedRows":["Image features from bottom - up attention , K\u003d36","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Yes / no"],"associatedMergedColumns":["Image features ( reference : image features from bottom - up attention , adaptive K )"]},{"number":"42.68","isBolded":false,"associatedRows":["Hidden states of dimension 1024","w img","pretrained","randomly shuffled","*"],"associatedColumns":["VQA v2 validation","VQA Score","Numbers","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["General architecture ( reference : gated tanh non - linear activations , hidden states of dimension 512 )"]},{"number":"±0.08","isBolded":false,"associatedRows":["128 Training questions","w img","pretrained","randomly shuffled","*"],"associatedColumns":["VQA v2 validation","VQA Score","All","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["Mini - batch size ( reference : 512 training questions )"]},{"number":"42.49","isBolded":false,"associatedRows":["200 - dimensional GloVe ; forward GRU","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Numbers"],"associatedMergedColumns":["Question embedding ( reference : 300 - dimensional GloVe word embeddings , 1 - layer forward GRU )"]},{"number":"51.55","isBolded":false,"associatedRows":["ResNet - 200 7×7 features , 1 head , softmax normalization","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","Other"],"associatedMergedColumns":["Image attention ( reference : image features from bottom - up attention , 1 attention head , softmax normalization )"]},{"number":"62.14","isBolded":false,"associatedRows":["300 - dimensional GloVe ; bag - of - words ( sum )","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["Question embedding ( reference : 300 - dimensional GloVe word embeddings , 1 - layer forward GRU )"]},{"number":"±0.26","isBolded":false,"associatedRows":["Image features from bottom - up attention , 2 heads , sigmoid normalization","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["Image attention ( reference : image features from bottom - up attention , 1 attention head , softmax normalization )"]},{"number":"43.08","isBolded":false,"associatedRows":["384 Training questions","w img","pretrained","randomly shuffled","*"],"associatedColumns":["VQA v2 validation","VQA Score","Numbers","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["Mini - batch size ( reference : 512 training questions )"]},{"number":"62.28","isBolded":false,"associatedRows":["Word embeddings learned from random initialization ; 1 - layer forward GRU","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["Question embedding ( reference : 300 - dimensional GloVe word embeddings , 1 - layer forward GRU )"]},{"number":"55.64","isBolded":false,"associatedRows":["300 - dimensional GloVe ; 1 - layer backward GRU","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","Other"],"associatedMergedColumns":["Question embedding ( reference : 300 - dimensional GloVe word embeddings , 1 - layer forward GRU )"]},{"number":"34.56","isBolded":false,"associatedRows":["Keep answers with \u003e12 training occurrences , N \u003d 2 , 418","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","balanced pairs"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"±0.12","isBolded":false,"associatedRows":["Discard training questions without answers of score\u003d1 . 0","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["Training data ( reference : with Visual Genome data ; shuffling keeps balanced pairs in the same minibatches )"]},{"number":"±0.08","isBolded":false,"associatedRows":["300 - dimensional GloVe randomly shuffled ; 1 - layer forward GRU","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["Question embedding ( reference : 300 - dimensional GloVe word embeddings , 1 - layer forward GRU )"]},{"number":"±0.04","isBolded":false,"associatedRows":["Keep answers with \u003e200 training occurrences , N \u003d 278","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"80.40","isBolded":false,"associatedRows":["Hidden states of dimension 1280","w img","pretrained","randomly shuffled","*"],"associatedColumns":["VQA v2 validation","VQA Score","Yes / no","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["General architecture ( reference : gated tanh non - linear activations , hidden states of dimension 512 )"]},{"number":"55.75","isBolded":false,"associatedRows":["384 Training questions","w img","pretrained","randomly shuffled","*"],"associatedColumns":["VQA v2 validation","Accuracy over","Other","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["Mini - batch size ( reference : 512 training questions )"]},{"number":"63.30","isBolded":false,"associatedRows":["Keep answers with \u003e10 training occurrences , N \u003d 2 , 748","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"80.29","isBolded":false,"associatedRows":["Keep answers with \u003e16 training occurrences , N \u003d 1 , 961","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Yes / no"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"±0.37","isBolded":false,"associatedRows":["ResNet - 200 7×7 features , 1 head , sigmoid normalization","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["Image attention ( reference : image features from bottom - up attention , 1 attention head , softmax normalization )"]},{"number":"80.21","isBolded":false,"associatedRows":["384 Training questions","w img","pretrained","randomly shuffled","*"],"associatedColumns":["VQA v2 validation","VQA Score","Yes / no","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["Mini - batch size ( reference : 512 training questions )"]},{"number":"42.61","isBolded":false,"associatedRows":["768 Training questions","w img","pretrained","randomly shuffled","*"],"associatedColumns":["VQA v2 validation","VQA Score","Numbers","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["Mini - batch size ( reference : 512 training questions )"]},{"number":"42.72","isBolded":false,"associatedRows":["Sigmoid output , w text","pretrained ,","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Numbers","pretrained","o","o","o","o"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"61.74","isBolded":false,"associatedRows":["Non - linear activations : tanh","w img","pretrained","randomly shuffled","*"],"associatedColumns":["VQA v2 validation","VQA Score","All","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["General architecture ( reference : gated tanh non - linear activations , hidden states of dimension 512 )"]},{"number":"78.84","isBolded":false,"associatedRows":["100 - dimensional GloVe ; forward GRU","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Yes / no"],"associatedMergedColumns":["Question embedding ( reference : 300 - dimensional GloVe word embeddings , 1 - layer forward GRU )"]},{"number":"42.89","isBolded":false,"associatedRows":["Hidden states of dimension 768","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Numbers","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["General architecture ( reference : gated tanh non - linear activations , hidden states of dimension 512 )"]},{"number":"80.22","isBolded":false,"associatedRows":["256 Training questions","w img","pretrained","randomly shuffled","*"],"associatedColumns":["VQA v2 validation","VQA Score","Yes / no","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["Mini - batch size ( reference : 512 training questions )"]},{"number":"34.69","isBolded":false,"associatedRows":["Keep answers with \u003e10 training occurrences , N \u003d 2 , 748","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","balanced pairs"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"59.20","isBolded":false,"associatedRows":["ResNet - 200 7×7 features , 2 heads , softmax normalization","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["Image attention ( reference : image features from bottom - up attention , 1 attention head , softmax normalization )"]},{"number":"55.11","isBolded":false,"associatedRows":["300 - dimensional GloVe randomly shuffled ; 1 - layer forward GRU","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","Other"],"associatedMergedColumns":["Question embedding ( reference : 300 - dimensional GloVe word embeddings , 1 - layer forward GRU )"]},{"number":"78.83","isBolded":false,"associatedRows":["Image features from bottom - up attention , 1 head , sigmoid normalization","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Yes / no"],"associatedMergedColumns":["Image attention ( reference : image features from bottom - up attention , 1 attention head , softmax normalization )"]},{"number":"79.76","isBolded":false,"associatedRows":["200 - dimensional GloVe ; forward GRU","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Yes / no"],"associatedMergedColumns":["Question embedding ( reference : 300 - dimensional GloVe word embeddings , 1 - layer forward GRU )"]},{"number":"±0.15","isBolded":false,"associatedRows":["Sigmoid output , w text","randomly shuffled ,","w img","pretrained","randomly shuffled","*"],"associatedColumns":["VQA v2 validation","VQA Score","All","pretrained","o","o","o"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"42.44","isBolded":false,"associatedRows":["Image features from bottom - up attention , K\u003d36","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Numbers"],"associatedMergedColumns":["Image features ( reference : image features from bottom - up attention , adaptive K )"]},{"number":"±0.10","isBolded":false,"associatedRows":["Keep answers with \u003e16 training occurrences , N \u003d 1 , 961","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"42.90","isBolded":false,"associatedRows":["Keep answers with \u003e20 training occurrences , N \u003d 1 , 656","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Numbers"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"42.42","isBolded":false,"associatedRows":["300 - dimensional GloVe ; 2 - layer forward GRU","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Numbers"],"associatedMergedColumns":["Question embedding ( reference : 300 - dimensional GloVe word embeddings , 1 - layer forward GRU )"]},{"number":"±0.10","isBolded":false,"associatedRows":["ResNet - 200 features downsampled to 7×7 ( K\u003d49 )","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["Image features ( reference : image features from bottom - up attention , adaptive K )"]},{"number":"59.35","isBolded":false,"associatedRows":["ResNet - 200 features downsampled to 7×7 ( K\u003d49 )","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["Image features ( reference : image features from bottom - up attention , adaptive K )"]},{"number":"34.62","isBolded":false,"associatedRows":["Keep answers with \u003e16 training occurrences , N \u003d 1 , 961","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","balanced pairs"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"34.76","isBolded":false,"associatedRows":["Hidden states of dimension 1280","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","balanced pairs","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["General architecture ( reference : gated tanh non - linear activations , hidden states of dimension 512 )"]},{"number":"55.68","isBolded":false,"associatedRows":["Sigmoid output , w text","randomly shuffled ,","w img","pretrained","*"],"associatedColumns":["VQA v2 validation","Accuracy over","Other","pretrained","o","o","o","o","o","o","o"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"±0.05","isBolded":false,"associatedRows":["100 - dimensional GloVe ; forward GRU","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["Question embedding ( reference : 300 - dimensional GloVe word embeddings , 1 - layer forward GRU )"]},{"number":"63.02","isBolded":false,"associatedRows":["Hidden states of dimension 1024","w img","pretrained","randomly shuffled","*"],"associatedColumns":["VQA v2 validation","VQA Score","All","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["General architecture ( reference : gated tanh non - linear activations , hidden states of dimension 512 )"]},{"number":"55.86","isBolded":false,"associatedRows":["Keep answers with \u003e10 training occurrences , N \u003d 2 , 748","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","Other"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"62.28","isBolded":false,"associatedRows":["Sigmoid output , w text","randomly initialized ,","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All","pretrained","o","o"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"63.16","isBolded":false,"associatedRows":["Random shuffling of training data","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["Training data ( reference : with Visual Genome data ; shuffling keeps balanced pairs in the same minibatches )"]},{"number":"28.40","isBolded":false,"associatedRows":["ResNet - 200 7×7 features , 2 heads , sigmoid normalization","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","balanced pairs"],"associatedMergedColumns":["Image attention ( reference : image features from bottom - up attention , 1 attention head , softmax normalization )"]},{"number":"42.12","isBolded":false,"associatedRows":["100 - dimensional GloVe ; forward GRU","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Numbers"],"associatedMergedColumns":["Question embedding ( reference : 300 - dimensional GloVe word embeddings , 1 - layer forward GRU )"]},{"number":"63.21","isBolded":false,"associatedRows":["Sigmoid output , w text","randomly initialized , w img","pretrained","*"],"associatedColumns":["VQA v2 validation","VQA Score","All","pretrained","o","o","o","o","o","o"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"41.73","isBolded":false,"associatedRows":["300 - dimensional GloVe randomly shuffled ; 1 - layer forward GRU","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Numbers"],"associatedMergedColumns":["Question embedding ( reference : 300 - dimensional GloVe word embeddings , 1 - layer forward GRU )"]},{"number":"37.52","isBolded":false,"associatedRows":["ResNet - 200 7×7 features , 2 heads , softmax normalization","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Numbers"],"associatedMergedColumns":["Image attention ( reference : image features from bottom - up attention , 1 attention head , softmax normalization )"]},{"number":"80.37","isBolded":false,"associatedRows":["Without extra training data from Visual Genome","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Yes / no"],"associatedMergedColumns":["Training data ( reference : with Visual Genome data ; shuffling keeps balanced pairs in the same minibatches )"]},{"number":"28.68","isBolded":false,"associatedRows":["ResNet - 200 7×7 features , 1 head , sigmoid normalization","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","balanced pairs"],"associatedMergedColumns":["Image attention ( reference : image features from bottom - up attention , 1 attention head , softmax normalization )"]},{"number":"34.30","isBolded":false,"associatedRows":["Image features from bottom - up attention , 2 heads , sigmoid normalization","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","balanced pairs"],"associatedMergedColumns":["Image attention ( reference : image features from bottom - up attention , 1 attention head , softmax normalization )"]},{"number":"55.65","isBolded":false,"associatedRows":["Keep answers with \u003e16 training occurrences , N \u003d 1 , 961","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","Other"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"55.53","isBolded":false,"associatedRows":["Hidden states of dimension 256","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","Other","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["General architecture ( reference : gated tanh non - linear activations , hidden states of dimension 512 )"]},{"number":"42.92","isBolded":false,"associatedRows":["Random shuffling of training data","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Numbers"],"associatedMergedColumns":["Training data ( reference : with Visual Genome data ; shuffling keeps balanced pairs in the same minibatches )"]},{"number":"33.73","isBolded":false,"associatedRows":["300 - dimensional GloVe ; bag - of - words ( sum )","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","balanced pairs"],"associatedMergedColumns":["Question embedding ( reference : 300 - dimensional GloVe word embeddings , 1 - layer forward GRU )"]},{"number":"55.13","isBolded":false,"associatedRows":["Sigmoid output , w text","randomly shuffled ,","w img","pretrained","randomly shuffled","*"],"associatedColumns":["VQA v2 validation","Accuracy over","Other","pretrained","o","o","o"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"54.57","isBolded":false,"associatedRows":["Image features from bottom - up attention , 1 head , sigmoid normalization","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","Other"],"associatedMergedColumns":["Image attention ( reference : image features from bottom - up attention , 1 attention head , softmax normalization )"]},{"number":"±0.15","isBolded":false,"associatedRows":["Without extra training data from Visual Genome","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["Training data ( reference : with Visual Genome data ; shuffling keeps balanced pairs in the same minibatches )"]},{"number":"42.97","isBolded":false,"associatedRows":["Sigmoid output , w text","randomly initialized , w img","pretrained","*"],"associatedColumns":["VQA v2 validation","VQA Score","Numbers","pretrained","o","o","o","o","o","o"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"46.57","isBolded":false,"associatedRows":["ResNet - 200 global features ( K\u003d1 , i . e . without image attention ) )","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","Other"],"associatedMergedColumns":["Image features ( reference : image features from bottom - up attention , adaptive K )"]},{"number":"63.26","isBolded":false,"associatedRows":["Keep answers with \u003e6 training occurrences , N \u003d 3 , 793","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"51.55","isBolded":false,"associatedRows":["ResNet - 200 features downsampled to 7×7 ( K\u003d49 )","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","Other"],"associatedMergedColumns":["Image features ( reference : image features from bottom - up attention , adaptive K )"]},{"number":"±0.04","isBolded":false,"associatedRows":["300 - dimensional GloVe ; bag - of - words ( sum )","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["Question embedding ( reference : 300 - dimensional GloVe word embeddings , 1 - layer forward GRU )"]},{"number":"33.70","isBolded":false,"associatedRows":["100 - dimensional GloVe ; forward GRU","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","balanced pairs"],"associatedMergedColumns":["Question embedding ( reference : 300 - dimensional GloVe word embeddings , 1 - layer forward GRU )"]},{"number":"27.64","isBolded":false,"associatedRows":["ResNet - 200 features 14×14 ( K\u003d196 ) )","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","balanced pairs"],"associatedMergedColumns":["Image features ( reference : image features from bottom - up attention , adaptive K )"]},{"number":"54.13","isBolded":false,"associatedRows":["Non - linear activations : tanh","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","Other","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["General architecture ( reference : gated tanh non - linear activations , hidden states of dimension 512 )"]},{"number":"55.81","isBolded":false,"associatedRows":["Reference model","Word embeddings learned from random initialization ; 1 - layer forward GRU","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","Other"],"associatedMergedColumns":[]},{"number":"±0.25","isBolded":false,"associatedRows":["ResNet - 200 features 14×14 ( K\u003d196 ) )","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["Image features ( reference : image features from bottom - up attention , adaptive K )"]},{"number":"79.70","isBolded":false,"associatedRows":["128 Training questions","w img","pretrained","randomly shuffled","*"],"associatedColumns":["VQA v2 validation","VQA Score","Yes / no","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["Mini - batch size ( reference : 512 training questions )"]},{"number":"80.18","isBolded":false,"associatedRows":["Keep answers with \u003e12 training occurrences , N \u003d 2 , 418","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Yes / no"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"34.67","isBolded":false,"associatedRows":["Keep answers with \u003e20 training occurrences , N \u003d 1 , 656","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","balanced pairs"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"34.31","isBolded":false,"associatedRows":["Sigmoid output , w text","randomly shuffled ,","w img","pretrained","*"],"associatedColumns":["VQA v2 validation","Accuracy over","balanced pairs","pretrained","o","o","o","o","o","o","o"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"80.06","isBolded":false,"associatedRows":["Hidden states of dimension 768","w img","pretrained","randomly shuffled","*"],"associatedColumns":["VQA v2 validation","VQA Score","Yes / no","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["General architecture ( reference : gated tanh non - linear activations , hidden states of dimension 512 )"]},{"number":"79.84","isBolded":false,"associatedRows":["768 Training questions","w img","pretrained","randomly shuffled","*"],"associatedColumns":["VQA v2 validation","VQA Score","Yes / no","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["Mini - batch size ( reference : 512 training questions )"]},{"number":"41.92","isBolded":false,"associatedRows":["Word embeddings learned from random initialization ; 1 - layer forward GRU","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Numbers"],"associatedMergedColumns":["Question embedding ( reference : 300 - dimensional GloVe word embeddings , 1 - layer forward GRU )"]},{"number":"77.34","isBolded":false,"associatedRows":["ResNet - 200 features downsampled to 7×7 ( K\u003d49 )","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Yes / no"],"associatedMergedColumns":["Image features ( reference : image features from bottom - up attention , adaptive K )"]},{"number":"42.94","isBolded":false,"associatedRows":["Keep answers with \u003e6 training occurrences , N \u003d 3 , 793","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Numbers"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"79.74","isBolded":false,"associatedRows":["Image features from bottom - up attention , 2 heads , sigmoid normalization","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Yes / no"],"associatedMergedColumns":["Image attention ( reference : image features from bottom - up attention , 1 attention head , softmax normalization )"]},{"number":"48.93","isBolded":false,"associatedRows":["Keep answers with \u003e200 training occurrences , N \u003d 278","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","Other"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"80.20","isBolded":false,"associatedRows":["Sigmoid output , w text","pretrained ,","w img","pretrained","randomly shuffled","*"],"associatedColumns":["VQA v2 validation","VQA Score","Yes / no","pretrained","o","o","o","o","o"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"80.15","isBolded":false,"associatedRows":["Discard training questions without answers of score\u003d1 . 0","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Yes / no"],"associatedMergedColumns":["Training data ( reference : with Visual Genome data ; shuffling keeps balanced pairs in the same minibatches )"]},{"number":"80.33","isBolded":false,"associatedRows":["Keep answers with \u003e10 training occurrences , N \u003d 2 , 748","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Yes / no"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"40.93","isBolded":false,"associatedRows":["Softmax output , w text","pretrained ,","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Numbers","pretrained","o"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"34.54","isBolded":false,"associatedRows":["Hidden states of dimension 768","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","balanced pairs","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["General architecture ( reference : gated tanh non - linear activations , hidden states of dimension 512 )"]},{"number":"34.17","isBolded":false,"associatedRows":["Sigmoid output , w text","randomly shuffled ,","w img","pretrained","randomly shuffled","*"],"associatedColumns":["VQA v2 validation","Accuracy over","balanced pairs","pretrained","o","o","o"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"63.17","isBolded":false,"associatedRows":["256 Training questions","w img","pretrained","*"],"associatedColumns":["VQA v2 validation","VQA Score","All","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["Mini - batch size ( reference : 512 training questions )"]},{"number":"±0.07","isBolded":false,"associatedRows":["Keep answers with \u003e6 training occurrences , N \u003d 3 , 793","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"42.62","isBolded":false,"associatedRows":["Sigmoid output , w text","randomly shuffled ,","w img","pretrained","*"],"associatedColumns":["VQA v2 validation","VQA Score","Numbers","pretrained","o","o","o","o","o","o","o"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"34.12","isBolded":false,"associatedRows":["Without extra training data from Visual Genome","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","balanced pairs"],"associatedMergedColumns":["Training data ( reference : with Visual Genome data ; shuffling keeps balanced pairs in the same minibatches )"]},{"number":"±0.04","isBolded":false,"associatedRows":["384 Training questions","w img","pretrained","randomly shuffled","*"],"associatedColumns":["VQA v2 validation","VQA Score","All","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["Mini - batch size ( reference : 512 training questions )"]},{"number":"58.96","isBolded":false,"associatedRows":["ResNet - 200 7×7 features , 1 head , sigmoid normalization","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["Image attention ( reference : image features from bottom - up attention , 1 attention head , softmax normalization )"]},{"number":"37.95","isBolded":false,"associatedRows":["ResNet - 200 7×7 features , 2 heads , sigmoid normalization","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Numbers"],"associatedMergedColumns":["Image attention ( reference : image features from bottom - up attention , 1 attention head , softmax normalization )"]},{"number":"55.47","isBolded":false,"associatedRows":["Sigmoid output , w text","pretrained ,","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","Other","pretrained","o","o","o","o"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"55.89","isBolded":false,"associatedRows":["Keep answers with \u003e6 training occurrences , N \u003d 3 , 793","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","Other"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"63.16","isBolded":false,"associatedRows":["Keep answers with \u003e12 training occurrences , N \u003d 2 , 418","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"34.65","isBolded":false,"associatedRows":["Sigmoid output , w text","randomly initialized , w img","pretrained","*"],"associatedColumns":["VQA v2 validation","Accuracy over","balanced pairs","pretrained","o","o","o","o","o","o"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"54.39","isBolded":false,"associatedRows":["Non - linear activations : ReLU","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","Other","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["General architecture ( reference : gated tanh non - linear activations , hidden states of dimension 512 )"]},{"number":"±0.09","isBolded":false,"associatedRows":["256 Training questions","w img","pretrained","randomly shuffled","*"],"associatedColumns":["VQA v2 validation","VQA Score","All","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["Mini - batch size ( reference : 512 training questions )"]},{"number":"63.14","isBolded":false,"associatedRows":["Keep answers with \u003e20 training occurrences , N \u003d 1 , 656","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"34.01","isBolded":false,"associatedRows":["128 Training questions","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","balanced pairs","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["Mini - batch size ( reference : 512 training questions )"]},{"number":"41.88","isBolded":false,"associatedRows":["300 - dimensional GloVe ; bag - of - words ( sum )","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Numbers"],"associatedMergedColumns":["Question embedding ( reference : 300 - dimensional GloVe word embeddings , 1 - layer forward GRU )"]},{"number":"51.58","isBolded":false,"associatedRows":["ResNet - 200 7×7 features , 2 heads , softmax normalization","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","Other"],"associatedMergedColumns":["Image attention ( reference : image features from bottom - up attention , 1 attention head , softmax normalization )"]},{"number":"42.15","isBolded":false,"associatedRows":["300 - dimensional GloVe ; bag - of - words ( average )","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Numbers"],"associatedMergedColumns":["Question embedding ( reference : 300 - dimensional GloVe word embeddings , 1 - layer forward GRU )"]},{"number":"36.25","isBolded":false,"associatedRows":["ResNet - 200 features 14×14 ( K\u003d196 ) )","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Numbers"],"associatedMergedColumns":["Image features ( reference : image features from bottom - up attention , adaptive K )"]},{"number":"±0.44","isBolded":false,"associatedRows":["Non - linear activations : tanh","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["General architecture ( reference : gated tanh non - linear activations , hidden states of dimension 512 )"]},{"number":"±0.08","isBolded":false,"associatedRows":["Reference model","Word embeddings learned from random initialization ; 1 - layer forward GRU","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":[]},{"number":"34.52","isBolded":false,"associatedRows":["Image features from bottom - up attention , 2 heads , softmax normalization","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","balanced pairs"],"associatedMergedColumns":["Image attention ( reference : image features from bottom - up attention , 1 attention head , softmax normalization )"]},{"number":"42.83","isBolded":false,"associatedRows":["Sigmoid output , w text","pretrained ,","w img","pretrained","randomly shuffled","*"],"associatedColumns":["VQA v2 validation","VQA Score","Numbers","pretrained","o","o","o","o","o"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"59.59","isBolded":false,"associatedRows":["Keep answers with \u003e200 training occurrences , N \u003d 278","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"49.95","isBolded":false,"associatedRows":["ResNet - 200 features 14×14 ( K\u003d196 ) )","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","Other"],"associatedMergedColumns":["Image features ( reference : image features from bottom - up attention , adaptive K )"]},{"number":"62.45","isBolded":false,"associatedRows":["100 - dimensional GloVe ; forward GRU","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["Question embedding ( reference : 300 - dimensional GloVe word embeddings , 1 - layer forward GRU )"]},{"number":"33.98","isBolded":false,"associatedRows":["300 - dimensional GloVe ; 1 - layer backward GRU","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","balanced pairs"],"associatedMergedColumns":["Question embedding ( reference : 300 - dimensional GloVe word embeddings , 1 - layer forward GRU )"]},{"number":"±0.13","isBolded":false,"associatedRows":["ResNet - 200 7×7 features , 2 heads , softmax normalization","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["Image attention ( reference : image features from bottom - up attention , 1 attention head , softmax normalization )"]},{"number":"34.50","isBolded":false,"associatedRows":["Keep answers with \u003e6 training occurrences , N \u003d 3 , 793","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","balanced pairs"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"55.75","isBolded":false,"associatedRows":["200 - dimensional GloVe ; forward GRU","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","Other"],"associatedMergedColumns":["Question embedding ( reference : 300 - dimensional GloVe word embeddings , 1 - layer forward GRU )"]},{"number":"63.12","isBolded":false,"associatedRows":["Hidden states of dimension 384","w img","pretrained","randomly shuffled","*"],"associatedColumns":["VQA v2 validation","VQA Score","All","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["General architecture ( reference : gated tanh non - linear activations , hidden states of dimension 512 )"]},{"number":"34.22","isBolded":false,"associatedRows":["300 - dimensional GloVe ; bag - of - words ( average )","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","balanced pairs"],"associatedMergedColumns":["Question embedding ( reference : 300 - dimensional GloVe word embeddings , 1 - layer forward GRU )"]},{"number":"75.89","isBolded":false,"associatedRows":["ResNet - 200 global features ( K\u003d1 , i . e . without image attention ) )","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Yes / no"],"associatedMergedColumns":["Image features ( reference : image features from bottom - up attention , adaptive K )"]},{"number":"34.83","isBolded":false,"associatedRows":["Keep answers with \u003e14 training occurrences , N \u003d 2 , 160","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","balanced pairs"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"62.99","isBolded":false,"associatedRows":["768 Training questions","w img","pretrained","*"],"associatedColumns":["VQA v2 validation","VQA Score","All","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["Mini - batch size ( reference : 512 training questions )"]},{"number":"±0.09","isBolded":false,"associatedRows":["300 - dimensional GloVe ; bag - of - words ( average )","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["Question embedding ( reference : 300 - dimensional GloVe word embeddings , 1 - layer forward GRU )"]},{"number":"±0.06","isBolded":false,"associatedRows":["Word embeddings learned from random initialization ; 1 - layer forward GRU","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["Question embedding ( reference : 300 - dimensional GloVe word embeddings , 1 - layer forward GRU )"]},{"number":"±0.02","isBolded":false,"associatedRows":["300 - dimensional GloVe ; 1 - layer backward GRU","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["Question embedding ( reference : 300 - dimensional GloVe word embeddings , 1 - layer forward GRU )"]},{"number":"55.69","isBolded":false,"associatedRows":["Keep answers with \u003e14 training occurrences , N \u003d 2 , 160","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","Other"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"±0.05","isBolded":false,"associatedRows":["Image features from bottom - up attention , 2 heads , softmax normalization","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["Image attention ( reference : image features from bottom - up attention , 1 attention head , softmax normalization )"]},{"number":"34.18","isBolded":false,"associatedRows":["Image features from bottom - up attention , K\u003d36","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","balanced pairs"],"associatedMergedColumns":["Image features ( reference : image features from bottom - up attention , adaptive K )"]},{"number":"55.74","isBolded":false,"associatedRows":["Hidden states of dimension 768","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","Other","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["General architecture ( reference : gated tanh non - linear activations , hidden states of dimension 512 )"]},{"number":"62.38","isBolded":false,"associatedRows":["128 Training questions","w img","pretrained","randomly shuffled","*"],"associatedColumns":["VQA v2 validation","VQA Score","All","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["Mini - batch size ( reference : 512 training questions )"]},{"number":"50.90","isBolded":false,"associatedRows":["ResNet - 200 7×7 features , 1 head , sigmoid normalization","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","Other"],"associatedMergedColumns":["Image attention ( reference : image features from bottom - up attention , 1 attention head , softmax normalization )"]},{"number":"42.94","isBolded":false,"associatedRows":["Keep answers with \u003e16 training occurrences , N \u003d 1 , 961","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Numbers"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"80.07","isBolded":false,"associatedRows":["Reference model","Word embeddings learned from random initialization ; 1 - layer forward GRU","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Yes / no"],"associatedMergedColumns":[]},{"number":"±0.07","isBolded":false,"associatedRows":["Non - linear activations : gated ReLU","w img","pretrained","randomly shuffled","*"],"associatedColumns":["VQA v2 validation","VQA Score","All","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["General architecture ( reference : gated tanh non - linear activations , hidden states of dimension 512 )"]},{"number":"33.45","isBolded":false,"associatedRows":["300 - dimensional GloVe randomly shuffled ; 1 - layer forward GRU","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","balanced pairs"],"associatedMergedColumns":["Question embedding ( reference : 300 - dimensional GloVe word embeddings , 1 - layer forward GRU )"]},{"number":"33.14","isBolded":false,"associatedRows":["Sigmoid output , w text","randomly initialized ,","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","balanced pairs","pretrained","o","o"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"32.57","isBolded":false,"associatedRows":["Non - linear activations : ReLU","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","balanced pairs","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["General architecture ( reference : gated tanh non - linear activations , hidden states of dimension 512 )"]},{"number":"62.80","isBolded":false,"associatedRows":["Hidden states of dimension 256","w img","pretrained","randomly shuffled","*"],"associatedColumns":["VQA v2 validation","VQA Score","All","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["General architecture ( reference : gated tanh non - linear activations , hidden states of dimension 512 )"]},{"number":"55.50","isBolded":false,"associatedRows":["Sigmoid output , w text","pretrained ,","w img","pretrained","randomly shuffled","*"],"associatedColumns":["VQA v2 validation","Accuracy over","Other","pretrained","o","o","o","o","o"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"80.06","isBolded":false,"associatedRows":["Sigmoid output , w text","randomly initialized , w img","pretrained","*"],"associatedColumns":["VQA v2 validation","VQA Score","Yes / no","pretrained","o","o","o","o","o","o"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"55.96","isBolded":false,"associatedRows":["Hidden states of dimension 1280","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","Other","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["General architecture ( reference : gated tanh non - linear activations , hidden states of dimension 512 )"]},{"number":"±0.08","isBolded":false,"associatedRows":["Keep answers with \u003e12 training occurrences , N \u003d 2 , 418","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"±0.21","isBolded":false,"associatedRows":["Non - linear activations : ReLU","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["General architecture ( reference : gated tanh non - linear activations , hidden states of dimension 512 )"]},{"number":"62.44","isBolded":false,"associatedRows":["Non - linear activations : gated ReLU","w img","pretrained","randomly shuffled","*"],"associatedColumns":["VQA v2 validation","VQA Score","All","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["General architecture ( reference : gated tanh non - linear activations , hidden states of dimension 512 )"]},{"number":"76.97","isBolded":false,"associatedRows":["ResNet - 200 7×7 features , 2 heads , softmax normalization","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Yes / no"],"associatedMergedColumns":["Image attention ( reference : image features from bottom - up attention , 1 attention head , softmax normalization )"]},{"number":"55.66","isBolded":false,"associatedRows":["Keep answers with \u003e12 training occurrences , N \u003d 2 , 418","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","Other"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"43.07","isBolded":false,"associatedRows":["Keep answers with \u003e14 training occurrences , N \u003d 2 , 160","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Numbers"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"78.74","isBolded":false,"associatedRows":["300 - dimensional GloVe randomly shuffled ; 1 - layer forward GRU","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Yes / no"],"associatedMergedColumns":["Question embedding ( reference : 300 - dimensional GloVe word embeddings , 1 - layer forward GRU )"]},{"number":"61.63","isBolded":false,"associatedRows":["Non - linear activations : ReLU","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["General architecture ( reference : gated tanh non - linear activations , hidden states of dimension 512 )"]},{"number":"56.16","isBolded":false,"associatedRows":["ResNet - 200 global features ( K\u003d1 , i . e . without image attention ) )","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["Image features ( reference : image features from bottom - up attention , adaptive K )"]},{"number":"78.50","isBolded":false,"associatedRows":["Sigmoid output , w text","randomly initialized ,","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Yes / no","pretrained","o","o"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"62.82","isBolded":false,"associatedRows":["Image features from bottom - up attention , K\u003d36","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["Image features ( reference : image features from bottom - up attention , adaptive K )"]},{"number":"42.50","isBolded":false,"associatedRows":["Sigmoid output , w text","randomly initialized ,","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Numbers","pretrained","o","o"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"63.17","isBolded":false,"associatedRows":["Keep answers with \u003e16 training occurrences , N \u003d 1 , 961","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"55.35","isBolded":false,"associatedRows":["Image features from bottom - up attention , K\u003d36","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","Other"],"associatedMergedColumns":["Image features ( reference : image features from bottom - up attention , adaptive K )"]},{"number":"55.90","isBolded":false,"associatedRows":["Sigmoid output , w text","randomly initialized , w img","pretrained","*"],"associatedColumns":["VQA v2 validation","Accuracy over","Other","pretrained","o","o","o","o","o","o"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"62.97","isBolded":false,"associatedRows":["Sigmoid output , w text","randomly shuffled ,","w img","pretrained","*"],"associatedColumns":["VQA v2 validation","VQA Score","All","pretrained","o","o","o","o","o","o","o"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"±0.12","isBolded":false,"associatedRows":["200 - dimensional GloVe ; forward GRU","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["Question embedding ( reference : 300 - dimensional GloVe word embeddings , 1 - layer forward GRU )"]},{"number":"42.11","isBolded":false,"associatedRows":["Keep answers with \u003e200 training occurrences , N \u003d 278","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Numbers"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"78.77","isBolded":false,"associatedRows":["Word embeddings learned from random initialization ; 1 - layer forward GRU","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Yes / no"],"associatedMergedColumns":["Question embedding ( reference : 300 - dimensional GloVe word embeddings , 1 - layer forward GRU )"]},{"number":"55.27","isBolded":false,"associatedRows":["Word embeddings learned from random initialization ; 1 - layer forward GRU","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","Other"],"associatedMergedColumns":["Question embedding ( reference : 300 - dimensional GloVe word embeddings , 1 - layer forward GRU )"]},{"number":"43.17","isBolded":false,"associatedRows":["Image features from bottom - up attention , 2 heads , softmax normalization","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Numbers"],"associatedMergedColumns":["Image attention ( reference : image features from bottom - up attention , 1 attention head , softmax normalization )"]},{"number":"55.73","isBolded":false,"associatedRows":["768 Training questions","w img","pretrained","randomly shuffled","*"],"associatedColumns":["VQA v2 validation","Accuracy over","Other","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["Mini - batch size ( reference : 512 training questions )"]},{"number":"34.71","isBolded":false,"associatedRows":["256 Training questions","w img","pretrained","randomly shuffled","*"],"associatedColumns":["VQA v2 validation","Accuracy over","balanced pairs","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["Mini - batch size ( reference : 512 training questions )"]},{"number":"42.46","isBolded":false,"associatedRows":["Hidden states of dimension 256","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Numbers","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["General architecture ( reference : gated tanh non - linear activations , hidden states of dimension 512 )"]},{"number":"±0.11","isBolded":false,"associatedRows":["Hidden states of dimension 384","w img","pretrained","randomly shuffled","*"],"associatedColumns":["VQA v2 validation","VQA Score","All","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["General architecture ( reference : gated tanh non - linear activations , hidden states of dimension 512 )"]},{"number":"±1.41","isBolded":false,"associatedRows":["Image features from bottom - up attention , 1 head , sigmoid normalization","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["Image attention ( reference : image features from bottom - up attention , 1 attention head , softmax normalization )"]},{"number":"32.98","isBolded":false,"associatedRows":["Image features from bottom - up attention , 1 head , sigmoid normalization","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","balanced pairs"],"associatedMergedColumns":["Image attention ( reference : image features from bottom - up attention , 1 attention head , softmax normalization )"]},{"number":"55.72","isBolded":false,"associatedRows":["256 Training questions","w img","pretrained","randomly shuffled","*"],"associatedColumns":["VQA v2 validation","Accuracy over","Other","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["Mini - batch size ( reference : 512 training questions )"]},{"number":"±0.06","isBolded":false,"associatedRows":["Random shuffling of training data","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["Training data ( reference : with Visual Genome data ; shuffling keeps balanced pairs in the same minibatches )"]},{"number":"63.15","isBolded":false,"associatedRows":["Discard training questions without answers of score\u003d1 . 0","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["Training data ( reference : with Visual Genome data ; shuffling keeps balanced pairs in the same minibatches )"]},{"number":"79.54","isBolded":false,"associatedRows":["300 - dimensional GloVe ; bag - of - words ( sum )","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Yes / no"],"associatedMergedColumns":["Question embedding ( reference : 300 - dimensional GloVe word embeddings , 1 - layer forward GRU )"]},{"number":"62.82","isBolded":false,"associatedRows":["300 - dimensional GloVe ; 1 - layer backward GRU","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["Question embedding ( reference : 300 - dimensional GloVe word embeddings , 1 - layer forward GRU )"]},{"number":"60.47","isBolded":false,"associatedRows":["Softmax output , w text","pretrained ,","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All","pretrained","o"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"±0.02","isBolded":false,"associatedRows":["Sigmoid output , w text","pretrained ,","w img","pretrained","randomly shuffled","*"],"associatedColumns":["VQA v2 validation","VQA Score","All","pretrained","o","o","o","o","o"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"34.66","isBolded":false,"associatedRows":["Sigmoid output , w text","pretrained ,","w img","pretrained","randomly shuffled","*"],"associatedColumns":["VQA v2 validation","Accuracy over","balanced pairs","pretrained","o","o","o","o","o"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"79.62","isBolded":false,"associatedRows":["Hidden states of dimension 256","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Yes / no","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["General architecture ( reference : gated tanh non - linear activations , hidden states of dimension 512 )"]},{"number":"32.64","isBolded":false,"associatedRows":["Keep answers with \u003e200 training occurrences , N \u003d 278","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","balanced pairs"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"33.67","isBolded":false,"associatedRows":["Word embeddings learned from random initialization ; 1 - layer forward GRU","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","balanced pairs"],"associatedMergedColumns":["Question embedding ( reference : 300 - dimensional GloVe word embeddings , 1 - layer forward GRU )"]},{"number":"78.66","isBolded":false,"associatedRows":["300 - dimensional GloVe ; 2 - layer forward GRU","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Yes / no"],"associatedMergedColumns":["Question embedding ( reference : 300 - dimensional GloVe word embeddings , 1 - layer forward GRU )"]},{"number":"43.44","isBolded":false,"associatedRows":["Image features from bottom - up attention , 1 head , sigmoid normalization","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Numbers"],"associatedMergedColumns":["Image attention ( reference : image features from bottom - up attention , 1 attention head , softmax normalization )"]},{"number":"58.70","isBolded":false,"associatedRows":["ResNet - 200 7×7 features , 2 heads , sigmoid normalization","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["Image attention ( reference : image features from bottom - up attention , 1 attention head , softmax normalization )"]},{"number":"±0.12","isBolded":false,"associatedRows":["768 Training questions","w img","pretrained","*"],"associatedColumns":["VQA v2 validation","VQA Score","All","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["Mini - batch size ( reference : 512 training questions )"]},{"number":"80.17","isBolded":false,"associatedRows":["Random shuffling of training data","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Yes / no"],"associatedMergedColumns":["Training data ( reference : with Visual Genome data ; shuffling keeps balanced pairs in the same minibatches )"]},{"number":"42.06","isBolded":false,"associatedRows":["Without extra training data from Visual Genome","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Numbers"],"associatedMergedColumns":["Training data ( reference : with Visual Genome data ; shuffling keeps balanced pairs in the same minibatches )"]},{"number":"78.19","isBolded":false,"associatedRows":["Softmax output , w text","pretrained ,","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Yes / no","pretrained","o"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"42.12","isBolded":false,"associatedRows":["Non - linear activations : gated ReLU","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Numbers","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["General architecture ( reference : gated tanh non - linear activations , hidden states of dimension 512 )"]},{"number":"55.23","isBolded":false,"associatedRows":["300 - dimensional GloVe ; 2 - layer forward GRU","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","Other"],"associatedMergedColumns":["Question embedding ( reference : 300 - dimensional GloVe word embeddings , 1 - layer forward GRU )"]},{"number":"±0.06","isBolded":false,"associatedRows":["Keep answers with \u003e10 training occurrences , N \u003d 2 , 748","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"±0.14","isBolded":false,"associatedRows":["Sigmoid output , w text","pretrained ,","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All","pretrained","o","o","o","o"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"37.74","isBolded":false,"associatedRows":["ResNet - 200 features downsampled to 7×7 ( K\u003d49 )","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Numbers"],"associatedMergedColumns":["Image features ( reference : image features from bottom - up attention , adaptive K )"]},{"number":"55.32","isBolded":false,"associatedRows":["Sigmoid output , w text","randomly initialized ,","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","Other","pretrained","o","o"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"50.87","isBolded":false,"associatedRows":["ResNet - 200 7×7 features , 2 heads , sigmoid normalization","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","Other"],"associatedMergedColumns":["Image attention ( reference : image features from bottom - up attention , 1 attention head , softmax normalization )"]},{"number":"79.90","isBolded":false,"associatedRows":["Keep answers with \u003e200 training occurrences , N \u003d 278","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Yes / no"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"79.20","isBolded":false,"associatedRows":["Non - linear activations : tanh","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Yes / no","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["General architecture ( reference : gated tanh non - linear activations , hidden states of dimension 512 )"]},{"number":"57.93","isBolded":false,"associatedRows":["ResNet - 200 features 14×14 ( K\u003d196 ) )","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["Image features ( reference : image features from bottom - up attention , adaptive K )"]},{"number":"55.73","isBolded":false,"associatedRows":["Hidden states of dimension 1024","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","Other","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["General architecture ( reference : gated tanh non - linear activations , hidden states of dimension 512 )"]},{"number":"±0.05","isBolded":false,"associatedRows":["Hidden states of dimension 256","w img","pretrained","randomly shuffled","*"],"associatedColumns":["VQA v2 validation","VQA Score","All","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["General architecture ( reference : gated tanh non - linear activations , hidden states of dimension 512 )"]},{"number":"29.49","isBolded":false,"associatedRows":["ResNet - 200 features downsampled to 7×7 ( K\u003d49 )","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","balanced pairs"],"associatedMergedColumns":["Image features ( reference : image features from bottom - up attention , adaptive K )"]},{"number":"55.82","isBolded":false,"associatedRows":["Image features from bottom - up attention , 2 heads , softmax normalization","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","Other"],"associatedMergedColumns":["Image attention ( reference : image features from bottom - up attention , 1 attention head , softmax normalization )"]},{"number":"79.99","isBolded":false,"associatedRows":["Sigmoid output , w text","pretrained ,","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Yes / no","pretrained","o","o","o","o"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"34.34","isBolded":false,"associatedRows":["200 - dimensional GloVe ; forward GRU","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","balanced pairs"],"associatedMergedColumns":["Question embedding ( reference : 300 - dimensional GloVe word embeddings , 1 - layer forward GRU )"]},{"number":"80.17","isBolded":false,"associatedRows":["300 - dimensional GloVe ; bag - of - words ( average )","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Yes / no"],"associatedMergedColumns":["Question embedding ( reference : 300 - dimensional GloVe word embeddings , 1 - layer forward GRU )"]},{"number":"±0.10","isBolded":false,"associatedRows":["300 - dimensional GloVe ; 2 - layer forward GRU","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["Question embedding ( reference : 300 - dimensional GloVe word embeddings , 1 - layer forward GRU )"]},{"number":"±0.01","isBolded":false,"associatedRows":["Sigmoid output , w text","randomly initialized , w img","pretrained","*"],"associatedColumns":["VQA v2 validation","VQA Score","All","pretrained","o","o","o","o","o","o"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"62.53","isBolded":false,"associatedRows":["300 - dimensional GloVe ; bag - of - words ( average )","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["Question embedding ( reference : 300 - dimensional GloVe word embeddings , 1 - layer forward GRU )"]},{"number":"±0.08","isBolded":false,"associatedRows":["Softmax output , w text","pretrained ,","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All","pretrained","o"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"42.89","isBolded":false,"associatedRows":["Hidden states of dimension 384","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Numbers","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["General architecture ( reference : gated tanh non - linear activations , hidden states of dimension 512 )"]},{"number":"34.40","isBolded":false,"associatedRows":["768 Training questions","w img","pretrained","randomly shuffled","*"],"associatedColumns":["VQA v2 validation","Accuracy over","balanced pairs","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["Mini - batch size ( reference : 512 training questions )"]},{"number":"34.54","isBolded":false,"associatedRows":["Hidden states of dimension 384","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","balanced pairs","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["General architecture ( reference : gated tanh non - linear activations , hidden states of dimension 512 )"]},{"number":"43.02","isBolded":false,"associatedRows":["Hidden states of dimension 1280","w img","pretrained","randomly shuffled","*"],"associatedColumns":["VQA v2 validation","VQA Score","Numbers","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["General architecture ( reference : gated tanh non - linear activations , hidden states of dimension 512 )"]},{"number":"32.27","isBolded":false,"associatedRows":["Softmax output , w text","pretrained ,","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","balanced pairs","pretrained","o"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"63.20","isBolded":false,"associatedRows":["384 Training questions","w img","pretrained","*"],"associatedColumns":["VQA v2 validation","VQA Score","All","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["Mini - batch size ( reference : 512 training questions )"]},{"number":"±0.05","isBolded":false,"associatedRows":["Keep answers with \u003e20 training occurrences , N \u003d 1 , 656","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]},{"number":"76.17","isBolded":false,"associatedRows":["ResNet - 200 features 14×14 ( K\u003d196 ) )","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Yes / no"],"associatedMergedColumns":["Image features ( reference : image features from bottom - up attention , adaptive K )"]},{"number":"79.33","isBolded":false,"associatedRows":["Non - linear activations : gated ReLU","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","VQA Score","Yes / no","pretrained","o","o","o","o","o","o","o","o"],"associatedMergedColumns":["General architecture ( reference : gated tanh non - linear activations , hidden states of dimension 512 )"]},{"number":"55.73","isBolded":false,"associatedRows":["Discard training questions without answers of score\u003d1 . 0","w img","pretrained","randomly initialized","*"],"associatedColumns":["VQA v2 validation","Accuracy over","Other"],"associatedMergedColumns":["Training data ( reference : with Visual Genome data ; shuffling keeps balanced pairs in the same minibatches )"]},{"number":"±0.06","isBolded":false,"associatedRows":["Sigmoid output , w text","randomly shuffled ,","w img","pretrained","*"],"associatedColumns":["VQA v2 validation","VQA Score","All","pretrained","o","o","o","o","o","o","o"],"associatedMergedColumns":["Output vocabulary ( reference : \u003e8 occurrences as correct answers in the training data , N \u003d 3 , 129"]}]},{"caption":"VQA v2 validation \n\nVQA Score \nAccuracy over \n\nAll \nYes/no \nNumbers \nOther \nbalanced pairs \n\nReference model \n63.15 ±0.08 \n80.07 \n42.87 \n55.81 \n34.66 \n\n(1) Removing initialization of w text \no (randomly shuffled) \n63.01 ±0.12 \n80.11 \n42.80 \n55.51 \n34.40 \n\n(2) Removing initialization of w img \no (randomly shuffled) \n62.67 ±0.07 \n79.75 \n42.64 \n55.14 \n34.22 \n\n(3) Removing image features from bottom-up attention [3]; 7×7 ResNet-200 features instead \n58.90 ±0.10 \n77.16 \n37.18 \n50.92 \n29.39 \n\n(4) Removing extra training data from the Visual Genome, only uses the VQA v2 training set \n57.84 ±0.05 \n77.46 \n36.73 \n48.68 \n28.66 \n\n(5) Removing shuffling \"by balanced pairs\", standard random shuffling instead \n57.68 ±0.14 \n77.25 \n36.46 \n48.58 \n28.53 \n\n(6) Removing GloVe embeddings to encode the question; learned from random init. instead \n56.97 ±0.22 \n75.92 \n36.03 \n48.26 \n27.50 \n\n(7a) Replace gated tanh layers with tanh activations \n52.13 ±7.33 \n75.90 \n34.51 \n38.92 \n24.78 \n\n(7b) Replace gated tanh layers with ReLU activations \n55.38 ±0.05 \n74.65 \n34.83 \n46.33 \n25.24 \n\n(8a) Binary ground truth targets s ij \u003d (sij \n\n? \n\n\u003e 0.0); ReLU \n54.34 ±0.19 \n73.81 \n34.50 \n44.95 \n23.75 \n\n(8b) Binary ground truth targets s ij \u003d (sij \n\n? \n\n\u003d 1.0); ReLU \n53.41 ±0.20 \n73.23 \n34.38 \n43.54 \n24.32 \n\n(9) Replace sigmoid output with softmax; single binary target s ij \u003d (sij \n\n? \n\n\u003d 1.0); ReLU \n52.52 ±0.31 \n72.79 \n34.33 \n42.09 \n23.81 \n\nTable 2. Cumulative ablations of a single network, evaluated on the VQA v2 validation set. The ablations of table rows are cumulative \nfrom top to bottom. The experimental setup is identical to the one used for Table 1. \n\n","rows":["( 1 )","( 2 )","Removing shuffling \" by balanced pairs \" , standard random shuffling instead","( 7b ) Replace gated tanh layers with ReLU activations","\u003d ( sij","( 6 )","( 5 )","( 3 )","( 4 )","\u003d 1 . 0 ) ;","( randomly shuffled )","\u003e 0 . 0 ) ;","( 9 )","Removing initialization of w text","( 7a ) Replace gated tanh layers with tanh activations","Removing extra training data from the Visual Genome , only uses the VQA v2 training set","( 8a ) Binary ground truth targets s ij \u003d ( sij","Reference model","Replace sigmoid output with softmax ; single binary target s","( 8b ) Binary ground truth targets s","Removing image features from bottom - up attention [ 3 ] ; 7×7 ResNet - 200 features instead","ReLU","Removing initialization of w img","Removing GloVe embeddings to encode the question ; learned from random init . instead"],"columns":["All","Numbers","VQA Score","Accuracy over","balanced pairs","VQA v2 validation","Yes / no","Other"],"mergedAllColumns":["ij","o","?"],"numberCells":[{"number":"25.24","isBolded":false,"associatedRows":["( 7b ) Replace gated tanh layers with ReLU activations","Replace sigmoid output with softmax ; single binary target s"],"associatedColumns":["VQA v2 validation","Accuracy over","balanced pairs"],"associatedMergedColumns":["o"]},{"number":"37.18","isBolded":false,"associatedRows":["( 3 )","Removing image features from bottom - up attention [ 3 ] ; 7×7 ResNet - 200 features instead","ReLU"],"associatedColumns":["VQA v2 validation","VQA Score","Numbers"],"associatedMergedColumns":["o"]},{"number":"±0.31","isBolded":true,"associatedRows":["( 9 )","Replace sigmoid output with softmax ; single binary target s","\u003d ( sij","\u003d 1 . 0 ) ;","ReLU"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["ij"]},{"number":"36.73","isBolded":false,"associatedRows":["( 4 )","Removing extra training data from the Visual Genome , only uses the VQA v2 training set","ReLU"],"associatedColumns":["VQA v2 validation","VQA Score","Numbers"],"associatedMergedColumns":["o"]},{"number":"24.32","isBolded":false,"associatedRows":["( 8b ) Binary ground truth targets s","\u003d ( sij","\u003d 1 . 0 ) ;","ReLU"],"associatedColumns":["VQA v2 validation","Accuracy over","balanced pairs"],"associatedMergedColumns":["?"]},{"number":"52.52","isBolded":false,"associatedRows":["( 9 )","Replace sigmoid output with softmax ; single binary target s","\u003d ( sij","\u003d 1 . 0 ) ;","ReLU"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["ij"]},{"number":"79.75","isBolded":false,"associatedRows":["( 2 )","Removing initialization of w img","( randomly shuffled )","ReLU"],"associatedColumns":["VQA v2 validation","VQA Score","Yes / no"],"associatedMergedColumns":["o"]},{"number":"55.14","isBolded":false,"associatedRows":["( 2 )","Removing initialization of w img","( randomly shuffled )","ReLU"],"associatedColumns":["VQA v2 validation","Accuracy over","Other"],"associatedMergedColumns":["o"]},{"number":"57.68","isBolded":false,"associatedRows":["( 5 )","Removing shuffling \" by balanced pairs \" , standard random shuffling instead","ReLU"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["o"]},{"number":"48.26","isBolded":false,"associatedRows":["( 6 )","Replace sigmoid output with softmax ; single binary target s"],"associatedColumns":["VQA v2 validation","Accuracy over","Other"],"associatedMergedColumns":["o"]},{"number":"74.65","isBolded":false,"associatedRows":["( 7b ) Replace gated tanh layers with ReLU activations","Replace sigmoid output with softmax ; single binary target s"],"associatedColumns":["VQA v2 validation","VQA Score","Yes / no"],"associatedMergedColumns":["o"]},{"number":"28.66","isBolded":false,"associatedRows":["( 4 )","Replace sigmoid output with softmax ; single binary target s"],"associatedColumns":["VQA v2 validation","Accuracy over","balanced pairs"],"associatedMergedColumns":["o"]},{"number":"38.92","isBolded":false,"associatedRows":["( 7a ) Replace gated tanh layers with tanh activations","Replace sigmoid output with softmax ; single binary target s"],"associatedColumns":["VQA v2 validation","Accuracy over","Other"],"associatedMergedColumns":["o"]},{"number":"80.07","isBolded":false,"associatedRows":["Reference model","Removing image features from bottom - up attention [ 3 ] ; 7×7 ResNet - 200 features instead","ReLU"],"associatedColumns":["VQA v2 validation","VQA Score","Yes / no"],"associatedMergedColumns":[]},{"number":"72.79","isBolded":false,"associatedRows":["( 9 )","Replace sigmoid output with softmax ; single binary target s","\u003d ( sij","\u003d 1 . 0 ) ;","ReLU"],"associatedColumns":["VQA v2 validation","VQA Score","Yes / no"],"associatedMergedColumns":["ij"]},{"number":"±0.10","isBolded":true,"associatedRows":["( 3 )","Removing image features from bottom - up attention [ 3 ] ; 7×7 ResNet - 200 features instead","ReLU"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["o"]},{"number":"77.46","isBolded":false,"associatedRows":["( 4 )","Removing extra training data from the Visual Genome , only uses the VQA v2 training set","ReLU"],"associatedColumns":["VQA v2 validation","VQA Score","Yes / no"],"associatedMergedColumns":["o"]},{"number":"±0.05","isBolded":true,"associatedRows":["( 7b ) Replace gated tanh layers with ReLU activations","Replace sigmoid output with softmax ; single binary target s"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["o"]},{"number":"42.87","isBolded":false,"associatedRows":["Reference model","Removing image features from bottom - up attention [ 3 ] ; 7×7 ResNet - 200 features instead","ReLU"],"associatedColumns":["VQA v2 validation","VQA Score","Numbers"],"associatedMergedColumns":[]},{"number":"62.67","isBolded":false,"associatedRows":["( 2 )","Removing initialization of w img","( randomly shuffled )","ReLU"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["o"]},{"number":"58.90","isBolded":false,"associatedRows":["( 3 )","Removing image features from bottom - up attention [ 3 ] ; 7×7 ResNet - 200 features instead","ReLU"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["o"]},{"number":"34.22","isBolded":false,"associatedRows":["( 2 )","Removing initialization of w img","( randomly shuffled )","ReLU"],"associatedColumns":["VQA v2 validation","Accuracy over","balanced pairs"],"associatedMergedColumns":["o"]},{"number":"54.34","isBolded":false,"associatedRows":["( 8a ) Binary ground truth targets s ij \u003d ( sij","\u003e 0 . 0 ) ;","ReLU"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["o"]},{"number":"±0.12","isBolded":true,"associatedRows":["( 1 )","Removing initialization of w text","( randomly shuffled )","ReLU"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":[]},{"number":"±0.07","isBolded":true,"associatedRows":["( 2 )","Removing initialization of w img","( randomly shuffled )","ReLU"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["o"]},{"number":"73.81","isBolded":false,"associatedRows":["( 8a ) Binary ground truth targets s ij \u003d ( sij","\u003e 0 . 0 ) ;","ReLU"],"associatedColumns":["VQA v2 validation","VQA Score","Yes / no"],"associatedMergedColumns":["o"]},{"number":"55.51","isBolded":false,"associatedRows":["( 1 )","Removing initialization of w text","( randomly shuffled )","ReLU"],"associatedColumns":["VQA v2 validation","Accuracy over","Other"],"associatedMergedColumns":[]},{"number":"34.33","isBolded":false,"associatedRows":["( 9 )","Replace sigmoid output with softmax ; single binary target s","\u003d ( sij","\u003d 1 . 0 ) ;","ReLU"],"associatedColumns":["VQA v2 validation","VQA Score","Numbers"],"associatedMergedColumns":["ij"]},{"number":"77.16","isBolded":false,"associatedRows":["( 3 )","Removing image features from bottom - up attention [ 3 ] ; 7×7 ResNet - 200 features instead","ReLU"],"associatedColumns":["VQA v2 validation","VQA Score","Yes / no"],"associatedMergedColumns":["o"]},{"number":"23.75","isBolded":false,"associatedRows":["( 8a ) Binary ground truth targets s ij \u003d ( sij","\u003e 0 . 0 ) ;","ReLU"],"associatedColumns":["VQA v2 validation","Accuracy over","balanced pairs"],"associatedMergedColumns":["o"]},{"number":"55.38","isBolded":false,"associatedRows":["( 7b ) Replace gated tanh layers with ReLU activations","Replace sigmoid output with softmax ; single binary target s"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["o"]},{"number":"34.40","isBolded":false,"associatedRows":["( 1 )","Removing initialization of w text","( randomly shuffled )","ReLU"],"associatedColumns":["VQA v2 validation","Accuracy over","balanced pairs"],"associatedMergedColumns":[]},{"number":"63.01","isBolded":false,"associatedRows":["( 1 )","Removing initialization of w text","( randomly shuffled )","ReLU"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":[]},{"number":"24.78","isBolded":false,"associatedRows":["( 7a ) Replace gated tanh layers with tanh activations","Replace sigmoid output with softmax ; single binary target s"],"associatedColumns":["VQA v2 validation","Accuracy over","balanced pairs"],"associatedMergedColumns":["o"]},{"number":"50.92","isBolded":false,"associatedRows":["( 3 )","Removing image features from bottom - up attention [ 3 ] ; 7×7 ResNet - 200 features instead","ReLU"],"associatedColumns":["VQA v2 validation","Accuracy over","Other"],"associatedMergedColumns":["o"]},{"number":"44.95","isBolded":false,"associatedRows":["( 8a ) Binary ground truth targets s ij \u003d ( sij","\u003e 0 . 0 ) ;","ReLU"],"associatedColumns":["VQA v2 validation","Accuracy over","Other"],"associatedMergedColumns":["o"]},{"number":"23.81","isBolded":false,"associatedRows":["( 9 )","Replace sigmoid output with softmax ; single binary target s","\u003d ( sij","\u003d 1 . 0 ) ;","ReLU"],"associatedColumns":["VQA v2 validation","Accuracy over","balanced pairs"],"associatedMergedColumns":["ij"]},{"number":"±0.22","isBolded":true,"associatedRows":["( 6 )","Removing GloVe embeddings to encode the question ; learned from random init . instead","ReLU"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["o"]},{"number":"53.41","isBolded":false,"associatedRows":["( 8b ) Binary ground truth targets s","\u003d ( sij","\u003d 1 . 0 ) ;","ReLU"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["?"]},{"number":"75.90","isBolded":false,"associatedRows":["( 7a ) Replace gated tanh layers with tanh activations","Replace sigmoid output with softmax ; single binary target s"],"associatedColumns":["VQA v2 validation","VQA Score","Yes / no"],"associatedMergedColumns":["o"]},{"number":"63.15","isBolded":false,"associatedRows":["Reference model","Removing image features from bottom - up attention [ 3 ] ; 7×7 ResNet - 200 features instead","ReLU"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":[]},{"number":"77.25","isBolded":false,"associatedRows":["( 5 )","Removing shuffling \" by balanced pairs \" , standard random shuffling instead","ReLU"],"associatedColumns":["VQA v2 validation","VQA Score","Yes / no"],"associatedMergedColumns":["o"]},{"number":"36.03","isBolded":false,"associatedRows":["( 6 )","Replace sigmoid output with softmax ; single binary target s"],"associatedColumns":["VQA v2 validation","VQA Score","Numbers"],"associatedMergedColumns":["o"]},{"number":"34.38","isBolded":false,"associatedRows":["( 8b ) Binary ground truth targets s","\u003d ( sij","\u003d 1 . 0 ) ;","ReLU"],"associatedColumns":["VQA v2 validation","VQA Score","Numbers"],"associatedMergedColumns":["?"]},{"number":"48.58","isBolded":false,"associatedRows":["( 5 )","Replace sigmoid output with softmax ; single binary target s"],"associatedColumns":["VQA v2 validation","Accuracy over","Other"],"associatedMergedColumns":["o"]},{"number":"57.84","isBolded":false,"associatedRows":["( 4 )","Removing extra training data from the Visual Genome , only uses the VQA v2 training set","ReLU"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["o"]},{"number":"42.09","isBolded":false,"associatedRows":["( 9 )","Replace sigmoid output with softmax ; single binary target s","\u003d ( sij","\u003d 1 . 0 ) ;","ReLU"],"associatedColumns":["VQA v2 validation","Accuracy over","Other"],"associatedMergedColumns":["ij"]},{"number":"29.39","isBolded":false,"associatedRows":["( 3 )","Replace sigmoid output with softmax ; single binary target s"],"associatedColumns":["VQA v2 validation","Accuracy over","balanced pairs"],"associatedMergedColumns":["o"]},{"number":"56.97","isBolded":false,"associatedRows":["( 6 )","Removing GloVe embeddings to encode the question ; learned from random init . instead","ReLU"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["o"]},{"number":"28.53","isBolded":false,"associatedRows":["( 5 )","Replace sigmoid output with softmax ; single binary target s"],"associatedColumns":["VQA v2 validation","Accuracy over","balanced pairs"],"associatedMergedColumns":["o"]},{"number":"46.33","isBolded":false,"associatedRows":["( 7b ) Replace gated tanh layers with ReLU activations","Replace sigmoid output with softmax ; single binary target s"],"associatedColumns":["VQA v2 validation","Accuracy over","Other"],"associatedMergedColumns":["o"]},{"number":"±0.14","isBolded":true,"associatedRows":["( 5 )","Removing shuffling \" by balanced pairs \" , standard random shuffling instead","ReLU"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["o"]},{"number":"±0.20","isBolded":true,"associatedRows":["( 8b ) Binary ground truth targets s","\u003d ( sij","\u003d 1 . 0 ) ;","ReLU"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["?"]},{"number":"42.80","isBolded":false,"associatedRows":["( 1 )","Removing initialization of w text","( randomly shuffled )","ReLU"],"associatedColumns":["VQA v2 validation","VQA Score","Numbers"],"associatedMergedColumns":[]},{"number":"52.13","isBolded":false,"associatedRows":["( 7a ) Replace gated tanh layers with tanh activations","Replace sigmoid output with softmax ; single binary target s"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["o"]},{"number":"55.81","isBolded":false,"associatedRows":["Reference model","Removing image features from bottom - up attention [ 3 ] ; 7×7 ResNet - 200 features instead","ReLU"],"associatedColumns":["VQA v2 validation","Accuracy over","Other"],"associatedMergedColumns":[]},{"number":"27.50","isBolded":false,"associatedRows":["( 6 )","Replace sigmoid output with softmax ; single binary target s"],"associatedColumns":["VQA v2 validation","Accuracy over","balanced pairs"],"associatedMergedColumns":["o"]},{"number":"34.51","isBolded":false,"associatedRows":["( 7a ) Replace gated tanh layers with tanh activations","Replace sigmoid output with softmax ; single binary target s"],"associatedColumns":["VQA v2 validation","VQA Score","Numbers"],"associatedMergedColumns":["o"]},{"number":"±0.05","isBolded":true,"associatedRows":["( 4 )","Removing extra training data from the Visual Genome , only uses the VQA v2 training set","ReLU"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["o"]},{"number":"42.64","isBolded":false,"associatedRows":["( 2 )","Removing initialization of w img","( randomly shuffled )","ReLU"],"associatedColumns":["VQA v2 validation","VQA Score","Numbers"],"associatedMergedColumns":["o"]},{"number":"80.11","isBolded":false,"associatedRows":["( 1 )","Removing initialization of w text","( randomly shuffled )","ReLU"],"associatedColumns":["VQA v2 validation","VQA Score","Yes / no"],"associatedMergedColumns":[]},{"number":"±7.33","isBolded":true,"associatedRows":["( 7a ) Replace gated tanh layers with tanh activations","Replace sigmoid output with softmax ; single binary target s"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["o"]},{"number":"34.83","isBolded":false,"associatedRows":["( 7b ) Replace gated tanh layers with ReLU activations","Replace sigmoid output with softmax ; single binary target s"],"associatedColumns":["VQA v2 validation","VQA Score","Numbers"],"associatedMergedColumns":["o"]},{"number":"43.54","isBolded":false,"associatedRows":["( 8b ) Binary ground truth targets s","\u003d ( sij","\u003d 1 . 0 ) ;","ReLU"],"associatedColumns":["VQA v2 validation","Accuracy over","Other"],"associatedMergedColumns":["?"]},{"number":"±0.19","isBolded":true,"associatedRows":["( 8a ) Binary ground truth targets s ij \u003d ( sij","\u003e 0 . 0 ) ;","ReLU"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":["o"]},{"number":"34.50","isBolded":false,"associatedRows":["( 8a ) Binary ground truth targets s ij \u003d ( sij","\u003e 0 . 0 ) ;","ReLU"],"associatedColumns":["VQA v2 validation","VQA Score","Numbers"],"associatedMergedColumns":["o"]},{"number":"±0.08","isBolded":true,"associatedRows":["Reference model","Removing image features from bottom - up attention [ 3 ] ; 7×7 ResNet - 200 features instead","ReLU"],"associatedColumns":["VQA v2 validation","VQA Score","All"],"associatedMergedColumns":[]},{"number":"75.92","isBolded":false,"associatedRows":["( 6 )","Replace sigmoid output with softmax ; single binary target s"],"associatedColumns":["VQA v2 validation","VQA Score","Yes / no"],"associatedMergedColumns":["o"]},{"number":"73.23","isBolded":false,"associatedRows":["( 8b ) Binary ground truth targets s","\u003d ( sij","\u003d 1 . 0 ) ;","ReLU"],"associatedColumns":["VQA v2 validation","VQA Score","Yes / no"],"associatedMergedColumns":["?"]},{"number":"48.68","isBolded":false,"associatedRows":["( 4 )","Replace sigmoid output with softmax ; single binary target s"],"associatedColumns":["VQA v2 validation","Accuracy over","Other"],"associatedMergedColumns":["o"]},{"number":"36.46","isBolded":false,"associatedRows":["( 5 )","Replace sigmoid output with softmax ; single binary target s"],"associatedColumns":["VQA v2 validation","VQA Score","Numbers"],"associatedMergedColumns":["o"]},{"number":"34.66","isBolded":false,"associatedRows":["Reference model","Removing image features from bottom - up attention [ 3 ] ; 7×7 ResNet - 200 features instead","ReLU"],"associatedColumns":["VQA v2 validation","Accuracy over","balanced pairs"],"associatedMergedColumns":[]}]}]