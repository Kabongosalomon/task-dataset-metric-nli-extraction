[{"caption":"Table 2.1: Sizes, architectures, and learning hyper-parameters (batch size in tokens and learning rate) of the models \nwhich we trained. All models were trained for a total of 300 billion tokens. \n\n","rows":["5140","GPT - 3 175B or \" GPT - 3 \"","4096","760M","GPT - 3 XL","GPT - 3","GPT - 3 13B","350M","2560","125M","GPT - 3 Small","GPT - 3 Large","1536","2048","1024","128","12288","768","GPT - 3 Medium","2M","1M"],"columns":["n heads","head","Model Name","Batch Size","Learning Rate","layers","n params"],"mergedAllColumns":["− 4"],"numberCells":[{"number":"80","isBolded":false,"associatedRows":["GPT - 3","760M","2560"],"associatedColumns":["head"],"associatedMergedColumns":[]},{"number":"1.3B","isBolded":false,"associatedRows":["GPT - 3 XL"],"associatedColumns":["n params"],"associatedMergedColumns":[]},{"number":"24","isBolded":false,"associatedRows":["GPT - 3 XL","760M"],"associatedColumns":["layers"],"associatedMergedColumns":[]},{"number":"0.6×","isBolded":true,"associatedRows":["GPT - 3 175B or \" GPT - 3 \"","760M","12288","128","2M"],"associatedColumns":["Learning Rate"],"associatedMergedColumns":["− 4"]},{"number":"32","isBolded":false,"associatedRows":["GPT - 3","760M","4096"],"associatedColumns":["n heads"],"associatedMergedColumns":[]},{"number":"40","isBolded":false,"associatedRows":["GPT - 3 13B","760M"],"associatedColumns":["layers"],"associatedMergedColumns":[]},{"number":"6.7B","isBolded":false,"associatedRows":["GPT - 3"],"associatedColumns":["n params"],"associatedMergedColumns":[]},{"number":"10−4","isBolded":true,"associatedRows":["GPT - 3","760M","2560","128","1M"],"associatedColumns":["Learning Rate"],"associatedMergedColumns":[]},{"number":"64","isBolded":false,"associatedRows":["GPT - 3 Medium","350M","1024"],"associatedColumns":["head"],"associatedMergedColumns":[]},{"number":"6.0×","isBolded":true,"associatedRows":["GPT - 3 Small","125M","768","128","1M"],"associatedColumns":["Learning Rate"],"associatedMergedColumns":[]},{"number":"12","isBolded":false,"associatedRows":["GPT - 3 Small","125M","768"],"associatedColumns":["n heads"],"associatedMergedColumns":[]},{"number":"32","isBolded":false,"associatedRows":["GPT - 3","760M"],"associatedColumns":["layers"],"associatedMergedColumns":[]},{"number":"1.0×","isBolded":true,"associatedRows":["GPT - 3 13B","760M","5140","128","2M"],"associatedColumns":["Learning Rate"],"associatedMergedColumns":[]},{"number":"12","isBolded":false,"associatedRows":["GPT - 3 Small","125M"],"associatedColumns":["layers"],"associatedMergedColumns":[]},{"number":"32","isBolded":false,"associatedRows":["GPT - 3","760M"],"associatedColumns":["layers"],"associatedMergedColumns":[]},{"number":"32","isBolded":false,"associatedRows":["GPT - 3","760M","2560"],"associatedColumns":["n heads"],"associatedMergedColumns":[]},{"number":"64","isBolded":false,"associatedRows":["GPT - 3 Small","125M","768"],"associatedColumns":["head"],"associatedMergedColumns":[]},{"number":"0.5M","isBolded":false,"associatedRows":["GPT - 3 Medium","350M","1024","128"],"associatedColumns":["Batch Size"],"associatedMergedColumns":[]},{"number":"0.5M","isBolded":false,"associatedRows":["GPT - 3 Large","760M","1536","128"],"associatedColumns":["Batch Size"],"associatedMergedColumns":[]},{"number":"10−4","isBolded":true,"associatedRows":["GPT - 3","760M","4096","128","2M"],"associatedColumns":["Learning Rate"],"associatedMergedColumns":[]},{"number":"10","isBolded":true,"associatedRows":["GPT - 3 13B","760M","5140","128","2M"],"associatedColumns":["Learning Rate"],"associatedMergedColumns":[]},{"number":"3.2M","isBolded":false,"associatedRows":["GPT - 3 175B or \" GPT - 3 \"","760M","12288","128"],"associatedColumns":["Batch Size"],"associatedMergedColumns":["− 4"]},{"number":"24","isBolded":false,"associatedRows":["GPT - 3 XL","760M","2048"],"associatedColumns":["n heads"],"associatedMergedColumns":[]},{"number":"10−4","isBolded":true,"associatedRows":["GPT - 3 Medium","350M","1024","128","1M"],"associatedColumns":["Learning Rate"],"associatedMergedColumns":[]},{"number":"2.7B","isBolded":false,"associatedRows":["GPT - 3"],"associatedColumns":["n params"],"associatedMergedColumns":[]},{"number":"6.7B","isBolded":false,"associatedRows":["GPT - 3"],"associatedColumns":["Model Name"],"associatedMergedColumns":[]},{"number":"13.0B","isBolded":false,"associatedRows":["GPT - 3 13B"],"associatedColumns":["n params"],"associatedMergedColumns":[]},{"number":"175.0B","isBolded":false,"associatedRows":["GPT - 3 175B or \" GPT - 3 \""],"associatedColumns":["n params"],"associatedMergedColumns":["− 4"]},{"number":"16","isBolded":false,"associatedRows":["GPT - 3 Medium","350M","1024"],"associatedColumns":["n heads"],"associatedMergedColumns":[]},{"number":"24","isBolded":false,"associatedRows":["GPT - 3 Medium","350M"],"associatedColumns":["layers"],"associatedMergedColumns":[]},{"number":"10−4","isBolded":true,"associatedRows":["GPT - 3 XL","760M","2048","128","1M"],"associatedColumns":["Learning Rate"],"associatedMergedColumns":[]},{"number":"96","isBolded":false,"associatedRows":["GPT - 3 175B or \" GPT - 3 \"","760M","12288"],"associatedColumns":["n heads"],"associatedMergedColumns":["− 4"]},{"number":"10−4","isBolded":true,"associatedRows":["GPT - 3 Large","760M","1536","128","1M"],"associatedColumns":["Learning Rate"],"associatedMergedColumns":[]},{"number":"1.2×","isBolded":true,"associatedRows":["GPT - 3","760M","4096","128","2M"],"associatedColumns":["Learning Rate"],"associatedMergedColumns":[]},{"number":"40","isBolded":false,"associatedRows":["GPT - 3 13B","760M","5140"],"associatedColumns":["n heads"],"associatedMergedColumns":[]},{"number":"10","isBolded":true,"associatedRows":["GPT - 3 175B or \" GPT - 3 \"","760M","12288","128","2M"],"associatedColumns":["Learning Rate"],"associatedMergedColumns":["− 4"]},{"number":"0.5M","isBolded":false,"associatedRows":["GPT - 3 Small","125M","768","128"],"associatedColumns":["Batch Size"],"associatedMergedColumns":[]},{"number":"2.5×","isBolded":true,"associatedRows":["GPT - 3 Large","760M","1536","128","1M"],"associatedColumns":["Learning Rate"],"associatedMergedColumns":[]},{"number":"96","isBolded":false,"associatedRows":["GPT - 3 175B or \" GPT - 3 \"","760M"],"associatedColumns":["layers"],"associatedMergedColumns":["− 4"]},{"number":"1.6×","isBolded":true,"associatedRows":["GPT - 3","760M","2560","128","1M"],"associatedColumns":["Learning Rate"],"associatedMergedColumns":[]},{"number":"16","isBolded":false,"associatedRows":["GPT - 3 Large","760M","1536"],"associatedColumns":["n heads"],"associatedMergedColumns":[]},{"number":"96","isBolded":false,"associatedRows":["GPT - 3 Large","760M","1536"],"associatedColumns":["head"],"associatedMergedColumns":[]},{"number":"24","isBolded":false,"associatedRows":["GPT - 3 Large","760M"],"associatedColumns":["layers"],"associatedMergedColumns":[]},{"number":"3.0×","isBolded":true,"associatedRows":["GPT - 3 Medium","350M","1024","128","1M"],"associatedColumns":["Learning Rate"],"associatedMergedColumns":[]},{"number":"2.7B","isBolded":false,"associatedRows":["GPT - 3"],"associatedColumns":["Model Name"],"associatedMergedColumns":[]},{"number":"2.0×","isBolded":true,"associatedRows":["GPT - 3 XL","760M","2048","128","1M"],"associatedColumns":["Learning Rate"],"associatedMergedColumns":[]},{"number":"10−4","isBolded":true,"associatedRows":["GPT - 3 Small","125M","768","128","1M"],"associatedColumns":["Learning Rate"],"associatedMergedColumns":[]}]},{"caption":"Figure 2.2: Total compute used during training. Based on the analysis in Scaling Laws For Neural Language Models \n[KMH + 20] we train much larger models on many fewer tokens than is typical. As a consequence, although GPT-3 3B \nis almost 10x larger than RoBERTa-Large (355M params), both models took roughly 50 petaflop/s-days of compute \nduring pre-training. Methodology for these calculations can be found in Appendix D. \n\nDataset \n\nQuantity \n(tokens) \n\nWeight in \ntraining mix \n\nEpochs elapsed when \ntraining for 300B tokens \n\nCommon Crawl (filtered) 410 billion \n60% \n0.44 \nWebText2 \n19 billion \n22% \n2.9 \nBooks1 \n12 billion \n8% \n1.9 \nBooks2 \n55 billion \n8% \n0.43 \nWikipedia \n3 billion \n3% \n3.4 \n\nTable 2.2: Datasets used to train GPT-3. \"Weight in training mix\" refers to the fraction of examples during training \nthat are drawn from a given dataset, which we intentionally do not make proportional to the size of the dataset. As a \nresult, when we train for 300 billion tokens, some datasets are seen up to 3.4 times during training while other datasets \nare seen less than once. \n\n","rows":["Table","12 billion","410 billion","22%","Wikipedia","60%","19 billion","8%","Figure","3 billion","result , when we train for 300 billion tokens , some datasets are seen up to","3%","WebText2","Books1","Common Crawl ( filtered )","Books2","55 billion"],"columns":["Epochs elapsed when","training for 300B tokens","[ KMH + 20 ] we train much larger models on many fewer tokens than is typical . As a consequence , although GPT - 3 3B"],"mergedAllColumns":["during pre - training . Methodology for these calculations can be found in Appendix D .","that are drawn from a given dataset , which we intentionally do not make proportional to the size of the dataset . As a"],"numberCells":[{"number":"0.43","isBolded":false,"associatedRows":["result , when we train for 300 billion tokens , some datasets are seen up to","Books2","55 billion","8%"],"associatedColumns":["[ KMH + 20 ] we train much larger models on many fewer tokens than is typical . As a consequence , although GPT - 3 3B","Epochs elapsed when","training for 300B tokens"],"associatedMergedColumns":["during pre - training . Methodology for these calculations can be found in Appendix D ."]},{"number":"3.4timesduringtrainingwhileotherdatasets","isBolded":false,"associatedRows":["result , when we train for 300 billion tokens , some datasets are seen up to"],"associatedColumns":["[ KMH + 20 ] we train much larger models on many fewer tokens than is typical . As a consequence , although GPT - 3 3B","Epochs elapsed when","training for 300B tokens"],"associatedMergedColumns":["that are drawn from a given dataset , which we intentionally do not make proportional to the size of the dataset . As a"]},{"number":"1.9","isBolded":false,"associatedRows":["result , when we train for 300 billion tokens , some datasets are seen up to","Books1","12 billion","8%"],"associatedColumns":["[ KMH + 20 ] we train much larger models on many fewer tokens than is typical . As a consequence , although GPT - 3 3B","Epochs elapsed when","training for 300B tokens"],"associatedMergedColumns":["during pre - training . Methodology for these calculations can be found in Appendix D ."]},{"number":"3.4","isBolded":false,"associatedRows":["result , when we train for 300 billion tokens , some datasets are seen up to","Wikipedia","3 billion","3%"],"associatedColumns":["[ KMH + 20 ] we train much larger models on many fewer tokens than is typical . As a consequence , although GPT - 3 3B","Epochs elapsed when","training for 300B tokens"],"associatedMergedColumns":["during pre - training . Methodology for these calculations can be found in Appendix D ."]},{"number":"0.44","isBolded":false,"associatedRows":["result , when we train for 300 billion tokens , some datasets are seen up to","Common Crawl ( filtered )","410 billion","60%"],"associatedColumns":["[ KMH + 20 ] we train much larger models on many fewer tokens than is typical . As a consequence , although GPT - 3 3B","Epochs elapsed when","training for 300B tokens"],"associatedMergedColumns":["during pre - training . Methodology for these calculations can be found in Appendix D ."]},{"number":"2.2:DatasetsusedtotrainGPT-3.\"Weightintrainingmix\"referstothefractionofexamplesduringtraining","isBolded":true,"associatedRows":["Table"],"associatedColumns":["[ KMH + 20 ] we train much larger models on many fewer tokens than is typical . As a consequence , although GPT - 3 3B","Epochs elapsed when","training for 300B tokens"],"associatedMergedColumns":["during pre - training . Methodology for these calculations can be found in Appendix D ."]},{"number":"2.2:Totalcomputeusedduringtraining.BasedontheanalysisinScalingLawsForNeuralLanguageModels","isBolded":true,"associatedRows":["Figure"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"2.9","isBolded":false,"associatedRows":["result , when we train for 300 billion tokens , some datasets are seen up to","WebText2","19 billion","22%"],"associatedColumns":["[ KMH + 20 ] we train much larger models on many fewer tokens than is typical . As a consequence , although GPT - 3 3B","Epochs elapsed when","training for 300B tokens"],"associatedMergedColumns":["during pre - training . Methodology for these calculations can be found in Appendix D ."]}]},{"caption":"Setting \n\nLAMBADA \n(acc) \n\nLAMBADA \n(ppl) \n\nStoryCloze \n(acc) \n\nHellaSwag \n(acc) \n\nSOTA \n68.0 a \n8.63 b \n91.8 c \n85.6 d \nGPT-3 Zero-Shot \n76.2 \n3.00 \n83.2 \n78.9 \nGPT-3 One-Shot \n72.5 \n3.35 \n84.7 \n78.1 \nGPT-3 Few-Shot \n86.4 \n1.92 \n87.7 \n79.3 \n\nTable 3.2: Performance on cloze and completion tasks. GPT-3 significantly improves SOTA on LAMBADA while \nachieving respectable performance on two difficult completion prediction datasets. a [Tur20] b [RWC + 19] c [LDL19] \nd [LCH + 20] \n\n","rows":["a","b","GPT - 3 Zero - Shot","c","GPT - 3 Few - Shot","Table","GPT - 3 One - Shot","SOTA"],"columns":["LAMBADA","StoryCloze","( acc )","( ppl )","HellaSwag"],"mergedAllColumns":[],"numberCells":[{"number":"68.0","isBolded":true,"associatedRows":["SOTA"],"associatedColumns":["LAMBADA","( acc )"],"associatedMergedColumns":[]},{"number":"3.35","isBolded":false,"associatedRows":["GPT - 3 One - Shot"],"associatedColumns":["LAMBADA","( ppl )"],"associatedMergedColumns":[]},{"number":"78.1","isBolded":true,"associatedRows":["GPT - 3 One - Shot"],"associatedColumns":["HellaSwag","( acc )"],"associatedMergedColumns":[]},{"number":"8.63","isBolded":true,"associatedRows":["SOTA"],"associatedColumns":["LAMBADA","( ppl )"],"associatedMergedColumns":[]},{"number":"79.3","isBolded":true,"associatedRows":["GPT - 3 Few - Shot"],"associatedColumns":["HellaSwag","( acc )"],"associatedMergedColumns":[]},{"number":"84.7","isBolded":true,"associatedRows":["GPT - 3 One - Shot"],"associatedColumns":["StoryCloze","( acc )"],"associatedMergedColumns":[]},{"number":"83.2","isBolded":true,"associatedRows":["GPT - 3 Zero - Shot"],"associatedColumns":["StoryCloze","( acc )"],"associatedMergedColumns":[]},{"number":"3.00","isBolded":false,"associatedRows":["GPT - 3 Zero - Shot"],"associatedColumns":["LAMBADA","( ppl )"],"associatedMergedColumns":[]},{"number":"78.9","isBolded":true,"associatedRows":["GPT - 3 Zero - Shot"],"associatedColumns":["HellaSwag","( acc )"],"associatedMergedColumns":[]},{"number":"87.7","isBolded":true,"associatedRows":["GPT - 3 Few - Shot"],"associatedColumns":["StoryCloze","( acc )"],"associatedMergedColumns":[]},{"number":"91.8","isBolded":false,"associatedRows":["SOTA","a","b"],"associatedColumns":["StoryCloze","( acc )"],"associatedMergedColumns":[]},{"number":"76.2","isBolded":false,"associatedRows":["GPT - 3 Zero - Shot"],"associatedColumns":["LAMBADA","( acc )"],"associatedMergedColumns":[]},{"number":"86.4","isBolded":false,"associatedRows":["GPT - 3 Few - Shot"],"associatedColumns":["LAMBADA","( acc )"],"associatedMergedColumns":[]},{"number":"72.5","isBolded":false,"associatedRows":["GPT - 3 One - Shot"],"associatedColumns":["LAMBADA","( acc )"],"associatedMergedColumns":[]},{"number":"1.92","isBolded":false,"associatedRows":["GPT - 3 Few - Shot"],"associatedColumns":["LAMBADA","( ppl )"],"associatedMergedColumns":[]},{"number":"3.2:Performanceonclozeandcompletiontasks.GPT-3significantlyimprovesSOTAonLAMBADAwhile","isBolded":false,"associatedRows":["Table"],"associatedColumns":["HellaSwag","LAMBADA","( acc )"],"associatedMergedColumns":[]},{"number":"85.6d","isBolded":false,"associatedRows":["SOTA","a","b","c"],"associatedColumns":["HellaSwag","( acc )"],"associatedMergedColumns":[]}]},{"caption":"Setting \n\nNaturalQS WebQS TriviaQA \n\nRAG (Fine-tuned, Open-Domain) [LPP + 20] \n44.5 \n45.5 \n68.0 \nT5-11B+SSM (Fine-tuned, Closed-Book) [RRS20] 36.6 \n44.7 \n60.5 \nT5-11B (Fine-tuned, Closed-Book) \n34.5 \n37.4 \n50.1 \nGPT-3 Zero-Shot \n14.6 \n14.4 \n64.3 \nGPT-3 One-Shot \n23.0 \n25.3 \n68.0 \nGPT-3 Few-Shot \n29.9 \n41.5 \n71.2 \n\nTable 3.3: Results on three Open-Domain QA tasks. GPT-3 is shown in the few-, one-, and zero-shot settings, as \ncompared to prior SOTA results for closed book and open domain settings. TriviaQA few-shot result is evaluated on the \nwiki split test server. \n\n","rows":["Table","T5 - 11B+SSM ( Fine - tuned , Closed - Book ) [ RRS20 ]","+","20 ]","RAG ( Fine - tuned , Open - Domain ) [ LPP"],"columns":["NaturalQS","TriviaQA","WebQS"],"mergedAllColumns":[],"numberCells":[{"number":"50.1","isBolded":false,"associatedRows":["T5 - 11B+SSM ( Fine - tuned , Closed - Book ) [ RRS20 ]"],"associatedColumns":["TriviaQA"],"associatedMergedColumns":[]},{"number":"41.5","isBolded":false,"associatedRows":["T5 - 11B+SSM ( Fine - tuned , Closed - Book ) [ RRS20 ]"],"associatedColumns":["WebQS"],"associatedMergedColumns":[]},{"number":"68.0","isBolded":true,"associatedRows":["RAG ( Fine - tuned , Open - Domain ) [ LPP","+","20 ]"],"associatedColumns":["TriviaQA"],"associatedMergedColumns":[]},{"number":"71.2","isBolded":true,"associatedRows":["T5 - 11B+SSM ( Fine - tuned , Closed - Book ) [ RRS20 ]"],"associatedColumns":["TriviaQA"],"associatedMergedColumns":[]},{"number":"3.3:ResultsonthreeOpen-DomainQAtasks.GPT-3isshowninthefew-,one-,andzero-shotsettings,as","isBolded":true,"associatedRows":["Table"],"associatedColumns":["TriviaQA"],"associatedMergedColumns":[]},{"number":"44.5","isBolded":true,"associatedRows":["RAG ( Fine - tuned , Open - Domain ) [ LPP","+","20 ]"],"associatedColumns":["NaturalQS"],"associatedMergedColumns":[]},{"number":"29.9","isBolded":false,"associatedRows":["T5 - 11B+SSM ( Fine - tuned , Closed - Book ) [ RRS20 ]"],"associatedColumns":["NaturalQS"],"associatedMergedColumns":[]},{"number":"37.4","isBolded":false,"associatedRows":["T5 - 11B+SSM ( Fine - tuned , Closed - Book ) [ RRS20 ]"],"associatedColumns":["WebQS"],"associatedMergedColumns":[]},{"number":"14.6","isBolded":false,"associatedRows":["T5 - 11B+SSM ( Fine - tuned , Closed - Book ) [ RRS20 ]"],"associatedColumns":["NaturalQS"],"associatedMergedColumns":[]},{"number":"68.0","isBolded":true,"associatedRows":["T5 - 11B+SSM ( Fine - tuned , Closed - Book ) [ RRS20 ]"],"associatedColumns":["TriviaQA"],"associatedMergedColumns":[]},{"number":"45.5","isBolded":true,"associatedRows":["RAG ( Fine - tuned , Open - Domain ) [ LPP","+","20 ]"],"associatedColumns":["WebQS"],"associatedMergedColumns":[]},{"number":"14.4","isBolded":false,"associatedRows":["T5 - 11B+SSM ( Fine - tuned , Closed - Book ) [ RRS20 ]"],"associatedColumns":["WebQS"],"associatedMergedColumns":[]},{"number":"23.0","isBolded":false,"associatedRows":["T5 - 11B+SSM ( Fine - tuned , Closed - Book ) [ RRS20 ]"],"associatedColumns":["NaturalQS"],"associatedMergedColumns":[]},{"number":"44.7","isBolded":false,"associatedRows":["T5 - 11B+SSM ( Fine - tuned , Closed - Book ) [ RRS20 ]"],"associatedColumns":["WebQS"],"associatedMergedColumns":[]},{"number":"64.3","isBolded":false,"associatedRows":["T5 - 11B+SSM ( Fine - tuned , Closed - Book ) [ RRS20 ]"],"associatedColumns":["TriviaQA"],"associatedMergedColumns":[]},{"number":"36.6","isBolded":false,"associatedRows":["T5 - 11B+SSM ( Fine - tuned , Closed - Book ) [ RRS20 ]"],"associatedColumns":["NaturalQS"],"associatedMergedColumns":[]},{"number":"25.3","isBolded":false,"associatedRows":["T5 - 11B+SSM ( Fine - tuned , Closed - Book ) [ RRS20 ]"],"associatedColumns":["WebQS"],"associatedMergedColumns":[]},{"number":"34.5","isBolded":false,"associatedRows":["T5 - 11B+SSM ( Fine - tuned , Closed - Book ) [ RRS20 ]"],"associatedColumns":["NaturalQS"],"associatedMergedColumns":[]},{"number":"60.5","isBolded":false,"associatedRows":["T5 - 11B+SSM ( Fine - tuned , Closed - Book ) [ RRS20 ]"],"associatedColumns":["TriviaQA"],"associatedMergedColumns":[]}]},{"caption":"Setting \n\nEn→Fr Fr→En En→De De→En En→Ro Ro→En \n\nSOTA (Supervised) \n45.6 a \n35.0 b \n41.2 c \n40.2 d \n38.5 e \n39.9 e \n\nXLM [LC19] \n33.4 \n33.3 \n26.4 \n34.3 \n33.3 \n31.8 \nMASS [STQ + 19] \n37.5 \n34.9 \n28.3 \n35.2 \n35.2 \n33.1 \nmBART [LGG + 20] \n-\n-\n29.8 \n34.0 \n35.0 \n30.5 \n\nGPT-3 Zero-Shot \n25.2 \n21.2 \n24.6 \n27.2 \n14.1 \n19.9 \nGPT-3 One-Shot \n28.3 \n33.7 \n26.2 \n30.4 \n20.6 \n38.6 \nGPT-3 Few-Shot \n32.6 \n39.2 \n29.7 \n40.6 \n21.0 \n39.5 \n\nTable 3.4: Few-shot GPT-3 outperforms previous unsupervised NMT work by 5 BLEU when translating \ninto English reflecting its strength as an English LM. We report BLEU scores on the WMT\u002714 Fr↔En, \nWMT\u002716 De↔En, and WMT\u002716 Ro↔En datasets as measured by multi-bleu.perl with XLM\u0027s tokeniza-\ntion in order to compare most closely with prior unsupervised NMT work. SacreBLEU f [Pos18] results re-\nported in Appendix H. Underline indicates an unsupervised or few-shot SOTA, bold indicates supervised SOTA \nwith relative confidence. a [EOAG18] b [DHKH14] c [WXH + 18] d [oR16] e [LGG + 20] f [SacreBLEU signature: \nBLEU+case.mixed+numrefs.1+smooth.exp+tok.intl+version.1.2.20] \n\nFigure 3.4: Few-shot translation performance on 6 language pairs as model capacity increases. There is a consistent \ntrend of improvement across all datasets as the model scales, and as well as tendency for translation into English to be \nstronger than translation from English. \n","rows":["mBART [ LGG + 20 ]","19 ]","GPT - 3 Zero - Shot","Table","GPT - 3 Few - Shot","MASS [ STQ","XLM [ LC19 ]","GPT - 3 One - Shot","-","SOTA ( Supervised )","Figure"],"columns":["Fr→En","f","[ SacreBLEU","Setting","En→Fr","Ro→En","+","LM .","WMT \u0027 14","De→En","SacreBLEU f","En→De","En→Ro","and WMT \u0027 16 Ro↔En datasets as measured by multi - bleu . perl with XLM \u0027 s tokeniza -"],"mergedAllColumns":["+","BLEU+case . mixed+numrefs . 1+smooth . exp+tok . intl+version . 1 . 2 . 20 ]"],"numberCells":[{"number":"38.5e","isBolded":true,"associatedRows":["Table","SOTA ( Supervised )"],"associatedColumns":["En→Ro"],"associatedMergedColumns":[]},{"number":"28.3","isBolded":false,"associatedRows":["Table","GPT - 3 One - Shot"],"associatedColumns":["En→Fr"],"associatedMergedColumns":["+"]},{"number":"39.5","isBolded":false,"associatedRows":["Table","GPT - 3 Few - Shot"],"associatedColumns":["Ro→En"],"associatedMergedColumns":["+"]},{"number":"45.6a","isBolded":true,"associatedRows":["Table","SOTA ( Supervised )"],"associatedColumns":["En→Fr"],"associatedMergedColumns":[]},{"number":"25.2","isBolded":false,"associatedRows":["Table","GPT - 3 Zero - Shot"],"associatedColumns":["En→Fr"],"associatedMergedColumns":["+"]},{"number":"35.2","isBolded":false,"associatedRows":["Table","MASS [ STQ","19 ]"],"associatedColumns":["En→Ro"],"associatedMergedColumns":[]},{"number":"20.6","isBolded":false,"associatedRows":["Table","GPT - 3 One - Shot"],"associatedColumns":["En→Ro"],"associatedMergedColumns":["+"]},{"number":"29.7","isBolded":false,"associatedRows":["Table","GPT - 3 Few - Shot"],"associatedColumns":["En→De"],"associatedMergedColumns":["+"]},{"number":"32.6","isBolded":false,"associatedRows":["Table","GPT - 3 Few - Shot"],"associatedColumns":["En→Fr"],"associatedMergedColumns":["+"]},{"number":"21.0","isBolded":false,"associatedRows":["Table","GPT - 3 Few - Shot"],"associatedColumns":["En→Ro"],"associatedMergedColumns":["+"]},{"number":"28.3","isBolded":false,"associatedRows":["Table","MASS [ STQ","19 ]"],"associatedColumns":["En→De"],"associatedMergedColumns":[]},{"number":"33.1","isBolded":false,"associatedRows":["Table","MASS [ STQ","19 ]"],"associatedColumns":["Ro→En"],"associatedMergedColumns":[]},{"number":"34.0","isBolded":false,"associatedRows":["Table","mBART [ LGG + 20 ]","-","-"],"associatedColumns":["De→En"],"associatedMergedColumns":["+"]},{"number":"33.3","isBolded":false,"associatedRows":["Table","XLM [ LC19 ]"],"associatedColumns":["Fr→En"],"associatedMergedColumns":[]},{"number":"21.2","isBolded":false,"associatedRows":["Table","GPT - 3 Zero - Shot"],"associatedColumns":["Fr→En"],"associatedMergedColumns":["+"]},{"number":"30.5","isBolded":false,"associatedRows":["Table","mBART [ LGG + 20 ]","-","-"],"associatedColumns":["Ro→En"],"associatedMergedColumns":["+"]},{"number":"38.6","isBolded":false,"associatedRows":["Table","GPT - 3 One - Shot"],"associatedColumns":["Ro→En"],"associatedMergedColumns":["+"]},{"number":"39.2","isBolded":false,"associatedRows":["Table","GPT - 3 Few - Shot"],"associatedColumns":["Fr→En"],"associatedMergedColumns":["+"]},{"number":"34.3","isBolded":false,"associatedRows":["Table","XLM [ LC19 ]"],"associatedColumns":["De→En"],"associatedMergedColumns":[]},{"number":"27.2","isBolded":false,"associatedRows":["Table","GPT - 3 Zero - Shot"],"associatedColumns":["De→En"],"associatedMergedColumns":["+"]},{"number":"29.8","isBolded":false,"associatedRows":["Table","mBART [ LGG + 20 ]","-","-"],"associatedColumns":["En→De"],"associatedMergedColumns":["+"]},{"number":"37.5","isBolded":false,"associatedRows":["Table","MASS [ STQ","19 ]"],"associatedColumns":["En→Fr"],"associatedMergedColumns":[]},{"number":"14.1","isBolded":false,"associatedRows":["Table","GPT - 3 Zero - Shot"],"associatedColumns":["En→Ro"],"associatedMergedColumns":["+"]},{"number":"33.7","isBolded":false,"associatedRows":["Table","GPT - 3 One - Shot"],"associatedColumns":["Fr→En"],"associatedMergedColumns":["+"]},{"number":"39.9e","isBolded":true,"associatedRows":["Table","SOTA ( Supervised )"],"associatedColumns":["Ro→En"],"associatedMergedColumns":[]},{"number":"35.0b","isBolded":false,"associatedRows":["Table","SOTA ( Supervised )"],"associatedColumns":["Fr→En"],"associatedMergedColumns":[]},{"number":"31.8","isBolded":false,"associatedRows":["Table","XLM [ LC19 ]"],"associatedColumns":["Ro→En"],"associatedMergedColumns":[]},{"number":"40.6","isBolded":false,"associatedRows":["Table","GPT - 3 Few - Shot"],"associatedColumns":["De→En"],"associatedMergedColumns":["+"]},{"number":"33.4","isBolded":false,"associatedRows":["Table","XLM [ LC19 ]"],"associatedColumns":["En→Fr"],"associatedMergedColumns":[]},{"number":"26.4","isBolded":false,"associatedRows":["Table","XLM [ LC19 ]"],"associatedColumns":["En→De"],"associatedMergedColumns":[]},{"number":"26.2","isBolded":false,"associatedRows":["Table","GPT - 3 One - Shot"],"associatedColumns":["En→De"],"associatedMergedColumns":["+"]},{"number":"40.2d","isBolded":false,"associatedRows":["Table","SOTA ( Supervised )"],"associatedColumns":["De→En"],"associatedMergedColumns":[]},{"number":"33.3","isBolded":false,"associatedRows":["Table","XLM [ LC19 ]"],"associatedColumns":["En→Ro"],"associatedMergedColumns":[]},{"number":"35.2","isBolded":false,"associatedRows":["Table","MASS [ STQ","19 ]"],"associatedColumns":["De→En"],"associatedMergedColumns":[]},{"number":"41.2c","isBolded":true,"associatedRows":["Table","SOTA ( Supervised )"],"associatedColumns":["En→De"],"associatedMergedColumns":[]},{"number":"19.9","isBolded":false,"associatedRows":["Table","GPT - 3 Zero - Shot"],"associatedColumns":["Ro→En"],"associatedMergedColumns":["+"]},{"number":"24.6","isBolded":false,"associatedRows":["Table","GPT - 3 Zero - Shot"],"associatedColumns":["En→De"],"associatedMergedColumns":["+"]},{"number":"34.9","isBolded":false,"associatedRows":["Table","MASS [ STQ","19 ]"],"associatedColumns":["Fr→En"],"associatedMergedColumns":[]},{"number":"3.4:","isBolded":true,"associatedRows":["Table"],"associatedColumns":["Setting"],"associatedMergedColumns":["+"]},{"number":"30.4","isBolded":false,"associatedRows":["Table","GPT - 3 One - Shot"],"associatedColumns":["De→En"],"associatedMergedColumns":["+"]},{"number":"3.4:Few-shottranslationperformanceon6languagepairsasmodelcapacityincreases.Thereisaconsistent","isBolded":true,"associatedRows":["Figure"],"associatedColumns":["Ro→En","LM .","WMT \u0027 14","and WMT \u0027 16 Ro↔En datasets as measured by multi - bleu . perl with XLM \u0027 s tokeniza -","SacreBLEU f","+","f","[ SacreBLEU"],"associatedMergedColumns":["BLEU+case . mixed+numrefs . 1+smooth . exp+tok . intl+version . 1 . 2 . 20 ]"]},{"number":"35.0","isBolded":false,"associatedRows":["Table","mBART [ LGG + 20 ]","-","-"],"associatedColumns":["En→Ro"],"associatedMergedColumns":["+"]}]},{"caption":"Setting \n\nPIQA ARC (Easy) \nARC (Challenge) OpenBookQA \n\nFine-tuned SOTA 79.4 \n92.0[KKS + 20] 78.5[KKS + 20] \n87.2[KKS + 20] \nGPT-3 Zero-Shot 80.5* 68.8 \n51.4 \n57.6 \nGPT-3 One-Shot \n80.5* 71.2 \n53.2 \n58.8 \nGPT-3 Few-Shot \n82.8* 70.1 \n51.5 \n65.4 \n\nTable 3.6: GPT-3 results on three commonsense reasoning tasks, PIQA, ARC, and OpenBookQA. GPT-3 Few-Shot \nPIQA result is evaluated on the test server. See Section 4 for details on potential contamination issues on the PIQA test \nset. \n\n","rows":["GPT - 3 Zero - Shot","GPT - 3 Few - Shot","Table","Fine - tuned SOTA","GPT - 3 One - Shot"],"columns":["ARC ( Challenge )","ARC ( Easy )","92 . 0 [ KKS + 20 ]","78 . 5 [ KKS","+","PIQA","20 ]","OpenBookQA","87 . 2 [ KKS"],"mergedAllColumns":[],"numberCells":[{"number":"65.4","isBolded":false,"associatedRows":["GPT - 3 Few - Shot"],"associatedColumns":["OpenBookQA","87 . 2 [ KKS"],"associatedMergedColumns":[]},{"number":"79.4","isBolded":false,"associatedRows":["Fine - tuned SOTA"],"associatedColumns":["PIQA"],"associatedMergedColumns":[]},{"number":"70.1","isBolded":false,"associatedRows":["GPT - 3 Few - Shot"],"associatedColumns":["ARC ( Easy )","92 . 0 [ KKS + 20 ]"],"associatedMergedColumns":[]},{"number":"53.2","isBolded":false,"associatedRows":["GPT - 3 One - Shot"],"associatedColumns":["ARC ( Challenge )","78 . 5 [ KKS"],"associatedMergedColumns":[]},{"number":"68.8","isBolded":false,"associatedRows":["GPT - 3 Zero - Shot"],"associatedColumns":["ARC ( Easy )","92 . 0 [ KKS + 20 ]"],"associatedMergedColumns":[]},{"number":"71.2","isBolded":false,"associatedRows":["GPT - 3 One - Shot"],"associatedColumns":["ARC ( Easy )","92 . 0 [ KKS + 20 ]"],"associatedMergedColumns":[]},{"number":"80.5*","isBolded":true,"associatedRows":["GPT - 3 Zero - Shot"],"associatedColumns":["PIQA","92 . 0 [ KKS + 20 ]"],"associatedMergedColumns":[]},{"number":"3.6:GPT-3resultsonthreecommonsensereasoningtasks,PIQA,ARC,andOpenBookQA.GPT-3Few-Shot","isBolded":true,"associatedRows":["Table"],"associatedColumns":["OpenBookQA","+","87 . 2 [ KKS","20 ]"],"associatedMergedColumns":[]},{"number":"51.4","isBolded":false,"associatedRows":["GPT - 3 Zero - Shot"],"associatedColumns":["ARC ( Challenge )","78 . 5 [ KKS"],"associatedMergedColumns":[]},{"number":"57.6","isBolded":false,"associatedRows":["GPT - 3 Zero - Shot"],"associatedColumns":["OpenBookQA","87 . 2 [ KKS"],"associatedMergedColumns":[]},{"number":"82.8*","isBolded":true,"associatedRows":["GPT - 3 Few - Shot"],"associatedColumns":["PIQA","92 . 0 [ KKS + 20 ]"],"associatedMergedColumns":[]},{"number":"80.5*","isBolded":true,"associatedRows":["GPT - 3 One - Shot"],"associatedColumns":["PIQA","92 . 0 [ KKS + 20 ]"],"associatedMergedColumns":[]},{"number":"51.5","isBolded":false,"associatedRows":["GPT - 3 Few - Shot"],"associatedColumns":["ARC ( Challenge )","78 . 5 [ KKS"],"associatedMergedColumns":[]},{"number":"58.8","isBolded":false,"associatedRows":["GPT - 3 One - Shot"],"associatedColumns":["OpenBookQA","87 . 2 [ KKS"],"associatedMergedColumns":[]}]},{"caption":"Setting \n\nCoQA DROP QuAC SQuADv2 RACE-h RACE-m \n\nFine-tuned SOTA 90.7 a \n89.1 b \n74.4 c \n93.0 d \n90.0 e \n93.1 e \nGPT-3 Zero-Shot 81.5 \n23.6 \n41.5 \n59.5 \n45.5 \n58.4 \nGPT-3 One-Shot \n84.0 \n34.3 \n43.3 \n65.4 \n45.9 \n57.4 \nGPT-3 Few-Shot \n85.0 \n36.5 \n44.3 \n69.8 \n46.8 \n58.1 \n\nTable 3.7: Results on reading comprehension tasks. All scores are F1 except results for RACE which report accuracy. \na [JZC + 19] b [JN20] c [AI19] d [QIA20] e [SPP + 19] \n\n","rows":["b","GPT - 3 Zero - Shot","c","GPT - 3 Few - Shot","Table","d","Fine - tuned SOTA","GPT - 3 One - Shot"],"columns":["QuAC","RACE - h","SQuADv2","CoQA","RACE - m","DROP"],"mergedAllColumns":["e"],"numberCells":[{"number":"93.0","isBolded":true,"associatedRows":["Fine - tuned SOTA","b","c"],"associatedColumns":["SQuADv2"],"associatedMergedColumns":[]},{"number":"90.0e","isBolded":true,"associatedRows":["Fine - tuned SOTA","b","c","d"],"associatedColumns":["RACE - h"],"associatedMergedColumns":[]},{"number":"43.3","isBolded":false,"associatedRows":["GPT - 3 One - Shot"],"associatedColumns":["QuAC"],"associatedMergedColumns":["e"]},{"number":"69.8","isBolded":false,"associatedRows":["GPT - 3 Few - Shot"],"associatedColumns":["SQuADv2"],"associatedMergedColumns":["e"]},{"number":"81.5","isBolded":false,"associatedRows":["GPT - 3 Zero - Shot"],"associatedColumns":["CoQA"],"associatedMergedColumns":["e"]},{"number":"23.6","isBolded":false,"associatedRows":["GPT - 3 Zero - Shot"],"associatedColumns":["DROP"],"associatedMergedColumns":["e"]},{"number":"85.0","isBolded":false,"associatedRows":["GPT - 3 Few - Shot"],"associatedColumns":["CoQA"],"associatedMergedColumns":["e"]},{"number":"58.1","isBolded":false,"associatedRows":["GPT - 3 Few - Shot"],"associatedColumns":["RACE - m"],"associatedMergedColumns":["e"]},{"number":"59.5","isBolded":false,"associatedRows":["GPT - 3 Zero - Shot"],"associatedColumns":["SQuADv2"],"associatedMergedColumns":["e"]},{"number":"44.3","isBolded":false,"associatedRows":["GPT - 3 Few - Shot"],"associatedColumns":["QuAC"],"associatedMergedColumns":["e"]},{"number":"3.7:Resultsonreadingcomprehensiontasks.AllscoresareF1exceptresultsforRACEwhichreportaccuracy.","isBolded":true,"associatedRows":["Table"],"associatedColumns":["RACE - m"],"associatedMergedColumns":["e"]},{"number":"34.3","isBolded":false,"associatedRows":["GPT - 3 One - Shot"],"associatedColumns":["DROP"],"associatedMergedColumns":["e"]},{"number":"45.5","isBolded":false,"associatedRows":["GPT - 3 Zero - Shot"],"associatedColumns":["RACE - h"],"associatedMergedColumns":["e"]},{"number":"45.9","isBolded":false,"associatedRows":["GPT - 3 One - Shot"],"associatedColumns":["RACE - h"],"associatedMergedColumns":["e"]},{"number":"74.4","isBolded":true,"associatedRows":["Fine - tuned SOTA","b"],"associatedColumns":["QuAC"],"associatedMergedColumns":[]},{"number":"90.7a","isBolded":true,"associatedRows":["Fine - tuned SOTA"],"associatedColumns":["CoQA"],"associatedMergedColumns":[]},{"number":"41.5","isBolded":false,"associatedRows":["GPT - 3 Zero - Shot"],"associatedColumns":["QuAC"],"associatedMergedColumns":["e"]},{"number":"84.0","isBolded":false,"associatedRows":["GPT - 3 One - Shot"],"associatedColumns":["CoQA"],"associatedMergedColumns":["e"]},{"number":"57.4","isBolded":false,"associatedRows":["GPT - 3 One - Shot"],"associatedColumns":["RACE - m"],"associatedMergedColumns":["e"]},{"number":"46.8","isBolded":false,"associatedRows":["GPT - 3 Few - Shot"],"associatedColumns":["RACE - h"],"associatedMergedColumns":["e"]},{"number":"89.1","isBolded":true,"associatedRows":["Fine - tuned SOTA"],"associatedColumns":["DROP"],"associatedMergedColumns":[]},{"number":"65.4","isBolded":false,"associatedRows":["GPT - 3 One - Shot"],"associatedColumns":["SQuADv2"],"associatedMergedColumns":["e"]},{"number":"93.1","isBolded":true,"associatedRows":["Fine - tuned SOTA","b","c","d"],"associatedColumns":["RACE - m"],"associatedMergedColumns":[]},{"number":"58.4","isBolded":false,"associatedRows":["GPT - 3 Zero - Shot"],"associatedColumns":["RACE - m"],"associatedMergedColumns":["e"]},{"number":"36.5","isBolded":false,"associatedRows":["GPT - 3 Few - Shot"],"associatedColumns":["DROP"],"associatedMergedColumns":["e"]}]},{"caption":"SuperGLUE \nBoolQ \nCB \nCB \nCOPA \nRTE \nAverage \nAccuracy Accuracy \nF1 \nAccuracy Accuracy \n\nFine-tuned SOTA \n89.0 \n91.0 \n96.9 \n93.9 \n94.8 \n92.5 \nFine-tuned BERT-Large \n69.0 \n77.4 \n83.6 \n75.7 \n70.6 \n71.7 \nGPT-3 Few-Shot \n71.8 \n76.4 \n75.6 \n52.0 \n92.0 \n69.0 \n\nWiC \nWSC \nMultiRC MultiRC ReCoRD ReCoRD \nAccuracy Accuracy Accuracy \nF1a \nAccuracy \nF1 \n\nFine-tuned SOTA \n76.1 \n93.8 \n62.3 \n88.2 \n92.5 \n93.3 \nFine-tuned BERT-Large \n69.6 \n64.6 \n24.1 \n70.0 \n71.3 \n72.0 \nGPT-3 Few-Shot \n49.4 \n80.1 \n30.5 \n75.4 \n90.2 \n91.1 \n\nTable 3.8: Performance of GPT-3 on SuperGLUE compared to fine-tuned baselines and SOTA. All results are reported \non the test set. GPT-3 few-shot is given a total of 32 examples within the context of each task and performs no gradient \nupdates. \n","rows":["Fine - tuned BERT - Large","GPT - 3 Few - Shot","Table","Fine - tuned SOTA"],"columns":["COPA","RTE","SuperGLUE","MultiRC","WSC","Average","F1","ReCoRD","WiC","BoolQ","Accuracy","F1a","CB"],"mergedAllColumns":[],"numberCells":[{"number":"30.5","isBolded":false,"associatedRows":["GPT - 3 Few - Shot"],"associatedColumns":["CB","Accuracy","MultiRC","Accuracy"],"associatedMergedColumns":[]},{"number":"71.8","isBolded":false,"associatedRows":["GPT - 3 Few - Shot"],"associatedColumns":["SuperGLUE","Average"],"associatedMergedColumns":[]},{"number":"72.0","isBolded":false,"associatedRows":["Fine - tuned BERT - Large"],"associatedColumns":["RTE","Accuracy","ReCoRD","F1"],"associatedMergedColumns":[]},{"number":"92.5","isBolded":true,"associatedRows":["Fine - tuned SOTA"],"associatedColumns":["RTE","Accuracy"],"associatedMergedColumns":[]},{"number":"83.6","isBolded":false,"associatedRows":["Fine - tuned BERT - Large"],"associatedColumns":["CB","Accuracy"],"associatedMergedColumns":[]},{"number":"89.0","isBolded":true,"associatedRows":["Fine - tuned SOTA"],"associatedColumns":["SuperGLUE","Average"],"associatedMergedColumns":[]},{"number":"62.3","isBolded":true,"associatedRows":["Fine - tuned SOTA"],"associatedColumns":["CB","Accuracy","MultiRC","Accuracy"],"associatedMergedColumns":[]},{"number":"71.3","isBolded":false,"associatedRows":["Fine - tuned BERT - Large"],"associatedColumns":["COPA","Accuracy","ReCoRD","Accuracy"],"associatedMergedColumns":[]},{"number":"69.0","isBolded":false,"associatedRows":["Fine - tuned BERT - Large"],"associatedColumns":["SuperGLUE","Average"],"associatedMergedColumns":[]},{"number":"76.1","isBolded":true,"associatedRows":["Fine - tuned SOTA"],"associatedColumns":["SuperGLUE","Average","WiC","Accuracy"],"associatedMergedColumns":[]},{"number":"77.4","isBolded":false,"associatedRows":["Fine - tuned BERT - Large"],"associatedColumns":["BoolQ","Accuracy"],"associatedMergedColumns":[]},{"number":"69.0","isBolded":false,"associatedRows":["GPT - 3 Few - Shot"],"associatedColumns":["RTE","Accuracy"],"associatedMergedColumns":[]},{"number":"49.4","isBolded":false,"associatedRows":["GPT - 3 Few - Shot"],"associatedColumns":["SuperGLUE","Average","WiC","Accuracy"],"associatedMergedColumns":[]},{"number":"75.7","isBolded":false,"associatedRows":["Fine - tuned BERT - Large"],"associatedColumns":["CB","F1"],"associatedMergedColumns":[]},{"number":"52.0","isBolded":false,"associatedRows":["GPT - 3 Few - Shot"],"associatedColumns":["CB","F1"],"associatedMergedColumns":[]},{"number":"93.3","isBolded":true,"associatedRows":["Fine - tuned SOTA"],"associatedColumns":["RTE","Accuracy","ReCoRD","F1"],"associatedMergedColumns":[]},{"number":"92.0","isBolded":false,"associatedRows":["GPT - 3 Few - Shot"],"associatedColumns":["COPA","Accuracy"],"associatedMergedColumns":[]},{"number":"70.0","isBolded":false,"associatedRows":["Fine - tuned BERT - Large"],"associatedColumns":["CB","F1","MultiRC","F1a"],"associatedMergedColumns":[]},{"number":"93.9","isBolded":true,"associatedRows":["Fine - tuned SOTA"],"associatedColumns":["CB","F1"],"associatedMergedColumns":[]},{"number":"70.6","isBolded":false,"associatedRows":["Fine - tuned BERT - Large"],"associatedColumns":["COPA","Accuracy"],"associatedMergedColumns":[]},{"number":"93.8","isBolded":true,"associatedRows":["Fine - tuned SOTA"],"associatedColumns":["BoolQ","Accuracy","WSC","Accuracy"],"associatedMergedColumns":[]},{"number":"90.2","isBolded":false,"associatedRows":["GPT - 3 Few - Shot"],"associatedColumns":["COPA","Accuracy","ReCoRD","Accuracy"],"associatedMergedColumns":[]},{"number":"76.4","isBolded":false,"associatedRows":["GPT - 3 Few - Shot"],"associatedColumns":["BoolQ","Accuracy"],"associatedMergedColumns":[]},{"number":"80.1","isBolded":false,"associatedRows":["GPT - 3 Few - Shot"],"associatedColumns":["BoolQ","Accuracy","WSC","Accuracy"],"associatedMergedColumns":[]},{"number":"96.9","isBolded":true,"associatedRows":["Fine - tuned SOTA"],"associatedColumns":["CB","Accuracy"],"associatedMergedColumns":[]},{"number":"64.6","isBolded":false,"associatedRows":["Fine - tuned BERT - Large"],"associatedColumns":["BoolQ","Accuracy","WSC","Accuracy"],"associatedMergedColumns":[]},{"number":"24.1","isBolded":false,"associatedRows":["Fine - tuned BERT - Large"],"associatedColumns":["CB","Accuracy","MultiRC","Accuracy"],"associatedMergedColumns":[]},{"number":"3.8:PerformanceofGPT-3onSuperGLUEcomparedtofine-tunedbaselinesandSOTA.Allresultsarereported","isBolded":true,"associatedRows":["Table"],"associatedColumns":["RTE","Accuracy","ReCoRD","F1"],"associatedMergedColumns":[]},{"number":"69.6","isBolded":false,"associatedRows":["Fine - tuned BERT - Large"],"associatedColumns":["SuperGLUE","Average","WiC","Accuracy"],"associatedMergedColumns":[]},{"number":"92.5","isBolded":true,"associatedRows":["Fine - tuned SOTA"],"associatedColumns":["COPA","Accuracy","ReCoRD","Accuracy"],"associatedMergedColumns":[]},{"number":"91.0","isBolded":true,"associatedRows":["Fine - tuned SOTA"],"associatedColumns":["BoolQ","Accuracy"],"associatedMergedColumns":[]},{"number":"75.6","isBolded":false,"associatedRows":["GPT - 3 Few - Shot"],"associatedColumns":["CB","Accuracy"],"associatedMergedColumns":[]},{"number":"94.8","isBolded":true,"associatedRows":["Fine - tuned SOTA"],"associatedColumns":["COPA","Accuracy"],"associatedMergedColumns":[]},{"number":"75.4","isBolded":false,"associatedRows":["GPT - 3 Few - Shot"],"associatedColumns":["CB","F1","MultiRC","F1a"],"associatedMergedColumns":[]},{"number":"91.1","isBolded":false,"associatedRows":["GPT - 3 Few - Shot"],"associatedColumns":["RTE","Accuracy","ReCoRD","F1"],"associatedMergedColumns":[]},{"number":"71.7","isBolded":false,"associatedRows":["Fine - tuned BERT - Large"],"associatedColumns":["RTE","Accuracy"],"associatedMergedColumns":[]},{"number":"88.2","isBolded":true,"associatedRows":["Fine - tuned SOTA"],"associatedColumns":["CB","F1","MultiRC","F1a"],"associatedMergedColumns":[]}]},{"caption":"Table 3.9: Results on basic arithmetic tasks for GPT-3 175B. {2,3,4,5}D{+,-} is 2, 3, 4, and 5 digit addition or \nsubtraction, 2Dx is 2 digit multiplication. 1DC is 1 digit composite operations. Results become progressively stronger \nmoving from the zero-shot to one-shot to few-shot setting, but even the zero-shot shows significant arithmetic abilities. \n\n","rows":["GPT - 3 One - shot","Zero - shot","Table","GPT - 3 Few - shot"],"columns":["4D - 5D+","1DC","3D - 4D+","5D - 2Dx","2D+","2D - 3D+"],"mergedAllColumns":[],"numberCells":[{"number":"100.0","isBolded":false,"associatedRows":["GPT - 3 Few - shot"],"associatedColumns":["2D+"],"associatedMergedColumns":[]},{"number":"98.9","isBolded":false,"associatedRows":["GPT - 3 Few - shot"],"associatedColumns":["2D - 3D+"],"associatedMergedColumns":[]},{"number":"3.9:ResultsonbasicarithmetictasksforGPT-3175B.{2,3,4,5}D{+,-}is2,3,4,and5digitadditionor","isBolded":true,"associatedRows":["Table"],"associatedColumns":["1DC"],"associatedMergedColumns":[]},{"number":"14.0","isBolded":false,"associatedRows":["GPT - 3 One - shot"],"associatedColumns":["4D - 5D+"],"associatedMergedColumns":[]},{"number":"25.5","isBolded":false,"associatedRows":["GPT - 3 Few - shot"],"associatedColumns":["3D - 4D+"],"associatedMergedColumns":[]},{"number":"0.8","isBolded":false,"associatedRows":["GPT - 3 One - shot","Zero - shot"],"associatedColumns":["5D - 2Dx"],"associatedMergedColumns":[]},{"number":"9.3","isBolded":false,"associatedRows":["GPT - 3 Few - shot"],"associatedColumns":["4D - 5D+"],"associatedMergedColumns":[]},{"number":"58.0","isBolded":false,"associatedRows":["GPT - 3 One - shot","Zero - shot"],"associatedColumns":["2D - 3D+"],"associatedMergedColumns":[]},{"number":"19.8","isBolded":false,"associatedRows":["GPT - 3 One - shot","Zero - shot"],"associatedColumns":["5D - 2Dx"],"associatedMergedColumns":[]},{"number":"4.0","isBolded":false,"associatedRows":["GPT - 3 One - shot","Zero - shot"],"associatedColumns":["3D - 4D+"],"associatedMergedColumns":[]},{"number":"94.2","isBolded":false,"associatedRows":["GPT - 3 Few - shot"],"associatedColumns":["3D - 4D+"],"associatedMergedColumns":[]},{"number":"76.9","isBolded":false,"associatedRows":["GPT - 3 One - shot","Zero - shot"],"associatedColumns":["2D+"],"associatedMergedColumns":[]},{"number":"14.0","isBolded":false,"associatedRows":["GPT - 3 One - shot"],"associatedColumns":["3D - 4D+"],"associatedMergedColumns":[]},{"number":"99.6","isBolded":false,"associatedRows":["GPT - 3 One - shot"],"associatedColumns":["2D+"],"associatedMergedColumns":[]},{"number":"27.4","isBolded":false,"associatedRows":["GPT - 3 One - shot"],"associatedColumns":["5D - 2Dx"],"associatedMergedColumns":[]},{"number":"7.5","isBolded":false,"associatedRows":["GPT - 3 One - shot","Zero - shot"],"associatedColumns":["4D - 5D+"],"associatedMergedColumns":[]},{"number":"3.5","isBolded":false,"associatedRows":["GPT - 3 One - shot"],"associatedColumns":["4D - 5D+"],"associatedMergedColumns":[]},{"number":"3.8","isBolded":false,"associatedRows":["GPT - 3 One - shot"],"associatedColumns":["5D - 2Dx"],"associatedMergedColumns":[]},{"number":"14.3","isBolded":false,"associatedRows":["GPT - 3 One - shot"],"associatedColumns":["1DC"],"associatedMergedColumns":[]},{"number":"9.8","isBolded":false,"associatedRows":["GPT - 3 Few - shot","Zero - shot"],"associatedColumns":["1DC"],"associatedMergedColumns":[]},{"number":"78.7","isBolded":false,"associatedRows":["GPT - 3 One - shot"],"associatedColumns":["3D - 4D+"],"associatedMergedColumns":[]},{"number":"48.3","isBolded":false,"associatedRows":["GPT - 3 One - shot","Zero - shot"],"associatedColumns":["3D - 4D+"],"associatedMergedColumns":[]},{"number":"80.4","isBolded":false,"associatedRows":["GPT - 3 Few - shot"],"associatedColumns":["2D - 3D+"],"associatedMergedColumns":[]},{"number":"34.2","isBolded":false,"associatedRows":["GPT - 3 One - shot","Zero - shot"],"associatedColumns":["2D - 3D+"],"associatedMergedColumns":[]},{"number":"0.7","isBolded":false,"associatedRows":["GPT - 3 One - shot","Zero - shot"],"associatedColumns":["4D - 5D+"],"associatedMergedColumns":[]},{"number":"65.5","isBolded":false,"associatedRows":["GPT - 3 One - shot"],"associatedColumns":["2D - 3D+"],"associatedMergedColumns":[]},{"number":"21.3","isBolded":false,"associatedRows":["GPT - 3 Few - shot"],"associatedColumns":["1DC"],"associatedMergedColumns":[]},{"number":"26.8","isBolded":false,"associatedRows":["GPT - 3 Few - shot"],"associatedColumns":["4D - 5D+"],"associatedMergedColumns":[]},{"number":"86.4","isBolded":false,"associatedRows":["GPT - 3 One - shot"],"associatedColumns":["2D - 3D+"],"associatedMergedColumns":[]},{"number":"29.2","isBolded":false,"associatedRows":["GPT - 3 Few - shot"],"associatedColumns":["5D - 2Dx"],"associatedMergedColumns":[]},{"number":"9.9","isBolded":false,"associatedRows":["GPT - 3 Few - shot"],"associatedColumns":["5D - 2Dx"],"associatedMergedColumns":[]}]},{"caption":"Table 3.10: GPT-3 175B performance on various word unscrambling and word manipulation tasks, in zero-, one-, and \nfew-shot settings. CL is \"cycle letters in word\", A1 is anagrams of but the first and last letters, A2 is anagrams of all but \nthe first and last two letters, RI is \"Random insertion in word\", RW is \"reversed words\". \n\n","rows":["Table","GPT - 3 Few - shot"],"columns":[],"mergedAllColumns":[],"numberCells":[{"number":"67.2","isBolded":false,"associatedRows":["GPT - 3 Few - shot"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"15.1","isBolded":false,"associatedRows":["GPT - 3 Few - shot"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"39.7","isBolded":false,"associatedRows":["GPT - 3 Few - shot"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"3.10:GPT-3175Bperformanceonvariouswordunscramblingandwordmanipulationtasks,inzero-,one-,and","isBolded":true,"associatedRows":["Table"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"0.44","isBolded":false,"associatedRows":["GPT - 3 Few - shot"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"37.9","isBolded":false,"associatedRows":["GPT - 3 Few - shot"],"associatedColumns":[],"associatedMergedColumns":[]}]},{"caption":"Table 3.9, and \nmodel capacity scaling for all three settings is shown in Appendix H. \n\n","rows":["Table","GPT - 3 Few - shot"],"columns":[],"mergedAllColumns":[],"numberCells":[{"number":"37.9","isBolded":false,"associatedRows":["GPT - 3 Few - shot"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"3.10:GPT-3175Bperformanceonvariouswordunscramblingandwordmanipulationtasks,inzero-,one-,and","isBolded":true,"associatedRows":["Table"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"0.44","isBolded":false,"associatedRows":["GPT - 3 Few - shot"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"39.7","isBolded":false,"associatedRows":["GPT - 3 Few - shot"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"15.1","isBolded":false,"associatedRows":["GPT - 3 Few - shot"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"67.2","isBolded":false,"associatedRows":["GPT - 3 Few - shot"],"associatedColumns":[],"associatedMergedColumns":[]}]},{"caption":"Table 3.11: Human accuracy in identifying whether short (∼200 word) news articles are model generated. We \nfind that human accuracy (measured by the ratio of correct assignments to non-neutral assignments) ranges from 86% \non the control model to 52% on GPT-3 175B. This table compares mean accuracy between five different models, and \nshows the results of a two-sample T-Test for the difference in mean accuracy between each model and the control model \n(an unconditional GPT-3 Small model with increased output randomness). \n\n","rows":["find that human accuracy ( measured by the ratio of correct assignments to non - neutral assignments ) ranges from","Table","49% - 54%","GPT - 3 175B","on the control model to"],"columns":[],"mergedAllColumns":[],"numberCells":[{"number":"16.9(1e-34)","isBolded":false,"associatedRows":["GPT - 3 175B","49% - 54%"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"3.11:Humanaccuracyinidentifyingwhethershort(∼200word)newsarticlesaremodelgenerated.We","isBolded":true,"associatedRows":["Table"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"52%onGPT-3175B.Thistablecomparesmeanaccuracybetweenfivedifferentmodels,and","isBolded":false,"associatedRows":["on the control model to"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"86%","isBolded":false,"associatedRows":["find that human accuracy ( measured by the ratio of correct assignments to non - neutral assignments ) ranges from"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"52%","isBolded":false,"associatedRows":["GPT - 3 175B"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"7.8%","isBolded":false,"associatedRows":["GPT - 3 175B","49% - 54%"],"associatedColumns":[],"associatedMergedColumns":[]}]},{"caption":"Mean accuracy \n\n95% Confidence \nInterval (low, hi) \n\nt compared to \ncontrol (p-value) \n\n\"I don\u0027t know\" \nassignments \n\nControl \n88% \n84%-91% \n-\n2.7% \nGPT-3 175B \n52% \n48%-57% \n12.7 (3.2e-23) \n10.6% \n\nTable 3.12: People\u0027s ability to identify whether ∼ 500 word articles are model generated (as measured by the ratio of \ncorrect assignments to non-neutral assignments) was 88% on the control model and 52% on GPT-3 175B. This table \nshows the results of a two-sample T-Test for the difference in mean accuracy between GPT-3 175B and the control \nmodel (an unconditional GPT-3 Small model with increased output randomness). \n","rows":["Control","48% - 57%","84% - 91%","Table","correct assignments to non - neutral assignments ) was","GPT - 3 175B","-"],"columns":["Mean accuracy","Interval ( low , hi )","\" I don \u0027 t know \"","assignments","t compared to","control ( p - value )"],"mergedAllColumns":[],"numberCells":[{"number":"3.12:People\u0027sabilitytoidentifywhether∼500wordarticlesaremodelgenerated(asmeasuredbytheratioof","isBolded":true,"associatedRows":["Table"],"associatedColumns":["t compared to","\" I don \u0027 t know \"","assignments"],"associatedMergedColumns":[]},{"number":"88%","isBolded":false,"associatedRows":["Control"],"associatedColumns":["t compared to","Mean accuracy"],"associatedMergedColumns":[]},{"number":"52%onGPT-3175B.Thistable","isBolded":false,"associatedRows":["correct assignments to non - neutral assignments ) was","48% - 57%"],"associatedColumns":["\" I don \u0027 t know \"","assignments"],"associatedMergedColumns":[]},{"number":"2.7%","isBolded":false,"associatedRows":["Control","84% - 91%","-"],"associatedColumns":["\" I don \u0027 t know \"","assignments"],"associatedMergedColumns":[]},{"number":"12.7(3.2e-23)","isBolded":false,"associatedRows":["GPT - 3 175B","48% - 57%"],"associatedColumns":["t compared to","control ( p - value )"],"associatedMergedColumns":[]},{"number":"95%Confidence","isBolded":false,"associatedRows":["GPT - 3 175B"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"52%","isBolded":false,"associatedRows":["GPT - 3 175B"],"associatedColumns":["t compared to","Mean accuracy"],"associatedMergedColumns":[]},{"number":"10.6%","isBolded":false,"associatedRows":["GPT - 3 175B","48% - 57%"],"associatedColumns":["\" I don \u0027 t know \"","assignments"],"associatedMergedColumns":[]},{"number":"88%onthecontrolmodeland","isBolded":false,"associatedRows":["correct assignments to non - neutral assignments ) was"],"associatedColumns":["t compared to","Interval ( low , hi )"],"associatedMergedColumns":[]}]}]