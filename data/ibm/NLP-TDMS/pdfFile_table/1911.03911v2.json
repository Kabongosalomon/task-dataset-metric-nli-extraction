[{"caption":"Table 2: Core statistics regarding released dataset. \n\n","rows":["Documents annotated","Mean clause length ( words )"],"columns":["Statistic","24 , 284","21"],"mergedAllColumns":[],"numberCells":[{"number":"586","isBolded":false,"associatedRows":["Documents annotated"],"associatedColumns":["Statistic"],"associatedMergedColumns":[]},{"number":"110","isBolded":false,"associatedRows":["Mean clause length ( words )"],"associatedColumns":["Statistic","24 , 284","21"],"associatedMergedColumns":[]}]},{"caption":"Table 7. ","rows":["1 - 3","1 - 2","−","+","1 - 1"],"columns":["Soft F1"],"mergedAllColumns":[],"numberCells":[{"number":"0.38","isBolded":true,"associatedRows":["1 - 2","+"],"associatedColumns":["Soft F1"],"associatedMergedColumns":[]},{"number":"0.36","isBolded":false,"associatedRows":["1 - 1","+"],"associatedColumns":["Soft F1"],"associatedMergedColumns":[]},{"number":"0.32","isBolded":false,"associatedRows":["1 - 1","−"],"associatedColumns":["Soft F1"],"associatedMergedColumns":[]},{"number":"0.36","isBolded":false,"associatedRows":["1 - 3","−"],"associatedColumns":["Soft F1"],"associatedMergedColumns":[]},{"number":"0.35","isBolded":false,"associatedRows":["1 - 2","−"],"associatedColumns":["Soft F1"],"associatedMergedColumns":[]},{"number":"0.37","isBolded":false,"associatedRows":["1 - 3","+"],"associatedColumns":["Soft F1"],"associatedMergedColumns":[]}]},{"caption":"Table 5: Results of Sentence-BERT models on the test-\nA dataset when returning the most similar sentence. \nNames as in sentence-transformers library: https:// \n\ngithub.com/UKPLab/sentence-transformers \n\nRange (n-grams) \nBinary \nSoft F1 \n\n1-1 \n− \n0.32 \n1-2 \n− \n0.35 \n1-3 \n− \n0.36 \n1-1 \n+ \n0.36 \n1-2 \n+ \n0.38 \n1-3 \n+ \n0.37 \n\n","rows":["bert - base - cased","bert - large - uncased","gpt2 - medium","bert - base - multilingual - uncased","bert - large - cased - whole - word - masking","bert - base - multilingual - cased","gpt2","bert - large - cased","bert - base - uncased","gpt2 - large","roberta - base"],"columns":["Soft F1"],"mergedAllColumns":["openai - gpt","roberta - large","bert - large - uncased - whole - word - masking"],"numberCells":[{"number":"0.31","isBolded":false,"associatedRows":["bert - large - cased - whole - word - masking"],"associatedColumns":["Soft F1"],"associatedMergedColumns":[]},{"number":"0.18","isBolded":false,"associatedRows":["bert - large - uncased"],"associatedColumns":["Soft F1"],"associatedMergedColumns":[]},{"number":"0.24","isBolded":false,"associatedRows":["bert - base - multilingual - cased"],"associatedColumns":["Soft F1"],"associatedMergedColumns":[]},{"number":"0.26","isBolded":false,"associatedRows":["bert - base - uncased"],"associatedColumns":["Soft F1"],"associatedMergedColumns":[]},{"number":"0.25","isBolded":false,"associatedRows":["bert - base - cased"],"associatedColumns":["Soft F1"],"associatedMergedColumns":[]},{"number":"0.32","isBolded":false,"associatedRows":["bert - large - cased - whole - word - masking"],"associatedColumns":["Soft F1"],"associatedMergedColumns":["bert - large - uncased - whole - word - masking"]},{"number":"0.16","isBolded":false,"associatedRows":["gpt2"],"associatedColumns":["Soft F1"],"associatedMergedColumns":["openai - gpt"]},{"number":"0.36","isBolded":false,"associatedRows":["bert - large - cased - whole - word - masking"],"associatedColumns":["Soft F1"],"associatedMergedColumns":["roberta - large"]},{"number":"0.32","isBolded":false,"associatedRows":["bert - base - multilingual - uncased"],"associatedColumns":["Soft F1"],"associatedMergedColumns":[]},{"number":"0.25","isBolded":false,"associatedRows":["roberta - base"],"associatedColumns":["Soft F1"],"associatedMergedColumns":["bert - large - uncased - whole - word - masking"]},{"number":"0.21","isBolded":false,"associatedRows":["bert - large - cased"],"associatedColumns":["Soft F1"],"associatedMergedColumns":[]},{"number":"0.41","isBolded":true,"associatedRows":["gpt2 - large"],"associatedColumns":["Soft F1"],"associatedMergedColumns":["openai - gpt"]},{"number":"0.35","isBolded":false,"associatedRows":["bert - large - cased - whole - word - masking"],"associatedColumns":["Soft F1"],"associatedMergedColumns":[]},{"number":"0.11","isBolded":false,"associatedRows":["gpt2 - medium"],"associatedColumns":["Soft F1"],"associatedMergedColumns":["openai - gpt"]}]},{"caption":"Table 6: Results of TF-IDF on the test-A dataset when \nreturning the most similar sentence. \n\n","rows":["multilingual - qa / 1","multilingual - large / 1","large / 3","multilingual / 1"],"columns":["Soft F1"],"mergedAllColumns":[],"numberCells":[{"number":"0.26","isBolded":false,"associatedRows":["large / 3"],"associatedColumns":["Soft F1"],"associatedMergedColumns":[]},{"number":"0.33","isBolded":false,"associatedRows":["multilingual - large / 1"],"associatedColumns":["Soft F1"],"associatedMergedColumns":[]},{"number":"0.38","isBolded":true,"associatedRows":["multilingual / 1"],"associatedColumns":["Soft F1"],"associatedMergedColumns":[]},{"number":"0.28","isBolded":false,"associatedRows":["multilingual - qa / 1"],"associatedColumns":["Soft F1"],"associatedMergedColumns":[]}]},{"caption":"Table 7: Results of Universal Sentence Encoder models \non the test-A dataset when returning the most similar \nsentence. \n\n","rows":["bert - base - cased","bert - large - uncased","gpt2 - medium","bert - base - multilingual - uncased","bert - large - cased - whole - word - masking","bert - base - multilingual - cased","gpt2","bert - large - cased","bert - base - uncased","gpt2 - large","roberta - base"],"columns":["Soft F1"],"mergedAllColumns":["openai - gpt","roberta - large","bert - large - uncased - whole - word - masking"],"numberCells":[{"number":"0.11","isBolded":false,"associatedRows":["gpt2 - medium"],"associatedColumns":["Soft F1"],"associatedMergedColumns":["openai - gpt"]},{"number":"0.32","isBolded":false,"associatedRows":["bert - base - multilingual - uncased"],"associatedColumns":["Soft F1"],"associatedMergedColumns":[]},{"number":"0.36","isBolded":false,"associatedRows":["bert - large - cased - whole - word - masking"],"associatedColumns":["Soft F1"],"associatedMergedColumns":["roberta - large"]},{"number":"0.21","isBolded":false,"associatedRows":["bert - large - cased"],"associatedColumns":["Soft F1"],"associatedMergedColumns":[]},{"number":"0.25","isBolded":false,"associatedRows":["roberta - base"],"associatedColumns":["Soft F1"],"associatedMergedColumns":["bert - large - uncased - whole - word - masking"]},{"number":"0.25","isBolded":false,"associatedRows":["bert - base - cased"],"associatedColumns":["Soft F1"],"associatedMergedColumns":[]},{"number":"0.35","isBolded":false,"associatedRows":["bert - large - cased - whole - word - masking"],"associatedColumns":["Soft F1"],"associatedMergedColumns":[]},{"number":"0.32","isBolded":false,"associatedRows":["bert - large - cased - whole - word - masking"],"associatedColumns":["Soft F1"],"associatedMergedColumns":["bert - large - uncased - whole - word - masking"]},{"number":"0.24","isBolded":false,"associatedRows":["bert - base - multilingual - cased"],"associatedColumns":["Soft F1"],"associatedMergedColumns":[]},{"number":"0.18","isBolded":false,"associatedRows":["bert - large - uncased"],"associatedColumns":["Soft F1"],"associatedMergedColumns":[]},{"number":"0.26","isBolded":false,"associatedRows":["bert - base - uncased"],"associatedColumns":["Soft F1"],"associatedMergedColumns":[]},{"number":"0.31","isBolded":false,"associatedRows":["bert - large - cased - whole - word - masking"],"associatedColumns":["Soft F1"],"associatedMergedColumns":[]},{"number":"0.16","isBolded":false,"associatedRows":["gpt2"],"associatedColumns":["Soft F1"],"associatedMergedColumns":["openai - gpt"]},{"number":"0.41","isBolded":true,"associatedRows":["gpt2 - large"],"associatedColumns":["Soft F1"],"associatedMergedColumns":["openai - gpt"]}]},{"caption":"Table 8: Results of particular Transformer-based Lan-\nguage Models (without finetuning) on the test-A dataset \nwhen returning the most similar sentence. Names as in \ntransformers library: https://github.com/huggi \n\nngface/transformers \n\nC \nSoft F1 \n\nc 0 \n0.36 \nc 0:1 \n0.30 \nc 0:2 \n0.25 \nc 0:3 \n0.20 \nc 0:4 \n0.18 \n\n","rows":["bert - base - cased","bert - large - uncased","gpt2 - medium","bert - base - multilingual - uncased","bert - large - cased - whole - word - masking","bert - base - multilingual - cased","gpt2","bert - large - cased","bert - base - uncased","gpt2 - large","roberta - base"],"columns":["Soft F1"],"mergedAllColumns":["openai - gpt","roberta - large","bert - large - uncased - whole - word - masking"],"numberCells":[{"number":"0.35","isBolded":false,"associatedRows":["bert - large - cased - whole - word - masking"],"associatedColumns":["Soft F1"],"associatedMergedColumns":[]},{"number":"0.24","isBolded":false,"associatedRows":["bert - base - multilingual - cased"],"associatedColumns":["Soft F1"],"associatedMergedColumns":[]},{"number":"0.32","isBolded":false,"associatedRows":["bert - base - multilingual - uncased"],"associatedColumns":["Soft F1"],"associatedMergedColumns":[]},{"number":"0.31","isBolded":false,"associatedRows":["bert - large - cased - whole - word - masking"],"associatedColumns":["Soft F1"],"associatedMergedColumns":[]},{"number":"0.16","isBolded":false,"associatedRows":["gpt2"],"associatedColumns":["Soft F1"],"associatedMergedColumns":["openai - gpt"]},{"number":"0.21","isBolded":false,"associatedRows":["bert - large - cased"],"associatedColumns":["Soft F1"],"associatedMergedColumns":[]},{"number":"0.18","isBolded":false,"associatedRows":["bert - large - uncased"],"associatedColumns":["Soft F1"],"associatedMergedColumns":[]},{"number":"0.36","isBolded":false,"associatedRows":["bert - large - cased - whole - word - masking"],"associatedColumns":["Soft F1"],"associatedMergedColumns":["roberta - large"]},{"number":"0.26","isBolded":false,"associatedRows":["bert - base - uncased"],"associatedColumns":["Soft F1"],"associatedMergedColumns":[]},{"number":"0.41","isBolded":true,"associatedRows":["gpt2 - large"],"associatedColumns":["Soft F1"],"associatedMergedColumns":["openai - gpt"]},{"number":"0.32","isBolded":false,"associatedRows":["bert - large - cased - whole - word - masking"],"associatedColumns":["Soft F1"],"associatedMergedColumns":["bert - large - uncased - whole - word - masking"]},{"number":"0.11","isBolded":false,"associatedRows":["gpt2 - medium"],"associatedColumns":["Soft F1"],"associatedMergedColumns":["openai - gpt"]},{"number":"0.25","isBolded":false,"associatedRows":["roberta - base"],"associatedColumns":["Soft F1"],"associatedMergedColumns":["bert - large - uncased - whole - word - masking"]},{"number":"0.25","isBolded":false,"associatedRows":["bert - base - cased"],"associatedColumns":["Soft F1"],"associatedMergedColumns":[]}]},{"caption":"Table 9: Results of GloVe embeddings (300d, EDGAR) \non the test-A dataset when Discrete Cosine Transform \nsentence embeddings were created. The c 0 is equiva-\nlent to embeddings mean when k-NN methods are con-\nsidered. The similar decrease of performance was ob-\nserved for other models. \n\n","rows":["c 0","c 0 : 4","c 0 : 3","c 0 : 2","c 0 : 1"],"columns":["Table 8 : Results of particular Transformer - based Lan -","Soft F1"],"mergedAllColumns":["ngface / transformers"],"numberCells":[{"number":"0.30","isBolded":false,"associatedRows":["c 0 : 1"],"associatedColumns":["Table 8 : Results of particular Transformer - based Lan -","Soft F1"],"associatedMergedColumns":["ngface / transformers"]},{"number":"0.36","isBolded":true,"associatedRows":["c 0"],"associatedColumns":["Table 8 : Results of particular Transformer - based Lan -","Soft F1"],"associatedMergedColumns":["ngface / transformers"]},{"number":"0.25","isBolded":false,"associatedRows":["c 0 : 2"],"associatedColumns":["Table 8 : Results of particular Transformer - based Lan -","Soft F1"],"associatedMergedColumns":["ngface / transformers"]},{"number":"0.18","isBolded":false,"associatedRows":["c 0 : 4"],"associatedColumns":["Table 8 : Results of particular Transformer - based Lan -","Soft F1"],"associatedMergedColumns":["ngface / transformers"]},{"number":"0.20","isBolded":false,"associatedRows":["c 0 : 3"],"associatedColumns":["Table 8 : Results of particular Transformer - based Lan -","Soft F1"],"associatedMergedColumns":["ngface / transformers"]}]}]