[{"caption":"Table 1: Training and Pre-training the model on the train split and evaluate \nthe performance on the validation split on the given dataset. \u0027finetune fc\u0027 stands \nfor train a linear classifier on top of the pretrained representation, \u0027finetune\u0027 \nstands for train the weight of the whole model. Our proposed pipeline (Phase-1 \n+ Phase-2) can have 16.7 performance gain in top-1 validation accuracy. \n\n","rows":["100","4096","MoCo v2 [ 7 ]","Supervised Training","256","Phase - 1 + finetune fc","1024","800","Margin loss","-","Phase - 1 + finetune"],"columns":["#Pretrain Epoch #Finetune Epoch Val Acc"],"mergedAllColumns":["#Neg Margin Val Acc"],"numberCells":[{"number":"0.4","isBolded":false,"associatedRows":["Phase - 1 + finetune","Margin loss","4096"],"associatedColumns":["#Pretrain Epoch #Finetune Epoch Val Acc"],"associatedMergedColumns":["#Neg Margin Val Acc"]},{"number":"0.4","isBolded":false,"associatedRows":["Phase - 1 + finetune","Margin loss","256"],"associatedColumns":["#Pretrain Epoch #Finetune Epoch Val Acc"],"associatedMergedColumns":["#Neg Margin Val Acc"]},{"number":"34.6","isBolded":false,"associatedRows":["Phase - 1 + finetune","Margin loss","4096","-"],"associatedColumns":["#Pretrain Epoch #Finetune Epoch Val Acc"],"associatedMergedColumns":["#Neg Margin Val Acc"]},{"number":"34.5","isBolded":false,"associatedRows":["Phase - 1 + finetune fc","MoCo v2 [ 7 ]","800","-","100"],"associatedColumns":["#Pretrain Epoch #Finetune Epoch Val Acc"],"associatedMergedColumns":[]},{"number":"27.9","isBolded":false,"associatedRows":["Supervised Training","MoCo v2 [ 7 ]","-","-","100"],"associatedColumns":["#Pretrain Epoch #Finetune Epoch Val Acc"],"associatedMergedColumns":[]},{"number":"32.1","isBolded":false,"associatedRows":["Phase - 1 + finetune","MoCo v2 [ 7 ]","1024","-"],"associatedColumns":["#Pretrain Epoch #Finetune Epoch Val Acc"],"associatedMergedColumns":["#Neg Margin Val Acc"]},{"number":"33.7","isBolded":false,"associatedRows":["Phase - 1 + finetune","Margin loss","256","-"],"associatedColumns":["#Pretrain Epoch #Finetune Epoch Val Acc"],"associatedMergedColumns":["#Neg Margin Val Acc"]},{"number":"39.4","isBolded":false,"associatedRows":["Phase - 1 + finetune","MoCo v2 [ 7 ]","800","-","100"],"associatedColumns":["#Pretrain Epoch #Finetune Epoch Val Acc"],"associatedMergedColumns":[]},{"number":"44.6","isBolded":false,"associatedRows":["Phase - 1 + finetune fc","MoCo v2 [ 7 ]","800","-","100"],"associatedColumns":["#Pretrain Epoch #Finetune Epoch Val Acc"],"associatedMergedColumns":[]},{"number":"34.2","isBolded":false,"associatedRows":["Phase - 1 + finetune","Margin loss","1024","-"],"associatedColumns":["#Pretrain Epoch #Finetune Epoch Val Acc"],"associatedMergedColumns":["#Neg Margin Val Acc"]},{"number":"0.4","isBolded":false,"associatedRows":["Phase - 1 + finetune","Margin loss","1024"],"associatedColumns":["#Pretrain Epoch #Finetune Epoch Val Acc"],"associatedMergedColumns":["#Neg Margin Val Acc"]},{"number":"29.1","isBolded":false,"associatedRows":["Phase - 1 + finetune","MoCo v2 [ 7 ]","256","-"],"associatedColumns":["#Pretrain Epoch #Finetune Epoch Val Acc"],"associatedMergedColumns":["#Neg Margin Val Acc"]},{"number":"34.5","isBolded":false,"associatedRows":["Phase - 1 + finetune","MoCo v2 [ 7 ]","4096","-"],"associatedColumns":["#Pretrain Epoch #Finetune Epoch Val Acc"],"associatedMergedColumns":["#Neg Margin Val Acc"]}]},{"caption":"Table 2: The Val Acc means the linear classification accuracy obtained by fine-\ntune a linear classifier on top of the learned representation. The original MoCo \nv2 is sensitive to the number of negative, the performance drops drastically \nwhen number negatives is small. Our modified margin loss is less sensitive to \nthe number negatives, as shown in the table, even has 16x less negatives the \nperformance only drops 0.9. \n\n","rows":["4096","MoCo v2 [ 7 ]","256","1024","Margin loss","-"],"columns":["#Neg Margin Val Acc"],"mergedAllColumns":[],"numberCells":[{"number":"34.2","isBolded":false,"associatedRows":["Margin loss","1024","-"],"associatedColumns":["#Neg Margin Val Acc"],"associatedMergedColumns":[]},{"number":"32.1","isBolded":false,"associatedRows":["MoCo v2 [ 7 ]","1024","-"],"associatedColumns":["#Neg Margin Val Acc"],"associatedMergedColumns":[]},{"number":"0.4","isBolded":false,"associatedRows":["Margin loss","1024"],"associatedColumns":["#Neg Margin Val Acc"],"associatedMergedColumns":[]},{"number":"0.4","isBolded":false,"associatedRows":["Margin loss","4096"],"associatedColumns":["#Neg Margin Val Acc"],"associatedMergedColumns":[]},{"number":"33.7","isBolded":false,"associatedRows":["Margin loss","256","-"],"associatedColumns":["#Neg Margin Val Acc"],"associatedMergedColumns":[]},{"number":"34.5","isBolded":false,"associatedRows":["MoCo v2 [ 7 ]","4096","-"],"associatedColumns":["#Neg Margin Val Acc"],"associatedMergedColumns":[]},{"number":"0.4","isBolded":false,"associatedRows":["Margin loss","256"],"associatedColumns":["#Neg Margin Val Acc"],"associatedMergedColumns":[]},{"number":"29.1","isBolded":false,"associatedRows":["MoCo v2 [ 7 ]","256","-"],"associatedColumns":["#Neg Margin Val Acc"],"associatedMergedColumns":[]},{"number":"34.6","isBolded":false,"associatedRows":["Margin loss","4096","-"],"associatedColumns":["#Neg Margin Val Acc"],"associatedMergedColumns":[]}]},{"caption":"Table 3: The tricks used in the competition, our final accuracy is 68.8 which is a \ncompetitive result in the challenge. Our code will be made public. Results in this \ntable are obtain by train the model on the combination of train and validation \nsplits. \n","rows":["+Ensemble two models","+Auto - Aug [ 3 ]","+ResNeXt101 [ 19 ]","+Input Resolution","+TenCrop","Phase - 1 + Phase - 2","+Label - Smooth [ 13 ]"],"columns":["#Pretrain Epoch #Finetune Epoch Test Acc"],"mergedAllColumns":[],"numberCells":[{"number":"800","isBolded":false,"associatedRows":["+ResNeXt101 [ 19 ]"],"associatedColumns":["#Pretrain Epoch #Finetune Epoch Test Acc"],"associatedMergedColumns":[]},{"number":"448","isBolded":false,"associatedRows":["+Input Resolution"],"associatedColumns":["#Pretrain Epoch #Finetune Epoch Test Acc"],"associatedMergedColumns":[]},{"number":"800","isBolded":false,"associatedRows":["+Label - Smooth [ 13 ]"],"associatedColumns":["#Pretrain Epoch #Finetune Epoch Test Acc"],"associatedMergedColumns":[]},{"number":"62.3","isBolded":false,"associatedRows":["+ResNeXt101 [ 19 ]"],"associatedColumns":["#Pretrain Epoch #Finetune Epoch Test Acc"],"associatedMergedColumns":[]},{"number":"64.2","isBolded":false,"associatedRows":["+Label - Smooth [ 13 ]"],"associatedColumns":["#Pretrain Epoch #Finetune Epoch Test Acc"],"associatedMergedColumns":[]},{"number":"800","isBolded":false,"associatedRows":["Phase - 1 + Phase - 2"],"associatedColumns":["#Pretrain Epoch #Finetune Epoch Test Acc"],"associatedMergedColumns":[]},{"number":"100","isBolded":false,"associatedRows":["+Ensemble two models"],"associatedColumns":["#Pretrain Epoch #Finetune Epoch Test Acc"],"associatedMergedColumns":[]},{"number":"65.7","isBolded":false,"associatedRows":["+Auto - Aug [ 3 ]"],"associatedColumns":["#Pretrain Epoch #Finetune Epoch Test Acc"],"associatedMergedColumns":[]},{"number":"100","isBolded":false,"associatedRows":["+Label - Smooth [ 13 ]"],"associatedColumns":["#Pretrain Epoch #Finetune Epoch Test Acc"],"associatedMergedColumns":[]},{"number":"68.8","isBolded":false,"associatedRows":["+Ensemble two models"],"associatedColumns":["#Pretrain Epoch #Finetune Epoch Test Acc"],"associatedMergedColumns":[]},{"number":"800","isBolded":false,"associatedRows":["+Input Resolution"],"associatedColumns":["#Pretrain Epoch #Finetune Epoch Test Acc"],"associatedMergedColumns":[]},{"number":"100","isBolded":false,"associatedRows":["+ResNeXt101 [ 19 ]"],"associatedColumns":["#Pretrain Epoch #Finetune Epoch Test Acc"],"associatedMergedColumns":[]},{"number":"800","isBolded":false,"associatedRows":["+Auto - Aug [ 3 ]"],"associatedColumns":["#Pretrain Epoch #Finetune Epoch Test Acc"],"associatedMergedColumns":[]},{"number":"800","isBolded":false,"associatedRows":["+Ensemble two models"],"associatedColumns":["#Pretrain Epoch #Finetune Epoch Test Acc"],"associatedMergedColumns":[]},{"number":"100","isBolded":false,"associatedRows":["+TenCrop"],"associatedColumns":["#Pretrain Epoch #Finetune Epoch Test Acc"],"associatedMergedColumns":[]},{"number":"66.2","isBolded":false,"associatedRows":["+TenCrop"],"associatedColumns":["#Pretrain Epoch #Finetune Epoch Test Acc"],"associatedMergedColumns":[]},{"number":"100","isBolded":false,"associatedRows":["+Input Resolution"],"associatedColumns":["#Pretrain Epoch #Finetune Epoch Test Acc"],"associatedMergedColumns":[]},{"number":"47.2","isBolded":false,"associatedRows":["Phase - 1 + Phase - 2"],"associatedColumns":["#Pretrain Epoch #Finetune Epoch Test Acc"],"associatedMergedColumns":[]},{"number":"800","isBolded":false,"associatedRows":["+TenCrop"],"associatedColumns":["#Pretrain Epoch #Finetune Epoch Test Acc"],"associatedMergedColumns":[]},{"number":"54.8","isBolded":false,"associatedRows":["+Input Resolution"],"associatedColumns":["#Pretrain Epoch #Finetune Epoch Test Acc"],"associatedMergedColumns":[]},{"number":"100","isBolded":false,"associatedRows":["+Auto - Aug [ 3 ]"],"associatedColumns":["#Pretrain Epoch #Finetune Epoch Test Acc"],"associatedMergedColumns":[]},{"number":"100","isBolded":false,"associatedRows":["Phase - 1 + Phase - 2"],"associatedColumns":["#Pretrain Epoch #Finetune Epoch Test Acc"],"associatedMergedColumns":[]}]}]