[{"caption":"Table 2: Multi-label HOI classification performance on HICO dataset. The top-half compares our performance \nto other full image-based methods. The bottom-half reports methods that use object bounding boxes/pose. Our \nmodel out-performs various approaches that need bounding boxes, multi-instance learning (MIL) or specialized \nlosses, and achieves performance competitive to state of the art. Note that even though our pose regularized \nmodel uses computed pose labels at training time, it does not require any pose input at test time. \n\n","rows":["AlexNet+SVM [ 7 ]","R * CNN [ 18 ] ( reported in [ 30 ] )","VGG16 , Fusion ( best ) [ 30 ]","VGG16 , full image [ 30 ]","Pose Regularized Attentional Pooling ( R101 ) ( ours )","Fusion , weighted loss ( best reported ) [ 30 ]","ResNet101 with CBP [ 16 ] ( impl . from [ 1 ] )","Attn . Pool . ( I - V2 ) ( ours )","Dense Trajectory + Pose [ 34 ]","Attn . Pool . ( R - 101 ) ( ours )","-","ResNet101 , full image ( ours )","VGG16 , RCNN [ 18 ]","Pose Reg . Attn . Pooling ( R - 101 ) ( ours )","Fusion ( best reported ) [ 30 ]","VGG16 , Fusion+MIL ( best ) [ 30 ]","ResNet101 ( ours )","VGG16 , R * CNN [ 18 ]","Inception - V2 ( ours )","Attentional Pooling ( R - 101 ) ( ours )","Scene - RCNN [ 18 ] ( reported in [ 30 ] )"],"columns":["Val ( mAP )","Test ( mAP )","mAP"],"mergedAllColumns":["-"],"numberCells":[{"number":"36.1","isBolded":false,"associatedRows":["Fusion , weighted loss ( best reported ) [ 30 ]","-"],"associatedColumns":["Test ( mAP )","mAP"],"associatedMergedColumns":["-"]},{"number":"36.0","isBolded":true,"associatedRows":["Attn . Pool . ( R - 101 ) ( ours )","-"],"associatedColumns":["Test ( mAP )"],"associatedMergedColumns":["-"]},{"number":"30.2","isBolded":false,"associatedRows":["ResNet101 , full image ( ours )","-"],"associatedColumns":["Test ( mAP )","mAP"],"associatedMergedColumns":["-"]},{"number":"24.3","isBolded":false,"associatedRows":["Attn . Pool . ( I - V2 ) ( ours )"],"associatedColumns":["Val ( mAP )"],"associatedMergedColumns":["-"]},{"number":"30.3","isBolded":true,"associatedRows":["Attn . Pool . ( R - 101 ) ( ours )"],"associatedColumns":["Val ( mAP )"],"associatedMergedColumns":["-"]},{"number":"26.7","isBolded":false,"associatedRows":["VGG16 , R * CNN [ 18 ]","-"],"associatedColumns":["Test ( mAP )"],"associatedMergedColumns":["-"]},{"number":"29.4","isBolded":false,"associatedRows":["VGG16 , full image [ 30 ]","-"],"associatedColumns":["Test ( mAP )","mAP"],"associatedMergedColumns":["-"]},{"number":"35.0","isBolded":true,"associatedRows":["Attentional Pooling ( R - 101 ) ( ours )","-"],"associatedColumns":["Test ( mAP )","mAP"],"associatedMergedColumns":["-"]},{"number":"16.5","isBolded":false,"associatedRows":["VGG16 , RCNN [ 18 ]"],"associatedColumns":["Val ( mAP )"],"associatedMergedColumns":["-"]},{"number":"31.9","isBolded":false,"associatedRows":["VGG16 , Fusion+MIL ( best ) [ 30 ]","-"],"associatedColumns":["Test ( mAP )"],"associatedMergedColumns":["-"]},{"number":"26.8","isBolded":false,"associatedRows":["ResNet101 with CBP [ 16 ] ( impl . from [ 1 ] )","-"],"associatedColumns":["Test ( mAP )","mAP"],"associatedMergedColumns":["-"]},{"number":"21.7","isBolded":false,"associatedRows":["VGG16 , R * CNN [ 18 ]"],"associatedColumns":["Val ( mAP )"],"associatedMergedColumns":["-"]},{"number":"36.1","isBolded":true,"associatedRows":["Pose Reg . Attn . Pooling ( R - 101 ) ( ours )","-"],"associatedColumns":["Test ( mAP )"],"associatedMergedColumns":["-"]},{"number":"30.6","isBolded":true,"associatedRows":["Pose Reg . Attn . Pooling ( R - 101 ) ( ours )"],"associatedColumns":["Val ( mAP )"],"associatedMergedColumns":["-"]},{"number":"29.0","isBolded":false,"associatedRows":["Scene - RCNN [ 18 ] ( reported in [ 30 ] )","-"],"associatedColumns":["Test ( mAP )","mAP"],"associatedMergedColumns":["-"]},{"number":"34.6","isBolded":true,"associatedRows":["Pose Regularized Attentional Pooling ( R101 ) ( ours )","-"],"associatedColumns":["Test ( mAP )","mAP"],"associatedMergedColumns":["-"]},{"number":"5.5","isBolded":false,"associatedRows":["Dense Trajectory + Pose [ 34 ]","-"],"associatedColumns":["Test ( mAP )"],"associatedMergedColumns":["-"]},{"number":"32.2","isBolded":false,"associatedRows":["VGG16 , Fusion ( best ) [ 30 ]","-"],"associatedColumns":["Test ( mAP )"],"associatedMergedColumns":["-"]},{"number":"33.8","isBolded":false,"associatedRows":["Fusion ( best reported ) [ 30 ]","-"],"associatedColumns":["Test ( mAP )","mAP"],"associatedMergedColumns":["-"]},{"number":"19.4","isBolded":false,"associatedRows":["AlexNet+SVM [ 7 ]","-"],"associatedColumns":["Test ( mAP )","mAP"],"associatedMergedColumns":["-"]},{"number":"26.2","isBolded":false,"associatedRows":["ResNet101 ( ours )"],"associatedColumns":["Val ( mAP )"],"associatedMergedColumns":["-"]},{"number":"25.2","isBolded":false,"associatedRows":["Inception - V2 ( ours )"],"associatedColumns":["Val ( mAP )"],"associatedMergedColumns":[]},{"number":"28.5","isBolded":false,"associatedRows":["R * CNN [ 18 ] ( reported in [ 30 ] )","-"],"associatedColumns":["Test ( mAP )","mAP"],"associatedMergedColumns":["-"]}]},{"caption":"Table 3: Action classification performance on HMDB51 dataset using only the RGB stream of a two-stream \nmodel. Our base ResNet stream training is done over 480px rescaled images, same as used in our attention \nmodel for comparison purposes. Our pose based attention model out-performs the base network by large margin, \nas well as the previous RGB stream (single-frame) state-of-the-art, TSN [54]. \n\n","rows":["TSN , ResNet101 ( RGB ) ( ours )","Linear Attentional Pooling ( ours )","ActionVLAD [ 17 ]","Pose regularized Attentional Pooling ( ours )","RGB Stream , ResNet50 ( RGB ) [ 14 ] ( reported at [ 2 ] )","RGB Stream , ResNet152 ( RGB ) [ 14 ] ( reported at [ 2 ] )","-","TSN , BN - inception ( RGB ) [ 54 ] ( Via email with authors )"],"columns":["Avg","Split 3","Split 2","Split 1"],"mergedAllColumns":[],"numberCells":[{"number":"51.2","isBolded":false,"associatedRows":["ActionVLAD [ 17 ]"],"associatedColumns":["Split 1"],"associatedMergedColumns":[]},{"number":"-46.7","isBolded":false,"associatedRows":["RGB Stream , ResNet152 ( RGB ) [ 14 ] ( reported at [ 2 ] )","-","-"],"associatedColumns":["Split 3"],"associatedMergedColumns":[]},{"number":"51.1","isBolded":false,"associatedRows":["Pose regularized Attentional Pooling ( ours )","-"],"associatedColumns":["Split 2"],"associatedMergedColumns":[]},{"number":"49.5","isBolded":false,"associatedRows":["TSN , BN - inception ( RGB ) [ 54 ] ( Via email with authors )","-"],"associatedColumns":["Split 2"],"associatedMergedColumns":[]},{"number":"51.6","isBolded":true,"associatedRows":["Linear Attentional Pooling ( ours )","-"],"associatedColumns":["Split 2"],"associatedMergedColumns":[]},{"number":"-49.8","isBolded":false,"associatedRows":["ActionVLAD [ 17 ]","-","-"],"associatedColumns":["Split 3"],"associatedMergedColumns":[]},{"number":"49.7","isBolded":false,"associatedRows":["Linear Attentional Pooling ( ours )","-","-"],"associatedColumns":["Split 3"],"associatedMergedColumns":[]},{"number":"48.2","isBolded":false,"associatedRows":["TSN , ResNet101 ( RGB ) ( ours )"],"associatedColumns":["Split 1"],"associatedMergedColumns":[]},{"number":"52.2","isBolded":true,"associatedRows":["Pose regularized Attentional Pooling ( ours )","-","-"],"associatedColumns":["Avg"],"associatedMergedColumns":[]},{"number":"51.1","isBolded":false,"associatedRows":["Linear Attentional Pooling ( ours )"],"associatedColumns":["Split 1"],"associatedMergedColumns":[]},{"number":"49.2","isBolded":false,"associatedRows":["TSN , BN - inception ( RGB ) [ 54 ] ( Via email with authors )","-","-"],"associatedColumns":["Split 3"],"associatedMergedColumns":[]},{"number":"54.4","isBolded":true,"associatedRows":["Pose regularized Attentional Pooling ( ours )"],"associatedColumns":["Split 1"],"associatedMergedColumns":[]},{"number":"47.1","isBolded":false,"associatedRows":["TSN , ResNet101 ( RGB ) ( ours )","-","-"],"associatedColumns":["Avg"],"associatedMergedColumns":[]},{"number":"-48.9","isBolded":false,"associatedRows":["RGB Stream , ResNet50 ( RGB ) [ 14 ] ( reported at [ 2 ] )","-","-"],"associatedColumns":["Split 3"],"associatedMergedColumns":[]},{"number":"54.4","isBolded":true,"associatedRows":["TSN , BN - inception ( RGB ) [ 54 ] ( Via email with authors )"],"associatedColumns":["Split 1"],"associatedMergedColumns":[]},{"number":"51.0","isBolded":false,"associatedRows":["TSN , BN - inception ( RGB ) [ 54 ] ( Via email with authors )","-","-"],"associatedColumns":["Avg"],"associatedMergedColumns":[]},{"number":"46.7","isBolded":false,"associatedRows":["TSN , ResNet101 ( RGB ) ( ours )","-","-"],"associatedColumns":["Split 3"],"associatedMergedColumns":[]},{"number":"50.9","isBolded":true,"associatedRows":["Pose regularized Attentional Pooling ( ours )","-","-"],"associatedColumns":["Split 3"],"associatedMergedColumns":[]},{"number":"46.5","isBolded":false,"associatedRows":["TSN , ResNet101 ( RGB ) ( ours )","-"],"associatedColumns":["Split 2"],"associatedMergedColumns":[]},{"number":"50.8","isBolded":false,"associatedRows":["Linear Attentional Pooling ( ours )","-","-"],"associatedColumns":["Avg"],"associatedMergedColumns":[]}]}]