[{"caption":"Model \n\nTest2016 \nTest2017 \nMSCOCO \n\nBLEU METEOR BLEU METEOR BLEU METEOR \n\nText-only Transformer [Vaswani et al., 2017] \n37.8 \n55.3 \n29.1 \n48.6 \n25.2 \n44.1 \nDoubly-attention [Calixto et al., 2017] \n36.5 \n55.0 \n-\n-\n-\n-\nFusion-conv [Caglayan et al., 2017] \n37.0 \n57.0 \n29.8 \n51.2 \n25.1 \n46.0 \nTrg-mul [Caglayan et al., 2017] \n37.8 \n55.7 \n30.7 \n52.2 \n26.4 \n47.4 \nLatent Variable MMT [Calixto et al., 2019] \n37.7 \n56.0 \n30.1 \n49.9 \n25.5 \n44.8 \nDeliberation networks [Ive et al., 2019] \n38.0 \n55.6 \n-\n-\n-\n-\nMulti-modal Transformer [Yao and Wan, 2020] \n38.7 \n55.7 \n-\n-\n-\n-\n\nGumbel-Attention MMT \n39.2 \n57.8 \n31.4 \n51.2 \n26.9 \n46.0 \n\nTable 1: Experimental results on the Multi30k test set. Best results are highlighted in bold. \n\n","rows":["Doubly - attention [ Calixto et al . , 2017 ]","Fusion - conv [ Caglayan et al . , 2017 ]","Gumbel - Attention MMT","Trg - mul [ Caglayan et al . , 2017 ]","Latent Variable MMT [ Calixto et al . , 2019 ]","Deliberation networks [ Ive et al . , 2019 ]","Text - only Transformer [ Vaswani et al . , 2017 ]","Multi - modal Transformer [ Yao and Wan , 2020 ]"],"columns":["METEOR","BLEU","MSCOCO","Test2017","Test2016","-"],"mergedAllColumns":["Model"],"numberCells":[{"number":"25.2","isBolded":false,"associatedRows":["Text - only Transformer [ Vaswani et al . , 2017 ]"],"associatedColumns":["MSCOCO","BLEU"],"associatedMergedColumns":["Model"]},{"number":"44.1","isBolded":false,"associatedRows":["Text - only Transformer [ Vaswani et al . , 2017 ]"],"associatedColumns":["MSCOCO","METEOR"],"associatedMergedColumns":["Model"]},{"number":"55.7","isBolded":false,"associatedRows":["Multi - modal Transformer [ Yao and Wan , 2020 ]"],"associatedColumns":["Test2016","METEOR","-","-"],"associatedMergedColumns":["Model"]},{"number":"55.3","isBolded":false,"associatedRows":["Text - only Transformer [ Vaswani et al . , 2017 ]"],"associatedColumns":["Test2016","METEOR"],"associatedMergedColumns":["Model"]},{"number":"57.0","isBolded":false,"associatedRows":["Fusion - conv [ Caglayan et al . , 2017 ]"],"associatedColumns":["Test2016","METEOR","-"],"associatedMergedColumns":["Model"]},{"number":"26.9","isBolded":true,"associatedRows":["Gumbel - Attention MMT"],"associatedColumns":["MSCOCO","BLEU","-","-","-"],"associatedMergedColumns":["Model"]},{"number":"51.2","isBolded":false,"associatedRows":["Gumbel - Attention MMT"],"associatedColumns":["Test2017","METEOR","-","-","-"],"associatedMergedColumns":["Model"]},{"number":"51.2","isBolded":false,"associatedRows":["Fusion - conv [ Caglayan et al . , 2017 ]"],"associatedColumns":["Test2017","METEOR","-"],"associatedMergedColumns":["Model"]},{"number":"55.0","isBolded":false,"associatedRows":["Doubly - attention [ Calixto et al . , 2017 ]"],"associatedColumns":["Test2016","METEOR"],"associatedMergedColumns":["Model"]},{"number":"52.2","isBolded":true,"associatedRows":["Trg - mul [ Caglayan et al . , 2017 ]"],"associatedColumns":["Test2017","METEOR","-"],"associatedMergedColumns":["Model"]},{"number":"44.8","isBolded":false,"associatedRows":["Latent Variable MMT [ Calixto et al . , 2019 ]"],"associatedColumns":["MSCOCO","METEOR","-"],"associatedMergedColumns":["Model"]},{"number":"39.2","isBolded":true,"associatedRows":["Gumbel - Attention MMT"],"associatedColumns":["Test2016","BLEU","-","-","-"],"associatedMergedColumns":["Model"]},{"number":"37.8","isBolded":false,"associatedRows":["Text - only Transformer [ Vaswani et al . , 2017 ]"],"associatedColumns":["Test2016","BLEU"],"associatedMergedColumns":["Model"]},{"number":"47.4","isBolded":true,"associatedRows":["Trg - mul [ Caglayan et al . , 2017 ]"],"associatedColumns":["MSCOCO","METEOR","-"],"associatedMergedColumns":["Model"]},{"number":"30.7","isBolded":false,"associatedRows":["Trg - mul [ Caglayan et al . , 2017 ]"],"associatedColumns":["Test2017","BLEU","-"],"associatedMergedColumns":["Model"]},{"number":"37.7","isBolded":false,"associatedRows":["Latent Variable MMT [ Calixto et al . , 2019 ]"],"associatedColumns":["Test2016","BLEU","-"],"associatedMergedColumns":["Model"]},{"number":"49.9","isBolded":false,"associatedRows":["Latent Variable MMT [ Calixto et al . , 2019 ]"],"associatedColumns":["Test2017","METEOR","-"],"associatedMergedColumns":["Model"]},{"number":"29.8","isBolded":false,"associatedRows":["Fusion - conv [ Caglayan et al . , 2017 ]"],"associatedColumns":["Test2017","BLEU","-"],"associatedMergedColumns":["Model"]},{"number":"38.0","isBolded":false,"associatedRows":["Deliberation networks [ Ive et al . , 2019 ]"],"associatedColumns":["Test2016","BLEU","-"],"associatedMergedColumns":["Model"]},{"number":"37.0","isBolded":false,"associatedRows":["Fusion - conv [ Caglayan et al . , 2017 ]"],"associatedColumns":["Test2016","BLEU","-"],"associatedMergedColumns":["Model"]},{"number":"46.0","isBolded":false,"associatedRows":["Fusion - conv [ Caglayan et al . , 2017 ]"],"associatedColumns":["MSCOCO","METEOR","-"],"associatedMergedColumns":["Model"]},{"number":"55.6","isBolded":false,"associatedRows":["Deliberation networks [ Ive et al . , 2019 ]"],"associatedColumns":["Test2016","METEOR","-"],"associatedMergedColumns":["Model"]},{"number":"30.1","isBolded":false,"associatedRows":["Latent Variable MMT [ Calixto et al . , 2019 ]"],"associatedColumns":["Test2017","BLEU","-"],"associatedMergedColumns":["Model"]},{"number":"29.1","isBolded":false,"associatedRows":["Text - only Transformer [ Vaswani et al . , 2017 ]"],"associatedColumns":["Test2017","BLEU"],"associatedMergedColumns":["Model"]},{"number":"25.1","isBolded":false,"associatedRows":["Fusion - conv [ Caglayan et al . , 2017 ]"],"associatedColumns":["MSCOCO","BLEU","-"],"associatedMergedColumns":["Model"]},{"number":"46.0","isBolded":false,"associatedRows":["Gumbel - Attention MMT"],"associatedColumns":["MSCOCO","METEOR","-","-","-"],"associatedMergedColumns":["Model"]},{"number":"48.6","isBolded":false,"associatedRows":["Text - only Transformer [ Vaswani et al . , 2017 ]"],"associatedColumns":["Test2017","METEOR"],"associatedMergedColumns":["Model"]},{"number":"36.5","isBolded":false,"associatedRows":["Doubly - attention [ Calixto et al . , 2017 ]"],"associatedColumns":["Test2016","BLEU"],"associatedMergedColumns":["Model"]},{"number":"26.4","isBolded":false,"associatedRows":["Trg - mul [ Caglayan et al . , 2017 ]"],"associatedColumns":["MSCOCO","BLEU","-"],"associatedMergedColumns":["Model"]},{"number":"57.8","isBolded":true,"associatedRows":["Gumbel - Attention MMT"],"associatedColumns":["Test2016","METEOR","-","-","-"],"associatedMergedColumns":["Model"]},{"number":"38.7","isBolded":false,"associatedRows":["Multi - modal Transformer [ Yao and Wan , 2020 ]"],"associatedColumns":["Test2016","BLEU","-","-"],"associatedMergedColumns":["Model"]},{"number":"55.7","isBolded":false,"associatedRows":["Trg - mul [ Caglayan et al . , 2017 ]"],"associatedColumns":["Test2016","METEOR","-"],"associatedMergedColumns":["Model"]},{"number":"25.5","isBolded":false,"associatedRows":["Latent Variable MMT [ Calixto et al . , 2019 ]"],"associatedColumns":["MSCOCO","BLEU","-"],"associatedMergedColumns":["Model"]},{"number":"31.4","isBolded":true,"associatedRows":["Gumbel - Attention MMT"],"associatedColumns":["Test2017","BLEU","-","-","-"],"associatedMergedColumns":["Model"]},{"number":"56.0","isBolded":false,"associatedRows":["Latent Variable MMT [ Calixto et al . , 2019 ]"],"associatedColumns":["Test2016","METEOR","-"],"associatedMergedColumns":["Model"]},{"number":"37.8","isBolded":false,"associatedRows":["Trg - mul [ Caglayan et al . , 2017 ]"],"associatedColumns":["Test2016","BLEU","-"],"associatedMergedColumns":["Model"]}]},{"caption":"Table 2: Ablation study of our model on Test2016 \n\n","rows":["Gumbel - Attention Model","Text - only Transformer","- replace with vanilla - attention","- shared parameters","- w / o multi - modal similarity loss","- replace with random images","- w / o multi - modal gated fusion"],"columns":["METEOR","BLEU"],"mergedAllColumns":[],"numberCells":[{"number":"38.9","isBolded":false,"associatedRows":["- w / o multi - modal gated fusion"],"associatedColumns":["BLEU"],"associatedMergedColumns":[]},{"number":"55.3","isBolded":false,"associatedRows":["Text - only Transformer"],"associatedColumns":["METEOR"],"associatedMergedColumns":[]},{"number":"55.9","isBolded":false,"associatedRows":["- replace with vanilla - attention"],"associatedColumns":["METEOR"],"associatedMergedColumns":[]},{"number":"56.2","isBolded":false,"associatedRows":["- w / o multi - modal gated fusion"],"associatedColumns":["METEOR"],"associatedMergedColumns":[]},{"number":"55.6","isBolded":false,"associatedRows":["- replace with random images"],"associatedColumns":["METEOR"],"associatedMergedColumns":[]},{"number":"38.3","isBolded":false,"associatedRows":["- replace with random images"],"associatedColumns":["BLEU"],"associatedMergedColumns":[]},{"number":"56.0","isBolded":false,"associatedRows":["- shared parameters"],"associatedColumns":["METEOR"],"associatedMergedColumns":[]},{"number":"38.5","isBolded":false,"associatedRows":["- shared parameters"],"associatedColumns":["BLEU"],"associatedMergedColumns":[]},{"number":"57.8","isBolded":false,"associatedRows":["Gumbel - Attention Model"],"associatedColumns":["METEOR"],"associatedMergedColumns":[]},{"number":"37.8","isBolded":false,"associatedRows":["Text - only Transformer"],"associatedColumns":["BLEU"],"associatedMergedColumns":[]},{"number":"38.6","isBolded":false,"associatedRows":["- replace with vanilla - attention"],"associatedColumns":["BLEU"],"associatedMergedColumns":[]},{"number":"39.0","isBolded":false,"associatedRows":["- w / o multi - modal similarity loss"],"associatedColumns":["BLEU"],"associatedMergedColumns":[]},{"number":"57.1","isBolded":false,"associatedRows":["- w / o multi - modal similarity loss"],"associatedColumns":["METEOR"],"associatedMergedColumns":[]},{"number":"39.2","isBolded":false,"associatedRows":["Gumbel - Attention Model"],"associatedColumns":["BLEU"],"associatedMergedColumns":[]}]},{"caption":"Table 2. \nreplace with vanilla-attention. In this variant, we replace \nGumebl-Attention with vanilla-attention, which performs a \nweighted sum of similarity between text and image informa-\ntion instead of selecting. This method can also make rea-\nsonable use of picture information, so the performance is \nimproved compared with text-only baseline. Additionally, \nGumbel-Attention model and vanilla-attention-based model \nhave a gap of more than 1 bleu on Test2016, which demon-\nstrates the influence of image noise on the MMT task. \n","rows":["Gumbel - Attention Model","Text - only Transformer","- replace with vanilla - attention","- shared parameters","- w / o multi - modal similarity loss","- replace with random images","- w / o multi - modal gated fusion"],"columns":["METEOR","BLEU"],"mergedAllColumns":[],"numberCells":[{"number":"39.2","isBolded":false,"associatedRows":["Gumbel - Attention Model"],"associatedColumns":["BLEU"],"associatedMergedColumns":[]},{"number":"56.0","isBolded":false,"associatedRows":["- shared parameters"],"associatedColumns":["METEOR"],"associatedMergedColumns":[]},{"number":"38.5","isBolded":false,"associatedRows":["- shared parameters"],"associatedColumns":["BLEU"],"associatedMergedColumns":[]},{"number":"55.3","isBolded":false,"associatedRows":["Text - only Transformer"],"associatedColumns":["METEOR"],"associatedMergedColumns":[]},{"number":"37.8","isBolded":false,"associatedRows":["Text - only Transformer"],"associatedColumns":["BLEU"],"associatedMergedColumns":[]},{"number":"56.2","isBolded":false,"associatedRows":["- w / o multi - modal gated fusion"],"associatedColumns":["METEOR"],"associatedMergedColumns":[]},{"number":"39.0","isBolded":false,"associatedRows":["- w / o multi - modal similarity loss"],"associatedColumns":["BLEU"],"associatedMergedColumns":[]},{"number":"55.9","isBolded":false,"associatedRows":["- replace with vanilla - attention"],"associatedColumns":["METEOR"],"associatedMergedColumns":[]},{"number":"38.9","isBolded":false,"associatedRows":["- w / o multi - modal gated fusion"],"associatedColumns":["BLEU"],"associatedMergedColumns":[]},{"number":"57.1","isBolded":false,"associatedRows":["- w / o multi - modal similarity loss"],"associatedColumns":["METEOR"],"associatedMergedColumns":[]},{"number":"57.8","isBolded":false,"associatedRows":["Gumbel - Attention Model"],"associatedColumns":["METEOR"],"associatedMergedColumns":[]},{"number":"38.6","isBolded":false,"associatedRows":["- replace with vanilla - attention"],"associatedColumns":["BLEU"],"associatedMergedColumns":[]},{"number":"55.6","isBolded":false,"associatedRows":["- replace with random images"],"associatedColumns":["METEOR"],"associatedMergedColumns":[]},{"number":"38.3","isBolded":false,"associatedRows":["- replace with random images"],"associatedColumns":["BLEU"],"associatedMergedColumns":[]}]}]