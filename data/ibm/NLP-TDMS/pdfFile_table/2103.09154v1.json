[{"caption":"Table 1. Performances of the proposed visual facial expression embedding \nnetwork on the AffectNet validation set comparing to existing state-of-the-\nart methods \n\nMethods \nAccuracy \nGeorgescu et al. [2019]  59.6% \nSiqueira et al. [2020]  59.3% \nOurs (Teacher model) \n61.3% \nOurs (Student, no distillation)  58.8% \nOurs (Distilled student, no PowderFaces) 61.1% \nOurs (Distilled student) \n61.6% \n\nTable 2. Triplet prediction performances of the proposed visual facial ex-\npression embedding network on the Google FEC test set comparing to ex-\nisting state-of-the-art methods \n\nMethods \nAccuracy \nAgarwala and Vemulapalli [2019] \n81.8% \nOurs (Teacher model) \n84.5% \nOurs (Student, no distillation) \n85.0% \nOurs (Distilled student, no PowderFaces) 86.4% \nOurs (Distilled student) \n86.5% \n\n1. AffectNet: for AffectNet, which requires classifying faces \ninto eight discrete facial expression classes, we train a lo-\ngistic regression model on the features extracted by our \nstudent network for the entire AffectNet training set. 3 This \nmethod achieves state-of-the-art results on the AffectNet \nvalidation set, with an accuracy of 61.6% (Table 1). \n2. Google FEC: following Agarwala and Vemulapalli \n","rows":["Georgescu et al . [ 2019 ]","Ours ( Teacher model )","Ours ( Distilled student )","Siqueira et al . [ 2020 ]","Agarwala and Vemulapalli [ 2019 ]","validation set , with an accuracy of","Ours ( Student , no distillation )","Ours ( Distilled student , no PowderFaces )"],"columns":["Accuracy","Table 1 . Performances of the proposed visual facial expression embedding"],"mergedAllColumns":["method achieves state - of - the - art results on the AffectNet","isting state - of - the - art methods","art methods"],"numberCells":[{"number":"59.3%","isBolded":false,"associatedRows":["Siqueira et al . [ 2020 ]"],"associatedColumns":["Table 1 . Performances of the proposed visual facial expression embedding","Accuracy"],"associatedMergedColumns":["art methods"]},{"number":"81.8%","isBolded":false,"associatedRows":["Agarwala and Vemulapalli [ 2019 ]"],"associatedColumns":["Table 1 . Performances of the proposed visual facial expression embedding","Accuracy","Accuracy"],"associatedMergedColumns":["isting state - of - the - art methods"]},{"number":"61.1%","isBolded":false,"associatedRows":["Ours ( Distilled student , no PowderFaces )"],"associatedColumns":["Table 1 . Performances of the proposed visual facial expression embedding","Accuracy"],"associatedMergedColumns":["art methods"]},{"number":"61.6%","isBolded":true,"associatedRows":["Ours ( Distilled student )"],"associatedColumns":["Table 1 . Performances of the proposed visual facial expression embedding","Accuracy"],"associatedMergedColumns":["art methods"]},{"number":"61.3%","isBolded":false,"associatedRows":["Ours ( Teacher model )"],"associatedColumns":["Table 1 . Performances of the proposed visual facial expression embedding","Accuracy"],"associatedMergedColumns":["art methods"]},{"number":"59.6%","isBolded":false,"associatedRows":["Georgescu et al . [ 2019 ]"],"associatedColumns":["Table 1 . Performances of the proposed visual facial expression embedding","Accuracy"],"associatedMergedColumns":["art methods"]},{"number":"86.5%","isBolded":true,"associatedRows":["Ours ( Distilled student )"],"associatedColumns":["Table 1 . Performances of the proposed visual facial expression embedding","Accuracy","Accuracy"],"associatedMergedColumns":["isting state - of - the - art methods"]},{"number":"58.8%","isBolded":false,"associatedRows":["Ours ( Student , no distillation )"],"associatedColumns":["Table 1 . Performances of the proposed visual facial expression embedding","Accuracy"],"associatedMergedColumns":["art methods"]},{"number":"85.0%","isBolded":false,"associatedRows":["Ours ( Student , no distillation )"],"associatedColumns":["Table 1 . Performances of the proposed visual facial expression embedding","Accuracy","Accuracy"],"associatedMergedColumns":["isting state - of - the - art methods"]},{"number":"84.5%","isBolded":false,"associatedRows":["Ours ( Teacher model )"],"associatedColumns":["Table 1 . Performances of the proposed visual facial expression embedding","Accuracy","Accuracy"],"associatedMergedColumns":["isting state - of - the - art methods"]},{"number":"61.6%(Table1).","isBolded":false,"associatedRows":["Ours ( Distilled student )","validation set , with an accuracy of"],"associatedColumns":["Table 1 . Performances of the proposed visual facial expression embedding","Accuracy","Accuracy"],"associatedMergedColumns":["method achieves state - of - the - art results on the AffectNet"]},{"number":"86.4%","isBolded":false,"associatedRows":["Ours ( Distilled student , no PowderFaces )"],"associatedColumns":["Table 1 . Performances of the proposed visual facial expression embedding","Accuracy","Accuracy"],"associatedMergedColumns":["isting state - of - the - art methods"]}]},{"caption":"Table 3. RECOLA dataset results (in terms of CCC) for predicting arousal \nand valence on train, development and test sets. \n\n","rows":["Audio - visual","Visual only","Audio only"],"columns":["Valence","Dev","Test","Arousal","Train"],"mergedAllColumns":[],"numberCells":[{"number":".57","isBolded":false,"associatedRows":["Visual only"],"associatedColumns":["Arousal","Test"],"associatedMergedColumns":[]},{"number":".55","isBolded":false,"associatedRows":["Audio only"],"associatedColumns":["Valence","Train"],"associatedMergedColumns":[]},{"number":".52","isBolded":false,"associatedRows":["Audio only"],"associatedColumns":["Arousal","Test"],"associatedMergedColumns":[]},{"number":".70","isBolded":false,"associatedRows":["Audio only"],"associatedColumns":["Arousal","Test"],"associatedMergedColumns":[]},{"number":".63","isBolded":false,"associatedRows":["Audio - visual"],"associatedColumns":["Valence","Dev"],"associatedMergedColumns":[]},{"number":".57","isBolded":false,"associatedRows":["Visual only"],"associatedColumns":["Arousal","Dev"],"associatedMergedColumns":[]},{"number":".55","isBolded":false,"associatedRows":["Visual only"],"associatedColumns":["Valence","Dev"],"associatedMergedColumns":[]},{"number":".80","isBolded":false,"associatedRows":["Audio only"],"associatedColumns":["Arousal","Dev"],"associatedMergedColumns":[]},{"number":".66","isBolded":false,"associatedRows":["Visual only"],"associatedColumns":["Arousal","Test"],"associatedMergedColumns":[]},{"number":".81","isBolded":false,"associatedRows":["Audio - visual"],"associatedColumns":["Arousal","Dev"],"associatedMergedColumns":[]},{"number":".78","isBolded":false,"associatedRows":["Audio only"],"associatedColumns":["Arousal","Train"],"associatedMergedColumns":[]},{"number":".72","isBolded":false,"associatedRows":["Audio - visual"],"associatedColumns":["Arousal","Test"],"associatedMergedColumns":[]},{"number":".6","isBolded":false,"associatedRows":["Visual only"],"associatedColumns":["Valence","Train"],"associatedMergedColumns":[]},{"number":".49","isBolded":false,"associatedRows":["Visual only"],"associatedColumns":["Arousal","Train"],"associatedMergedColumns":[]},{"number":".46","isBolded":false,"associatedRows":["Audio only"],"associatedColumns":["Valence","Dev"],"associatedMergedColumns":[]},{"number":".78","isBolded":false,"associatedRows":["Audio - visual"],"associatedColumns":["Arousal","Train"],"associatedMergedColumns":[]},{"number":".69","isBolded":false,"associatedRows":["Audio - visual"],"associatedColumns":["Valence","Train"],"associatedMergedColumns":[]},{"number":".74","isBolded":false,"associatedRows":["Audio - visual"],"associatedColumns":["Arousal","Test"],"associatedMergedColumns":[]}]},{"caption":"Valence \nArousal \nCCC \nTrain \nDev Test Train \nDev Test \nVisual only \n.6 \n.55 \n.66 \n.49 \n.57 \n.57 \nAudio only \n.55 \n.46 \n.52 \n.78 \n.80 \n.70 \nAudio-visual .69 \n.63 \n.74 \n.78 \n.81 \n.72 \n\nTable 4. Performances of the proposed audio embedding network on the \nRECOLA dataset comparing to existing state-of-the-art methods. In \nparenthesis are the performances obtained in the development set. --\n: no results reported in the original papers. \n\n","rows":["Audio - visual","Visual only","Audio only"],"columns":["Valence","Dev","Test","Arousal","Train"],"mergedAllColumns":[],"numberCells":[{"number":".69","isBolded":false,"associatedRows":["Audio - visual"],"associatedColumns":["Valence","Train"],"associatedMergedColumns":[]},{"number":".74","isBolded":false,"associatedRows":["Audio - visual"],"associatedColumns":["Arousal","Test"],"associatedMergedColumns":[]},{"number":".55","isBolded":false,"associatedRows":["Visual only"],"associatedColumns":["Valence","Dev"],"associatedMergedColumns":[]},{"number":".49","isBolded":false,"associatedRows":["Visual only"],"associatedColumns":["Arousal","Train"],"associatedMergedColumns":[]},{"number":".66","isBolded":false,"associatedRows":["Visual only"],"associatedColumns":["Arousal","Test"],"associatedMergedColumns":[]},{"number":".63","isBolded":false,"associatedRows":["Audio - visual"],"associatedColumns":["Valence","Dev"],"associatedMergedColumns":[]},{"number":".70","isBolded":false,"associatedRows":["Audio only"],"associatedColumns":["Arousal","Test"],"associatedMergedColumns":[]},{"number":".57","isBolded":false,"associatedRows":["Visual only"],"associatedColumns":["Arousal","Dev"],"associatedMergedColumns":[]},{"number":".46","isBolded":false,"associatedRows":["Audio only"],"associatedColumns":["Valence","Dev"],"associatedMergedColumns":[]},{"number":".78","isBolded":false,"associatedRows":["Audio only"],"associatedColumns":["Arousal","Train"],"associatedMergedColumns":[]},{"number":".78","isBolded":false,"associatedRows":["Audio - visual"],"associatedColumns":["Arousal","Train"],"associatedMergedColumns":[]},{"number":".6","isBolded":false,"associatedRows":["Visual only"],"associatedColumns":["Valence","Train"],"associatedMergedColumns":[]},{"number":".80","isBolded":false,"associatedRows":["Audio only"],"associatedColumns":["Arousal","Dev"],"associatedMergedColumns":[]},{"number":".52","isBolded":false,"associatedRows":["Audio only"],"associatedColumns":["Arousal","Test"],"associatedMergedColumns":[]},{"number":".72","isBolded":false,"associatedRows":["Audio - visual"],"associatedColumns":["Arousal","Test"],"associatedMergedColumns":[]},{"number":".81","isBolded":false,"associatedRows":["Audio - visual"],"associatedColumns":["Arousal","Dev"],"associatedMergedColumns":[]},{"number":".57","isBolded":false,"associatedRows":["Visual only"],"associatedColumns":["Arousal","Test"],"associatedMergedColumns":[]},{"number":".55","isBolded":false,"associatedRows":["Audio only"],"associatedColumns":["Valence","Train"],"associatedMergedColumns":[]}]}]