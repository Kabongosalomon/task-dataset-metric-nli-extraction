[{"caption":"dataset \n#class #images \n#v-labels \nFood-101N \n101 \n310k/ -/25k 55k/5k \nClothing1M 14 \n1M/14k/10k 25k/7k \nWebVision \n1000 \n2.4M/50k/ -\n25k/ -\n\nTable 1. Datasets. #images shows the numbers of images in \ntrain/val/test sets for classification (the train set is noisy labeled). \n#v-labels shows the numbers of validation labels in train/val sets. \n\n","rows":[", - . / 01 - 2 \u003d","\"",") ,","cos",")","+"],"columns":["Sample Weight","Cross - Entropy Loss","CleanNet","Weighted Cross - Entropy Loss"],"mergedAllColumns":[],"numberCells":[{"number":"5%,\u0026\u003d(","isBolded":false,"associatedRows":["\"",") ,"],"associatedColumns":["Weighted Cross - Entropy Loss","Cross - Entropy Loss"],"associatedMergedColumns":[]},{"number":"3","isBolded":false,"associatedRows":[],"associatedColumns":["Weighted Cross - Entropy Loss","Sample Weight"],"associatedMergedColumns":[]},{"number":"9","isBolded":false,"associatedRows":[],"associatedColumns":["Weighted Cross - Entropy Loss","Sample Weight"],"associatedMergedColumns":[]},{"number":"9","isBolded":false,"associatedRows":[],"associatedColumns":["Weighted Cross - Entropy Loss","Sample Weight","CleanNet"],"associatedMergedColumns":[]},{"number":"4","isBolded":false,"associatedRows":["+",", - . / 01 - 2 \u003d"],"associatedColumns":["Weighted Cross - Entropy Loss"],"associatedMergedColumns":[]},{"number":"4\u003d","isBolded":false,"associatedRows":[],"associatedColumns":["Weighted Cross - Entropy Loss","Sample Weight"],"associatedMergedColumns":[]},{"number":"9;","isBolded":false,"associatedRows":["\"",")"],"associatedColumns":["Weighted Cross - Entropy Loss","Sample Weight","CleanNet"],"associatedMergedColumns":[]},{"number":"3","isBolded":false,"associatedRows":["+",", - . / 01 - 2 \u003d"],"associatedColumns":["Weighted Cross - Entropy Loss"],"associatedMergedColumns":[]},{"number":"5","isBolded":false,"associatedRows":["+",", - . / 01 - 2 \u003d"],"associatedColumns":["Weighted Cross - Entropy Loss"],"associatedMergedColumns":[]},{"number":"9;","isBolded":false,"associatedRows":["cos","\"",") ,"],"associatedColumns":["Weighted Cross - Entropy Loss","Sample Weight","CleanNet"],"associatedMergedColumns":[]},{"number":"3cos","isBolded":false,"associatedRows":[],"associatedColumns":["Weighted Cross - Entropy Loss","Sample Weight"],"associatedMergedColumns":[]},{"number":"9","isBolded":false,"associatedRows":["cos"],"associatedColumns":["Weighted Cross - Entropy Loss","Sample Weight","CleanNet"],"associatedMergedColumns":[]},{"number":"9;","isBolded":false,"associatedRows":["\"",") ,"],"associatedColumns":["Weighted Cross - Entropy Loss","Cross - Entropy Loss"],"associatedMergedColumns":[]}]},{"caption":"average error rate \nmethod \nFood-101N Clothing1M \nnaive baseline \n19.66 \n38.46 \nsupervised baselines \nMLP \n10.42 \n16.09 \nkNN \n13.28 \n17.58 \nSVM \n11.21 \n16.75 \nlabel prop [40] \n13.24 \n17.81 \nlabel spread [39] \n12.03 \n17.71 \nweakly supervised baselines \nclassification filtering \n16.60 \n23.55 \nunsupervised baselines \nDRAE [34] \n18.70 \n38.95 \naverage baseline \n16.20 \n30.56 \nCleanNet (full supervision) \nCleanNet \n9.61 \n15.91 \nCleanNet* \n6.99 \n15.77 \n\nTable 2. Label noise detection in terms of average error rate over \nall the classes (%). CleanNet* denotes the results using image \nfeatures extracted from the classifiers retrained with data cleansed \nby CleanNet. \n\n","rows":["MLP","label spread [ 39 ]","DRAE [ 34 ]","average baseline","classification filtering","CleanNet *","CleanNet","label prop [ 40 ]","kNN","SVM","naive baseline"],"columns":["average error rate","Clothing1M","Food - 101N"],"mergedAllColumns":["weakly supervised baselines","CleanNet ( full supervision )","supervised baselines","unsupervised baselines"],"numberCells":[{"number":"13.24","isBolded":false,"associatedRows":["label prop [ 40 ]"],"associatedColumns":["average error rate","Food - 101N"],"associatedMergedColumns":["supervised baselines"]},{"number":"16.60","isBolded":false,"associatedRows":["classification filtering"],"associatedColumns":["average error rate","Food - 101N"],"associatedMergedColumns":["weakly supervised baselines"]},{"number":"9.61","isBolded":true,"associatedRows":["CleanNet"],"associatedColumns":["average error rate","Food - 101N"],"associatedMergedColumns":["CleanNet ( full supervision )"]},{"number":"17.71","isBolded":false,"associatedRows":["label spread [ 39 ]"],"associatedColumns":["average error rate","Clothing1M"],"associatedMergedColumns":["supervised baselines"]},{"number":"16.75","isBolded":false,"associatedRows":["SVM"],"associatedColumns":["average error rate","Clothing1M"],"associatedMergedColumns":["supervised baselines"]},{"number":"16.20","isBolded":false,"associatedRows":["average baseline"],"associatedColumns":["average error rate","Food - 101N"],"associatedMergedColumns":["unsupervised baselines"]},{"number":"17.58","isBolded":false,"associatedRows":["kNN"],"associatedColumns":["average error rate","Clothing1M"],"associatedMergedColumns":["supervised baselines"]},{"number":"15.77","isBolded":true,"associatedRows":["CleanNet *"],"associatedColumns":["average error rate","Clothing1M"],"associatedMergedColumns":["CleanNet ( full supervision )"]},{"number":"18.70","isBolded":false,"associatedRows":["DRAE [ 34 ]"],"associatedColumns":["average error rate","Food - 101N"],"associatedMergedColumns":["unsupervised baselines"]},{"number":"13.28","isBolded":false,"associatedRows":["kNN"],"associatedColumns":["average error rate","Food - 101N"],"associatedMergedColumns":["supervised baselines"]},{"number":"11.21","isBolded":false,"associatedRows":["SVM"],"associatedColumns":["average error rate","Food - 101N"],"associatedMergedColumns":["supervised baselines"]},{"number":"38.95","isBolded":false,"associatedRows":["DRAE [ 34 ]"],"associatedColumns":["average error rate","Clothing1M"],"associatedMergedColumns":["unsupervised baselines"]},{"number":"16.09","isBolded":false,"associatedRows":["MLP"],"associatedColumns":["average error rate","Clothing1M"],"associatedMergedColumns":["supervised baselines"]},{"number":"38.46","isBolded":false,"associatedRows":["naive baseline"],"associatedColumns":["average error rate","Clothing1M"],"associatedMergedColumns":[]},{"number":"19.66","isBolded":false,"associatedRows":["naive baseline"],"associatedColumns":["average error rate","Food - 101N"],"associatedMergedColumns":[]},{"number":"17.81","isBolded":false,"associatedRows":["label prop [ 40 ]"],"associatedColumns":["average error rate","Clothing1M"],"associatedMergedColumns":["supervised baselines"]},{"number":"6.99","isBolded":true,"associatedRows":["CleanNet *"],"associatedColumns":["average error rate","Food - 101N"],"associatedMergedColumns":["CleanNet ( full supervision )"]},{"number":"10.42","isBolded":false,"associatedRows":["MLP"],"associatedColumns":["average error rate","Food - 101N"],"associatedMergedColumns":["supervised baselines"]},{"number":"23.55","isBolded":false,"associatedRows":["classification filtering"],"associatedColumns":["average error rate","Clothing1M"],"associatedMergedColumns":["weakly supervised baselines"]},{"number":"12.03","isBolded":false,"associatedRows":["label spread [ 39 ]"],"associatedColumns":["average error rate","Food - 101N"],"associatedMergedColumns":["supervised baselines"]},{"number":"30.56","isBolded":false,"associatedRows":["average baseline"],"associatedColumns":["average error rate","Clothing1M"],"associatedMergedColumns":["unsupervised baselines"]},{"number":"15.91","isBolded":true,"associatedRows":["CleanNet"],"associatedColumns":["average error rate","Clothing1M"],"associatedMergedColumns":["CleanNet ( full supervision )"]}]},{"caption":"method \ndata \ntop-1 accuracy \nNone \nFood-101 \n81.67 \nNone \nFood-101N \n81.44 \nCleanNet, w hard Food-101N \n83.47 \nCleanNet, w sof t \nFood-101N \n83.95 \n\nTable 3. Image classification on Food-101N in terms of top-1 ac-\ncuracy (%). Verification labels in all classes are available. \"None\" \ndenotes classifier without any method for label noise. \n\n","rows":["CleanNet , w","sof t","Food - 101","hard","None","Food - 101N"],"columns":["top - 1 accuracy"],"mergedAllColumns":[],"numberCells":[{"number":"81.67","isBolded":false,"associatedRows":["None","hard","Food - 101"],"associatedColumns":["top - 1 accuracy"],"associatedMergedColumns":[]},{"number":"83.95","isBolded":true,"associatedRows":["CleanNet , w","sof t","Food - 101N"],"associatedColumns":["top - 1 accuracy"],"associatedMergedColumns":[]},{"number":"81.44","isBolded":false,"associatedRows":["None","hard","Food - 101N"],"associatedColumns":["top - 1 accuracy"],"associatedMergedColumns":[]},{"number":"83.47","isBolded":false,"associatedRows":["CleanNet , w","hard","Food - 101N"],"associatedColumns":["top - 1 accuracy"],"associatedMergedColumns":[]}]},{"caption":"# method \n\ndata \npretrained top-1 \n1 None [20] \n1M noisy ImageNet 68.94 \n2 None [20] \n50k clean ImageNet 75.19 \n3 loss correct. [20] 1M noisy ImageNet 69.84 \n4 None [20] \n50k clean #3 model \n80.38  † \n5 CleanNet,w hard \n1M noisy ImageNet 74.15 \n6 CleanNet,w sof t \n1M noisy ImageNet 74.69 \n7 None \n50k clean #6 model \n79.90 \n\nTable 4. Image classification on Clothing1M in terms of top-1 ac-\ncuracy (top-1)(%). \"None\" denotes classifier without any method \nfor label noise.  † : the result is not directly comparable to ours (See \nSec. 4.3 for more details). \n\n","rows":["loss correct . [ 20 ]","CleanNet , w","None [ 20 ]","50k clean","#3 model","1","2","3","4","#6 model","5","6","sof t","7","hard","1M noisy","None","ImageNet","Sec ."],"columns":["method","top - 1"],"mergedAllColumns":["for label noise . † : the result is not directly comparable to ours ( See"],"numberCells":[{"number":"80.38†","isBolded":true,"associatedRows":["4","None [ 20 ]","hard","50k clean","#3 model"],"associatedColumns":["top - 1"],"associatedMergedColumns":[]},{"number":"74.15","isBolded":false,"associatedRows":["5","CleanNet , w","hard","1M noisy","ImageNet"],"associatedColumns":["top - 1"],"associatedMergedColumns":[]},{"number":"68.94","isBolded":false,"associatedRows":["1","None [ 20 ]","hard","1M noisy","ImageNet"],"associatedColumns":["top - 1"],"associatedMergedColumns":[]},{"number":"79.90","isBolded":true,"associatedRows":["7","None","hard","50k clean","#6 model"],"associatedColumns":["top - 1"],"associatedMergedColumns":[]},{"number":"75.19","isBolded":false,"associatedRows":["2","None [ 20 ]","hard","50k clean","ImageNet"],"associatedColumns":["top - 1"],"associatedMergedColumns":[]},{"number":"74.69","isBolded":true,"associatedRows":["6","CleanNet , w","sof t","1M noisy","ImageNet"],"associatedColumns":["top - 1"],"associatedMergedColumns":[]},{"number":"4.3formoredetails).","isBolded":false,"associatedRows":["Sec ."],"associatedColumns":["method"],"associatedMergedColumns":["for label noise . † : the result is not directly comparable to ours ( See"]},{"number":"69.84","isBolded":false,"associatedRows":["3","loss correct . [ 20 ]","hard","1M noisy","ImageNet"],"associatedColumns":["top - 1"],"associatedMergedColumns":[]}]},{"caption":"verification \ndefinition \nevery-image \nverification labels for every image \nall-1000 \nall 1000 classes \nsemantic-308 308 classes selected from each group of \nclasses that share a common second-level \nhypernym in WordNet [18] \nrandom-308 \nrandom selected 308 classes \nrandom-118 \nrandom selected 118 classes \ndogs-118 \n118 dog classes \n\nTable 5. Verification conditions: selecting different classes for \nadding verification labels. Other than every-image, all other con-\nditions have only 250 verification labels in each class. \n\n","rows":["loss correct . [ 20 ]","CleanNet , w","None [ 20 ]","50k clean","#3 model","1","2","3","4","#6 model","5","6","sof t","7","hard","1M noisy","None","ImageNet","Sec ."],"columns":["method","top - 1"],"mergedAllColumns":["for label noise . † : the result is not directly comparable to ours ( See"],"numberCells":[{"number":"75.19","isBolded":false,"associatedRows":["2","None [ 20 ]","hard","50k clean","ImageNet"],"associatedColumns":["top - 1"],"associatedMergedColumns":[]},{"number":"69.84","isBolded":false,"associatedRows":["3","loss correct . [ 20 ]","hard","1M noisy","ImageNet"],"associatedColumns":["top - 1"],"associatedMergedColumns":[]},{"number":"68.94","isBolded":false,"associatedRows":["1","None [ 20 ]","hard","1M noisy","ImageNet"],"associatedColumns":["top - 1"],"associatedMergedColumns":[]},{"number":"74.15","isBolded":false,"associatedRows":["5","CleanNet , w","hard","1M noisy","ImageNet"],"associatedColumns":["top - 1"],"associatedMergedColumns":[]},{"number":"74.69","isBolded":true,"associatedRows":["6","CleanNet , w","sof t","1M noisy","ImageNet"],"associatedColumns":["top - 1"],"associatedMergedColumns":[]},{"number":"4.3formoredetails).","isBolded":false,"associatedRows":["Sec ."],"associatedColumns":["method"],"associatedMergedColumns":["for label noise . † : the result is not directly comparable to ours ( See"]},{"number":"80.38†","isBolded":true,"associatedRows":["4","None [ 20 ]","hard","50k clean","#3 model"],"associatedColumns":["top - 1"],"associatedMergedColumns":[]},{"number":"79.90","isBolded":true,"associatedRows":["7","None","hard","50k clean","#6 model"],"associatedColumns":["top - 1"],"associatedMergedColumns":[]}]},{"caption":"val acc top-1(top-5) \nmethod \nverification \nWebVision \nILSVRC \nbaseline \n-\n67.76(85.75) 58.88(79.76) \nupper bnd every-image \n70.31(87.77) 63.42(84.59) \nCleanNet \nall-1000 \n69.14(86.73) 61.03(82.01) \nCleanNet \nsemantic-308 68.96(86.64) 60.48(81.40) \nCleanNet \nrandom-308 \n68.89(86.61) 60.27(81.27) \nCleanNet \nrandom-118 \n68.50(86.51) 60.16(81.05) \nCleanNet \ndogs-118 \n68.33(86.04) 59.43(80.22) \n\nTable 6. Image classification on WebVision in terms of top-1 and \ntop-5 accuracy (%). The models are trained WebVision training \nset and tested on WebVision and ILSVRC validation sets under \nvarious verification conditions. \n\n","rows":[],"columns":[],"mergedAllColumns":[],"numberCells":[]},{"caption":"Table 5. ","rows":[],"columns":[],"mergedAllColumns":[],"numberCells":[]}]