[{"caption":"Table 1. Speech emotion detection models and accuracy \nModel \nAccuracy \n\nSpeech Model1 \n50.6% \n\nSpeech Model2 \n51.32% \n\nSpeech Model3 \n54.15% \n\nSpeech Model4 \n55.65% \n\nTable 2. Comparison between our Speech emotion detection \nmodels and previous research \nModel \nAccuracy \n\nLee and Tashev [3] \n62.85% \n\nOurs (improv only) \n62.72% \n\nChernykh [4] \n54% \n\nNeumann [5] \n56.10% \n\nLakomkin [14] \n56% \n\nOurs (all) \n55.65% \n\nSoftmax (like [10]). The model takes the flattened speech vec-\ntors as input and trains using cross entropy loss with Adadelta \nas the optimizer. Speech Model2 uses two stacked LSTM \nlayers with 512 and 256 units followed by a Dense layer with \n512 units and Relu activation (like [3]). Speech Model3 uses \n2 LSTM layers with 128 units each but the second LSTM \nlayer has Attention implementation as well, followed by 512 \nunits of Dense layer with Relu activation. Speech Model4 \nimproves both the encoding LSTM and Attention based de-\ncoding LSTM by making them bi-directional. All the last 3 \nmodels use Adadelta as the optimizer. As we can see the final \nAttention based bidirectional LSTM model performs the best. \n","rows":["Ours ( all )","Lee and Tashev [ 3 ]","Speech Model1","Speech Model2","Speech Model3","Ours ( improv only )","Speech Model4","Neumann [ 5 ]"],"columns":["Accuracy","56%","54%","Table 1 . Speech emotion detection models and accuracy"],"mergedAllColumns":["models and previous research"],"numberCells":[{"number":"55.65%","isBolded":false,"associatedRows":["Speech Model4"],"associatedColumns":["Table 1 . Speech emotion detection models and accuracy","Accuracy"],"associatedMergedColumns":[]},{"number":"62.72%","isBolded":false,"associatedRows":["Ours ( improv only )"],"associatedColumns":["Table 1 . Speech emotion detection models and accuracy","Accuracy","Accuracy"],"associatedMergedColumns":["models and previous research"]},{"number":"50.6%","isBolded":false,"associatedRows":["Speech Model1"],"associatedColumns":["Table 1 . Speech emotion detection models and accuracy","Accuracy"],"associatedMergedColumns":[]},{"number":"55.65%","isBolded":false,"associatedRows":["Ours ( all )"],"associatedColumns":["Table 1 . Speech emotion detection models and accuracy","Accuracy","Accuracy","54%","56%"],"associatedMergedColumns":["models and previous research"]},{"number":"62.85%","isBolded":false,"associatedRows":["Lee and Tashev [ 3 ]"],"associatedColumns":["Table 1 . Speech emotion detection models and accuracy","Accuracy","Accuracy"],"associatedMergedColumns":["models and previous research"]},{"number":"51.32%","isBolded":false,"associatedRows":["Speech Model2"],"associatedColumns":["Table 1 . Speech emotion detection models and accuracy","Accuracy"],"associatedMergedColumns":[]},{"number":"54.15%","isBolded":false,"associatedRows":["Speech Model3"],"associatedColumns":["Table 1 . Speech emotion detection models and accuracy","Accuracy"],"associatedMergedColumns":[]},{"number":"56.10%","isBolded":false,"associatedRows":["Neumann [ 5 ]"],"associatedColumns":["Table 1 . Speech emotion detection models and accuracy","Accuracy","Accuracy","54%"],"associatedMergedColumns":["models and previous research"]}]},{"caption":"Table 3. Text emotion detection models and accuracy \nModel \nAccuracy \n\nText Model1 \n62.55% \n\nText Model2 \n64.68% \n\nText Model3 \n64.78% \n\nvery common and well researched task of Natural Language \nProcessing. Here we try two approaches Text Model1 which \nuses 1D convolutions of kernel size 3 each, with 256, 128, \n64 and 32 filters using Relu as Activation and Dropout of \n0.2 probability, followed by 256 dimension fully connected \nlayer and Relu, feeding to 4 output neurons with Softmax. \nText Model2 uses two stacked LSTM layers with 512 and \n256 units followed by a Dense layer with 512 units and Relu \nActivation. Both these models are initialized with Glove Em-\nbeddings based word-vectors. We also try Randomized ini-\ntialization with 128 dimensions in Text Model3 and obtain \nsimilar performance as Text Model2. The LSTM based mod-\nels use Adadelta and Convolution based models use Adam as \noptimizers. \n\n","rows":["Text Model2 uses two stacked LSTM layers with","Text Model1","Text Model2","tialization with","Text Model3"],"columns":["Accuracy","We also try Randomized ini -","Table 3 . Text emotion detection models and accuracy","Model"],"mergedAllColumns":["Activation . Both these models are initialized with Glove Em -","layer and Relu , feeding to 4 output neurons with Softmax .","64 and 32 filters using Relu as Activation and Dropout of"],"numberCells":[{"number":"512and","isBolded":false,"associatedRows":["Text Model2 uses two stacked LSTM layers with"],"associatedColumns":["Table 3 . Text emotion detection models and accuracy","Accuracy"],"associatedMergedColumns":["layer and Relu , feeding to 4 output neurons with Softmax ."]},{"number":"512unitsandRelu","isBolded":false,"associatedRows":["Text Model3"],"associatedColumns":["Table 3 . Text emotion detection models and accuracy","Accuracy"],"associatedMergedColumns":["layer and Relu , feeding to 4 output neurons with Softmax ."]},{"number":"128dimensionsinTextModel3andobtain","isBolded":false,"associatedRows":["tialization with"],"associatedColumns":["Table 3 . Text emotion detection models and accuracy","Accuracy","We also try Randomized ini -"],"associatedMergedColumns":["Activation . Both these models are initialized with Glove Em -"]},{"number":"62.55%","isBolded":false,"associatedRows":["Text Model1"],"associatedColumns":["Table 3 . Text emotion detection models and accuracy","Accuracy"],"associatedMergedColumns":[]},{"number":"0.2probability,followedby","isBolded":false,"associatedRows":[],"associatedColumns":["Table 3 . Text emotion detection models and accuracy","Model"],"associatedMergedColumns":["64 and 32 filters using Relu as Activation and Dropout of"]},{"number":"256dimensionfullyconnected","isBolded":false,"associatedRows":[],"associatedColumns":["Table 3 . Text emotion detection models and accuracy","Accuracy"],"associatedMergedColumns":["64 and 32 filters using Relu as Activation and Dropout of"]},{"number":"64.78%","isBolded":false,"associatedRows":["Text Model3"],"associatedColumns":["Table 3 . Text emotion detection models and accuracy","Accuracy"],"associatedMergedColumns":[]},{"number":"64.68%","isBolded":false,"associatedRows":["Text Model2"],"associatedColumns":["Table 3 . Text emotion detection models and accuracy","Accuracy"],"associatedMergedColumns":[]},{"number":"256unitsfollowedbyaDenselayerwith","isBolded":false,"associatedRows":[],"associatedColumns":["Table 3 . Text emotion detection models and accuracy","Model"],"associatedMergedColumns":["layer and Relu , feeding to 4 output neurons with Softmax ."]}]},{"caption":"Table 4. MoCap emotion detection models and accuracy \nModel \nAccuracy \n\nMoCap-head Head Model1 \n37.75% \n\nMoCap-head Head Model2 \n40.28% \n\nMoCap-hand Hand Model1 \n33.70% \n\nMoCap-hand Hand Model2 \n36.94% \n\nMoCap-face Face Model1 \n48.99% \n\nMoCap-face Face Model2 \n48.58% \n\nMoCap-combined Mocap Model1 \n51.11% \n\n","rows":["MoCap - hand Hand Model1","MoCap - head Head Model2","MoCap - head Head Model1","MoCap - hand Hand Model2","MoCap - combined Mocap Model1","MoCap - face Face Model2","MoCap - face Face Model1"],"columns":["Accuracy","Table 4 . MoCap emotion detection models and accuracy"],"mergedAllColumns":[],"numberCells":[{"number":"36.94%","isBolded":false,"associatedRows":["MoCap - hand Hand Model2"],"associatedColumns":["Table 4 . MoCap emotion detection models and accuracy","Accuracy"],"associatedMergedColumns":[]},{"number":"37.75%","isBolded":false,"associatedRows":["MoCap - head Head Model1"],"associatedColumns":["Table 4 . MoCap emotion detection models and accuracy","Accuracy"],"associatedMergedColumns":[]},{"number":"51.11%","isBolded":false,"associatedRows":["MoCap - combined Mocap Model1"],"associatedColumns":["Table 4 . MoCap emotion detection models and accuracy","Accuracy"],"associatedMergedColumns":[]},{"number":"40.28%","isBolded":false,"associatedRows":["MoCap - head Head Model2"],"associatedColumns":["Table 4 . MoCap emotion detection models and accuracy","Accuracy"],"associatedMergedColumns":[]},{"number":"48.99%","isBolded":false,"associatedRows":["MoCap - face Face Model1"],"associatedColumns":["Table 4 . MoCap emotion detection models and accuracy","Accuracy"],"associatedMergedColumns":[]},{"number":"33.70%","isBolded":false,"associatedRows":["MoCap - hand Hand Model1"],"associatedColumns":["Table 4 . MoCap emotion detection models and accuracy","Accuracy"],"associatedMergedColumns":[]},{"number":"48.58%","isBolded":false,"associatedRows":["MoCap - face Face Model2"],"associatedColumns":["Table 4 . MoCap emotion detection models and accuracy","Accuracy"],"associatedMergedColumns":[]}]},{"caption":"Table 5. Multimodal emotion detection models and accuracy \nModel \nAccuracy \n\nText + Speech + Mocap Combined \n71.04% \n\nPoria [11] \n71.59% \n\n5. RESULTS \n\n5.1. Combined Multi-Modal Emotion Detection \n\nFor our final model we take the best individual models \nfor each modality without their final softmax layers. The \nText Model2 with stacked LSTMs and Glove word embed-\ndings is chosen for text modality, Speech Model4 for the \nspeech modality with 2 stacked bidirections LSTMs with At-\ntention, and combined Mocap Model1 with stacked convolu-\ntion layers. We then perform feature fusion by concatenating \ntheir final fully connected layers. We add another final fully-\nconnected layer with 256 neurons followed by a softmax \nlayer. This forms our combined final model. \n\n","rows":["Text + Speech + Mocap Combined","Poria [ 11 ]"],"columns":["Accuracy","5 .","Model","Table 5 . Multimodal emotion detection models and accuracy"],"mergedAllColumns":[],"numberCells":[{"number":"71.59%","isBolded":false,"associatedRows":["Poria [ 11 ]"],"associatedColumns":["Table 5 . Multimodal emotion detection models and accuracy","Accuracy"],"associatedMergedColumns":[]},{"number":"71.04%","isBolded":false,"associatedRows":["Text + Speech + Mocap Combined"],"associatedColumns":["Table 5 . Multimodal emotion detection models and accuracy","Accuracy"],"associatedMergedColumns":[]},{"number":"5.1.","isBolded":true,"associatedRows":[],"associatedColumns":["Table 5 . Multimodal emotion detection models and accuracy","Model","5 ."],"associatedMergedColumns":[]}]}]