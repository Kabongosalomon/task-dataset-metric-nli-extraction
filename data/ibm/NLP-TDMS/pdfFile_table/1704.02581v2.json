[{"caption":"Table 1. Comprehensive evaluation results of two-stream RNN on three datasets. \n\n","rows":["Hierarchical","Chain","3D transform","Traversal","Stacked","No transform"],"columns":["F1 - score","SBU Interaction","( % )","Precision","Cross subject","Channel","Recall","NTU RGB+D","Cross view","ChaLearn Gesture","Temporal RNN"],"mergedAllColumns":["1","Spatial RNN","Temporal RNN"],"numberCells":[{"number":"84.0","isBolded":false,"associatedRows":["Traversal"],"associatedColumns":["ChaLearn Gesture","SBU Interaction","F1 - score"],"associatedMergedColumns":["Temporal RNN"]},{"number":"89.6","isBolded":false,"associatedRows":["Stacked"],"associatedColumns":["ChaLearn Gesture","SBU Interaction","Recall"],"associatedMergedColumns":[]},{"number":"68.9","isBolded":false,"associatedRows":["Stacked"],"associatedColumns":["NTU RGB+D","SBU Interaction","Cross view"],"associatedMergedColumns":[]},{"number":"89.5","isBolded":false,"associatedRows":["Stacked"],"associatedColumns":["ChaLearn Gesture","SBU Interaction","F1 - score"],"associatedMergedColumns":[]},{"number":"67.8","isBolded":false,"associatedRows":["Hierarchical"],"associatedColumns":["NTU RGB+D","( % )","Cross subject"],"associatedMergedColumns":[]},{"number":"79.5","isBolded":false,"associatedRows":["3D transform"],"associatedColumns":["NTU RGB+D","SBU Interaction","Cross view"],"associatedMergedColumns":["Spatial RNN"]},{"number":"94.8","isBolded":false,"associatedRows":["3D transform"],"associatedColumns":["ChaLearn Gesture","SBU Interaction","Cross view"],"associatedMergedColumns":["Spatial RNN"]},{"number":"82.1","isBolded":false,"associatedRows":["Chain"],"associatedColumns":["ChaLearn Gesture","SBU Interaction","Recall"],"associatedMergedColumns":["Temporal RNN"]},{"number":"86.6","isBolded":false,"associatedRows":["Traversal"],"associatedColumns":["ChaLearn Gesture","SBU Interaction","Cross view"],"associatedMergedColumns":["Temporal RNN"]},{"number":"0.5","isBolded":true,"associatedRows":[],"associatedColumns":["NTU RGB+D","Channel","Cross subject","Temporal RNN"],"associatedMergedColumns":["1"]},{"number":"91.3","isBolded":false,"associatedRows":["No transform"],"associatedColumns":["ChaLearn Gesture","SBU Interaction","Precision"],"associatedMergedColumns":["Spatial RNN"]},{"number":"89.8","isBolded":false,"associatedRows":["Hierarchical"],"associatedColumns":["ChaLearn Gesture","SBU Interaction","Precision"],"associatedMergedColumns":[]},{"number":"71.7","isBolded":false,"associatedRows":["No transform"],"associatedColumns":["NTU RGB+D","SBU Interaction","Cross view"],"associatedMergedColumns":["Spatial RNN"]},{"number":"0.3","isBolded":true,"associatedRows":[],"associatedColumns":["NTU RGB+D","Channel","Cross subject","Temporal RNN"],"associatedMergedColumns":["1"]},{"number":"84.2","isBolded":false,"associatedRows":["Traversal"],"associatedColumns":["ChaLearn Gesture","SBU Interaction","Recall"],"associatedMergedColumns":["Temporal RNN"]},{"number":"89.9","isBolded":false,"associatedRows":["Hierarchical"],"associatedColumns":["ChaLearn Gesture","SBU Interaction","Recall"],"associatedMergedColumns":[]},{"number":"91.3","isBolded":false,"associatedRows":["No transform"],"associatedColumns":["ChaLearn Gesture","SBU Interaction","Recall"],"associatedMergedColumns":["Spatial RNN"]},{"number":"91.7","isBolded":false,"associatedRows":["3D transform"],"associatedColumns":["ChaLearn Gesture","SBU Interaction","Precision"],"associatedMergedColumns":["Spatial RNN"]},{"number":"91.7","isBolded":false,"associatedRows":["3D transform"],"associatedColumns":["ChaLearn Gesture","SBU Interaction","F1 - score"],"associatedMergedColumns":["Spatial RNN"]},{"number":"0.2","isBolded":true,"associatedRows":[],"associatedColumns":["NTU RGB+D","Channel","Cross subject","Temporal RNN"],"associatedMergedColumns":["1"]},{"number":"0.4","isBolded":true,"associatedRows":[],"associatedColumns":["NTU RGB+D","Channel","Cross subject","Temporal RNN"],"associatedMergedColumns":["1"]},{"number":"91.8","isBolded":false,"associatedRows":["3D transform"],"associatedColumns":["ChaLearn Gesture","SBU Interaction","Recall"],"associatedMergedColumns":["Spatial RNN"]},{"number":"81.9","isBolded":false,"associatedRows":["Chain"],"associatedColumns":["ChaLearn Gesture","SBU Interaction","F1 - score"],"associatedMergedColumns":["Temporal RNN"]},{"number":"91.9","isBolded":false,"associatedRows":["No transform"],"associatedColumns":["ChaLearn Gesture","SBU Interaction","Cross view"],"associatedMergedColumns":["Spatial RNN"]},{"number":"55.2","isBolded":false,"associatedRows":["Traversal"],"associatedColumns":["NTU RGB+D","( % )","Cross subject"],"associatedMergedColumns":["Temporal RNN"]},{"number":"0.8","isBolded":true,"associatedRows":[],"associatedColumns":["NTU RGB+D","Channel","Cross subject","Temporal RNN"],"associatedMergedColumns":["1"]},{"number":"0.9","isBolded":true,"associatedRows":[],"associatedColumns":["NTU RGB+D","Channel","Cross subject","Temporal RNN"],"associatedMergedColumns":["1"]},{"number":"70.5","isBolded":false,"associatedRows":["Hierarchical"],"associatedColumns":["NTU RGB+D","SBU Interaction","Cross view"],"associatedMergedColumns":[]},{"number":"66.1","isBolded":false,"associatedRows":["Stacked"],"associatedColumns":["NTU RGB+D","( % )","Cross subject"],"associatedMergedColumns":[]},{"number":"89.5","isBolded":false,"associatedRows":["Stacked"],"associatedColumns":["ChaLearn Gesture","SBU Interaction","Precision"],"associatedMergedColumns":[]},{"number":"91.3","isBolded":false,"associatedRows":["No transform"],"associatedColumns":["ChaLearn Gesture","SBU Interaction","F1 - score"],"associatedMergedColumns":["Spatial RNN"]},{"number":"53.7","isBolded":false,"associatedRows":["Chain"],"associatedColumns":["NTU RGB+D","( % )","Cross subject"],"associatedMergedColumns":["Temporal RNN"]},{"number":"81.9","isBolded":false,"associatedRows":["Chain"],"associatedColumns":["ChaLearn Gesture","SBU Interaction","Precision"],"associatedMergedColumns":["Temporal RNN"]},{"number":"60.5","isBolded":false,"associatedRows":["Traversal"],"associatedColumns":["NTU RGB+D","SBU Interaction","Cross view"],"associatedMergedColumns":["Temporal RNN"]},{"number":"68.6","isBolded":false,"associatedRows":["No transform"],"associatedColumns":["NTU RGB+D","( % )","Cross subject"],"associatedMergedColumns":["Spatial RNN"]},{"number":"0.7","isBolded":true,"associatedRows":[],"associatedColumns":["NTU RGB+D","Channel","Cross subject","Temporal RNN"],"associatedMergedColumns":["1"]},{"number":"90.2","isBolded":false,"associatedRows":["Hierarchical"],"associatedColumns":["ChaLearn Gesture","SBU Interaction","Cross view"],"associatedMergedColumns":[]},{"number":"0.6","isBolded":true,"associatedRows":[],"associatedColumns":["NTU RGB+D","Channel","Cross subject","Temporal RNN"],"associatedMergedColumns":["1"]},{"number":"84.0","isBolded":false,"associatedRows":["Traversal"],"associatedColumns":["ChaLearn Gesture","SBU Interaction","Precision"],"associatedMergedColumns":["Temporal RNN"]},{"number":"82.2","isBolded":false,"associatedRows":["Chain"],"associatedColumns":["ChaLearn Gesture","SBU Interaction","Cross view"],"associatedMergedColumns":["Temporal RNN"]},{"number":"71.3","isBolded":false,"associatedRows":["3D transform"],"associatedColumns":["NTU RGB+D","( % )","Cross subject"],"associatedMergedColumns":["Spatial RNN"]},{"number":"89.7","isBolded":false,"associatedRows":["Hierarchical"],"associatedColumns":["ChaLearn Gesture","SBU Interaction","F1 - score"],"associatedMergedColumns":[]},{"number":"89.0","isBolded":false,"associatedRows":["Stacked"],"associatedColumns":["ChaLearn Gesture","SBU Interaction","Cross view"],"associatedMergedColumns":[]},{"number":"58.9","isBolded":false,"associatedRows":["Chain"],"associatedColumns":["NTU RGB+D","SBU Interaction","Cross view"],"associatedMergedColumns":["Temporal RNN"]}]},{"caption":"Table 2. Empirical study of networks structures. For stacked RNN, \nR512-512 denotes two stacked layers of RNN with 512 hidden \nneurons. Similarly, R1024 denotes one RNN layer with 1024 hid-\nden neurons. For hierarchical RNN, P128-128, B512 denotes two \nstacked RNN layers with 128 hidden neurons for the body part and \none RNN layer with 512 hidden neurons for the whole body. And \nso on for the other symbols. The default structures of stacked RNN \nand hierarchical RNN are R512-512 and P128, B512, respectively. \n\n","rows":["P128 - 128 , B512","P128 , B1024","R512 - 512","R512","P128 , B512","R256 - 256","R1024 - 1024","P256 , B1024","R512 - 512 - 512","P256 , B512"],"columns":["Stacked RNN","Hierarchical RNN"],"mergedAllColumns":[],"numberCells":[{"number":"72.2","isBolded":false,"associatedRows":["R256 - 256","P256 , B1024"],"associatedColumns":["Hierarchical RNN"],"associatedMergedColumns":[]},{"number":"68.2","isBolded":false,"associatedRows":["R256 - 256"],"associatedColumns":["Stacked RNN"],"associatedMergedColumns":[]},{"number":"70.5","isBolded":false,"associatedRows":["R512 - 512","P128 , B512"],"associatedColumns":["Hierarchical RNN"],"associatedMergedColumns":[]},{"number":"71.4","isBolded":false,"associatedRows":["R512 - 512 - 512","P128 - 128 , B512"],"associatedColumns":["Hierarchical RNN"],"associatedMergedColumns":[]},{"number":"71.4","isBolded":false,"associatedRows":["R512","P256 , B512"],"associatedColumns":["Hierarchical RNN"],"associatedMergedColumns":[]},{"number":"69.2","isBolded":false,"associatedRows":["R512 - 512 - 512"],"associatedColumns":["Stacked RNN"],"associatedMergedColumns":[]},{"number":"68.9","isBolded":false,"associatedRows":["R512 - 512"],"associatedColumns":["Stacked RNN"],"associatedMergedColumns":[]},{"number":"68.6","isBolded":false,"associatedRows":["R512"],"associatedColumns":["Stacked RNN"],"associatedMergedColumns":[]},{"number":"68.9","isBolded":false,"associatedRows":["R1024 - 1024"],"associatedColumns":["Stacked RNN"],"associatedMergedColumns":[]},{"number":"70.6","isBolded":false,"associatedRows":["R1024 - 1024","P128 , B1024"],"associatedColumns":["Hierarchical RNN"],"associatedMergedColumns":[]}]},{"caption":"Table 3. Comparison of the proposed approach with the state-of-\nthe-art methods on the NTU RGB+D dataset. \nMethod \nCross subject Cross view \nLie Group [44]  50.1 \n52.8 \nSkeletal Quads [10]  38.6 \n41.4 \nFTP Dynamic [18]  60.2 \n65.2 \nHBRNN [7]  59.1 \n64.0 \nPart-aware LSTM [37]  62.9 \n70.3 \nTrust Gate ST-LSTM [30]  69.2 \n77.7 \nTwo-stream RNN \n71.3 \n79.5 \n\nTable 4. Comparison of the proposed approach with the state-of-\nthe-art methods on the SBU Interaction dataset. \nMethod \nAccuracy \nJoint Feature [53]  80.3 \nJoint Feature [22]  86.9 \nHBRNN [7]  80.4 \nDeep LSTM [55]  86.0 \nCo-occurrence LSTM [55]  90.4 \nTrust Gate ST-LSTM [30]  93.3 \nTwo-stream RNN \n94.8 \n\nTable 5. Comparison of the proposed approach with the state-of-\nthe-art methods on the ChaLearn Gesture Recognition dataset. \n\n","rows":["Skeleton Feature [ 48 ]","Lie Group [ 44 ]","HiVideoDarwin [ 45 ]","FTP Dynamic [ 18 ]","Deep LSTM [ 55 ]","Portfolios [ 52 ]","Co - occurrence LSTM [ 55 ]","-","Part - aware LSTM [ 37 ]","Two - stream RNN","Gesture Spotting [ 35 ]","Skeletal Quads [ 10 ]","Joint Feature [ 53 ]","Joint Feature [ 22 ]","Trust Gate ST - LSTM [ 30 ]","VideoDarwin [ 12 ]","CNN for Skeleton [ 5 ]","HBRNN [ 7 ]"],"columns":["F1 - score","Accuracy","Precision","Cross subject","Recall","Method","Table 3 . Comparison of the proposed approach with the state - of -","Cross view"],"mergedAllColumns":["the - art methods on the SBU Interaction dataset .","the - art methods on the NTU RGB+D dataset .","the - art methods on the ChaLearn Gesture Recognition dataset ."],"numberCells":[{"number":"86.9","isBolded":false,"associatedRows":["Trust Gate ST - LSTM [ 30 ]","Joint Feature [ 22 ]"],"associatedColumns":["Table 3 . Comparison of the proposed approach with the state - of -","Cross subject","Accuracy"],"associatedMergedColumns":["the - art methods on the SBU Interaction dataset ."]},{"number":"65.2","isBolded":false,"associatedRows":["FTP Dynamic [ 18 ]","Joint Feature [ 53 ]"],"associatedColumns":["Table 3 . Comparison of the proposed approach with the state - of -","Cross view"],"associatedMergedColumns":["the - art methods on the NTU RGB+D dataset ."]},{"number":"80.3","isBolded":false,"associatedRows":["Trust Gate ST - LSTM [ 30 ]","Joint Feature [ 53 ]"],"associatedColumns":["Table 3 . Comparison of the proposed approach with the state - of -","Cross subject","Accuracy"],"associatedMergedColumns":["the - art methods on the SBU Interaction dataset ."]},{"number":"59.3","isBolded":false,"associatedRows":["Skeleton Feature [ 48 ]","-"],"associatedColumns":["Table 3 . Comparison of the proposed approach with the state - of -","Cross subject","Accuracy","Recall"],"associatedMergedColumns":["the - art methods on the ChaLearn Gesture Recognition dataset ."]},{"number":"91.7","isBolded":true,"associatedRows":["Two - stream RNN"],"associatedColumns":["Table 3 . Comparison of the proposed approach with the state - of -","Cross subject","Method","Precision"],"associatedMergedColumns":["the - art methods on the ChaLearn Gesture Recognition dataset ."]},{"number":"59.6","isBolded":false,"associatedRows":["Skeleton Feature [ 48 ]","-"],"associatedColumns":["Table 3 . Comparison of the proposed approach with the state - of -","Cross view","Accuracy","F1 - score"],"associatedMergedColumns":["the - art methods on the ChaLearn Gesture Recognition dataset ."]},{"number":"38.6","isBolded":false,"associatedRows":["Skeletal Quads [ 10 ]","Joint Feature [ 53 ]"],"associatedColumns":["Table 3 . Comparison of the proposed approach with the state - of -","Cross subject"],"associatedMergedColumns":["the - art methods on the NTU RGB+D dataset ."]},{"number":"75.6","isBolded":false,"associatedRows":["HiVideoDarwin [ 45 ]","-"],"associatedColumns":["Table 3 . Comparison of the proposed approach with the state - of -","Cross subject","Accuracy","Recall"],"associatedMergedColumns":["the - art methods on the ChaLearn Gesture Recognition dataset ."]},{"number":"86.0","isBolded":false,"associatedRows":["Two - stream RNN","Deep LSTM [ 55 ]"],"associatedColumns":["Table 3 . Comparison of the proposed approach with the state - of -","Cross subject","Accuracy"],"associatedMergedColumns":["the - art methods on the SBU Interaction dataset ."]},{"number":"75.3","isBolded":false,"associatedRows":["VideoDarwin [ 12 ]"],"associatedColumns":["Table 3 . Comparison of the proposed approach with the state - of -","Cross subject","Method","Precision"],"associatedMergedColumns":["the - art methods on the ChaLearn Gesture Recognition dataset ."]},{"number":"91.3","isBolded":false,"associatedRows":["CNN for Skeleton [ 5 ]","-"],"associatedColumns":["Table 3 . Comparison of the proposed approach with the state - of -","Cross subject","Accuracy","Recall"],"associatedMergedColumns":["the - art methods on the ChaLearn Gesture Recognition dataset ."]},{"number":"91.2","isBolded":false,"associatedRows":["CNN for Skeleton [ 5 ]","-"],"associatedColumns":["Table 3 . Comparison of the proposed approach with the state - of -","Cross view","Accuracy","F1 - score"],"associatedMergedColumns":["the - art methods on the ChaLearn Gesture Recognition dataset ."]},{"number":"90.4","isBolded":false,"associatedRows":["Skeleton Feature [ 48 ]","Co - occurrence LSTM [ 55 ]"],"associatedColumns":["Table 3 . Comparison of the proposed approach with the state - of -","Cross subject","Accuracy"],"associatedMergedColumns":["the - art methods on the SBU Interaction dataset ."]},{"number":"62.3","isBolded":false,"associatedRows":["Gesture Spotting [ 35 ]","-"],"associatedColumns":["Table 3 . Comparison of the proposed approach with the state - of -","Cross subject","Accuracy","Recall"],"associatedMergedColumns":["the - art methods on the ChaLearn Gesture Recognition dataset ."]},{"number":"94.8","isBolded":true,"associatedRows":["Skeleton Feature [ 48 ]","Two - stream RNN"],"associatedColumns":["Table 3 . Comparison of the proposed approach with the state - of -","Cross subject","Accuracy"],"associatedMergedColumns":["the - art methods on the SBU Interaction dataset ."]},{"number":"64.0","isBolded":false,"associatedRows":["HBRNN [ 7 ]","Joint Feature [ 53 ]"],"associatedColumns":["Table 3 . Comparison of the proposed approach with the state - of -","Cross view"],"associatedMergedColumns":["the - art methods on the NTU RGB+D dataset ."]},{"number":"62.9","isBolded":false,"associatedRows":["Part - aware LSTM [ 37 ]","Joint Feature [ 53 ]"],"associatedColumns":["Table 3 . Comparison of the proposed approach with the state - of -","Cross subject"],"associatedMergedColumns":["the - art methods on the NTU RGB+D dataset ."]},{"number":"77.7","isBolded":false,"associatedRows":["Trust Gate ST - LSTM [ 30 ]","Joint Feature [ 53 ]"],"associatedColumns":["Table 3 . Comparison of the proposed approach with the state - of -","Cross view"],"associatedMergedColumns":["the - art methods on the NTU RGB+D dataset ."]},{"number":"50.1","isBolded":false,"associatedRows":["Lie Group [ 44 ]","Joint Feature [ 53 ]"],"associatedColumns":["Table 3 . Comparison of the proposed approach with the state - of -","Cross subject"],"associatedMergedColumns":["the - art methods on the NTU RGB+D dataset ."]},{"number":"80.4","isBolded":false,"associatedRows":["Two - stream RNN","HBRNN [ 7 ]"],"associatedColumns":["Table 3 . Comparison of the proposed approach with the state - of -","Cross subject","Accuracy"],"associatedMergedColumns":["the - art methods on the SBU Interaction dataset ."]},{"number":"61.7","isBolded":false,"associatedRows":["Gesture Spotting [ 35 ]","-"],"associatedColumns":["Table 3 . Comparison of the proposed approach with the state - of -","Cross view","Accuracy","F1 - score"],"associatedMergedColumns":["the - art methods on the ChaLearn Gesture Recognition dataset ."]},{"number":"75.1","isBolded":false,"associatedRows":["VideoDarwin [ 12 ]","-"],"associatedColumns":["Table 3 . Comparison of the proposed approach with the state - of -","Cross subject","Accuracy","Recall"],"associatedMergedColumns":["the - art methods on the ChaLearn Gesture Recognition dataset ."]},{"number":"91.7","isBolded":true,"associatedRows":["Two - stream RNN","-"],"associatedColumns":["Table 3 . Comparison of the proposed approach with the state - of -","Cross view","Accuracy","F1 - score"],"associatedMergedColumns":["the - art methods on the ChaLearn Gesture Recognition dataset ."]},{"number":"41.4","isBolded":false,"associatedRows":["Skeletal Quads [ 10 ]","Joint Feature [ 53 ]"],"associatedColumns":["Table 3 . Comparison of the proposed approach with the state - of -","Cross view"],"associatedMergedColumns":["the - art methods on the NTU RGB+D dataset ."]},{"number":"59.1","isBolded":false,"associatedRows":["HBRNN [ 7 ]","Joint Feature [ 53 ]"],"associatedColumns":["Table 3 . Comparison of the proposed approach with the state - of -","Cross subject"],"associatedMergedColumns":["the - art methods on the NTU RGB+D dataset ."]},{"number":"60.2","isBolded":false,"associatedRows":["FTP Dynamic [ 18 ]","Joint Feature [ 53 ]"],"associatedColumns":["Table 3 . Comparison of the proposed approach with the state - of -","Cross subject"],"associatedMergedColumns":["the - art methods on the NTU RGB+D dataset ."]},{"number":"75.2","isBolded":false,"associatedRows":["VideoDarwin [ 12 ]","-"],"associatedColumns":["Table 3 . Comparison of the proposed approach with the state - of -","Cross view","Accuracy","F1 - score"],"associatedMergedColumns":["the - art methods on the ChaLearn Gesture Recognition dataset ."]},{"number":"74.9","isBolded":false,"associatedRows":["HiVideoDarwin [ 45 ]"],"associatedColumns":["Table 3 . Comparison of the proposed approach with the state - of -","Cross subject","Method","Precision"],"associatedMergedColumns":["the - art methods on the ChaLearn Gesture Recognition dataset ."]},{"number":"91.2","isBolded":false,"associatedRows":["CNN for Skeleton [ 5 ]"],"associatedColumns":["Table 3 . Comparison of the proposed approach with the state - of -","Cross subject","Method","Precision"],"associatedMergedColumns":["the - art methods on the ChaLearn Gesture Recognition dataset ."]},{"number":"52.8","isBolded":false,"associatedRows":["Lie Group [ 44 ]","Joint Feature [ 53 ]"],"associatedColumns":["Table 3 . Comparison of the proposed approach with the state - of -","Cross view"],"associatedMergedColumns":["the - art methods on the NTU RGB+D dataset ."]},{"number":"56.0","isBolded":false,"associatedRows":["Portfolios [ 52 ]","-","-"],"associatedColumns":["Table 3 . Comparison of the proposed approach with the state - of -","Cross view","Accuracy","F1 - score"],"associatedMergedColumns":["the - art methods on the ChaLearn Gesture Recognition dataset ."]},{"number":"74.6","isBolded":false,"associatedRows":["HiVideoDarwin [ 45 ]","-"],"associatedColumns":["Table 3 . Comparison of the proposed approach with the state - of -","Cross view","Accuracy","F1 - score"],"associatedMergedColumns":["the - art methods on the ChaLearn Gesture Recognition dataset ."]},{"number":"71.3","isBolded":true,"associatedRows":["Two - stream RNN","Joint Feature [ 53 ]"],"associatedColumns":["Table 3 . Comparison of the proposed approach with the state - of -","Cross subject"],"associatedMergedColumns":["the - art methods on the NTU RGB+D dataset ."]},{"number":"70.3","isBolded":false,"associatedRows":["Part - aware LSTM [ 37 ]","Joint Feature [ 53 ]"],"associatedColumns":["Table 3 . Comparison of the proposed approach with the state - of -","Cross view"],"associatedMergedColumns":["the - art methods on the NTU RGB+D dataset ."]},{"number":"79.5","isBolded":true,"associatedRows":["Two - stream RNN","Joint Feature [ 53 ]"],"associatedColumns":["Table 3 . Comparison of the proposed approach with the state - of -","Cross view"],"associatedMergedColumns":["the - art methods on the NTU RGB+D dataset ."]},{"number":"61.2","isBolded":false,"associatedRows":["Gesture Spotting [ 35 ]"],"associatedColumns":["Table 3 . Comparison of the proposed approach with the state - of -","Cross subject","Method","Precision"],"associatedMergedColumns":["the - art methods on the ChaLearn Gesture Recognition dataset ."]},{"number":"69.2","isBolded":false,"associatedRows":["Trust Gate ST - LSTM [ 30 ]","Joint Feature [ 53 ]"],"associatedColumns":["Table 3 . Comparison of the proposed approach with the state - of -","Cross subject"],"associatedMergedColumns":["the - art methods on the NTU RGB+D dataset ."]},{"number":"91.8","isBolded":true,"associatedRows":["Two - stream RNN","-"],"associatedColumns":["Table 3 . Comparison of the proposed approach with the state - of -","Cross subject","Accuracy","Recall"],"associatedMergedColumns":["the - art methods on the ChaLearn Gesture Recognition dataset ."]},{"number":"59.9","isBolded":false,"associatedRows":["Skeleton Feature [ 48 ]"],"associatedColumns":["Table 3 . Comparison of the proposed approach with the state - of -","Cross subject","Method","Precision"],"associatedMergedColumns":["the - art methods on the ChaLearn Gesture Recognition dataset ."]},{"number":"93.3","isBolded":false,"associatedRows":["Skeleton Feature [ 48 ]","Trust Gate ST - LSTM [ 30 ]"],"associatedColumns":["Table 3 . Comparison of the proposed approach with the state - of -","Cross subject","Accuracy"],"associatedMergedColumns":["the - art methods on the SBU Interaction dataset ."]}]}]