[{"caption":"Table 2: We report the mean and standard deviation of one-class classification AUCs averaged over \nclasses over 5 runs. The best methods are bold-faced for each setting. The per-class AUCs are \nreported in Appendix A.5. All methods are implemented and evaluated under the same condition. \n\n","rows":["83 . 4±1 . 0","85 . 6±0 . 5","86 . 5±0 . 7","87 . 4±1 . 7","Golan and El - Yaniv [ 20 ] †","KDE","89 . 6±0 . 5","89 . 6±0 . 4","90 . 8±0 . 3","86 . 1±0 . 3","Bergman and Hoshen [ 22 ] †","81 . 9±0 . 5","84 . 1±0 . 6","82 . 8±0 . 6","95 . 8±0 . 3","Ruff et al . [ 16 ]","-","93 . 7±0 . 4","87 . 7±0 . 5","86 . 8±0 . 4","91 . 3±0 . 3","87 . 7±0 . 4","77 . 4±1 . 0","84 . 6±2 . 5","Rotation Classifier","92 . 5±0 . 6","67 . 0±0 . 7","82 . 4±0 . 8","94 . 6±0 . 3","69 . 5±1 . 7","86 . 4±0 . 6","75 . 2±1 . 0","66 . 8±0 . 9","83 . 7±0 . 6","83 . 5±1 . 0","51 . 4±3 . 9","89 . 3±0 . 3","65 . 8±0 . 9","80 . 3±0 . 5","86 . 4±0 . 2","92 . 4±0 . 7","OC - SVM","Hendrycks et al . [ 21 ] †","83 . 5±2 . 4","Huang et al . [ 36 ] †","89 . 0±0 . 7","93 . 6±0 . 3","57 . 3±1 . 3","94 . 5±0 . 4","84 . 5±1 . 1","93 . 9±0 . 3","94 . 8±0 . 3","93 . 9±0 . 4"],"columns":["cat - vs - dog","Mean","f - MNIST","CIFAR - 10","Cat - vs - Dog","Classifier","CelebA","CIFAR - 100","-"],"mergedAllColumns":["Rotation Prediction","RotNet [ 20 ]","ResNet - 50 ( ImageNet )","Contrastive ( DA )","Contrastive","-","Denoising"],"numberCells":[{"number":"78.8","isBolded":false,"associatedRows":["Huang et al . [ 36 ] †","KDE"],"associatedColumns":["CIFAR - 10","CIFAR - 100","-","-"],"associatedMergedColumns":["-"]},{"number":"83.1","isBolded":false,"associatedRows":["Bergman and Hoshen [ 22 ] †","Rotation Classifier","86 . 8±0 . 4","80 . 3±0 . 5","87 . 4±1 . 7","86 . 1±0 . 3","51 . 4±3 . 9"],"associatedColumns":["Mean"],"associatedMergedColumns":["ResNet - 50 ( ImageNet )"]},{"number":"86.6","isBolded":false,"associatedRows":["Bergman and Hoshen [ 22 ] †","KDE","89 . 3±0 . 3","81 . 9±0 . 5","94 . 6±0 . 3","86 . 4±0 . 2","77 . 4±1 . 0"],"associatedColumns":["Mean"],"associatedMergedColumns":["ResNet - 50 ( ImageNet )"]},{"number":"64.8","isBolded":false,"associatedRows":["Ruff et al . [ 16 ]"],"associatedColumns":["Classifier","CIFAR - 10"],"associatedMergedColumns":["Contrastive ( DA )"]},{"number":"74.5","isBolded":false,"associatedRows":["Golan and El - Yaniv [ 20 ] †","OC - SVM","86 . 8±0 . 4","80 . 3±0 . 5","87 . 4±1 . 7"],"associatedColumns":["Cat - vs - Dog"],"associatedMergedColumns":[]},{"number":"89.9","isBolded":true,"associatedRows":["Bergman and Hoshen [ 22 ] †","OC - SVM","92 . 5±0 . 6","86 . 5±0 . 7","94 . 8±0 . 3","89 . 6±0 . 5","84 . 5±1 . 1"],"associatedColumns":["Mean"],"associatedMergedColumns":["Contrastive"]},{"number":"89.8","isBolded":true,"associatedRows":["Bergman and Hoshen [ 22 ] †","KDE","92 . 4±0 . 7","86 . 5±0 . 7","94 . 5±0 . 4","89 . 6±0 . 4","85 . 6±0 . 5"],"associatedColumns":["Mean"],"associatedMergedColumns":["Contrastive"]},{"number":"83.7","isBolded":false,"associatedRows":["Golan and El - Yaniv [ 20 ] †","KDE","86 . 8±0 . 4","80 . 3±0 . 5","87 . 4±1 . 7","86 . 1±0 . 3","51 . 4±3 . 9"],"associatedColumns":["Mean"],"associatedMergedColumns":[]},{"number":"83.7","isBolded":false,"associatedRows":["Golan and El - Yaniv [ 20 ] †","OC - SVM","86 . 8±0 . 4"],"associatedColumns":["CIFAR - 100"],"associatedMergedColumns":[]},{"number":"82.4","isBolded":false,"associatedRows":["Golan and El - Yaniv [ 20 ] †","KDE","86 . 8±0 . 4","80 . 3±0 . 5","87 . 4±1 . 7","86 . 1±0 . 3"],"associatedColumns":["CelebA"],"associatedMergedColumns":[]},{"number":"74.6","isBolded":false,"associatedRows":["Golan and El - Yaniv [ 20 ] †","KDE","86 . 8±0 . 4","80 . 3±0 . 5","87 . 4±1 . 7"],"associatedColumns":["Cat - vs - Dog"],"associatedMergedColumns":[]},{"number":"86.9","isBolded":false,"associatedRows":["Bergman and Hoshen [ 22 ] †","OC - SVM","89 . 0±0 . 7","82 . 4±0 . 8","93 . 9±0 . 3","87 . 7±0 . 5","83 . 5±2 . 4"],"associatedColumns":["Mean"],"associatedMergedColumns":["Rotation Prediction"]},{"number":"93.5","isBolded":false,"associatedRows":["Golan and El - Yaniv [ 20 ] †","KDE"],"associatedColumns":["CIFAR - 10","f - MNIST","-"],"associatedMergedColumns":["Contrastive ( DA )"]},{"number":"80.4","isBolded":false,"associatedRows":["Bergman and Hoshen [ 22 ] †","OC - SVM","83 . 4±1 . 0","75 . 2±1 . 0","93 . 9±0 . 4","57 . 3±1 . 3","66 . 8±0 . 9"],"associatedColumns":["Mean"],"associatedMergedColumns":["RotNet [ 20 ]"]},{"number":"91.8","isBolded":false,"associatedRows":["Golan and El - Yaniv [ 20 ] †","OC - SVM","86 . 8±0 . 4","80 . 3±0 . 5"],"associatedColumns":["f - MNIST"],"associatedMergedColumns":[]},{"number":"81.4","isBolded":false,"associatedRows":["Golan and El - Yaniv [ 20 ] †","OC - SVM","86 . 8±0 . 4","80 . 3±0 . 5","87 . 4±1 . 7","86 . 1±0 . 3"],"associatedColumns":["CelebA"],"associatedMergedColumns":[]},{"number":"90.5","isBolded":false,"associatedRows":["Golan and El - Yaniv [ 20 ] †","KDE","86 . 8±0 . 4","80 . 3±0 . 5"],"associatedColumns":["f - MNIST"],"associatedMergedColumns":[]},{"number":"86.6","isBolded":false,"associatedRows":["Huang et al . [ 36 ] †"],"associatedColumns":["Classifier","CIFAR - 10","-","-"],"associatedMergedColumns":["-"]},{"number":"80.0","isBolded":false,"associatedRows":["Golan and El - Yaniv [ 20 ] †","KDE"],"associatedColumns":["CIFAR - 10"],"associatedMergedColumns":[]},{"number":"93.9","isBolded":false,"associatedRows":["Huang et al . [ 36 ] †","KDE"],"associatedColumns":["CIFAR - 10","f - MNIST","-","-"],"associatedMergedColumns":["-"]},{"number":"87.1","isBolded":false,"associatedRows":["Bergman and Hoshen [ 22 ] †","OC - SVM","90 . 8±0 . 3","82 . 8±0 . 6","94 . 6±0 . 3","83 . 7±0 . 6","65 . 8±0 . 9"],"associatedColumns":["Mean"],"associatedMergedColumns":["Denoising"]},{"number":"88.2","isBolded":false,"associatedRows":["Bergman and Hoshen [ 22 ] †","KDE","91 . 3±0 . 3","84 . 1±0 . 6","95 . 8±0 . 3","86 . 4±0 . 6","69 . 5±1 . 7"],"associatedColumns":["Mean"],"associatedMergedColumns":["Denoising"]},{"number":"88.2","isBolded":false,"associatedRows":["Bergman and Hoshen [ 22 ] †"],"associatedColumns":["Classifier","CIFAR - 10","-"],"associatedMergedColumns":["Contrastive ( DA )"]},{"number":"84.0","isBolded":false,"associatedRows":["Golan and El - Yaniv [ 20 ] †","OC - SVM","86 . 8±0 . 4","80 . 3±0 . 5","87 . 4±1 . 7","86 . 1±0 . 3","51 . 4±3 . 9"],"associatedColumns":["Mean"],"associatedMergedColumns":[]},{"number":"94.1","isBolded":false,"associatedRows":["Bergman and Hoshen [ 22 ] †","KDE","-"],"associatedColumns":["CIFAR - 10","f - MNIST","-"],"associatedMergedColumns":["Contrastive ( DA )"]},{"number":"83.7","isBolded":false,"associatedRows":["Golan and El - Yaniv [ 20 ] †","KDE","86 . 8±0 . 4"],"associatedColumns":["CIFAR - 100"],"associatedMergedColumns":[]},{"number":"78.7","isBolded":false,"associatedRows":["Golan and El - Yaniv [ 20 ] †","KDE"],"associatedColumns":["CIFAR - 10","CIFAR - 100","-"],"associatedMergedColumns":["Contrastive ( DA )"]},{"number":"86.0","isBolded":false,"associatedRows":["Golan and El - Yaniv [ 20 ] †"],"associatedColumns":["Classifier","CIFAR - 10","-"],"associatedMergedColumns":["Contrastive ( DA )"]},{"number":"90.1","isBolded":false,"associatedRows":["Hendrycks et al . [ 21 ] †"],"associatedColumns":["Classifier","CIFAR - 10","-"],"associatedMergedColumns":["-"]},{"number":"80.0","isBolded":false,"associatedRows":["Golan and El - Yaniv [ 20 ] †","OC - SVM"],"associatedColumns":["CIFAR - 10"],"associatedMergedColumns":[]},{"number":"88.8","isBolded":false,"associatedRows":["Golan and El - Yaniv [ 20 ] †","KDE","92 . 4±0 . 7"],"associatedColumns":["CIFAR - 100","cat - vs - dog","-"],"associatedMergedColumns":["Contrastive ( DA )"]},{"number":"80.4","isBolded":false,"associatedRows":["Bergman and Hoshen [ 22 ] †","KDE","83 . 5±1 . 0","75 . 2±1 . 0","93 . 7±0 . 4","57 . 3±1 . 3","67 . 0±0 . 7"],"associatedColumns":["Mean"],"associatedMergedColumns":["RotNet [ 20 ]"]},{"number":"86.8","isBolded":false,"associatedRows":["Bergman and Hoshen [ 22 ] †","KDE","89 . 0±0 . 7","82 . 4±0 . 8","93 . 6±0 . 3","87 . 7±0 . 4","84 . 6±2 . 5"],"associatedColumns":["Mean"],"associatedMergedColumns":["Rotation Prediction"]}]},{"caption":"Table 4: Image-level detection and pixel-level localization AUCs on MVTec anomaly detection \ndataset ","rows":["2","prised of","MMD","6","8","batch size","Contrastive g f","AUC","Contrastive ( DA ) g f"],"columns":["We use","Contrastive ( DA ) f","83 . 5±3 . 0","Vanilla CLR †","Figure 4 : Ablation study of contrastive representations trained with different batch sizes .","RotNet †","86 . 5±1 . 6","75 . 6±2 . 1","92 . 6±1 . 0","86 . 3±2 . 4","85 . 6±1 . 3","( c ) AUCs with various MLP depths .","RotNet ( MLP head ) †","93 . 0±0 . 9","Localization","71 . 0±3 . 5","Depth of MLP head","( a ) MMDs with various batch sizes .","90 . 4±0 . 8","0","8","Contrastive f","Detection","80 . 2±1 . 8","DistAug CLR †"],"mergedAllColumns":["Contrastive g f","We further improve the performance with model ensemble , which we report in Appendix A . 2 . 2 .","Finally , we evaluate our proposed framework on MVTec [ 31 ] defect detection dataset , which is com -","Contrastive ( DA ) g f"],"numberCells":[{"number":"102","isBolded":false,"associatedRows":[],"associatedColumns":["RotNet †","Detection","Localization","Contrastive f","Contrastive ( DA ) f"],"associatedMergedColumns":["Contrastive g f"]},{"number":"64","isBolded":false,"associatedRows":["8","6","2","8"],"associatedColumns":["RotNet ( MLP head ) †","86 . 3±2 . 4","93 . 0±0 . 9","Contrastive f","Contrastive ( DA ) f"],"associatedMergedColumns":["Contrastive ( DA ) g f"]},{"number":"70","isBolded":false,"associatedRows":["8","Contrastive g f","Contrastive g f"],"associatedColumns":["Vanilla CLR †","80 . 2±1 . 8","85 . 6±1 . 3"],"associatedMergedColumns":["Contrastive ( DA ) g f"]},{"number":"128","isBolded":false,"associatedRows":["8"],"associatedColumns":["RotNet †","71 . 0±3 . 5","75 . 6±2 . 1","Contrastive f","Contrastive ( DA ) f"],"associatedMergedColumns":["Contrastive ( DA ) g f"]},{"number":"51","isBolded":false,"associatedRows":["8","batch size","6"],"associatedColumns":["RotNet †","71 . 0±3 . 5","75 . 6±2 . 1","Contrastive f","Contrastive ( DA ) f"],"associatedMergedColumns":["Contrastive ( DA ) g f"]},{"number":"30","isBolded":false,"associatedRows":["8","6"],"associatedColumns":["RotNet †","83 . 5±3 . 0","92 . 6±1 . 0","Contrastive f","Contrastive ( DA ) f"],"associatedMergedColumns":["Contrastive g f"]},{"number":"30","isBolded":false,"associatedRows":["8","6","2","8","6","2"],"associatedColumns":["Vanilla CLR †","80 . 2±1 . 8","85 . 6±1 . 3","Contrastive f","Contrastive ( DA ) f"],"associatedMergedColumns":["Contrastive g f"]},{"number":"32","isBolded":false,"associatedRows":["8","6","2","8"],"associatedColumns":["RotNet ( MLP head ) †","86 . 3±2 . 4","93 . 0±0 . 9","Contrastive f","Contrastive ( DA ) f"],"associatedMergedColumns":["Contrastive ( DA ) g f"]},{"number":"15differentcategories,includingobjectsandtextures.Insteadoflearningrepresentations","isBolded":true,"associatedRows":["prised of"],"associatedColumns":["DistAug CLR †","86 . 5±1 . 6","80 . 2±1 . 8","93 . 0±0 . 9","90 . 4±0 . 8","Contrastive f","Contrastive f","Contrastive ( DA ) f","Contrastive ( DA ) f","8","Depth of MLP head","( c ) AUCs with various MLP depths .","We use"],"associatedMergedColumns":["Finally , we evaluate our proposed framework on MVTec [ 31 ] defect detection dataset , which is com -"]},{"number":"32","isBolded":false,"associatedRows":["8"],"associatedColumns":["RotNet †","Detection","Localization","Contrastive f","Contrastive ( DA ) f"],"associatedMergedColumns":["Contrastive ( DA ) g f"]},{"number":"25","isBolded":false,"associatedRows":["8","batch size","6","2","8","batch size"],"associatedColumns":["RotNet ( MLP head ) †","86 . 3±2 . 4","93 . 0±0 . 9","Contrastive f","Contrastive ( DA ) f"],"associatedMergedColumns":["Contrastive ( DA ) g f"]},{"number":"70","isBolded":false,"associatedRows":["8","Contrastive g f"],"associatedColumns":["RotNet †","83 . 5±3 . 0","92 . 6±1 . 0"],"associatedMergedColumns":["Contrastive ( DA ) g f"]},{"number":"50","isBolded":false,"associatedRows":["8","Contrastive g f","Contrastive g f"],"associatedColumns":["Vanilla CLR †","80 . 2±1 . 8","85 . 6±1 . 3"],"associatedMergedColumns":["Contrastive ( DA ) g f"]},{"number":"90","isBolded":false,"associatedRows":["8","Contrastive g f","Contrastive g f"],"associatedColumns":["Vanilla CLR †","80 . 2±1 . 8","85 . 6±1 . 3"],"associatedMergedColumns":[]},{"number":"64","isBolded":false,"associatedRows":["8"],"associatedColumns":["RotNet †","71 . 0±3 . 5","Localization","Contrastive f","Contrastive ( DA ) f"],"associatedMergedColumns":["Contrastive ( DA ) g f"]},{"number":"25","isBolded":false,"associatedRows":["8","batch size"],"associatedColumns":["RotNet †","71 . 0±3 . 5","75 . 6±2 . 1","Contrastive f","Contrastive ( DA ) f"],"associatedMergedColumns":["Contrastive ( DA ) g f"]},{"number":"60","isBolded":false,"associatedRows":["MMD","8","Contrastive g f","AUC","Contrastive ( DA ) g f","AUC"],"associatedColumns":["Vanilla CLR †","80 . 2±1 . 8","85 . 6±1 . 3"],"associatedMergedColumns":["Contrastive ( DA ) g f"]},{"number":"50","isBolded":false,"associatedRows":["8","6"],"associatedColumns":["RotNet †","83 . 5±3 . 0","92 . 6±1 . 0"],"associatedMergedColumns":["Contrastive ( DA ) g f"]},{"number":"16","isBolded":false,"associatedRows":["8"],"associatedColumns":["RotNet †","Detection","Localization","Contrastive f","Contrastive ( DA ) f"],"associatedMergedColumns":["Contrastive ( DA ) g f"]},{"number":"60","isBolded":false,"associatedRows":["MMD","8","Contrastive g f","AUC"],"associatedColumns":["RotNet †","83 . 5±3 . 0","92 . 6±1 . 0"],"associatedMergedColumns":["Contrastive ( DA ) g f"]},{"number":"101","isBolded":false,"associatedRows":[],"associatedColumns":["RotNet †","Detection","Localization"],"associatedMergedColumns":[]},{"number":"80","isBolded":false,"associatedRows":["8","Contrastive g f"],"associatedColumns":["RotNet †","83 . 5±3 . 0","92 . 6±1 . 0"],"associatedMergedColumns":[]},{"number":"80","isBolded":false,"associatedRows":["8","Contrastive g f","Contrastive g f"],"associatedColumns":["Vanilla CLR †","80 . 2±1 . 8","85 . 6±1 . 3"],"associatedMergedColumns":[]},{"number":"51","isBolded":false,"associatedRows":["8","batch size","6","2","8","batch size","6"],"associatedColumns":["Vanilla CLR †","80 . 2±1 . 8","85 . 6±1 . 3","Contrastive f","Contrastive ( DA ) f"],"associatedMergedColumns":["Contrastive ( DA ) g f"]},{"number":"4.2","isBolded":true,"associatedRows":[],"associatedColumns":["RotNet †","Detection","Localization","Contrastive f","Contrastive ( DA ) f","0","Depth of MLP head","( a ) MMDs with various batch sizes .","Figure 4 : Ablation study of contrastive representations trained with different batch sizes ."],"associatedMergedColumns":["We further improve the performance with model ensemble , which we report in Appendix A . 2 . 2 ."]},{"number":"100","isBolded":false,"associatedRows":[],"associatedColumns":["RotNet †","Detection","Localization"],"associatedMergedColumns":["Contrastive ( DA ) g f"]},{"number":"90","isBolded":false,"associatedRows":["8","Contrastive g f"],"associatedColumns":["RotNet †","83 . 5±3 . 0","92 . 6±1 . 0"],"associatedMergedColumns":[]},{"number":"16","isBolded":false,"associatedRows":["8","6","2","8"],"associatedColumns":["RotNet †","83 . 5±3 . 0","92 . 6±1 . 0","Contrastive f","Contrastive ( DA ) f"],"associatedMergedColumns":["Contrastive ( DA ) g f"]},{"number":"128","isBolded":false,"associatedRows":["8","6","2","8"],"associatedColumns":["RotNet ( MLP head ) †","86 . 3±2 . 4","93 . 0±0 . 9","Contrastive f","Contrastive ( DA ) f"],"associatedMergedColumns":["Contrastive ( DA ) g f"]},{"number":"40","isBolded":false,"associatedRows":["8","6"],"associatedColumns":["RotNet †","83 . 5±3 . 0","92 . 6±1 . 0","Contrastive f"],"associatedMergedColumns":["Contrastive g f"]},{"number":"101","isBolded":false,"associatedRows":[],"associatedColumns":["RotNet †","Detection","Localization"],"associatedMergedColumns":["Contrastive ( DA ) g f"]},{"number":"40","isBolded":false,"associatedRows":["8","6","Contrastive ( DA ) g f"],"associatedColumns":["Vanilla CLR †","80 . 2±1 . 8","85 . 6±1 . 3","Contrastive f"],"associatedMergedColumns":["Contrastive g f"]}]},{"caption":"Table 5: One-class classification results using different one-class classifiers on rotation-augmented \ncontrastive representations. In addition to OC-SVM and KDE, both of which with RBF kernels, we \ntest with the linear OC-SVM and the Gaussian density estimator (GDE). \n\n","rows":["90 . 6±0 . 4","85 . 6±0 . 5","90 . 7±0 . 8","86 . 0±0 . 8","86 . 5±0 . 7","88 . 9±0 . 3","92 . 4±0 . 7","81 . 1±1 . 3","GDE","KDE","95 . 5±0 . 3","OC - SVM ( kernel )","89 . 6±0 . 5","89 . 6±0 . 4","93 . 7±0 . 8","88 . 4±1 . 4","94 . 5±0 . 4","86 . 3±0 . 7","92 . 0±0 . 5","84 . 5±1 . 1","OC - SVM ( linear )","94 . 8±0 . 3","92 . 5±0 . 6"],"columns":["Mean"],"mergedAllColumns":[],"numberCells":[{"number":"89.8","isBolded":false,"associatedRows":["GDE","92 . 0±0 . 5","86 . 0±0 . 8","95 . 5±0 . 3","88 . 9±0 . 3","90 . 6±0 . 4"],"associatedColumns":["Mean"],"associatedMergedColumns":[]},{"number":"89.9","isBolded":false,"associatedRows":["OC - SVM ( kernel )","92 . 5±0 . 6","86 . 5±0 . 7","94 . 8±0 . 3","89 . 6±0 . 5","84 . 5±1 . 1"],"associatedColumns":["Mean"],"associatedMergedColumns":[]},{"number":"89.8","isBolded":false,"associatedRows":["KDE","92 . 4±0 . 7","86 . 5±0 . 7","94 . 5±0 . 4","89 . 6±0 . 4","85 . 6±0 . 5"],"associatedColumns":["Mean"],"associatedMergedColumns":[]},{"number":"86.7","isBolded":true,"associatedRows":["OC - SVM ( linear )","90 . 7±0 . 8","81 . 1±1 . 3","93 . 7±0 . 8","86 . 3±0 . 7","88 . 4±1 . 4"],"associatedColumns":["Mean"],"associatedMergedColumns":[]}]},{"caption":"Table 6: Performance of single and ensemble models of distribution augmented contrastive represen-\ntations on CIFAR-10. For each augmented distribution, we report the mean and standard deviation \nof single model performance (\"single model\") and that of ensemble model whose ensemble score is \naggregated from 5 models trained with different random seeds (\"ensemble of 5 models\"). \"Ensemble \nof 5\" aggregates score from 5 models with different augmentation distributions. \n\n","rows":["ensemble of 5 models"],"columns":["+hflip , +rot90","Ensemble of 5","93 . 1±0 . 4","93 . 7±0 . 6","93 . 6±0 . 4","93 . 1±0 . 8","+rot90 , hflip","+rot270","+rot180","+rot180 , hflip","93 . 5±0 . 5","94 . 4±0 . 2"],"mergedAllColumns":[],"numberCells":[{"number":"93.9","isBolded":false,"associatedRows":["ensemble of 5 models"],"associatedColumns":["+hflip , +rot90","93 . 1±0 . 4"],"associatedMergedColumns":[]},{"number":"94.4","isBolded":false,"associatedRows":["ensemble of 5 models"],"associatedColumns":["+rot90 , hflip","93 . 7±0 . 6"],"associatedMergedColumns":[]},{"number":"94.6","isBolded":true,"associatedRows":["ensemble of 5 models"],"associatedColumns":["Ensemble of 5","94 . 4±0 . 2"],"associatedMergedColumns":[]},{"number":"93.9","isBolded":false,"associatedRows":["ensemble of 5 models"],"associatedColumns":["+rot270","93 . 1±0 . 8"],"associatedMergedColumns":[]},{"number":"94.3","isBolded":false,"associatedRows":["ensemble of 5 models"],"associatedColumns":["+rot180","93 . 6±0 . 4"],"associatedMergedColumns":[]},{"number":"94.2","isBolded":false,"associatedRows":["ensemble of 5 models"],"associatedColumns":["+rot180 , hflip","93 . 5±0 . 5"],"associatedMergedColumns":[]}]},{"caption":"Table 8: Per-class one-class classification AUCs on CIFAR-10. \n\n","rows":["parameter configurations , such as learning rate of","temperature τ of"],"columns":["deer","73 . 0±0 . 9","truck","77 . 7±0 . 6","ship","73 . 1±0 . 9","Representation","79 . 6±0 . 6","Classifier","89 . 8±0 . 5","automobile","horse","72 . 9±0 . 6","83 . 5±0 . 6","frog","mean","78 . 4±0 . 4","airplane","bird","cat","To this end , we train all models across all datasets using the same hyper -","64 . 1±0 . 7","dog"],"mergedAllColumns":["PER - CLASS AUCS"],"numberCells":[{"number":"8","isBolded":false,"associatedRows":[],"associatedColumns":["To this end , we train all models across all datasets using the same hyper -","Representation","Classifier","airplane","automobile","bird","cat","deer","dog","frog","horse","ship","truck","mean","Representation","Classifier","77 . 7±0 . 6","73 . 0±0 . 9","72 . 9±0 . 6","79 . 6±0 . 6","78 . 4±0 . 4","73 . 1±0 . 9","89 . 8±0 . 5","64 . 1±0 . 7"],"associatedMergedColumns":["PER - CLASS AUCS"]},{"number":"3","isBolded":false,"associatedRows":[],"associatedColumns":["To this end , we train all models across all datasets using the same hyper -","Representation","Classifier","airplane","automobile","bird","cat","deer","dog","frog","horse","ship","truck","mean","Representation","Classifier","77 . 7±0 . 6","73 . 0±0 . 9","72 . 9±0 . 6"],"associatedMergedColumns":["PER - CLASS AUCS"]},{"number":"2","isBolded":false,"associatedRows":[],"associatedColumns":["To this end , we train all models across all datasets using the same hyper -","Representation","Classifier","airplane","automobile","bird","cat","deer","dog","frog","horse","ship","truck","mean","Representation","Classifier","77 . 7±0 . 6","73 . 0±0 . 9"],"associatedMergedColumns":["PER - CLASS AUCS"]},{"number":"0","isBolded":false,"associatedRows":[],"associatedColumns":["To this end , we train all models across all datasets using the same hyper -","Representation","Classifier","airplane","automobile","bird","cat","deer","dog","frog","horse","ship","truck","mean","Representation","Classifier"],"associatedMergedColumns":["PER - CLASS AUCS"]},{"number":"6","isBolded":false,"associatedRows":[],"associatedColumns":["To this end , we train all models across all datasets using the same hyper -","Representation","Classifier","airplane","automobile","bird","cat","deer","dog","frog","horse","ship","truck","mean","Representation","Classifier","77 . 7±0 . 6","73 . 0±0 . 9","72 . 9±0 . 6","79 . 6±0 . 6","78 . 4±0 . 4","73 . 1±0 . 9"],"associatedMergedColumns":["PER - CLASS AUCS"]},{"number":"1","isBolded":false,"associatedRows":[],"associatedColumns":["To this end , we train all models across all datasets using the same hyper -","Representation","Classifier","airplane","automobile","bird","cat","deer","dog","frog","horse","ship","truck","mean","Representation","Classifier","77 . 7±0 . 6"],"associatedMergedColumns":["PER - CLASS AUCS"]},{"number":"9","isBolded":false,"associatedRows":[],"associatedColumns":["To this end , we train all models across all datasets using the same hyper -","Representation","Classifier","airplane","automobile","bird","cat","deer","dog","frog","horse","ship","truck","mean","Representation","Classifier","77 . 7±0 . 6","73 . 0±0 . 9","72 . 9±0 . 6","79 . 6±0 . 6","78 . 4±0 . 4","73 . 1±0 . 9","89 . 8±0 . 5","64 . 1±0 . 7","83 . 5±0 . 6"],"associatedMergedColumns":["PER - CLASS AUCS"]},{"number":"0.01,projectionheadofdepth","isBolded":true,"associatedRows":["parameter configurations , such as learning rate of"],"associatedColumns":["To this end , we train all models across all datasets using the same hyper -"],"associatedMergedColumns":[]},{"number":"0.2,orbatchsizeof32.","isBolded":true,"associatedRows":["temperature τ of"],"associatedColumns":["To this end , we train all models across all datasets using the same hyper -"],"associatedMergedColumns":[]},{"number":"4","isBolded":false,"associatedRows":[],"associatedColumns":["To this end , we train all models across all datasets using the same hyper -","Representation","Classifier","airplane","automobile","bird","cat","deer","dog","frog","horse","ship","truck","mean","Representation","Classifier","77 . 7±0 . 6","73 . 0±0 . 9","72 . 9±0 . 6","79 . 6±0 . 6"],"associatedMergedColumns":["PER - CLASS AUCS"]},{"number":"8([512×8,128]),","isBolded":true,"associatedRows":["parameter configurations , such as learning rate of"],"associatedColumns":["To this end , we train all models across all datasets using the same hyper -"],"associatedMergedColumns":[]},{"number":"7","isBolded":false,"associatedRows":[],"associatedColumns":["To this end , we train all models across all datasets using the same hyper -","Representation","Classifier","airplane","automobile","bird","cat","deer","dog","frog","horse","ship","truck","mean","Representation","Classifier","77 . 7±0 . 6","73 . 0±0 . 9","72 . 9±0 . 6","79 . 6±0 . 6","78 . 4±0 . 4","73 . 1±0 . 9","89 . 8±0 . 5"],"associatedMergedColumns":["PER - CLASS AUCS"]},{"number":"5","isBolded":false,"associatedRows":[],"associatedColumns":["To this end , we train all models across all datasets using the same hyper -","Representation","Classifier","airplane","automobile","bird","cat","deer","dog","frog","horse","ship","truck","mean","Representation","Classifier","77 . 7±0 . 6","73 . 0±0 . 9","72 . 9±0 . 6","79 . 6±0 . 6","78 . 4±0 . 4"],"associatedMergedColumns":["PER - CLASS AUCS"]},{"number":"A.5","isBolded":false,"associatedRows":[],"associatedColumns":["To this end , we train all models across all datasets using the same hyper -"],"associatedMergedColumns":[]}]},{"caption":"Table 9: Per-class one-class classification AUCs on CIFAR-20. \n\n","rows":[],"columns":["82 . 8±0 . 4","69 . 4±0 . 4","61 . 8±1 . 2","78 . 0±0 . 3","86 . 1±0 . 6","Representation","Classifier","0","1","2","3","4","90 . 8±0 . 3","5","6","7","8","9","83 . 7±0 . 5","89 . 7±0 . 3","92 . 5±0 . 4"],"mergedAllColumns":[],"numberCells":[{"number":"14","isBolded":false,"associatedRows":[],"associatedColumns":["Representation","Classifier","0","1","2","3","4","5","6","7","8","9","86 . 1±0 . 6","83 . 7±0 . 5","82 . 8±0 . 4","61 . 8±1 . 2"],"associatedMergedColumns":[]},{"number":"13","isBolded":false,"associatedRows":[],"associatedColumns":["Representation","Classifier","0","1","2","3","4","5","6","7","8","9","86 . 1±0 . 6","83 . 7±0 . 5","82 . 8±0 . 4"],"associatedMergedColumns":[]},{"number":"16","isBolded":false,"associatedRows":[],"associatedColumns":["Representation","Classifier","0","1","2","3","4","5","6","7","8","9","86 . 1±0 . 6","83 . 7±0 . 5","82 . 8±0 . 4","61 . 8±1 . 2","89 . 7±0 . 3","69 . 4±0 . 4"],"associatedMergedColumns":[]},{"number":"10","isBolded":false,"associatedRows":[],"associatedColumns":["Representation","Classifier","0","1","2","3","4","5","6","7","8","9"],"associatedMergedColumns":[]},{"number":"15","isBolded":false,"associatedRows":[],"associatedColumns":["Representation","Classifier","0","1","2","3","4","5","6","7","8","9","86 . 1±0 . 6","83 . 7±0 . 5","82 . 8±0 . 4","61 . 8±1 . 2","89 . 7±0 . 3"],"associatedMergedColumns":[]},{"number":"17","isBolded":false,"associatedRows":[],"associatedColumns":["Representation","Classifier","0","1","2","3","4","5","6","7","8","9","86 . 1±0 . 6","83 . 7±0 . 5","82 . 8±0 . 4","61 . 8±1 . 2","89 . 7±0 . 3","69 . 4±0 . 4","78 . 0±0 . 3"],"associatedMergedColumns":[]},{"number":"12","isBolded":false,"associatedRows":[],"associatedColumns":["Representation","Classifier","0","1","2","3","4","5","6","7","8","9","86 . 1±0 . 6","83 . 7±0 . 5"],"associatedMergedColumns":[]},{"number":"11","isBolded":false,"associatedRows":[],"associatedColumns":["Representation","Classifier","0","1","2","3","4","5","6","7","8","9","86 . 1±0 . 6"],"associatedMergedColumns":[]},{"number":"19","isBolded":false,"associatedRows":[],"associatedColumns":["Representation","Classifier","0","1","2","3","4","5","6","7","8","9","86 . 1±0 . 6","83 . 7±0 . 5","82 . 8±0 . 4","61 . 8±1 . 2","89 . 7±0 . 3","69 . 4±0 . 4","78 . 0±0 . 3","92 . 5±0 . 4","90 . 8±0 . 3"],"associatedMergedColumns":[]},{"number":"18","isBolded":false,"associatedRows":[],"associatedColumns":["Representation","Classifier","0","1","2","3","4","5","6","7","8","9","86 . 1±0 . 6","83 . 7±0 . 5","82 . 8±0 . 4","61 . 8±1 . 2","89 . 7±0 . 3","69 . 4±0 . 4","78 . 0±0 . 3","92 . 5±0 . 4"],"associatedMergedColumns":[]}]},{"caption":"Table 10: Per-class one-class classification AUCs on Fashion MNIST. \n","rows":[],"columns":["83 . 5±2 . 1","96 . 9±0 . 8","78 . 1±2 . 0","77 . 3±1 . 2","92 . 2±1 . 5","Representation","83 . 7±2 . 2","96 . 2±1 . 9","Classifier","83 . 7±2 . 1","87 . 6±1 . 5"],"mergedAllColumns":[],"numberCells":[{"number":"6","isBolded":false,"associatedRows":[],"associatedColumns":["Representation","Classifier","83 . 7±2 . 2","96 . 2±1 . 9","78 . 1±2 . 0","83 . 7±2 . 1","83 . 5±2 . 1","87 . 6±1 . 5"],"associatedMergedColumns":[]},{"number":"9","isBolded":false,"associatedRows":[],"associatedColumns":["Representation","Classifier","83 . 7±2 . 2","96 . 2±1 . 9","78 . 1±2 . 0","83 . 7±2 . 1","83 . 5±2 . 1","87 . 6±1 . 5","77 . 3±1 . 2","96 . 9±0 . 8","92 . 2±1 . 5"],"associatedMergedColumns":[]},{"number":"4","isBolded":false,"associatedRows":[],"associatedColumns":["Representation","Classifier","83 . 7±2 . 2","96 . 2±1 . 9","78 . 1±2 . 0","83 . 7±2 . 1"],"associatedMergedColumns":[]},{"number":"8","isBolded":false,"associatedRows":[],"associatedColumns":["Representation","Classifier","83 . 7±2 . 2","96 . 2±1 . 9","78 . 1±2 . 0","83 . 7±2 . 1","83 . 5±2 . 1","87 . 6±1 . 5","77 . 3±1 . 2","96 . 9±0 . 8"],"associatedMergedColumns":[]},{"number":"2","isBolded":false,"associatedRows":[],"associatedColumns":["Representation","Classifier","83 . 7±2 . 2","96 . 2±1 . 9"],"associatedMergedColumns":[]},{"number":"3","isBolded":false,"associatedRows":[],"associatedColumns":["Representation","Classifier","83 . 7±2 . 2","96 . 2±1 . 9","78 . 1±2 . 0"],"associatedMergedColumns":[]},{"number":"1","isBolded":false,"associatedRows":[],"associatedColumns":["Representation","Classifier","83 . 7±2 . 2"],"associatedMergedColumns":[]},{"number":"5","isBolded":false,"associatedRows":[],"associatedColumns":["Representation","Classifier","83 . 7±2 . 2","96 . 2±1 . 9","78 . 1±2 . 0","83 . 7±2 . 1","83 . 5±2 . 1"],"associatedMergedColumns":[]},{"number":"7","isBolded":false,"associatedRows":[],"associatedColumns":["Representation","Classifier","83 . 7±2 . 2","96 . 2±1 . 9","78 . 1±2 . 0","83 . 7±2 . 1","83 . 5±2 . 1","87 . 6±1 . 5","77 . 3±1 . 2"],"associatedMergedColumns":[]},{"number":"0","isBolded":false,"associatedRows":[],"associatedColumns":["Representation","Classifier"],"associatedMergedColumns":[]}]},{"caption":"Table 11: Per-class one-class classification AUCs on Cat-vs-Dog. \n\n","rows":[],"columns":[],"mergedAllColumns":[],"numberCells":[]},{"caption":"Table 12: Image-level detection and pixel-level localization AUC results on MVTec anomaly de-\ntection dataset. We run experiments 5 times with different random seeds and report the mean and \nstandard deviations. We bold-face the best entry of each row and those within the standard deviation. \n\n","rows":["embeddings f from image patches with the stride of","each patch location , which results in a ( 256 − 224","( e . g . , bottle , cable , transistor ) and","Detection on texture","Detection on all","Detection on object"],"columns":["77 . 9±2 . 3","B","EXPERIMENTS ON MVTEC ANOMALY DETECTION DATASET","set containing ∼115 images per category from both normal and defective data distributions .","[ 76 ]","u","Instead of learning the holistic image representation , we learn a patch representation of size","ited .","+ 1 ) \u003d 57×57 anomaly score map .","73 . 2±3 . 5","CAVGA - R","+ 1 ) × ( 256 − 224"],"mergedAllColumns":["For evaluation , we compute both image - level detection and localization AUCs . We densely extract","EXPERIMENTAL RESULTS","we upsample 57×57 into 256×256 with Gaussian kernel","There are 15 different categories in MVTec anomaly detection dataset [ 31 ] , where 10 are object","For image - level detection , we apply spatial max - pooling to obtain a single score . For localization ,","localization performance . Images are of high - resolution , whose side length is as long as 1024 ."],"numberCells":[{"number":"5aretexture(e.g.,grid,leather)categories.Eachcategorycomes","isBolded":false,"associatedRows":["( e . g . , bottle , cable , transistor ) and"],"associatedColumns":["EXPERIMENTS ON MVTEC ANOMALY DETECTION DATASET"],"associatedMergedColumns":["There are 15 different categories in MVTec anomaly detection dataset [ 31 ] , where 10 are object"]},{"number":"4","isBolded":true,"associatedRows":["each patch location , which results in a ( 256 − 224"],"associatedColumns":["EXPERIMENTS ON MVTEC ANOMALY DETECTION DATASET","set containing ∼115 images per category from both normal and defective data distributions .","Instead of learning the holistic image representation , we learn a patch representation of size"],"associatedMergedColumns":["For evaluation , we compute both image - level detection and localization AUCs . We densely extract"]},{"number":"B.2","isBolded":false,"associatedRows":[],"associatedColumns":["B","set containing ∼115 images per category from both normal and defective data distributions ."],"associatedMergedColumns":["localization performance . Images are of high - resolution , whose side length is as long as 1024 ."]},{"number":"4andcomputeanomalyscoreswithKDEat","isBolded":true,"associatedRows":["embeddings f from image patches with the stride of"],"associatedColumns":["EXPERIMENTS ON MVTEC ANOMALY DETECTION DATASET","set containing ∼115 images per category from both normal and defective data distributions .","Instead of learning the holistic image representation , we learn a patch representation of size"],"associatedMergedColumns":["For evaluation , we compute both image - level detection and localization AUCs . We densely extract"]},{"number":"7[67]andcomparewiththeannotation.","isBolded":false,"associatedRows":["embeddings f from image patches with the stride of"],"associatedColumns":["EXPERIMENTS ON MVTEC ANOMALY DETECTION DATASET","set containing ∼115 images per category from both normal and defective data distributions .","Instead of learning the holistic image representation , we learn a patch representation of size","+ 1 ) \u003d 57×57 anomaly score map ."],"associatedMergedColumns":["For image - level detection , we apply spatial max - pooling to obtain a single score . For localization ,"]},{"number":"83.8","isBolded":false,"associatedRows":["Detection on object"],"associatedColumns":["EXPERIMENTS ON MVTEC ANOMALY DETECTION DATASET","set containing ∼115 images per category from both normal and defective data distributions .","Instead of learning the holistic image representation , we learn a patch representation of size","+ 1 ) × ( 256 − 224","CAVGA - R","u","[ 76 ]"],"associatedMergedColumns":["EXPERIMENTAL RESULTS"]},{"number":"81.9","isBolded":false,"associatedRows":["Detection on all"],"associatedColumns":["EXPERIMENTS ON MVTEC ANOMALY DETECTION DATASET","set containing ∼115 images per category from both normal and defective data distributions .","Instead of learning the holistic image representation , we learn a patch representation of size","+ 1 ) × ( 256 − 224","CAVGA - R","u","[ 76 ]","77 . 9±2 . 3","73 . 2±3 . 5"],"associatedMergedColumns":["EXPERIMENTAL RESULTS"]},{"number":"B.3","isBolded":false,"associatedRows":[],"associatedColumns":["B","set containing ∼115 images per category from both normal and defective data distributions .","ited .","+ 1 ) × ( 256 − 224"],"associatedMergedColumns":["we upsample 57×57 into 256×256 with Gaussian kernel"]},{"number":"B.1","isBolded":false,"associatedRows":[],"associatedColumns":["B"],"associatedMergedColumns":[]},{"number":"4","isBolded":true,"associatedRows":["Detection on object"],"associatedColumns":["EXPERIMENTS ON MVTEC ANOMALY DETECTION DATASET","set containing ∼115 images per category from both normal and defective data distributions .","Instead of learning the holistic image representation , we learn a patch representation of size"],"associatedMergedColumns":["For evaluation , we compute both image - level detection and localization AUCs . We densely extract"]},{"number":"78.2","isBolded":false,"associatedRows":["Detection on texture"],"associatedColumns":["EXPERIMENTS ON MVTEC ANOMALY DETECTION DATASET","set containing ∼115 images per category from both normal and defective data distributions .","Instead of learning the holistic image representation , we learn a patch representation of size","+ 1 ) × ( 256 − 224","CAVGA - R","u","[ 76 ]","77 . 9±2 . 3"],"associatedMergedColumns":["EXPERIMENTAL RESULTS"]}]}]