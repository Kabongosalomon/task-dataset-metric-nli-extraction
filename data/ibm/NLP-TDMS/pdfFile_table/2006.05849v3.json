[{"caption":"Table 1: Comparison on various benchmarks. Mean accuracy (percentage) and standard deviation \nover three runs (ResNet-32). Best results in bold. Linear Evaluation: training on unlabeled data \nand linear evaluation on labeled data. Domain Transfer: training on unlabeled CIFAR-10 and \nlinear evaluation on labeled CIFAR-100 (10→100), and viceversa (100→10). Grain: training \non unlabeled CIFAR-100, linear evaluation on coarse-grained CIFAR-100-20 (20 super-classes). \nFinetune: training on the unlabeled set of STL-10, finetuning on the labeled set (ResNet-34). \n\n","rows":[],"columns":[],"mergedAllColumns":[],"numberCells":[]},{"caption":"Table 2: Linear evaluation. Self-supervised training on unlabeled data and linear evaluation on labeled \ndata. Comparison between three datasets (CIFAR-10, CIFAR-100, tiny-ImageNet) for a shallow \n(Conv-4) and a deep (ResNet-32) backbone. Mean accuracy (percentage) and standard deviation over \nthree runs. Best results highlighted in bold. \n\n","rows":[],"columns":[],"mergedAllColumns":[],"numberCells":[]},{"caption":"Table 4: Domain transfer. Training with self-supervision on unlabeled CIFAR-10 linear evaluation on \nCIFAR-100 (10 → 100), and viceversa (100 → 10). ∆ indicates the difference between the accuracy \nin the standard setting (unsupervised train and linear evaluation on the same dataset) and the accuracy \nin the transfer setting (unsupervised train on first dataset and linear evaluation on the second dataset). \nMean accuracy (percentage) and standard deviation over three runs. Best results highlighted in bold. \n\n","rows":["31 . 84±0 . 23","33 . 98±0 . 70","41 . 50±0 . 35","18 . 37±0 . 41","43 . 30±0 . 15","23 . 73±0 . 04","67 . 81±0 . 42","43 . 59±1 . 31","32 . 06±0 . 63","22 . 35±0 . 12","45 . 05±0 . 24","65 . 59±0 . 76","36 . 21±0 . 16","51 . 86±0 . 36","DeepCluster ( Caron et al . , 2018 )","71 . 01±0 . 44","SimCLR ( Chen et al . , 2020 )","29 . 20±0 . 08","Relational Reasoning ( ours )","Supervised ( upper bound )","27 . 02±0 . 20","RotationNet ( Gidaris et al . , 2018 )","52 . 22±0 . 70","Deep InfoMax ( Hjelm et al . , 2019 )","64 . 00±1 . 07","19 . 68±1 . 23","43 . 39±1 . 84","26 . 06±0 . 09","54 . 73±0 . 60","57 . 30±0 . 26"],"columns":["Conv - 4","n / a","∆","ResNet - 32"],"mergedAllColumns":[],"numberCells":[{"number":"-17.23","isBolded":false,"associatedRows":["Supervised ( upper bound )","32 . 06±0 . 63"],"associatedColumns":["Conv - 4","∆"],"associatedMergedColumns":[]},{"number":"-5.92","isBolded":false,"associatedRows":["SimCLR ( Chen et al . , 2020 )","29 . 20±0 . 08","54 . 73±0 . 60","36 . 21±0 . 16"],"associatedColumns":["ResNet - 32","∆","n / a"],"associatedMergedColumns":[]},{"number":"-1.54","isBolded":false,"associatedRows":["Relational Reasoning ( ours )","31 . 84±0 . 23"],"associatedColumns":["Conv - 4","∆","n / a"],"associatedMergedColumns":[]},{"number":"-16.46","isBolded":false,"associatedRows":["Supervised ( upper bound )","32 . 06±0 . 63","64 . 00±1 . 07"],"associatedColumns":["Conv - 4","∆"],"associatedMergedColumns":[]},{"number":"-4.87","isBolded":false,"associatedRows":["RotationNet ( Gidaris et al . , 2018 )","26 . 06±0 . 09","51 . 86±0 . 36"],"associatedColumns":["Conv - 4","∆","n / a"],"associatedMergedColumns":[]},{"number":"-2.07","isBolded":false,"associatedRows":["DeepCluster ( Caron et al . , 2018 )","19 . 68±1 . 23","43 . 59±1 . 31","18 . 37±0 . 41"],"associatedColumns":["ResNet - 32","∆","n / a"],"associatedMergedColumns":[]},{"number":"-1.30","isBolded":false,"associatedRows":["Deep InfoMax ( Hjelm et al . , 2019 )","22 . 35±0 . 12","43 . 30±0 . 15"],"associatedColumns":["Conv - 4","∆","n / a"],"associatedMergedColumns":[]},{"number":"-31.34","isBolded":false,"associatedRows":["Supervised ( upper bound )","32 . 06±0 . 63","64 . 00±1 . 07","33 . 98±0 . 70"],"associatedColumns":["ResNet - 32","∆"],"associatedMergedColumns":[]},{"number":"-2.08","isBolded":false,"associatedRows":["Deep InfoMax ( Hjelm et al . , 2019 )","22 . 35±0 . 12","43 . 30±0 . 15","23 . 73±0 . 04","45 . 05±0 . 24"],"associatedColumns":["ResNet - 32","∆","n / a"],"associatedMergedColumns":[]},{"number":"-4.67","isBolded":false,"associatedRows":["Relational Reasoning ( ours )","31 . 84±0 . 23","57 . 30±0 . 26","41 . 50±0 . 35"],"associatedColumns":["ResNet - 32","∆","n / a"],"associatedMergedColumns":[]},{"number":"-1.35","isBolded":false,"associatedRows":["DeepCluster ( Caron et al . , 2018 )","19 . 68±1 . 23"],"associatedColumns":["Conv - 4","∆","n / a"],"associatedMergedColumns":[]},{"number":"+0.71","isBolded":false,"associatedRows":["DeepCluster ( Caron et al . , 2018 )","19 . 68±1 . 23","43 . 59±1 . 31"],"associatedColumns":["Conv - 4","∆","n / a"],"associatedMergedColumns":[]},{"number":"-5.70","isBolded":false,"associatedRows":["SimCLR ( Chen et al . , 2020 )","29 . 20±0 . 08","54 . 73±0 . 60"],"associatedColumns":["Conv - 4","∆","n / a"],"associatedMergedColumns":[]},{"number":"-3.73","isBolded":false,"associatedRows":["Relational Reasoning ( ours )","31 . 84±0 . 23","57 . 30±0 . 26"],"associatedColumns":["Conv - 4","∆","n / a"],"associatedMergedColumns":[]},{"number":"-9.78","isBolded":false,"associatedRows":["RotationNet ( Gidaris et al . , 2018 )","26 . 06±0 . 09","51 . 86±0 . 36","27 . 02±0 . 20","52 . 22±0 . 70"],"associatedColumns":["ResNet - 32","∆","n / a"],"associatedMergedColumns":[]},{"number":"-2.00","isBolded":false,"associatedRows":["RotationNet ( Gidaris et al . , 2018 )","26 . 06±0 . 09","51 . 86±0 . 36","27 . 02±0 . 20"],"associatedColumns":["ResNet - 32","∆","n / a"],"associatedMergedColumns":[]},{"number":"-1.39","isBolded":false,"associatedRows":["RotationNet ( Gidaris et al . , 2018 )","26 . 06±0 . 09"],"associatedColumns":["Conv - 4","∆","n / a"],"associatedMergedColumns":[]},{"number":"-11.43","isBolded":false,"associatedRows":["SimCLR ( Chen et al . , 2020 )","29 . 20±0 . 08","54 . 73±0 . 60","36 . 21±0 . 16","65 . 59±0 . 76"],"associatedColumns":["ResNet - 32","∆","n / a"],"associatedMergedColumns":[]},{"number":"-19.86","isBolded":false,"associatedRows":["Supervised ( upper bound )","32 . 06±0 . 63","64 . 00±1 . 07","33 . 98±0 . 70","71 . 01±0 . 44"],"associatedColumns":["ResNet - 32","∆"],"associatedMergedColumns":[]},{"number":"-0.39","isBolded":false,"associatedRows":["Deep InfoMax ( Hjelm et al . , 2019 )","22 . 35±0 . 12"],"associatedColumns":["Conv - 4","∆","n / a"],"associatedMergedColumns":[]},{"number":"-0.34","isBolded":false,"associatedRows":["Deep InfoMax ( Hjelm et al . , 2019 )","22 . 35±0 . 12","43 . 30±0 . 15","23 . 73±0 . 04"],"associatedColumns":["ResNet - 32","∆","n / a"],"associatedMergedColumns":[]},{"number":"-1.25","isBolded":false,"associatedRows":["SimCLR ( Chen et al . , 2020 )","29 . 20±0 . 08"],"associatedColumns":["Conv - 4","∆","n / a"],"associatedMergedColumns":[]},{"number":"+0.08","isBolded":false,"associatedRows":["DeepCluster ( Caron et al . , 2018 )","19 . 68±1 . 23","43 . 59±1 . 31","18 . 37±0 . 41","43 . 39±1 . 84"],"associatedColumns":["ResNet - 32","∆","n / a"],"associatedMergedColumns":[]},{"number":"-7.18","isBolded":false,"associatedRows":["Relational Reasoning ( ours )","31 . 84±0 . 23","57 . 30±0 . 26","41 . 50±0 . 35","67 . 81±0 . 42"],"associatedColumns":["ResNet - 32","∆","n / a"],"associatedMergedColumns":[]}]},{"caption":"Table 5: Grain. Training with self-supervision on unlabeled CIFAR-100, and linear evaluation on \nlabeled CIFAR-100 Fine-Grained (100 classes) and CIFAR-100-20 Coarse-Grained (20 super-classes). \nMean accuracy (percentage) and standard deviation over three runs. Best results highlighted in bold. \n\n","rows":[],"columns":["Conv - 4","RotationNet ( Gidaris et al . , 2018 )","Random Weights ( lower bound )","DeepCluster ( Caron et al . , 2018 )","Deep InfoMax ( Hjelm et al . , 2019 )","SimCLR ( Chen et al . , 2020 )","Method","Relational Reasoning ( ours )","Supervised ( upper bound )"],"mergedAllColumns":[],"numberCells":[{"number":"B.4","isBolded":false,"associatedRows":[],"associatedColumns":["Conv - 4","Method","Supervised ( upper bound )","Random Weights ( lower bound )","DeepCluster ( Caron et al . , 2018 )","RotationNet ( Gidaris et al . , 2018 )","Deep InfoMax ( Hjelm et al . , 2019 )","SimCLR ( Chen et al . , 2020 )","Relational Reasoning ( ours )"],"associatedMergedColumns":[]}]},{"caption":"Table 6: Finetuning. Comparison with other results reported in the literature on unsupervised training \nand finetuning on the STL-10 dataset. Best result in bold. Local refers to our local reproduction of \nthe method, with results reported as best (mean ± std) on three runs with different seeds. Note that \nbackbone and learning schedule may differ. The ResNet-34 backbone is much larger than ResNet-32 \n(21.3 × 10 6 vs 0.47 × 10 6 ), showing that the proposed method can be effectively scaled. \n\n","rows":["Exemplars ( Dosovitskiy et al . , 2014 )","WideResnet - 16 - 8","ResNet - 34","Invariant Info Clustering ( Ji et al . , 2019 )","Artifacts ( Jenni and Favaro , 2018 )","Jenni and Favaro ( 2018 )","Hybrid - WideResnet","Supervised ( crop + cutout )","DeVries and Taylor ( 2017 )","ADC ( Haeusser et al . , 2018 )","Dosovitskiy et al . ( 2014 )","Supervised ( scattering )","DeepCluster ( Caron et al . , 2018 )","Local","SimCLR ( Chen et al . , 2020 )","Custom","Ji et al . ( 2019 )","Relational Reasoning ( ours )","Oyallon et al . ( 2017 )","Conv - 3","RotationNet ( Gidaris et al . , 2018 )","Deep InfoMax ( Hjelm et al . , 2019 )","6","AlexNet","Supervised ( affine + cutout )","vs"],"columns":["Accuracy","Method","Table 6 : Finetuning . Comparison with other results reported in the literature on unsupervised training"],"mergedAllColumns":["backbone and learning schedule may differ . The ResNet - 34 backbone is much larger than ResNet - 32",") , showing that the proposed method can be effectively scaled ."],"numberCells":[{"number":"87.30","isBolded":false,"associatedRows":["Supervised ( crop + cutout )","DeVries and Taylor ( 2017 )","WideResnet - 16 - 8"],"associatedColumns":["Table 6 : Finetuning . Comparison with other results reported in the literature on unsupervised training","Accuracy"],"associatedMergedColumns":[") , showing that the proposed method can be effectively scaled ."]},{"number":"80.10","isBolded":false,"associatedRows":["Artifacts ( Jenni and Favaro , 2018 )","Jenni and Favaro ( 2018 )","Custom"],"associatedColumns":["Table 6 : Finetuning . Comparison with other results reported in the literature on unsupervised training","Accuracy"],"associatedMergedColumns":[") , showing that the proposed method can be effectively scaled ."]},{"number":"83.77","isBolded":false,"associatedRows":["RotationNet ( Gidaris et al . , 2018 )","Local","ResNet - 34"],"associatedColumns":["Table 6 : Finetuning . Comparison with other results reported in the literature on unsupervised training","Accuracy"],"associatedMergedColumns":[") , showing that the proposed method can be effectively scaled ."]},{"number":"(73.37±","isBolded":false,"associatedRows":["DeepCluster ( Caron et al . , 2018 )","Local","ResNet - 34"],"associatedColumns":["Table 6 : Finetuning . Comparison with other results reported in the literature on unsupervised training","Accuracy"],"associatedMergedColumns":[") , showing that the proposed method can be effectively scaled ."]},{"number":"(69.82±","isBolded":false,"associatedRows":["Supervised ( affine + cutout )","Local","ResNet - 34"],"associatedColumns":["Table 6 : Finetuning . Comparison with other results reported in the literature on unsupervised training","Accuracy"],"associatedMergedColumns":[") , showing that the proposed method can be effectively scaled ."]},{"number":"B.5","isBolded":true,"associatedRows":[],"associatedColumns":["Table 6 : Finetuning . Comparison with other results reported in the literature on unsupervised training","Method"],"associatedMergedColumns":[") , showing that the proposed method can be effectively scaled ."]},{"number":"(21.3×10","isBolded":false,"associatedRows":[],"associatedColumns":["Table 6 : Finetuning . Comparison with other results reported in the literature on unsupervised training"],"associatedMergedColumns":["backbone and learning schedule may differ . The ResNet - 34 backbone is much larger than ResNet - 32"]},{"number":"90.04","isBolded":true,"associatedRows":["Relational Reasoning ( ours )","Local","ResNet - 34"],"associatedColumns":["Table 6 : Finetuning . Comparison with other results reported in the literature on unsupervised training","Accuracy"],"associatedMergedColumns":[") , showing that the proposed method can be effectively scaled ."]},{"number":"89.44","isBolded":false,"associatedRows":["SimCLR ( Chen et al . , 2020 )","Local","ResNet - 34"],"associatedColumns":["Table 6 : Finetuning . Comparison with other results reported in the literature on unsupervised training","Accuracy"],"associatedMergedColumns":[") , showing that the proposed method can be effectively scaled ."]},{"number":"0.37)","isBolded":false,"associatedRows":["Deep InfoMax ( Hjelm et al . , 2019 )","Local","ResNet - 34"],"associatedColumns":["Table 6 : Finetuning . Comparison with other results reported in the literature on unsupervised training","Accuracy"],"associatedMergedColumns":[") , showing that the proposed method can be effectively scaled ."]},{"number":"56.70","isBolded":false,"associatedRows":["ADC ( Haeusser et al . , 2018 )","Ji et al . ( 2019 )","ResNet - 34"],"associatedColumns":["Table 6 : Finetuning . Comparison with other results reported in the literature on unsupervised training","Accuracy"],"associatedMergedColumns":[") , showing that the proposed method can be effectively scaled ."]},{"number":"74.00","isBolded":false,"associatedRows":["DeepCluster ( Caron et al . , 2018 )","Local","ResNet - 34"],"associatedColumns":["Table 6 : Finetuning . Comparison with other results reported in the literature on unsupervised training","Accuracy"],"associatedMergedColumns":[") , showing that the proposed method can be effectively scaled ."]},{"number":"73.40","isBolded":false,"associatedRows":["DeepCluster ( Caron et al . , 2018 )","Ji et al . ( 2019 )","ResNet - 34"],"associatedColumns":["Table 6 : Finetuning . Comparison with other results reported in the literature on unsupervised training","Accuracy"],"associatedMergedColumns":[") , showing that the proposed method can be effectively scaled ."]},{"number":"72.04","isBolded":false,"associatedRows":["Supervised ( affine + cutout )","Local","ResNet - 34"],"associatedColumns":["Table 6 : Finetuning . Comparison with other results reported in the literature on unsupervised training","Accuracy"],"associatedMergedColumns":[") , showing that the proposed method can be effectively scaled ."]},{"number":"(76.03±","isBolded":false,"associatedRows":["Deep InfoMax ( Hjelm et al . , 2019 )","Local","ResNet - 34"],"associatedColumns":["Table 6 : Finetuning . Comparison with other results reported in the literature on unsupervised training","Accuracy"],"associatedMergedColumns":[") , showing that the proposed method can be effectively scaled ."]},{"number":"0.33)","isBolded":true,"associatedRows":["Relational Reasoning ( ours )","Local","ResNet - 34"],"associatedColumns":["Table 6 : Finetuning . Comparison with other results reported in the literature on unsupervised training","Accuracy"],"associatedMergedColumns":[") , showing that the proposed method can be effectively scaled ."]},{"number":"(89.31±","isBolded":false,"associatedRows":["SimCLR ( Chen et al . , 2020 )","Local","ResNet - 34"],"associatedColumns":["Table 6 : Finetuning . Comparison with other results reported in the literature on unsupervised training","Accuracy"],"associatedMergedColumns":[") , showing that the proposed method can be effectively scaled ."]},{"number":"88.80","isBolded":false,"associatedRows":["Invariant Info Clustering ( Ji et al . , 2019 )","Ji et al . ( 2019 )","ResNet - 34"],"associatedColumns":["Table 6 : Finetuning . Comparison with other results reported in the literature on unsupervised training","Accuracy"],"associatedMergedColumns":[") , showing that the proposed method can be effectively scaled ."]},{"number":"77.00","isBolded":false,"associatedRows":["Deep InfoMax ( Hjelm et al . , 2019 )","Ji et al . ( 2019 )","AlexNet"],"associatedColumns":["Table 6 : Finetuning . Comparison with other results reported in the literature on unsupervised training","Accuracy"],"associatedMergedColumns":[") , showing that the proposed method can be effectively scaled ."]},{"number":"0.14)","isBolded":false,"associatedRows":["SimCLR ( Chen et al . , 2020 )","Local","ResNet - 34"],"associatedColumns":["Table 6 : Finetuning . Comparison with other results reported in the literature on unsupervised training","Accuracy"],"associatedMergedColumns":[") , showing that the proposed method can be effectively scaled ."]},{"number":"0.55)","isBolded":false,"associatedRows":["DeepCluster ( Caron et al . , 2018 )","Local","ResNet - 34"],"associatedColumns":["Table 6 : Finetuning . Comparison with other results reported in the literature on unsupervised training","Accuracy"],"associatedMergedColumns":[") , showing that the proposed method can be effectively scaled ."]},{"number":"(83.29±","isBolded":false,"associatedRows":["RotationNet ( Gidaris et al . , 2018 )","Local","ResNet - 34"],"associatedColumns":["Table 6 : Finetuning . Comparison with other results reported in the literature on unsupervised training","Accuracy"],"associatedMergedColumns":[") , showing that the proposed method can be effectively scaled ."]},{"number":"(89.67±","isBolded":false,"associatedRows":["Relational Reasoning ( ours )","Local","ResNet - 34"],"associatedColumns":["Table 6 : Finetuning . Comparison with other results reported in the literature on unsupervised training","Accuracy"],"associatedMergedColumns":[") , showing that the proposed method can be effectively scaled ."]},{"number":"87.60","isBolded":false,"associatedRows":["Supervised ( scattering )","Oyallon et al . ( 2017 )","Hybrid - WideResnet"],"associatedColumns":["Table 6 : Finetuning . Comparison with other results reported in the literature on unsupervised training","Accuracy"],"associatedMergedColumns":[") , showing that the proposed method can be effectively scaled ."]},{"number":"0.47×10","isBolded":true,"associatedRows":["6","vs"],"associatedColumns":["Table 6 : Finetuning . Comparison with other results reported in the literature on unsupervised training"],"associatedMergedColumns":["backbone and learning schedule may differ . The ResNet - 34 backbone is much larger than ResNet - 32"]},{"number":"3.36)","isBolded":false,"associatedRows":["Supervised ( affine + cutout )","Local","ResNet - 34"],"associatedColumns":["Table 6 : Finetuning . Comparison with other results reported in the literature on unsupervised training","Accuracy"],"associatedMergedColumns":[") , showing that the proposed method can be effectively scaled ."]},{"number":"76.45","isBolded":false,"associatedRows":["Deep InfoMax ( Hjelm et al . , 2019 )","Local","ResNet - 34"],"associatedColumns":["Table 6 : Finetuning . Comparison with other results reported in the literature on unsupervised training","Accuracy"],"associatedMergedColumns":[") , showing that the proposed method can be effectively scaled ."]},{"number":"0.44)","isBolded":false,"associatedRows":["RotationNet ( Gidaris et al . , 2018 )","Local","ResNet - 34"],"associatedColumns":["Table 6 : Finetuning . Comparison with other results reported in the literature on unsupervised training","Accuracy"],"associatedMergedColumns":[") , showing that the proposed method can be effectively scaled ."]},{"number":"72.80","isBolded":false,"associatedRows":["Exemplars ( Dosovitskiy et al . , 2014 )","Dosovitskiy et al . ( 2014 )","Conv - 3"],"associatedColumns":["Table 6 : Finetuning . Comparison with other results reported in the literature on unsupervised training","Accuracy"],"associatedMergedColumns":[") , showing that the proposed method can be effectively scaled ."]}]},{"caption":"Table 7: Comparison on different backbones: linear evaluation. Comparison between four backbones \nof different depth for baselines and the three best performing methods. Training with self-supervision \non unlabeled CIFAR-10 and CIFAR-100, and linear evaluation on labeled version of the same datasets. \nMean accuracy (percentage) and standard deviation over three runs. Best results highlighted in bold. \n\n","rows":["Exemplars ( Dosovitskiy et al . , 2014 )","Dosovitskiy et al . ( 2014 )","Supervised ( scattering )","WideResnet - 16 - 8","ResNet - 34","DeepCluster ( Caron et al . , 2018 )","Invariant Info Clustering ( Ji et al . , 2019 )","Artifacts ( Jenni and Favaro , 2018 )","Local","SimCLR ( Chen et al . , 2020 )","Custom","Ji et al . ( 2019 )","Jenni and Favaro ( 2018 )","Relational Reasoning ( ours )","Oyallon et al . ( 2017 )","Conv - 3","RotationNet ( Gidaris et al . , 2018 )","Hybrid - WideResnet","Deep InfoMax ( Hjelm et al . , 2019 )","Supervised ( crop + cutout )","AlexNet","DeVries and Taylor ( 2017 )","ADC ( Haeusser et al . , 2018 )","Supervised ( affine + cutout )"],"columns":["Accuracy","Method"],"mergedAllColumns":[],"numberCells":[{"number":"(89.31±","isBolded":false,"associatedRows":["SimCLR ( Chen et al . , 2020 )","Local","ResNet - 34"],"associatedColumns":["Accuracy"],"associatedMergedColumns":[]},{"number":"87.60","isBolded":false,"associatedRows":["Supervised ( scattering )","Oyallon et al . ( 2017 )","Hybrid - WideResnet"],"associatedColumns":["Accuracy"],"associatedMergedColumns":[]},{"number":"(89.67±","isBolded":false,"associatedRows":["Relational Reasoning ( ours )","Local","ResNet - 34"],"associatedColumns":["Accuracy"],"associatedMergedColumns":[]},{"number":"0.14)","isBolded":false,"associatedRows":["SimCLR ( Chen et al . , 2020 )","Local","ResNet - 34"],"associatedColumns":["Accuracy"],"associatedMergedColumns":[]},{"number":"72.04","isBolded":false,"associatedRows":["Supervised ( affine + cutout )","Local","ResNet - 34"],"associatedColumns":["Accuracy"],"associatedMergedColumns":[]},{"number":"0.55)","isBolded":false,"associatedRows":["DeepCluster ( Caron et al . , 2018 )","Local","ResNet - 34"],"associatedColumns":["Accuracy"],"associatedMergedColumns":[]},{"number":"83.77","isBolded":false,"associatedRows":["RotationNet ( Gidaris et al . , 2018 )","Local","ResNet - 34"],"associatedColumns":["Accuracy"],"associatedMergedColumns":[]},{"number":"3.36)","isBolded":false,"associatedRows":["Supervised ( affine + cutout )","Local","ResNet - 34"],"associatedColumns":["Accuracy"],"associatedMergedColumns":[]},{"number":"(76.03±","isBolded":false,"associatedRows":["Deep InfoMax ( Hjelm et al . , 2019 )","Local","ResNet - 34"],"associatedColumns":["Accuracy"],"associatedMergedColumns":[]},{"number":"0.44)","isBolded":false,"associatedRows":["RotationNet ( Gidaris et al . , 2018 )","Local","ResNet - 34"],"associatedColumns":["Accuracy"],"associatedMergedColumns":[]},{"number":"0.33)","isBolded":true,"associatedRows":["Relational Reasoning ( ours )","Local","ResNet - 34"],"associatedColumns":["Accuracy"],"associatedMergedColumns":[]},{"number":"B.5","isBolded":true,"associatedRows":[],"associatedColumns":["Method"],"associatedMergedColumns":[]},{"number":"(69.82±","isBolded":false,"associatedRows":["Supervised ( affine + cutout )","Local","ResNet - 34"],"associatedColumns":["Accuracy"],"associatedMergedColumns":[]},{"number":"76.45","isBolded":false,"associatedRows":["Deep InfoMax ( Hjelm et al . , 2019 )","Local","ResNet - 34"],"associatedColumns":["Accuracy"],"associatedMergedColumns":[]},{"number":"73.40","isBolded":false,"associatedRows":["DeepCluster ( Caron et al . , 2018 )","Ji et al . ( 2019 )","ResNet - 34"],"associatedColumns":["Accuracy"],"associatedMergedColumns":[]},{"number":"89.44","isBolded":false,"associatedRows":["SimCLR ( Chen et al . , 2020 )","Local","ResNet - 34"],"associatedColumns":["Accuracy"],"associatedMergedColumns":[]},{"number":"72.80","isBolded":false,"associatedRows":["Exemplars ( Dosovitskiy et al . , 2014 )","Dosovitskiy et al . ( 2014 )","Conv - 3"],"associatedColumns":["Accuracy"],"associatedMergedColumns":[]},{"number":"90.04","isBolded":true,"associatedRows":["Relational Reasoning ( ours )","Local","ResNet - 34"],"associatedColumns":["Accuracy"],"associatedMergedColumns":[]},{"number":"56.70","isBolded":false,"associatedRows":["ADC ( Haeusser et al . , 2018 )","Ji et al . ( 2019 )","ResNet - 34"],"associatedColumns":["Accuracy"],"associatedMergedColumns":[]},{"number":"0.37)","isBolded":false,"associatedRows":["Deep InfoMax ( Hjelm et al . , 2019 )","Local","ResNet - 34"],"associatedColumns":["Accuracy"],"associatedMergedColumns":[]},{"number":"88.80","isBolded":false,"associatedRows":["Invariant Info Clustering ( Ji et al . , 2019 )","Ji et al . ( 2019 )","ResNet - 34"],"associatedColumns":["Accuracy"],"associatedMergedColumns":[]},{"number":"74.00","isBolded":false,"associatedRows":["DeepCluster ( Caron et al . , 2018 )","Local","ResNet - 34"],"associatedColumns":["Accuracy"],"associatedMergedColumns":[]},{"number":"77.00","isBolded":false,"associatedRows":["Deep InfoMax ( Hjelm et al . , 2019 )","Ji et al . ( 2019 )","AlexNet"],"associatedColumns":["Accuracy"],"associatedMergedColumns":[]},{"number":"(73.37±","isBolded":false,"associatedRows":["DeepCluster ( Caron et al . , 2018 )","Local","ResNet - 34"],"associatedColumns":["Accuracy"],"associatedMergedColumns":[]},{"number":"87.30","isBolded":false,"associatedRows":["Supervised ( crop + cutout )","DeVries and Taylor ( 2017 )","WideResnet - 16 - 8"],"associatedColumns":["Accuracy"],"associatedMergedColumns":[]},{"number":"(83.29±","isBolded":false,"associatedRows":["RotationNet ( Gidaris et al . , 2018 )","Local","ResNet - 34"],"associatedColumns":["Accuracy"],"associatedMergedColumns":[]},{"number":"80.10","isBolded":false,"associatedRows":["Artifacts ( Jenni and Favaro , 2018 )","Jenni and Favaro ( 2018 )","Custom"],"associatedColumns":["Accuracy"],"associatedMergedColumns":[]}]},{"caption":"Table 8: Comparison on different backbones: grain. Comparison between four backbones of different \ndepth for baselines and the three best performing methods. Training with self-supervision on \nunlabeled CIFAR-100 and linear evaluation on labeled version of the same datasets with 100 labels \n(fine) or 20 super-labels (coarse). Mean accuracy (percentage) and standard deviation over three runs. \nBest results highlighted in bold. \n\n","rows":["( fine ) or"],"columns":[],"mergedAllColumns":[],"numberCells":[{"number":"20super-labels(coarse).Meanaccuracy(percentage)andstandarddeviationoverthreeruns.","isBolded":false,"associatedRows":["( fine ) or"],"associatedColumns":[],"associatedMergedColumns":[]}]},{"caption":"Table 9: Comparison on different backbones: domain transfer. Comparison between four backbones \nof different depth for baselines and the three best performing methods. Training with self-supervision \non unlabeled CIFAR-10 linear evaluation on CIFAR-100 (10 → 100), and viceversa (100 → 10). \nMean accuracy (percentage) and standard deviation over three runs. Best results highlighted in bold. \n\n","rows":[],"columns":["Conv - 4","RotationNet ( Gidaris et al . , 2018 )","Random Weights ( lower bound )","SimCLR ( Chen et al . , 2020 )","Method","Relational Reasoning ( ours )","Supervised ( upper bound )"],"mergedAllColumns":[],"numberCells":[{"number":"B.6","isBolded":false,"associatedRows":[],"associatedColumns":["Conv - 4","Method","Supervised ( upper bound )","Random Weights ( lower bound )","RotationNet ( Gidaris et al . , 2018 )","SimCLR ( Chen et al . , 2020 )","Relational Reasoning ( ours )"],"associatedMergedColumns":[]}]},{"caption":"Table 10: Accuracy with respect to the number of augmentations K . Methods have been trained on \nCIFAR-10 with a Conv-4 backbone for 100 epochs. The input mini-batch has been augmented K \ntimes then given as input. Results are the average accuracy (linear evaluation) of three runs on the \nvalidation set. Only the relational reasoning accuracy is positively correlated with K. \n\n","rows":["K \u003d","Method"],"columns":["35 . 94±1 . 39","ResNet - 32","7 . 65±0 . 44","K \u003d 16","33 . 98±0 . 70","41 . 50±0 . 35","31 . 60±0 . 54","61 . 34±0 . 24","34 . 46±0 . 78","36 . 21±0 . 16","Random Weights ( lower bound )","56 . 85±0 . 13","SimCLR ( Chen et al . , 2020 )","Method","Relational Reasoning ( ours )","Supervised","36 . 07±0 . 35","Supervised ( upper bound )","Conv - 4","27 . 02±0 . 20","63 . 24±0 . 52","RotationNet ( Gidaris et al . , 2018 )","100→10","10→100","ResNet - 8","13 . 08±0 . 91","36 . 83±0 . 36","71 . 20±0 . 18"],"mergedAllColumns":["Number of augmentations"],"numberCells":[{"number":"4","isBolded":false,"associatedRows":["Method","K \u003d","K \u003d"],"associatedColumns":["ResNet - 8","100→10","71 . 20±0 . 18","35 . 94±1 . 39","56 . 85±0 . 13","61 . 34±0 . 24","63 . 24±0 . 52"],"associatedMergedColumns":["Number of augmentations"]},{"number":"2","isBolded":false,"associatedRows":["Method","K \u003d"],"associatedColumns":["ResNet - 8","10→100","36 . 83±0 . 36","13 . 08±0 . 91","31 . 60±0 . 54","34 . 46±0 . 78","36 . 07±0 . 35"],"associatedMergedColumns":["Number of augmentations"]},{"number":"B.7","isBolded":true,"associatedRows":[],"associatedColumns":["Conv - 4","Method","Supervised ( upper bound )","Random Weights ( lower bound )","RotationNet ( Gidaris et al . , 2018 )","SimCLR ( Chen et al . , 2020 )","Relational Reasoning ( ours )","K \u003d 16","Supervised","RotationNet ( Gidaris et al . , 2018 )","Relational Reasoning ( ours )"],"associatedMergedColumns":["Number of augmentations"]},{"number":"8","isBolded":false,"associatedRows":["Method","K \u003d","K \u003d","K \u003d"],"associatedColumns":["ResNet - 32","10→100","33 . 98±0 . 70","7 . 65±0 . 44","27 . 02±0 . 20","36 . 21±0 . 16","41 . 50±0 . 35"],"associatedMergedColumns":["Number of augmentations"]},{"number":"B.6","isBolded":true,"associatedRows":[],"associatedColumns":["Conv - 4","Method","Supervised ( upper bound )","Random Weights ( lower bound )","RotationNet ( Gidaris et al . , 2018 )","SimCLR ( Chen et al . , 2020 )","Relational Reasoning ( ours )"],"associatedMergedColumns":[]}]},{"caption":"Table 11: Test accuracy on CIFAR-10 with respect to the percentage of labeled data available. \nMethods have been trained with a ResNet-32 backbone (200 epochs), followed by linear evaluation \non the entire labeled dataset (100 epochs). The quality of the representations improves with the \nnumber of labeled data available. \n\n","rows":["1%","0%","Method"],"columns":["51 . 51±1 . 02","59 . 24±0 . 51","K \u003d 16","Method","Supervised","Relational Reasoning ( ours )","K \u003d 4","79 . 56±0 . 49","K \u003d 8","RotationNet ( Gidaris et al . , 2018 )","58 . 05±0 . 67","79 . 76±0 . 54","52 . 62±0 . 68","79 . 96±0 . 71","52 . 85±1 . 24","60 . 26±0 . 59"],"mergedAllColumns":["Semi - supervised and supervised"],"numberCells":[{"number":"25%","isBolded":false,"associatedRows":["Method","0%","1%"],"associatedColumns":["K \u003d 8","79 . 96±0 . 71","52 . 62±0 . 68","59 . 24±0 . 51"],"associatedMergedColumns":["Semi - supervised and supervised"]},{"number":"10%","isBolded":false,"associatedRows":["Method","0%","1%"],"associatedColumns":["K \u003d 4","79 . 76±0 . 54","51 . 51±1 . 02","58 . 05±0 . 67"],"associatedMergedColumns":["Semi - supervised and supervised"]},{"number":"B.7","isBolded":true,"associatedRows":[],"associatedColumns":["Method","Supervised","RotationNet ( Gidaris et al . , 2018 )","Relational Reasoning ( ours )"],"associatedMergedColumns":[]},{"number":"50%","isBolded":false,"associatedRows":["Method","0%","1%"],"associatedColumns":["K \u003d 16","79 . 56±0 . 49","52 . 85±1 . 24","60 . 26±0 . 59"],"associatedMergedColumns":["Semi - supervised and supervised"]}]},{"caption":"Table 12: Test accuracy on CIFAR-100 with respect to the percentage of labeled data available. \nMethods have been trained with a ResNet-32 backbone (200 epochs), followed by linear evaluation \non the entire labeled dataset (100 epochs). The quality of the representations improves with the \nnumber of labeled data available. \n\n","rows":["1%","0%","Method"],"columns":["on the entire labeled dataset ( 100 epochs ) . The quality of the representations improves with the"],"mergedAllColumns":[],"numberCells":[{"number":"10%","isBolded":false,"associatedRows":["Method","0%","1%"],"associatedColumns":["on the entire labeled dataset ( 100 epochs ) . The quality of the representations improves with the"],"associatedMergedColumns":[]},{"number":"50%","isBolded":false,"associatedRows":["Method","0%","1%"],"associatedColumns":["on the entire labeled dataset ( 100 epochs ) . The quality of the representations improves with the"],"associatedMergedColumns":[]},{"number":"25%","isBolded":false,"associatedRows":["Method","0%","1%"],"associatedColumns":["on the entire labeled dataset ( 100 epochs ) . The quality of the representations improves with the"],"associatedMergedColumns":[]}]},{"caption":"Table 13: Ablation of the aggregation function. Training with relational self-supervision on unlabeled \nCIFAR-10 and CIFAR-100, and linear evaluation on labeled datasets ","rows":["Mean","a","i , z","mean ( z"],"columns":["60±0 . 23"],"mergedAllColumns":[],"numberCells":[{"number":"2","isBolded":false,"associatedRows":["Mean","a","mean ( z","i , z"],"associatedColumns":["60±0 . 23"],"associatedMergedColumns":[]}]},{"caption":"Table 14: Ablation of the relation head. The models have been trained on unlabeled CIFAR-10 and \nCIFAR-100 and tested on various benchmarks with a ResNet32 backbone for 200 epochs (mean \naccuracy and standard deviation of 3 runs). We consider three head types: (a) dot product between the \npairs encoded through the backbone, followed by BCE loss; (b) Encoder + dot product, aggregation \nis not performed, for each encoded representation an MLP performs a second encoding, then dot \nproduct is applied between pairs and the BCE loss minimized (similar to SimCLR, Chen et al. \n2020); (c) Relation module corresponds to the proposed method where encodings are aggregated \n(concatenation) and passed through an MLP for binary classification. All the other factors are kept \nconstant for a fair comparison (e.g. augmentation strategy, mini-batch size). Best results in bold. \n\n","rows":[],"columns":[],"mergedAllColumns":[],"numberCells":[]}]