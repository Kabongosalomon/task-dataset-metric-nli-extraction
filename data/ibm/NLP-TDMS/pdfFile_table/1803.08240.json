[{"caption":"Penn Treebank (Character) \nenwik8 \nWikiText-103 \nTrain Valid \nTest \nTrain Valid Test \nTrain \nValid Test \n\nTokens \n5.01M 393k \n442k \n90M \n5M \n5M 103.2M 217k 245k \n\nVocab size \n51 \n205 \n267,735 \nOoV rate \n-\n-\n0.4% \n\nTable 1. Statistics of the character-level Penn Treebank, character-level enwik8 dataset, and WikiText-103. The out of vocabulary (OoV) \nrate notes what percentage of tokens have been replaced by an unk token, not applicable to character-level datasets. \n\n","rows":["442k","OoV rate","393k","90M","5M","-","Tokens"],"columns":["267 , 735","217k","Valid","WikiText - 103","Penn Treebank ( Character )","Train"],"mergedAllColumns":[],"numberCells":[{"number":"0.4%","isBolded":false,"associatedRows":["OoV rate","-","-"],"associatedColumns":["WikiText - 103","Valid","217k","267 , 735"],"associatedMergedColumns":[]},{"number":"103.2M","isBolded":false,"associatedRows":["Tokens","393k","442k","90M","5M","5M"],"associatedColumns":["WikiText - 103","Train"],"associatedMergedColumns":[]},{"number":"5.01M","isBolded":false,"associatedRows":["Tokens"],"associatedColumns":["Penn Treebank ( Character )","Train"],"associatedMergedColumns":[]}]},{"caption":"Table 2. Bits Per Character (BPC) on character-level Penn Tree-\nbank. \n\n","rows":["FS - LSTM - 2 ( Mujika et al . , 2017 )","FS - LSTM - 4 ( Mujika et al . , 2017 )","6 layer QRNN ( h \u003d 1024 ) ( ours )","Zoneout LSTM ( Krueger et al . , 2016 )","2 - Layers LSTM ( Mujika et al . , 2017 )","HyperLSTM ( Ha et al . , 2016 )","NASCell ( Zoph \u0026 Le , 2016 )","HM - LSTM ( Chung et al . , 2016 )","HyperLSTM - small ( Ha et al . , 2016 )","NASCell ( small ) ( Zoph \u0026 Le , 2016 )","3 layer LSTM ( h \u003d 1000 ) ( ours )"],"columns":["BPC","Params"],"mergedAllColumns":["-"],"numberCells":[{"number":"1.27","isBolded":false,"associatedRows":["Zoneout LSTM ( Krueger et al . , 2016 )"],"associatedColumns":["BPC"],"associatedMergedColumns":[]},{"number":"6.5M","isBolded":false,"associatedRows":["FS - LSTM - 4 ( Mujika et al . , 2017 )"],"associatedColumns":["Params"],"associatedMergedColumns":["-"]},{"number":"1.243","isBolded":false,"associatedRows":["2 - Layers LSTM ( Mujika et al . , 2017 )"],"associatedColumns":["BPC"],"associatedMergedColumns":["-"]},{"number":"1.214","isBolded":false,"associatedRows":["NASCell ( Zoph \u0026 Le , 2016 )"],"associatedColumns":["BPC"],"associatedMergedColumns":["-"]},{"number":"1.187","isBolded":false,"associatedRows":["6 layer QRNN ( h \u003d 1024 ) ( ours )"],"associatedColumns":["BPC"],"associatedMergedColumns":["-"]},{"number":"6.6M","isBolded":false,"associatedRows":["NASCell ( small ) ( Zoph \u0026 Le , 2016 )"],"associatedColumns":["Params"],"associatedMergedColumns":["-"]},{"number":"6.6M","isBolded":false,"associatedRows":["2 - Layers LSTM ( Mujika et al . , 2017 )"],"associatedColumns":["Params"],"associatedMergedColumns":["-"]},{"number":"1.193","isBolded":false,"associatedRows":["FS - LSTM - 4 ( Mujika et al . , 2017 )"],"associatedColumns":["BPC"],"associatedMergedColumns":["-"]},{"number":"13.8M","isBolded":false,"associatedRows":["3 layer LSTM ( h \u003d 1000 ) ( ours )"],"associatedColumns":["Params"],"associatedMergedColumns":["-"]},{"number":"5.1M","isBolded":false,"associatedRows":["HyperLSTM - small ( Ha et al . , 2016 )"],"associatedColumns":["Params"],"associatedMergedColumns":["-"]},{"number":"1.24","isBolded":false,"associatedRows":["HM - LSTM ( Chung et al . , 2016 )"],"associatedColumns":["BPC"],"associatedMergedColumns":["-"]},{"number":"1.233","isBolded":false,"associatedRows":["HyperLSTM - small ( Ha et al . , 2016 )"],"associatedColumns":["BPC"],"associatedMergedColumns":["-"]},{"number":"7.2M","isBolded":false,"associatedRows":["FS - LSTM - 2 ( Mujika et al . , 2017 )"],"associatedColumns":["Params"],"associatedMergedColumns":["-"]},{"number":"1.175","isBolded":false,"associatedRows":["3 layer LSTM ( h \u003d 1000 ) ( ours )"],"associatedColumns":["BPC"],"associatedMergedColumns":["-"]},{"number":"1.190","isBolded":false,"associatedRows":["FS - LSTM - 2 ( Mujika et al . , 2017 )"],"associatedColumns":["BPC"],"associatedMergedColumns":["-"]},{"number":"1.219","isBolded":false,"associatedRows":["HyperLSTM ( Ha et al . , 2016 )"],"associatedColumns":["BPC"],"associatedMergedColumns":["-"]},{"number":"1.228","isBolded":false,"associatedRows":["NASCell ( small ) ( Zoph \u0026 Le , 2016 )"],"associatedColumns":["BPC"],"associatedMergedColumns":["-"]},{"number":"14.4M","isBolded":false,"associatedRows":["HyperLSTM ( Ha et al . , 2016 )"],"associatedColumns":["Params"],"associatedMergedColumns":["-"]},{"number":"16.3M","isBolded":false,"associatedRows":["NASCell ( Zoph \u0026 Le , 2016 )"],"associatedColumns":["Params"],"associatedMergedColumns":["-"]},{"number":"13.8M","isBolded":false,"associatedRows":["6 layer QRNN ( h \u003d 1024 ) ( ours )"],"associatedColumns":["Params"],"associatedMergedColumns":["-"]}]},{"caption":"Table 3. Bits Per Character (BPC) on enwik8. \n\n","rows":["RHN - depth 5 ( Zilly et al . , 2016 )","HM - LSTM ( Chung et al . , 2016 )","Layer Norm LSTM , 1800 units","LSTM , 2000 units ( Mujika et al . , 2017 )","3 layer LSTM ( h \u003d 1840 ) ( ours )","SD Zoneout ( Rocki et al . , 2016 )","cmix v13 ( Knoll , 2018 )","Large RHN ( Zilly et al . , 2016 )","FS - LSTM - 2 ( Mujika et al . , 2017 )","FS - LSTM - 4 ( Mujika et al . , 2017 )","RHN - depth 10 ( Zilly et al . , 2016 )","HyperLSTM ( Ha et al . , 2016 )","Large FS - LSTM - 4 ( Mujika et al . , 2017 )","4 layer QRNN ( h \u003d 1800 ) ( ours )"],"columns":["BPC"],"mergedAllColumns":["18M","27M","26M","14M","47M","35M","46M","23M","21M","64M"],"numberCells":[{"number":"1.27","isBolded":false,"associatedRows":["Large RHN ( Zilly et al . , 2016 )"],"associatedColumns":["BPC"],"associatedMergedColumns":["21M"]},{"number":"1.245","isBolded":false,"associatedRows":["Large FS - LSTM - 4 ( Mujika et al . , 2017 )"],"associatedColumns":["BPC"],"associatedMergedColumns":["27M"]},{"number":"1.402","isBolded":false,"associatedRows":["Layer Norm LSTM , 1800 units"],"associatedColumns":["BPC"],"associatedMergedColumns":["18M"]},{"number":"1.336","isBolded":false,"associatedRows":["4 layer QRNN ( h \u003d 1800 ) ( ours )"],"associatedColumns":["BPC"],"associatedMergedColumns":["47M"]},{"number":"1.225","isBolded":false,"associatedRows":["cmix v13 ( Knoll , 2018 )"],"associatedColumns":["BPC"],"associatedMergedColumns":["47M"]},{"number":"1.340","isBolded":false,"associatedRows":["HyperLSTM ( Ha et al . , 2016 )"],"associatedColumns":["BPC"],"associatedMergedColumns":["14M"]},{"number":"1.232","isBolded":false,"associatedRows":["3 layer LSTM ( h \u003d 1840 ) ( ours )"],"associatedColumns":["BPC"],"associatedMergedColumns":["26M"]},{"number":"1.32","isBolded":false,"associatedRows":["HM - LSTM ( Chung et al . , 2016 )"],"associatedColumns":["BPC"],"associatedMergedColumns":["27M"]},{"number":"1.31","isBolded":false,"associatedRows":["RHN - depth 5 ( Zilly et al . , 2016 )"],"associatedColumns":["BPC"],"associatedMergedColumns":["64M"]},{"number":"1.31","isBolded":false,"associatedRows":["SD Zoneout ( Rocki et al . , 2016 )"],"associatedColumns":["BPC"],"associatedMergedColumns":["35M"]},{"number":"1.461","isBolded":false,"associatedRows":["LSTM , 2000 units ( Mujika et al . , 2017 )"],"associatedColumns":["BPC"],"associatedMergedColumns":[]},{"number":"1.30","isBolded":false,"associatedRows":["RHN - depth 10 ( Zilly et al . , 2016 )"],"associatedColumns":["BPC"],"associatedMergedColumns":["23M"]},{"number":"1.290","isBolded":false,"associatedRows":["FS - LSTM - 2 ( Mujika et al . , 2017 )"],"associatedColumns":["BPC"],"associatedMergedColumns":["46M"]},{"number":"1.277","isBolded":false,"associatedRows":["FS - LSTM - 4 ( Mujika et al . , 2017 )"],"associatedColumns":["BPC"],"associatedMergedColumns":["27M"]}]},{"caption":"Table 6. Hyper-parameters for word-and character-level language modeling experiments. Training time is for all noted epochs on an \nNVIDIA Volta. Dropout refers to embedding, (RNN) hidden, input, and output. \n\n","rows":["Total parameters","Learning rate","Epochs","Batch size","Input embedding size","Weight drop","BPTT length"],"columns":["LSTM","An Analysis of Neural Language Modeling at Multiple Scales","QRNN","1000","0","Character PTB","3","1840","4","2500","1 . 2e − 6","enwik8","0 / 0 . 01 / 0 . 01 / 0 . 4","WikiText - 103","50","0 / 0","[ 300 , 400 ]","0 / 0 . 1 / 0 . 1 / 0 . 1","0 / 0 . 25 / 0 . 1 / 0 . 1"],"mergedAllColumns":["0","60","10"],"numberCells":[{"number":"128","isBolded":false,"associatedRows":["Input embedding size"],"associatedColumns":["An Analysis of Neural Language Modeling at Multiple Scales","Character PTB","LSTM","3","1000","0 / 0","0 / 0 . 25 / 0 . 1 / 0 . 1","1 . 2e − 6"],"associatedMergedColumns":["60"]},{"number":"200","isBolded":false,"associatedRows":["BPTT length"],"associatedColumns":["An Analysis of Neural Language Modeling at Multiple Scales","enwik8","LSTM","3","1840","0 / 0","0 / 0 . 01 / 0 . 01 / 0 . 4","1 . 2e − 6"],"associatedMergedColumns":["0"]},{"number":"0.2","isBolded":false,"associatedRows":["Weight drop"],"associatedColumns":["An Analysis of Neural Language Modeling at Multiple Scales","enwik8","LSTM","3","1840","0 / 0","0 / 0 . 01 / 0 . 01 / 0 . 4"],"associatedMergedColumns":[]},{"number":"0.001","isBolded":false,"associatedRows":["Learning rate"],"associatedColumns":["An Analysis of Neural Language Modeling at Multiple Scales","enwik8","LSTM","3","1840","0 / 0","0 / 0 . 01 / 0 . 01 / 0 . 4","1 . 2e − 6"],"associatedMergedColumns":["60"]},{"number":"140","isBolded":false,"associatedRows":["BPTT length"],"associatedColumns":["An Analysis of Neural Language Modeling at Multiple Scales","WikiText - 103","QRNN","4","2500","0 / 0","0 / 0 . 1 / 0 . 1 / 0 . 1","0"],"associatedMergedColumns":["0"]},{"number":"150","isBolded":false,"associatedRows":["BPTT length"],"associatedColumns":["An Analysis of Neural Language Modeling at Multiple Scales","Character PTB","LSTM","3","1000","0 / 0","0 / 0 . 25 / 0 . 1 / 0 . 1","1 . 2e − 6"],"associatedMergedColumns":["0"]},{"number":"0.5","isBolded":false,"associatedRows":["Weight drop"],"associatedColumns":["An Analysis of Neural Language Modeling at Multiple Scales","Character PTB","LSTM","3","1000","0 / 0","0 / 0 . 25 / 0 . 1 / 0 . 1"],"associatedMergedColumns":[]},{"number":"0.002","isBolded":false,"associatedRows":["Learning rate"],"associatedColumns":["An Analysis of Neural Language Modeling at Multiple Scales","Character PTB","LSTM","3","1000","0 / 0","0 / 0 . 25 / 0 . 1 / 0 . 1","1 . 2e − 6"],"associatedMergedColumns":["60"]},{"number":"500","isBolded":false,"associatedRows":["Epochs"],"associatedColumns":["An Analysis of Neural Language Modeling at Multiple Scales","Character PTB","LSTM","3","1000","0 / 0","0 / 0 . 25 / 0 . 1 / 0 . 1","1 . 2e − 6"],"associatedMergedColumns":["60"]},{"number":"128","isBolded":false,"associatedRows":["Batch size"],"associatedColumns":["An Analysis of Neural Language Modeling at Multiple Scales","enwik8","LSTM","3","1840","0 / 0","0 / 0 . 01 / 0 . 01 / 0 . 4","1 . 2e − 6"],"associatedMergedColumns":["0"]},{"number":"400","isBolded":false,"associatedRows":["Input embedding size"],"associatedColumns":["An Analysis of Neural Language Modeling at Multiple Scales","WikiText - 103","QRNN","4","2500","0 / 0","0 / 0 . 1 / 0 . 1 / 0 . 1","0"],"associatedMergedColumns":["60"]},{"number":"128","isBolded":false,"associatedRows":["Batch size"],"associatedColumns":["An Analysis of Neural Language Modeling at Multiple Scales","Character PTB","LSTM","3","1000","0 / 0","0 / 0 . 25 / 0 . 1 / 0 . 1","1 . 2e − 6"],"associatedMergedColumns":["0"]},{"number":"400","isBolded":false,"associatedRows":["Input embedding size"],"associatedColumns":["An Analysis of Neural Language Modeling at Multiple Scales","enwik8","LSTM","3","1840","0 / 0","0 / 0 . 01 / 0 . 01 / 0 . 4","1 . 2e − 6"],"associatedMergedColumns":["60"]},{"number":"13.8M","isBolded":false,"associatedRows":["Total parameters"],"associatedColumns":["An Analysis of Neural Language Modeling at Multiple Scales","Character PTB","LSTM","3","1000","0 / 0","0 / 0 . 25 / 0 . 1 / 0 . 1","1 . 2e − 6","50","[ 300 , 400 ]"],"associatedMergedColumns":["10"]},{"number":"0.001","isBolded":false,"associatedRows":["Learning rate"],"associatedColumns":["An Analysis of Neural Language Modeling at Multiple Scales","WikiText - 103","QRNN","4","2500","0 / 0","0 / 0 . 1 / 0 . 1 / 0 . 1","0"],"associatedMergedColumns":["60"]}]}]