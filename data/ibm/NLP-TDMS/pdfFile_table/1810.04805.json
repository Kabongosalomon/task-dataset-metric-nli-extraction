[{"caption":"System \n\nMNLI-(m/mm) QQP QNLI SST-2 CoLA STS-B MRPC RTE Average \n392k \n363k 108k 67k 8.5k 5.7k \n3.5k 2.5k \n-\nPre-OpenAI SOTA \n80.6/80.1 \n66.1 82.3 93.2 35.0 81.0 \n86.0 61.7 74.0 \nBiLSTM+ELMo+Attn \n76.4/76.1 \n64.8 79.9 90.4 36.0 73.3 \n84.9 56.8 71.0 \nOpenAI GPT \n82.1/81.4 \n70.3 88.1 91.3 45.4 80.0 \n82.3 56.0 75.2 \nBERT BASE \n84.6/83.4 \n71.2 90.1 93.5 52.1 85.8 \n88.9 66.4 79.6 \nBERT LARGE \n86.7/85.9 \n72.1 91.1 94.9 60.5 86.5 \n89.3 70.1 81.9 \n\nTable 1: GLUE Test results, scored by the GLUE evaluation server. The number below each task denotes the \nnumber of training examples. The \"Average\" column is slightly different than the official GLUE score, since \nwe exclude the problematic WNLI set. OpenAI GPT \u003d (L\u003d12, H\u003d768, A\u003d12); BERT BASE \u003d (L\u003d12, H\u003d768, \nA\u003d12); BERT LARGE \u003d (L\u003d24, H\u003d1024, A\u003d16). BERT and OpenAI GPT are single-model, single task. All \nresults obtained from https://gluebenchmark.com/leaderboard and https://blog.openai. \ncom/language-unsupervised/. \n\n","rows":["OpenAI GPT","BERT BASE","BiLSTM+ELMo+Attn","363k","108k","392k","76 . 4 / 76 . 1","84 . 6 / 83 . 4","80 . 6 / 80 . 1","67k","82 . 1 / 81 . 4","Pre - OpenAI SOTA","BERT LARGE","86 . 7 / 85 . 9"],"columns":["CoLA","QQP","RTE","SST - 2","Average","STS - B","MRPC","QNLI"],"mergedAllColumns":["-"],"numberCells":[{"number":"88.9","isBolded":false,"associatedRows":["BERT BASE","84 . 6 / 83 . 4"],"associatedColumns":["MRPC"],"associatedMergedColumns":["-"]},{"number":"3.5k","isBolded":false,"associatedRows":["BiLSTM+ELMo+Attn","392k","363k","108k","67k"],"associatedColumns":["MRPC"],"associatedMergedColumns":[]},{"number":"81.0","isBolded":false,"associatedRows":["Pre - OpenAI SOTA","80 . 6 / 80 . 1"],"associatedColumns":["STS - B"],"associatedMergedColumns":["-"]},{"number":"89.3","isBolded":true,"associatedRows":["BERT LARGE","86 . 7 / 85 . 9"],"associatedColumns":["MRPC"],"associatedMergedColumns":["-"]},{"number":"75.2","isBolded":false,"associatedRows":["OpenAI GPT","82 . 1 / 81 . 4"],"associatedColumns":["Average"],"associatedMergedColumns":["-"]},{"number":"80.0","isBolded":false,"associatedRows":["OpenAI GPT","82 . 1 / 81 . 4"],"associatedColumns":["STS - B"],"associatedMergedColumns":["-"]},{"number":"2.5k","isBolded":false,"associatedRows":["BiLSTM+ELMo+Attn","392k","363k","108k","67k"],"associatedColumns":["RTE"],"associatedMergedColumns":[]},{"number":"93.2","isBolded":false,"associatedRows":["Pre - OpenAI SOTA","80 . 6 / 80 . 1"],"associatedColumns":["SST - 2"],"associatedMergedColumns":["-"]},{"number":"72.1","isBolded":true,"associatedRows":["BERT LARGE","86 . 7 / 85 . 9"],"associatedColumns":["QQP"],"associatedMergedColumns":["-"]},{"number":"84.9","isBolded":false,"associatedRows":["BiLSTM+ELMo+Attn","76 . 4 / 76 . 1"],"associatedColumns":["MRPC"],"associatedMergedColumns":["-"]},{"number":"61.7","isBolded":false,"associatedRows":["Pre - OpenAI SOTA","80 . 6 / 80 . 1"],"associatedColumns":["RTE"],"associatedMergedColumns":["-"]},{"number":"79.6","isBolded":false,"associatedRows":["BERT BASE","84 . 6 / 83 . 4"],"associatedColumns":["Average"],"associatedMergedColumns":["-"]},{"number":"94.9","isBolded":true,"associatedRows":["BERT LARGE","86 . 7 / 85 . 9"],"associatedColumns":["SST - 2"],"associatedMergedColumns":["-"]},{"number":"82.3","isBolded":false,"associatedRows":["Pre - OpenAI SOTA","80 . 6 / 80 . 1"],"associatedColumns":["QNLI"],"associatedMergedColumns":["-"]},{"number":"90.4","isBolded":false,"associatedRows":["BiLSTM+ELMo+Attn","76 . 4 / 76 . 1"],"associatedColumns":["SST - 2"],"associatedMergedColumns":["-"]},{"number":"66.1","isBolded":false,"associatedRows":["Pre - OpenAI SOTA","80 . 6 / 80 . 1"],"associatedColumns":["QQP"],"associatedMergedColumns":["-"]},{"number":"5.7k","isBolded":false,"associatedRows":["BiLSTM+ELMo+Attn","392k","363k","108k","67k"],"associatedColumns":["STS - B"],"associatedMergedColumns":[]},{"number":"45.4","isBolded":false,"associatedRows":["OpenAI GPT","82 . 1 / 81 . 4"],"associatedColumns":["CoLA"],"associatedMergedColumns":["-"]},{"number":"90.1","isBolded":false,"associatedRows":["BERT BASE","84 . 6 / 83 . 4"],"associatedColumns":["QNLI"],"associatedMergedColumns":["-"]},{"number":"91.1","isBolded":true,"associatedRows":["BERT LARGE","86 . 7 / 85 . 9"],"associatedColumns":["QNLI"],"associatedMergedColumns":["-"]},{"number":"35.0","isBolded":false,"associatedRows":["Pre - OpenAI SOTA","80 . 6 / 80 . 1"],"associatedColumns":["CoLA"],"associatedMergedColumns":["-"]},{"number":"86.5","isBolded":true,"associatedRows":["BERT LARGE","86 . 7 / 85 . 9"],"associatedColumns":["STS - B"],"associatedMergedColumns":["-"]},{"number":"56.8","isBolded":false,"associatedRows":["BiLSTM+ELMo+Attn","76 . 4 / 76 . 1"],"associatedColumns":["RTE"],"associatedMergedColumns":["-"]},{"number":"93.5","isBolded":false,"associatedRows":["BERT BASE","84 . 6 / 83 . 4"],"associatedColumns":["SST - 2"],"associatedMergedColumns":["-"]},{"number":"85.8","isBolded":false,"associatedRows":["BERT BASE","84 . 6 / 83 . 4"],"associatedColumns":["STS - B"],"associatedMergedColumns":["-"]},{"number":"86.0","isBolded":false,"associatedRows":["Pre - OpenAI SOTA","80 . 6 / 80 . 1"],"associatedColumns":["MRPC"],"associatedMergedColumns":["-"]},{"number":"82.3","isBolded":false,"associatedRows":["OpenAI GPT","82 . 1 / 81 . 4"],"associatedColumns":["MRPC"],"associatedMergedColumns":["-"]},{"number":"52.1","isBolded":false,"associatedRows":["BERT BASE","84 . 6 / 83 . 4"],"associatedColumns":["CoLA"],"associatedMergedColumns":["-"]},{"number":"81.9","isBolded":true,"associatedRows":["BERT LARGE","86 . 7 / 85 . 9"],"associatedColumns":["Average"],"associatedMergedColumns":["-"]},{"number":"70.1","isBolded":true,"associatedRows":["BERT LARGE","86 . 7 / 85 . 9"],"associatedColumns":["RTE"],"associatedMergedColumns":["-"]},{"number":"91.3","isBolded":false,"associatedRows":["OpenAI GPT","82 . 1 / 81 . 4"],"associatedColumns":["SST - 2"],"associatedMergedColumns":["-"]},{"number":"60.5","isBolded":true,"associatedRows":["BERT LARGE","86 . 7 / 85 . 9"],"associatedColumns":["CoLA"],"associatedMergedColumns":["-"]},{"number":"8.5k","isBolded":false,"associatedRows":["BiLSTM+ELMo+Attn","392k","363k","108k","67k"],"associatedColumns":["CoLA"],"associatedMergedColumns":[]},{"number":"88.1","isBolded":false,"associatedRows":["OpenAI GPT","82 . 1 / 81 . 4"],"associatedColumns":["QNLI"],"associatedMergedColumns":["-"]},{"number":"74.0","isBolded":false,"associatedRows":["Pre - OpenAI SOTA","80 . 6 / 80 . 1"],"associatedColumns":["Average"],"associatedMergedColumns":["-"]},{"number":"73.3","isBolded":false,"associatedRows":["BiLSTM+ELMo+Attn","76 . 4 / 76 . 1"],"associatedColumns":["STS - B"],"associatedMergedColumns":["-"]},{"number":"79.9","isBolded":false,"associatedRows":["BiLSTM+ELMo+Attn","76 . 4 / 76 . 1"],"associatedColumns":["QNLI"],"associatedMergedColumns":["-"]},{"number":"56.0","isBolded":false,"associatedRows":["OpenAI GPT","82 . 1 / 81 . 4"],"associatedColumns":["RTE"],"associatedMergedColumns":["-"]},{"number":"71.0","isBolded":false,"associatedRows":["BiLSTM+ELMo+Attn","76 . 4 / 76 . 1"],"associatedColumns":["Average"],"associatedMergedColumns":["-"]},{"number":"70.3","isBolded":false,"associatedRows":["OpenAI GPT","82 . 1 / 81 . 4"],"associatedColumns":["QQP"],"associatedMergedColumns":["-"]},{"number":"71.2","isBolded":false,"associatedRows":["BERT BASE","84 . 6 / 83 . 4"],"associatedColumns":["QQP"],"associatedMergedColumns":["-"]},{"number":"36.0","isBolded":false,"associatedRows":["BiLSTM+ELMo+Attn","76 . 4 / 76 . 1"],"associatedColumns":["CoLA"],"associatedMergedColumns":["-"]},{"number":"66.4","isBolded":false,"associatedRows":["BERT BASE","84 . 6 / 83 . 4"],"associatedColumns":["RTE"],"associatedMergedColumns":["-"]},{"number":"64.8","isBolded":false,"associatedRows":["BiLSTM+ELMo+Attn","76 . 4 / 76 . 1"],"associatedColumns":["QQP"],"associatedMergedColumns":["-"]}]},{"caption":"Table 2: SQuAD results. The BERT ensemble is 7x \nsystems which use different pre-training checkpoints \nand fine-tuning seeds. \n\n","rows":["Human","#1 Single - nlnet","BERTLARGE ( Ens . +TriviaQA )","BERTLARGE ( Sgl . +TriviaQA )","#1 Ensemble - nlnet","R . M . Reader ( Single )","BERTLARGE ( Ensemble )","R . M . Reader ( Ensemble )","BiDAF+ELMo ( Single )","-","BERTBASE ( Single )","BERTLARGE ( Single )","#2 Single - QANet","#2 Ensemble - QANet"],"columns":["Dev","Test","EM","F1","-"],"mergedAllColumns":["Ours","Published","Leaderboard ( Oct 8th , 2018 )"],"numberCells":[{"number":"88.5","isBolded":false,"associatedRows":["BERTBASE ( Single )","-"],"associatedColumns":["Dev","F1","-"],"associatedMergedColumns":["Ours"]},{"number":"78.9","isBolded":false,"associatedRows":["R . M . Reader ( Single )"],"associatedColumns":["Dev","EM","-"],"associatedMergedColumns":["Published"]},{"number":"84.2","isBolded":true,"associatedRows":["BERTLARGE ( Sgl . +TriviaQA )"],"associatedColumns":["Dev","EM","-","-","-","-"],"associatedMergedColumns":["Ours"]},{"number":"79.5","isBolded":false,"associatedRows":["R . M . Reader ( Single )","-"],"associatedColumns":["Test","EM","-"],"associatedMergedColumns":["Published"]},{"number":"91.8","isBolded":false,"associatedRows":["BERTLARGE ( Ensemble )","-"],"associatedColumns":["Dev","F1","-","-","-"],"associatedMergedColumns":["Ours"]},{"number":"84.1","isBolded":false,"associatedRows":["BERTLARGE ( Single )"],"associatedColumns":["Dev","EM","-","-"],"associatedMergedColumns":["Ours"]},{"number":"89.3","isBolded":false,"associatedRows":["#2 Single - QANet","-"],"associatedColumns":["Test","F1"],"associatedMergedColumns":["Leaderboard ( Oct 8th , 2018 )"]},{"number":"-86.0","isBolded":false,"associatedRows":["#1 Ensemble - nlnet","-"],"associatedColumns":["Test","EM"],"associatedMergedColumns":["Leaderboard ( Oct 8th , 2018 )"]},{"number":"-82.5","isBolded":false,"associatedRows":["#2 Single - QANet","-"],"associatedColumns":["Test","EM"],"associatedMergedColumns":["Leaderboard ( Oct 8th , 2018 )"]},{"number":"90.5","isBolded":false,"associatedRows":["#2 Ensemble - QANet","-"],"associatedColumns":["Test","F1"],"associatedMergedColumns":["Leaderboard ( Oct 8th , 2018 )"]},{"number":"86.6","isBolded":false,"associatedRows":["R . M . Reader ( Single )","-"],"associatedColumns":["Test","F1","-"],"associatedMergedColumns":["Published"]},{"number":"81.2","isBolded":false,"associatedRows":["R . M . Reader ( Ensemble )"],"associatedColumns":["Dev","EM","-"],"associatedMergedColumns":["Published"]},{"number":"92.2","isBolded":true,"associatedRows":["BERTLARGE ( Ens . +TriviaQA )","-"],"associatedColumns":["Dev","F1","-","-","-","-"],"associatedMergedColumns":["Ours"]},{"number":"91.8","isBolded":true,"associatedRows":["BERTLARGE ( Sgl . +TriviaQA )","-"],"associatedColumns":["Test","F1","-","-","-","-"],"associatedMergedColumns":["Ours"]},{"number":"93.2","isBolded":true,"associatedRows":["BERTLARGE ( Ens . +TriviaQA )","-"],"associatedColumns":["Test","F1","-","-","-","-"],"associatedMergedColumns":["Ours"]},{"number":"-83.5","isBolded":false,"associatedRows":["#1 Single - nlnet","-"],"associatedColumns":["Test","EM"],"associatedMergedColumns":["Leaderboard ( Oct 8th , 2018 )"]},{"number":"91.1","isBolded":true,"associatedRows":["BERTLARGE ( Sgl . +TriviaQA )","-"],"associatedColumns":["Dev","F1","-","-","-","-"],"associatedMergedColumns":["Ours"]},{"number":"-84.5","isBolded":false,"associatedRows":["#2 Ensemble - QANet","-"],"associatedColumns":["Test","EM"],"associatedMergedColumns":["Leaderboard ( Oct 8th , 2018 )"]},{"number":"91.7","isBolded":false,"associatedRows":["#1 Ensemble - nlnet","-"],"associatedColumns":["Test","F1"],"associatedMergedColumns":["Leaderboard ( Oct 8th , 2018 )"]},{"number":"-82.3","isBolded":false,"associatedRows":["Human","-"],"associatedColumns":["Test","EM"],"associatedMergedColumns":["Leaderboard ( Oct 8th , 2018 )"]},{"number":"87.9","isBolded":false,"associatedRows":["R . M . Reader ( Ensemble )","-"],"associatedColumns":["Dev","F1","-"],"associatedMergedColumns":["Published"]},{"number":"85.1","isBolded":true,"associatedRows":["BERTLARGE ( Sgl . +TriviaQA )","-"],"associatedColumns":["Test","EM","-","-","-","-"],"associatedMergedColumns":["Ours"]},{"number":"86.3","isBolded":false,"associatedRows":["R . M . Reader ( Single )","-"],"associatedColumns":["Dev","F1","-"],"associatedMergedColumns":["Published"]},{"number":"88.5","isBolded":false,"associatedRows":["R . M . Reader ( Ensemble )","-"],"associatedColumns":["Test","F1","-"],"associatedMergedColumns":["Published"]},{"number":"-85.8","isBolded":false,"associatedRows":["BiDAF+ELMo ( Single )"],"associatedColumns":["Dev","F1"],"associatedMergedColumns":["Published"]},{"number":"85.8","isBolded":false,"associatedRows":["BERTLARGE ( Ensemble )"],"associatedColumns":["Dev","EM","-","-","-"],"associatedMergedColumns":["Ours"]},{"number":"90.1","isBolded":false,"associatedRows":["#1 Single - nlnet","-"],"associatedColumns":["Test","F1"],"associatedMergedColumns":["Leaderboard ( Oct 8th , 2018 )"]},{"number":"87.4","isBolded":true,"associatedRows":["BERTLARGE ( Ens . +TriviaQA )","-"],"associatedColumns":["Test","EM","-","-","-","-"],"associatedMergedColumns":["Ours"]},{"number":"82.3","isBolded":false,"associatedRows":["R . M . Reader ( Ensemble )","-"],"associatedColumns":["Test","EM","-"],"associatedMergedColumns":["Published"]},{"number":"91.2","isBolded":false,"associatedRows":["Human","-"],"associatedColumns":["Test","F1"],"associatedMergedColumns":["Leaderboard ( Oct 8th , 2018 )"]},{"number":"86.2","isBolded":true,"associatedRows":["BERTLARGE ( Ens . +TriviaQA )"],"associatedColumns":["Dev","EM","-","-","-","-"],"associatedMergedColumns":["Ours"]},{"number":"80.8","isBolded":false,"associatedRows":["BERTBASE ( Single )"],"associatedColumns":["Dev","EM","-"],"associatedMergedColumns":["Ours"]},{"number":"90.9","isBolded":false,"associatedRows":["BERTLARGE ( Single )","-"],"associatedColumns":["Dev","F1","-","-"],"associatedMergedColumns":["Ours"]}]},{"caption":"Table 3: CoNLL-2003 Named Entity Recognition re-\nsults. The hyperparameters were selected using the \nDev set, and the reported Dev and Test scores are aver-\naged over 5 random restarts using those hyperparame-\nters. \n\n","rows":["BERT BASE","BERT LARGE","ELMo+BiLSTM+CRF","CVT+Multi ( Clark et al . , 2018 )","-"],"columns":["Test F1","Dev F1"],"mergedAllColumns":[],"numberCells":[{"number":"92.2","isBolded":false,"associatedRows":["ELMo+BiLSTM+CRF"],"associatedColumns":["Test F1"],"associatedMergedColumns":[]},{"number":"96.4","isBolded":false,"associatedRows":["BERT BASE"],"associatedColumns":["Dev F1"],"associatedMergedColumns":[]},{"number":"92.4","isBolded":false,"associatedRows":["BERT BASE"],"associatedColumns":["Test F1"],"associatedMergedColumns":[]},{"number":"95.7","isBolded":false,"associatedRows":["ELMo+BiLSTM+CRF"],"associatedColumns":["Dev F1"],"associatedMergedColumns":[]},{"number":"92.6","isBolded":false,"associatedRows":["CVT+Multi ( Clark et al . , 2018 )","-"],"associatedColumns":["Test F1"],"associatedMergedColumns":[]},{"number":"96.6","isBolded":true,"associatedRows":["BERT LARGE"],"associatedColumns":["Dev F1"],"associatedMergedColumns":[]},{"number":"92.8","isBolded":true,"associatedRows":["BERT LARGE"],"associatedColumns":["Test F1"],"associatedMergedColumns":[]}]},{"caption":"Table 4: SWAG Dev and Test accuracies. Test results \nwere scored against the hidden labels by the SWAG au-\nthors.  † Human performance is measure with 100 sam-\nples, as reported in the SWAG paper. \n\n","rows":["BERT BASE","Human ( expert ) †","BERT LARGE","Human ( 5 annotations ) †","ESIM+GloVe","ESIM+ELMo"],"columns":["Dev","Test"],"mergedAllColumns":["-"],"numberCells":[{"number":"52.7","isBolded":false,"associatedRows":["ESIM+GloVe"],"associatedColumns":["Test"],"associatedMergedColumns":[]},{"number":"59.1","isBolded":false,"associatedRows":["ESIM+ELMo"],"associatedColumns":["Dev"],"associatedMergedColumns":[]},{"number":"59.2","isBolded":false,"associatedRows":["ESIM+ELMo"],"associatedColumns":["Test"],"associatedMergedColumns":[]},{"number":"81.6","isBolded":false,"associatedRows":["BERT BASE"],"associatedColumns":["Dev"],"associatedMergedColumns":[]},{"number":"51.9","isBolded":false,"associatedRows":["ESIM+GloVe"],"associatedColumns":["Dev"],"associatedMergedColumns":[]},{"number":"86.6","isBolded":true,"associatedRows":["BERT LARGE"],"associatedColumns":["Dev"],"associatedMergedColumns":["-"]},{"number":"86.3","isBolded":true,"associatedRows":["BERT LARGE"],"associatedColumns":["Test"],"associatedMergedColumns":["-"]},{"number":"-88.0","isBolded":false,"associatedRows":["Human ( 5 annotations ) †"],"associatedColumns":["Test"],"associatedMergedColumns":["-"]},{"number":"-85.0","isBolded":false,"associatedRows":["Human ( expert ) †"],"associatedColumns":["Test"],"associatedMergedColumns":["-"]}]},{"caption":"Table 5: Ablation over the pre-training tasks using the \nBERT BASE architecture. \"No NSP\" is trained without \nthe next sentence prediction task. \"LTR \u0026 No NSP\" is \ntrained as a left-to-right LM without the next sentence \nprediction, like OpenAI GPT. \"+ BiLSTM\" adds a ran-\ndomly initialized BiLSTM on top of the \"LTR + No \nNSP\" model during fine-tuning. \n\n","rows":["BERTBASE","No NSP","LTR \u0026 No NSP","+ BiLSTM"],"columns":["SQuAD","( Acc )","SST - 2","Dev Set","( F1 )","MNLI - m","QNLI","MRPC"],"mergedAllColumns":[],"numberCells":[{"number":"92.6","isBolded":false,"associatedRows":["No NSP"],"associatedColumns":["Dev Set","SST - 2","( Acc )"],"associatedMergedColumns":[]},{"number":"92.7","isBolded":false,"associatedRows":["BERTBASE"],"associatedColumns":["Dev Set","SST - 2","( Acc )"],"associatedMergedColumns":[]},{"number":"77.8","isBolded":false,"associatedRows":["LTR \u0026 No NSP"],"associatedColumns":["Dev Set","SQuAD","( F1 )"],"associatedMergedColumns":[]},{"number":"84.4","isBolded":false,"associatedRows":["BERTBASE"],"associatedColumns":["Dev Set","MNLI - m","( Acc )"],"associatedMergedColumns":[]},{"number":"84.1","isBolded":false,"associatedRows":["+ BiLSTM"],"associatedColumns":["Dev Set","QNLI","( Acc )"],"associatedMergedColumns":[]},{"number":"75.7","isBolded":false,"associatedRows":["+ BiLSTM"],"associatedColumns":["Dev Set","MRPC","( Acc )"],"associatedMergedColumns":[]},{"number":"88.5","isBolded":false,"associatedRows":["BERTBASE"],"associatedColumns":["Dev Set","SQuAD","( F1 )"],"associatedMergedColumns":[]},{"number":"86.5","isBolded":false,"associatedRows":["No NSP"],"associatedColumns":["Dev Set","MRPC","( Acc )"],"associatedMergedColumns":[]},{"number":"84.3","isBolded":false,"associatedRows":["LTR \u0026 No NSP"],"associatedColumns":["Dev Set","QNLI","( Acc )"],"associatedMergedColumns":[]},{"number":"92.1","isBolded":false,"associatedRows":["LTR \u0026 No NSP"],"associatedColumns":["Dev Set","SST - 2","( Acc )"],"associatedMergedColumns":[]},{"number":"87.9","isBolded":false,"associatedRows":["No NSP"],"associatedColumns":["Dev Set","SQuAD","( F1 )"],"associatedMergedColumns":[]},{"number":"82.1","isBolded":false,"associatedRows":["+ BiLSTM"],"associatedColumns":["Dev Set","MNLI - m","( Acc )"],"associatedMergedColumns":[]},{"number":"82.1","isBolded":false,"associatedRows":["LTR \u0026 No NSP"],"associatedColumns":["Dev Set","MNLI - m","( Acc )"],"associatedMergedColumns":[]},{"number":"86.7","isBolded":false,"associatedRows":["BERTBASE"],"associatedColumns":["Dev Set","MRPC","( Acc )"],"associatedMergedColumns":[]},{"number":"84.9","isBolded":false,"associatedRows":["+ BiLSTM"],"associatedColumns":["Dev Set","SQuAD","( F1 )"],"associatedMergedColumns":[]},{"number":"91.6","isBolded":false,"associatedRows":["+ BiLSTM"],"associatedColumns":["Dev Set","SST - 2","( Acc )"],"associatedMergedColumns":[]},{"number":"83.9","isBolded":false,"associatedRows":["No NSP"],"associatedColumns":["Dev Set","MNLI - m","( Acc )"],"associatedMergedColumns":[]},{"number":"88.4","isBolded":false,"associatedRows":["BERTBASE"],"associatedColumns":["Dev Set","QNLI","( Acc )"],"associatedMergedColumns":[]},{"number":"77.5","isBolded":false,"associatedRows":["LTR \u0026 No NSP"],"associatedColumns":["Dev Set","MRPC","( Acc )"],"associatedMergedColumns":[]},{"number":"84.9","isBolded":false,"associatedRows":["No NSP"],"associatedColumns":["Dev Set","QNLI","( Acc )"],"associatedMergedColumns":[]}]},{"caption":"Table 6: Ablation over BERT model size. #L \u003d the \nnumber of layers; #H \u003d hidden size; #A \u003d number of at-\ntention heads. \"LM (ppl)\" is the masked LM perplexity \nof held-out training data. \n\n","rows":["12","24","3","16","6","1024","768"],"columns":["By contrast , BERT BASE","Hyperparams","LM ( ppl )","SST - 2",") .","Dev Set Accuracy","MNLI - m","MRPC"],"mergedAllColumns":[],"numberCells":[{"number":"82.2","isBolded":false,"associatedRows":["12","6","768","3"],"associatedColumns":["By contrast , BERT BASE","Dev Set Accuracy","MRPC"],"associatedMergedColumns":[]},{"number":"86.7","isBolded":false,"associatedRows":["12","6","768","12"],"associatedColumns":["By contrast , BERT BASE","Dev Set Accuracy","MRPC"],"associatedMergedColumns":[]},{"number":"92.9","isBolded":false,"associatedRows":["12","6","768","12"],"associatedColumns":["By contrast , BERT BASE","Dev Set Accuracy","SST - 2"],"associatedMergedColumns":[]},{"number":"4.68","isBolded":false,"associatedRows":["12","6","768","12"],"associatedColumns":[") .","Hyperparams","LM ( ppl )"],"associatedMergedColumns":[]},{"number":"86.9","isBolded":false,"associatedRows":["12","6","1024","16"],"associatedColumns":["By contrast , BERT BASE","Dev Set Accuracy","MRPC"],"associatedMergedColumns":[]},{"number":"5.84","isBolded":false,"associatedRows":["12","3","768","12"],"associatedColumns":[") .","Hyperparams","LM ( ppl )"],"associatedMergedColumns":[]},{"number":"84.4","isBolded":false,"associatedRows":["12","6","768","12"],"associatedColumns":["By contrast , BERT BASE","Dev Set Accuracy","MNLI - m"],"associatedMergedColumns":[]},{"number":"5.24","isBolded":false,"associatedRows":["12","6","768","3"],"associatedColumns":[") .","Hyperparams","LM ( ppl )"],"associatedMergedColumns":[]},{"number":"91.3","isBolded":false,"associatedRows":["12","6","768","12"],"associatedColumns":["By contrast , BERT BASE","Dev Set Accuracy","SST - 2"],"associatedMergedColumns":[]},{"number":"85.7","isBolded":false,"associatedRows":["12","6","1024","16"],"associatedColumns":["By contrast , BERT BASE","Dev Set Accuracy","MNLI - m"],"associatedMergedColumns":[]},{"number":"81.9","isBolded":false,"associatedRows":["12","6","768","12"],"associatedColumns":["By contrast , BERT BASE","Dev Set Accuracy","MNLI - m"],"associatedMergedColumns":[]},{"number":"3.23","isBolded":false,"associatedRows":["24","6","1024","16"],"associatedColumns":["By contrast , BERT BASE","Hyperparams","LM ( ppl )"],"associatedMergedColumns":[]},{"number":"3.99","isBolded":false,"associatedRows":["12","6","768","12"],"associatedColumns":[") .","Hyperparams","LM ( ppl )"],"associatedMergedColumns":[]},{"number":"77.9","isBolded":false,"associatedRows":["12","3","768","12"],"associatedColumns":["By contrast , BERT BASE","Dev Set Accuracy","MNLI - m"],"associatedMergedColumns":[]},{"number":"79.8","isBolded":false,"associatedRows":["12","3","768","12"],"associatedColumns":["By contrast , BERT BASE","Dev Set Accuracy","MRPC"],"associatedMergedColumns":[]},{"number":"84.8","isBolded":false,"associatedRows":["12","6","768","12"],"associatedColumns":["By contrast , BERT BASE","Dev Set Accuracy","MRPC"],"associatedMergedColumns":[]},{"number":"88.4","isBolded":false,"associatedRows":["12","3","768","12"],"associatedColumns":["By contrast , BERT BASE","Dev Set Accuracy","SST - 2"],"associatedMergedColumns":[]},{"number":"3.54","isBolded":false,"associatedRows":["12","6","1024","16"],"associatedColumns":["By contrast , BERT BASE","Hyperparams","LM ( ppl )"],"associatedMergedColumns":[]},{"number":"90.7","isBolded":false,"associatedRows":["12","6","768","3"],"associatedColumns":["By contrast , BERT BASE","Dev Set Accuracy","SST - 2"],"associatedMergedColumns":[]},{"number":"93.3","isBolded":false,"associatedRows":["12","6","1024","16"],"associatedColumns":["By contrast , BERT BASE","Dev Set Accuracy","SST - 2"],"associatedMergedColumns":[]},{"number":"86.6","isBolded":false,"associatedRows":["24","6","1024","16"],"associatedColumns":["By contrast , BERT BASE","Dev Set Accuracy","MNLI - m"],"associatedMergedColumns":[]},{"number":"80.6","isBolded":false,"associatedRows":["12","6","768","3"],"associatedColumns":["By contrast , BERT BASE","Dev Set Accuracy","MNLI - m"],"associatedMergedColumns":[]},{"number":"87.8","isBolded":false,"associatedRows":["24","6","1024","16"],"associatedColumns":["By contrast , BERT BASE","Dev Set Accuracy","MRPC"],"associatedMergedColumns":[]},{"number":"93.7","isBolded":false,"associatedRows":["24","6","1024","16"],"associatedColumns":["By contrast , BERT BASE","Dev Set Accuracy","SST - 2"],"associatedMergedColumns":[]}]},{"caption":"Table 7. The best perform-\ning method is to concatenate the token representa-\ntions from the top four hidden layers of the pre-\ntrained Transformer, which is only 0.3 F1 behind \nfine-tuning the entire model. This demonstrates \nthat BERT is effective for both the fine-tuning and \nfeature-based approaches. \n\n","rows":["Sum Last Four Hidden","Sum All 12 Layers","Second - to - Last Hidden","First Layer ( Embeddings )","Finetune All","Concat Last Four Hidden","Last Hidden"],"columns":["F1"],"mergedAllColumns":[],"numberCells":[{"number":"91.0","isBolded":false,"associatedRows":["First Layer ( Embeddings )"],"associatedColumns":["F1"],"associatedMergedColumns":[]},{"number":"95.9","isBolded":false,"associatedRows":["Sum Last Four Hidden"],"associatedColumns":["F1"],"associatedMergedColumns":[]},{"number":"94.9","isBolded":false,"associatedRows":["Last Hidden"],"associatedColumns":["F1"],"associatedMergedColumns":[]},{"number":"96.1","isBolded":false,"associatedRows":["Concat Last Four Hidden"],"associatedColumns":["F1"],"associatedMergedColumns":[]},{"number":"95.5","isBolded":false,"associatedRows":["Sum All 12 Layers"],"associatedColumns":["F1"],"associatedMergedColumns":[]},{"number":"96.4","isBolded":false,"associatedRows":["Finetune All"],"associatedColumns":["F1"],"associatedMergedColumns":[]},{"number":"95.6","isBolded":false,"associatedRows":["Second - to - Last Hidden"],"associatedColumns":["F1"],"associatedMergedColumns":[]}]}]