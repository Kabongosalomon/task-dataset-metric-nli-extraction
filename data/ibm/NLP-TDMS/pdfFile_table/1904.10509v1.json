[{"caption":"Table 2. Sparse patterns showed increased speed and also better \nloss on the datasets where we could compare both, which may \npoint to a useful inductive bias in the patterns we learned or an \nunderlying optimization issue with full attention. \n\n","rows":["Sparse Transformer ( Fixed )","Sparse Transformer ( Strided )","Dense Attention"],"columns":["Bits per byte","Time / Iter"],"mergedAllColumns":["CIFAR - 10 ( 3 , 072 context )","Enwik8 ( 12 , 288 context )"],"numberCells":[{"number":"1.13","isBolded":false,"associatedRows":["Sparse Transformer ( Strided )"],"associatedColumns":["Bits per byte"],"associatedMergedColumns":["Enwik8 ( 12 , 288 context )"]},{"number":"0.55","isBolded":false,"associatedRows":["Sparse Transformer ( Fixed )"],"associatedColumns":["Time / Iter"],"associatedMergedColumns":["Enwik8 ( 12 , 288 context )"]},{"number":"0.54","isBolded":false,"associatedRows":["Dense Attention"],"associatedColumns":["Time / Iter"],"associatedMergedColumns":["CIFAR - 10 ( 3 , 072 context )"]},{"number":"0.47","isBolded":false,"associatedRows":["Sparse Transformer ( Fixed )"],"associatedColumns":["Time / Iter"],"associatedMergedColumns":["CIFAR - 10 ( 3 , 072 context )"]},{"number":"1.31","isBolded":false,"associatedRows":["Dense Attention"],"associatedColumns":["Time / Iter"],"associatedMergedColumns":["Enwik8 ( 12 , 288 context )"]},{"number":"2.82","isBolded":false,"associatedRows":["Dense Attention"],"associatedColumns":["Bits per byte"],"associatedMergedColumns":["CIFAR - 10 ( 3 , 072 context )"]},{"number":"0.35","isBolded":false,"associatedRows":["Sparse Transformer ( Strided )"],"associatedColumns":["Time / Iter"],"associatedMergedColumns":["Enwik8 ( 12 , 288 context )"]},{"number":"1.00","isBolded":false,"associatedRows":["Dense Attention"],"associatedColumns":["Bits per byte"],"associatedMergedColumns":["Enwik8 ( 12 , 288 context )"]},{"number":"2.80","isBolded":true,"associatedRows":["Sparse Transformer ( Strided )"],"associatedColumns":["Bits per byte"],"associatedMergedColumns":["CIFAR - 10 ( 3 , 072 context )"]},{"number":"2.85","isBolded":false,"associatedRows":["Sparse Transformer ( Fixed )"],"associatedColumns":["Bits per byte"],"associatedMergedColumns":["CIFAR - 10 ( 3 , 072 context )"]},{"number":"0.38","isBolded":false,"associatedRows":["Sparse Transformer ( Strided )"],"associatedColumns":["Time / Iter"],"associatedMergedColumns":["CIFAR - 10 ( 3 , 072 context )"]},{"number":"0.99","isBolded":true,"associatedRows":["Sparse Transformer ( Fixed )"],"associatedColumns":["Bits per byte"],"associatedMergedColumns":["Enwik8 ( 12 , 288 context )"]}]},{"caption":"Model \nBits per byte Time/Iter \n\nEnwik8 (12,288 context) \n\nDense Attention \n1.00 \n1.31 \nSparse Transformer (Fixed) \n0.99 \n0.55 \nSparse Transformer (Strided) \n1.13 \n0.35 \n\nCIFAR-10 (3,072 context) \n\nDense Attention \n2.82 \n0.54 \nSparse Transformer (Fixed) \n2.85 \n0.47 \nSparse Transformer (Strided) \n2.80 \n0.38 \n\nTable 3. We observe increased compression of Enwik8 with longer \ncontexts, suggesting the Sparse Transformer can effectively incor-\nporate long-term dependencies. \n\n","rows":["10 , 752 tokens","9 , 216 tokens","6 , 144 tokens","11 , 904 tokens","12 , 096 tokens","12 , 160 tokens"],"columns":["Bits per byte"],"mergedAllColumns":[],"numberCells":[{"number":"0.9932","isBolded":false,"associatedRows":["10 , 752 tokens"],"associatedColumns":["Bits per byte"],"associatedMergedColumns":[]},{"number":"0.9952","isBolded":false,"associatedRows":["6 , 144 tokens"],"associatedColumns":["Bits per byte"],"associatedMergedColumns":[]},{"number":"0.9922","isBolded":false,"associatedRows":["12 , 096 tokens"],"associatedColumns":["Bits per byte"],"associatedMergedColumns":[]},{"number":"0.9936","isBolded":false,"associatedRows":["9 , 216 tokens"],"associatedColumns":["Bits per byte"],"associatedMergedColumns":[]},{"number":"0.9908","isBolded":true,"associatedRows":["12 , 160 tokens"],"associatedColumns":["Bits per byte"],"associatedMergedColumns":[]},{"number":"0.9930","isBolded":false,"associatedRows":["11 , 904 tokens"],"associatedColumns":["Bits per byte"],"associatedMergedColumns":[]}]},{"caption":"Table 4. Performance of a strided Sparse Transformer on a classical \naudio dataset (Âµ-law encoded at 12 kHz) as a function of sequence \nlength and model size. \n\n","rows":["262 , 144","65 , 536","152M","25M","1 , 048 , 576","3M"],"columns":["Bits per byte"],"mergedAllColumns":[],"numberCells":[{"number":"2.99","isBolded":false,"associatedRows":["1 , 048 , 576","3M"],"associatedColumns":["Bits per byte"],"associatedMergedColumns":[]},{"number":"1.97","isBolded":false,"associatedRows":["65 , 536","152M"],"associatedColumns":["Bits per byte"],"associatedMergedColumns":[]},{"number":"2.17","isBolded":false,"associatedRows":["262 , 144","25M"],"associatedColumns":["Bits per byte"],"associatedMergedColumns":[]}]}]