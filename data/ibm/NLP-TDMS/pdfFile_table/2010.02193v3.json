[{"caption":"Table K.1. There are different approaches for aggregating the \nscores across the 55 games and we show that this choice can have a substantial impact on the relative \nperformance between algorithms. To extensively compare DreamerV2 to the model-free algorithms, \nwe consider the following four aggregation approaches: \n\nAgent \nGamer Median Gamer Mean Record Mean Clipped Record Mean \n\nDreamerV2 \n2.15 \n42.26 \n0.44 \n0.28 \nDreamerV2 (schedules) \n2.64 \n31.71 \n0.43 \n0.28 \nIMPALA \n1.92 \n16.72 \n0.34 \n0.23 \nIQN \n1.29 \n11.27 \n0.21 \n0.21 \nRainbow \n1.47 \n9.95 \n0.17 \n0.17 \nC51 \n1.09 \n8.25 \n0.15 \n0.15 \nDQN \n0.65 \n3.28 \n0.12 \n0.12 \n\nTable 1: Atari performance at 200M steps. The scores of the 55 games are aggregated using the \nfour different protocols described in Section 3. To overcome limitations of the previous metrics, we \nrecommend the task mean of clipped record normalized scores as a robust measure of algorithm \nperformance, shown in the right-most column. DreamerV2 outperforms previous single-GPU agents \nacross all metrics. The baseline scores are taken from Dopamine Baselines (Castro et al., 2018). \n","rows":["DQN","DreamerV2","Rainbow","IQN","DreamerV2 ( schedules )","IMPALA","C51"],"columns":["There are different approaches for aggregating the","Record Mean","Gamer Mean","Table K . 1 .","Gamer Median","Clipped Record Mean"],"mergedAllColumns":["we consider the following four aggregation approaches :"],"numberCells":[{"number":"0.15","isBolded":false,"associatedRows":["C51"],"associatedColumns":["There are different approaches for aggregating the","Clipped Record Mean"],"associatedMergedColumns":["we consider the following four aggregation approaches :"]},{"number":"0.28","isBolded":true,"associatedRows":["DreamerV2"],"associatedColumns":["There are different approaches for aggregating the","Clipped Record Mean"],"associatedMergedColumns":["we consider the following four aggregation approaches :"]},{"number":"0.23","isBolded":false,"associatedRows":["IMPALA"],"associatedColumns":["There are different approaches for aggregating the","Clipped Record Mean"],"associatedMergedColumns":["we consider the following four aggregation approaches :"]},{"number":"0.21","isBolded":false,"associatedRows":["IQN"],"associatedColumns":["There are different approaches for aggregating the","Record Mean"],"associatedMergedColumns":["we consider the following four aggregation approaches :"]},{"number":"1.47","isBolded":false,"associatedRows":["Rainbow"],"associatedColumns":["Table K . 1 .","Gamer Median"],"associatedMergedColumns":["we consider the following four aggregation approaches :"]},{"number":"0.15","isBolded":false,"associatedRows":["C51"],"associatedColumns":["There are different approaches for aggregating the","Record Mean"],"associatedMergedColumns":["we consider the following four aggregation approaches :"]},{"number":"1.29","isBolded":false,"associatedRows":["IQN"],"associatedColumns":["Table K . 1 .","Gamer Median"],"associatedMergedColumns":["we consider the following four aggregation approaches :"]},{"number":"0.17","isBolded":false,"associatedRows":["Rainbow"],"associatedColumns":["There are different approaches for aggregating the","Clipped Record Mean"],"associatedMergedColumns":["we consider the following four aggregation approaches :"]},{"number":"8.25","isBolded":false,"associatedRows":["C51"],"associatedColumns":["There are different approaches for aggregating the","Gamer Mean"],"associatedMergedColumns":["we consider the following four aggregation approaches :"]},{"number":"16.72","isBolded":false,"associatedRows":["IMPALA"],"associatedColumns":["There are different approaches for aggregating the","Gamer Mean"],"associatedMergedColumns":["we consider the following four aggregation approaches :"]},{"number":"11.27","isBolded":false,"associatedRows":["IQN"],"associatedColumns":["There are different approaches for aggregating the","Gamer Mean"],"associatedMergedColumns":["we consider the following four aggregation approaches :"]},{"number":"0.21","isBolded":false,"associatedRows":["IQN"],"associatedColumns":["There are different approaches for aggregating the","Clipped Record Mean"],"associatedMergedColumns":["we consider the following four aggregation approaches :"]},{"number":"0.43","isBolded":false,"associatedRows":["DreamerV2 ( schedules )"],"associatedColumns":["There are different approaches for aggregating the","Record Mean"],"associatedMergedColumns":["we consider the following four aggregation approaches :"]},{"number":"3.28","isBolded":false,"associatedRows":["DQN"],"associatedColumns":["There are different approaches for aggregating the","Gamer Mean"],"associatedMergedColumns":["we consider the following four aggregation approaches :"]},{"number":"0.28","isBolded":true,"associatedRows":["DreamerV2 ( schedules )"],"associatedColumns":["There are different approaches for aggregating the","Clipped Record Mean"],"associatedMergedColumns":["we consider the following four aggregation approaches :"]},{"number":"42.26","isBolded":true,"associatedRows":["DreamerV2"],"associatedColumns":["There are different approaches for aggregating the","Gamer Mean"],"associatedMergedColumns":["we consider the following four aggregation approaches :"]},{"number":"31.71","isBolded":false,"associatedRows":["DreamerV2 ( schedules )"],"associatedColumns":["There are different approaches for aggregating the","Gamer Mean"],"associatedMergedColumns":["we consider the following four aggregation approaches :"]},{"number":"0.34","isBolded":false,"associatedRows":["IMPALA"],"associatedColumns":["There are different approaches for aggregating the","Record Mean"],"associatedMergedColumns":["we consider the following four aggregation approaches :"]},{"number":"1.09","isBolded":false,"associatedRows":["C51"],"associatedColumns":["Table K . 1 .","Gamer Median"],"associatedMergedColumns":["we consider the following four aggregation approaches :"]},{"number":"2.15","isBolded":false,"associatedRows":["DreamerV2"],"associatedColumns":["Table K . 1 .","Gamer Median"],"associatedMergedColumns":["we consider the following four aggregation approaches :"]},{"number":"1.92","isBolded":false,"associatedRows":["IMPALA"],"associatedColumns":["Table K . 1 .","Gamer Median"],"associatedMergedColumns":["we consider the following four aggregation approaches :"]},{"number":"0.44","isBolded":true,"associatedRows":["DreamerV2"],"associatedColumns":["There are different approaches for aggregating the","Record Mean"],"associatedMergedColumns":["we consider the following four aggregation approaches :"]},{"number":"0.12","isBolded":false,"associatedRows":["DQN"],"associatedColumns":["There are different approaches for aggregating the","Record Mean"],"associatedMergedColumns":["we consider the following four aggregation approaches :"]},{"number":"0.12","isBolded":false,"associatedRows":["DQN"],"associatedColumns":["There are different approaches for aggregating the","Clipped Record Mean"],"associatedMergedColumns":["we consider the following four aggregation approaches :"]},{"number":"9.95","isBolded":false,"associatedRows":["Rainbow"],"associatedColumns":["There are different approaches for aggregating the","Gamer Mean"],"associatedMergedColumns":["we consider the following four aggregation approaches :"]},{"number":"0.65","isBolded":false,"associatedRows":["DQN"],"associatedColumns":["Table K . 1 .","Gamer Median"],"associatedMergedColumns":["we consider the following four aggregation approaches :"]},{"number":"0.17","isBolded":false,"associatedRows":["Rainbow"],"associatedColumns":["There are different approaches for aggregating the","Record Mean"],"associatedMergedColumns":["we consider the following four aggregation approaches :"]},{"number":"2.64","isBolded":true,"associatedRows":["DreamerV2 ( schedules )"],"associatedColumns":["Table K . 1 .","Gamer Median"],"associatedMergedColumns":["we consider the following four aggregation approaches :"]}]},{"caption":"Table 2: Ablations to DreamerV2 measured by their Atari performance at 200M frames, sorted by the \nlast column. The this experiment uses a slightly earlier version of DreamerV2 compared to Table 1. \nEach ablation only removes one part of the DreamerV2 agent. Discrete latent variables and KL \nbalancing substantially contribute to the success of DreamerV2. Moreover, the world model relies \non image gradients to learn general representations that lead to successful behaviors, even if the \nrepresentations are not specifically learned for predicting past rewards. \n\n","rows":["DreamerV2","No Layer Norm","No Reward Gradients","No KL Balancing","No Image Gradients","No Discrete Latents","No Policy Reinforce"],"columns":["Record Mean","Gamer Mean","Gamer Median","Clipped Record Mean"],"mergedAllColumns":[],"numberCells":[{"number":"0.37","isBolded":false,"associatedRows":["No Image Gradients"],"associatedColumns":["Gamer Mean"],"associatedMergedColumns":[]},{"number":"14.29","isBolded":false,"associatedRows":["No Reward Gradients"],"associatedColumns":["Gamer Mean"],"associatedMergedColumns":[]},{"number":"0.01","isBolded":false,"associatedRows":["No Image Gradients"],"associatedColumns":["Clipped Record Mean"],"associatedMergedColumns":[]},{"number":"1.68","isBolded":false,"associatedRows":["No Reward Gradients"],"associatedColumns":["Gamer Median"],"associatedMergedColumns":[]},{"number":"0.16","isBolded":false,"associatedRows":["No KL Balancing"],"associatedColumns":["Clipped Record Mean"],"associatedMergedColumns":[]},{"number":"0.72","isBolded":false,"associatedRows":["No Policy Reinforce"],"associatedColumns":["Gamer Median"],"associatedMergedColumns":[]},{"number":"0.01","isBolded":false,"associatedRows":["No Image Gradients"],"associatedColumns":["Record Mean"],"associatedMergedColumns":[]},{"number":"0.24","isBolded":false,"associatedRows":["No Reward Gradients"],"associatedColumns":["Clipped Record Mean"],"associatedMergedColumns":[]},{"number":"0.38","isBolded":false,"associatedRows":["No Layer Norm"],"associatedColumns":["Record Mean"],"associatedMergedColumns":[]},{"number":"4.25","isBolded":false,"associatedRows":["No KL Balancing"],"associatedColumns":["Gamer Mean"],"associatedMergedColumns":[]},{"number":"13.39","isBolded":false,"associatedRows":["DreamerV2"],"associatedColumns":["Gamer Mean"],"associatedMergedColumns":[]},{"number":"11.29","isBolded":false,"associatedRows":["No Layer Norm"],"associatedColumns":["Gamer Mean"],"associatedMergedColumns":[]},{"number":"0.16","isBolded":false,"associatedRows":["No Policy Reinforce"],"associatedColumns":["Record Mean"],"associatedMergedColumns":[]},{"number":"0.87","isBolded":false,"associatedRows":["No KL Balancing"],"associatedColumns":["Gamer Median"],"associatedMergedColumns":[]},{"number":"0.25","isBolded":false,"associatedRows":["No Layer Norm"],"associatedColumns":["Clipped Record Mean"],"associatedMergedColumns":[]},{"number":"0.19","isBolded":false,"associatedRows":["No Discrete Latents"],"associatedColumns":["Clipped Record Mean"],"associatedMergedColumns":[]},{"number":"1.66","isBolded":false,"associatedRows":["No Layer Norm"],"associatedColumns":["Gamer Median"],"associatedMergedColumns":[]},{"number":"0.25","isBolded":false,"associatedRows":["DreamerV2"],"associatedColumns":["Clipped Record Mean"],"associatedMergedColumns":[]},{"number":"0.37","isBolded":false,"associatedRows":["No Reward Gradients"],"associatedColumns":["Record Mean"],"associatedMergedColumns":[]},{"number":"0.15","isBolded":false,"associatedRows":["No Policy Reinforce"],"associatedColumns":["Clipped Record Mean"],"associatedMergedColumns":[]},{"number":"5.10","isBolded":false,"associatedRows":["No Policy Reinforce"],"associatedColumns":["Gamer Mean"],"associatedMergedColumns":[]},{"number":"0.36","isBolded":false,"associatedRows":["DreamerV2"],"associatedColumns":["Record Mean"],"associatedMergedColumns":[]},{"number":"3.96","isBolded":false,"associatedRows":["No Discrete Latents"],"associatedColumns":["Gamer Mean"],"associatedMergedColumns":[]},{"number":"0.85","isBolded":false,"associatedRows":["No Discrete Latents"],"associatedColumns":["Gamer Median"],"associatedMergedColumns":[]},{"number":"0.24","isBolded":false,"associatedRows":["No Discrete Latents"],"associatedColumns":["Record Mean"],"associatedMergedColumns":[]},{"number":"0.19","isBolded":false,"associatedRows":["No KL Balancing"],"associatedColumns":["Record Mean"],"associatedMergedColumns":[]},{"number":"0.05","isBolded":false,"associatedRows":["No Image Gradients"],"associatedColumns":["Gamer Median"],"associatedMergedColumns":[]},{"number":"1.64","isBolded":false,"associatedRows":["DreamerV2"],"associatedColumns":["Gamer Median"],"associatedMergedColumns":[]}]},{"caption":"Table 3: Conceptual comparison of recent RL algorithms that leverage planning with a learned model. \nDreamerV2 and SimPLe learn complete models of the environment by leveraging the learning signal \nprovided by the image inputs, while MuZero learns its model through value gradients that are specific \nto an individual task. The Monte-Carlo tree search used by MuZero is effective but adds complexity \nand is challenging to parallelize. This component is orthogonal to the world model proposed here. \n\n","rows":["74M","MuZero","40M","DreamerV2","20B","4M","MuZero Reanalyze","200M","22M","SimPLe"],"columns":["Days","Accelerator"],"mergedAllColumns":["Algorithm"],"numberCells":[{"number":"80","isBolded":false,"associatedRows":["MuZero Reanalyze","40M","200M"],"associatedColumns":["Accelerator","Days"],"associatedMergedColumns":["Algorithm"]},{"number":"80","isBolded":false,"associatedRows":["MuZero","40M","20B"],"associatedColumns":["Accelerator","Days"],"associatedMergedColumns":["Algorithm"]},{"number":"40","isBolded":false,"associatedRows":["SimPLe","74M","4M"],"associatedColumns":["Accelerator","Days"],"associatedMergedColumns":["Algorithm"]},{"number":"10","isBolded":false,"associatedRows":["DreamerV2","22M","200M"],"associatedColumns":["Accelerator","Days"],"associatedMergedColumns":["Algorithm"]}]}]