[{"caption":"Model \nL \nH \nA \nI \nBERT-Small \n4 \n512 \n8 2,048 \nBERT-Base \n12 768 12 3,072 \nBERT-Large \n24 1,024 16 4,096 \nBERT-xLarge 36 1,536 24 6,144 \n\nTable 1: Model architectures for BERT evaluation. L: \n#layers, H: hidden size, A: #heads, I: intermediate size. \n\n","rows":["BERT - xLarge","1 , 536","1 , 024","768","BERT - Base","BERT - Large"],"columns":["A","4","8","L"],"mergedAllColumns":["4 , 096","3 , 072"],"numberCells":[{"number":"12","isBolded":false,"associatedRows":["BERT - Base","768"],"associatedColumns":["A","8"],"associatedMergedColumns":[]},{"number":"36","isBolded":false,"associatedRows":["BERT - xLarge"],"associatedColumns":["L","4"],"associatedMergedColumns":["4 , 096"]},{"number":"16","isBolded":false,"associatedRows":["BERT - Large","1 , 024"],"associatedColumns":["A","8"],"associatedMergedColumns":["3 , 072"]},{"number":"12","isBolded":false,"associatedRows":["BERT - Base"],"associatedColumns":["L","4"],"associatedMergedColumns":[]},{"number":"24","isBolded":false,"associatedRows":["BERT - xLarge","1 , 536"],"associatedColumns":["A","8"],"associatedMergedColumns":["4 , 096"]},{"number":"24","isBolded":false,"associatedRows":["BERT - Large"],"associatedColumns":["L","4"],"associatedMergedColumns":["3 , 072"]}]},{"caption":"Table 2: Masked Language Modeling accuracy on de-\nvelopment set after pre-training 1M steps. 5 RealFormer \noutperforms baselines more as model gets larger. \n\n","rows":["BERT - Small","BERT - xLarge","BERT - Base","BERT - Large"],"columns":["RealFormer","Pre - LN","Post - LN"],"mergedAllColumns":[],"numberCells":[{"number":"73.72%","isBolded":false,"associatedRows":["BERT - xLarge"],"associatedColumns":["Post - LN"],"associatedMergedColumns":[]},{"number":"73.53%","isBolded":false,"associatedRows":["BERT - xLarge"],"associatedColumns":["Pre - LN"],"associatedMergedColumns":[]},{"number":"74.76%","isBolded":true,"associatedRows":["BERT - xLarge"],"associatedColumns":["RealFormer"],"associatedMergedColumns":[]},{"number":"61.88%","isBolded":false,"associatedRows":["BERT - Small"],"associatedColumns":["Post - LN"],"associatedMergedColumns":[]},{"number":"69.74%","isBolded":false,"associatedRows":["BERT - Base"],"associatedColumns":["Pre - LN"],"associatedMergedColumns":[]},{"number":"73.94%","isBolded":true,"associatedRows":["BERT - Large"],"associatedColumns":["RealFormer"],"associatedMergedColumns":[]},{"number":"61.67%","isBolded":false,"associatedRows":["BERT - Small"],"associatedColumns":["Pre - LN"],"associatedMergedColumns":[]},{"number":"73.64%","isBolded":false,"associatedRows":["BERT - Large"],"associatedColumns":["Post - LN"],"associatedMergedColumns":[]},{"number":"73.21%","isBolded":false,"associatedRows":["BERT - Large"],"associatedColumns":["Pre - LN"],"associatedMergedColumns":[]},{"number":"70.42%","isBolded":true,"associatedRows":["BERT - Base"],"associatedColumns":["RealFormer"],"associatedMergedColumns":[]},{"number":"70.20%","isBolded":false,"associatedRows":["BERT - Base"],"associatedColumns":["Post - LN"],"associatedMergedColumns":[]},{"number":"62.02%","isBolded":true,"associatedRows":["BERT - Small"],"associatedColumns":["RealFormer"],"associatedMergedColumns":[]}]},{"caption":"Table 3: GLUE development set results of fine-tuning \nBERT-Large models in Table 2. Default metric: ac-\ncuracy, MC: Matthews correlation, PC: Pearson corre-\nlation, SC: Spearman correlation. Overall: first aver-\nage metrics within each task (if there are 1+) and then \nacross tasks. Numbers in smaller font are standard de-\nviations. All numbers are scaled by 100. \n\n","rows":["Overall"],"columns":["90 . 06±0 . 33","85 . 05±0 . 19","68 . 59±1 . 52","Pre - LN","89 . 77±0 . 26","89 . 62±0 . 28","90 . 11±0 . 56","90 . 91±0 . 65",") . Improvement","Post - LN","58 . 85±1 . 31","88 . 34±0 . 15","86 . 76±5 . 64","71 . 12±2 . 52","92 . 35±0 . 26","91 . 34±0 . 03","93 . 81±0 . 13","58 . 04±1 . 50","92 . 89±0 . 17","90 . 08±0 . 27","94 . 04±0 . 24","91 . 89±0 . 17","59 . 83±1 . 06","85 . 96±0 . 11","86 . 34±0 . 30","91 . 16±0 . 45","73 . 65±0 . 90","86 . 28±0 . 14","85 . 98±0 . 14","91 . 29±0 . 10","RealFormer","88 . 33±0 . 26","88 . 28±0 . 08","89 . 88±0 . 54","87 . 01±0 . 91","91 . 29±0 . 16","90 . 69±3 . 16","92 . 26±0 . 15","85 . 03±0 . 12","87 . 50±0 . 67"],"mergedAllColumns":["by simply using a larger learning rate and thereby even double the gap size over Post - LN . )"],"numberCells":[{"number":"84.53","isBolded":true,"associatedRows":["Overall"],"associatedColumns":[") . Improvement","RealFormer","86 . 28±0 . 14","86 . 34±0 . 30","91 . 34±0 . 03","88 . 28±0 . 08","91 . 89±0 . 17","94 . 04±0 . 24","59 . 83±1 . 06","90 . 11±0 . 56","89 . 88±0 . 54","87 . 01±0 . 91","90 . 91±0 . 65","73 . 65±0 . 90"],"associatedMergedColumns":["by simply using a larger learning rate and thereby even double the gap size over Post - LN . )"]},{"number":"83.47","isBolded":false,"associatedRows":["Overall"],"associatedColumns":[") . Improvement","Pre - LN","85 . 03±0 . 12","85 . 05±0 . 19","91 . 29±0 . 16","88 . 33±0 . 26","92 . 35±0 . 26","93 . 81±0 . 13","58 . 04±1 . 50","90 . 06±0 . 33","89 . 62±0 . 28","86 . 76±5 . 64","90 . 69±3 . 16","68 . 59±1 . 52"],"associatedMergedColumns":["by simply using a larger learning rate and thereby even double the gap size over Post - LN . )"]},{"number":"84.01","isBolded":false,"associatedRows":["Overall"],"associatedColumns":[") . Improvement","Post - LN","85 . 96±0 . 11","85 . 98±0 . 14","91 . 29±0 . 10","88 . 34±0 . 15","92 . 26±0 . 15","92 . 89±0 . 17","58 . 85±1 . 31","90 . 08±0 . 27","89 . 77±0 . 26","87 . 50±0 . 67","91 . 16±0 . 45","71 . 12±2 . 52"],"associatedMergedColumns":["by simply using a larger learning rate and thereby even double the gap size over Post - LN . )"]}]},{"caption":"Table 4: SQuAD development set results of fine-tuning \nBERT-Large models in Table 2. EM: exact match. Pub-\nlic: Post-LN results from ","rows":[],"columns":["SQuAD","82 . 51±0 . 12 80 . 30±0 . 12","85 . 15±0 . 13 83 . 98±0 . 24","91 . 68±0 . 12 91 . 06±0 . 09","Public Post - LN"],"mergedAllColumns":[],"numberCells":[{"number":"v2.0(F1)","isBolded":false,"associatedRows":[],"associatedColumns":["SQuAD","91 . 68±0 . 12 91 . 06±0 . 09","85 . 15±0 . 13 83 . 98±0 . 24"],"associatedMergedColumns":[]},{"number":"v1.1(EM)","isBolded":false,"associatedRows":[],"associatedColumns":["SQuAD","91 . 68±0 . 12 91 . 06±0 . 09"],"associatedMergedColumns":[]},{"number":"84.1","isBolded":false,"associatedRows":[],"associatedColumns":["Public Post - LN","91 . 68±0 . 12 91 . 06±0 . 09"],"associatedMergedColumns":[]},{"number":"v1.1(F1)","isBolded":false,"associatedRows":[],"associatedColumns":["SQuAD"],"associatedMergedColumns":[]},{"number":"90.9","isBolded":false,"associatedRows":[],"associatedColumns":["Public Post - LN"],"associatedMergedColumns":[]},{"number":"v2.0(EM)","isBolded":false,"associatedRows":[],"associatedColumns":["SQuAD","91 . 68±0 . 12 91 . 06±0 . 09","85 . 15±0 . 13 83 . 98±0 . 24","82 . 51±0 . 12 80 . 30±0 . 12"],"associatedMergedColumns":[]},{"number":"81.9","isBolded":false,"associatedRows":[],"associatedColumns":["Public Post - LN","91 . 68±0 . 12 91 . 06±0 . 09","85 . 15±0 . 13 83 . 98±0 . 24"],"associatedMergedColumns":[]},{"number":"78.7","isBolded":false,"associatedRows":[],"associatedColumns":["Public Post - LN","91 . 68±0 . 12 91 . 06±0 . 09","85 . 15±0 . 13 83 . 98±0 . 24","82 . 51±0 . 12 80 . 30±0 . 12"],"associatedMergedColumns":[]}]},{"caption":"Table 5: Downstream development set results of fine-\ntuning BERT-Large with Post-LN and RealFormer pre-\ntrained with different number of steps. v*.*: SQuAD \nversion, EM: exact match. Overall: First average \nacross SQuAD and then GLUE. Numbers in smaller \nfont are standard deviations. All numbers are scaled by \n100. \n\n","rows":["Overall","GLUE"],"columns":["( 1M )","Task","84 . 87±0 . 24","79 . 54±0 . 54","91 . 68±0 . 12","82 . 51±0 . 12","91 . 56±0 . 09","79 . 57±0 . 12","Post - LN","78 . 64±0 . 48","RealFormer","81 . 44±0 . 50","( 500K )","82 . 52±0 . 55","91 . 46±0 . 18","85 . 15±0 . 13","85 . 06±0 . 12"],"mergedAllColumns":[],"numberCells":[{"number":"84.37","isBolded":false,"associatedRows":["Overall"],"associatedColumns":["Post - LN","( 1M )","91 . 68±0 . 12","85 . 15±0 . 13","82 . 51±0 . 12","79 . 57±0 . 12"],"associatedMergedColumns":[]},{"number":"v2.0(EM)","isBolded":false,"associatedRows":[],"associatedColumns":["Task","( 500K )","91 . 46±0 . 18","84 . 87±0 . 24","81 . 44±0 . 50"],"associatedMergedColumns":[]},{"number":"v1.1(EM)","isBolded":false,"associatedRows":[],"associatedColumns":["Task","( 500K )","91 . 46±0 . 18"],"associatedMergedColumns":[]},{"number":"83.97","isBolded":false,"associatedRows":["Overall"],"associatedColumns":["Post - LN","( 500K )","91 . 46±0 . 18","84 . 87±0 . 24","81 . 44±0 . 50","78 . 64±0 . 48"],"associatedMergedColumns":[]},{"number":"v2.0(F1)","isBolded":false,"associatedRows":[],"associatedColumns":["Task","( 500K )","91 . 46±0 . 18","84 . 87±0 . 24"],"associatedMergedColumns":[]},{"number":"v1.1(F1)","isBolded":false,"associatedRows":[],"associatedColumns":["Task","( 500K )"],"associatedMergedColumns":[]},{"number":"84.01","isBolded":false,"associatedRows":["GLUE"],"associatedColumns":["Post - LN","( 1M )"],"associatedMergedColumns":[]},{"number":"83.84","isBolded":false,"associatedRows":["GLUE"],"associatedColumns":["Post - LN","( 500K )"],"associatedMergedColumns":[]},{"number":"84.34","isBolded":false,"associatedRows":["GLUE"],"associatedColumns":["RealFormer","( 500K )"],"associatedMergedColumns":[]},{"number":"84.51","isBolded":true,"associatedRows":["Overall"],"associatedColumns":["RealFormer","( 500K )","91 . 56±0 . 09","85 . 06±0 . 12","82 . 52±0 . 55","79 . 54±0 . 54"],"associatedMergedColumns":[]}]},{"caption":"Table 6: Masked Language Modeling (MLM) accu-\nracy on development set of BERT-Large with different \ndropout rates. When dropout rate is 0%, we report the \nbest possible number with early-stop because all mod-\nels start to overfit at around 500K steps. \n\n","rows":["0%","10%","20%"],"columns":["RealFormer","Pre - LN","Post - LN"],"mergedAllColumns":[],"numberCells":[{"number":"73.94%","isBolded":true,"associatedRows":["10%"],"associatedColumns":["RealFormer"],"associatedMergedColumns":[]},{"number":"71.30%","isBolded":true,"associatedRows":["0%"],"associatedColumns":["RealFormer"],"associatedMergedColumns":[]},{"number":"71.16%","isBolded":false,"associatedRows":["0%"],"associatedColumns":["Post - LN"],"associatedMergedColumns":[]},{"number":"73.21%","isBolded":false,"associatedRows":["10%"],"associatedColumns":["Pre - LN"],"associatedMergedColumns":[]},{"number":"73.66%","isBolded":true,"associatedRows":["20%"],"associatedColumns":["RealFormer"],"associatedMergedColumns":[]},{"number":"73.64%","isBolded":false,"associatedRows":["10%"],"associatedColumns":["Post - LN"],"associatedMergedColumns":[]},{"number":"69.80%","isBolded":false,"associatedRows":["0%"],"associatedColumns":["Pre - LN"],"associatedMergedColumns":[]},{"number":"73.21%","isBolded":false,"associatedRows":["20%"],"associatedColumns":["Post - LN"],"associatedMergedColumns":[]},{"number":"72.97%","isBolded":false,"associatedRows":["20%"],"associatedColumns":["Pre - LN"],"associatedMergedColumns":[]}]}]