[{"caption":"Table 1: Comparison with the state of the art on character level language modeling on enwik8. We \nreport bpc for the test set as well as the number of parameters. \n\n","rows":["Al - Rfou et al . [ 1 ] - T12","Chung et al . [ 7 ] - LN HM - LSTM","46M","44M","All - attention network + adaptive span","88M","Zilly et al . [ 45 ] - Recurrent highway networks","Krause et al . [ 22 ] - Large mLSTM","Dai et al . [ 8 ] - Transformer - XL","Child et al . [ 6 ] - Sparse Transformer ( fixed )","Al - Rfou et al . [ 1 ] - T64","Dai et al . [ 8 ] - Transformer - XL 24l","209M","Sukhbaatar et al . [ 39 ] - Transformer + adaptive span","Dai et al . [ 8 ] - Transformer - XL 18l","39M","27M","47M","35M","277M","235M","114M","41M","95M","Ha et al . [ 16 ] - LN HyperNetworks","Mujika et al . [ 30 ] - Large FS - LSTM - 4"],"columns":["test bpc"],"mergedAllColumns":["Large models","Small models"],"numberCells":[{"number":"0.99","isBolded":false,"associatedRows":["Child et al . [ 6 ] - Sparse Transformer ( fixed )","95M"],"associatedColumns":["test bpc"],"associatedMergedColumns":["Large models"]},{"number":"1.01","isBolded":true,"associatedRows":["All - attention network + adaptive span","39M"],"associatedColumns":["test bpc"],"associatedMergedColumns":["Small models"]},{"number":"1.25","isBolded":false,"associatedRows":["Mujika et al . [ 30 ] - Large FS - LSTM - 4","47M"],"associatedColumns":["test bpc"],"associatedMergedColumns":["Small models"]},{"number":"0.98","isBolded":true,"associatedRows":["All - attention network + adaptive span","114M"],"associatedColumns":["test bpc"],"associatedMergedColumns":["Large models"]},{"number":"1.24","isBolded":false,"associatedRows":["Krause et al . [ 22 ] - Large mLSTM","46M"],"associatedColumns":["test bpc"],"associatedMergedColumns":["Small models"]},{"number":"0.98","isBolded":true,"associatedRows":["Sukhbaatar et al . [ 39 ] - Transformer + adaptive span","209M"],"associatedColumns":["test bpc"],"associatedMergedColumns":["Large models"]},{"number":"1.11","isBolded":false,"associatedRows":["Al - Rfou et al . [ 1 ] - T12","44M"],"associatedColumns":["test bpc"],"associatedMergedColumns":["Small models"]},{"number":"1.32","isBolded":false,"associatedRows":["Chung et al . [ 7 ] - LN HM - LSTM","35M"],"associatedColumns":["test bpc"],"associatedMergedColumns":["Small models"]},{"number":"1.02","isBolded":false,"associatedRows":["Sukhbaatar et al . [ 39 ] - Transformer + adaptive span","39M"],"associatedColumns":["test bpc"],"associatedMergedColumns":["Small models"]},{"number":"1.03","isBolded":false,"associatedRows":["Dai et al . [ 8 ] - Transformer - XL 18l","88M"],"associatedColumns":["test bpc"],"associatedMergedColumns":["Large models"]},{"number":"0.99","isBolded":false,"associatedRows":["Dai et al . [ 8 ] - Transformer - XL 24l","277M"],"associatedColumns":["test bpc"],"associatedMergedColumns":["Large models"]},{"number":"1.34","isBolded":false,"associatedRows":["Ha et al . [ 16 ] - LN HyperNetworks","27M"],"associatedColumns":["test bpc"],"associatedMergedColumns":["Small models"]},{"number":"1.06","isBolded":false,"associatedRows":["Dai et al . [ 8 ] - Transformer - XL","41M"],"associatedColumns":["test bpc"],"associatedMergedColumns":["Small models"]},{"number":"1.27","isBolded":false,"associatedRows":["Zilly et al . [ 45 ] - Recurrent highway networks","46M"],"associatedColumns":["test bpc"],"associatedMergedColumns":["Small models"]},{"number":"1.06","isBolded":false,"associatedRows":["Al - Rfou et al . [ 1 ] - T64","235M"],"associatedColumns":["test bpc"],"associatedMergedColumns":["Large models"]}]},{"caption":"Table 2. Our large model is 0.01 bpc \nbelow the state-of-the-art, but with half the number of parameters. \n\n","rows":["Al - Rfou et al . [ 1 ] - T12","Al - Rfou et al . [ 1 ] - T64","Chung et al . [ 7 ] - LN HM - LSTM","209M","Sukhbaatar et al . [ 39 ] - Transformer + adaptive span","38M","35M","45M","277M","-","44M","All - attention network + adaptive span","235M","114M","Zilly et al . [ 45 ] - Recurrent highway networks","Krause et al . [ 22 ] - Large mLSTM","Dai et al . [ 8 ] - Transformer - XL"],"columns":["test bpc","dev bpc"],"mergedAllColumns":["Large models","Small models"],"numberCells":[{"number":"1.27","isBolded":false,"associatedRows":["Zilly et al . [ 45 ] - Recurrent highway networks","45M","-"],"associatedColumns":["test bpc"],"associatedMergedColumns":["Small models"]},{"number":"1.01","isBolded":false,"associatedRows":["Sukhbaatar et al . [ 39 ] - Transformer + adaptive span","209M"],"associatedColumns":["dev bpc"],"associatedMergedColumns":["Large models"]},{"number":"1.08","isBolded":false,"associatedRows":["Dai et al . [ 8 ] - Transformer - XL","277M","-"],"associatedColumns":["test bpc"],"associatedMergedColumns":["Large models"]},{"number":"1.08","isBolded":false,"associatedRows":["All - attention network + adaptive span","114M","-"],"associatedColumns":["test bpc"],"associatedMergedColumns":["Large models"]},{"number":"1.06","isBolded":false,"associatedRows":["Al - Rfou et al . [ 1 ] - T64","235M"],"associatedColumns":["dev bpc"],"associatedMergedColumns":["Large models"]},{"number":"1.07","isBolded":true,"associatedRows":["Sukhbaatar et al . [ 39 ] - Transformer + adaptive span","209M","-"],"associatedColumns":["test bpc"],"associatedMergedColumns":["Large models"]},{"number":"1.27","isBolded":false,"associatedRows":["Krause et al . [ 22 ] - Large mLSTM","45M","-"],"associatedColumns":["test bpc"],"associatedMergedColumns":["Small models"]},{"number":"1.02","isBolded":false,"associatedRows":["All - attention network + adaptive span","114M"],"associatedColumns":["dev bpc"],"associatedMergedColumns":["Large models"]},{"number":"1.13","isBolded":false,"associatedRows":["Al - Rfou et al . [ 1 ] - T64","235M","-"],"associatedColumns":["test bpc"],"associatedMergedColumns":["Large models"]},{"number":"1.29","isBolded":false,"associatedRows":["Chung et al . [ 7 ] - LN HM - LSTM","35M","-"],"associatedColumns":["test bpc"],"associatedMergedColumns":["Small models"]},{"number":"1.11","isBolded":true,"associatedRows":["All - attention network + adaptive span","38M","-"],"associatedColumns":["test bpc"],"associatedMergedColumns":["Small models"]},{"number":"1.05","isBolded":false,"associatedRows":["All - attention network + adaptive span","38M"],"associatedColumns":["dev bpc"],"associatedMergedColumns":["Small models"]},{"number":"1.18","isBolded":false,"associatedRows":["Al - Rfou et al . [ 1 ] - T12","44M","-"],"associatedColumns":["test bpc"],"associatedMergedColumns":["Small models"]},{"number":"1.11","isBolded":true,"associatedRows":["Sukhbaatar et al . [ 39 ] - Transformer + adaptive span","38M","-"],"associatedColumns":["test bpc"],"associatedMergedColumns":["Small models"]},{"number":"1.05","isBolded":false,"associatedRows":["Sukhbaatar et al . [ 39 ] - Transformer + adaptive span","38M"],"associatedColumns":["dev bpc"],"associatedMergedColumns":["Small models"]}]},{"caption":"Table 3: Comparison with the state of the art on word level language modeling on WikiText-103. \nWe report perplexity (ppl) for the dev and test sets as well as the number of parameters. \n\n","rows":["Bai et al . ( 2018 ) - TCN","Rae et al . [ 33 ] - LSTM + Hebbian + Cache","Grave et al . [ 14 ] - LSTM + Neural cache","Best published result with a large model [ 8 ]","( bpc )","133M","-","All - attention network + adaptive span","257M","Dev .","Dauphin et al . [ 9 ] - GCNN - 8","Merity et al . [ 26 ] - 4 - layer QRNN","Dai et al . [ 8 ] - Transformer - XL Standard","Grave et al . [ 14 ] - LSTM","151M"],"columns":["#Params","test ppl","dev ppl","Model"],"mergedAllColumns":["Small models"],"numberCells":[{"number":"1.01","isBolded":false,"associatedRows":["Dev .","Best published result with a large model [ 8 ]","Dev ."],"associatedColumns":["#Params"],"associatedMergedColumns":["Small models"]},{"number":"48.7","isBolded":false,"associatedRows":["( bpc )","Grave et al . [ 14 ] - LSTM","( bpc )","-","-"],"associatedColumns":["test ppl"],"associatedMergedColumns":["Small models"]},{"number":"29.7","isBolded":false,"associatedRows":["( bpc )","Rae et al . [ 33 ] - LSTM + Hebbian + Cache","( bpc )","-"],"associatedColumns":["dev ppl"],"associatedMergedColumns":["Small models"]},{"number":"17.7","isBolded":false,"associatedRows":["( bpc )","Best published result with a large model [ 8 ]","( bpc )","257M"],"associatedColumns":["dev ppl"],"associatedMergedColumns":["Small models"]},{"number":"1.100","isBolded":false,"associatedRows":["( bpc )"],"associatedColumns":["Model"],"associatedMergedColumns":["Small models"]},{"number":"1.075","isBolded":false,"associatedRows":["( bpc )"],"associatedColumns":["Model"],"associatedMergedColumns":["Small models"]},{"number":"33.0","isBolded":false,"associatedRows":["( bpc )","Merity et al . [ 26 ] - 4 - layer QRNN","( bpc )","151M","-"],"associatedColumns":["test ppl"],"associatedMergedColumns":["Small models"]},{"number":"44.9","isBolded":false,"associatedRows":["( bpc )","Dauphin et al . [ 9 ] - GCNN - 8","( bpc )","-","-"],"associatedColumns":["test ppl"],"associatedMergedColumns":["Small models"]},{"number":"32.0","isBolded":false,"associatedRows":["( bpc )","Merity et al . [ 26 ] - 4 - layer QRNN","( bpc )","151M"],"associatedColumns":["dev ppl"],"associatedMergedColumns":["Small models"]},{"number":"1.025","isBolded":false,"associatedRows":["Dev ."],"associatedColumns":["Model"],"associatedMergedColumns":["Small models"]},{"number":"1.04","isBolded":false,"associatedRows":["( bpc )","Best published result with a large model [ 8 ]","( bpc )"],"associatedColumns":["#Params"],"associatedMergedColumns":["Small models"]},{"number":"1.050","isBolded":false,"associatedRows":["( bpc )"],"associatedColumns":["Model"],"associatedMergedColumns":["Small models"]},{"number":"19.7","isBolded":false,"associatedRows":["( bpc )","All - attention network + adaptive span","( bpc )","133M"],"associatedColumns":["dev ppl"],"associatedMergedColumns":["Small models"]},{"number":"45.2","isBolded":false,"associatedRows":["( bpc )","Bai et al . ( 2018 ) - TCN","( bpc )","-","-"],"associatedColumns":["test ppl"],"associatedMergedColumns":["Small models"]},{"number":"1.03","isBolded":false,"associatedRows":["( bpc )","Best published result with a large model [ 8 ]","( bpc )"],"associatedColumns":["#Params"],"associatedMergedColumns":["Small models"]},{"number":"20.6","isBolded":true,"associatedRows":["( bpc )","All - attention network + adaptive span","( bpc )","133M","-"],"associatedColumns":["test ppl"],"associatedMergedColumns":["Small models"]},{"number":"24.0","isBolded":false,"associatedRows":["( bpc )","Dai et al . [ 8 ] - Transformer - XL Standard","( bpc )","151M","-"],"associatedColumns":["test ppl"],"associatedMergedColumns":["Small models"]},{"number":"18.3","isBolded":true,"associatedRows":["( bpc )","Best published result with a large model [ 8 ]","( bpc )","257M","-"],"associatedColumns":["test ppl"],"associatedMergedColumns":["Small models"]},{"number":"1.02","isBolded":false,"associatedRows":["Dev .","Best published result with a large model [ 8 ]","Dev ."],"associatedColumns":["#Params"],"associatedMergedColumns":["Small models"]},{"number":"23.1","isBolded":false,"associatedRows":["( bpc )","Dai et al . [ 8 ] - Transformer - XL Standard","( bpc )","151M"],"associatedColumns":["dev ppl"],"associatedMergedColumns":["Small models"]},{"number":"40.8","isBolded":false,"associatedRows":["( bpc )","Grave et al . [ 14 ] - LSTM + Neural cache","( bpc )","-","-"],"associatedColumns":["test ppl"],"associatedMergedColumns":["Small models"]},{"number":"29.9","isBolded":false,"associatedRows":["( bpc )","Rae et al . [ 33 ] - LSTM + Hebbian + Cache","( bpc )","-","-"],"associatedColumns":["test ppl"],"associatedMergedColumns":["Small models"]}]}]