[{"caption":"Table 1. Experimental results on different k settings of Global \nConvolutional Network. The score is evaluated by standard mean \nIoU(%) on PASCAL VOC 2012 validation set. \n\n","rows":["Score"],"columns":["11","13","3","15","5","7","9","base"],"mergedAllColumns":[],"numberCells":[{"number":"73.7","isBolded":false,"associatedRows":["Score"],"associatedColumns":["11"],"associatedMergedColumns":[]},{"number":"71.1","isBolded":false,"associatedRows":["Score"],"associatedColumns":["5"],"associatedMergedColumns":[]},{"number":"69.0","isBolded":false,"associatedRows":["Score"],"associatedColumns":["base"],"associatedMergedColumns":[]},{"number":"73.4","isBolded":false,"associatedRows":["Score"],"associatedColumns":["9"],"associatedMergedColumns":[]},{"number":"74.0","isBolded":false,"associatedRows":["Score"],"associatedColumns":["13"],"associatedMergedColumns":[]},{"number":"74.5","isBolded":false,"associatedRows":["Score"],"associatedColumns":["15"],"associatedMergedColumns":[]},{"number":"70.1","isBolded":false,"associatedRows":["Score"],"associatedColumns":["3"],"associatedMergedColumns":[]},{"number":"72.8","isBolded":false,"associatedRows":["Score"],"associatedColumns":["7"],"associatedMergedColumns":[]}]},{"caption":"Table 2. From the results we can see \nthat for any given kernel size, the trivial convolution design \ncontains more parameters than GCN. However, the latter is \nconsistently better than the former in performance respec-\ntively. It is also clear that for trivial convolution version, \n\n","rows":["Score ( Conv )","Score ( GCN )"],"columns":["3","5","7","9"],"mergedAllColumns":[],"numberCells":[{"number":"70.1","isBolded":false,"associatedRows":["Score ( GCN )"],"associatedColumns":["3"],"associatedMergedColumns":[]},{"number":"73.4","isBolded":false,"associatedRows":["Score ( GCN )"],"associatedColumns":["9"],"associatedMergedColumns":[]},{"number":"72.8","isBolded":false,"associatedRows":["Score ( GCN )"],"associatedColumns":["7"],"associatedMergedColumns":[]},{"number":"68.8","isBolded":false,"associatedRows":["Score ( Conv )"],"associatedColumns":["9"],"associatedMergedColumns":[]},{"number":"69.8","isBolded":false,"associatedRows":["Score ( Conv )"],"associatedColumns":["3"],"associatedMergedColumns":[]},{"number":"71.1","isBolded":false,"associatedRows":["Score ( GCN )"],"associatedColumns":["5"],"associatedMergedColumns":[]},{"number":"70.4","isBolded":false,"associatedRows":["Score ( Conv )"],"associatedColumns":["5"],"associatedMergedColumns":[]},{"number":"69.6","isBolded":false,"associatedRows":["Score ( Conv )"],"associatedColumns":["7"],"associatedMergedColumns":[]}]},{"caption":"Table 2. Comparison experiments between Global Convolutional \nNetwork and the trivial implementation. The score is measured \nunder standard mean IoU(%), and the 3rd and 4th rows show num-\nber of parameters of GCN and trivial Convolution after res-5. \n\nlarger kernel will result in better performance if k ≤ 5, yet \nfor k ≥ 7 the performance drops. One hypothesis is that \ntoo many parameters make the training suffer from overfit, \nwhich weakens the benefits from larger kernels. However, \nin training we find trivial large kernels in fact make the net-\nwork difficult to converge, while our GCN structure will not \nsuffer from this drawback. Thus the actual reason still needs \nfurther study. \n","rows":["Score ( Conv )","Score ( GCN )"],"columns":["3","5","7","9"],"mergedAllColumns":[],"numberCells":[{"number":"72.8","isBolded":false,"associatedRows":["Score ( GCN )"],"associatedColumns":["7"],"associatedMergedColumns":[]},{"number":"69.6","isBolded":false,"associatedRows":["Score ( Conv )"],"associatedColumns":["7"],"associatedMergedColumns":[]},{"number":"68.8","isBolded":false,"associatedRows":["Score ( Conv )"],"associatedColumns":["9"],"associatedMergedColumns":[]},{"number":"71.1","isBolded":false,"associatedRows":["Score ( GCN )"],"associatedColumns":["5"],"associatedMergedColumns":[]},{"number":"69.8","isBolded":false,"associatedRows":["Score ( Conv )"],"associatedColumns":["3"],"associatedMergedColumns":[]},{"number":"70.4","isBolded":false,"associatedRows":["Score ( Conv )"],"associatedColumns":["5"],"associatedMergedColumns":[]},{"number":"70.1","isBolded":false,"associatedRows":["Score ( GCN )"],"associatedColumns":["3"],"associatedMergedColumns":[]},{"number":"73.4","isBolded":false,"associatedRows":["Score ( GCN )"],"associatedColumns":["9"],"associatedMergedColumns":[]}]},{"caption":"Table 3. Comparison Experiments between Global Convolutional \nNetwork and the equivalent stack of small kernel convolutions. \nThe score is measured under standard mean IoU(%). GCN is still \nbetter with large kernels (k \u003e 7). \n\n","rows":["Score ( GCN )","Score ( Stack )"],"columns":["11","3","5","7","9"],"mergedAllColumns":[],"numberCells":[{"number":"72.8","isBolded":false,"associatedRows":["Score ( GCN )"],"associatedColumns":["7"],"associatedMergedColumns":[]},{"number":"69.5","isBolded":false,"associatedRows":["Score ( Stack )"],"associatedColumns":["9"],"associatedMergedColumns":[]},{"number":"71.8","isBolded":false,"associatedRows":["Score ( Stack )"],"associatedColumns":["5"],"associatedMergedColumns":[]},{"number":"70.1","isBolded":false,"associatedRows":["Score ( GCN )"],"associatedColumns":["3"],"associatedMergedColumns":[]},{"number":"71.1","isBolded":false,"associatedRows":["Score ( GCN )"],"associatedColumns":["5"],"associatedMergedColumns":[]},{"number":"73.4","isBolded":false,"associatedRows":["Score ( GCN )"],"associatedColumns":["9"],"associatedMergedColumns":[]},{"number":"73.7","isBolded":false,"associatedRows":["Score ( GCN )"],"associatedColumns":["11"],"associatedMergedColumns":[]},{"number":"67.5","isBolded":false,"associatedRows":["Score ( Stack )"],"associatedColumns":["11"],"associatedMergedColumns":[]},{"number":"69.8","isBolded":false,"associatedRows":["Score ( Stack )"],"associatedColumns":["3"],"associatedMergedColumns":[]},{"number":"71.3","isBolded":false,"associatedRows":["Score ( Stack )"],"associatedColumns":["7"],"associatedMergedColumns":[]}]},{"caption":"Table 4. Experimental results on the channels of stacking of small \nkernel convolutions. The score is measured under standard mean \nIoU. GCN outperforms the convolutional stack design with less \nparameters. \n\n","rows":["Score"],"columns":["210","2048","1024","2048 ( GCN )"],"mergedAllColumns":[],"numberCells":[{"number":"68.8","isBolded":false,"associatedRows":["Score"],"associatedColumns":["210"],"associatedMergedColumns":[]},{"number":"70.4","isBolded":false,"associatedRows":["Score"],"associatedColumns":["1024"],"associatedMergedColumns":[]},{"number":"71.3","isBolded":false,"associatedRows":["Score"],"associatedColumns":["2048"],"associatedMergedColumns":[]},{"number":"72.8","isBolded":false,"associatedRows":["Score"],"associatedColumns":["2048 ( GCN )"],"associatedMergedColumns":[]}]},{"caption":"Model \nBoundary (acc.) Internal (acc. ) Overall (IoU) \nBaseline \n71.3 \n93.9 \n69.0 \nGCN \n71.5 \n95.0 \n74.5 \nGCN + BR \n73.4 \n95.1 \n74.7 \n\nTable 5. Experimental results on Residual Boundary Alignment. \nThe Boundary and Internal columns are measured by the per-pixel \naccuracy while the 3rd column is measured by standard mean IoU. \n\n","rows":["GCN","GCN + BR","Baseline"],"columns":["Internal ( acc . )","Boundary ( acc . )","Overall ( IoU )"],"mergedAllColumns":[],"numberCells":[{"number":"74.7","isBolded":false,"associatedRows":["GCN + BR"],"associatedColumns":["Overall ( IoU )"],"associatedMergedColumns":[]},{"number":"73.4","isBolded":false,"associatedRows":["GCN + BR"],"associatedColumns":["Boundary ( acc . )"],"associatedMergedColumns":[]},{"number":"93.9","isBolded":false,"associatedRows":["Baseline"],"associatedColumns":["Internal ( acc . )"],"associatedMergedColumns":[]},{"number":"74.5","isBolded":false,"associatedRows":["GCN"],"associatedColumns":["Overall ( IoU )"],"associatedMergedColumns":[]},{"number":"69.0","isBolded":false,"associatedRows":["Baseline"],"associatedColumns":["Overall ( IoU )"],"associatedMergedColumns":[]},{"number":"95.0","isBolded":false,"associatedRows":["GCN"],"associatedColumns":["Internal ( acc . )"],"associatedMergedColumns":[]},{"number":"71.5","isBolded":false,"associatedRows":["GCN"],"associatedColumns":["Boundary ( acc . )"],"associatedMergedColumns":[]},{"number":"95.1","isBolded":false,"associatedRows":["GCN + BR"],"associatedColumns":["Internal ( acc . )"],"associatedMergedColumns":[]},{"number":"71.3","isBolded":false,"associatedRows":["Baseline"],"associatedColumns":["Boundary ( acc . )"],"associatedMergedColumns":[]}]},{"caption":"In Stage-1, we mix up all \nthe images from COCO, SBD and standard PASCAL VOC \n2012, resulting in 109,892 images for training. (2) During \nthe Stage-2, we use the SBD and standard PASCAL VOC \n2012 images, the same as Section 4.1. (3) For Stage-3, we \nonly use the standard PASCAL VOC 2012 dataset. The in-\nput image is padded to 640 × 640 in Stage-1 and 512 × 512 \nfor Stage-2 and Stage-3. The evaluation on validation set is \nshown in Table 7. \n\n","rows":["Stage - 3 - MS ( % )","Stage - 3 - MS - CRF ( % )","Stage - 1 ( % )","Stage - 3 ( % )","Stage - 2 ( % )"],"columns":["GCN","GCN + BR","Baseline"],"mergedAllColumns":[],"numberCells":[{"number":"74.1","isBolded":false,"associatedRows":["Stage - 1 ( % )"],"associatedColumns":["GCN"],"associatedMergedColumns":[]},{"number":"80.4","isBolded":false,"associatedRows":["Stage - 3 - MS ( % )"],"associatedColumns":["GCN + BR"],"associatedMergedColumns":[]},{"number":"69.6","isBolded":false,"associatedRows":["Stage - 1 ( % )"],"associatedColumns":["Baseline"],"associatedMergedColumns":[]},{"number":"78.6","isBolded":false,"associatedRows":["Stage - 2 ( % )"],"associatedColumns":["GCN + BR"],"associatedMergedColumns":[]},{"number":"81.0","isBolded":true,"associatedRows":["Stage - 3 - MS - CRF ( % )"],"associatedColumns":["GCN + BR"],"associatedMergedColumns":[]},{"number":"80.3","isBolded":false,"associatedRows":["Stage - 3 ( % )"],"associatedColumns":["GCN + BR"],"associatedMergedColumns":[]},{"number":"77.6","isBolded":false,"associatedRows":["Stage - 2 ( % )"],"associatedColumns":["GCN"],"associatedMergedColumns":[]},{"number":"72.4","isBolded":false,"associatedRows":["Stage - 2 ( % )"],"associatedColumns":["Baseline"],"associatedMergedColumns":[]},{"number":"74.0","isBolded":false,"associatedRows":["Stage - 3 ( % )"],"associatedColumns":["Baseline"],"associatedMergedColumns":[]},{"number":"78.7","isBolded":false,"associatedRows":["Stage - 3 ( % )"],"associatedColumns":["GCN"],"associatedMergedColumns":[]},{"number":"75.0","isBolded":false,"associatedRows":["Stage - 1 ( % )"],"associatedColumns":["GCN + BR"],"associatedMergedColumns":[]}]},{"caption":"Phase \nBaseline GCN GCN + BR \nStage-1(%) \n69.6 \n74.1 \n75.0 \nStage-2(%) \n72.4 \n77.6 \n78.6 \nStage-3(%) \n74.0 \n78.7 \n80.3 \nStage-3-MS(%) \n80.4 \nStage-3-MS-CRF(%) \n81.0 \n\nTable 7. Experimental results on PASCAL VOC 2012 validation \nset. The results are evaluated by standard mean IoU. \n\n","rows":["Stage - 3 - MS ( % )","Stage - 3 - MS - CRF ( % )","Stage - 1 ( % )","Stage - 3 ( % )","Stage - 2 ( % )"],"columns":["GCN","GCN + BR","Baseline"],"mergedAllColumns":[],"numberCells":[{"number":"74.0","isBolded":false,"associatedRows":["Stage - 3 ( % )"],"associatedColumns":["Baseline"],"associatedMergedColumns":[]},{"number":"74.1","isBolded":false,"associatedRows":["Stage - 1 ( % )"],"associatedColumns":["GCN"],"associatedMergedColumns":[]},{"number":"72.4","isBolded":false,"associatedRows":["Stage - 2 ( % )"],"associatedColumns":["Baseline"],"associatedMergedColumns":[]},{"number":"78.7","isBolded":false,"associatedRows":["Stage - 3 ( % )"],"associatedColumns":["GCN"],"associatedMergedColumns":[]},{"number":"75.0","isBolded":false,"associatedRows":["Stage - 1 ( % )"],"associatedColumns":["GCN + BR"],"associatedMergedColumns":[]},{"number":"78.6","isBolded":false,"associatedRows":["Stage - 2 ( % )"],"associatedColumns":["GCN + BR"],"associatedMergedColumns":[]},{"number":"77.6","isBolded":false,"associatedRows":["Stage - 2 ( % )"],"associatedColumns":["GCN"],"associatedMergedColumns":[]},{"number":"80.4","isBolded":false,"associatedRows":["Stage - 3 - MS ( % )"],"associatedColumns":["GCN + BR"],"associatedMergedColumns":[]},{"number":"69.6","isBolded":false,"associatedRows":["Stage - 1 ( % )"],"associatedColumns":["Baseline"],"associatedMergedColumns":[]},{"number":"81.0","isBolded":true,"associatedRows":["Stage - 3 - MS - CRF ( % )"],"associatedColumns":["GCN + BR"],"associatedMergedColumns":[]},{"number":"80.3","isBolded":false,"associatedRows":["Stage - 3 ( % )"],"associatedColumns":["GCN + BR"],"associatedMergedColumns":[]}]},{"caption":"Table 9. \n\n","rows":["Stage - 1 ( % )","Stage - 2 - MS - CRF ( % )","Stage - 2 - MS ( % )","Stage - 2 ( % )"],"columns":["GCN + BR"],"mergedAllColumns":[],"numberCells":[{"number":"73.0","isBolded":false,"associatedRows":["Stage - 1 ( % )"],"associatedColumns":["GCN + BR"],"associatedMergedColumns":[]},{"number":"77.2","isBolded":false,"associatedRows":["Stage - 2 - MS ( % )"],"associatedColumns":["GCN + BR"],"associatedMergedColumns":[]},{"number":"76.9","isBolded":false,"associatedRows":["Stage - 2 ( % )"],"associatedColumns":["GCN + BR"],"associatedMergedColumns":[]},{"number":"77.4","isBolded":true,"associatedRows":["Stage - 2 - MS - CRF ( % )"],"associatedColumns":["GCN + BR"],"associatedMergedColumns":[]}]},{"caption":"Phase \nGCN + BR \nStage-1(%) \n73.0 \nStage-2(%) \n76.9 \nStage-2-MS(%) \n77.2 \nStage-2-MS-CRF(%) \n77.4 \n\nTable 9. Experimental results on Cityscapes validation set. The \nstandard mean IoU is used here. \n\n","rows":["Stage - 1 ( % )","Stage - 2 - MS - CRF ( % )","Stage - 2 - MS ( % )","Stage - 2 ( % )"],"columns":["GCN + BR"],"mergedAllColumns":[],"numberCells":[{"number":"77.2","isBolded":false,"associatedRows":["Stage - 2 - MS ( % )"],"associatedColumns":["GCN + BR"],"associatedMergedColumns":[]},{"number":"77.4","isBolded":true,"associatedRows":["Stage - 2 - MS - CRF ( % )"],"associatedColumns":["GCN + BR"],"associatedMergedColumns":[]},{"number":"76.9","isBolded":false,"associatedRows":["Stage - 2 ( % )"],"associatedColumns":["GCN + BR"],"associatedMergedColumns":[]},{"number":"73.0","isBolded":false,"associatedRows":["Stage - 1 ( % )"],"associatedColumns":["GCN + BR"],"associatedMergedColumns":[]}]},{"caption":"Table 10. Once again, we outperforms all the previous \npublications and reaches the new state-of-art. \n\n","rows":["Stage - 1 ( % )","Stage - 2 - MS - CRF ( % )","Stage - 2 - MS ( % )","Stage - 2 ( % )"],"columns":["GCN + BR"],"mergedAllColumns":[],"numberCells":[{"number":"76.9","isBolded":false,"associatedRows":["Stage - 2 ( % )"],"associatedColumns":["GCN + BR"],"associatedMergedColumns":[]},{"number":"77.4","isBolded":true,"associatedRows":["Stage - 2 - MS - CRF ( % )"],"associatedColumns":["GCN + BR"],"associatedMergedColumns":[]},{"number":"73.0","isBolded":false,"associatedRows":["Stage - 1 ( % )"],"associatedColumns":["GCN + BR"],"associatedMergedColumns":[]},{"number":"77.2","isBolded":false,"associatedRows":["Stage - 2 - MS ( % )"],"associatedColumns":["GCN + BR"],"associatedMergedColumns":[]}]}]