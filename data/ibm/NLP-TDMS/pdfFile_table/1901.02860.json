[{"caption":"Table 1: Comparison with state-of-the-art results on WikiText-103. indicates contemporary work. \n\n","rows":["Bai et al . ( 2018 ) - TCN","Dauphin et al . ( 2016 ) - GCNN - 8","Dauphin et al . ( 2016 ) - GCNN - 14","Rae et al . ( 2018 ) - LSTM + Hebbian + Cache","Grave et al . ( 2016b ) - LSTM + Neural cache","Ours - Transformer - XL Standard","-","257M","247M","Grave et al . ( 2016b ) - LSTM","Baevski \u0026 Auli ( 2018 ) - adaptive input","Ours - Transformer - XL Large","151M","Merity et al . ( 2018 ) - 4 - layer QRNN"],"columns":["Validation PPL","Test PPL"],"mergedAllColumns":[],"numberCells":[{"number":"45.2","isBolded":false,"associatedRows":["Bai et al . ( 2018 ) - TCN","-","-"],"associatedColumns":["Test PPL"],"associatedMergedColumns":[]},{"number":"32.0","isBolded":false,"associatedRows":["Merity et al . ( 2018 ) - 4 - layer QRNN","151M"],"associatedColumns":["Validation PPL"],"associatedMergedColumns":[]},{"number":"48.7","isBolded":false,"associatedRows":["Grave et al . ( 2016b ) - LSTM","-","-"],"associatedColumns":["Test PPL"],"associatedMergedColumns":[]},{"number":"29.9","isBolded":false,"associatedRows":["Rae et al . ( 2018 ) - LSTM + Hebbian + Cache","-","-"],"associatedColumns":["Test PPL"],"associatedMergedColumns":[]},{"number":"24.0","isBolded":true,"associatedRows":["Ours - Transformer - XL Standard","151M","-"],"associatedColumns":["Test PPL"],"associatedMergedColumns":[]},{"number":"37.2","isBolded":false,"associatedRows":["Dauphin et al . ( 2016 ) - GCNN - 14","-","-"],"associatedColumns":["Test PPL"],"associatedMergedColumns":[]},{"number":"17.7","isBolded":true,"associatedRows":["Ours - Transformer - XL Large","257M"],"associatedColumns":["Validation PPL"],"associatedMergedColumns":[]},{"number":"40.8","isBolded":false,"associatedRows":["Grave et al . ( 2016b ) - LSTM + Neural cache","-","-"],"associatedColumns":["Test PPL"],"associatedMergedColumns":[]},{"number":"44.9","isBolded":false,"associatedRows":["Dauphin et al . ( 2016 ) - GCNN - 8","-","-"],"associatedColumns":["Test PPL"],"associatedMergedColumns":[]},{"number":"20.5","isBolded":false,"associatedRows":["Baevski \u0026 Auli ( 2018 ) - adaptive input","247M","-"],"associatedColumns":["Test PPL"],"associatedMergedColumns":[]},{"number":"33.0","isBolded":false,"associatedRows":["Merity et al . ( 2018 ) - 4 - layer QRNN","151M","-"],"associatedColumns":["Test PPL"],"associatedMergedColumns":[]},{"number":"18.3","isBolded":true,"associatedRows":["Ours - Transformer - XL Large","257M","-"],"associatedColumns":["Test PPL"],"associatedMergedColumns":[]},{"number":"29.7","isBolded":false,"associatedRows":["Rae et al . ( 2018 ) - LSTM + Hebbian + Cache","-"],"associatedColumns":["Validation PPL"],"associatedMergedColumns":[]},{"number":"19.8","isBolded":false,"associatedRows":["Baevski \u0026 Auli ( 2018 ) - adaptive input","247M"],"associatedColumns":["Validation PPL"],"associatedMergedColumns":[]},{"number":"23.1","isBolded":true,"associatedRows":["Ours - Transformer - XL Standard","151M"],"associatedColumns":["Validation PPL"],"associatedMergedColumns":[]}]},{"caption":"We apply Transformer-XL to a variety of datasets on both word-level and character-level language \nmodeling to have a comparison with state-of-the-art systems, including WikiText-103 (Merity et al., \n2016), enwiki8 (LLC, 2009), text8 (LLC, 2009), One Billion Word (Chelba et al., 2013), and Penn \nTreebank (Mikolov \u0026 Zweig, 2012). \n\nWikiText-103 is the largest available word-level language modeling benchmark with long-term de-\npendency. It contains 103M training tokens from 28K articles, with an average length of 3.6K tokens \nper article, which allows testing the ability of long-term dependency modeling. We set the attention \nlength to 384 during training and 1600 during evaluation. We adopted adaptive softmax and input \nrepresentations (Baevski \u0026 Auli, 2018; Grave et al., 2016a). As shown in Table 1, Transformer-XL \nreduces the previous SoTA perplexity from 20.5 to 18.3, which demonstrates the superiority of the \nTransformer-XL architecture. \n\nThe dataset enwiki8 contains 100M bytes of unprocessed Wikipedia text. We compare our architec-\nture with the previous results in Table 2. Under the model size constraint, the 12-layer Transformer-\nXL achieves a new SoTA result, outperforming the 12-layer vanilla Transformer from Al-Rfou et al. \n(2018) by 0.05, while both Transformer variants have a large margin over conventional RNN-based \nmodels. Notably, our 12-layer architecture achieves the same result as the 64-layer network from \nAl-Rfou et al. (2018), using only 17% of the parameter budget. In order to see whether better perfor-\nmances can be obtained by increasing the model size, we train 18-layer and 24-layer Transformer-\nXLs with increased model sizes. With the attention length 784 during training and 3,800 during \nevaluation, we obtained a new SoTA result and our method is the first to break through 1.0 on ","rows":["Bai et al . ( 2018 ) - TCN","Dauphin et al . ( 2016 ) - GCNN - 8","Dauphin et al . ( 2016 ) - GCNN - 14","Rae et al . ( 2018 ) - LSTM + Hebbian + Cache","Grave et al . ( 2016b ) - LSTM + Neural cache","Ours - Transformer - XL Standard","-","257M","247M","Grave et al . ( 2016b ) - LSTM","Baevski \u0026 Auli ( 2018 ) - adaptive input","Ours - Transformer - XL Large","151M","Merity et al . ( 2018 ) - 4 - layer QRNN"],"columns":["Validation PPL","Test PPL"],"mergedAllColumns":[],"numberCells":[{"number":"37.2","isBolded":false,"associatedRows":["Dauphin et al . ( 2016 ) - GCNN - 14","-","-"],"associatedColumns":["Test PPL"],"associatedMergedColumns":[]},{"number":"17.7","isBolded":true,"associatedRows":["Ours - Transformer - XL Large","257M"],"associatedColumns":["Validation PPL"],"associatedMergedColumns":[]},{"number":"20.5","isBolded":false,"associatedRows":["Baevski \u0026 Auli ( 2018 ) - adaptive input","247M","-"],"associatedColumns":["Test PPL"],"associatedMergedColumns":[]},{"number":"29.9","isBolded":false,"associatedRows":["Rae et al . ( 2018 ) - LSTM + Hebbian + Cache","-","-"],"associatedColumns":["Test PPL"],"associatedMergedColumns":[]},{"number":"18.3","isBolded":true,"associatedRows":["Ours - Transformer - XL Large","257M","-"],"associatedColumns":["Test PPL"],"associatedMergedColumns":[]},{"number":"48.7","isBolded":false,"associatedRows":["Grave et al . ( 2016b ) - LSTM","-","-"],"associatedColumns":["Test PPL"],"associatedMergedColumns":[]},{"number":"29.7","isBolded":false,"associatedRows":["Rae et al . ( 2018 ) - LSTM + Hebbian + Cache","-"],"associatedColumns":["Validation PPL"],"associatedMergedColumns":[]},{"number":"44.9","isBolded":false,"associatedRows":["Dauphin et al . ( 2016 ) - GCNN - 8","-","-"],"associatedColumns":["Test PPL"],"associatedMergedColumns":[]},{"number":"33.0","isBolded":false,"associatedRows":["Merity et al . ( 2018 ) - 4 - layer QRNN","151M","-"],"associatedColumns":["Test PPL"],"associatedMergedColumns":[]},{"number":"23.1","isBolded":true,"associatedRows":["Ours - Transformer - XL Standard","151M"],"associatedColumns":["Validation PPL"],"associatedMergedColumns":[]},{"number":"40.8","isBolded":false,"associatedRows":["Grave et al . ( 2016b ) - LSTM + Neural cache","-","-"],"associatedColumns":["Test PPL"],"associatedMergedColumns":[]},{"number":"19.8","isBolded":false,"associatedRows":["Baevski \u0026 Auli ( 2018 ) - adaptive input","247M"],"associatedColumns":["Validation PPL"],"associatedMergedColumns":[]},{"number":"24.0","isBolded":true,"associatedRows":["Ours - Transformer - XL Standard","151M","-"],"associatedColumns":["Test PPL"],"associatedMergedColumns":[]},{"number":"45.2","isBolded":false,"associatedRows":["Bai et al . ( 2018 ) - TCN","-","-"],"associatedColumns":["Test PPL"],"associatedMergedColumns":[]},{"number":"32.0","isBolded":false,"associatedRows":["Merity et al . ( 2018 ) - 4 - layer QRNN","151M"],"associatedColumns":["Validation PPL"],"associatedMergedColumns":[]}]},{"caption":"Table 2: Comparison with state-of-the-art results on enwiki8. \n\n","rows":["27M","Krause et al . ( 2016 ) - Large mLSTM","47M","35M","46M","277M","-","44M","88M","235M","Zilly et al . ( 2016 ) - Recurrent highway networks","41M","Ours - 18 - layer Transformer - XL","Al - Rfou et al . ( 2018 ) - 64 - layer Transformer","Mujika et al . ( 2017 ) - Large FS - LSTM - 4","Ours - 12 - layer Transformer - XL","Chung et al . ( 2016 ) - LN HM - LSTM","Ours - 24 - layer Transformer - XL","Ha et al . ( 2016 ) - LN HyperNetworks","Al - Rfou et al . ( 2018 ) - 12 - layer Transformer","Knol ( 2017 ) - cmix v13"],"columns":["Test bpc"],"mergedAllColumns":[],"numberCells":[{"number":"1.34","isBolded":false,"associatedRows":["Ha et al . ( 2016 ) - LN HyperNetworks","27M"],"associatedColumns":["Test bpc"],"associatedMergedColumns":[]},{"number":"1.27","isBolded":false,"associatedRows":["Zilly et al . ( 2016 ) - Recurrent highway networks","46M"],"associatedColumns":["Test bpc"],"associatedMergedColumns":[]},{"number":"1.25","isBolded":false,"associatedRows":["Mujika et al . ( 2017 ) - Large FS - LSTM - 4","47M"],"associatedColumns":["Test bpc"],"associatedMergedColumns":[]},{"number":"1.23","isBolded":false,"associatedRows":["Knol ( 2017 ) - cmix v13","-"],"associatedColumns":["Test bpc"],"associatedMergedColumns":[]},{"number":"0.99","isBolded":true,"associatedRows":["Ours - 24 - layer Transformer - XL","277M"],"associatedColumns":["Test bpc"],"associatedMergedColumns":[]},{"number":"1.24","isBolded":false,"associatedRows":["Krause et al . ( 2016 ) - Large mLSTM","46M"],"associatedColumns":["Test bpc"],"associatedMergedColumns":[]},{"number":"1.03","isBolded":false,"associatedRows":["Ours - 18 - layer Transformer - XL","88M"],"associatedColumns":["Test bpc"],"associatedMergedColumns":[]},{"number":"1.06","isBolded":false,"associatedRows":["Al - Rfou et al . ( 2018 ) - 64 - layer Transformer","235M"],"associatedColumns":["Test bpc"],"associatedMergedColumns":[]},{"number":"1.11","isBolded":false,"associatedRows":["Al - Rfou et al . ( 2018 ) - 12 - layer Transformer","44M"],"associatedColumns":["Test bpc"],"associatedMergedColumns":[]},{"number":"1.06","isBolded":true,"associatedRows":["Ours - 12 - layer Transformer - XL","41M"],"associatedColumns":["Test bpc"],"associatedMergedColumns":[]},{"number":"1.32","isBolded":false,"associatedRows":["Chung et al . ( 2016 ) - LN HM - LSTM","35M"],"associatedColumns":["Test bpc"],"associatedMergedColumns":[]}]},{"caption":"Table 4: Comparison with state-of-the-art results on One Billion Word. indicates contemporary work. \n\n","rows":["Shazeer et al . ( 2017 ) - High - Budget MoE","33B","20B","Shazeer et al . ( 2017 ) - Low - Budget MoE","Kuchaiev \u0026 Ginsburg ( 2017 ) - BIG G - LSTM - 2","∼5B","Jozefowicz et al . ( 2016 ) - LSTM - 8192 - 1024 + CNN Input","Shazeer et al . ( 2014 ) - Sparse Non - Negative","-","Jozefowicz et al . ( 2016 ) - LSTM - 8192 - 1024","Ours - Transformer - XL Base","Shazeer et al . ( 2018 ) - Mesh Tensorflow","Chelba et al . ( 2013 ) - RNN - 1024 + 9 Gram","Ours - Transformer - XL Large","Jozefowicz et al . ( 2016 ) - LSTM - 2048 - 512","Dauphin et al . ( 2016 ) - GCNN - 14 bottleneck","Baevski \u0026 Auli ( 2018 ) - Adaptive Input Large","Baevski \u0026 Auli ( 2018 ) - Adaptive Input Very Large"],"columns":["#Params","PPL"],"mergedAllColumns":[],"numberCells":[{"number":"36.0","isBolded":false,"associatedRows":["Kuchaiev \u0026 Ginsburg ( 2017 ) - BIG G - LSTM - 2","-"],"associatedColumns":["PPL"],"associatedMergedColumns":[]},{"number":"4.9B","isBolded":false,"associatedRows":["Shazeer et al . ( 2018 ) - Mesh Tensorflow"],"associatedColumns":["#Params"],"associatedMergedColumns":[]},{"number":"21.8","isBolded":true,"associatedRows":["Ours - Transformer - XL Large","∼5B"],"associatedColumns":["PPL"],"associatedMergedColumns":[]},{"number":"23.7","isBolded":false,"associatedRows":["Baevski \u0026 Auli ( 2018 ) - Adaptive Input Very Large","∼5B"],"associatedColumns":["PPL"],"associatedMergedColumns":[]},{"number":"52.9","isBolded":false,"associatedRows":["Shazeer et al . ( 2014 ) - Sparse Non - Negative","33B"],"associatedColumns":["PPL"],"associatedMergedColumns":[]},{"number":"0.46B","isBolded":false,"associatedRows":["Baevski \u0026 Auli ( 2018 ) - Adaptive Input Large"],"associatedColumns":["#Params"],"associatedMergedColumns":[]},{"number":"0.83B","isBolded":false,"associatedRows":["Jozefowicz et al . ( 2016 ) - LSTM - 2048 - 512"],"associatedColumns":["#Params"],"associatedMergedColumns":[]},{"number":"0.8B","isBolded":false,"associatedRows":["Ours - Transformer - XL Large"],"associatedColumns":["#Params"],"associatedMergedColumns":[]},{"number":"31.9","isBolded":false,"associatedRows":["Dauphin et al . ( 2016 ) - GCNN - 14 bottleneck","-"],"associatedColumns":["PPL"],"associatedMergedColumns":[]},{"number":"1.04B","isBolded":false,"associatedRows":["Jozefowicz et al . ( 2016 ) - LSTM - 8192 - 1024 + CNN Input"],"associatedColumns":["#Params"],"associatedMergedColumns":[]},{"number":"30.0","isBolded":false,"associatedRows":["Jozefowicz et al . ( 2016 ) - LSTM - 8192 - 1024 + CNN Input","∼5B"],"associatedColumns":["PPL"],"associatedMergedColumns":[]},{"number":"43.7","isBolded":false,"associatedRows":["Jozefowicz et al . ( 2016 ) - LSTM - 2048 - 512","20B"],"associatedColumns":["PPL"],"associatedMergedColumns":[]},{"number":"34.1","isBolded":false,"associatedRows":["Shazeer et al . ( 2017 ) - Low - Budget MoE","∼5B"],"associatedColumns":["PPL"],"associatedMergedColumns":[]},{"number":"30.6","isBolded":false,"associatedRows":["Jozefowicz et al . ( 2016 ) - LSTM - 8192 - 1024","∼5B"],"associatedColumns":["PPL"],"associatedMergedColumns":[]},{"number":"28.0","isBolded":false,"associatedRows":["Shazeer et al . ( 2017 ) - High - Budget MoE","∼5B"],"associatedColumns":["PPL"],"associatedMergedColumns":[]},{"number":"51.3","isBolded":false,"associatedRows":["Chelba et al . ( 2013 ) - RNN - 1024 + 9 Gram","20B"],"associatedColumns":["PPL"],"associatedMergedColumns":[]},{"number":"1.8B","isBolded":false,"associatedRows":["Jozefowicz et al . ( 2016 ) - LSTM - 8192 - 1024"],"associatedColumns":["#Params"],"associatedMergedColumns":[]},{"number":"24.1","isBolded":false,"associatedRows":["Baevski \u0026 Auli ( 2018 ) - Adaptive Input Large","∼5B"],"associatedColumns":["PPL"],"associatedMergedColumns":[]},{"number":"1.0B","isBolded":false,"associatedRows":["Baevski \u0026 Auli ( 2018 ) - Adaptive Input Very Large"],"associatedColumns":["#Params"],"associatedMergedColumns":[]},{"number":"0.46B","isBolded":false,"associatedRows":["Ours - Transformer - XL Base"],"associatedColumns":["#Params"],"associatedMergedColumns":[]},{"number":"24.0","isBolded":false,"associatedRows":["Shazeer et al . ( 2018 ) - Mesh Tensorflow","∼5B"],"associatedColumns":["PPL"],"associatedMergedColumns":[]},{"number":"23.5","isBolded":false,"associatedRows":["Ours - Transformer - XL Base","∼5B"],"associatedColumns":["PPL"],"associatedMergedColumns":[]}]},{"caption":"Table 5: Comparison with state-of-the-art results on Penn Treebank.  † indicates using two-step finetuning. \n\n","rows":["Inan et al . ( 2016 ) - Tied Variational LSTM + augmented loss","Yang et al . ( 2017 ) - AWD - LSTM - MoS","Zilly et al . ( 2016 ) - Variational RHN","Pham et al . ( 2018 ) - Efficient NAS","Liu et al . ( 2018 ) - Differentiable NAS","25M","24M","23M","Zoph \u0026 Le ( 2016 ) - NAS Cell","-","Merity et al . ( 2017 ) - AWD - LSTM","22M","Melis et al . ( 2018 ) - 2 - layer skip - LSTM + dropout tuning","Ours - Transformer - XL","Yang et al . ( 2017 ) - AWD - LSTM - MoS + finetuning †","Merity et al . ( 2017 ) - AWD - LSTM + finetuning †"],"columns":["Test PPL","Dev PPL"],"mergedAllColumns":[],"numberCells":[{"number":"60.8","isBolded":false,"associatedRows":["Pham et al . ( 2018 ) - Efficient NAS","24M"],"associatedColumns":["Dev PPL"],"associatedMergedColumns":[]},{"number":"58.3","isBolded":false,"associatedRows":["Liu et al . ( 2018 ) - Differentiable NAS","23M"],"associatedColumns":["Dev PPL"],"associatedMergedColumns":[]},{"number":"54.52","isBolded":true,"associatedRows":["Ours - Transformer - XL","24M"],"associatedColumns":["Test PPL"],"associatedMergedColumns":[]},{"number":"57.1","isBolded":false,"associatedRows":["Melis et al . ( 2018 ) - 2 - layer skip - LSTM + dropout tuning","24M"],"associatedColumns":["Dev PPL"],"associatedMergedColumns":[]},{"number":"54.44","isBolded":true,"associatedRows":["Yang et al . ( 2017 ) - AWD - LSTM - MoS + finetuning †","22M"],"associatedColumns":["Test PPL"],"associatedMergedColumns":[]},{"number":"56.54","isBolded":true,"associatedRows":["Yang et al . ( 2017 ) - AWD - LSTM - MoS + finetuning †","22M"],"associatedColumns":["Dev PPL"],"associatedMergedColumns":[]},{"number":"58.6","isBolded":false,"associatedRows":["Pham et al . ( 2018 ) - Efficient NAS","24M"],"associatedColumns":["Test PPL"],"associatedMergedColumns":[]},{"number":"67.9","isBolded":false,"associatedRows":["Zilly et al . ( 2016 ) - Variational RHN","23M"],"associatedColumns":["Dev PPL"],"associatedMergedColumns":[]},{"number":"65.4","isBolded":false,"associatedRows":["Zilly et al . ( 2016 ) - Variational RHN","23M"],"associatedColumns":["Test PPL"],"associatedMergedColumns":[]},{"number":"56.1","isBolded":false,"associatedRows":["Liu et al . ( 2018 ) - Differentiable NAS","23M"],"associatedColumns":["Test PPL"],"associatedMergedColumns":[]},{"number":"60.7","isBolded":false,"associatedRows":["Merity et al . ( 2017 ) - AWD - LSTM","24M"],"associatedColumns":["Dev PPL"],"associatedMergedColumns":[]},{"number":"64.0","isBolded":false,"associatedRows":["Zoph \u0026 Le ( 2016 ) - NAS Cell","25M","-"],"associatedColumns":["Test PPL"],"associatedMergedColumns":[]},{"number":"55.3","isBolded":false,"associatedRows":["Melis et al . ( 2018 ) - 2 - layer skip - LSTM + dropout tuning","24M"],"associatedColumns":["Test PPL"],"associatedMergedColumns":[]},{"number":"75.7","isBolded":false,"associatedRows":["Inan et al . ( 2016 ) - Tied Variational LSTM + augmented loss","24M"],"associatedColumns":["Dev PPL"],"associatedMergedColumns":[]},{"number":"73.2","isBolded":false,"associatedRows":["Inan et al . ( 2016 ) - Tied Variational LSTM + augmented loss","24M"],"associatedColumns":["Test PPL"],"associatedMergedColumns":[]},{"number":"55.97","isBolded":false,"associatedRows":["Yang et al . ( 2017 ) - AWD - LSTM - MoS","22M"],"associatedColumns":["Test PPL"],"associatedMergedColumns":[]},{"number":"58.08","isBolded":false,"associatedRows":["Yang et al . ( 2017 ) - AWD - LSTM - MoS","22M"],"associatedColumns":["Dev PPL"],"associatedMergedColumns":[]},{"number":"60.0","isBolded":false,"associatedRows":["Merity et al . ( 2017 ) - AWD - LSTM + finetuning †","24M"],"associatedColumns":["Dev PPL"],"associatedMergedColumns":[]},{"number":"57.3","isBolded":false,"associatedRows":["Merity et al . ( 2017 ) - AWD - LSTM + finetuning †","24M"],"associatedColumns":["Test PPL"],"associatedMergedColumns":[]},{"number":"58.8","isBolded":false,"associatedRows":["Merity et al . ( 2017 ) - AWD - LSTM","24M"],"associatedColumns":["Test PPL"],"associatedMergedColumns":[]},{"number":"56.72","isBolded":true,"associatedRows":["Ours - Transformer - XL","24M"],"associatedColumns":["Dev PPL"],"associatedMergedColumns":[]}]},{"caption":"Table 6: Ablation study on WikiText-103. For the first two blocks, we use a slightly smaller model (128M pa-\n\nrameters).  † indicates that the corresponding row is reduced to the same setting as the Transformer network in \nAl-Rfou et al. ","rows":["Transformer - XL ( 128M )","Half","Ours","Shaw et al . ( 2018 )","Vaswani et al . ( 2017 )","Transformer ( 128M ) †","Al - Rfou et al . ( 2018 )","Transformer - XL ( 151M )","-","Full"],"columns":["PPL init","PPL best"],"mergedAllColumns":["640","256","500","260","460","120","450"],"numberCells":[{"number":"27.02","isBolded":true,"associatedRows":["Transformer - XL ( 128M )","Ours","Full"],"associatedColumns":["PPL init"],"associatedMergedColumns":[]},{"number":"30.50","isBolded":false,"associatedRows":["-","Shaw et al . ( 2018 )","Half"],"associatedColumns":["PPL best"],"associatedMergedColumns":["120"]},{"number":"31.16","isBolded":false,"associatedRows":["Transformer ( 128M ) †","Al - Rfou et al . ( 2018 )","Half"],"associatedColumns":["PPL best"],"associatedMergedColumns":["120"]},{"number":"26.77","isBolded":true,"associatedRows":["Transformer - XL ( 128M )","Ours","Full"],"associatedColumns":["PPL best"],"associatedMergedColumns":[]},{"number":"23.09","isBolded":true,"associatedRows":["Transformer - XL ( 151M )","Al - Rfou et al . ( 2018 )","Half"],"associatedColumns":["PPL best"],"associatedMergedColumns":["120"]},{"number":"29.59","isBolded":false,"associatedRows":["-","Ours","Full"],"associatedColumns":["PPL init"],"associatedMergedColumns":["460"]},{"number":"29.02","isBolded":false,"associatedRows":["-","Ours","Full"],"associatedColumns":["PPL best"],"associatedMergedColumns":["460"]},{"number":"30.10","isBolded":false,"associatedRows":["-","Ours","Half"],"associatedColumns":["PPL best"],"associatedMergedColumns":["260"]},{"number":"23.43","isBolded":false,"associatedRows":["Transformer - XL ( 151M )","Ours","Full"],"associatedColumns":["PPL init"],"associatedMergedColumns":["640"]},{"number":"28.69","isBolded":false,"associatedRows":["-","Ours","Half"],"associatedColumns":["PPL init"],"associatedMergedColumns":["256"]},{"number":"29.75","isBolded":false,"associatedRows":["-","Shaw et al . ( 2018 )","Full"],"associatedColumns":["PPL best"],"associatedMergedColumns":["120"]},{"number":"23.35","isBolded":false,"associatedRows":["Transformer - XL ( 151M )","Al - Rfou et al . ( 2018 )","Full"],"associatedColumns":["PPL best"],"associatedMergedColumns":["450"]},{"number":"30.97","isBolded":false,"associatedRows":["-","Vaswani et al . ( 2017 )","Half"],"associatedColumns":["PPL init"],"associatedMergedColumns":["120"]},{"number":"27.94","isBolded":false,"associatedRows":["-","Shaw et al . ( 2018 )","Full"],"associatedColumns":["PPL init"],"associatedMergedColumns":["500"]},{"number":"23.16","isBolded":false,"associatedRows":["Transformer - XL ( 151M )","Ours","Full"],"associatedColumns":["PPL best"],"associatedMergedColumns":["640"]},{"number":"27.94","isBolded":false,"associatedRows":["-","Shaw et al . ( 2018 )","Full"],"associatedColumns":["PPL best"],"associatedMergedColumns":["500"]},{"number":"30.97","isBolded":false,"associatedRows":["-","Vaswani et al . ( 2017 )","Half"],"associatedColumns":["PPL best"],"associatedMergedColumns":["120"]},{"number":"30.10","isBolded":false,"associatedRows":["-","Ours","Half"],"associatedColumns":["PPL init"],"associatedMergedColumns":["260"]},{"number":"28.33","isBolded":false,"associatedRows":["-","Ours","Half"],"associatedColumns":["PPL best"],"associatedMergedColumns":["256"]},{"number":"29.75","isBolded":false,"associatedRows":["-","Shaw et al . ( 2018 )","Full"],"associatedColumns":["PPL init"],"associatedMergedColumns":["120"]},{"number":"30.50","isBolded":false,"associatedRows":["-","Shaw et al . ( 2018 )","Half"],"associatedColumns":["PPL init"],"associatedMergedColumns":["120"]},{"number":"31.16","isBolded":false,"associatedRows":["Transformer ( 128M ) †","Al - Rfou et al . ( 2018 )","Half"],"associatedColumns":["PPL init"],"associatedMergedColumns":["120"]}]},{"caption":"Table 8: Relative effective context length (RECL) comparison. See text for the definition of RECL and r. The \n\nfirst three models and the last four models are compared as two model groups when we calculate RECL (RECL \nis computed on a model group rather than a single model). Each group has the same parameter budget. \n\n","rows":["- use Shaw et al . ( 2018 ) encoding","- remove recurrence","LSTM","Transformer","Transformer - XL 151M","QRNN","Transformer - XL 128M"],"columns":["Model"],"mergedAllColumns":[],"numberCells":[{"number":"128","isBolded":false,"associatedRows":["Transformer"],"associatedColumns":["Model"],"associatedMergedColumns":[]},{"number":"300","isBolded":false,"associatedRows":["LSTM"],"associatedColumns":["Model"],"associatedMergedColumns":[]},{"number":"700","isBolded":true,"associatedRows":["Transformer - XL 128M"],"associatedColumns":["Model"],"associatedMergedColumns":[]},{"number":"500","isBolded":true,"associatedRows":["Transformer - XL 128M"],"associatedColumns":["Model"],"associatedMergedColumns":[]},{"number":"300","isBolded":false,"associatedRows":["- use Shaw et al . ( 2018 ) encoding"],"associatedColumns":["Model"],"associatedMergedColumns":[]},{"number":"400","isBolded":false,"associatedRows":["- use Shaw et al . ( 2018 ) encoding"],"associatedColumns":["Model"],"associatedMergedColumns":[]},{"number":"700","isBolded":true,"associatedRows":["Transformer - XL 151M"],"associatedColumns":["Model"],"associatedMergedColumns":[]},{"number":"400","isBolded":false,"associatedRows":["- use Shaw et al . ( 2018 ) encoding"],"associatedColumns":["Model"],"associatedMergedColumns":[]},{"number":"128","isBolded":false,"associatedRows":["Transformer"],"associatedColumns":["Model"],"associatedMergedColumns":[]},{"number":"300","isBolded":false,"associatedRows":["- remove recurrence"],"associatedColumns":["Model"],"associatedMergedColumns":[]},{"number":"200","isBolded":false,"associatedRows":["LSTM"],"associatedColumns":["Model"],"associatedMergedColumns":[]},{"number":"500","isBolded":false,"associatedRows":["QRNN"],"associatedColumns":["Model"],"associatedMergedColumns":[]},{"number":"300","isBolded":false,"associatedRows":["- remove recurrence"],"associatedColumns":["Model"],"associatedMergedColumns":[]},{"number":"300","isBolded":false,"associatedRows":["- remove recurrence"],"associatedColumns":["Model"],"associatedMergedColumns":[]},{"number":"800","isBolded":true,"associatedRows":["Transformer - XL 151M"],"associatedColumns":["Model"],"associatedMergedColumns":[]},{"number":"300","isBolded":false,"associatedRows":["QRNN"],"associatedColumns":["Model"],"associatedMergedColumns":[]},{"number":"400","isBolded":false,"associatedRows":["LSTM"],"associatedColumns":["Model"],"associatedMergedColumns":[]},{"number":"900","isBolded":true,"associatedRows":["Transformer - XL 151M"],"associatedColumns":["Model"],"associatedMergedColumns":[]},{"number":"128","isBolded":false,"associatedRows":["Transformer"],"associatedColumns":["Model"],"associatedMergedColumns":[]},{"number":"400","isBolded":false,"associatedRows":["QRNN"],"associatedColumns":["Model"],"associatedMergedColumns":[]},{"number":"600","isBolded":true,"associatedRows":["Transformer - XL 128M"],"associatedColumns":["Model"],"associatedMergedColumns":[]}]},{"caption":"Table 9: Slowdown in terms of computational time during evaluation. Evaluation is based on per-token time \n\non one GPU. \n\n","rows":[],"columns":["1 , 800","3 , 800","2 , 800","Attn Len"],"mergedAllColumns":[],"numberCells":[{"number":"800","isBolded":false,"associatedRows":[],"associatedColumns":["Attn Len","3 , 800","2 , 800","1 , 800"],"associatedMergedColumns":[]}]},{"caption":"Table 10: Ablation study on WikiText-103 with the same GPU memory constraints. \n\n","rows":["176","Ours","Partial","128","172","Full"],"columns":["pplx best","pplx init"],"mergedAllColumns":["400","500","460"],"numberCells":[{"number":"27.98","isBolded":false,"associatedRows":["176","Ours","Full"],"associatedColumns":["pplx best"],"associatedMergedColumns":["460"]},{"number":"28.69","isBolded":false,"associatedRows":["128","Ours","Partial"],"associatedColumns":["pplx init"],"associatedMergedColumns":["500"]},{"number":"28.33","isBolded":false,"associatedRows":["128","Ours","Partial"],"associatedColumns":["pplx best"],"associatedMergedColumns":["500"]},{"number":"28.83","isBolded":false,"associatedRows":["172","Ours","Partial"],"associatedColumns":["pplx best"],"associatedMergedColumns":["400"]},{"number":"26.77","isBolded":true,"associatedRows":["128","Ours","Full"],"associatedColumns":["pplx best"],"associatedMergedColumns":[]},{"number":"28.83","isBolded":false,"associatedRows":["172","Ours","Partial"],"associatedColumns":["pplx init"],"associatedMergedColumns":["400"]},{"number":"27.02","isBolded":true,"associatedRows":["128","Ours","Full"],"associatedColumns":["pplx init"],"associatedMergedColumns":[]},{"number":"28.43","isBolded":false,"associatedRows":["176","Ours","Full"],"associatedColumns":["pplx init"],"associatedMergedColumns":["460"]}]}]