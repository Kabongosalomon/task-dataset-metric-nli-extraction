[{"caption":"left) shows CIFAR-10 samples generated \n\nModel \nNLL Test \n\nDBM 2hl [1]: \n≈ 84.62 \nDBN 2hl [2]: \n≈ 84.55 \nNADE [3]: \n88.33 \nEoNADE 2hl (128 orderings) [3]: \n85.10 \nEoNADE-5 2hl (128 orderings) [4]: \n84.68 \nDLGM [5]: \n≈ 86.60 \nDLGM 8 leapfrog steps [6]: \n≈ 85.51 \nDARN 1hl [7]: \n≈ 84.13 \nMADE 2hl (32 masks) [8]: \n86.64 \nDRAW [9]: \n≤ 80.97 \n\nPixelCNN: \n81.30 \nRow LSTM: \n80.54 \nDiagonal BiLSTM (1 layer, h \u003d 32): \n80.75 \nDiagonal BiLSTM (7 layers, h \u003d 16): \n79.20 \n\nTable 4. Test set performance of different models on MNIST \nin nats (negative log-likelihood). Prior results taken from [1] \n(Salakhutdinov \u0026 Hinton, 2009), [2] (Murray \u0026 Salakhutdinov, \n2009), [3] (Uria et al., 2014), [4] (Raiko et al., 2014), [5] (Rezende \net al., 2014), [6] (Salimans et al., 2015), [7] (Gregor et al., 2014), \n[8] ","rows":["≤","Diagonal BiLSTM ( 7 layers , h \u003d 16 ) :","DBM 2hl [ 1 ] :","NADE [ 3 ] :","≈","Diagonal BiLSTM ( 1 layer , h \u003d 32 ) :","DRAW [ 9 ] :","DLGM [ 5 ] :","Row LSTM :","PixelCNN :","DBN 2hl [ 2 ] :","EoNADE 2hl ( 128 orderings ) [ 3 ] :","EoNADE - 5 2hl ( 128 orderings ) [ 4 ] :","DLGM 8 leapfrog steps [ 6 ] :","MADE 2hl ( 32 masks ) [ 8 ] :","DARN 1hl [ 7 ] :"],"columns":["NLL Test"],"mergedAllColumns":[],"numberCells":[{"number":"85.10","isBolded":false,"associatedRows":["EoNADE 2hl ( 128 orderings ) [ 3 ] :"],"associatedColumns":["NLL Test"],"associatedMergedColumns":[]},{"number":"85.51","isBolded":false,"associatedRows":["DLGM 8 leapfrog steps [ 6 ] :","≈"],"associatedColumns":["NLL Test"],"associatedMergedColumns":[]},{"number":"86.64","isBolded":false,"associatedRows":["MADE 2hl ( 32 masks ) [ 8 ] :"],"associatedColumns":["NLL Test"],"associatedMergedColumns":[]},{"number":"84.13","isBolded":false,"associatedRows":["DARN 1hl [ 7 ] :","≈"],"associatedColumns":["NLL Test"],"associatedMergedColumns":[]},{"number":"80.97","isBolded":false,"associatedRows":["DRAW [ 9 ] :","≤"],"associatedColumns":["NLL Test"],"associatedMergedColumns":[]},{"number":"79.20","isBolded":true,"associatedRows":["Diagonal BiLSTM ( 7 layers , h \u003d 16 ) :"],"associatedColumns":["NLL Test"],"associatedMergedColumns":[]},{"number":"84.55","isBolded":false,"associatedRows":["DBN 2hl [ 2 ] :","≈"],"associatedColumns":["NLL Test"],"associatedMergedColumns":[]},{"number":"84.62","isBolded":false,"associatedRows":["DBM 2hl [ 1 ] :","≈"],"associatedColumns":["NLL Test"],"associatedMergedColumns":[]},{"number":"80.75","isBolded":true,"associatedRows":["Diagonal BiLSTM ( 1 layer , h \u003d 32 ) :"],"associatedColumns":["NLL Test"],"associatedMergedColumns":[]},{"number":"86.60","isBolded":false,"associatedRows":["DLGM [ 5 ] :","≈"],"associatedColumns":["NLL Test"],"associatedMergedColumns":[]},{"number":"88.33","isBolded":false,"associatedRows":["NADE [ 3 ] :"],"associatedColumns":["NLL Test"],"associatedMergedColumns":[]},{"number":"81.30","isBolded":false,"associatedRows":["PixelCNN :"],"associatedColumns":["NLL Test"],"associatedMergedColumns":[]},{"number":"80.54","isBolded":false,"associatedRows":["Row LSTM :"],"associatedColumns":["NLL Test"],"associatedMergedColumns":[]},{"number":"84.68","isBolded":false,"associatedRows":["EoNADE - 5 2hl ( 128 orderings ) [ 4 ] :"],"associatedColumns":["NLL Test"],"associatedMergedColumns":[]}]},{"caption":"Figure 8. Samples from models trained on ImageNet 64x64 images. Left: normal model, right: multi-scale model. The single-scale \nmodel trained on 64x64 images is less able to capture global structure than the 32x32 model. The multi-scale model seems to resolve \nthis problem. Although these models get similar performance in log-likelihood, the samples on the right do seem globally more coherent. \n\nModel \nNLL Test (Train) \n\nUniform Distribution: \n8.00 \nMultivariate Gaussian: \n4.70 \nNICE [1]: \n4.48 \nDeep Diffusion [2]: \n4.20 \nDeep GMMs [3]: \n4.00 \nRIDE [4]: \n3.47 \n\nPixelCNN: \n3.14 (3.08) \nRow LSTM: \n3.07 (3.00) \nDiagonal BiLSTM: \n3.00 (2.93) \n\nTable 5. Test set performance of different models on CIFAR-10 in \nbits/dim. For our models we give training performance in brack-\nets. [1] (Dinh et al., 2014), [2] (Sohl-Dickstein et al., 2015), [3] \n(van den Oord \u0026 Schrauwen, 2014a), [4] personal communication \n(Theis \u0026 Bethge, 2015). \n\n","rows":["PixelCNN :","Diagonal BiLSTM :","Uniform Distribution :","Deep Diffusion [ 2 ] :","RIDE [ 4 ] :","Deep GMMs [ 3 ] :","NICE [ 1 ] :","Row LSTM :","Multivariate Gaussian :"],"columns":["Figure 8 . Samples from models trained on ImageNet 64x64 images . Left : normal model , right : multi - scale model . The single - scale","NLL Test ( Train )"],"mergedAllColumns":["this problem . Although these models get similar performance in log - likelihood , the samples on the right do seem globally more coherent ."],"numberCells":[{"number":"3.14(3.08)","isBolded":false,"associatedRows":["PixelCNN :"],"associatedColumns":["Figure 8 . Samples from models trained on ImageNet 64x64 images . Left : normal model , right : multi - scale model . The single - scale","NLL Test ( Train )"],"associatedMergedColumns":["this problem . Although these models get similar performance in log - likelihood , the samples on the right do seem globally more coherent ."]},{"number":"4.00","isBolded":false,"associatedRows":["Deep GMMs [ 3 ] :"],"associatedColumns":["Figure 8 . Samples from models trained on ImageNet 64x64 images . Left : normal model , right : multi - scale model . The single - scale","NLL Test ( Train )"],"associatedMergedColumns":["this problem . Although these models get similar performance in log - likelihood , the samples on the right do seem globally more coherent ."]},{"number":"3.07(3.00)","isBolded":false,"associatedRows":["Row LSTM :"],"associatedColumns":["Figure 8 . Samples from models trained on ImageNet 64x64 images . Left : normal model , right : multi - scale model . The single - scale","NLL Test ( Train )"],"associatedMergedColumns":["this problem . Although these models get similar performance in log - likelihood , the samples on the right do seem globally more coherent ."]},{"number":"4.70","isBolded":false,"associatedRows":["Multivariate Gaussian :"],"associatedColumns":["Figure 8 . Samples from models trained on ImageNet 64x64 images . Left : normal model , right : multi - scale model . The single - scale","NLL Test ( Train )"],"associatedMergedColumns":["this problem . Although these models get similar performance in log - likelihood , the samples on the right do seem globally more coherent ."]},{"number":"4.20","isBolded":false,"associatedRows":["Deep Diffusion [ 2 ] :"],"associatedColumns":["Figure 8 . Samples from models trained on ImageNet 64x64 images . Left : normal model , right : multi - scale model . The single - scale","NLL Test ( Train )"],"associatedMergedColumns":["this problem . Although these models get similar performance in log - likelihood , the samples on the right do seem globally more coherent ."]},{"number":"3.00(2.93)","isBolded":true,"associatedRows":["Diagonal BiLSTM :"],"associatedColumns":["Figure 8 . Samples from models trained on ImageNet 64x64 images . Left : normal model , right : multi - scale model . The single - scale","NLL Test ( Train )"],"associatedMergedColumns":["this problem . Although these models get similar performance in log - likelihood , the samples on the right do seem globally more coherent ."]},{"number":"8.00","isBolded":false,"associatedRows":["Uniform Distribution :"],"associatedColumns":["Figure 8 . Samples from models trained on ImageNet 64x64 images . Left : normal model , right : multi - scale model . The single - scale","NLL Test ( Train )"],"associatedMergedColumns":["this problem . Although these models get similar performance in log - likelihood , the samples on the right do seem globally more coherent ."]},{"number":"3.47","isBolded":false,"associatedRows":["RIDE [ 4 ] :"],"associatedColumns":["Figure 8 . Samples from models trained on ImageNet 64x64 images . Left : normal model , right : multi - scale model . The single - scale","NLL Test ( Train )"],"associatedMergedColumns":["this problem . Although these models get similar performance in log - likelihood , the samples on the right do seem globally more coherent ."]},{"number":"4.48","isBolded":false,"associatedRows":["NICE [ 1 ] :"],"associatedColumns":["Figure 8 . Samples from models trained on ImageNet 64x64 images . Left : normal model , right : multi - scale model . The single - scale","NLL Test ( Train )"],"associatedMergedColumns":["this problem . Although these models get similar performance in log - likelihood , the samples on the right do seem globally more coherent ."]}]}]