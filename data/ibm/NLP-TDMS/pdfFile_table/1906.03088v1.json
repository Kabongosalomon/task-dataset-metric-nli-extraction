[{"caption":"Table 2: Comparison of the datasets used for evaluation \n\nTACRED: The TAC Relation E xtraction Dataset [Zhang et al., 2017] contains 106k \nsentences with entity mention pairs collected from the TAC KBP evaluations 5 2009-2014, \nwith the years 2009 to 2012 used for training, 2013 for evaluation, and 2014 for testing. \nSentences are annotated with person-and organization-oriented relation types, e.g. per:title, \norg:founded, and no relation for negative examples. In contrast to the SemEval dataset the \nentity mentions are typed, with subjects classified into person and organization, and objects \ncategorized into 16 fine-grained classes (e.g., date, location, title). As per convention, we \nreport our results as micro-averaged F1 scores. Following the evaluation strategy of Zhang  et al. [2017], we select our best model based on the median validation F1 score over 5 \nindependent runs and report its performance on the test set. \nSemEval 2010 Task 8: The SemEval 2010 Task 8 dataset [Hendrickx et al., 2010] is \na standard benchmark for binary relation classification, and contains 8,000 sentences for \ntraining, and 2,717 for testing. Sentences are annotated with a pair of untyped nominals \nand one of 9 directed semantic relation types, such as Cause-Effect, Entity-Origin, as well \nas the undirected Other type to indicate no relation, resulting in 19 distinct types in total. \n","rows":["TACRED","Task","8 :","10 , 717","approximately 10x the size of SemEval","SemEval","19","106 , 264","with the years","The SemEval","42"],"columns":["al . ,","106k","categorized into 16 fine - grained classes ( e . g . , date , location , title ) .","Dataset","Table 2 shows key statistics of the TACRED and SemEval datasets .","The","negative examples","[ 2017 ] ,","contains","examples","E xtraction","5","TAC","relation types","As per convention , we","While TACRED is"],"mergedAllColumns":["independent runs and report its performance on the test set .","negative training examples , which makes classification more challenging .","sentences with entity mention pairs collected from the TAC KBP evaluations 5 2009 - 2014 ,"],"numberCells":[{"number":"2010Task8,itcontainsamuchhigherfractionof","isBolded":false,"associatedRows":["approximately 10x the size of SemEval"],"associatedColumns":["While TACRED is"],"associatedMergedColumns":[]},{"number":"2009to","isBolded":false,"associatedRows":["with the years"],"associatedColumns":["Table 2 shows key statistics of the TACRED and SemEval datasets .","Dataset","TAC"],"associatedMergedColumns":["sentences with entity mention pairs collected from the TAC KBP evaluations 5 2009 - 2014 ,"]},{"number":"2014fortesting.","isBolded":false,"associatedRows":["with the years","19","10 , 717"],"associatedColumns":["While TACRED is","negative examples","106k"],"associatedMergedColumns":["sentences with entity mention pairs collected from the TAC KBP evaluations 5 2009 - 2014 ,"]},{"number":"2010Task8","isBolded":false,"associatedRows":["SemEval"],"associatedColumns":["Table 2 shows key statistics of the TACRED and SemEval datasets .","Dataset"],"associatedMergedColumns":["negative training examples , which makes classification more challenging ."]},{"number":"17.4%","isBolded":false,"associatedRows":["SemEval","19","10 , 717"],"associatedColumns":["Table 2 shows key statistics of the TACRED and SemEval datasets .","negative examples"],"associatedMergedColumns":["negative training examples , which makes classification more challenging ."]},{"number":"2010","isBolded":true,"associatedRows":["SemEval"],"associatedColumns":["Table 2 shows key statistics of the TACRED and SemEval datasets .","Dataset","The","categorized into 16 fine - grained classes ( e . g . , date , location , title ) .","[ 2017 ] ,"],"associatedMergedColumns":["independent runs and report its performance on the test set ."]},{"number":"79.5%","isBolded":false,"associatedRows":["TACRED","42","106 , 264"],"associatedColumns":["Table 2 shows key statistics of the TACRED and SemEval datasets .","negative examples"],"associatedMergedColumns":["negative training examples , which makes classification more challenging ."]},{"number":"2012usedfortraining,","isBolded":false,"associatedRows":["with the years"],"associatedColumns":["Table 2 shows key statistics of the TACRED and SemEval datasets .","relation types","E xtraction"],"associatedMergedColumns":["sentences with entity mention pairs collected from the TAC KBP evaluations 5 2009 - 2014 ,"]},{"number":"2013forevaluation,and","isBolded":false,"associatedRows":["with the years","19"],"associatedColumns":["Table 2 shows key statistics of the TACRED and SemEval datasets .","examples","al . ,"],"associatedMergedColumns":["sentences with entity mention pairs collected from the TAC KBP evaluations 5 2009 - 2014 ,"]},{"number":"2010Task8dataset[Hendrickxetal.,2010]is","isBolded":false,"associatedRows":["SemEval","Task","8 :","The SemEval"],"associatedColumns":["While TACRED is","negative examples","contains","As per convention , we","5"],"associatedMergedColumns":["independent runs and report its performance on the test set ."]}]},{"caption":"Table 3: Best hyperparameter configuration for TACRED and SemEval \n\n","rows":["TACRED","3","2e - 3","5 . 25e - 5","SemEval","6 . 25e - 5","1e - 3"],"columns":["Table 3 shows the best performing","On SemEval 2010 Task 8 ,","Attn . Dropout","λ","we first split"],"mergedAllColumns":["training set with the best parameter configuration ."],"numberCells":[{"number":"0.7","isBolded":false,"associatedRows":["SemEval","3","6 . 25e - 5","1e - 3"],"associatedColumns":["Table 3 shows the best performing","On SemEval 2010 Task 8 ,","λ"],"associatedMergedColumns":["training set with the best parameter configuration ."]},{"number":"0.5","isBolded":false,"associatedRows":["TACRED","3","5 . 25e - 5","2e - 3"],"associatedColumns":["Table 3 shows the best performing","On SemEval 2010 Task 8 ,","λ"],"associatedMergedColumns":["training set with the best parameter configuration ."]},{"number":"0.1","isBolded":false,"associatedRows":["TACRED","3","5 . 25e - 5","2e - 3"],"associatedColumns":["Table 3 shows the best performing","we first split","Attn . Dropout"],"associatedMergedColumns":["training set with the best parameter configuration ."]},{"number":"0.15","isBolded":false,"associatedRows":["SemEval","3","6 . 25e - 5","1e - 3"],"associatedColumns":["Table 3 shows the best performing","we first split","Attn . Dropout"],"associatedMergedColumns":["training set with the best parameter configuration ."]}]},{"caption":"Table 4: TACRED single-model test set performance. We selected the hyperparameters \nusing the validation set, and report the test score of the run with the median \nvalidation score among 5 randomly initialized runs.  † marks results reported in \nthe corresponding papers. \n\n","rows":["C - GCN † Zhang et al . [ 2018 ]","Tree - LSTM † Zhang et al . [ 2018 ]","PA - LSTM † Zhang et al . [ 2018 ]","CNN † Zhang et al . [ 2017 ]","TRE ( ours )","LR † Zhang et al . [ 2017 ]"],"columns":["P","R","F1"],"mergedAllColumns":[],"numberCells":[{"number":"72.0","isBolded":false,"associatedRows":["LR † Zhang et al . [ 2017 ]"],"associatedColumns":["P"],"associatedMergedColumns":[]},{"number":"69.9","isBolded":false,"associatedRows":["C - GCN † Zhang et al . [ 2018 ]"],"associatedColumns":["P"],"associatedMergedColumns":[]},{"number":"66.4","isBolded":false,"associatedRows":["C - GCN † Zhang et al . [ 2018 ]"],"associatedColumns":["F1"],"associatedMergedColumns":[]},{"number":"65.7","isBolded":false,"associatedRows":["PA - LSTM † Zhang et al . [ 2018 ]"],"associatedColumns":["P"],"associatedMergedColumns":[]},{"number":"57.5","isBolded":false,"associatedRows":["LR † Zhang et al . [ 2017 ]"],"associatedColumns":["F1"],"associatedMergedColumns":[]},{"number":"63.3","isBolded":false,"associatedRows":["C - GCN † Zhang et al . [ 2018 ]"],"associatedColumns":["R"],"associatedMergedColumns":[]},{"number":"65.1","isBolded":false,"associatedRows":["PA - LSTM † Zhang et al . [ 2018 ]"],"associatedColumns":["F1"],"associatedMergedColumns":[]},{"number":"47.8","isBolded":false,"associatedRows":["LR † Zhang et al . [ 2017 ]"],"associatedColumns":["R"],"associatedMergedColumns":[]},{"number":"59.2","isBolded":false,"associatedRows":["CNN † Zhang et al . [ 2017 ]"],"associatedColumns":["F1"],"associatedMergedColumns":[]},{"number":"66.0","isBolded":false,"associatedRows":["Tree - LSTM † Zhang et al . [ 2018 ]"],"associatedColumns":["P"],"associatedMergedColumns":[]},{"number":"62.4","isBolded":false,"associatedRows":["Tree - LSTM † Zhang et al . [ 2018 ]"],"associatedColumns":["F1"],"associatedMergedColumns":[]},{"number":"67.4","isBolded":true,"associatedRows":["TRE ( ours )"],"associatedColumns":["F1"],"associatedMergedColumns":[]},{"number":"70.1","isBolded":false,"associatedRows":["TRE ( ours )"],"associatedColumns":["P"],"associatedMergedColumns":[]},{"number":"72.1","isBolded":true,"associatedRows":["CNN † Zhang et al . [ 2017 ]"],"associatedColumns":["P"],"associatedMergedColumns":[]},{"number":"64.5","isBolded":false,"associatedRows":["PA - LSTM † Zhang et al . [ 2018 ]"],"associatedColumns":["R"],"associatedMergedColumns":[]},{"number":"50.3","isBolded":false,"associatedRows":["CNN † Zhang et al . [ 2017 ]"],"associatedColumns":["R"],"associatedMergedColumns":[]},{"number":"65.0","isBolded":true,"associatedRows":["TRE ( ours )"],"associatedColumns":["R"],"associatedMergedColumns":[]},{"number":"59.2","isBolded":false,"associatedRows":["Tree - LSTM † Zhang et al . [ 2018 ]"],"associatedColumns":["R"],"associatedMergedColumns":[]}]},{"caption":"Table 5: SemEval single-model test set performance.  † marks results reported in the corre-\nsponding papers. We report the mean and standard deviation across 5 randomly \ninitialized runs. \n\n","rows":["C - GCN † Zhang et al . [ 2018 ]","PA - LSTM † Zhang et al . [ 2018 ]","PCNN Zeng et al . [ 2015 ]","BRCNN † Cai et al . [ 2016 ]","TRE ( ours )","-","SVM † Rink and Harabagiu [ 2010 ]","DRNN † Xu et al . [ 2016 ]"],"columns":["P","R","F1"],"mergedAllColumns":[],"numberCells":[{"number":"86.1","isBolded":false,"associatedRows":["DRNN † Xu et al . [ 2016 ]","-","-"],"associatedColumns":["F1"],"associatedMergedColumns":[]},{"number":"87.1(±0.16)","isBolded":true,"associatedRows":["TRE ( ours )","-","-"],"associatedColumns":["F1"],"associatedMergedColumns":[]},{"number":"86.2","isBolded":false,"associatedRows":["TRE ( ours )","-"],"associatedColumns":["R"],"associatedMergedColumns":[]},{"number":"84.8","isBolded":false,"associatedRows":["C - GCN † Zhang et al . [ 2018 ]","-","-"],"associatedColumns":["F1"],"associatedMergedColumns":[]},{"number":"86.3","isBolded":false,"associatedRows":["BRCNN † Cai et al . [ 2016 ]","-","-"],"associatedColumns":["F1"],"associatedMergedColumns":[]},{"number":"86.6","isBolded":false,"associatedRows":["PCNN Zeng et al . [ 2015 ]","-","-"],"associatedColumns":["F1"],"associatedMergedColumns":[]},{"number":"82.2","isBolded":false,"associatedRows":["SVM † Rink and Harabagiu [ 2010 ]","-","-"],"associatedColumns":["F1"],"associatedMergedColumns":[]},{"number":"86.7","isBolded":false,"associatedRows":["PCNN Zeng et al . [ 2015 ]"],"associatedColumns":["P"],"associatedMergedColumns":[]},{"number":"86.7","isBolded":false,"associatedRows":["PCNN Zeng et al . [ 2015 ]","-"],"associatedColumns":["R"],"associatedMergedColumns":[]},{"number":"82.7","isBolded":false,"associatedRows":["PA - LSTM † Zhang et al . [ 2018 ]","-","-"],"associatedColumns":["F1"],"associatedMergedColumns":[]},{"number":"88.0","isBolded":false,"associatedRows":["TRE ( ours )"],"associatedColumns":["P"],"associatedMergedColumns":[]}]},{"caption":"Table 6: SemEval single-model test set performance with all entity mentions masked by \nan unknown (UNK) token.  † marks results reported in the corresponding papers. \n","rows":["C - GCN † Zhang et al . [ 2018 ]","PA - LSTM † Zhang et al . [ 2018 ]","TRE ( ours )","-","Our model achieves an F1 score of"],"columns":["P","R","we substitute the entity mentions in the training set","F1"],"mergedAllColumns":["and prevents overfitting to entity mentions that strongly correlate with specific relations ."],"numberCells":[{"number":"2.6pointsF1scoreover","isBolded":false,"associatedRows":["Our model achieves an F1 score of","PA - LSTM † Zhang et al . [ 2018 ]","-","-"],"associatedColumns":["we substitute the entity mentions in the training set"],"associatedMergedColumns":["and prevents overfitting to entity mentions that strongly correlate with specific relations ."]},{"number":"76.5","isBolded":false,"associatedRows":["Our model achieves an F1 score of","C - GCN † Zhang et al . [ 2018 ]","-","-"],"associatedColumns":["we substitute the entity mentions in the training set","F1"],"associatedMergedColumns":["and prevents overfitting to entity mentions that strongly correlate with specific relations ."]},{"number":"0.37)","isBolded":false,"associatedRows":["TRE ( ours )","-","-"],"associatedColumns":["we substitute the entity mentions in the training set","F1"],"associatedMergedColumns":["and prevents overfitting to entity mentions that strongly correlate with specific relations ."]},{"number":"75.3","isBolded":false,"associatedRows":["Our model achieves an F1 score of","PA - LSTM † Zhang et al . [ 2018 ]","-","-"],"associatedColumns":["we substitute the entity mentions in the training set","F1"],"associatedMergedColumns":["and prevents overfitting to entity mentions that strongly correlate with specific relations ."]},{"number":"80.3","isBolded":false,"associatedRows":["TRE ( ours )"],"associatedColumns":["we substitute the entity mentions in the training set","P"],"associatedMergedColumns":["and prevents overfitting to entity mentions that strongly correlate with specific relations ."]},{"number":"79.1(Table6),animprovementof","isBolded":false,"associatedRows":["Our model achieves an F1 score of","TRE ( ours )"],"associatedColumns":["we substitute the entity mentions in the training set"],"associatedMergedColumns":["and prevents overfitting to entity mentions that strongly correlate with specific relations ."]},{"number":"78.0","isBolded":false,"associatedRows":["TRE ( ours )","-"],"associatedColumns":["we substitute the entity mentions in the training set","R"],"associatedMergedColumns":["and prevents overfitting to entity mentions that strongly correlate with specific relations ."]},{"number":"79.1(±","isBolded":true,"associatedRows":["TRE ( ours )","-","-"],"associatedColumns":["we substitute the entity mentions in the training set","F1"],"associatedMergedColumns":["and prevents overfitting to entity mentions that strongly correlate with specific relations ."]}]},{"caption":"Table 7: Ablation with and without masked entities for SemEval (left) and TACRED val-\nidation set (right). We report F1 scores over 5 independent runs. \n\n","rows":["- w / o pre - trained LM and BPE","- w / o pre - trained LM","Best model"],"columns":["TACRED","NE + GR","UNK","None"],"mergedAllColumns":[],"numberCells":[{"number":"38.4","isBolded":false,"associatedRows":["- w / o pre - trained LM and BPE"],"associatedColumns":["TACRED","UNK"],"associatedMergedColumns":[]},{"number":"75.6","isBolded":true,"associatedRows":["- w / o pre - trained LM"],"associatedColumns":["TACRED","None"],"associatedMergedColumns":[]},{"number":"43.3","isBolded":false,"associatedRows":["- w / o pre - trained LM"],"associatedColumns":["TACRED","None"],"associatedMergedColumns":[]},{"number":"38.5","isBolded":false,"associatedRows":["- w / o pre - trained LM and BPE"],"associatedColumns":["TACRED","None"],"associatedMergedColumns":[]},{"number":"60.8","isBolded":true,"associatedRows":["- w / o pre - trained LM and BPE"],"associatedColumns":["TACRED","NE + GR"],"associatedMergedColumns":[]},{"number":"41.6","isBolded":false,"associatedRows":["- w / o pre - trained LM"],"associatedColumns":["TACRED","UNK"],"associatedMergedColumns":[]},{"number":"60.9","isBolded":true,"associatedRows":["- w / o pre - trained LM and BPE"],"associatedColumns":["TACRED","UNK"],"associatedMergedColumns":[]},{"number":"76.9","isBolded":false,"associatedRows":["Best model"],"associatedColumns":["TACRED","UNK"],"associatedMergedColumns":[]},{"number":"63.3","isBolded":false,"associatedRows":["Best model"],"associatedColumns":["TACRED","None"],"associatedMergedColumns":[]},{"number":"85.6","isBolded":true,"associatedRows":["Best model"],"associatedColumns":["TACRED","None"],"associatedMergedColumns":[]},{"number":"64.2","isBolded":true,"associatedRows":["- w / o pre - trained LM"],"associatedColumns":["TACRED","NE + GR"],"associatedMergedColumns":[]},{"number":"68.2","isBolded":false,"associatedRows":["- w / o pre - trained LM"],"associatedColumns":["TACRED","UNK"],"associatedMergedColumns":[]},{"number":"55.3","isBolded":false,"associatedRows":["- w / o pre - trained LM and BPE"],"associatedColumns":["TACRED","None"],"associatedMergedColumns":[]},{"number":"51.0","isBolded":false,"associatedRows":["Best model"],"associatedColumns":["TACRED","UNK"],"associatedMergedColumns":[]},{"number":"68.0","isBolded":true,"associatedRows":["Best model"],"associatedColumns":["TACRED","NE + GR"],"associatedMergedColumns":[]}]},{"caption":"Table 8: TACRED validation F1 scores for TACRED with different entity masking strate-\ngies. \n\n","rows":["NE + GR","UNK","NE","GR","None"],"columns":["Precision","Recall","F1"],"mergedAllColumns":[],"numberCells":[{"number":"69.5","isBolded":true,"associatedRows":["None"],"associatedColumns":["Precision"],"associatedMergedColumns":[]},{"number":"46.3","isBolded":false,"associatedRows":["UNK"],"associatedColumns":["Recall"],"associatedMergedColumns":[]},{"number":"63.8","isBolded":false,"associatedRows":["GR"],"associatedColumns":["Precision"],"associatedMergedColumns":[]},{"number":"65.3","isBolded":false,"associatedRows":["NE"],"associatedColumns":["Recall"],"associatedMergedColumns":[]},{"number":"58.1","isBolded":false,"associatedRows":["None"],"associatedColumns":["Recall"],"associatedMergedColumns":[]},{"number":"67.2","isBolded":true,"associatedRows":["NE + GR"],"associatedColumns":["Recall"],"associatedMergedColumns":[]},{"number":"68.8","isBolded":false,"associatedRows":["NE"],"associatedColumns":["Precision"],"associatedMergedColumns":[]},{"number":"50.1","isBolded":false,"associatedRows":["GR"],"associatedColumns":["Recall"],"associatedMergedColumns":[]},{"number":"56.1","isBolded":false,"associatedRows":["GR"],"associatedColumns":["F1"],"associatedMergedColumns":[]},{"number":"63.3","isBolded":false,"associatedRows":["None"],"associatedColumns":["F1"],"associatedMergedColumns":[]},{"number":"68.0","isBolded":true,"associatedRows":["NE + GR"],"associatedColumns":["F1"],"associatedMergedColumns":[]},{"number":"51.0","isBolded":false,"associatedRows":["UNK"],"associatedColumns":["F1"],"associatedMergedColumns":[]},{"number":"67.0","isBolded":false,"associatedRows":["NE"],"associatedColumns":["F1"],"associatedMergedColumns":[]},{"number":"56.9","isBolded":false,"associatedRows":["UNK"],"associatedColumns":["Precision"],"associatedMergedColumns":[]},{"number":"68.8","isBolded":false,"associatedRows":["NE + GR"],"associatedColumns":["Precision"],"associatedMergedColumns":[]}]}]