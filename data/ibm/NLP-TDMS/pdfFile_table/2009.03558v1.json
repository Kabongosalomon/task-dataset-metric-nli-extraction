[{"caption":"Table 1: Mean accuracies (%) of different methods on the MiniImageNet and CIFAR-FS dataset. Results are obtained over \n600 test episodes with 95% confidence intervals. Note that Conv4-n denotes 4-layer convolution network outputting feature \nmaps with n channels. *: (Wu et al. 2019) uses feature extractor as 6-layer convolution network with deformable convolution \nkernel (Dai et al. 2017)   Model \nBackbone \nType \nMini-ImageNet (5-way) \nCIFAR-FS (5-way) \n1-shot \n5-shot \n1-shot \n5-shot \nMETA LSTM (Ravi and Larochelle 2017) \nConv4-32 \nMeta \n43.44±0.77 60.60±0.71 \n-\n-\nMAML (Finn, Abbeel, and Levine 2017) \nConv4-32 \nMeta \n48.70±1.84 63.11±0.92 \n58.9±1.9 \n71.5±1.0 \nDynamic-Net (Gidaris and Komodakis 2018) \nConv4-64 \nMeta \n56.20±0.86 72.81±0.62 \n-\n-\nDynamic-Net (Gidaris and Komodakis 2018) \nRes12 \nMeta \n55.45±0.89 70.13±0.68 \n-\n-\nSNAIL (Mishra et al. 2017) \nRes12 \nMeta \n55.71±0.99 68.88±0.92 \nAdaResNet (Lee et al. 2019) \nRes12 \nMeta \n56.88±0.62 71.94±0.57 \n-\n-\nMATCHING NETS (Vinyals et al. 2016) \nConv4-64 \nMetric 43.56±0.84 55.31±0.73 \n-\n-\nPROTOTYPICAL NETS (Snell, Swersky, and Zemel 2017) \nConv4-64 \nMetric 49.42±0.78 68.20±0.66 \n55.5±0.7 \n72.0±0.6 \nRELATION NETS (Sung et al. 2018) \nConv4-64 \nMetric 50.44±0.82 65.32±0.70 \n55.0±1.0 \n69.3±0.8 \nGNN (Garcia and Bruna 2017) \nConv4-64 \nMetric 50.33±0.36 66.41±0.63 \n61.9 \n75.3 \nPABN (Huang et al. 2019) \nConv4-64 \nMetric 51.87±0.45 65.37±0.68 \n-\n-\nTPN (Liu et al. 2019) \nConv4-64 \nMetric 52.78±0.27 66.59±0.28 \n-\n-\nDN4 (Li et al. 2019b) \nConv4-64 \nMetric 51.24±0.74 71.02±0.64 \n-\n-\nR2-D2 (Bertinetto et al. 2019) \nConv4-512 Metric 51.80±0.20 \n68.4±0.20 \n65.3±0.2 \n79.4±0.1 \nGCR (Li et al. 2019a) \nConv4-512 Metric 53.21±0.40 72.32±0.32 \n-\n-\nPARN (Wu et al. 2019) \n* \nMetric 55.22±0.82 71.55±0.66 \n-\n-\nRCN \nConv4-64 \nMetric 53.47±0.84 71.63±0.70 61.61±0.96 77.63±0.75 \nRCN \nRes12 \nMetric 57.40±0.86 75.19±0.64 69.02±0.92 82.96±0.67 \n\n","rows":["GNN ( Garcia and Bruna 2017 )","66 . 41±0 . 63","Conv4 - 64","Metric","50 . 33±0 . 36"],"columns":["Table 1 : Mean accuracies ( % ) of different methods on the MiniImageNet and CIFAR - FS dataset . Results are obtained over","55 . 5±0 . 7","5 - shot","72 . 0±0 . 6","69 . 3±0 . 8","CIFAR - FS ( 5 - way )","68 . 88±0 . 92","55 . 0±1 . 0","-","58 . 9±1 . 9","71 . 5±1 . 0","1 - shot"],"mergedAllColumns":["kernel ( Dai et al . 2017 )"],"numberCells":[{"number":"61.9","isBolded":false,"associatedRows":["GNN ( Garcia and Bruna 2017 )","Conv4 - 64","Metric","50 . 33±0 . 36","66 . 41±0 . 63"],"associatedColumns":["Table 1 : Mean accuracies ( % ) of different methods on the MiniImageNet and CIFAR - FS dataset . Results are obtained over","CIFAR - FS ( 5 - way )","1 - shot","-","58 . 9±1 . 9","-","-","68 . 88±0 . 92","-","-","55 . 5±0 . 7","55 . 0±1 . 0"],"associatedMergedColumns":["kernel ( Dai et al . 2017 )"]},{"number":"75.3","isBolded":false,"associatedRows":["GNN ( Garcia and Bruna 2017 )","Conv4 - 64","Metric","50 . 33±0 . 36","66 . 41±0 . 63"],"associatedColumns":["Table 1 : Mean accuracies ( % ) of different methods on the MiniImageNet and CIFAR - FS dataset . Results are obtained over","CIFAR - FS ( 5 - way )","5 - shot","-","71 . 5±1 . 0","-","-","68 . 88±0 . 92","-","-","72 . 0±0 . 6","69 . 3±0 . 8"],"associatedMergedColumns":["kernel ( Dai et al . 2017 )"]}]},{"caption":"Table 2: Mean accuracies (%) of different methods on the \nCUB-200. Results are obtained over 600 test episodes with \n95% confidence intervals.  †: Split CUB as (Li et al. 2019b). \n ‡: Split CUB as (Chen et al. 2019b) \n\nModel \nBackbone \nType \nCUB-200 (5-way) \n1-shot \n5-shot \nPCM  † (Wei et al. 2019) \nConv4-64 Metric 42.10±1.96 62.48±1.21 \nMATCHING NETS  † (Vinyals et al. 2016) \nConv4-64 Metric 45.30±1.03 59.50±1.01 \nPROTOTYPICAL NETS  † (Snell, Swersky, and Zemel 2017) Conv4-64 Metric 37.36±1.00 45.28±1.03 \nGNN  † (Garcia and Bruna 2017) \nConv4-64 Metric 51.83±0.98 63.69±0.94 \nDN4  † (Li et al. 2019b) \nConv4-64 Metric 53.15±0.84 81.90±0.60 \nRCN  † \nConv4-64 Metric 66.48±0.90 82.04±0.58 \nRCN  † \nRes12 \nMetric 78.64±0.88 90.10±0.50 \nBaseline++  ‡ (Chen et al. 2019b) \nRes10 \nMetric 69.55±0.89 85.17±0.50 \nMAML++(High-End)+SCA  ‡ (Antoniou and Storkey 2019) \n-\nMeta \n70.46±1.18 85.63±0.66 \nGPShot(CosSim)  ‡ (Patacchiola et al. 2019) \nRes10 \nMeta \n70.81±0.52 83.26±0.50 \nGPShot(BNCosSim)  ‡ (Patacchiola et al. 2019) \nRes10 \nMeta \n72.27±0.30 85.64±0.29 \nRCN  ‡ \nConv4-64 Metric 67.06±0.93 82.36±0.61 \nRCN  ‡ \nRes12 \nMetric 74.65±0.86 88.81±0.57 \n\n","rows":["GNN ( Garcia and Bruna 2017 )","66 . 41±0 . 63","Conv4 - 64","Metric","50 . 33±0 . 36"],"columns":["Table 1 : Mean accuracies ( % ) of different methods on the MiniImageNet and CIFAR - FS dataset . Results are obtained over","55 . 5±0 . 7","5 - shot","72 . 0±0 . 6","69 . 3±0 . 8","CIFAR - FS ( 5 - way )","68 . 88±0 . 92","55 . 0±1 . 0","-","58 . 9±1 . 9","71 . 5±1 . 0","1 - shot"],"mergedAllColumns":["kernel ( Dai et al . 2017 )"],"numberCells":[{"number":"61.9","isBolded":false,"associatedRows":["GNN ( Garcia and Bruna 2017 )","Conv4 - 64","Metric","50 . 33±0 . 36","66 . 41±0 . 63"],"associatedColumns":["Table 1 : Mean accuracies ( % ) of different methods on the MiniImageNet and CIFAR - FS dataset . Results are obtained over","CIFAR - FS ( 5 - way )","1 - shot","-","58 . 9±1 . 9","-","-","68 . 88±0 . 92","-","-","55 . 5±0 . 7","55 . 0±1 . 0"],"associatedMergedColumns":["kernel ( Dai et al . 2017 )"]},{"number":"75.3","isBolded":false,"associatedRows":["GNN ( Garcia and Bruna 2017 )","Conv4 - 64","Metric","50 . 33±0 . 36","66 . 41±0 . 63"],"associatedColumns":["Table 1 : Mean accuracies ( % ) of different methods on the MiniImageNet and CIFAR - FS dataset . Results are obtained over","CIFAR - FS ( 5 - way )","5 - shot","-","71 . 5±1 . 0","-","-","68 . 88±0 . 92","-","-","72 . 0±0 . 6","69 . 3±0 . 8"],"associatedMergedColumns":["kernel ( Dai et al . 2017 )"]}]},{"caption":"Table 3: Mean accuracies (%) of different methods on the \nStanford Dogs. Results are obtained over 600 test episodes \nwith 95% confidence intervals. \n\n","rows":["Stanford Dogs . Results are obtained over","CUB - 200 . Results are obtained over"],"columns":[],"mergedAllColumns":[],"numberCells":[{"number":"600testepisodes","isBolded":false,"associatedRows":["CUB - 200 . Results are obtained over","Stanford Dogs . Results are obtained over"],"associatedColumns":[],"associatedMergedColumns":[]},{"number":"600testepisodeswith","isBolded":false,"associatedRows":["CUB - 200 . Results are obtained over"],"associatedColumns":[],"associatedMergedColumns":[]}]},{"caption":"Table 4: Mean accuracies (%) of different methods on the \nMini-ImageNet and CUB-200(using split criterion as (Li et  al. 2019b)). Results are obtained over 600 test episodes with \n95% confidence intervals. Note that the items in the region \nweight of fixed linear layer are all fixed as 1 \n\nh×w \n\nVersion \nMini-ImageNet \nCUB-200 \n1-shot \n5-shot \n1-shot \n5-shot \n\nFixed Linear Layer (5×5) \n49.30±0.89 \n55.51±0.71 \n62.61±1.63 \n67.26±0.83 \nLearnable Linear Layer (5×5) \n55.97±0.86 \n72.80±0.63 \n73.23±0.90 \n88.12±0.56 \nMeta Learner (5×5) \n57.40±0.86 \n75.19±0.64 \n78.64±0.88 \n90.10±0.50 \nFixed Linear Layer (4×4) \n51.79±0.90 \n57.40±0.70 \n65.18±1.08 \n71.65±0.83 \nLearnable Linear Layer (4×4) \n55.18±0.84 \n73.25±0.64 \n75.12±0.89 \n87.63±0.54 \nMeta Learner (4×4) \n55.73±0.83 \n72.78±0.62 \n76.48±0.86 \n87.89±0.57 \nFixed Linear Layer (3×3) \n51.51±0.90 \n56.02±0.70 \n65.97±1.03 \n74.59±0.89 \nLearnable Linear Layer (3×3) \n56.50±0.87 \n73.48±0.62 \n76.15±0.87 \n88.10±0.51 \nMeta Learner (3×3) \n55.41±0.85 \n72.16±0.68 \n75.63±0.88 \n86.96±0.57 \nFixed Linear Layer (2×2) \n51.58±0.91 \n57.59±0.70 \n68.95±1.05 \n77.64±0.81 \nLearnable Linear Layer (2×2) \n56.03±0.85 \n72.23±0.64 \n73.79±0.85 \n87.42±0.57 \nMeta Learner (2×2) \n55.65±0.83 \n72.36±0.64 \n75.79±0.87 \n86.64±0.55 \nFixed Linear Layer (1×1) \n52.22±1.03 \n57.34±0.75 \n70.70±0.78 \n78.43±0.43 \nLearnable Linear Layer (1×1) \n54.80±0.86 \n71.80±0.69 \n75.83±0.85 \n86.97±0.53 \nMeta Learner (1×1) \n55.40±0.89 \n72.78±0.62 \n73.83±0.98 \n84.77±0.54 \n\ninformation, while we may have too much noise region vec-\ntors like the regions of backgrounds if the size is too big. \n\n","rows":["al . 2019b ) ) . Results are obtained over"],"columns":["Table 4 : Mean accuracies ( % ) of different methods on the"],"mergedAllColumns":["Mini - ImageNet and CUB - 200 ( using split criterion as ( Li et"],"numberCells":[{"number":"600testepisodeswith","isBolded":false,"associatedRows":["al . 2019b ) ) . Results are obtained over"],"associatedColumns":["Table 4 : Mean accuracies ( % ) of different methods on the"],"associatedMergedColumns":["Mini - ImageNet and CUB - 200 ( using split criterion as ( Li et"]}]}]