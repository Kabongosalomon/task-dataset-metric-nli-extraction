<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">EMNLP-Findings&apos;20 CommonGen: A Constrained Text Generation Challenge for Generative Commonsense Reasoning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><forename type="middle">Yuchen</forename><surname>Lin</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Southern California ♠ Allen Institute for Artificial Intelligence ♦ Paul G. Allen School of Computer Science &amp; Engineering</orgName>
								<orgName type="institution" key="instit2">University of Washington</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangchunshu</forename><surname>Zhou</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Southern California ♠ Allen Institute for Artificial Intelligence ♦ Paul G. Allen School of Computer Science &amp; Engineering</orgName>
								<orgName type="institution" key="instit2">University of Washington</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Shen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Southern California ♠ Allen Institute for Artificial Intelligence ♦ Paul G. Allen School of Computer Science &amp; Engineering</orgName>
								<orgName type="institution" key="instit2">University of Washington</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pei</forename><surname>Zhou</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Southern California ♠ Allen Institute for Artificial Intelligence ♦ Paul G. Allen School of Computer Science &amp; Engineering</orgName>
								<orgName type="institution" key="instit2">University of Washington</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chandra</forename><surname>Bhagavatula</surname></persName>
							<email>chandrab@allenai.org</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Southern California ♠ Allen Institute for Artificial Intelligence ♦ Paul G. Allen School of Computer Science &amp; Engineering</orgName>
								<orgName type="institution" key="instit2">University of Washington</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
							<email>yejinc@allenai.org</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Southern California ♠ Allen Institute for Artificial Intelligence ♦ Paul G. Allen School of Computer Science &amp; Engineering</orgName>
								<orgName type="institution" key="instit2">University of Washington</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">♠</forename><forename type="middle">♦</forename><surname>Xiang</surname></persName>
							<email>xiangren@usc.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Southern California ♠ Allen Institute for Artificial Intelligence ♦ Paul G. Allen School of Computer Science &amp; Engineering</orgName>
								<orgName type="institution" key="instit2">University of Washington</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ren</forename></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Southern California ♠ Allen Institute for Artificial Intelligence ♦ Paul G. Allen School of Computer Science &amp; Engineering</orgName>
								<orgName type="institution" key="instit2">University of Washington</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">EMNLP-Findings&apos;20 CommonGen: A Constrained Text Generation Challenge for Generative Commonsense Reasoning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T07:29+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recently, large-scale pretrained language models have demonstrated impressive performance on several commonsense-reasoning benchmark datasets. However, building machines with commonsense to compose realistically plausible sentences remains challenging. In this paper, we present a constrained text generation task, COMMONGEN associated with a benchmark dataset, to explicitly test machines for the ability of generative commonsense reasoning. Given a set of common concepts (e.g., {dog, frisbee, catch, throw}); the task is to generate a coherent sentence describing an everyday scenario using these concepts (e.g., "a man throws a frisbee and his dog catches it").</p><p>The COMMONGEN task is challenging because it inherently requires 1) relational reasoning with background commonsense knowledge, and 2) compositional generalization ability to work on unseen concept combinations. Our dataset, constructed through a combination of crowdsourced and existing caption corpora, consists of 79k commonsense descriptions over 35k unique concept-sets. Experiments show that there is a large gap between state-of-the-art text generation models (e.g., T5) and human performance. Furthermore, we demonstrate that the learned generative commonsense reasoning capability can be transferred to improve downstream tasks by generating additional context.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Commonsense reasoning, the ability to make acceptable and logical assumptions about ordinary scenes in our daily life, has long been acknowledged as a critical bottleneck of artificial intelligence and natural language processing <ref type="bibr">(Davis and Marcus, 2015)</ref>. Most recent commonsense reasoning challenges, such as CommonsenseQA <ref type="bibr" target="#b33">(Talmor et al., 2019)</ref>, SocialIQA <ref type="bibr" target="#b28">(Sap et al., 2019b)</ref>, dog, frisbee, catch, throw -A dog leaps to catch a thrown frisbee.</p><p>-The dog catches the frisbee when the boy throws it. -A man throws away his dog 's favorite frisbee expecting him to catch it in the air.</p><p>Expected Output: everyday scenarios covering all given concepts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>[Humans]</head><p>GPT2: A dog throws a frisbee at a football player.</p><p>UniLM: Two dogs are throwing frisbees at each other .</p><p>BART: A dog throws a frisbee and a dog catches it.</p><p>T5: dog catches a frisbee and throws it to a dog <ref type="bibr">[Machines]</ref> exercise | rope | wall | tie | wave -A man in a gym exercises by waving ropes tied to a wall. -The gym owner decided to tie a rope to the wall so people could make a wave in it for exercise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Concept-Set:</head><p>[Humans] <ref type="bibr">GPT2:</ref> A woman is tied up in a rope and swinging a wave at a wall. <ref type="bibr">UniLM:</ref> A man with a rope and tie is doing some exercise on a wall.</p><p>BART: A man is tied to a rope and is waving his arms and doing exercises on the wall.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>[Machines]</head><p>Concept-Set: a collection of objects/actions. <ref type="figure">Figure 1</ref>: An example of the dataset of COMMONGEN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Generative Commonsense Reasoning</head><p>GPT-2, UniLM, BART and T5 are large pre-trained text generation models, fine-tuned on the proposed task.</p><p>WinoGrande <ref type="bibr" target="#b26">(Sakaguchi et al., 2019)</ref> and Hel-laSwag <ref type="bibr" target="#b48">(Zellers et al., 2019b)</ref>, have been framed as discriminative tasks -i.e. AI systems are required to choose the correct option from a set of choices based on a given context. While significant progress has been made on these discriminative tasks, we argue that commonsense reasoning in text generation poses a distinct complementary challenge. In this paper, we advance machine commonsense towards generative reasoning ability.</p><p>Humans acquire the ability to compose sentences by learning to understand and use common concepts that they recognize in their surrounding environment <ref type="bibr" target="#b34">(Tincoff and Jusczyk, 1999)</ref>. The acquisition of such an ability is regarded as a significant milestone of human development <ref type="bibr" target="#b18">(Moore, 2013)</ref>. Can machines acquire such generative commonsense reasoning ability? To initiate the investigation, we present COMMONGEN 1 -a novel constrained generation task that requires machines to generate a sentence describing a day-to-day scene using concepts from a given concept-set. For example, in <ref type="figure">Figure 1</ref>, given a set of concepts: {dog, { exercise, rope, wall, tie, wave } A woman in a gym exercises by waving ropes tied to a wall.</p><p>(exercise, HasSubEvent , releasing energy) (rope, UsedFor, tying something) (releasing energy, HasPrerequisite, motion) (wave, IsA, motion) ; (rope, UsedFor, waving) The motion costs more energy if ropes are tied to a wall.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Underlying Relational Commonsense Knowledge</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Relational Reasoning for Generation</head><p>Training Compositional Generalization</p><p>x 1 = { apple, bag, put } y 1 = a girl puts an apple in her bag x = { pear, basket, pick, put, tree }, y = ?</p><p>Reference: "a girl picks some pear from a tree and put them in her basket."</p><p>x 2 = { apple, tree, pick } y 2 = a man picks some apples from a tree x 3 = { apple, basket, wash } y 3 = a boy takes an apple from a basket and washes it.</p><p>Test <ref type="figure">Figure 2</ref>: Two key challenges of COMMONGEN: relational reasoning with underlying commonsense knowledge about given concepts (left), and compositional generalization for unseen combinations of concepts (right).</p><p>frisbee, catch, throw}, machines are required to generate a sentence such as "a man throws a frisbee and his dog catches it in the air."</p><p>To successfully solve the task, models need to incorporate two key capabilities: a) relational reasoning, and b) compositional generalization. Grammatically sound sentences may not always be realistic as they might violate our commonsense (e.g., "a dog throws a frisbee ..."). In order to compose a plausible sentence that describes an everyday scenario, models need to construct a grammatical sentence while adhering to and reasoning over the commonsense relations between the given concepts. Models additionally need compositional generalization ability to infer about unseen concept compounds. This encourages models to reason about a potentially infinite number of novel combinations of familiar concepts -an ability believed to be a limitation of current AI systems (Lake and <ref type="bibr" target="#b5">Baroni, 2017;</ref><ref type="bibr" target="#b2">Keysers et al., 2020)</ref>.</p><p>Therefore, in support of the COMMONGEN task, we present a dataset consisting of 35,141 conceptsets associated with 77,449 sentences. We explicitly design our dataset collection process to capture the key challenges of relational reasoning and compositional generalization described above, through an actively controlled crowd-sourcing process. We establish comprehensive baseline performance for state-of-the-art language generation models with both extensive automatic evaluation and manual comparisons. The best model, based on <ref type="bibr">T5 (Raffel et al., 2019)</ref>, achieves 28.86% with significant gap compared to human performance of 52.43% in the SPICE metric -demonstrating the difficulty of the task. Our analysis shows that state-of-the-art models struggle at the task, generating implausible sentences -e.g. "dog throws a frisbee ..." , "giving massage to a table", etc. Additionally, we show that successful COMMONGEN models can benefit downstream tasks (e.g., commonsense-centric question answering) via generating useful context as background scenarios. We believe these findings point to interesting future research directions for the community of commonsense reasoning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Task Formulation and Key Challenges</head><p>We formulate the proposed COMMONGEN task with mathematical notations and discuss its inherent challenges with concrete examples. The input is an unordered set of k concepts x = {c 1 , c 2 , . . . , c k } ∈ X (i.e. a concept-set), where each concept c i ∈ C is a common object (noun) or action (verb). We use X to denote the space of all possible concept-sets and use C to denote the concept vocabulary (a subset of ConceptNet's unigram concepts). The expected output is a simple, grammatical sentence y ∈ Y that describes a common scenario in our daily life, using all given concepts in x (morphological inflections are allowed). A scenario can depict either a static situation or a short series of actions. The COMMONGEN task is to learn a function f ∶ X → Y, which maps a concept-set x to a sentence y. The unique challenges of this task come from two aspects: Relational Reasoning with Commonsense. Expected generative reasoners should prioritize the most plausible scenarios over many other less realistic ones. As shown in <ref type="figure">Figure 2</ref>, models need to recall necessary relational commonsense facts that are relevant to the given concepts, and then reason an optimal composition of them for generating a desired sentence. In order to complete a scenario, generative commonsense reasoners also need to reasonably associate additional concepts (e.g., 'woman', 'gym') as agents or background environments for completing a coherent scenario.</p><p>This not only requires understanding underlying commonsense relations between concepts, but also incrementally composing them towards a globally optimal scenario. The underlying reasoning chains are inherently based on a variety of background knowledge such as spatial relations, object properties, physical rules, temporal event knowledge, social conventions, etc. However, they may not be recorded in any existing knowledge bases.</p><p>Compositional Generalization. Humans can compose a sentence to describe a scenario about the concepts they may never seen them co-occurring. For example, in <ref type="figure">Figure 2</ref>, there is a testing conceptsetx ={pear, basket, pick, put, tree}. The concept 'pear' never appear in the training data, and 'pick' never co-occurs with 'basket'. We, humans, can generalize from these seen scenarios in the training data and infer that a plausible output:ŷ ="a girl picks some pears from a tree and put them into her basket." This compositionally generalization ability via analogy, i.e., to make "infinite use of finite means" <ref type="bibr">(Chomsky, 1965)</ref>, is challenging for machines. This analogical challenge not only requires inference about similar concepts (e.g., 'apple' → 'pear') but also their latent associations. <ref type="figure" target="#fig_0">Figure 3</ref> illustrates the overall workflow of our data construction for the proposed COMMONGEN task. We utilize several existing caption corpora for sampling frequent concept-sets (Sec. 3.1) for reflecting common scenarios. We employ AMT crowd workers for collecting human-written sentences (Sec. 3.2) for the development and test set, while we carefully monitor the quality of crowd workers and refine them dynamically. Finally, we present the statistics of the COMMONGEN dataset, and the analysis on the challenges (Sec. 3.6).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Dataset Construction and Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Collecting Concept-Sets from Captions</head><p>It can be unreasonable to present any arbitrary set of concepts (e.g., x ={apple, fold, rope}) and ask a reasoner to generate a commonsense scenario, since such an arbitrary set of concepts can be too unrelated. Therefore, our concept-sets are supposed to reflect reasonable concept co-occurrences in everyday situations. As web images and video  clips capture diverse everyday scenarios, we use their caption text as a natural resource for collecting concept-sets and their corresponding descriptions of commonsense scenarios. More specifically, we collect visually-grounded sentences from several existing caption datasets, including image captioning datasets, such as Flickr30k <ref type="bibr" target="#b45">(Young et al., 2014)</ref>, MSCOCO <ref type="bibr" target="#b12">(Lin et al., 2014)</ref>, Conceptual Captions <ref type="bibr" target="#b29">(Sharma et al., 2018)</ref>, as well as video captioning datasets including LSMDC <ref type="bibr" target="#b25">(Rohrbach et al., 2017)</ref>, ActivityNet <ref type="bibr" target="#b4">(Krishna et al., 2017)</ref>, and VATEX <ref type="bibr" target="#b39">(Wang et al., 2019b)</ref>.</p><p>We first conduct part-of-speech tagging over all sentences in the corpora such that words in sentences can be matched to the concept vocabulary of ConceptNet. Then, we compute the sentence frequency of concept-sets consisting of 3∼5 concepts. That is, for each combination of three/four/five concepts in the vocabulary, we know how many sentences are in the corpora covering all concepts.</p><p>Ideally, we want the selected concept-sets in our dataset to reflect the natural distribution of conceptsets in the real world. At first glance, a reasonable solution may seem to sample from the distribution of the concept-sets based on their frequencies in the source datasets. However, we find that this method leads to a rather unnaturally skewed collection of concept-sets, due to the inherent data biases from the source datasets. We therefore design a function to score a concept-set x based on scene diversity and inverse frequency penalty. We denote S(x) as the set of unique sentences that contain all given concepts {c 1 , c 2 , . . . , c k }, and then we have</p><formula xml:id="formula_0">score(x) = |S(x)| | ⋃ s i ∈S(x) {w|w ∈ s i }| ∑ s i ∈S(x) len(s i ) ρ(x),</formula><p>where ρ(x) = |X | max c i ∈x |{x ′ | c i ∈x ′ and x ′ ∈X }| . The first term in score is the number of unique sentences covering all given concepts in x, and the second term is to represent the diversity of the scenes  described in these sentences. Th last term ρ(x) is the penalty of inverse frequency. Specifically, we find the concept in x that has the maximum "set frequency" (i.e., the number of unique conceptsets containing a particular concept), then we take the inverse with the number of all concept-sets for normalization. This penalty based on inverse set-frequency effectively controls the bias towards highly frequent concepts. With the distribution of such scores of concept-sets, we sample our candidate examples for the next steps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Crowd-Sourcing References via AMT</head><p>In order to ensure the best quality, the references of the evaluation examples are crowdsourced from crowd workers on Amazon Mechanical Turk, which amounts to 10,060 references over 2.5k distinct concept-sets. Note that these newly collected references for dev and test examples can ensure that we can do a fair comparisons targeting generalization, considering potential data-leak (i.e., recent pre-trained language models might have seen the caption datasets). Each concept-set was assigned to at least 3 workers. In addition to references about given concept-sets, we also ask the workers to provide rationale sentences to explain what commonsense facts they have used, for ensuring that the described scenarios are common in daily life (example rationales are shown in <ref type="figure">Fig 10)</ref>.</p><p>We control the quality by actively filtering workers who produced low-quality references, then removing their annotations, and finally re-opening the slots only for quality workers. There were 1,492 accepted workers in total and 171 disqual-ified workers in the end after the active filtering. There are three criteria for efficiently narrowing down candidates for us to further manually remove out low-quality workers: 1) coverage via part-ofspeech tagging, 2) especially high perplexity via GPT-2, and 3) length of the rationales. Meanwhile, we also dynamically replaced the concept-sets that majority of the references do not make sense to ensure the final quality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Permutation-Invariant Annotating</head><p>We have to present every input as a a string for annotators to read, which means we take a random permutation of the concept-set as a linear sequence. Therefore we may wonder if annotators will make flexible adjustment on the concept order when creating references for CommonGen. To address this concern, we first study the correlation between the input concept-order and the reference concept-order (i.e., the order of the given concepts in the human annotations). We find that 96.97% of the references, of which the concept-order is different from the order shown when they are annotating.</p><p>More specifically, we use Spearmans's rank correlation coefficient to understand the correlation between input concept-order and reference conceptorder. It turns out that the mean correlation over all input-reference pairs on test examples is -0.031, which suggests that different permutation of the input concept-order do not have notable influence on the order of concept in the human references, thus being permutation-invariant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Finalizing Adequate References</head><p>As there may be more than one acceptable scenes for each input concept-set, we would like to check if our human references are enough before we finalizing our dataset. Thus, we took one more round of crowd-sourcing to add one more reference for each concept-set by new annotators. Then, we compute the inter-annotator agreement (IAA) by using the cosine similarity between all pairs of human references, based on SentenceBERT (Reimers and Gurevych, 2019) (fine-tuned for semantic similarity analysis). Note that if we have k human references for an example in the end, then we will have k(k − 1)/2 different pairs of references, each of which has a cosine similarity between their sentence embeddings. Then, we take the median of these similarity scores as a proxy to understand if we have collect adequate human references. The underlying rationale here is that if there are more references that are very similar to each other yet from different annotators, then it is likely that current references are adequate for this example. As shown in <ref type="figure" target="#fig_1">Figure 4</ref>, we simulated different sizes of number of references per example. We find that the IAA will be saturated when we have the fifth ones, and thus we believe references are adequate. Also, from the std of these IAA scores, we find that the diversity of the references, and it also saturate when there are five references.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Down-Sampling Training Examples</head><p>In order to evaluate the compositional generalization ability, we down-sample the remaining candidate concept-sets to construct a distantly supervised training dataset (i.e., using caption sentences as the human references). We explicitly control the overlap of the concept-sets between training examples and dev and test examples. The basic statistics of the final dataset is shown in <ref type="table" target="#tab_2">Table 1</ref>. There are on average four sentences for each example in dev and test sets, which provide a richer and more diverse test-bed for automatic and manual evaluation. <ref type="table" target="#tab_2">Table 1</ref> also shows the ratio of unseen concept compositions (i.e., concept, concept-pair, and concept-triple) in the dev and test. Notably, all pairs of concepts in every test concept-set are unseen in training data and thus pose a challenge for compositional generalization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Analysis of Underlying Common Sense</head><p>We here introduce deeper analysis of the dataset by utilizing the largest commonsense knowledge graph (KG), ConceptNet <ref type="bibr" target="#b30">(Speer et al., 2017)</ref>, as an tool to study connectivity and relation types.</p><p>Connectivity Distribution. If the concepts in- side a given concept-set is more densely connected with each other on the KG, then it is likely to be easier to write a scenario about them. In each 5size concept-set (i.e. a concept-set consists of five concepts), there are 10 unique pairs of concepts, the connections of which we are interested in. As shown in <ref type="figure" target="#fig_2">Figure 5</ref>, if we look at the one-hop links on the KG, about 60% of the 5-size concept-set have less than one link among all concept-pairs. On the other hand, if we consider two-hop links, then nearly 50% of them are almost fully connected (i.e. each pair of concepts has connections). These two observations together suggest that the COM-MONGEN has a reasonable difficulty: the concepts are not too distant or too close, and thus the inputs are neither too difficult nor too trivial.</p><p>Relation Distribution. Furthermore, the relation types of such connections can also tell us what kinds of commonsense knowledge are potentially useful for relational reasoning towards generation. We report the frequency of different relation types 2 of the one/two-hop connections among conceptpairs in the dev and test examples in <ref type="figure">Fig. 9</ref>. To better summarize the distributions, we categorize these relations into five major types and present their distribution in <ref type="table" target="#tab_4">Table 2</ref>, respectively for one/two-hop connections between concept pairs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Methods</head><p>We briefly introduce the baseline methods that are tested on the COMMONGEN task.</p><p>Encoder-Decoder Models. Bidirectional RNNs and Transformers <ref type="bibr" target="#b35">(Vaswani et al., 2017)</ref> are two most popular architectures for seq2seq learning. We use them with the addition of attention mecha- <ref type="bibr">2</ref> Relation definitions are at https://github.com/ commonsense/conceptnet5/wiki/Relations.  nism <ref type="bibr" target="#b16">(Luong et al., 2015)</ref> with copying ability <ref type="bibr" target="#b53">(Gu et al., 2016)</ref>, which are based on an open-source framework OpenNMT-py <ref type="bibr" target="#b3">(Klein et al., 2017)</ref>. We use bRNN-CopyNet and Trans-CopyNet denote them respectively. To alleviate the influence from the concept ordering in such sequential learning methods, we randomly permute them multiple times for training and decoding and then get their average performance. To explicitly eliminate the order-sensitivity of inputs, we replace the encoder with a mean pooling-based MLP network (MeanPooling-CopyNet).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Non-autoregressive generation.</head><p>Recent advances <ref type="bibr" target="#b6">(Lee et al., 2018;</ref><ref type="bibr" target="#b31">Stern et al., 2019)</ref> in conditional sentence generation have an emerging interest on (edit-based) non-autoregressive generation models, which iteratively refine generated sequences. We assume that these models potentially would have better performance because of their explicit modeling on iterative refinements, and thus study the most recent such model Levenshtein Transformer (LevenTrans) by <ref type="bibr" target="#b54">Gu et al. (2019)</ref>. We also include a recent enhanced version, ConstLeven , which incorporates lexical constraints in LevenTrans.</p><p>Pre-trained Language Generation Models. We also employ various pre-trained language generation models, including GPT-2 , <ref type="bibr" target="#b58">UniLM (Dong et al., 2019)</ref>, <ref type="bibr" target="#b59">UniLM-v2 (Bao et al., 2020)</ref>, BERT-Gen , BART , and T5 , to tackle this task and test their generative commonsense reasoning ability. We fine-tuned all the above models on our training data with a seq2seq format.</p><p>Specifically, to use GPT-2 for this sequence-to-sequence task, we condition the language model on the format "c 1 c 2 . . . c k = y" during fine-tuning, where c i is a concept in the given concept-set and connects with other concepts with a blank; y is a target sentence. For inference, we sample from the fine-tuned GPT-2 model after a prompt of "c 1 c 2 . . . c k =" with beam search and use the first generated sentence as the output sentence. For BERT-Gen, we use the s2s-ft package 3 to finetune them in a sequence-to-sequence fashion that is similar to the LM objective employed by UniLM.</p><p>As for T5, the state-of-the-art text-to-text pretrained model which is pre-trained with a multitask objective by prepending a task description before the input text, we prepend the input concept set with a simple prompt: "generate a sentence with:" and fine-tune the model with the source sentence on the format "generate a sentence with c 1 c 2 . . . c k ." For decoding, we employ the standard beam search with a beam size of 5 for all compared models. We also report their results with a lexically-constrained decoding method, dynamic beam allocation (DBA) <ref type="bibr" target="#b20">(Post and Vilar, 2018)</ref>, which do not show improvement over conventional beam searching. <ref type="bibr" target="#b74">4</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Evaluation</head><p>We first introduce the automatic evaluation metrics, then present main experimental results with manual analysis, and finally introduce the potential application in transferring CommonGen-trained models for other downstream tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Metrics</head><p>Following other conventional generation tasks, we use several widely-used automatic metrics to automatically assess the performance, such as BLEU <ref type="bibr" target="#b19">(Papineni et al., 2002)</ref>, ROUGE <ref type="bibr" target="#b11">(Lin, 2004)</ref>, METEOR (Banerjee and Lavie, 2005), which mainly focus on measuring surface similarities. We report the concept Coverage, which is the average percentage of input concepts that are present in lemmatizatized outputs.</p><p>In addition, we argue that it is more suitable to use evaluation metrics specially design for captioning task, such as CIDEr <ref type="bibr" target="#b36">(Vedantam et al., 2015)</ref> and SPICE <ref type="bibr" target="#b0">(Anderson et al., 2016)</ref>. They usually assume system generations and human references use similar concepts, and thus focus on evaluate the  associations between mentioned concepts instead of n-gram overlap. For example, the SPICE metric uses dependency parse trees as proxy of scene graphs to measure the similarity of scenarios. <ref type="bibr">5</ref> To estimate human performance within each metric, we treat each reference sentence in dev/test data as a "system prediction" to be compared with all other references, which is equivalent to compute inter-annotator agreement within each metric. Thus, systems that have better generative ability than average crowd-workers should exceed this.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Experimental Results</head><p>Automatic Evaluation. <ref type="table" target="#tab_6">Table 3</ref> presents the experimental results in a variety of metrics. We can see that all fine-tuned pre-trained models (the lower group) outperform non-pretrained models (the upper group) with a significant margin. This is not surprising because their pretraining objectives, including masked language modeling, word ordering, and text infilling which predicts missing words or text spans, are relevant to our task. On the other hand, we find that the key disadvantage of nonpretrained models with CopyNet still falls in the failure of using all given concepts (i.e., low coverage), which results in worse results.</p><p>Among them, UniLM, BART, and T5 performs the best, which may be due to its inherent sequence- <ref type="bibr">5</ref> We also tried recent metrics such as BERTScore <ref type="bibr" target="#b50">(Zhang et al., 2020b</ref>), but we find that they overly focus on lexical semantics instead of dependencies between words, thus resulting low correlation with the manual evaluation results.  to-sequence pre-training framework. We found that BART has the best concept coverage, which is probably due to its comprehensive pre-training tasks that aim to recover text with noise. The results suggest that further modifying pre-trained models is a promising direction for generative commonsense. Manual Evaluation. We conduct manual evaluation with a focus on commonsense plausibility for comparing the 6 best-performing models in <ref type="table" target="#tab_8">Table 4</ref>. We ask five graduate students to compare 1,500 pairs of model-generated sentences respectively, for ranking the models within 100 conceptsets that are covered by all the models. The final average ranked results are shown in <ref type="table" target="#tab_8">Table 4</ref> and their inter-annotator agreement is 0.85 in Kendall's rank correlation coefficient. Note that the coverage-weighted hit@1 rate correlates with the SPICE metric the most, i.e., 0.94 in Spearman's ρ for model ranks, CIDEr for 0.91, while METEOR and ROUGE-2 are both 0.88 and BLEU-4 is 0.78. Case study. <ref type="figure">Fig. 6</ref> shows the top generations of different models and human references about an input concept-set: {hand, sink, soup, wash} (more cases are shown in <ref type="figure">Fig. 10</ref> in the appendix). We find that [GPT-2]: hands washing soap on the sink.</p><p>[BERT-Gen]: a woman washes her hands with a sink of soaps.</p><p>[UniLM]: hands washing soap in the sink [BART]: a man is washing his hands in a sink with soap and washing them with hand soap.</p><p>[T5]: hand washed with soap in a sink.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1.</head><p>A girl is washing her hands with soap in the bathroom sink.</p><p>2. I will wash each hand thoroughly with soap while at the sink.</p><p>3. The child washed his hands in the sink with soap.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.</head><p>A woman washes her hands with hand soap in a sink.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5.</head><p>The girl uses soap to wash her hands at the sink.</p><p>Concept-Set: { hand, sink, wash, soap } <ref type="figure">Figure 6</ref>: A case study with a concept-set {hand, sink, wash, soap} for qualitative analysis of machine generations. Human references are collected from AMT. non-pretrained seq2seq models (e.g., bRNN, Mean-Pooling, ConstLeven) can successfully use part of given concepts, while the generated sentences are less meaningful and coherent. On the contrary, the outputs of fine-tuned pre-trained language models are significantly more commonsensical. Most of them use all given concepts in their outputs. Con-stLeven tends to make use of frequent patterns to compose a non-sense sentence but uses all concepts. GPT-2 and UniLM incorrectly compose the dependency among hand, wash, and soap. The phrase 'a sink of soaps' in BERT-gen's output makes itself less common. BART and T5 generate relatively reasonable scenarios, but both are not as natural as human references; BART's contains repetitive content while T5's lacks a human agent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Influence of Dynamic Beam Allocation.</head><p>Considering that all tested models decode sentences with beam searching, one may wonder what if we use a decoding method specially designed for constrained decoding. Thus, we employed dynamic beam allocation (DBA) <ref type="bibr" target="#b20">(Post and Vilar, 2018)</ref>. The results are shown in <ref type="table" target="#tab_10">Table 5</ref>. Note that the models are the same as in <ref type="table" target="#tab_6">Table 3</ref> while only the decoding method is changed to DBA. We can see that all methods are negatively impacted by the decoding method. This suggests that for the COMMON-GEN task and pre-trained language models, we may need to focus on knowledge-based decoding or re-ranking as future directions.</p><p>Training Steps Accuracy <ref type="figure">Figure 7</ref>: Learning curve for the transferring study. We use several trained COMMONGEN (GG) models to generate choice-specific context for the CSQA task. Detailed numbers are shown in Tab. 8 in the appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Transferring CommonGen Models</head><p>One may wonder how fine-tuned COMMONGEN models can benefit commonsense-centric downstream tasks such as Commonsense Question Answering <ref type="bibr" target="#b33">(Talmor et al., 2019)</ref> (CSQA) with their generative commonsense reasoning ability. To this end, we use the models trained with the COMMON-GEN dataset for generating useful context.</p><p>We extract the nouns and verbs in questions and all choices respectively, and combine the concepts of the question q and each choice c i to build five concept-sets. Then, we use these concept-sets as inputs to a trained COMMONGEN model (e.g., T5) for generating scenario a sentence g i for each as choice-specific contexts. Finally, we prepend the outputs in front of the questions, i.e., "&lt;s&gt;G: g i | Q: q &lt;/s&gt; C: c i &lt;/s&gt;". Note that the state-ofthe-art RoBERTa-based models for CSQA uses the same form without "G: g i |" in fine-tuning.</p><p>We show the learning-efficiency curve in <ref type="figure">Fig. 7</ref>, where y is the accuracy on the official dev set and x is the number of training steps. The details of the experiments are shown in the appendix.</p><p>We highlight the performance of original RoBERTa-Large as the baseline. We find that some CommonGen models further improves the performance by a large margin, e.g., 76.9 UniLM − −−− → 78.4 and they converge at better accuracy in the end. Note that BERT-gen and ConstLeven cause negative transfer due to the low quality of generated context. Particularly, we find that the context gener-  Through manual analysis, we find that the successful COMMONGEN models can generate more reasonable and natural sentence for correct choices while noisy sentences for wrong choices. For example with CG (T5), q="What do people aim to do at work?", c i ='complete job' () with g i ="people work to complete a job aimed at achieving a certain goal."; c j ='wear hats' () g j ="people wearing hats aim their guns at each other while working on a construction site." The used question concepts and choice concepts are underlined.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>Commonsense benchmark datasets. There are many emerging datasets for testing machine commonsense from different angles, such as commonsense extraction <ref type="bibr" target="#b9">Li et al., 2016)</ref>, next situation prediction (SWAG <ref type="bibr" target="#b47">(Zellers et al., 2018)</ref>, CODAH (Chen et al., 2019), Hel-laSWAG <ref type="bibr" target="#b48">(Zellers et al., 2019b)</ref>), cultural and social understanding <ref type="bibr">Sap et al., 2019a,b)</ref>, visual scene comprehension <ref type="bibr" target="#b46">(Zellers et al., 2019a)</ref>, and general commonsense question answering <ref type="bibr" target="#b33">(Talmor et al., 2019;</ref><ref type="bibr">Huang et al., 2019;</ref><ref type="bibr" target="#b38">Wang et al., 2019a</ref>). However, the success of fine-tuning pre-trained language models for these tasks does not necessarily mean machines can produce novel assumptions in a more open, realistic, generative setting. We see COMMONGEN as a novel, complementary commonsense reasoning benchmark task for advancing machine commonsense in NLG.</p><p>Constrained Text Generation. Constrained text generation aims to decode sentences with expected attributes such as sentiment <ref type="bibr">Hu et al., 2017)</ref>, tense <ref type="bibr">(Hu et al., 2017)</ref>, template <ref type="bibr" target="#b52">(Zhu et al., 2019;</ref><ref type="bibr" target="#b1">J Kurisinkel and Chen, 2019)</ref>, style <ref type="bibr">(Fu et al., 2018;</ref><ref type="bibr" target="#b8">Li et al., 2018</ref><ref type="bibr">), topics (Feng et al., 2018</ref>, etc. Two related scenarios with our task is lexically constrained decoding and word ordering <ref type="bibr" target="#b51">(Zhang and Clark, 2015;</ref><ref type="bibr">Hasler et al., 2018;</ref><ref type="bibr">Dinu et al., 2019;</ref><ref type="bibr">Hokamp and Liu, 2017;</ref><ref type="bibr" target="#b21">Puduppully et al., 2017;</ref><ref type="bibr" target="#b17">Miao et al., 2019)</ref>. However, they are not easily adopted by the recent pre-trained language models and thus not directly useful for our task. Topical story generation <ref type="bibr">(Fan et al., 2018;</ref><ref type="bibr" target="#b44">Yao et al., 2019)</ref> is also a related direction, while it targets generating longer, creative stories around the given topics, making it hard to directly adopt them to our task. Additionally, the COMMONGEN task brings some more challenges mentioned in Section 2. Prior constrained generation methods cannot address these issues together in a unified model.</p><p>Incorporating Commonsense for NLG. There are a few recent works that incorporate commonsense knowledge in language generation tasks such as essay generation <ref type="bibr">(Guan et al., 2019;</ref>, image captioning <ref type="bibr" target="#b13">(Lu et al., 2018)</ref>, video storytelling , and conversational systems <ref type="bibr" target="#b49">(Zhang et al., 2020a)</ref>. These works suggest that generative commonsense reasoning has a great potential to benefit downstream applications. Our proposed COMMONGEN, to the best of our knowledge, is the very first constrained sentence generation dataset for assessing and conferring generative machine commonsense and we hope it can benefit such applications. Our transferring study in Sec. 5.3 also shows the potential benefits of CommonGen-generated contexts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>Our major contribution in this paper are threefold:</p><p>• we present COMMONGEN, a novel constrained text generation task for generative commonsense reasoning, with a large dataset; • we carefully analyze the inherent challenges of the proposed task, i.e., a) relational reasoning with latent commonsense knowledge, and b) compositional generalization. • our extensive experiments systematically examine recent pre-trained language generation models (e.g., UniLM, BART, T5) on the task , and find that their performance is still far from humans, generating grammatically sound yet realistically implausible sentences. Our study points to interesting future research directions on modeling commonsense knowledge in language generation process, towards conferring machines with generative commonsense reasoning ability. We hope COMMONGEN would also benefit downstream NLG applications such as conversational systems and storytelling models. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Supplementary Figures and Tables</head><p>We include additional figures and tables that we mentioned in the main content here.</p><p>• <ref type="figure">Figure 9</ref> shows the detailed distribution of the commonsense relations between given concepts, the summary of which was shown in <ref type="table" target="#tab_4">Table 2</ref> of the main content. • <ref type="figure">Figure 10</ref> presents 4 more case studies with human rationales which we asked our crowd workers to provide. • <ref type="figure">Figure 8</ref> shows instructions and AMT interface for crowd-sourcing human references. • <ref type="table">Table 7</ref> shows the model performances on the dev set of COMMONGEN, as a reference for future development. • <ref type="table" target="#tab_15">Table 8</ref> is the full results of the learning curve in <ref type="figure">Figure 6</ref>. We highlight the highest checkpoints and the speed-up by the CG-T5, which are discussed in Section 5.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Experimental Details</head><p>Main experiments. We present some implementation details in training and testing the baseline models in <ref type="table" target="#tab_13">Table 6</ref>. The detailed instructions for installing dependencies and all necessary training command-lines are shown in the instruction 'readme.md' files. The number of trainable model parameters are directly induced from either output of the frameworks or the original papers. We show some key hyper-parameters that we manually tuned on top of the development set.</p><p>All key hyper-parameters were initialized by the default values as suggested by the original authors of the frameworks. The bound of our manual tuning is done by iterating the magnitudes or the neighboring choices, for example, the learning rates ('lr') of the last seven models are selected from {1e − 3, . . . , 1e − 4, . . . , 1e − 5}. Then, similarly, the batch size (bsz) is first maximized by making full use of the GPU memory. Note that the first three models are implemented with the OpenNMT-py framework 6 .  BERT-gen, UniLM, UniLMv2 are all based on their official source code 10 . The GPT-2 and T5 are both adopted by the huggingface transformers 11 framework <ref type="bibr" target="#b40">(Wolf et al., 2019)</ref>. All models use beam searching as their decoding algorithms and beam-size are mostly 5, which is selected from {5, 10, 20}. All our models were trained on Quadro RTX 6000 GPUs. The training time of X-CopyNet and LevenTrans models are less than 12 hours with a single GPU. The second group of models are trained between 12 and 24 hours, expect for T5large, which we used 3 GPUs and fine-tuned about 48 hours. Note that all the above methods are self-contained in our submitted code as long as users follow the associated readme instructions.</p><p>Transferring study experiments. We use the same hyper-parameters which are searched over the baseline RoBERTa-Large model for these experiments. The best hyper-parameter 12 of RoBERTa-Large for CommonsenseQA 13 :</p><p>• batch size = 16, learning rate = 1e-5, • maximum updates = 3,000 (∼5 epochs) • warmup steps=150, dropout rate=0.1 • weight decay = 0.01, adam epsilon = 1e-6 We tried 10 random seeds and use the best one (42). Then, we follow the steps described in Sec. 5.3 to run other CG-enhanced models with the 10 https://github.com/microsoft/unilm 11 https://github.com/huggingface/ transformers <ref type="bibr">12</ref> We follow the hps selected by 100 trials of tuning in https://github.com/pytorch/fairseq/tree/ master/examples/roberta/commonsense_qa. 13 https://www.tau-nlp.org/commonsenseqa <ref type="figure">Figure 8</ref>: Our annotation interface on the AMT platform. The upper part is the instruction for the annotators and we provide an example for them. Note that we give the part-of-speech hints (from the captain corpora) to boost the speed of annotation, but we do not remove sentences with wrong part-of-speech as long as they also make sense.</p><p>(1) One-hop Relation Distribution</p><p>(2) Two-hop Relation Distribution <ref type="figure">Figure 9</ref>: One/two-hop relation frequency in the COMMONGEN dev.&amp;test sets on ConceptNet.</p><p>3. The woman gives the man who lays on the table a massage.</p><p>[Rationale]: Some massages are done laying down; people like to get massages;</p><p>tables are used for people to get massages; people lay on tables to get massages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>[Human references from AMT]</head><p>1) [Input concept-set]: { give, lay, massage, table } <ref type="figure">Figure 10</ref>: Four cases for qualitative analysis of machine generations. References are collected from AMT crowdworkers and they are required to provide rationales. Note that the third one is a positive case showing that some models can successfully generate reasonable scenarios. However, most models perform poorly on the other cases.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 :</head><label>3</label><figDesc>Dataset construction workflow overview.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 :</head><label>4</label><figDesc>The curve of inter-annotator agreement (IAA) in terms of their std (up) and median (bottom) when average number of references increase.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5 :</head><label>5</label><figDesc>Connectivity analysis in 5-size concept-sets in the test set, each of which consists of 10 concept pairs. For example, 12.0 in blue means: there are 12% concept-sets that have 3 concept pairs with one-hop connections on ConceptNet.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>[ bRNN -</head><label>bRNN</label><figDesc>CopyNet]: a hand works in the sink .[MeanPooling-CopyNet]: the hand of a sink being washed up [ConstLeven]: a hand strikes a sink to wash from his soap.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>The basic statistics of the COMMONGEN data.</figDesc><table><row><cell>We highlight the ratios of concept compositions that are</cell></row><row><cell>unseen in training data, which assures the challenge in</cell></row><row><cell>compositional generalization ability.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 :</head><label>2</label><figDesc>The distributions of the relation categories on one/two-hop connections.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3 :</head><label>3</label><figDesc>Experimental results of different baseline methods on the COMMONGEN test set (v1.1). The first group of models are non-pretrained models, while the second group is large pretrained models that we have fine-tuned.</figDesc><table /><note>The best models are bold and second best ones are underlined within each metric. We highlight the metrics that we used in our official leaderboard. (Results on dev set are at Table. 7.)</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 4 :</head><label>4</label><figDesc>Manual</figDesc><table /><note>Evaluation via Pair-wise Comparisons for Ranking. Numbers are hit rates (%) at top 1/3/5.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 5 :</head><label>5</label><figDesc>Experimental results of models with DBA decoding method on the test set.</figDesc><table><row><cell>ated by the T5-based CommonGen model (CG-T5)</cell></row><row><cell>helps speed up training about 2 times, if we look at</cell></row><row><cell>550th steps of CG-T5 (74.85%) and 1,250th steps</cell></row><row><cell>of original RoBERTa (74.77%).</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head></head><label></label><figDesc>ArXiv, abs/1904.04365.   Noam Chomsky. 1965. Aspects of the theory of syntax.Ernest Davis and Gary Marcus. 2015. Commonsense reasoning and commonsense knowledge in artificial intelligence. Commun. ACM, 58:92-103.</figDesc><table><row><cell>Chris Hokamp and Qun Liu. 2017. Lexically con-</cell></row><row><cell>strained decoding for sequence generation using grid</cell></row><row><cell>beam search. In Proceedings of the 55th Annual</cell></row><row><cell>Meeting of the Association for Computational Lin-</cell></row><row><cell>guistics (Volume 1: Long Papers), pages 1535-1546,</cell></row><row><cell>Vancouver, Canada. Association for Computational</cell></row><row><cell>Satanjeev Banerjee and Alon Lavie. 2005. METEOR: An automatic metric for MT evaluation with im-proved correlation with human judgments. In Pro-ceedings of the ACL Workshop on Intrinsic and Ex-trinsic Evaluation Measures for Machine Transla-tion and/or Summarization, pages 65-72, Ann Ar-bor, Michigan. Association for Computational Lin-guistics. Hangbo Bao, Li Dong, Furu Wei, Wenhui Wang, Nan Yang, Xiulei Liu, Yu Wang, Songhao Piao, Jian-feng Gao, Ming Zhou, and Hsiao-Wuen Hon. 2020. Unilmv2: Pseudo-masked language models for uni-fied language model pre-training. arXiv: Computa-tion and Language. Michael Chen, Mike D'Arcy, Alisa Liu, Jared Fernan-dez, and Doug Downey. 2019. Codah: An adversar-ially authored question-answer dataset for common Linguistics. Zhiting Hu, Zichao Yang, Xiaodan Liang, Ruslan Salakhutdinov, and Eric P Xing. 2017. Toward controlled generation of text. In Proceedings of the 34th International Conference on Machine Learning-Volume 70, pages 1587-1596. JMLR. org. Lifu Huang, Ronan Le Bras, Chandra Bhagavatula, and Yejin Choi. 2019. Cosmos QA: Machine reading comprehension with contextual commonsense rea-soning. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natu-ral Language Processing (EMNLP-IJCNLP), pages sense. Georgiana Dinu, Prashant Mathur, Marcello Federico, and Yaser Al-Onaizan. 2019. Training neural ma-chine translation to apply terminology constraints. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 3063-3068, Florence, Italy. Association for Compu-tational Linguistics. Li Dong, Nan Yang, Wenhui Wang, Furu Wei, Xi-aodong Liu, Yu Wang, Jianfeng Gao, Ming Zhou, and Hsiao-Wuen Hon. 2019. Unified language model pre-training for natural language understand-ing and generation. In Advances in Neural Informa-tion Processing Systems, pages 13042-13054. of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 889-898, Melbourne, Australia. Association for Computational Linguistics. Xiaocheng Feng, Ming Liu, Jiahao Liu, Bing Qin, Yibo Sun, and Ting Liu. 2018. Topic-to-essay generation with neural networks. In IJCAI, pages 4078-4084. Zhenxin Fu, Xiaoye Tan, Nanyun Peng, Dongyan Zhao, and Rui Yan. 2018. Style transfer in text: Explo-ration and evaluation. In Thirty-Second AAAI Con-ference on Artificial Intelligence. Jiatao Gu, Zhengdong Lu, Hang Li, and Victor O.K. Li. 2016. Incorporating copying mechanism in sequence-to-sequence learning. In Proceedings of the 54th Annual Meeting of the Association for Com-putational Linguistics (Volume 1: Long Papers), pages 1631-1640, Berlin, Germany. Association for Computational Linguistics. Jiatao Gu, Changhan Wang, and Junbo Zhao. 2019. Levenshtein transformer. In Advances in Neural In-formation Processing Systems, pages 11179-11189. Jian Guan, Yansen Wang, and Minlie Huang. 2019. Story ending generation with incremental encoding and commonsense knowledge. In Proceedings of the AAAI Conference on Artificial Intelligence, vol-ume 33, pages 6473-6480. Eva Hasler, Adrià de Gispert, Gonzalo Iglesias, and Bill Byrne. 2018. Neural machine translation decod-ing with terminology constraints. In Proceedings of the 2018 Conference of the North American Chap-ter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Pa-pers), pages 506-512, New Orleans, Louisiana. As-sociation for Computational Linguistics. 2391-2401, Hong Kong, China. Association for Angela Fan, Mike Lewis, and Yann Dauphin. 2018. Hi-erarchical neural story generation. In Proceedings Computational Linguistics.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 6 :</head><label>6</label><figDesc>The paths to the instruction files in our submitted code zip file (under the 'methods/ ' folder), and their numbers of parameters and key hyper-parameters.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head></head><label></label><figDesc>Training Steps RoBERTa-Large w/CG(BART) w/CG(T5) w/CG(UniLM) w/CG(BERT-Gen) w/CG(ConstLeven)</figDesc><table><row><cell>50</cell><cell>0.2252</cell><cell>0.1884</cell><cell>0.2506</cell><cell>0.2244</cell><cell>0.2007</cell><cell>0.2162</cell></row><row><cell>100</cell><cell>0.3088</cell><cell>0.2703</cell><cell>0.3587</cell><cell>0.3153</cell><cell>0.2924</cell><cell>0.2809</cell></row><row><cell>150</cell><cell>0.5053</cell><cell>0.2973</cell><cell>0.5643</cell><cell>0.1851</cell><cell>0.3391</cell><cell>0.3653</cell></row><row><cell>200</cell><cell>0.5717</cell><cell>0.4439</cell><cell>0.6650</cell><cell>0.3833</cell><cell>0.5274</cell><cell>0.5324</cell></row><row><cell>250</cell><cell>0.6020</cell><cell>0.5242</cell><cell>0.6937</cell><cell>0.5348</cell><cell>0.5839</cell><cell>0.6396</cell></row><row><cell>300</cell><cell>0.6388</cell><cell>0.6601</cell><cell>0.7117</cell><cell>0.6323</cell><cell>0.6274</cell><cell>0.6634</cell></row><row><cell>350</cell><cell>0.6675</cell><cell>0.6814</cell><cell>0.7150</cell><cell>0.6503</cell><cell>0.6626</cell><cell>0.6740</cell></row><row><cell>400</cell><cell>0.6830</cell><cell>0.6830</cell><cell>0.7215</cell><cell>0.6847</cell><cell>0.6781</cell><cell>0.6773</cell></row><row><cell>450</cell><cell>0.7027</cell><cell>0.7068</cell><cell>0.7338</cell><cell>0.6921</cell><cell>0.7068</cell><cell>0.6962</cell></row><row><cell>500</cell><cell>0.7019</cell><cell>0.7076</cell><cell>0.7428</cell><cell>0.7011</cell><cell>0.6929</cell><cell>0.7052</cell></row><row><cell>550</cell><cell>0.6978</cell><cell>0.7248</cell><cell>0.7486</cell><cell>0.7256</cell><cell>0.7068</cell><cell>0.6904</cell></row><row><cell>600</cell><cell>0.6790</cell><cell>0.7232</cell><cell>0.7494</cell><cell>0.7338</cell><cell>0.7248</cell><cell>0.7068</cell></row><row><cell>650</cell><cell>0.7150</cell><cell>0.7289</cell><cell>0.7428</cell><cell>0.7469</cell><cell>0.7101</cell><cell>0.7117</cell></row><row><cell>700</cell><cell>0.7142</cell><cell>0.7453</cell><cell>0.7477</cell><cell>0.7387</cell><cell>0.7305</cell><cell>0.7183</cell></row><row><cell>750</cell><cell>0.7027</cell><cell>0.7453</cell><cell>0.7314</cell><cell>0.7527</cell><cell>0.7166</cell><cell>0.7183</cell></row><row><cell>800</cell><cell>0.7158</cell><cell>0.7355</cell><cell>0.7437</cell><cell>0.7371</cell><cell>0.7281</cell><cell>0.7240</cell></row><row><cell>850</cell><cell>0.7174</cell><cell>0.7445</cell><cell>0.7625</cell><cell>0.7420</cell><cell>0.7379</cell><cell>0.7322</cell></row><row><cell>900</cell><cell>0.7191</cell><cell>0.7543</cell><cell>0.7559</cell><cell>0.7502</cell><cell>0.7477</cell><cell>0.7338</cell></row><row><cell>950</cell><cell>0.7355</cell><cell>0.7486</cell><cell>0.7477</cell><cell>0.7387</cell><cell>0.7428</cell><cell>0.7404</cell></row><row><cell>1000</cell><cell>0.7477</cell><cell>0.7510</cell><cell>0.7461</cell><cell>0.7486</cell><cell>0.7428</cell><cell>0.7363</cell></row><row><cell>1050</cell><cell>0.7346</cell><cell>0.7502</cell><cell>0.7568</cell><cell>0.7469</cell><cell>0.7412</cell><cell>0.7297</cell></row><row><cell>1100</cell><cell>0.7428</cell><cell>0.7527</cell><cell>0.7551</cell><cell>0.7494</cell><cell>0.7363</cell><cell>0.7420</cell></row><row><cell>1150</cell><cell>0.7379</cell><cell>0.7609</cell><cell>0.7576</cell><cell>0.7641</cell><cell>0.7453</cell><cell>0.7437</cell></row><row><cell>1200</cell><cell>0.7469</cell><cell>0.7477</cell><cell>0.7502</cell><cell>0.7461</cell><cell>0.7420</cell><cell>0.7477</cell></row><row><cell>1250</cell><cell>0.7477</cell><cell>0.7412</cell><cell>0.7592</cell><cell>0.7518</cell><cell>0.7273</cell><cell>0.7371</cell></row><row><cell>1300</cell><cell>0.7502</cell><cell>0.7518</cell><cell>0.7617</cell><cell>0.7666</cell><cell>0.7518</cell><cell>0.7412</cell></row><row><cell>1350</cell><cell>0.7469</cell><cell>0.7502</cell><cell>0.7551</cell><cell>0.7568</cell><cell>0.7437</cell><cell>0.7404</cell></row><row><cell>1400</cell><cell>0.7420</cell><cell>0.7494</cell><cell>0.7641</cell><cell>0.7559</cell><cell>0.7494</cell><cell>0.7428</cell></row><row><cell>1450</cell><cell>0.7510</cell><cell>0.7584</cell><cell>0.7625</cell><cell>0.7461</cell><cell>0.7461</cell><cell>0.7461</cell></row><row><cell>1500</cell><cell>0.7535</cell><cell>0.7674</cell><cell>0.7690</cell><cell>0.7551</cell><cell>0.7412</cell><cell>0.7428</cell></row><row><cell>1550</cell><cell>0.7461</cell><cell>0.7559</cell><cell>0.7674</cell><cell>0.7510</cell><cell>0.7445</cell><cell>0.7412</cell></row><row><cell>1600</cell><cell>0.7437</cell><cell>0.7584</cell><cell>0.7584</cell><cell>0.7543</cell><cell>0.7445</cell><cell>0.7420</cell></row><row><cell>1650</cell><cell>0.7568</cell><cell>0.7609</cell><cell>0.7633</cell><cell>0.7543</cell><cell>0.7494</cell><cell>0.7428</cell></row><row><cell>1700</cell><cell>0.7551</cell><cell>0.7584</cell><cell>0.7633</cell><cell>0.7625</cell><cell>0.7535</cell><cell>0.7396</cell></row><row><cell>1750</cell><cell>0.7600</cell><cell>0.7568</cell><cell>0.7699</cell><cell>0.7740</cell><cell>0.7551</cell><cell>0.7518</cell></row><row><cell>1800</cell><cell>0.7617</cell><cell>0.7559</cell><cell>0.7731</cell><cell>0.7740</cell><cell>0.7527</cell><cell>0.7486</cell></row><row><cell>1850</cell><cell>0.7690</cell><cell>0.7584</cell><cell>0.7772</cell><cell>0.7707</cell><cell>0.7617</cell><cell>0.7461</cell></row><row><cell>1900</cell><cell>0.7658</cell><cell>0.7592</cell><cell>0.7805</cell><cell>0.7838</cell><cell>0.7486</cell><cell>0.7445</cell></row><row><cell>1950</cell><cell>0.7584</cell><cell>0.7617</cell><cell>0.7715</cell><cell>0.7715</cell><cell>0.7510</cell><cell>0.7396</cell></row><row><cell>2000</cell><cell>0.7510</cell><cell>0.7617</cell><cell>0.7690</cell><cell>0.7715</cell><cell>0.7445</cell><cell>0.7355</cell></row><row><cell>2050</cell><cell>0.7551</cell><cell>0.7641</cell><cell>0.7731</cell><cell>0.7649</cell><cell>0.7559</cell><cell>0.7477</cell></row><row><cell>2100</cell><cell>0.7641</cell><cell>0.7617</cell><cell>0.7641</cell><cell>0.7625</cell><cell>0.7559</cell><cell>0.7412</cell></row><row><cell>2150</cell><cell>0.7584</cell><cell>0.7543</cell><cell>0.7658</cell><cell>0.7641</cell><cell>0.7527</cell><cell>0.7461</cell></row><row><cell>2200</cell><cell>0.7584</cell><cell>0.7477</cell><cell>0.7649</cell><cell>0.7633</cell><cell>0.7453</cell><cell>0.7371</cell></row><row><cell>2250</cell><cell>0.7551</cell><cell>0.7559</cell><cell>0.7641</cell><cell>0.7609</cell><cell>0.7461</cell><cell>0.7363</cell></row><row><cell>2300</cell><cell>0.7535</cell><cell>0.7600</cell><cell>0.7699</cell><cell>0.7674</cell><cell>0.7412</cell><cell>0.7420</cell></row><row><cell>2350</cell><cell>0.7551</cell><cell>0.7617</cell><cell>0.7682</cell><cell>0.7625</cell><cell>0.7502</cell><cell>0.7412</cell></row><row><cell>2400</cell><cell>0.7559</cell><cell>0.7649</cell><cell>0.7699</cell><cell>0.7625</cell><cell>0.7559</cell><cell>0.7387</cell></row><row><cell>2450</cell><cell>0.7584</cell><cell>0.7674</cell><cell>0.7707</cell><cell>0.7658</cell><cell>0.7477</cell><cell>0.7387</cell></row><row><cell>2500</cell><cell>0.7551</cell><cell>0.7649</cell><cell>0.7600</cell><cell>0.7633</cell><cell>0.7502</cell><cell>0.7363</cell></row><row><cell>2550</cell><cell>0.7592</cell><cell>0.7658</cell><cell>0.7731</cell><cell>0.7658</cell><cell>0.7518</cell><cell>0.7387</cell></row><row><cell>2600</cell><cell>0.7559</cell><cell>0.7658</cell><cell>0.7715</cell><cell>0.7600</cell><cell>0.7420</cell><cell>0.7371</cell></row><row><cell>2650</cell><cell>0.7576</cell><cell>0.7674</cell><cell>0.7690</cell><cell>0.7600</cell><cell>0.7494</cell><cell>0.7420</cell></row><row><cell>2700</cell><cell>0.7568</cell><cell>0.7707</cell><cell>0.7690</cell><cell>0.7600</cell><cell>0.7461</cell><cell>0.7379</cell></row><row><cell>2750</cell><cell>0.7568</cell><cell>0.7699</cell><cell>0.7674</cell><cell>0.7649</cell><cell>0.7445</cell><cell>0.7437</cell></row><row><cell>2800</cell><cell>0.7592</cell><cell>0.7682</cell><cell>0.7690</cell><cell>0.7617</cell><cell>0.7445</cell><cell>0.7453</cell></row><row><cell>2850</cell><cell>0.7592</cell><cell>0.7641</cell><cell>0.7707</cell><cell>0.7649</cell><cell>0.7461</cell><cell>0.7445</cell></row><row><cell>2900</cell><cell>0.7609</cell><cell>0.7649</cell><cell>0.7740</cell><cell>0.7658</cell><cell>0.7477</cell><cell>0.7437</cell></row><row><cell>2950</cell><cell>0.7617</cell><cell>0.7649</cell><cell>0.7740</cell><cell>0.7658</cell><cell>0.7469</cell><cell>0.7437</cell></row><row><cell>3000</cell><cell>0.7600</cell><cell>0.7658</cell><cell>0.7731</cell><cell>0.7658</cell><cell>0.7437</cell><cell>0.7420</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 8 :</head><label>8</label><figDesc>Experimental results of the transferring study on CommonsenseQA dev set.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">http://inklab.usc.edu/CommonGen/. arXiv:1911.03705v4 [cs.CL] 30 Nov 2020</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">https://github.com/microsoft/unilm 4 The used hyper-parameters are reported in the appendix.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Spice: Semantic propositional image caption evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Basura</forename><surname>Fernando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Gould</surname></persName>
		</author>
		<idno type="DOI">https:/link.springer.com/chapter/10.1007/978-3-319-46454-1_24</idno>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="382" to="398" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Set to ordered text: Generating discharge instructions from medical billing codes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Litton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nancy</forename><surname>Kurisinkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1638</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6165" to="6175" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Measuring compositional generalization: A comprehensive method on realistic data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Keysers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathanael</forename><surname>Schärli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Scales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hylke</forename><surname>Buisman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Furrer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergii</forename><surname>Kashubin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikola</forename><surname>Momchev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danila</forename><surname>Sinopalnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Stafiniak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tibor</forename><surname>Tihon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Tsarkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Marc Van Zee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bousquet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">OpenNMT: Opensource toolkit for neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuntian</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Senellart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Rush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL 2017, System Demonstrations</title>
		<meeting>ACL 2017, System Demonstrations<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="67" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Dense-captioning events in videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ranjay</forename><surname>Krishna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenji</forename><surname>Hata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frederic</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juan</forename><forename type="middle">Carlos</forename><surname>Niebles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="706" to="715" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Generalization without systematicity: On the compositional skills of sequence-to-sequence recurrent networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brenden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Lake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Baroni</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Deterministic non-autoregressive neural sequence modeling by iterative refinement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elman</forename><surname>Mansimov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1149</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1173" to="1182" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naman</forename><surname>Goyal ; Abdelrahman Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ves</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno>abs/1910.13461</idno>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ArXiv</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Delete, retrieve, generate: a simple approach to sentiment and style transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juncen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robin</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">He</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N18-1169</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>New Orleans, Louisiana</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1865" to="1874" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Commonsense knowledge base completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aynaz</forename><surname>Taheri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lifu</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P16-1137</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1445" to="1455" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Mining cross-cultural differences and similarities in social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><forename type="middle">F</forename><surname>Bill Yuchen Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenny</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seungwon</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hwang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P18-1066</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="709" to="719" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">ROUGE: A package for automatic evaluation of summaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Text Summarization Branches Out</title>
		<meeting><address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="74" to="81" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Microsoft coco: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
		<idno type="DOI">https:/link.springer.com/chapter/10.1007/978-3-319-10602-1_48</idno>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="740" to="755" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Neural baby talk</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiasen</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianwei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Parikh</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2018.00754</idno>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting><address><addrLine>Salt Lake City, UT, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2018-06-18" />
			<biblScope unit="page" from="7219" to="7228" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Towards fine-grained text sentiment transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fuli</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengcheng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutong</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baobao</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifang</forename><surname>Sui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Sun</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1194</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2013" to="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">A dual reinforcement learning framework for unsupervised text style transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fuli</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengcheng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baobao</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifang</forename><surname>Sui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.10060</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Effective approaches to attention-based neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D15-1166</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1412" to="1421" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Cgmh: Constrained sentence generation by metropolis-hastings sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ning</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lili</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="6834" to="6842" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">The development of commonsense psychology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Moore</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>Psychology Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Bleu: a method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Jing</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="DOI">10.3115/1073083.1073135</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 40th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Philadelphia, Pennsylvania, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Fast lexically constrained decoding with dynamic beam allocation for neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Vilar</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N18-1119</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Long Papers; New Orleans, Louisiana</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1314" to="1324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Transition-based deep input linearization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ratish</forename><surname>Puduppully</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manish</forename><surname>Shrivastava</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 15th Conference of the European Chapter of the Association for Computational Linguistics<address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="643" to="654" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Language models are unsupervised multitask learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katherine</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanqi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter J</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.10683</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Sentence-BERT: Sentence embeddings using Siamese BERTnetworks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nils</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1410</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3982" to="3992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Movie description</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Atousa</forename><surname>Torabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcus</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niket</forename><surname>Tandon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
		<idno type="DOI">https:/link.springer.com/article/10.1007/s11263-016-0987-1</idno>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">123</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="94" to="120" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Winogrande: An adversarial winograd schema challenge at scale. ArXiv, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keisuke</forename><surname>Sakaguchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Ronan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chandra</forename><surname>Bras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Bhagavatula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Choi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1907" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Atomic: An atlas of machine commonsense for if-then reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maarten</forename><surname>Sap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><surname>Ronan Le Bras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chandra</forename><surname>Allaway</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Bhagavatula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannah</forename><surname>Lourie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brendan</forename><surname>Rashkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Roof</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Noah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="3027" to="3035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Social IQa: Commonsense reasoning about social interactions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maarten</forename><surname>Sap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannah</forename><surname>Rashkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Derek</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Ronan Le Bras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Choi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1454</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4463" to="4473" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Conceptual captions: A cleaned, hypernymed, image alt-text dataset for automatic image captioning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piyush</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Soricut</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P18-1238</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2556" to="2565" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Conceptnet 5.5: An open multilingual graph of general knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robyn</forename><surname>Speer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><surname>Chin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Catherine</forename><surname>Havasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-First AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Insertion transformer: Flexible sequence generation via insertion operations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitchell</forename><surname>Stern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.03249</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Lexically constrained neural machine translation with levenshtein transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond Hendy</forename><surname>Susanto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shamil</forename><surname>Chollampatt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Ling Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note>To appear</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">CommonsenseQA: A question answering challenge targeting commonsense knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Talmor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Herzig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Lourie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1421</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Long and Short Papers</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4149" to="4158" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Some beginnings of word comprehension in 6-month-olds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruth</forename><surname>Tincoff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jusczyk</surname></persName>
		</author>
		<idno type="DOI">https:/journals.sagepub.com/doi/abs/10.1111/1467-9280.00127</idno>
	</analytic>
	<monogr>
		<title level="j">Psychological science</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="172" to="175" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Łukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Cider: Consensus-based image description evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramakrishna</forename><surname>Vedantam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Parikh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="4566" to="4575" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">SemEval-2020 task 4: Commonsense validation and explanation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cunxiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuailong</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yili</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yilong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 14th International Workshop on Semantic Evaluation. Association for Computational Linguistics</title>
		<meeting>The 14th International Workshop on Semantic Evaluation. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Does it make sense? and why? a pilot study for sense making and explanation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cunxiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuailong</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaonan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tian</forename><surname>Gao</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1393</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4020" to="4026" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Vatex: A large-scale, high-quality multilingual dataset for video-and-language research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junkun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan-Fang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">Yang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4581" to="4591" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Huggingface&apos;s transformers: State-of-the-art natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lysandre</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clement</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierric</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R&amp;apos;emi</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Morgan</forename><surname>Funtowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Brew</surname></persName>
		</author>
		<idno>abs/1910.03771</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Automatic extraction of commonsense LocatedNear knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><forename type="middle">Yuchen</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenny</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P18-2016</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="96" to="101" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Enhancing topic-to-essay generation with external commonsense knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengcheng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fuli</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Sun</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1193</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2002" to="2012" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Knowledgeable storyteller: a commonsense-driven generative model for visual storytelling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengcheng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fuli</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyi</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence</title>
		<meeting>the Twenty-Eighth International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5356" to="5362" />
		</imprint>
	</monogr>
	<note>Xiaodong He, and Xu Sun</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Planand-write: Towards better automatic storytelling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lili</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nanyun</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Weischedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongyan</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="7378" to="7385" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alice</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Micah</forename><surname>Hodosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julia</forename><surname>Hockenmaier</surname></persName>
		</author>
		<idno type="DOI">https:/www.mitpressjournals.org/doi/abs/10.1162/tacl_a_00166</idno>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="67" to="78" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">From recognition to cognition: Visual commonsense reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rowan</forename><surname>Zellers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonatan</forename><surname>Bisk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6720" to="6731" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">SWAG: A large-scale adversarial dataset for grounded commonsense inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rowan</forename><surname>Zellers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonatan</forename><surname>Bisk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1009</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="93" to="104" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">HellaSwag: Can a machine really finish your sentence?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rowan</forename><surname>Zellers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ari</forename><surname>Holtzman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonatan</forename><surname>Bisk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1472</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4791" to="4800" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Grounded conversation generation as guided traverses in commonsense knowledge graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Houyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenghao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenyan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note>To appear</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">bertscore: Evaluating text generation with bert</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Varsha</forename><surname>Kishore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Artzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Discriminative syntax-based word ordering for text generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
		<idno type="DOI">https:/www.mitpressjournals.org/doi/10.1162/COLI_a_00229</idno>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="503" to="538" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanrong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiting</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>Text infilling. ArXiv, abs/1901.00158</note>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">ROUGE-2/L BLEU-3/4 METEOR CIDEr SPICE Coverage bRNN-CopyNet</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Leventrans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gu</surname></persName>
		</author>
		<idno>12.22 35.42 23.10 15.00 22.10 8.94 21.40 71.83</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Constleven</forename><surname>Susanto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gpt-2 (radford</surname></persName>
		</author>
		<idno>17.74 41.24 32.70 23.30</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">(</forename><surname>Bert-Gen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bao</surname></persName>
		</author>
		<idno>18.73 42.36 33.00 23.70 29.10 13.34 28.70 91.71</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">(</forename><surname>Unilm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dong</surname></persName>
		</author>
		<idno>21.68 45.66 40.40 30.40</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Unilm-V2 (</forename><surname>Bao</surname></persName>
		</author>
		<idno>19.24 43.01 33.40 24.20</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bart (lewis</surname></persName>
		</author>
		<idno>22.13 43.02 37.00 27.50</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>T5-Base ; Raffel</surname></persName>
		</author>
		<idno>36.20 28.10 18.00</idno>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page">15</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>T5-Large ; Raffel</surname></persName>
		</author>
		<idno>21.98 44.41 40.80 30.60</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">Experimental results of different baseline methods on the COMMONGEN dev set. The first group of models are non-pretrained models, while the second group is large pretrained models that we have fine-tuned. The best models are bold and second best ones are underlined within each metric</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Someone lowers his horse from the wall and lasso glass by cows</title>
	</analytic>
	<monogr>
		<title level="m">A horse having lasso in the bridal cows</title>
		<imprint/>
	</monogr>
	<note>MP-CpNet. Cow in a lasso getting the ride</note>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Rationale]: cowboys ride horses and lasso cows for a living 2. A cowboy can use a lasso to control a horse or cow in order to ride them. [Rationale]: I understand the words and I can read and write English. 3. The cowboy will lasso the cow while riding on the horse</title>
	</analytic>
	<monogr>
		<title level="m">Have seen it</title>
		<imprint/>
	</monogr>
	<note>Human references from AMT</note>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
			</analytic>
	<monogr>
		<title level="m">Process of holds at hands under walk on hours</title>
		<meeting>ess of holds at hands under walk on hours</meeting>
		<imprint/>
	</monogr>
	<note>Hands with a walk in the water. MP-CpNet]: Walk across the hold to water. [LevenTrans]: Hand moored at the water. [GPT-2</note>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
				<title level="m">A man walking and holding a hand in water while walking</title>
		<imprint/>
	</monogr>
	<note>A man is walking and holding a hand in the water</note>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">A man walks with a woman holding her hand as they walk through water</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Couples hold hands when taking walk even by a body of water. 2. The girl is walking holding in her hand a bottle of water</title>
	</analytic>
	<monogr>
		<title level="m">The couple holds hands as they walk by the water</title>
		<imprint/>
	</monogr>
	<note>I see this reading the words 3. The couple hold hands while they walk by the water. [Rationale]: People sometimes hold hands. People Like to walk near water. Human references from AMT</note>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">The window stands out a ladder but clean the sun to being squeegee</title>
	</analytic>
	<monogr>
		<title level="m">{ hand, hold, walk, water }</title>
		<imprint/>
	</monogr>
	<note>Input concept-set. bRNN-CpNet. A brown leather ladder with green eyes</note>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Someone grabs a ladder from a window and squeezes it open</title>
	</analytic>
	<monogr>
		<title level="m">A woman is cleaning a window with a ladder and a squeegee</title>
		<imprint/>
	</monogr>
	<note>GPT-2. BERT-Gen</note>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
				<title level="m">Someone stands next to a window and stands on a ladder to clean the squeegee</title>
		<imprint/>
	</monogr>
	<note>UniLM-v2]: A man is standing on a ladder and using a ladder to clean the window</note>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">A squeegee is a tool to clean windows. A ladder is something that people use to reach high places. 2. The man clean the window on the ladder stand by using squeegee. [Rationale]: man need to clean the window by using squeegee on the ladder stand 3. The man stood beside the ladder and cleaned the window with a squeegee</title>
	</analytic>
	<monogr>
		<title level="m">A man with a squeegee and a ladder standing on the ledge of a window is cleaning the window</title>
		<imprint/>
	</monogr>
	<note>Machine generations] 1. The window cleaner stands on the ladder to clean the window with a squeegee. Rationale]: people can stand next to ladders. People clean windows. Squeegees are used to clean windows. Human references from AMT</note>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">A massage table being calling with an improvisation lay free speaker</title>
	</analytic>
	<monogr>
		<title level="m">Lays massage someone table vertical gives on and the water. [Trans-CpNet]: Massage lays on the kitchen</title>
		<imprint/>
	</monogr>
	<note>Input concept-set. bRNN-CpNet. MP-CpNet. A man chatting at the table. [GPT-2]: A man gives a massage to a table</note>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
				<title level="m">A woman lays down on a table and gives a massage to a man</title>
		<imprint/>
	</monogr>
	<note>BERT-Gen</note>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">A woman lays down a massage on a table and gives a massage</title>
	</analytic>
	<monogr>
		<title level="m">A woman is laying down and giving a massage on a table</title>
		<imprint/>
	</monogr>
	<note>UniLM-v2</note>
</biblStruct>

<biblStruct xml:id="b77">
	<monogr>
				<title level="m">A man lays on a table and gives a massage to a woman laying on the table</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
		<title level="m" type="main">The man must lay down to receive a massage. The therapist is the giver of massages</title>
		<imprint/>
	</monogr>
	<note>The man lays down on the massage table and the therapist gives him a massage. The table is a massage table</note>
</biblStruct>

<biblStruct xml:id="b79">
	<monogr>
		<title level="m" type="main">Lay down on the table and the masseuse will give you a neck massage</title>
		<imprint/>
	</monogr>
	<note>A masseuse is a woman who gives massages professionally. Massages are usually done on tables</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
