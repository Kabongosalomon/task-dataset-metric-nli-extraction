<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Smooth-AP: Smoothing the Path Towards Large-Scale Image Retrieval</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Brown</surname></persName>
							<email>abrown@robots.ox.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Visual Geometry Group</orgName>
								<orgName type="institution">University of Oxford</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weidi</forename><surname>Xie</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Visual Geometry Group</orgName>
								<orgName type="institution">University of Oxford</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vicky</forename><surname>Kalogeiton</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Visual Geometry Group</orgName>
								<orgName type="institution">University of Oxford</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Visual Geometry Group</orgName>
								<orgName type="institution">University of Oxford</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Smooth-AP: Smoothing the Path Towards Large-Scale Image Retrieval</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T07:23+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Optimising a ranking-based metric, such as Average Precision (AP), is notoriously challenging due to the fact that it is nondifferentiable, and hence cannot be optimised directly using gradientdescent methods. To this end, we introduce an objective that optimises instead a smoothed approximation of AP, coined Smooth-AP. Smooth-AP is a plug-and-play objective function that allows for end-to-end training of deep networks with a simple and elegant implementation. We also present an analysis for why directly optimising the ranking based metric of AP offers benefits over other deep metric learning losses. We apply Smooth-AP to standard retrieval benchmarks : Stanford Online products and VehicleID, and also evaluate on larger-scale datasets: INaturalist for fine-grained category retrieval, and VGGFace2 and IJB-C for face retrieval. In all cases, we improve the performance over the state-of-the-art, especially for larger-scale datasets, thus demonstrating the effectiveness and scalability of Smooth-AP to real-world scenarios.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Our objective in this paper is to improve the performance of 'query by example', where the task is: given a query image, rank all the instances in a retrieval set according to their relevance to the query. For instance, imagine that you have a photo of a friend or family member, and want to search for all of the images of that person within your large smart-phone image collection; or on a photo licensing site, you want to find all photos of a particular building or object, starting from a single photo. These use cases, where high recall is premium, differ from the 'Google Lens' application of identifying an object from an image, where only one 'hit' (match) is sufficient.</p><p>The benchmark metric for retrieval quality is Average Precision (AP) (or its generalized variant, Normalized Discounted Cumulative Gain, which includes non-binary relevance judgements). With the resurgence of deep neural networks, end-to-end training has become the de facto choice for solving specific vision tasks with well-defined metrics. However, the core problem with AP and similar metrics is that they include a discrete ranking function that is neither differentiable nor decomposable. Consequently, their direct optimization, e.g. with gradient-descent methods, is notoriously difficult. In this paper, we introduce a novel differentiable AP approximation, Smooth-AP, that allows end-to-end training of deep networks for ranking-based tasks.</p><p>Smooth-AP is a simple, elegant, and scalable method that takes the form of a plug-and-play objective function by relaxing the Indicator function in the non-differentiable AP with a sigmoid function. To demonstrate its effectiveness, we perform experiments on two commonly used image retrieval benchmarks, Stanford Online Products and VehicleID, where Smooth-AP outperforms all recent AP approximation approaches <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b53">54]</ref> as well as recent deep metric learning methods. We also experiment on three further large-scale retrieval datasets (VG-GFace2, IJB-C, INaturalist), which are orders of magnitude larger than the existing retrieval benchmarks. To our knowledge, this is the first work that demonstrates the possibility of training networks for AP on datasets with millions of images for the task of image retrieval. We show large performance gains over all recently proposed AP approximating approaches and, somewhat surprisingly, also outperform strong verification systems <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b35">36]</ref> by a significant margin, reflecting the fact that metric learning approaches are indeed inefficient for training large-scale retrieval systems that are measured by global ranking metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>As an essential component of information retrieval <ref type="bibr" target="#b37">[38]</ref>, algorithms that optimize rank-based metrics have been the focus of extensive research over the years. In general, the previous approaches can be split into two lines of research, namely metric learning, and direct approximation of Average Precision.</p><p>Image Retrieval. This is one of the most researched topics in the vision community. Several themes have been explored in the literature, for example, one theme is on the speed of retrieval and explores methods of approximate nearest neighbors <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b59">60]</ref>. Another theme is on how to obtain a compact image descriptor for retrieval in order to reduce the memory footprint. Descriptors were typically constructed through an aggregation of local features, such as Fisher vectors <ref type="bibr" target="#b45">[46]</ref> and VLAD <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b29">30]</ref>. More recently, neural networks have made impressive progress on learning representations for image retrieval <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b68">69]</ref>, but common to all is the choice of the loss function used for training; in particular, it should ideally be a loss that will encourage good ranking.</p><p>Metric Learning. To avoid the difficulties from directly optimising rank-based metrics, such as Average Precision, there is a great body of work that focuses on metric learning <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b51">52,</ref><ref type="bibr" target="#b63">64,</ref><ref type="bibr" target="#b69">70,</ref><ref type="bibr" target="#b72">73]</ref>. For instance, the contrastive <ref type="bibr" target="#b11">[12]</ref> and triplet <ref type="bibr" target="#b72">[73]</ref> losses, which consider pairs or triplets of elements, and force all positive instances to be close in the high-dimensional embedding space, while separating negatives by a fixed distance (margin). However, due to the limited rank-positional awareness that a pair/triplet provides, a model is likely to waste capacity on improving the order of positive instances at low (poor) ranks at the expense of those at high ranks, as was pointed out by Burges et al. <ref type="bibr" target="#b3">[4]</ref>. Of more relevance, the list-wise approaches <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b69">70]</ref> look at many examples from the retrieval set, and have been proven to improve training efficiency and performance. Despite being successful, one drawback of metric learning approaches is that they are mostly driven by minimizing distances, and therefore remain ignorant of the importance of shifting ranking orders -the latter is essential when evaluating with a rank-based metric.</p><p>Optimizing Average Precision (AP). The trend of directly optimising the non-differentiable AP has been recently revived in the retrieval community. Sophisticated methods <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b60">61,</ref><ref type="bibr" target="#b62">63,</ref><ref type="bibr" target="#b63">64,</ref><ref type="bibr" target="#b75">76,</ref><ref type="bibr" target="#b77">78]</ref> have been developed to overcome the challenge of non-decomposability and non-differentiability in optimizing AP. Methods include: creating a distribution over rankings by treating each relevance score as a Gaussian random variable <ref type="bibr" target="#b62">[63]</ref>, loss-augmented inference <ref type="bibr" target="#b39">[40]</ref>, direct loss minimization <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b60">61]</ref>, optimizing a smooth and differentiable upper bound of AP <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b77">78]</ref>, training a LSTM to approximate the discrete ranking step <ref type="bibr" target="#b15">[16]</ref>, differentiable histogram binning <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b63">64]</ref>, error driven update schemes <ref type="bibr" target="#b10">[11]</ref>, and the very recent blackbox optimization <ref type="bibr" target="#b53">[54]</ref>. Significant progress on optimizing AP was made by the information retrieval community <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b62">63]</ref>, but the methods have largely been ignored by the vision community, possibly because they have never been demonstrated on largescale image retrieval or due to the complexity of the proposed smooth objectives. One of the motivations of this work is to show that with the progress of deep learning research, e.g. auto-differentiation, better optimization techniques, largescale datasets, and fast computation devices, it is possible and in fact very easy to directly optimize a close approximation to AP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Background</head><p>In this section, we define the notations used throughout the paper.</p><p>Task definition. Given an input query, the goal of a retrieval system is to rank all instances in a retrieval set Ω = {I i , i = 0, · · · , m} based on their relevance to the query. For each query instance I q , the retrieval set is split into the positive P q and negative N q sets, which are formed by all instances of the same class and of different classes, respectively. Note that there is a different positive and negative set for each query.</p><p>Average Precision (AP). AP is one of the standard metrics for information retrieval tasks <ref type="bibr" target="#b37">[38]</ref>. It is a single value defined as the area under a Precision-Recall curve. For a query I q , the predicted relevance scores of all instances in the retrieval set are measured via a chosen metric. In our case, we use the cosine similarity (though the Smooth-AP method is independent of this choice):</p><formula xml:id="formula_0">S Ω = s i = v q v q · v i v i , i = 0, · · · , n ,<label>(1)</label></formula><p>where S Ω = S P ∪ S N , and S P = {s ζ , ∀ζ ∈ P q }, S N = {s ξ , ∀ξ ∈ N q } are the positive and negative relevance score sets, respectively, v q refers to the query vector, and v i to the vectorized retrieval set. The AP of a query I q can be computed as:</p><formula xml:id="formula_1">AP q = 1 |S P | i∈S P R(i, S P ) R(i, S Ω ) ,<label>(2)</label></formula><p>where R(i, S P ) and R(i, S Ω ) refer to the rankings of the instance i in P and Ω, respectively. Note that, the rankings referred to in this paper are assumed to be proper rankings, meaning no two samples are ranked equally.</p><p>Ranking Function (R). Given that AP is a ranking-based method, the key element for direct optimisation is to define the ranking R of one instance i. Here, we define it in the following way <ref type="bibr" target="#b49">[50]</ref>:</p><formula xml:id="formula_2">R(i, S) = 1 + j∈S,j =i 1{(s i − s j ) &lt; 0},<label>(3)</label></formula><p>where 1{·} acts as an Indicator function, and S any set, e.g. Ω. Conveniently, this can be implemented by computing a difference matrix D ∈ R m×m : The exact AP for a query instance I q from Eq. 2 becomes:</p><formula xml:id="formula_3">D =    s 1 . . . s m . . . . . . . . . s 1 . . . s m    −    s 1 . . . s 1 . . . . . . . . .</formula><formula xml:id="formula_4">AP q = 1 |S P | i∈S P 1 + j∈Sp,j =i 1{D ij &gt; 0} 1 + j∈S P ,j =i 1{D ij &gt; 0} + j∈S N 1{D ij &gt; 0}<label>(5)</label></formula><p>Derivatives of Indicator. The particular Indicator function used in computing AP is a Heaviside step function H(·) <ref type="bibr" target="#b49">[50]</ref>, with its distributional derivative defined as Dirac delta function:</p><formula xml:id="formula_5">dH(x) dx = δ(x),</formula><p>This is either flat everywhere, with zero gradient, or discontinuous, and hence cannot be optimized with gradient based methods ( <ref type="figure" target="#fig_1">Figure 2</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Approximating Average Precision (AP)</head><p>As explained, AP and similar metrics include a discrete ranking function that is neither differentiable nor decomposable. In this section, we first describe Smooth-AP, which essentially replaces the discrete indicator function with a sigmoid function, and then we provide an analysis on its relation to other ranking losses, such as triplet loss <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b72">73]</ref>, FastAP <ref type="bibr" target="#b4">[5]</ref> and Blackbox AP <ref type="bibr" target="#b53">[54]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Smoothing AP</head><p>To smooth the ranking procedure, which will enable direct optimization of AP, Smooth-AP takes a simple solution which is to replace the Indicator function 1{·} by a sigmoid function G(·; τ ), where the τ refers to the temperature adjusting the sharpness:</p><formula xml:id="formula_6">G(x; τ ) = 1 1 + e −x τ .<label>(6)</label></formula><p>Substituting G(·; τ ) into Eq. 5, the true AP can be approximated as:</p><formula xml:id="formula_7">AP q ≈ 1 |S P | i∈S P 1 + j∈S P G(D ij ; τ ) 1 + j∈S P G(D ij ; τ ) + j∈S N G(D ij ; τ )</formula><p>with tighter approximation and convergence to the indicator function as τ → 0. The objective function during optimization is denoted as:</p><formula xml:id="formula_8">L AP = 1 m m k=1 (1 − AP k )<label>(7)</label></formula><p>Smoothing parameter τ governs the temperature of the sigmoid that replaces the Indicator function 1{·}. It defines an operating region, where terms of the difference matrix are given a gradient by the Smooth-AP loss. If the terms are mis-ranked, Smooth-AP will attempt to shift them to the correct order. Specifically, a small value of τ results in a small operating region <ref type="figure" target="#fig_1">(Figure 2</ref> (b) -note the small region with gradient seen in the sigmoid derivative), and a tighter approximation of true AP. The strong acceleration in gradient around the zero point ( <ref type="figure" target="#fig_1">Figure 2</ref> (b)-(c) second row) is essential to replicating the desired qualities of AP, as it encourages the shifting of instances in the embedding space that result in a change of rank (and hence change in AP), rather than shifting instances by some large distance but not changing the rank. A large value of τ offers a large operating region, however, at the cost of a looser approximation to AP due to its divergence from the indicator function.</p><p>Relation to Triplet Loss. Here, we demonstrate that the triplet loss (a popular surrogate loss for ranking) is in fact optimising a distance metric rather than a ranking metric, which is sub-optimal when evaluating using a ranking metric. As shown in Eq. 5, the goal of optimizing AP is equivalent to minimizing all the i∈S P ,j∈S N 1{D ij &lt; 0}, i.e. the violating terms. We term these as such because these terms refer to cases where a negative instance is ranked above a positive instance in terms of relevance to the query, and optimal AP is only acquired when all positive instances are ranked above all negative instances.</p><p>For example, consider one query instance with predicted relevance score and ground-truth relevance labels as:</p><p>Instances ordered by score : (s 0 s 4 s 1 s 2 s 5 s 6 s 7 s 3 ) Ground truth labels : (1 0 1 1 0 0 0 1) the violating terms are:</p><formula xml:id="formula_9">{(s 4 −s 1 ), (s 4 −s 2 ), (s 4 −s 3 ), (s 5 −s 3 ), (s 6 −s 3 ), (s 7 −s 3 )}.</formula><p>An ideal AP loss would actually treat each of the terms unequally, i.e. the model would be forced to spend more capacity on shifting orders between s 4 and s 1 , rather than s 3 and s 7 , as that makes a larger impact on improving the AP.</p><p>Another interpretation of these violating cases can also be drawn from the triplet loss perspective. Specifically, if we treat the query instance as an "anchor", with s j denoting the similarity between the "anchor" and negative instance, and s i denoting the similarity between the "anchor" and positive instance. In this example, the triplet loss tries to optimize a margin hinge loss:</p><formula xml:id="formula_10">L triplet = max(s 4 − s 1 + α, 0) + max(s 4 − s 2 + α, 0) + max(s 4 − s 3 + α, 0) + max(s 5 − s 3 + α, 0) + max(s 6 − s 3 + α, 0) + max(s 7 − s 3 + α, 0)</formula><p>This can be viewed as a differentiable approximation to the goal of optimizing AP where the Indicator function has been replaced with the margin hinge loss, thus solving the gradient problem. Nevertheless, using a triplet loss to approximate AP may suffer from two problems: First, all terms are linearly combined and treated equally in L triplet . Such a surrogate loss may force the model to optimize the terms that have only a small effect on AP, e.g. optimizing s 4 − s 1 is the same as s 7 − s 4 in the triplet loss, however, from an AP perspective, it is important to correct the mis-ordered instances at high rank. Second, the linear derivative means that the optimization process is purely based on distance (not ranking orders), which makes it sub-optimal when evaluating AP. For instance, in the triplet loss case, reducing the distance s 4 − s 1 from 0.8 to 0.5 is the same as from 0.2 to −0.1. In practise, however, the latter case (shifting orders) will clearly have a much larger impact on the AP computation than the former. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental Setup</head><p>In this section, we describe the datasets used for evaluation, the test protocols, and the implementation details. The procedure followed here is to take a pre-trained network and fine-tune with Smooth-AP loss. Specifically, ImageNet pretrained networks are used for the object/animal retrieval datasets, and highperforming face-verification models for the face retrieval datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Datasets</head><p>We evaluate the Smooth-AP loss on five datasets containing a wide range of domains and sizes. These include the commonly used retrieval benchmark datasets, as well as several additional large-scale (&gt;100K images) datasets. <ref type="table" target="#tab_0">Table 1</ref> describes their details.</p><p>Stanford Online Product (SOP) <ref type="bibr" target="#b60">[61]</ref> was initially collected for investigating the problem of metric learning. It includes 120K images of products that were sold online. We use the same evaluation protocol and train/test split as <ref type="bibr" target="#b69">[70]</ref>.</p><p>VehicleID <ref type="bibr" target="#b66">[67]</ref> contains 221, 736 images of 26, 267 vehicle categories, 13, 134 of which are used for training (containing 110, 178 images). By following the same test protocol as <ref type="bibr" target="#b66">[67]</ref>, three test sets of increasing size are used for evaluation (termed small, medium, large), which contain 800 classes (7, 332 images), 1600 classes (12, 995 images) and 2400 classes (20, 038 images) respectively.</p><p>INaturalist <ref type="bibr" target="#b64">[65]</ref> is a large-scale animal and plant species classification dataset, designed to replicate real-world scenarios through 461,939 images from 8,142 classes. It features many visually similar species, captured in a wide variety of environments. We construct a new image retrieval task from this dataset, by keeping 5,690 classes for training, and 2,452 unseen classes for evaluating image retrieval at test time, according to the same test protocols as existing benchmarks <ref type="bibr" target="#b69">[70]</ref>. We will make the train/test splits publicly available.</p><p>VGGFace2 <ref type="bibr" target="#b6">[7]</ref> is a large-scale face dataset with over 3.31 million images of 9, 131 subjects. The images have large variations in pose, age, illumination, ethnicity and profession, e.g. actors, athletes, politicians. For training, we use the pre-defined training set with 8, 631 identities, and for testing we use the test set with 500 identities, totalling 169K testing images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IJB-C [39]</head><p>is a challenging public benchmark for face recognition, containing images of subjects from both still frames and videos. Each video is treated as a single instance by averaging the CNN-produced vectors for each frame to a single vector. Identities with less than 5 instances (images or videos) are removed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Test Protocol</head><p>Here, we describe the protocols for evaluating retrieval performance, mean Average Precision (mAP) and Recall@K (R@K). For all datasets, every instance of each class is used in turn as the query I q , and the retrieval set Ω is formed out of all the remaining instances. We ensure that each class in all datasets contains several images ( <ref type="table" target="#tab_0">Table 1)</ref>, such that if an instance from a class is used as the query, there are plenty of remaining positive instances in the retrieval set. For object/animal retrieval evaluation, we use the Recall@K metric in order to compare to existing works. For face retrieval, AP is computed from the resulting output ranking for each query, and the mAP score is computed by averaging the APs across every instance in the dataset, resulting in a single value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Implementation Details</head><p>Object/animal retrieval (SOP, VehicleID, INaturalist). In line with previous works <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b71">72,</ref><ref type="bibr" target="#b73">74]</ref>,we use ResNet50 <ref type="bibr" target="#b20">[21]</ref> as the backbone architecture, which was pretrained on ImageNet <ref type="bibr" target="#b56">[57]</ref>. We replace the final softmax layer with one linear layer (following <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b53">54]</ref>, with dimension being set to 512). All images are resized to 256 × 256. At training time, we use random crops and flips as augmentations, and at test time, a single centre crop of size 224 × 224 is used.</p><p>For all experiments we set τ to 0.01 (Section 6.4).</p><p>Face retrieval datasets (VGGFace2, IJB-C). We use two high performing face verification networks: the method from <ref type="bibr" target="#b6">[7]</ref> using the SENet-50 architecture <ref type="bibr" target="#b26">[27]</ref> and the state-of-the-art ArcFace <ref type="bibr" target="#b13">[14]</ref> (using ResNet-50), both trained on the VGGFace2 training set. For SENet-50, we follow <ref type="bibr" target="#b6">[7]</ref> and use the same face crops (extended by the recommended amount), resized to 224 × 224 and we L2-normalize the final 256D embedding. For ArcFace, we generate normalised face crops (112 × 112) by using the provided face detector <ref type="bibr" target="#b13">[14]</ref>, and align them with the predicted 5 facial key points, then L2-normalize the final 512D embedding. For both models, we set the batch size to 224 and τ to 0.01 (Section 6.4).</p><p>Mini-batch training. During training, we form each mini-batch by randomly sampling classes such that each represented class has |P| samples per class. For all experiments, we L2-normalize the embeddings, use cosine similarity to compute the relevance scores between the query and the retrieval set, set |P| to 4, and use an Adam <ref type="bibr" target="#b32">[33]</ref> optimiser with a base learning rate of 10 −5 with weight decay 4e −5 . We employ the same hard negative mining technique as <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b53">54]</ref> only for the Online Products dataset. Otherwise we use no special sampling strategies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results</head><p>In this section, we first explore the effectiveness of the proposed Smooth-AP by examining the performance of various models on the five retrieval datasets. Specifically, we compare with the recent AP optimization and broader metric learning methods on the standard benchmarks SOP and VehicleID (Section 6.1), and then shift to further large-scale experiments, e.g. INaturalist for animal/plant retrieval, and IJB-C and VGGFace2 for face retrieval (Sections 6.2-6.3). Then, we present an ablation study of various hyper-parameters that affect the performance of Smooth-AP: the sigmoid temperature, the size of the positive set, and the batch size (Section 6.4). Finally, we discuss various findings and analyze the performance gaps between various models (Section 6.5).</p><p>Note that, although there has been a rich literature on metric learning methods <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b60">61,</ref><ref type="bibr" target="#b61">62,</ref><ref type="bibr" target="#b63">64,</ref><ref type="bibr" target="#b67">68,</ref><ref type="bibr" target="#b69">70,</ref><ref type="bibr" target="#b70">71,</ref><ref type="bibr" target="#b71">72,</ref><ref type="bibr" target="#b73">74,</ref><ref type="bibr" target="#b74">75,</ref><ref type="bibr" target="#b76">77]</ref> using these image retrieval benchmarks, we only list the very recent state-of-the-art approaches, and try to compare with them as fairly as we can, e.g. no model ensemble, and using the same backbone network and image resolution. However, there still remain differences on some small experimental details, such as embedding dimensions, optimizer, and learning rates. Qualitative results for the INaturalist dataset are illustrated in <ref type="figure" target="#fig_3">Figure 3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Evaluation on Stanford Online Products (SOP)</head><p>We compare with a wide variety of state-of-the-art image retrieval methods, e.g. deep metric learning methods <ref type="bibr" target="#b55">[56,</ref><ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b71">72,</ref><ref type="bibr" target="#b73">74]</ref>, and AP approximation methods <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b53">54]</ref>. As shown in <ref type="table" target="#tab_2">Table 2</ref>, we observe that Smooth-AP achieves state-ofthe-art results on the SOP benchmark. In particular, our best model outperforms the very recent AP approximating methods (Blackbox AP and FastAP) by a 1.5% margin for Recall@1. Furthermore, Smooth-AP performs on par with the concurrent work (Cross-Batch Memory <ref type="bibr" target="#b71">[72]</ref>). This is particularly impressive as <ref type="bibr" target="#b71">[72]</ref>    mini-batch on each training iteration. <ref type="figure" target="#fig_4">Figure 4</ref> provides a quantitative analysis into the effect of sigmoid temperature τ on the tightness of the AP approximation, which can be plotted via the AP approximation error:</p><formula xml:id="formula_11">AP e = |AP pred − AP |<label>(8)</label></formula><p>where AP pred is the predicted approximate AP when the sigmoid is used in place of the indicator function in <ref type="bibr">Equation 5</ref>, and AP is the true AP. As expected, a lower value of τ leads to a tighter approximation to Average Precision, shown by the low approximation error.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Evaluation on VehicleID and INaturalist</head><p>In As we are the first to report results on INaturalist for image retrieval, in addition to Smooth-AP, we re-train state-of-the-art metric learning and AP approximating methods, with the respective official code, e.g. Triplet and Prox-yNCA <ref type="bibr" target="#b54">[55]</ref>, FastAP <ref type="bibr" target="#b5">[6]</ref>, Blackbox AP <ref type="bibr" target="#b65">[66]</ref>. As shown in <ref type="table" target="#tab_3">Table 3</ref>. Smooth-AP outperforms all methods by 2 − 5% on Recall@1 for the experiments when the same batch size is used (224). Increasing the batch size to 384 for Smooth-AP leads to a further boost of 1.4% to 66.6 for Recall@1. These results demonstrate that Smooth-AP is particularly suitable for large-scale retrieval datasets, thus revealing its scalability to real-world retrieval problems. We note here that these large-scale datasets (&gt;100k images) are less influenced by hyper-parameter  tuning and so provide ideal test environments to demonstrate improved image retrieval techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Evaluation on Face Retrieval</head><p>Due to impressive results <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b13">14]</ref>, face retrieval is considered saturated. Nevertheless, we demonstrate here that Smooth-AP can further boost the face retrieval performance. Specifically, we append Smooth-AP on top of modern methods (VGGFace2 and ArcFace) and evaluate mAP on IJB-C and VGGFace2, i.e. one of the largest face recognition datasets. As shown in <ref type="table" target="#tab_5">Table 4</ref>, when appending the Smooth-AP loss, retrieval metrics such as mAP can be significantly improved upon the baseline model for both datasets. This is particularity impressive as both baselines have already shown very strong performance on facial verification and identification tasks, yet Smooth-AP is able to increase mAP by up to 4.4% on VGGFace2 and 3.1% on ArcFace. Moreover, Smooth-AP strongly outperforms both the pairwise <ref type="bibr" target="#b11">[12]</ref> and triplet <ref type="bibr" target="#b58">[59]</ref> losses, i.e. the two most popular surrogates to a ranking loss. As discussed in Section 4.1, these surrogates optimise a distance metric rather than a ranking metric, and the results show that the latter is optimal for AP. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Ablation study</head><p>To investigate the effect of different hyper-parameter settings, e.g. the sigmoid temperature τ , the size of the positive set |P|, and batch size B <ref type="table" target="#tab_6">(Table 5</ref>), we use VGGFace2 and IJB-C with SE-Net50 <ref type="bibr" target="#b6">[7]</ref>, as the large-scale datasets are unlikely to lead to overfitting, and therefore provide a fair understanding about these hyper-parameters. Note that we only vary one parameter at a time.</p><p>Effect of sigmoid temperature τ . As explained in Section 4.1, τ governs the smoothing of the sigmoid that is used to approximate the indicator function in the Smooth-AP loss. The ablation shows that a value of 0.01 leads to the best mAP scores, which is the optimal trade-off between AP approximation and a large enough operating region in which to provide gradients. Surprisingly, this value (0.01) corresponds to a small operating region. We conjecture that a tight approximation to true AP is the key, and when partnered with a large enough batch size, enough elements of the difference matrix will lie within the operating region in order to induce sufficient re-ranking gradients. The sigmoid temperature can further be viewed from the margin perspective (inter-class margins are commonly used in metric learning to help generalisation <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b72">73]</ref>). Smooth-AP only stops providing gradients to push a positive instance above a negative instance once they are a distance equal to the width of the operating region apart, hence enforcing a margin that equates to roughly 0.1 for this choice of τ .</p><p>Effect of positive set |P|. In this setting, the positive set represents the instances that come from the same class in the mini-batch during training. We observe that a small value (4) results in the highest mAP scores, this is because mini-batches are formed by sampling at the class level, where a low value for |P| means a larger number of sampled classes and a higher probability of sampling hard-negative instances that violate the correct ranking order. Increasing the number of classes in the batch results in a better batch approximation of the true class distribution, allowing each training iteration to enforce a more optimally structured embedding space.</p><p>Effect of batch size B. <ref type="table" target="#tab_6">Table 5</ref> shows that large batch sizes result in better mAP, especially for VGGFace2. This is expected, as it again increases the chance of getting hard-negative samples in the batch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5">Further discussion</head><p>There are several important observations in the above results. Smooth-AP outperforms all previous AP approximation approaches, as well as the metric learning techniques (pair, triplet, and list-wise) on three image retrieval benchmarks, SOP, VehicleID, Inaturalist, with the performance gap being particularly apparent on the large-scale INaturalist dataset. Similarly, when scaled to face datasets containing millions of images, Smooth-AP is able to improve the retrieval metrics for state-of-the-art face verification networks. We hypothesis that these performance gains upon the previous AP approximating methods come from a tighter approximation to AP than other existing approaches, hence demonstrating the effectiveness and scalability of Smooth-AP. Furthermore, many of the properties that deep metric learning losses handcraft into their respective methods (distance-based weighting <ref type="bibr" target="#b60">[61,</ref><ref type="bibr" target="#b73">74]</ref>, inter-class margins <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b58">59,</ref><ref type="bibr" target="#b60">61,</ref><ref type="bibr" target="#b69">70]</ref>, intra-class margins <ref type="bibr" target="#b69">[70]</ref>), are naturally built into our AP formulation, and result in improved generalisation capabilities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions</head><p>We introduce Smooth-AP, a novel loss that directly optimizes a smoothed approximation of AP. This is in contrast to modern contrastive, triplet, and listwise deep metric learning losses which act as surrogates to encourage ranking. We show that Smooth-AP outperforms recent AP-optimising methods, as well as the deep metric learning methods, and with a simple and elegant, plug-and-play style method. We provide an analysis for the reasons why Smooth-AP outperforms these other losses, i.e. Smooth-AP preserves the goal of AP which is to optimise ranking rather than distances in the embedding space. Moreover, we also show that fine-tuning face-verification networks by appending the Smooth-AP loss can strongly improve the performance. Finally, in an effort to bridge the gap between experimental settings and real-world retrieval scenarios, we provide experiments on several large-scale datasets and show Smooth-AP loss to be considerably more scalable than previous approximations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Further qualitative results</head><p>In this Section, we provide additional qualitative results for four of the datasets used in our experiments (VGGFace2 Test set, Stanford Online Products, and INaturalist). For each dataset, we display the top retrieved instances for various queries from the baseline model, both with and without appending the Smooth-AP loss. In all cases, the query example is shown in blue. The retrieved instances belonging to the same class as the query (i.e. positive set) are shown in green, while the ones belonging to a different class from the query (i.e. negative set) are shown in red. For all retrieval examples we have shown the corresponding precision-recall curves below, in which the baseline model is represented in blue, and the Smooth-AP model for the same query instance is represented overlaid in green. For Figures S1, S2 the retrieval set is ranked from left to right starting in the top row next to the query. For <ref type="figure" target="#fig_3">Figures S3, S4</ref>, S5, S6 the retrieval set is ranked from top to bottom. In each case, the Average Precision (AP) computed over the whole retrieval set is provided either below or alongside the ranked instances.     In this Section, we provide a further quantitative validation of the claims made in Section 6.4 (in the main manuscript) about the effects of mini-batch size on the Smooth-AP loss. We conjecture that a large mini-batch size increases the likelihood of relevance scores in the mini-batch being close to each other, and hence elements of the difference matrix (Equation 4 in main manuscript) falling into the narrow operating region of the sigmoid (we define the the operating region of the sigmoid as the narrow region with non-negligible gradients, see <ref type="figure">Figure S7b</ref>), meaning that non-negligible gradients are fed backwards from Smooth-AP. This conjecture can be verified by increasing the mini-batch size during training and logging the proportion of elements of the difference matrix that fall into the operating region of the sigmoid. For each mini-batch during training, a difference matrix D is constructed of size (m * m) where m is the mini-batch size. The proportion of elements of D that fall into the operating region of the sigmoid used in Smooth-AP, which we denote as P , can be computed using Equation 1 (we use a value of 0.005 to represent a non-negligible gradient). While keeping all parameters equal except mini-batch size, the average P is computed across all mini-batches in one epoch of training on the Online Products dataset for several different mini-batch sizes, with the results plotted in <ref type="figure">Figure S7a</ref>. As expected, P increases with mini-batch size due to the fact that more instances in a minibatch means that more instances are close enough together in terms of similarity score to lie within the operating zone of the sigmoid. This in turn leads to more non-negligible gradients being fed backwards to the network weights, and hence a higher evaluation performance, as was shown in the ablation <ref type="table" target="#tab_6">Table 5</ref> in the main manuscript. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Choice of hyper-parameters for the compared-to methods for the INaturalist experiments</head><p>The two AP-optimising methods that we compare to for the INaturalist experiments <ref type="table" target="#tab_3">(Table 3)</ref> have several hyper-parameters associated with them. For FastAP <ref type="bibr" target="#b4">[5]</ref>, there is the number of histogram bins, L, and for Blackbox AP <ref type="bibr" target="#b53">[54]</ref>, there is the value of λ and the margin. For both methods we choose the hyperparameters that are recommended in the respective publications for the largest dataset that was experimented on, which would be closest to INaturalist in terms of number of training images. For FastAP the number of histogram bins L is set to 20, and for Blackbox AP, λ is set to 4 and the margin is set to 0.02. We note that the evaluated Recall@K scores might be increased by varying these parameters. For all experiments on the INaturalist dataset, we multiply the learning rate on the last linear layer by a factor of 2. <ref type="table" target="#tab_0">Table S1</ref> shows the time complexities of Smooth-AP, and also the other APoptimising loss functions that we compare to. We also measure the times of the forward and backward passes for a single training iteration when each of the different loss functions are appended onto a ResNet50 <ref type="bibr" target="#b21">[22]</ref> backbone architecture. More specifically, we measure the forwards and backwards pass time for the backbone network, backbone time, and the appended loss function, loss time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Complexity of the proposed loss</head><p>These values for timings are averaged over all iterations in one training epoch for the Online Products dataset. The relevant notation: M is the number of instances in the retrieval set, which during mini-batch training is equal to the size of the mini-batch (with p + n = M and p, n the number of positive and negative instances, respectively). L refers to the number of bins used in the Histogram Binning technique <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b63">64]</ref>. Even though the complexity of the proposed Smooth-AP loss is higher, <ref type="table" target="#tab_0">Table S1</ref> shows that this leads to a very small overhead in computational cost on top of the ResNet50 backbone architecture (&lt; 3ms for every iteration compared to previous methods where the backbone takes 705 ms), and hence in practice has a minor impact on the usability of the proposed loss function. In all experiments here, all training parameters are equal (|P | = 4, and mini-batch size M of 112). Table S1: The time complexities of different AP-optimising methods that we compare to, as well as the time taken for the forwards and backwards pass through the backbone for one iteration, backbone time, and the time taken for the computation of the loss, loss time. The slightly increased time complexity of Smooth-AP leads to a negligible increase in training time.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 :</head><label>1</label><figDesc>Ranked retrieval sets before (top) and after (bottom) applying Smooth-AP on a baseline network (i.e. ImageNet pre-trained weights) for a given query (pink image). The precision-recall curve is shown on the left. Smooth-AP results in large boost in AP, as it moves positive instances (green) high up the ranks and negative ones (red) low down. |P| is the number of positive instances in the retrieval set for this query. Images are from the INaturalist dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 :</head><label>2</label><figDesc>The possible different approximations to the discrete Indicator function. First row: Indicator function (a), three sigmoids with increasing temperatures (b, c, d), linear (e), exponential (f). Second row: their derivatives.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Comparison to other AP-optimising methods. The two key differences between Smooth-AP and the recently introduced FastAP and Blackbox AP, are that Smooth-AP (i) provides a closer approximation to Average Precision, and (ii) is far simpler to implement. Firstly, due to the sigmoid function, Smooth-AP optimises a ranking metric, and so has the same objective as Average Precision. In contrast, FastAP and Blackbox AP linearly interpolate the nondifferentiable (piecewise constant) function, which can potentially lead to the same issues as triplet loss, i.e. optimizing a distance metric, rather than rankings. Secondly, Smooth-AP simply needs to replace the indicator function in the AP objective with a sigmoid function. While FastAP uses abstractions such as Histogram Binning, and Blackbox AP uses a variant of numerical derivative. These differences are positively affirmed through the improved performance of Smooth-AP over several datasets (Section 6.5).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 :</head><label>3</label><figDesc>Qualitative results for the INaturalist dataset using Smooth-AP loss.For each query image (top row), the top 3 instances from the retrieval set are shown ranked from top to bottom. Every retrieved instance shown is a true positive.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 :</head><label>4</label><figDesc>The AP approximation error, APe over one training epoch for Online Products for different values of sigmoid annealing temperature, τ .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. S1 :</head><label>S1</label><figDesc>Qualitative results from the VGGFace2 Test set for the SENet-50<ref type="bibr" target="#b6">[7]</ref> baseline model. We show a query instance (blue) and the first 79 ranked instances in the retrieval set for the baseline model both before and after Smooth-AP was appended (ranked from left to right, starting next to the query). As shown by the precision-recall curves, Smooth-AP causes the Average Precision to jump by an impressive 52.9%, and the number of false positives (shown in red) in the top ranked retrieved instances drops considerably. The size of the positive set for each instance in the VGGFace2 test set, |P | ≈ 338.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. S2 :</head><label>S2</label><figDesc>Here, we show the qualitative results for a second query instance for the SENet-50<ref type="bibr" target="#b6">[7]</ref> baseline model on the VGGFace2 test set, both before and after appending the Smooth-AP loss. Here, we see another large increase in Average Precision of 54.9% caused by the addition of the Smooth-AP loss. We see that all false positives (shown in red) are removed from the top ranked retrieved instances after adding the Smooth-AP loss. Take the situation where each row of top-ranked instances corresponds to pages of retrieved results that a user is presented with when using a retrieval system. With the baseline model, the user comes across many false positives in the first few pages. After appending the Smooth-AP loss, the user encounters no false positives in at least the first five pages. This demonstrates the benefit to user experience in appending Smooth-AP to a retrieval network.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. S3 :</head><label>S3</label><figDesc>Here, we show the qualitative results for a third query instance for the SENet-50<ref type="bibr" target="#b6">[7]</ref> baseline model on the VGGFace2 test set, both before and after appending the Smooth-AP loss. We see a large improvement in Average Precision of 41.8% after adding the Smooth-AP loss and the removal of all false positives from the top ranked retrieval results. These results confirm that Smooth-AP is indeed tailored to addressing the ranking issue.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. S4 :</head><label>S4</label><figDesc>Here, we show the qualitative results for a query instance from the VGGFace2 test set (same as inFigure S3) for the state-of-the-art ArcFace (ResNet-50)<ref type="bibr" target="#b13">[14]</ref> baseline, both before and after appending the Smooth-AP loss. Appending the Smooth-AP loss to this impressive baseline leads to a large gain in Average Precision (24.8%), and again to the removal of all false positives from the top ranked retrieval results. This demonstrates that state-of-the-art face retrieval networks are far from saturated on the Average Precision metric, and through appending the simple Smooth-AP loss, this metric and the resulting user experience when using the face retrieval system can be greatly improved.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. S5 :Fig. S6 :Algorithm 1 :</head><label>S5S61</label><figDesc>This Figure shows four separate query instances from the online products dataset and the top ranked instances from the retrieval set when using the baseline model (ImageNet pre-trained weights), and after appending the Smooth-AP loss. It is noted that for this dataset, the size of the positive set (|P |) in the retrieval set is very small (|P | = 11, 5, 7, 11 for (a),(b),(c),(d) respectively), and so for cases (a) and (b) all positive instances are shown correctly retrieved above all false positives (also indicated by the AP=1.00) for the Smooth-AP model. Particularly impressive are the examples (b) and (c), where instances from the positive set which depict a far different pose from the query are retrieved above false positives that are very visually similar to the query. This Figure shows three separate query instances from the INaturalist dataset and the top ranked instances from the retrieval set when using the baseline model (ImageNet pre-trained weights), and after appending the Smooth-AP loss. As can be seen by the false positive retrieved instances for the baseline model, this is a highly challenging, fine-grained dataset; yet in all cases shown, appending the Smooth-AP loss leads to large gains in Average Precision. |P | = 985, 20, 28 for (a),(b),(c) respectively.2 Source code Here, we provide pseudocode for the Smooth-AP loss written in PyTorch style. The simplicity of the method is demonstrated by the short implementation. Pseudocode for Smooth-AP in Pytorch-style. # scores: predicted relevance scores (1 x m) # gt: groundtruth relevance scores (1 x m) def t_sigmoid(tensor, tau=1.0): # tau is the temperature. exponent = -tensor / tau y = 1.0 / (1.0 + exp(exponent)) return y def smooth_ap(scores, gt): # repeat the number row-wise. s1 = scores.repeat(m, 1) # s1: m x m # repeat the number column-wise. s2 = s1.transpose # s2: m x m # compute difference matrix D = s1 -s2 # approximating heaviside D_ = t_sigmoid(D, tau=0.01) # ranking of each instance R = 1 + sum(D_ * (1-eye(m)), 1) # compute positive ranking R_pos = gt.T * R # compute AP AP = (1 / sum(gt)) * sum(R_pos / R) return 1-AP 3 Details on the effects of increasing the mini-batch size on Smooth-AP</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig</head><label></label><figDesc>. S7: (a): P , the proportion of elements of the difference matrix that fall into the operating region of the sigmoid (shown in (b)), and hence receive non negligible gradients, for several different mini-batch sizes. This explains why Smooth-AP benefits from large mini-batch sizes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>M ethod complexity backbone time (ms) loss time (ms) Blackbox AP<ref type="bibr" target="#b53">[54]</ref> O(n log(n))</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Datasets used for training and evaluation.</figDesc><table><row><cell cols="2">dataset</cell><cell cols="3"># Images # Classes # Ims/Class</cell></row><row><cell></cell><cell>SOP train</cell><cell>59,551</cell><cell>11,318</cell><cell>5.3</cell></row><row><cell>object/animal</cell><cell>SOP test</cell><cell>60,502</cell><cell>11,316</cell><cell>5.3</cell></row><row><cell>retrieval datasets</cell><cell>VehicleID train</cell><cell>110,178</cell><cell>13,134</cell><cell>8.4</cell></row><row><cell></cell><cell>VehicleID test</cell><cell>40,365</cell><cell>4,800</cell><cell>8.4</cell></row><row><cell></cell><cell>INaturalist train</cell><cell>325,846</cell><cell>5,690</cell><cell>57.3</cell></row><row><cell></cell><cell>INaturalist test</cell><cell>136,093</cell><cell>2,452</cell><cell>55.5</cell></row><row><cell>face retrieval datasets</cell><cell>VGGFace2 train VGGFace2 test IJB-C</cell><cell>3.31 M 169,396 148,824</cell><cell>8,631 500 3,531</cell><cell>363.7 338.8 42.1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>harnesses memory techniques to sample from many mini-batches simultaneously for each weight update, whereas Smooth-AP only makes use of a single</figDesc><table><row><cell></cell><cell>SOP</cell></row><row><cell>Recall@K</cell><cell>1 10 100 1000</cell></row><row><cell>Margin [74]</cell><cell>72.7 86.2 93.8 98.0</cell></row><row><cell>Divide [58]</cell><cell>75.9 88.4 94.9 98.1</cell></row><row><cell>FastAP [5]</cell><cell>76.4 89.0 95.1 98.2</cell></row><row><cell>MIC [56]</cell><cell>77.2 89.4 95.6 -</cell></row><row><cell>Blackbox AP [54]</cell><cell>78.6 90.5 96.0 98.7</cell></row><row><cell>Cont. w/M [72]</cell><cell>80.6 91.6 96.2 98.7</cell></row><row><cell cols="2">Smooth-AP BS=224 79.2 91.0 96.5 98.9</cell></row><row><cell cols="2">Smooth-AP BS=384 80.1 91.5 96.6 99.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Results on Stanford Online Products. Deep metric learning and recent AP approximating methods are compared to using the ResNet50 architecture. BS: mini-batch size.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3</head><label>3</label><figDesc></figDesc><table /><note>, we show results on the VehicleID and INaturalist dataset. We ob- serve that Smooth-AP achieves state-of-the-art results on the challenging and large-scale VehicleID dataset. In particular, our model outperforms FastAP by a significant 3% for the Small protocol Recall@1. Furthermore, Smooth-AP ex- ceeds the performance of [72] on 4 of the 6 recall metrics.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Results on the VehicleID (left) and INaturalist (right). All experiments are conducted using ResNet50 as backbone. All results for INaturalist are from publicly available official implementations in the PyTorch framework with a batch size of 224. † refers to the recent re-implementation [55] -we make the design choice for Proxy NCA loss to keep the number of proxies equal to the number of training classes. The VehicleID results are obtained with a batch-size of 384.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">VehicleID</cell><cell></cell><cell></cell><cell></cell><cell>INaturalist</cell></row><row><cell></cell><cell cols="2">Small</cell><cell cols="2">Medium</cell><cell cols="2">Large</cell><cell>Recall@K</cell><cell>1</cell><cell>4</cell><cell>16</cell><cell>32</cell></row><row><cell>Recall@K</cell><cell>1</cell><cell>5</cell><cell>1</cell><cell>5</cell><cell>1</cell><cell>5</cell><cell cols="2">Triplet Semi-Hard [74] 58.1 75.5 86.8 90.7</cell></row><row><cell>Divide [58]</cell><cell cols="6">87.7 92.9 85.7 90.4 82.9 90.2</cell><cell>Proxy NCA † [42]</cell><cell>61.6 77.4 87.0 90.6</cell></row><row><cell>MIC [56]</cell><cell cols="3">86.9 93.4 -</cell><cell cols="3">-82.0 91.0</cell><cell>FastAP [5]</cell><cell>60.6 77.0 87.2 90.6</cell></row><row><cell>FastAP [5]</cell><cell cols="6">91.9 96.8 90.6 95.9 87.5 95.1</cell><cell>Blackbox AP [54]</cell><cell>62.9 79.0 88.9 92.1</cell></row><row><cell cols="7">Cont. w/M [72] 94.7 96.8 93.7 95.8 93.0 95.8</cell><cell cols="2">Smooth-AP BS=224 65.9 80.9 89.8 92.7</cell></row><row><cell cols="7">Smooth-AP 94.9 97.6 93.3 96.4 91.9 96.2</cell><cell cols="2">Smooth-AP BS=384 67.2 81.8 90.3 93.1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>mAP results on face retrieval datasets. Smooth-AP consistently boosts the AP performance for both VGGFace2 and ArcFace, while outperforming other standard metric learning losses (Pairwise contrastive and Triplet).</figDesc><table><row><cell>VGGFace2</cell><cell cols="2">VF2 Test IJB-C</cell><cell>ArcFace</cell><cell cols="2">VF2 Test IJB-C</cell></row><row><cell>Softmax</cell><cell>0.828</cell><cell>0.726</cell><cell>ArcFace</cell><cell>0.858</cell><cell>0.772</cell></row><row><cell>+Pairwise</cell><cell>0.828</cell><cell>0.728</cell><cell>+Pairwise</cell><cell>0.861</cell><cell>0.775</cell></row><row><cell>+Triplet</cell><cell>0.845</cell><cell>0.740</cell><cell>+Triplet</cell><cell>0.880</cell><cell>0.787</cell></row><row><cell>+Smooth-AP</cell><cell>0.850</cell><cell>0.754</cell><cell>+Smooth-AP</cell><cell>0.902</cell><cell>0.803</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 :</head><label>5</label><figDesc>Ablation study over different parameters: temperature τ , size of positive set during minibatch sampling |P|, and batch size B.</figDesc><table><row><cell>Performance is benchmarked on</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgements. We are grateful to Tengda Han, Olivia Wiles, Christian Rupprecht, Sagar Vaze, Quentin Pleple and Maya Gulieva for proof-reading, and to Ernesto Coto for the initial motivation for this work. Funding for this research is provided by the EPSRC Programme Grant Seebibyte EP/M013774/1. AB is funded by an EPSRC DTA Studentship.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">NetVLAD: CNN architecture for weakly supervised place recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Arandjelović</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Gronat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torii</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pajdla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sivic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">All about vlad</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Arandjelovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Neural codes for image retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Babenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Slesarev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chigorin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Learning to rank with nonsmooth cost functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Burges</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ragno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Deep metric learning to rank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Cakir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sclaroff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Fastap: Deep metric learning to rank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Cakir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sclaroff</surname></persName>
		</author>
		<ptr target="https://github.com/kunhe/Deep-Metric-Learning-Baselines" />
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">VGGFace2: A dataset for recognising faces across pose and age</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">M</forename><surname>Parkhi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Autom. Face and Gesture Recog</title>
		<meeting>Int. Conf. Autom. Face and Gesture Recog</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Learning to rank: from pairwise approach to listwise approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">F</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Large margin optimization of ranking measures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Chapelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Smola</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Autocorrect: Deep inductive alignment of noisy geometric annotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. BMVC</title>
		<meeting>BMVC</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Towards accurate one-stage object detection with ap-loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>See</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning a similarity metric discriminatively, with application to face verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Total recall II: Query expansion revisited</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Chum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mikulik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Perďoch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Matas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Arcface: Additive angular margin loss for deep face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Deep adversarial metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Sodeep: a sorting deep net to learn ranking loss surrogates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Engilberge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chevallier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Pérez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cord</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Deep metric learning with hierarchical triplet loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Scott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Deep image retrieval: Learning global representations for image search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gordo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Almazan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Revaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Larlus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Learning to rank with softrank and gaussian processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Guiver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Snelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 31st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Smart mining for deep metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Harwood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Carneiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Drummond</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Hashing as tie-aware learning to rank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Cakir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bargal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sclaroff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Local descriptors optimized for average precision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sclaroff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">End-to-end training of object class detectors for mean average precision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ferrari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACCV</title>
		<meeting>ACCV</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hermans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Leibe</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.07737</idno>
		<title level="m">Defense of the Triplet Loss for Person Re-Identification</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Squeeze-and-excitation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Hamming embedding and weak geometric consistency for large scale image search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jégou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Product quantization for nearest neighbor search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jégou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE PAMI</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Aggregating local descriptors into a compact image representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jégou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Pérez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Aggregating local image descriptors into compact codes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jégou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Perronnin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sánchez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>P&amp;apos;erez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE PAMI</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Attention-based ensemble for deep metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chawla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kwon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Deep spectral clustering learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">T</forename><surname>Law</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A maximal figure-of-merit learning approach to maximizing mean average precision with deep neural network based classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">C</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICASSP</title>
		<meeting>ICASSP</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Sphereface: Deep hypersphere embedding for face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Raj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Sampling wisely: Deep image embedding by top-k precision optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">Y</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Introduction to Information Retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Raghavan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Schütze</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Iarpa janus benchmark-c: Face dataset and protocol</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Maze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Duncan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kalka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Otto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">T</forename><surname>Niggel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cheney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Conference on Biometrics (ICB)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Metric learning to rank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mcfee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">R</forename><surname>Lanckriet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Efficient optimization for rank-based loss functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mohapatra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rolinek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Jawahar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kolmogorov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Pawan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">No fuss distance metric learning using proxies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Movshovitz-Attias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Toshev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">K</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Deep metric learning via facility location</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oh</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jegelka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rathod</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Deep metric learning via lifted structured feature embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oh</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jegelka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">BIER: Boosting Independent Embeddings Robustly</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Opitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Waltner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Possegger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bischof</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Large-scale image retrieval with compressed fisher vectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Perronnin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sánchez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Poirier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Object retrieval with large vocabularies and fast spatial matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Philbin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Chum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sivic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Softsort: A continuous relaxation for the argsort operator</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Prillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Eisenschlos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Softtriple loss: Deep metric learning without triplet sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">A general approximation framework for direct optimization of information retrieval measures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Retrieval</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">CNN image retrieval learns from bow: Unsupervised fine-tuning with hard examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Radenovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tolias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Chum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Learning globally optimized object detector via policy gradient</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Learning with average precision: Training image retrieval with a listwise loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Revaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Almazá</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>De Souza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Optimizing rank-based metrics with blackbox differentiation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rolnek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Musil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Paulus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Vlastelica</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Michaelis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Martius</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Deep metric learning baselines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Brattoli</surname></persName>
		</author>
		<ptr target="https://github.com/Confusezius/Deep-Metric-Learning-Baselines" />
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Mic: Mining interclass characteristics for improved metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Brattoli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ommer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bernstein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>Imagenet large scale visual recognition challenge. IJCV</note>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Divide and conquer the embedding space for metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sanakoyeu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Tschernezki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Buchler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ommer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Facenet: A unified embedding for face recognition and clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kalenichenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Philbin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Video Google: A text retrieval approach to object matching in videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sivic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Deep metric learning via lifted structured feature embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">O</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jegelka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Stochastic class-based hard example mining for deep metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Suh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">Softrank: Optimising non-smooth rank metrics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Guiver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Minka</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>WSDM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">Learning deep embeddings with histogram loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ustinova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">The inaturalist species classification and detection dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Van Horn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Mac Aodha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shepard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Differentiation of blackbox combinatorial solvers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Vlastelica</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Paulus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Musil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Martius</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rolnek</surname></persName>
		</author>
		<ptr target="https://github.com/martius-lab/blackbox-backprop" />
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">The Caltech-UCSD Birds-200-2011 Dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Welinder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<idno>CNS-TR-2011-001</idno>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
		<respStmt>
			<orgName>California Institute of Technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Deep metric learning with angular loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Learning fine-grained image similarity with deep ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Philbin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Ranked list loss for deep metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kodirov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Garnier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Robertson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Multi-similarity loss with general pair weighting for deep metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Scott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Cross-batch memory for embedding learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Scott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">Distance metric learning for large margin nearest neighbor classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Saul</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Sampling matters in deep embedding learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Manmatha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Krahenbuhl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Deep randomized ensembles for metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Souvenir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pless</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Cross-batch reference learning for deep classification and retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">F</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">S</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACMMM</title>
		<meeting>ACMMM</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Hard-aware deeply cascaded embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<monogr>
		<title level="m" type="main">A support vector method for optimizing average precision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Finley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Radlinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<publisher>SIGIR</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
