<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Case-based Reasoning for Natural Language Queries over Knowledge Bases</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajarshi</forename><surname>Das</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manzil</forename><surname>Zaheer</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dung</forename><surname>Thai</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ameya</forename><surname>Godbole</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ethan</forename><surname>Perez</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jay-Yoon</forename><surname>Lee</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lizhen</forename><surname>Tan</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lazaros</forename><surname>Polymenakos</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
						</author>
						<title level="a" type="main">Case-based Reasoning for Natural Language Queries over Knowledge Bases</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T17:54+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>What colors do the school where Donald Stanley</head><p>Marshall is grad student use?</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>It is often challenging for a system to solve a new complex problem from scratch, but much easier if the system can access other similar problems and description of their solutions -a paradigm known as case-based reasoning (CBR). We propose a neuro-symbolic CBR approach for question answering over large knowledge bases (CBR-KBQA). While the idea of CBR is tempting, composing a solution from cases is nontrivial, when individual cases only contain partial logic to the full solution. To resolve this, CBR-KBQA consists of two modules: a non-parametric memory that stores cases (question and logical forms) and a parametric model which can generate logical forms by retrieving relevant cases from memory. Through experiments, we show that CBR-KBQA can effectively derive novel combination of relations not presented in case memory that is required to answer compositional questions. On several KBQA datasets that test compositional generalization, CBR-KBQA achieves competitive performance. For example, on the challenging COMPLEXWEBQUESTIONS dataset, CBR-KBQA outperforms the current state of the art by 11% accuracy. Furthermore, we show that CBR-KBQA is capable of using new cases without any further training. Just by incorporating few humanlabeled examples in the non-parametric case memory, CBR-KBQA is able to successfully generate queries containing unseen KB relations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Humans often solve a new problem by recollecting and adapting the solution to multiple related problems that they have encountered in the past <ref type="bibr" target="#b58">(Ross, 1984;</ref><ref type="bibr" target="#b33">Lancaster &amp; Kolodner, 1987;</ref><ref type="bibr" target="#b61">Schmidt et al., 1990)</ref>. In classical artificial 1 University of Massachusetts Amherst 2 Google Research 3 New York University 4 Amazon. Correspondence to: Rajarshi Das &lt;rajarshi@cs.umass.edu&gt;, Ameya Godbole &lt;agod-bole@cs.umass.edu&gt;.</p><p>What are the shapes of the galaxies which have the classification code m110? <ref type="bibr">KNN search (case-retrieval)</ref> What shape does the galaxy i0 have? i10 astronomy.galactic_shape</p><p>Retrieved Case 1 E5PEC is classification code for which galaxies? intelligence (AI), case-based reasoning (CBR) pioneered by <ref type="bibr" target="#b60">Schank (1982)</ref>, tries to incorporate such model of reasoning in AI systems <ref type="bibr" target="#b29">(Kolodner, 1983;</ref><ref type="bibr" target="#b57">Rissland, 1983;</ref><ref type="bibr" target="#b35">Leake, 1996)</ref>. A sketch of a CBR system <ref type="bibr" target="#b0">(Aamodt &amp; Plaza, 1994)</ref> comprises of the following modules -(i) a retrieval module, in which 'cases' that are similar to the given problem are retrieved, (ii) a reuse module, in which the solutions of the retrieved cases are re-used to synthesize a new solution. Often, the newly derived solution can not be used directly (e.g. because of domain mismatch) and hence needs (iii) revision. Finally, successful solutions are (iv) retained in a case memory, to be reused later.</p><p>In its early days, the components of CBR were implemented with symbolic systems, which had their limitations.For example, finding similar cases and generating new solutions from them is a challenging task for a CBR system implemented with symbolic components. However, with the recent advancements in representation learning <ref type="bibr" target="#b36">(LeCun et al., 2015)</ref>, the performance of ML systems have improved substantially on a range of practical tasks.</p><p>Large symbolic KBs form the underlying data store for a wide variety of applications. Therefore, the ability to query information stored in the KB via a natural language interface is of practical importance. Current approaches for KBQA <ref type="bibr" target="#b3">(Berant et al., 2013;</ref><ref type="bibr" target="#b68">Sun et al., 2019a)</ref> do not leverage the power of CBR. Combined with the power of representations obtained from large pre-trained language models <ref type="bibr" target="#b12">(Devlin et al., 2019;</ref><ref type="bibr" target="#b44">Liu et al., 2019;</ref><ref type="bibr">Raffel et al., 2020, inter-alia)</ref>, we present a neuro-symbolic CBR approach for answering complex questions over a large symbolic KB <ref type="figure" target="#fig_0">(Figure 1)</ref>.</p><p>Given a NL query, our model (CBR-KBQA) first retrieves other similar cases (queries and its logical forms) from a case memory (e.g. training set). Next, CBR-KBQA synthesizes a logical form for the given query by learning to reuse various components of the solutions of the retrieved cases ( <ref type="figure" target="#fig_0">Figure 1</ref>). The newly generated logical form is then executed against the KB. However, often the generated logical form does not execute successfully. This can happen because one or more KB relations needed are never present in the retrieved cases (because of lack of good nearest neighbors) or because of the incompleteness of the knowledge graph (KG) <ref type="bibr" target="#b47">(Min et al., 2013)</ref>.</p><p>To alleviate such cases, CBR-KBQA has an additional revise step that aligns the generated relations in the logical form to the query entities' local neighborhood in the KG. To achieve this, we take advantage of pre-trained relation embeddings from KB completion techniques (e.g. Trans-E <ref type="bibr" target="#b5">(Bordes et al., 2013)</ref>) that learn the structure of the KG. We also experiment with another alignment model which takes advantage of the fact that similar KB relation often have overlapping terms in its surface form (e.g. person.siblings and fictional character.siblings) and hence the corresponding token embeddings are similar.</p><p>It has been shown black-box models do not generalize to questions requiring novel compositions especially if they are not seen at training time <ref type="bibr" target="#b45">Loula et al., 2018)</ref>. We show that CBR-KBQA is effective for complex compositional questions and we obtain new state-of-the art results on the challenging CWQ dataset <ref type="bibr" target="#b70">(Talmor &amp; Berant, 2018)</ref> outperforming baselines by over 11% points.</p><p>It is important for ML systems to be debuggable -i.e. it should be easy to gain insights about what went wrong when a model outputs a erroneous prediction for a given input. Current models for question answering (QA) built on top of massive pre-trained language models (LMs) <ref type="bibr" target="#b44">(Liu et al., 2019;</ref><ref type="bibr" target="#b55">Raffel et al., 2020)</ref> often function as black-boxes, offering very little insight when the model outputs a wrong answer. Currently, the popular approach to handle such cases is to re-train or fine-tune the model on new examples. This process is not only time-consuming and laborious but also many models often suffer from catastrophic forgetting <ref type="bibr" target="#b21">(Hinton &amp; Plaut, 1987;</ref><ref type="bibr" target="#b28">Kirkpatrick et al., 2017)</ref>, making wrong predictions on examples which it previously predicted correctly. On the other hand, CBR-KBQA is non-parametric and derives the logical form for a new query conditioned on other similar queries. Therefore, it is possible to fix model predictions by adding missing relevant cases to the casememory (KNN-index) without requiring any retraining. We  demonstrate this ( <ref type="figure" target="#fig_1">Figure 2)</ref> by showing that CBR-KBQA can predict LFs of queries containing relations not seen during training when an expert (e.g. system administrator) adds few "simple cases" (containing only one relation) to the KNN index. We believe that such controllable properties are essential for models to be deployed in real-world settings and we hope that our work will inspire further research in this direction. It should also be noted there has been a lot of work which try to make neural models transparent and explainable <ref type="bibr" target="#b56">(Ribeiro et al., 2016)</ref>. CBR-KBQA differs from them because in addition to making models explainable, it also allows predictions to be fixable.</p><p>Recent works such as REALM <ref type="bibr" target="#b19">(Guu et al., 2020)</ref> and RAG <ref type="bibr" target="#b38">(Lewis et al., 2020b)</ref> retrieve relevant paragraphs from a non-parametric memory for answering questions. Our CBR-KBQA, in contrast, retrieves similar queries w.r.t the input query and use their solution to derive a new solution for the query. CBR-KBQA is also similar to the recent retrieve and edit framework <ref type="bibr" target="#b20">(Hashimoto et al., 2018)</ref> for generating structured output. However, unlike us they condition on only a single retrieved example and hence is unlikely to be able to handle compositional questions. Moreover, unlike CBR-KBQA, retrieve and edit does not have a component that can explicitly revise a generated output.</p><p>The contributions of our paper are as follows -(a) We present a neural CBR approach for KBQA capable of generating complex logical forms conditioned on similar retrieved questions and their logical forms. (b) Since CBR-KBQA explicitly learns to reuse cases, we show it is able to generalize to unseen relations at test time, when relevant cases are provided. (c) We also show the efficacy of our revise step of CBR-KBQA which allows to correct generated output by aligning it to local neighborhood of the query entity. (d) Lastly, we show that CBR-KBQA outperforms other competitive KBQA models, especially on datasets containing complex questions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Model</head><p>This section describes the implementation of various modules of CBR-KBQA. In CBR, a case is defined as an abstract representation of a problem along with its solution. In our KBQA setting, a case is a natural language query paired with an executable logical form. As mentioned earlier, the practical importance of KBQA has led to the creation of an array of recent datasets <ref type="bibr" target="#b80">(Zelle &amp; Mooney, 1996;</ref><ref type="bibr" target="#b6">Bordes et al., 2015;</ref><ref type="bibr" target="#b65">Su et al., 2016;</ref><ref type="bibr" target="#b77">Yih et al., 2016;</ref><ref type="bibr">Zhong et al., 2017a;</ref><ref type="bibr" target="#b49">Ngomo, 2018;</ref><ref type="bibr" target="#b78">Yu et al., 2018;</ref><ref type="bibr">Talmor &amp; Berant, 2018, inter-alia)</ref>. In these datasets, a question is paired with an executable logical form such as SPARQL, SQL, S-expression or graph query. All of these forms have equal representational capacity and are interchangeable <ref type="bibr" target="#b65">(Su et al., 2016)</ref>. <ref type="figure" target="#fig_2">Figure 3</ref> shows an example of two equivalent logical forms. For our experiments, we consider executable SPARQL programs as our logical form.</p><p>Formal definition of task: let q be a NL query and let K be a symbolic knowledge base that needs to be queried to retrieve an answer list A containing the answer(s) for q. We also assume access to a training set D = {(q 1 , 1 ), (q 2 , 2 ), . . . (q N , N )} of NL queries and their corresponding logical forms where q i , i represents NL query and its corresponding logical form, respectively. A logical form is an executable query containing entities, relations and free variables ( <ref type="figure" target="#fig_2">Figure 3</ref>). CBR-KBQA first retrieves K similar cases D q from D ( § 2.1). It then generates a intermediate logical form inter by learning to reuse components of the logical forms of the retrieved cases ( § 2.2). Next, the logical form inter is revised to output the final logical form by aligning to the relations present in the neighborhood subgraph of the query entity to recover from any spurious relations generated in the reuse step ( § 2.3). Finally, is executed against K and the list of answer entities are returned. We evaluate our KBQA system by calculating the accuracy of the retrieved answer list w.r.t a held-out set of queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Retrieve</head><p>The retrieval module computes dense representation of the given query and uses it to retrieve other similar query representation from a training set. Inspired by the recent advances in neural dense passage retrieval <ref type="bibr" target="#b25">Karpukhin et al., 2020)</ref>, we use a ROBERTA-base encoder to encode each question independently. Also, we want to retrieve questions that have high relational similarity instead of questions which share the same entities (e.g. we prefer to score the query pair (Who is Justin Bieber's brother?, Who is Rihanna's brother?), higher than (Who is Justin Bieber's brother?, Who is Justin Bieber's father?)). To minimize the effect of any entity similarity, we use a named entity tagger 1 to detect spans of entities and mask them with [BLANK] symbol with a probability p mask . The entity masking strategy has previously been successfully used in learning entityindependent relational representations <ref type="bibr" target="#b63">(Soares et al., 2019)</ref>. The similarity score between two queries is given by the inner product between their normalized vector representations (cosine similarity), where each representation, following standard practice <ref type="bibr" target="#b19">(Guu et al., 2020)</ref>, is obtained from the encoding of the initial [CLS] token of the query.</p><p>Fine-tuning question retriever: In passage retrieval, training data is gathered via distant supervision in which passages containing the answer is marked as a positive example for training. Since in our setup, we need to retrieve similar questions, we use the available logical forms as a source of distant supervision. Specifically, a question pair is weighed by the amount of overlap it has in their corresponding logical queries. Following DPR <ref type="bibr" target="#b25">(Karpukhin et al., 2020)</ref>, we sample in-batch negative examples and use a weighted negative log-likelihood loss where the weights are computed by the F 1 score between the set of relations present in the corresponding logical forms. Concretely, let (q 1 , q 2 , . . . , q B ) denote all questions in a mini-batch. The loss function is:</p><formula xml:id="formula_0">L = − i,j w i,j log exp(sim(q i , q j )) j exp(sim(q i , q j ))</formula><p>Here, q i ∈ R d denotes the vector representation of query q i and sim(q i , q j ) = q i q j . w i,j is computed as the F 1 overlap between relations in the logical pairs of q i and q j . We pre-compute and cache the query representations of the training set D. For query q, we return the top-k similar queries in D w.r.t q and pass it to the reuse module.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Reuse</head><p>The reuse step generates an intermediate logical form from the k cases that are fed to it as input from the retriever module. Pre-trained encoder-decoder transformer models such as BART <ref type="bibr" target="#b37">(Lewis et al., 2020a)</ref> and T5 <ref type="bibr" target="#b55">(Raffel et al., 2020)</ref> have enjoyed dramatic success on semantic parsing <ref type="bibr" target="#b43">(Lin et al., 2018;</ref><ref type="bibr" target="#b24">Hwang et al., 2019;</ref><ref type="bibr" target="#b62">Shaw et al., 2020;</ref><ref type="bibr" target="#b66">Suhr et al., 2020)</ref>. We take a similar approach in generating an intermediate logical form conditioned on the retrieved cases. However, one of the core limitation of transformer-based models is its quadratic dependency (in terms of memory),  because of full-attention, which severely limits the sequence length it can operate on. For example, BART and T5 only supports sequence length of 512 tokens in its encoder. Recall that for us, a case is a query from the train set and an executable SPARQL program, which can be arbitrarily long.</p><p>To increase the number of cases we can utilize, we leverage a recently proposed sparse-attention transformer architecture -BIGBIRD . Instead of having each token attend to all input tokens as in the standard transformer, each token attends to only nearby tokens. Additionally, a small set of global tokens attend to all tokens in the input. This reduces the transformer's quadratic complexity to linear in terms of memory, and empirically, BIGBIRD enables us to use many more cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Description of input:</head><p>The input query q and cases</p><formula xml:id="formula_1">D q = {(q 1 , 1 ), (q 2 , 2 ), . . . (q k , k )} are concatenated on the encoder side. Specifically, Input ENC (q, D q ) = q[SEP]q 1 [SEP] 1 , . . . q k [SEP] k , where [SEP]</formula><p>denotes the standard separator token. Each logical form also contain the KB entity id of each entities in the question (e.g. m.03 r3 for Jamaica in <ref type="figure" target="#fig_2">Figure 3</ref>). We append the entity id after the surface form of the entity mention in the question string. For example, the query in <ref type="figure" target="#fig_2">Figure 3</ref> becomes "What do Jamaican m.03 r3 people speak?".</p><p>Large deep neural networks usually benefit from "good" initialization points <ref type="bibr" target="#b15">(Frankle &amp; Carbin, 2019)</ref> and being able to utilize pre-trained weights is critical for our seq2seq models. However, our reuse step focuses more on copying artifacts from the input, rather than memorizing and generating the solution as in most pre-trained models. This change in training objective poses a challenge during fine-tuning. We conjecture that initial gradients from memorizing and generating objective are fairly small compared to those of copying when fine-tuning pre-trained weights. Therefore, some forms of loss regularization is needed to calibrate the two objectives. We introduce a regularization term that measures the Kullback-Leibler divergence (KLD) between prediction distributions (softmax layers) (1) when only the query q is presented (requires memorizing and generating), and <ref type="formula">(2)</ref> when cases D q are available (requires copying). Formally, let f be the seq2seq model, let σ = sof tmax(f (q, D q )) and σ = sof tmax(f (q)) be the prediction distribution with and without cases, respectively. The following KLD term is added to the seq2seq cross-entropy loss</p><formula xml:id="formula_2">L = L CE (f (q, D q ), l) + λ T KLD(σ, σ )</formula><p>Intuitively, this term regularizes the prediction of f (q, D q ) not to deviate too far away from that of the f (q), especially in the beginning of the training process when the new information from cases D q is presented to the network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Revise</head><p>In the previous step, the model explicitly reuses the relations present in D q , nonetheless, there is no guarantee that the query relations in D q will contain the relations required to answer the original query q. This can happen when the domain of q and domain of cases in D q are different even when the relations are semantically similar. For example, in figure 4 (top), the input query q and q 1 , q 2 in cases are all asking information about siblings. However, 'person.sibling' relation in the retrieved case is not directly applicable for the fictional character 'Demeter' in the query q.</p><p>Similarly, large KBs are very incomplete <ref type="bibr" target="#b47">(Min et al., 2013)</ref>, so querying with a valid relation might require an edge that is missing in the KB <ref type="figure" target="#fig_3">(Figure 4</ref>, bottom) leading to intermediate logical forms which do not execute.</p><p>To alleviate this problem and to make the queries executable, we explicitly align the generated relations with relations (edges) present in the local neighborhood of the query entity in the KG. We propose the following alignment models:</p><p>Using pre-trained KB embeddings: KB completion is a extensively studied research field <ref type="bibr" target="#b50">(Nickel et al., 2011;</ref><ref type="bibr" target="#b5">Bordes et al., 2013;</ref><ref type="bibr" target="#b64">Socher et al., 2013;</ref><ref type="bibr" target="#b73">Velickovic et al., 2018;</ref><ref type="bibr" target="#b69">Sun et al., 2019b)</ref> and several methods have been developed that learn low dimensional representation of relations such that similar relations are closer to each other in the embedding space. We take advantage of the pre-trained relations obtained from TransE <ref type="bibr" target="#b5">(Bordes et al., 2013)</ref>, a widely used model for KB completion. For each predicted relation outgoing from / incoming to an entity, we find the most similar relation edge (in terms of cosine similarity) that exists in the KB for that entity and align with it. If the predicted edge exists in the KB, it trivially aligns with itself.</p><p>Using similarity in surface forms: Similar relations (even across domains) have overlap in their surface forms (e.g. 'siblings' is common term in both 'person.siblings' and 'fictional character.siblings'). Therefore, word embeddings obtained by encoding these words should be similar. This observation has been successfully utilized in previous works <ref type="bibr" target="#b72">(Toutanova &amp; Chen, 2015;</ref><ref type="bibr" target="#b24">Hwang et al., 2019)</ref>. We similarly encode the predicted relation and all the outgoing or incoming edges with ROBERTA-base model. Follow-  Our alignment is very simple and requires no learning. By aligning only single edges to existing edges in the KB, we make sure that we do not change the structure of the logical form generated in the re-use phase. We leave the exploration of learning to align single edges in the program to sequence of edges (paths) in the KB as future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Retain</head><p>A CBR framework also stipulates an explicit retain step, in which derived solution of new cases that are solved successfully are stored. In classic CBR work, successful solutions were represented as domain specific symbolic rules. In our neural CBR framework, such rules are analogously stored in the parameters of each modules.</p><p>In the next section we show the efficacy of CBR-KBQA on various benchmarks that test compositional generalization. We also show that CBR-KBQA is able to reuse newly added cases containing unseen relations without any re-training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Data</head><p>For all our experiments, the underlying KB is the full Freebase KB containing over 45 million entities (nodes) and 3 billion facts (edges). <ref type="bibr" target="#b4">(Bollacker et al., 2008)</ref>. We test CBR-KBQA on three datasets -WEBQUESTIONSSP <ref type="bibr" target="#b77">(Yih et al., 2016)</ref>, COMPLEXWEBQUESTIONS <ref type="bibr" target="#b70">(Talmor &amp; Berant, 2018)</ref> and Compositional Freebase Questions <ref type="bibr" target="#b26">(Keysers et al., 2020)</ref>. WEBQUESTIONSSP (WebQSP) contains 4737 NL questions belonging to 56 domains covering 661 unique relations. Most questions need up to 2 hops of reasoning, where each hop is a KB edge. COMPLEXWEBQUESTIONS (CWQ) is generated by extending the WebQSP dataset with the goal of making it a more complex multi-hop dataset. There are four types of questions: composition (45%), conjunction (45%), comparative (5%), and superlative (5%). Answering these questions requires up to 4 hops of reasoning in the KB, making the dataset challenging. Compositional Freebase Questions (CFQ) is a recently proposed benchmark explicitly developed for measuring compositional generalization. For all the datasets above, the logical form (LF) for each NL question is a SPARQL query that can be executed against the Freebase KB to obtain the answer entity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Model Hyperparameters</head><p>The hyperparameters listed below are set by tuning on the valdation set for each dataset. WebQSP dataset does not contain a validation split, so we choose 300 training instance to form the validation set. Case Retriever: We initialize our retriever with the pretrained ROBERTA-base weights. We set p mask = 0.2 for COMPLEXWEBQUESTIONS and p mask = 0.5 for the remaining datasets. We set the initial learning rate to 5 × 10 −5 and decay it linearly throughout training. with 6 encoding and 6 decoding sparse-attention layers, which we initialize with pre-trained BART-base weights. We use k=20 cases and decode with a beam size of 5 for decoding. We set the initial learning rate to 5 × 10 −5 and decay it linearly throughout training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Entity Linking</head><p>The first step required to generate an executable LF for a NL query is to identify and link the entities present in the query. For our experiments, we use a combination of an offthe-shelf entity linker and a large mapping of mentions to surface forms. For the off-the-shelf linker, we use a recently proposed high precision entity linker ELQ .</p><p>To further improve recall of our system, we first identify mention spans of entities in the question by tagging it with a NER 2 system. Next, we link entities not linked by ELQ by exact matching with surface form annotated in FACC1 project <ref type="bibr" target="#b17">(Gabrilovich et al., 2013)</ref>. Our entity linking results are shown in <ref type="table">Table 2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Retrieval Performance</head><p>We compare the performance of our trained retriever with a ROBERTA-base model. We found that ROBERTA model even without any fine-tuning performs well at retrieval. However, fine-tuning ROBERTA with our distant supervision objective improved the overall recall, e.g., from 86.6% to 90.4% on WEBQUESTIONSSP and from 94.8% to 98.4% on CFQ MCD1 split.  <ref type="table">Table 3</ref>. Performance on the CWQ dataset. The performance of models in the top section are taken from the official leaderboard. Questions in CWQ need complex reasoning and CBR-KBQA outperforms all other existing models (including a massive fine-tuned T5 model for this task) by a significant margin. <ref type="table" target="#tab_3">Table 1</ref> reports results on WebQSP. All reported model except ours directly operate on the KB (e.g. traverse KB paths starting from the query entity) to generate the LF or the answer. As a result, models such as STAGG tend to enjoy much higher recall. On the other hand, much of our logical query is generated by reusing components of similar cases. Models such as GraftNet <ref type="bibr" target="#b67">(Sun et al., 2018)</ref> and PullNet <ref type="bibr" target="#b68">(Sun et al., 2019a)</ref> rank answer entities and return the top entity as answer (Hits@1 in table 2). This is undesirable for questions that have multiple entities as answers (e.g. "Name all major cities in the U.S.?"). We also compare to T5 (Raffel et al., 2020) a large pre-trained seq2seq model with over 11B parameters. T5 was fine-tuned on the query and LF pair. As show in <ref type="table" target="#tab_3">Table 1</ref>, CBR-KBQA outperforms all other models significantly and improves on the strict exact-match accuracy by more than 6 points w.r.t. the best model. <ref type="table">Table 3</ref> reports performance on CWQ 3 . As discussed earlier, <ref type="bibr">3</ref> The result of our model in the official leaderboard (https: //www.tau-nlp.org/compwebq-leaderboard) is higher (70.4 vs 67.1). This is because the official evaluation script assigns full score if any of the correct answer entities are returned even if there are multiple correct answers for a question. In the CWQ contains complex multi-hop questions that require compositional reasoning. The top section reports performance of various baselines in the official leader-board.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">KBQA Results</head><p>Finally, we report results on CFQ in <ref type="table" target="#tab_5">Table 4</ref>. The creators of CFQ propose to evaluate performance with exact string match accuracy between SPARQL programs is computed, which is quite conservative in what is counted as correct. For example, in a SPARQL query having a different (but consistent) name for a free variable (x1 instead of x) does not change the semantics of the query. Also SPARQL is independent of the order of the relational triples. This is especially unfair to our model, which copies relations from other nearest neighbor queries and can copy relations in any order. As a remedy, we report results from evaluating the predicted (and gold) queries against a Freebase KB. We also recreate the results of the baseline T5-large model (which also improves w.r.t. the original results reported in ). With the exception of the MCD-2 split of the data, CBR-KBQA performs comparably with the T5 model. Efficacy of the Revise step: <ref type="table">Table 5</ref> show that the revise step is useful for CBR-KBQA on multiple datasets. We also show that the T5 model also benefits from the alignment in revise step with more than 3 points improvement in F1 score on the CWQ dataset. We find that TransE alignment outperforms ROBERTA based alignment, suggesting that graph structure information is more useful than surface form similarity for aligning relations. Moreover, relation names are usually short strings, so they do not provide enough context for LMs to form good representation.</p><p>paper we report the stricter metric which only assigns when all the answer entities are returned by the model</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.">Applying Point-Fixes to Model Predictions without Re-Training</head><p>Modern NLP systems built on top of large LMs are used as black-boxes. Specifically, it does not provide users no control or insights to fix an erroneous prediction. The current approach for fixing this practical problem is to re-train the model on the failed examples. However, this process is time-consuming and impractical for production settings. Moreover, it has been shown (and as we will empirically demonstrate) that this approach can also lead to catastrophic forgetting where the model forgets what it had learned before <ref type="bibr" target="#b21">(Hinton &amp; Plaut, 1987;</ref><ref type="bibr" target="#b46">McCloskey &amp; Cohen, 1989;</ref><ref type="bibr" target="#b28">Kirkpatrick et al., 2017;</ref><ref type="bibr" target="#b71">Toneva et al., 2019)</ref>.</p><p>On the contrary, we show that our CBR-KBQA approach lets user inspect erroneous predictions and also allows them to perform point fixes without re-training the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.1.">PERFORMANCE ON UNSEEN RELATIONS</head><p>We consider the case when the model generates a wrong LF for a given query. We create a controlled setup by removing all queries from the training set of WebQSP which contain the (people.person.education) relation. This led to a removal of 136 queries from the train set and ensured that the model failed to correctly answer the 86 queries (held-out) in the test set which contained the removed relation in its LF.</p><p>For this experiment, we compare to a black-box seq2seq BART transformer model as our baseline. As shown in Table 6, both baseline and CBR-KBQA do not perform well without any relevant cases since a required KB relation was missing during training. Next, we add the 136 training instances back to the training set and recompute the KNN index. This process involves encoding the newly added NL queries and recomputing the KNN index, a process which is computationally much cheaper than re-training the model again.</p><p>Row 5 in <ref type="table" target="#tab_6">Table 6</ref> shows the new result. On addition of the new cases, CBR-KBQA can seamlessly use them and copy the unseen relation to predict the correct LF, reaching 70.6% accuracy on the 86 held-out queries.</p><p>In contrast, the baseline transformer must be fine-tuned on the new cases to handle the new relation, which is more computationally expensive than adding the cases to our index. Moreover, just fine-tuning on the new instances leads to catastrophic forgetting as seen in row 2 of <ref type="table" target="#tab_6">Table 6</ref> where the baseline model's performance on the initial set decreases drastically. We find it necessary to carefully fine-tune the model on new examples alongside original training examples (in a 1:2 proportion). However, it still converges to a performance which is lower than its original performance and much lower than the performance of CBR-KBQA.  <ref type="table">Table 7</ref>. Results for H-I-T-L experiment. After adding a few cases , we see that we can get the accuracy of OOV questions to improve considerably, without needing to re-train the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.2.">HUMAN-IN-THE-LOOP EXPERIMENT</head><p>During error analysis, we realized that there are queries in the evaluation set of WebQSP that contain KB relations in their LFs which were never seen during training. That means model trained on the corresponding train set will never be able to predict the correct LF for the query because of the required unseen relation.</p><p>To further showcase the flexibility of our model we conduct a human-in-the-loop experiment <ref type="figure" target="#fig_1">(Figure 2</ref>) in which users add simple 'cases' to point-fix erroneous predictions of CBR-KBQA for those queries. A simple case is a NL query paired with a program which only contain one KB relation.  <ref type="bibr" target="#b6">(Bordes et al., 2015)</ref> which is a large collection of NL queries that can be a mapped to a single KB edge. <ref type="table" target="#tab_3">Table 10</ref> in Appendix B shows various statistics of the missing relations and the number of cases added by humans and from SimpleQuestions. <ref type="table">Table 7</ref> shows the result of this experiment. For WebQSP by adding a few cases, the performance of the model increases by 36 F1 without requiring any model re-training. Note unlike the previous controlled experiment in §3.6.1, we only add around 3 -4 cases for each unseen relation. The cases are added to the original KNN-index and to get a prediction right, the retriever module has to get the relation from the index and the reuse module has to learn to copy the unseen relation in the retrieved case (without any additional training). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7.">Analysis</head><p>To further demonstrate CBR's ability to handle compositional questions, we analyze questions in the evaluation set which require novel combinations of relations never seen in the training set. This means, in order for our model to answer these questions correctly, it would have to retrieve relevant nearest neighbor (NN) questions from the training set and copy the required relations from the logical form of multiple NN queries. <ref type="table" target="#tab_8">Table 8</ref> shows that our model outperforms the competitive T5 baseline. Also as we saw in the last section, our model is able to quickly adapt to relations never seen in the training set altogether by picking them up from newly added cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Related Work</head><p>Retrieval augmented LM architectures: A growing class of models (e.g., <ref type="bibr" target="#b19">Guu et al., 2020;</ref><ref type="bibr" target="#b38">Lewis et al., 2020b)</ref> augments language models with a non-parametric memory, instead of solely relying on information stored in model parameters. In contrast, our CBR approach retrieves similar queries, instead of relevant supporting context, w.r.t the input query and use their solution (logical forms) to derive a new solution for the query. Recently, <ref type="bibr" target="#b39">(Lewis et al., 2020c)</ref> also noted that the train set often contain similar questions w.r.t. the evaluation set, and concurrent work uses this insight to derive the answer to natural language questions using similar, retrieved questions <ref type="bibr" target="#b40">(Lewis et al., 2021)</ref>. Our work develops a case-based reasoning approach for KBQA and is further capable of answering compositional questions from multiple simple questions.</p><p>Retrieve and edit: Our model shares similarities with the RETRIEVE-AND-EDIT framework <ref type="bibr" target="#b20">(Hashimoto et al., 2018)</ref> which utilizes the case of the nearest-neighbor w.r.t input.</p><p>Their "edit" step is similar to our "reuse" step, however, they simply rely on the sequence-to-sequence model to generate answer from the retrieved case without "revise" and "retain" steps. Furthermore, our "reuse" step brings in new challenges as parametric model have to compose one SPARQL query from multiple cases in contrast to RETRIEVE-AND-EDIT that only considers a single nearest case.</p><p>K-NN based approach in other NLP applications: Nearest neighbor models have been used in a number of NLP applications such as parts-of-speech tagging <ref type="bibr" target="#b9">(Daelemans et al., 1996)</ref> and morphological analysis <ref type="bibr" target="#b7">(Bosch et al., 2007)</ref>. <ref type="bibr" target="#b75">Wiseman &amp; Stratos (2019)</ref> achieved accurate sequence labeling by explicitly and only copying labels from retrieved neighbors. Another recent line of work use training examples at test time to improve language generation <ref type="bibr" target="#b74">(Weston et al., 2018;</ref><ref type="bibr" target="#b51">Pandey et al., 2018;</ref><ref type="bibr" target="#b8">Cao et al., 2018;</ref><ref type="bibr" target="#b52">Peng et al., 2019)</ref>. <ref type="bibr" target="#b27">Khandelwal et al. (2020)</ref> also observed improvements in language modeling by utilizing explicit examples from past training data obtained via nearest neighbor search in a continuous vector space. However, unlike us, these work do not do explicit reasoning with subquestions. <ref type="bibr">(Hua et al., 2020)</ref> recently proposed a meta-learning approach which utilizes cases retrieved w.r.t. the similarity of the input. However, their main goal is to learn a better parametric model (retriever and generator) through neighboring cases rather than composing and fixing cases to generate answers at test time as we do.</p><p>Case-based Reasoning for KB completion: Recently, a CBR based approach was proposed by <ref type="bibr" target="#b11">Das et al. (2020)</ref>. Similar to our approach, they retrieve similar entities and then find reasoning paths from those entities. However, their approach does not handle complex natural language queries. Additionally, the logical forms handled by our model have much more expressive power than knowledge base paths.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Question Decomposition</head><p>One strategy to answer a compositional question is to first break it down into simpler subquestions, each of which can be viewed as a natural language program describing how to answer the question. This approach has been shown to be effective as far back as IBM Watson <ref type="bibr" target="#b14">(Ferrucci et al., 2010)</ref> to more recent systems for answering questions about text <ref type="bibr" target="#b48">Min et al., 2019;</ref><ref type="bibr" target="#b53">Perez et al., 2020;</ref><ref type="bibr" target="#b76">Wolfson et al., 2020)</ref> or knowledge bases <ref type="bibr" target="#b70">(Talmor &amp; Berant, 2018)</ref>. These prior studies do not leverage case-based reasoning when generating decompositions and thus may also benefit from similar techniques as proposed in our work.</p><p>Program Synthesis: Repairing / Revising generated programs has been studied in the field of program synthesis. For example, prior work repairs a program based on syntax of the underlying language <ref type="bibr" target="#b34">(Le et al., 2017)</ref>, by generating sketches <ref type="bibr" target="#b22">(Hua et al., 2018)</ref>. More recently, <ref type="bibr" target="#b18">Gupta et al. (2020)</ref> proposes a framework in which they use a program debugger to revise the program generated by a neural program synthesizer. However, none of these works take advantage of the similarity between semantic relations present in the knowledge base, and hence, unlike us, they do not use embeddings of similar relation to align relations. More generally, many prior efforts have employed neural models to generate SPARQL-like code for semantic parsing <ref type="bibr" target="#b13">(Dong &amp; Lapata, 2016;</ref><ref type="bibr" target="#b2">Balog et al., 2016;</ref><ref type="bibr">Zhong et al., 2017a)</ref>, SQL queries over relational databases <ref type="bibr">(Zhong et al., 2017b)</ref>, program-structured neural network layouts <ref type="bibr" target="#b1">(Andreas et al., 2016)</ref>, or even proofs for mathematical theorems <ref type="bibr" target="#b54">(Polu &amp; Sutskever, 2020)</ref>. Our work differs in our use of case-based reasoning, whose advantages we showcased earlier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Limitation of our Model and Future Work</head><p>To the best of our knowledge, our work is the first to propose a neuralized case-based reasoning approach for KBQA. We showed that our model is effective in handling complex compositional questions, but our work also has several limitations. First, our model relies on the availability of supervised logical forms such as SPARQL queries, which can be expensive to annotate at scale. In the future, we plan to explore ways to directly learn from question-answer pairs <ref type="bibr" target="#b3">(Berant et al., 2013;</ref><ref type="bibr" target="#b42">Liang et al., 2016)</ref>. Even though, our CBR approach is modular and has several advantages, the retrieve and reuse components of our model are trained separately. In future, we plan to explore avenues for end to end learning for CBR.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Acknowledgments</head><p>We In this section, we include more details about our held-out experiment described in section 3.7. The goal of this experiment is to show that our approach can generalize to unseen relations without requiring any further training of the model. This is a relevant setting to explore, because real-world knowledge bases are often updated with new kinds of relations, and we would like KBQA systems that adapt to handle new information with minimal effort.</p><p>We explicitly hold-out all questions containing a particular relation from the datasets. <ref type="table">Table 9</ref> shows the relation type and the number of questions that are removed as a result of removing the relation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Relation name Train Test</head><p>WebQSP people.person.education 136 86 <ref type="table">Table 9</ref>. Relation type and the corresponding number of NL queries that are held-out.</p><p>Our baseline is a transformer-based seq2seq model which does not utilize similar cases. To be most fair, we use a similar BIGBIRD architecture but only providing the encoder with the NL query (no retrieved cases) as input. Since there are no SPARQL queries given to the encoder, we do not do any hashing of relation strings since that would make learning impossible. To be fair to the baseline, we fine-tuned the baseline model with the held-out train set. This is a time-consuming process; on this small dataset, it took 25x longer to re-train when compared to just re-indexing for our model. On re-training, we found that the baseline model performed very well on the heldout dataset, even outperforming our model. However, when tested on the entire dataset, we found that the model exhibited catastrophic forgetting <ref type="bibr" target="#b28">(Kirkpatrick et al., 2017</ref>) (row 2, col 1) where the performance drastically fell from 59.6% to 1.3%. On further analysis, we found that the model was only predicting the held-out relation for all questions.</p><p>To overcome the catastrophic forgetting issue, we trained the model not only on the held-out data but also with some original training examples (we sample twice the number of held-out examples from the original data) . This is even more time-consuming (75x longer than just re-indexing). Here, we find that the amount of catastrophic forgetting is reduced to some extent, but the overall performance of the baseline model is lower for both the full and held-out sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Details on Automated Case Collection and Human-in-the-Loop Experiments ( §3.7)</head><p>The held-out experiment in the previous section ( §A) was synthetically designed by us to showcase the effectiveness of our approach on unseen relations. However, while conducting analysis, we also noticed that both WebQSP and CWQ actually have queries in the test set for which the required relations are never present in the training set.</p><p>This gives us an opportunity to conduct real experiments to demonstrate the advantage of our model. To add more cases, we resort to a mix of automated data collection and human-in-the-loop strategy. For each of the missing relation, we first try to find NL queries present in the SimpleQuestions <ref type="bibr" target="#b6">(Bordes et al., 2015)</ref>. Freebase KB. For each missing relation type, we try to find questions in the SQ dataset that can be mapped to the missing relation. However, even SQ has missing coverage in which case, we manually generate a question and its corresponding SPARQL query by reading the description of the relation. <ref type="table" target="#tab_3">Table 10</ref> shows the number of questions in the evaluation set which at least has a relation never seen during training and also the number of cases that has been added. For example, we 4 were able to collect 292 questions from SQ and we manually created 72 questions for WebQSP. Overall, we add 3.87 new cases per query relation for WebQSP and 4.35 cases per relation for CWQ. <ref type="table" target="#tab_3">Table 11</ref> shows some example of cases added manually or from SQ. We look up entity ids for entities from the FACC1 alias <ref type="table">table ( §3.3</ref>). Also note, that since we only add questions which are simple in nature, the corresponding SPARQL query can be easily constructed from the missing relation type and the entity id. <ref type="table">Table 7</ref> show the results for our experiment. It is encouraging to see that only after adding 3 -4 similar questions per query relation, our performance increases from 0% to 32.89% on WebQSP, without requiring any additional training. On CWQ, our relative improvement is lesser. On analysis, we found that even though the relations from the new cases were being used correctly, the SPARQL required for answering a CWQ query is more complex (e.g. with the use of operators such as order-by, filter, limit etc.). Since the cases we added are simple in nature where the SPARQL did not have such constructs, the generated queries also did not have them. We believe this can be fixed by adding cases with SPARQL queries containing similar construct and we leave it as future work.</p><p>In <ref type="table" target="#tab_3">Table 13</ref>, we further show some predictions of the model after we added the cases for missing relations. In the first example, our model can pick up the missing relation (in bold) right away without any training/fine-tuning. In the second example, however, our model can only predict part of the SPARQL, which corresponds to Edgar Allan Poe's occupation. Our error analysis show that the problem lies in decomposition of the question and retrieve the other part -earliest publication end date rather than reuse and combine the relations. We leave this issue for future works.</p><p>Importance of this result: Through this experiment, we demonstrate two important properties of our model -interpretability and controllability. Database schemas keep changing and new tables keep getting added to a corporate database. When our QA system gets a query wrong, by looking at the retrieved K-nearest neighbors, users can determine (interpretability) that the required relation is not present in the training set. By adding few cases for the new relations, they can query the DB for similar questions, without needing to train the QA system (controllability). Current black-box NLP models are not capable of doing such point-fixes and our experiment is an initial attempt towards building such systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Ablation</head><p>We also compare with a model with the same reuse component of CBR-KBQA but is trained and tested without retrieving any cases from the case-memory. <ref type="table" target="#tab_3">Table 12</ref> reports the result which shows that having cases is indeed helpful for correctly answering questions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset</head><p>WebQSP <ref type="table" target="#tab_3">CWQ  Attempted revisions  247  1128  Revised program covers more target clauses  29  114  Revised program produces an answer  13  27  Revised clauses match target  9  41   Table 15</ref>. We report the outcomes of the revise step on various datasets. We attempt revision if the predicted program produces no answer. If the revision step aligns some but not all clauses, it is not guanranteed to produce the answer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Analysis of the Revise Step</head><p>In the Revise step, we attempt to fix programs predicted by our Reuse step that did not execute on the knowledge base. The predicted program can be syntactically incorrect or enforce conditions that lead to an unsatisfiable query. In our work, we focus on predicted programs that can be fixed by aligning clauses to relations in the local neighborhood of query entities. Note that we only attempt to fix clauses that contain at least one grounded entity in the KB. This means there are clauses in the predicted program that we do not attempt to align during revision. As a result, not all programs with a successful alignment lead to the correct answer <ref type="table" target="#tab_3">Table 15</ref>. We give examples of successful alignments <ref type="table" target="#tab_3">Table 16</ref> as well as failed attempts at alignment <ref type="table" target="#tab_3">Table 17</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Entity Linking Errors</head><p>Identifying relevant entities is an important step in generating SPARQL queries that yield correct answers. Missing or incorrect entities can drastically change the SPARQL results and therefore, has a significant impact on the final scores. Our analysis shows that a large portion of errors are cascaded from entity linking. In WebQSP, 43.35% of incorrect SPARQL queries are from missing or incorrect entities being copied. In ComplexWebQuestions, the corresponding number is 37.29%.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Our CBR approach derives the logical form for a new query from the solutions of other retrieved queries. Here, the retrieved queries are about different entities but share relational similarity. CBR-KBQA is capable of composing relations from different queries to answer a new query.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Human-in-the-loop setting in which an expert point-fixes a model prediction on a real example by adding a simple case (query + LF containing only one relation) to the KNN index. The model got it wrong initially because no query with the relation (educational institution.colors) was present in the train set. To handle this unseen relation, an expert adds a relevant simple case to the full KNN-index and CBR-KBQA retrieves this case and fixes the erroneous prediction without requiring any re-training.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>An example of a SPARQL logical form for a simple query and its equivalent graph-query.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>In the revise step of CBR-KBQA, any generated relations which are not present for an entity are aligned to edges (that are similar above a threshold) present in the local KG neighborhood. Top figure shows a case where the generated relation belongs to a different domain (e.g. Demeter is a fictional character, however the generated edges were for people because of the retrieval). In the bottom figure, even though edges are in the same domain, generated edges could be missing because of incompleteness of the KB.ing standard practices, relation strings are prepended with a [CLS] token and the word pieces are encoder with the ROBERTA model and the output embeddings of the[CLS]   token is considered as the relation representation. Like previous alignment model, similarity is computer w.r.t cosine similarity.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>What do jamaican people speak? SPARQL: select distinct ?x where { m.03_r3 location.country.languages_spoken ?x }</figDesc><table><row><cell>Graph-query:</cell><cell></cell><cell></cell></row><row><cell>jamaica</cell><cell>location.country.</cell><cell>type:lang</cell></row><row><cell></cell><cell>languages_spoken</cell><cell></cell></row></table><note>NL:</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Demeter people.person.sibling_s fi ct io na l_ ch ar ac te r. si bl in gsfilm.performance .actor Voldemort fil m .c ha ra ct er Harry Porter film.character _portrayed_in_ fims film.performance .actor</head><label></label><figDesc></figDesc><table><row><cell></cell><cell>1. Retrieve</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>2. Reuse</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Retrieved Case</cell></row><row><cell></cell><cell></cell><cell>q' 1 :</cell><cell cols="4">Who were Shakespeare's sibling?</cell></row><row><cell></cell><cell></cell><cell>' 1 :</cell><cell cols="2">Shakespeare</cell><cell cols="2">people.person.sibling_s</cell><cell>type:Person</cell><cell>Zeus</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>3. Revise</cell></row><row><cell>q: Who were</cell><cell>KNN search</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Demeter's siblings?</cell><cell>(case-retrieval)</cell><cell>q' 2 :</cell><cell cols="4">Who are Rihanna's sibling? Retrieved Case</cell><cell>fi c ti o n a l_ c h a ra c e r .d a u g h te r</cell><cell>Vector space alignment generated relation with actual KB relations.</cell></row><row><cell></cell><cell></cell><cell>' 2 :</cell><cell>Rihanna</cell><cell></cell><cell cols="2">people.person.sibling_s</cell><cell>type:Person</cell><cell>Persephone</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Vector space alignment</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Retrieved Case</cell><cell>generated relation with</cell></row><row><cell>q: Who played Voldemort in Harry</cell><cell>KNN search (case-retrieval)</cell><cell>q' 1 :</cell><cell cols="4">Who played dorothy in the wizard of oz movie?</cell><cell>actual KB relations.</cell></row><row><cell>Potter movie series?</cell><cell></cell><cell>' 1 :</cell><cell>Dorothy</cell><cell cols="2">film.character</cell><cell>Wizard of Oz</cell><cell>Ralph Fiennes</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>type:Person</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1 .</head><label>1</label><figDesc>Performance on the WebQSP dataset. GraftNet, PullNet and EmbedKGQA produces a ranking of KG entities hence evaluation is in Hits@k (see text for description). CBR-KBQA significantly outperforms baseline models in the strict exact match accuracy metric.</figDesc><table><row><cell cols="2">Model</cell><cell></cell><cell></cell><cell cols="2">Precision Recall</cell><cell>F1</cell><cell>Accuracy</cell></row><row><cell cols="3">STAGG (Yih et al., 2016)</cell><cell></cell><cell>70.9</cell><cell>80.3</cell><cell>71.7</cell><cell>63.9</cell></row><row><cell cols="4">GraftNet (Sun et al., 2018)</cell><cell>-</cell><cell>-</cell><cell>66.4 (Hits@1)</cell><cell>-</cell></row><row><cell cols="4">PullNet (Sun et al., 2019a)</cell><cell>-</cell><cell>-</cell><cell>68.1 (Hits@1)</cell><cell>-</cell></row><row><cell cols="4">EmbedKGQA (Saxena et al., 2020)</cell><cell>-</cell><cell>-</cell><cell>66.6 (Hits@1)</cell><cell>-</cell></row><row><cell cols="4">T5-11B (Raffel et al., 2020)</cell><cell>62.1</cell><cell>62.6</cell><cell>61.5</cell><cell>56.5</cell></row><row><cell cols="3">T5-11B + Revise</cell><cell></cell><cell>63.6</cell><cell>64.3</cell><cell>63.0</cell><cell>57.7</cell></row><row><cell cols="3">CBR-KBQA (Ours)</cell><cell></cell><cell>73.1</cell><cell>75.1</cell><cell>72.8</cell><cell>70.0</cell></row><row><cell>Dataset</cell><cell cols="2">Precision Recall</cell><cell>F1</cell><cell></cell></row><row><cell>WebQSP</cell><cell>0.761</cell><cell cols="2">0.819 0.789</cell><cell></cell></row><row><cell>CWQ</cell><cell>0.707</cell><cell cols="2">0.910 0.796</cell><cell></cell></row></table><note>Seq2Seq Generator: We use a BIGBIRD generator networkTable 2. Entity linking performance on various datasets</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 .</head><label>4</label><figDesc>Accuracy on the CFQ dataset. Our CBR approach (with order of magnitude less parameters) outperforms a massive T5 model.</figDesc><table><row><cell>Model</cell><cell cols="4">MCD1 MCD2 MCD3 MCD-mean</cell></row><row><cell>T5-11B</cell><cell>72.9</cell><cell>69.2</cell><cell>62.0</cell><cell>67.7</cell></row><row><cell>CBR-KBQA</cell><cell>87.9</cell><cell>61.3</cell><cell>60.6</cell><cell>69.93</cell></row><row><cell>WebQSP</cell><cell></cell><cell></cell><cell>Accuracy(%)</cell><cell>∆</cell></row><row><cell cols="3">CBR-KBQA (before Revise)</cell><cell>69.43</cell><cell>-</cell></row><row><cell cols="2">+Revise (Roberta)</cell><cell></cell><cell>69.49</cell><cell>+0.06</cell></row><row><cell cols="2">+Revise (TransE)</cell><cell></cell><cell>70.00</cell><cell>+0.57</cell></row><row><cell>CWQ</cell><cell></cell><cell></cell><cell>Accuracy(%)</cell><cell>∆</cell></row><row><cell cols="3">CBR-KBQA (before Revise)</cell><cell>65.95</cell><cell>-</cell></row><row><cell cols="2">+Revise (Roberta)</cell><cell></cell><cell>66.32</cell><cell>+0.37</cell></row><row><cell cols="2">+Revise (TransE)</cell><cell></cell><cell>67.11</cell><cell>+1.16</cell></row></table><note>Table 5. Impacts of the revise step. We show that the revise step consistently improves the accuracy on WebQSP and CWQ, espe- cially with the TransE pretrained embeddings.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 .</head><label>6</label><figDesc>Robustness and controllability of our method against transformer. We can easily and quickly adopt to new relations given cases about it, whereas heavily parameterized transformer is finicky, not stable, and can undergo catastrophic forgetting when we try to add new relation information intro its parameters.</figDesc><table><row><cell>Scenario</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 11 (</head><label>11</label><figDesc>Appendix B) shows some example of such cases. Because of the simple nature of the questions, these cases can be created manually (by a user who is knowledgeable about the KB schema) or automatically curated from data sources such as SimpleQuestions</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 8 .</head><label>8</label><figDesc>Analysis of Compositional Reasoning. We compare the performance of models on questions that need novel combinations of relations not seen during training.</figDesc><table><row><cell>Data</cell><cell># Total Q</cell><cell># Q that need comp. reasoning</cell><cell cols="2"># Correct T5 CBR</cell></row><row><cell>CWQ</cell><cell>3531</cell><cell>639</cell><cell>205</cell><cell>270</cell></row><row><cell>CFQ</cell><cell>11968</cell><cell>6541</cell><cell cols="2">3351 3886</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 6</head><label>6</label><figDesc>shows the results. First, the baseline model does worse on the original test set than our approach, indicating that the retrieved cases are helpful. When tested on the held-out relations as is, both our model and the baseline get 0% accuracy (row1, row 4; col2) since the examples require generating an unseen relation. However, we show that if the held-out examples in the train set are added back to the KNN index (without any training), our model's performance significantly increases to 70.6% (row 5, col2).</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 10 .Table 11 .</head><label>1011</label><figDesc>SimpleQuestions (SQ) is a large dataset containing more than 100K NL questions that are 'simple' in nature -i.e. each NL query maps to a single relation (fact) in the Number of questions in the evaluation set that needs a relation which is not seen in the training set. Note that, there can be multiple relations in a question that might not be seen during training. The last two columns show the number of cases added both via human-in-the-loop (H-I-T-L) annotation and automatically from SimpleQuestions dataset.What is the Mexican Peso called? select ?x where { m.012ts8 finance.currency.currency code ?x .} Manual Who invented the telephone? select ?x where { m.0g 3r base.argumentmaps.original idea.innovator ?x .} Manual what area is wrvr broadcated in? select ?x where { m.025z9rx broadcast.broadcast.area served ?x .} SQ Where are Siamese cats originally from? select ?x where { m.012ts8 biology.animal breed.place of origin ?x .} Manual Examples of few added questions and their corresponding SPARQL queries. Notice that the SPARQL queries are very simple to create once we know the name of the missing relation. The source column indicate whether the question was manually created or automatically added from Simple Questions (SQ) dataset.Table 12. Comparison with a baseline model that do not use cases. The numbers denote exact match accuracy.</figDesc><table><row><cell>Cases Added via</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://cloud.google.com/ natural-language</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Zhong, V., Xiong, C., and Socher, R. Seq2sql: Generating structured queries from natural language using reinforcement learning. CoRR, abs/1709.00103, 2017b.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">The H-I-T-L case addition was done by 2 graduate students in the lab.</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>{m.02y8 r, m.06zmv9} Comments:</p><p>The original prediction has missing clauses so alignment produces more answers than target program </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Case-based reasoning: Foundational issues, methodological variations, and system approaches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Aamodt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Plaza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI communications</title>
		<imprint>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Neural module networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Andreas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2016-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Balog</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Gaunt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brockschmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nowozin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tarlow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Deepcoder</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.01989</idno>
		<title level="m">Learning to write programs</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Semantic parsing on freebase from question-answer pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Frostig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Freebase: A collaboratively created graph database for structuring human knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bollacker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Paritosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Sturge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Translating embeddings for modeling multi-relational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Garcia-Duran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yakhnenko</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename></persName>
		</author>
		<editor>Neurips</editor>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Largescale simple question answering with memory networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weston</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1506.02075</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">An efficient memory-based morphosyntactic tagger and parser for dutch. LOT Occasional Series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bosch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Busser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Canisius</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Daelemans</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Retrieve, rerank and rewrite: Soft template based neural summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ACL</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A memory-based part of speech tagger-generator</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Daelemans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zavrel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Berck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gillis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mbt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WVLC</title>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Multi-step retriever-reader interaction for scalable opendomain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dhuliawala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">A simple approach to case-based reasoning in knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Godbole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dhuliawala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mc-Callum</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.14198</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Language to logical form with neural attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Building watson: An overview of the deepqa project</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ferrucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chu-Carroll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gondek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Kalyanpur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lally</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Murdock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Nyberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Prager</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Schlaefer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Welty</surname></persName>
		</author>
		<idno type="DOI">10.1609/aimag.v31i3.2303</idno>
		<ptr target="https://www.aaai.org/ojs/index.php/aimagazine/article/view/2303" />
	</analytic>
	<monogr>
		<title level="j">AI Magazine</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="59" to="79" />
			<date type="published" when="2010-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">The lottery ticket hypothesis: Finding sparse, trainable neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Frankle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Carbin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Compositional generalization in semantic parsing: Pretraining vs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Furrer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Van Zee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Scales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Schärli</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.08970</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">specialized architectures. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Facc1: Freebase annotation of clueweb corpora, version 1 (release date 2013-06-26</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Gabrilovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ringgaard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Subramanya</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>format version 1, correction level 0</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Synthesize, execute and debug: Learning to repair for neural program synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">E</forename><surname>Christensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Song</surname></persName>
		</author>
		<editor>Neurips</editor>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Realm: Retrieval-augmented language model pre-training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Guu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Pasupat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-W</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">A retrieveand-edit framework for predicting structured outputs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">B</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Guu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Oren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<editor>Neurips</editor>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Using fast weights to deblur old memories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">C</forename><surname>Plaut</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ninth annual conference of the Cognitive Science Society</title>
		<meeting>the ninth annual conference of the Cognitive Science Society</meeting>
		<imprint>
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Towards practical program repair with on-demand candidate generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Khurshid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">international conference on software engineering</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="12" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Retrieve, program, repeat: complex knowledge base question answering via alternate meta-learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-F</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Haffari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for the Advancement of Artificial Intelligence (AAAI)</title>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
	<note>International Joint Conference on Artificial Intelligence 2020</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Seo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.01069</idno>
		<title level="m">A comprehensive exploration on wikisql with table-aware word contextualization</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Dense passage retrieval for opendomain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Karpukhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Oguz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Edunov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Measuring compositional generalization: A comprehensive method on realistic data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Keysers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Schärli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Scales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Buisman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Furrer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kashubin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Momchev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sinopalnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Stafiniak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tihon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tsarkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Van Zee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Bousquet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Generalization through memorization: Nearest neighbor language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Khandelwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lewis</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Overcoming catastrophic forgetting in neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Rabinowitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Veness</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Desjardins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Milan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Quan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ramalho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Grabska-Barwinska</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>PNAS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Maintaining organization in a dynamic long-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Kolodner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive science</title>
		<imprint>
			<date type="published" when="1983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Generalization without systematicity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">M</forename><surname>Lake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Baroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Query graph generation for answering multi-hop complex questions from knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Knowledge base question answering with topic units</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jiang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Problem solving in a natural task as a function of experience</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Lancaster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Kolodner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Georgia Tech CS Department</title>
		<imprint>
			<date type="published" when="1987" />
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">S3: syntax-and semantic-guided repair synthesis via programming by examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X.-B</forename><forename type="middle">D</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-H</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Le Goues</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Visser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Foundations of Software Engineering</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Cbr in context: The present and future. Casebased reasoning: Experiences, lessons, and future directions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>Leake</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Deep learning. nature</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ghazvininejad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Retrieval-augmented generation for knowledgeintensive nlp tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Piktus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Petroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Karpukhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Küttler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-T</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Rocktäschel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neurips</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Question and answer test-train overlap in open-domain question answering datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Stenetorp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Riedel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2008.02637</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Paq: 65 million probablyasked questions and what you can do with them</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Minervini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Küttler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Piktus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Stenetorp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Riedel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Efficient one-pass end-to-end entity linking for questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Mehdad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Neural symbolic machines: Learning semantic parsers on freebase with weak supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">D</forename><surname>Forbus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Lao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.00020</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Nl2bash: A corpus and semantic parser for natural language interface to the linux operating system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><forename type="middle">V</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Ernst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Roberta</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<title level="m">A robustly optimized bert pretraining approach</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Rearranging the familiar: Testing compositional generalization in recurrent networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Loula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Baroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">M</forename><surname>Lake</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP Blackbox NLP Workshop</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Catastrophic interference in connectionist networks: The sequential learning problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mccloskey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">J</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Psychology of learning and motivation</title>
		<imprint>
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Distant supervision for relation extraction with an incomplete knowledge base</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Grishman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gondek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Multihop reading comprehension through question decomposition and rescoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hajishirzi</surname></persName>
		</author>
		<idno>doi: 10.18653/ v1/P19-1613</idno>
		<ptr target="https://www.aclweb.org/anthology/P19-1613" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-07" />
			<biblScope unit="page" from="6097" to="6109" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">9th challenge on question answering over linked data (qald-9). language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ngomo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">A three-way model for collective learning on multi-relational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Tresp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-P</forename><surname>Kriegel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Exemplar encoder-decoder for neural conversation generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Pandey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Contractor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Joshi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Text generation with exemplar-based adaptive decoding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Faruqui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Dhingra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Das</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Unsupervised question decomposition for question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-T</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kiela</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.713</idno>
		<ptr target="https://www.aclweb.org/anthology/2020.emnlp-main.713" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-11" />
			<biblScope unit="page" from="8864" to="8880" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Generative language modeling for automated theorem proving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Polu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>JMLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">why should i trust you?&quot; explaining the predictions of any classifier</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">T</forename><surname>Ribeiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Guestrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Examples in legal reasoning: Legal hypotheticals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">L</forename><surname>Rissland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="1983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Remindings and their effects in learning a cognitive skill</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">H</forename><surname>Ross</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive psychology</title>
		<imprint>
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Improving multihop question answering over knowledge graphs using knowledge base embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Saxena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tripathi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Talukdar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Dynamic memory: A theory of reminding and learning in computers and people</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">C</forename><surname>Schank</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1982" />
			<publisher>cambridge university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">A cognitive perspective on medical expertise: theory and implications. Academic medicine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Norman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Boshuizen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">Compositional generalization and natural language variation: Can a semantic parsing approach handle both?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Shaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Pasupat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.12725</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Matching the blanks: Distributional similarity for relation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">B</forename><surname>Soares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Fitzgerald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kwiatkowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Reasoning with neural tensor networks for knowledge base completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ng</surname></persName>
		</author>
		<editor>Neurips</editor>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">On generating characteristic-rich question sets for qa evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sadler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Srivatsa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Gür</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Exploring unexplored generalization challenges for cross-database semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Suhr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Shaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Open domain question answering using early fusion of knowledge bases and text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Dhingra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mazaitis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Open domain question answering with iterative retrieval on knowledge bases and text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Bedrax-Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pullnet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Rotate: Knowledge graph embedding by relational rotation in complex space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z.-H</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-Y</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">The web as a knowledge-base for answering complex questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Talmor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Berant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">An empirical study of example forgetting during deep neural network learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Toneva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T D</forename><surname>Combes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Trischler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gordon</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Observed versus latent features for knowledge base and text inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Continuous Vector Space Models and their Compositionality Workshop</title>
		<imprint>
			<date type="published" when="2015-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Graph attention networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Velickovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liò</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Retrieve and refine: Improved sequence generation models for dialogue</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Dinan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ConvAI Workshop EMNLP</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Label-agnostic sequence labeling by copying nearest neighbors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wiseman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Stratos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Break it down: A question understanding benchmark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wolfson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Geva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Deutch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Berant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="183" to="198" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">The value of semantic parse labeling for knowledge base question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Meek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Suh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Spider: A large-scale human-labeled dataset for complex and crossdomain semantic parsing and text-to-sql task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yasunaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Big bird: Transformers for longer sequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Guruganesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dubey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ainslie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Alberti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ontanon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ravula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neurips</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Question What colors do the school where Donald Stanley Marshall is a grad student use? Predicted SPARQL: select ?x where { ?c ns:education.educational institution.students graduates ?k . ?k ns:education.education.student ns:m.0 y98vd . ?c ns:education.educational institution.colors ?x . } Ground-truth SPARQL: Same as predicted. Predicted answers: crimson Ground-truth answers: crimson Questions: What magazine with earliest publication end date did Edgar Allan Poe work for? Predicted SPARQL: select ?x where { ns:m.02lt8 ns:book.periodical editor.periodicals edited ?y . ?y ns:book.erial tenure.periodical ?x . } Ground-truth SPARQL: select ?x where { ns:m.02lt8 ns:book.periodical editor.periodicals edited ?y . ?y ns:book.editorial tenure.periodical ?x . ?x ns:book.magazine.place of publication ?c . ?c ns:book.place of publication period.to ?num . } order by ?num limit 1 Predicted answers: Graham&apos;s Magazine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Zelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NCAI</title>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
	<note>Burton&apos;s Gentleman&apos;s Magazine Ground-truth answers: Burton&apos;s Gentleman&apos;s Magazine Table 13. Compositional examples from the H-I-T-L experiment. Query: What was the title of the first book Charles Darwin wrote? Target SPARQL: select distinct ?x where { m. 01lwx book.author.works written ?x . ?x common.creative work.release date ?time} order by xsd:datetime(?time) limit 1</note>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
				<title level="m">KNN1 question: What books did Lincoln write? KNN1 SPARQL: select distinct ?x where { m.0gzh book.author.works written ?x} KNN2 question: What was the first album of Michael Jackson? KNN2 SPARQL: select distinct ?x where { m.09889g music.artist.album ?x . ?x common.creative work.release date ?time} order by xsd:datetime(?time) limit</title>
		<imprint>
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<monogr>
				<title level="m">Table 14. A NL query shown with its target SPARQL program. Also shown are two nearest neighbor retrieved cases. Note, the target query can be generated by copying one relation from each of the retrieved cases (book.author.works written from KNN1 and common.creative work.release date from KNN2) WebQSP Question: when did kaley cuoco m.03kxp7 join charmed m.01f3p ? Predicted SPARQL: SELECT DISTINCT ?x WHERE { ns:m.03kxp7 ns:tv.tv character.appeared in tv program ?y . ?y ns:tv.regular tv appearance.from ?x . ?y ns:tv.regular tv appearance.series ns:m.01f3p . } Ground-truth SPARQL: SELECT DISTINCT ?x WHERE { ns:m.03kxp7 ns:tv.tv actor.starring roles ?y . ?y ns:tv.regular tv appearance.from ?x . ?y ns:tv.regular tv appearance.s eries ns:m.01f3p . } Revised SPARQL: SELECT DISTINCT ?x WHERE { ns:m.03kxp7 ns:tv.tv actor.starring roles ?y . ?y ns:tv.regular tv appearance.from ?x . ?y ns:tv.regular tv appearance.s eries ns:m.01f3p . } CWQ Question: What text in the religion which include Zhang Jue m.02gjv7 as a key figure is considered to be sacred m.02vt2rp ? Predicted SPARQL: SELECT DISTINCT ?x WHERE { ?c ns:religion.religion.deities ns:m.02gjv7</title>
		<imprint/>
	</monogr>
	<note>c ns:religion.religion.texts ?x . . . . benign filters . . . }</note>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">} Question: What is the mascot of the educational institution that has a sports team named the North Dakota State Bison m.0c5s26 ? Predicted SPARQL: SELECT DISTINCT ?x WHERE { ?c ns:education.educational institution.sports teams ns:m.0c5s26</title>
	</analytic>
	<monogr>
		<title level="m">ns:education.educational institution.mascot ?x . } Ground-truth SPARQL: SELECT DISTINCT ?x WHERE { ?c ns:education.educational institution.sports teams ns:m.0c41 v . ?c ns:education.educational institution.mascot ?x . } Revised SPARQL: SELECT DISTINCT ?x WHERE { ?c ns:education.educational institution.athletics brand ns:m.0c5s26 . ?c ns:education.educational institution.mascot ?x . } Comments: The entity linker has tagged the bison as a university symbol</title>
		<imprint/>
	</monogr>
	<note>SPARQL: SELECT DISTINCT ?x WHERE { ?c ns:religion.religion.notable figures ns:m.02gjv7 . ?c ns:religion.religion.texts ?x .} Revised SPARQL: SELECT DISTINCT ?x WHERE { ?c ns:religion.religion.notable figures ns:m.02gjv7 . ?c ns:religion.religion.texts ?x . . . . benign filters. m.0c5s26) rather than the Bison football team (m.0c41 v). Alignment helps the model recover from this by picking the relation that connects the tagged entity to the university</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
