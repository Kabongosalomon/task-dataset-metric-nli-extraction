<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">EDGNN: A SIMPLE AND POWERFUL GNN FOR DI- RECTED LABELED GRAPHS</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2019-12-04">4 Dec 2019</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Jaume</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">An-Phi</forename><surname>Nguyen</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">María</forename><surname>Rodríguez Martínez</surname></persName>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>EPFL</roleName><forename type="first">Jean-Philippe</forename><surname>Thiran</surname></persName>
							<email>jean-philippe.thiran@epfl.ch</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Gabrani</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">IBM Research</orgName>
								<address>
									<settlement>Zurich EPFL, Lausanne</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">IBM Research</orgName>
								<address>
									<settlement>Zurich ETH, Zurich</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">IBM Research</orgName>
								<address>
									<settlement>Zurich</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">IBM Research</orgName>
								<address>
									<settlement>Zurich</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">EDGNN: A SIMPLE AND POWERFUL GNN FOR DI- RECTED LABELED GRAPHS</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2019-12-04">4 Dec 2019</date>
						</imprint>
					</monogr>
					<note>Published as a RLGM workshop paper at ICLR 2019</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T11:57+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The ability of a graph neural network (GNN) to leverage both the graph topology and graph labels is fundamental to building discriminative node and graph embeddings. Building on previous work, we theoretically show that edGNN, our model for directed labeled graphs, is as powerful as the Weisfeiler-Lehman algorithm for graph isomorphism. Our experiments support our theoretical findings, confirming that graph neural networks can be used effectively for inference problems on directed graphs with both node and edge labels. Code available at</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>In recent years, much work has been devoted to extending deep-learning models to graphs, e.g., <ref type="bibr" target="#b22">Scarselli et al. (2009)</ref> <ref type="bibr">;</ref><ref type="bibr" target="#b1">Bruna et al. (2014)</ref>; <ref type="bibr" target="#b15">Li et al. (2016)</ref>; <ref type="bibr" target="#b5">Defferrard et al. (2016)</ref>; <ref type="bibr" target="#b12">Kipf &amp; Welling (2017)</ref>; <ref type="bibr" target="#b8">Hamilton et al. (2017a;</ref><ref type="bibr" target="#b27">b)</ref>; <ref type="bibr" target="#b26">Veličković et al. (2017)</ref>; <ref type="bibr" target="#b29">Ying et al. (2018)</ref>. <ref type="bibr" target="#b6">Gilmer et al. (2017)</ref> formulated numerous such models within their proposed Message Passing Neural Network (MPNN) framework. In this model, the state of a vertex is represented by a feature vector. The state is then updated iteratively via a two-step strategy: For each vertex (i) in the aggregation step, the feature vectors of the neighboring vertices are combined into a single vector via a differentiable operator, e.g., a sum. Then, (ii) in the update step, a new state is computed by applying another differentiable operator, e.g., a one-layer perceptron, to the current state of the vertex and to the aggregate vector from the previous step.</p><p>In two recent works, <ref type="bibr" target="#b28">Xu et al. (2019)</ref> and , independently proved that certain formulations of MPNNs are as powerful as the Weisfeiler-Lehman (WL) algorithm for graph isomorphism <ref type="bibr" target="#b27">(Weisfeiler &amp; Leman (1968)</ref>). In practice, this means that there exist MPNNs able to learn unique representations for (almost) all undirected node-labeled graphs, which is desirable for such tasks as node or graph classification. Note that previous work has drawn a parallel between the WL test and the MPNN, e.g., <ref type="bibr" target="#b8">Hamilton et al. (2017a)</ref>; ; <ref type="bibr" target="#b14">Lei et al. (2017)</ref>.</p><p>In this paper, we extend the above-mentioned results to directed graphs with labels for both nodes and edges. In particular, by extending the theoretical framework provided by , we show that there exist MPNNs as powerful as the (one-dimensional) WL algorithm for directed labeled graphs. Although this problem has already been addressed, e.g., <ref type="bibr" target="#b15">Li et al. (2016)</ref>; <ref type="bibr" target="#b17">Niepert et al. (2016)</ref>; <ref type="bibr" target="#b25">Simonovsky &amp; Komodakis (2017)</ref>; <ref type="bibr" target="#b0">Beck et al. (2018)</ref>; <ref type="bibr" target="#b23">Schlichtkrull et al. (2018)</ref>, we present a theoretically-grounded GNN formulation for directed labeled graphs. We experimentally corroborate our theoretical results by comparing our model, edGNN, against state-ofthe-art models for node and graph classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">THEORETICAL FRAMEWORK</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">NOTATION AND SETUP</head><p>As our work is an extension of , we maintain a notation consistent to theirs in order to more easily reference their results.</p><p>A graph G is a pair (V, E), where V is the set of vertices, E is the set of edges and the directed edge (u, v) ∈ E for u, v ∈ V is an edge starting in u and ending in v. We will denote the vertex and the edge sets of G as V G and E G , respectively.</p><p>We are interested in graphs with both node and edge labels. We therefore assume that, given a graph G, there exists a vertex-labeling function l V : V G → X and an edge-labeling function l E : E G → Z that assign to each vertex and edge of G a label from countable sets X and Z. For the rest of this paper, we will refer to graphs with node and edge labels simply as labeled graphs.</p><formula xml:id="formula_0">For each vertex v ∈ V , we can define the neighborhood N (v) := {u ∈ V | (v, u) ∈ E ∨ (u, v) ∈ E}.</formula><p>As we are dealing with directed graphs, we distinguish between incoming neighbors</p><formula xml:id="formula_1">N I (v) := {u ∈ V | (u, v) ∈ E} and outgoing neighbors N O (v) := {u ∈ V | (v, u) ∈ E}. Naturally, N (v) = N I (v) ∪ N O (v). The cardinalities |N (v)|, |N I (v)| and |N O (v)</formula><p>| of the neighborhoods are referred to as the degree, the in-degree and the out-degree of vertex v, respectively.</p><p>Definition 2.1. Two labeled directed graphs G and H are isomorphic if there exists a bijection f :</p><formula xml:id="formula_2">V G → V H such that (u, v) ∈ E G if and only if (f (u), f (v)) ∈ E H with l VG (v) = l VH (f (v)) and l EG (u, v) = l EH (f (u), f (v)).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">THE WEISFEILER-LEHMAN ALGORITHM</head><p>The Weisfeiler-Lehman (WL) test <ref type="bibr" target="#b27">(Weisfeiler &amp; Leman (1968)</ref>) is an algorithm to distinguish whether two graphs are non-isomorphic. We present the test in its one-dimensional variant, also known as the naive vertex refinement. We will start by presenting the WL test on node-labeled graphs, and later discuss its extension to directed labeled graphs.</p><p>At initialization, the vertices are labeled consistently with the vertex-labeling function l V . We call this the initial coloring of the graph and we denote it as c</p><formula xml:id="formula_3">(0) l (v) := l V (v), ∀v ∈ V .</formula><p>The algorithm then proceeds in a recursive fashion. At iteration t, new labels are computed for each vertex from the current labels of the vertex itself and its neighbors, i.e.,</p><formula xml:id="formula_4">c (t) l (v) = g c (t−1) l (v), c (t−1) l (u) : u ∈ N (v) ,<label>(1)</label></formula><p>where g is an injective hashing function, and · denotes a multiset, i.e., a generalization of a set that allows elements to be repeated. Each iteration is performed in parallel for the two graphs to be tested, G and H. If at some iteration t, the number of vertices assigned to a label l ∈ X differs for the two graphs, then the algorithm stops, concluding that the two graphs are not isomorphic. Otherwise, the algorithm will stop whenever a stable coloring is achieved, i.e., whenever c</p><formula xml:id="formula_5">(t) l (v G ) = c (t) l (v H ) for all t ≥ T and for any pair (v G , v H ) with v G ∈ V G , v H ∈ V H , and c (T ) l (v G ) = c (T ) l (v H )</formula><p>. This is guaranteed to happen at most after T = max{|V G |, |V H |} iterations. In this case, G and H are considered isomorphic.</p><p>Despite a few corner cases, the WL test is able to distinguish a wide class of graphs <ref type="bibr" target="#b2">(Cai et al. (1992)</ref>). Moreover, the most efficient implementation of the algorithm has a runtime complexity which is quasi-linear in the number of vertices <ref type="bibr" target="#b7">(Grohe et al. (2017)</ref>).</p><p>The extension of the WL test to a directed graph with edge labels is straightforward <ref type="bibr" target="#b7">(Grohe et al. (2017)</ref>; <ref type="bibr" target="#b18">Orsini et al. (2016)</ref>). During the recursive step, for each vertex v, we need to include the in-degrees and out-degrees of v separately in the hashing function with respect to each edge label.</p><p>Let us denote an edge label as e ∈ Z. For each vertex v, we then define n I v (e) := |{u ∈ N I (v) | l E (u, v) = e}| as the number of edges incoming to v with label e. Similarly, n O v (e) is defined for outgoing edges. Then, Eq. (1) can be adapted for labeled directed graphs in the follow-ing way:</p><formula xml:id="formula_6">c (t) l (v) = g c (t−1) l (v), c (t−1) l (u) : u ∈ N (v) , n I v (e), e : ∃(u, v) ∈ E with l E (u, v) = e , n O v (e), e : ∃(v, u) ∈ E with l E (v, u) = e .</formula><p>(2)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">GRAPH NEURAL NETWORKS</head><p>Graph neural networks architectures implement a neighborhood aggregation strategy. Similar to , our work focuses on the GNN model presented by <ref type="bibr" target="#b8">Hamilton et al. (2017a)</ref>, which implements this strategy with the node update function</p><formula xml:id="formula_7">f (t) (v) = σ f (t−1) (v)W (t) 1 + u∈N (v) f (t−1) (u)W (t) 2 ,<label>(3)</label></formula><p>where  showed that there exists a sequence (W</p><formula xml:id="formula_8">f (t) (v) ∈ R 1×d (t) is the d (t) -dimensional node representation, or node embedding, at time step t of the vertex v, and W (t) 1 , W (t) 2 ∈ R d (t−1) ×d (t) are weight matrices. The initial represen- tation f (0) (v) is consistent with the vertex-labeling function l V , i.e., f (0) (v) = f (0) (u) if and only if l V (v) = l V (u) for all v, u ∈ V .</formula><formula xml:id="formula_9">(t) 1 , W (t)</formula><p>2 ) such that the GNN model in Eq. <ref type="formula" target="#formula_7">(3)</ref> is as powerful as the WL test.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">EXTENSION TO DIRECTED LABELED GRAPHS</head><p>The extension of Eq. (3) to directed labeled graphs follows the WL test extension. We simply need to augment the equation with embeddings for the labeled edges with incoming and outgoing edges considered separately, i.e.,</p><formula xml:id="formula_10">f (t) (v) = σ f (t−1) (v)W (t) 1 + u∈N (v) f (t−1) (u)W (t) 2 + + (u,v)∈E f E u, v, l E (u, v) W (t) 3 + (v,u)∈E f E v, u, l E (v, u) W (t) 4 ,<label>(4)</label></formula><p>where <ref type="bibr">u)</ref>. The embeddings f E should be defined such that <ref type="bibr">(u,v)</ref></p><formula xml:id="formula_11">f E v, u, l E (v, u) ∈ R 1×dE is the d E -dimensional embedding of the edge (v, u) with la- bel l E (v,</formula><formula xml:id="formula_12">∈E f E u, v, l E (u, v) = (u,v ′ )∈E f E u, v ′ , l E (u, v ′ ) if and only if n I v (e), e : ∃(u, v) ∈ E with l E (u, v) = e = n I v ′ (e), e : ∃(u, v ′ ) ∈ E with l E (u, v ′ ) = e .</formula><p>The same should hold for outgoing edges. For practical applications, this can be achieved by using one-hot encodings of the edge labels. We can now directly extend the theorems presented in . Theorem 2.1 (Theorem 1 in ). Let G be a directed labeled graph. Then for all t ≥ 0 and for all choices of initial colorings f (0) consistent with l V and of edge embeddings f E consistent with l E , and weights W</p><formula xml:id="formula_13">(t) 1 , W (t) 2 , W (t) 3 , W (t) 4 c (t) l (v) = c (t) l (u) ⇒ f (t) (v) = f (t) (u) ∀u, v ∈ V (5) with c (t)</formula><p>l and f (t) defined in Eqs.</p><p>(2) and (4), respectively.  prove this theorem by induction. The proof is essentially the same for our extended case. In fact, as neither the labels l E nor the embeddings f E change over the iterations, there is no need to include them in the induction step. Theorem 2.2 (Theorem 2 in ). Let G be a directed labeled graph with finite vertex degree. Then there exists a sequence (W</p><formula xml:id="formula_14">(t) 1 , W (t) 2 , W (t) 3 , W (t) 4 ) with t ≥ 0 such that c (t) l (v) = c (t) l (u) ⇔ f (t) (v) = f (t) (u) ∀u, v ∈ V<label>(6)</label></formula><p>The proof is provided in the supplemental material. Note that we specifically require the graph to have finite vertex degree. However, this is not a strong assumption in real-world applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">GRAPH CLASSIFICATION</head><p>For graph classification tasks, we need a representation f G of the graph. We build it from the node representations f (t) (v) following the formulation of <ref type="bibr" target="#b28">Xu et al. (2019)</ref>:</p><formula xml:id="formula_15">f G = Concat v∈VG f (t) (v) t = 0, . . . , T .<label>(7)</label></formula><p>Note that, although T should theoretically be at least |V G | <ref type="figure">(Section 2.1.1)</ref>, only a few layers (i.e., iterations) are used in practice to update the node representations. Finally, a linear classifier is applied to the graph representation to perform the classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">EXPERIMENTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">DATASETS AND BASELINES</head><p>We benchmark our algorithm edGNN on graph and node classification tasks. For graph classification tasks, we benchmark our model against the Subgraph Matching Kernel (CSM) <ref type="bibr" target="#b13">(Kriege &amp; Mutzel (2012)</ref>), Weisfeiler-Lehman Shortest Path Kernel <ref type="bibr" target="#b24">(Shervashidze et al. (2011)</ref>) and R-GCN <ref type="bibr" target="#b23">(Schlichtkrull et al. (2018)</ref>) . As R-GCN only defines how to build node embeddings, we reuse the formulation of <ref type="bibr" target="#b28">Xu et al. (2019)</ref> to build a graph-level representation. For node classification tasks, we compare our model against R-GCN <ref type="bibr" target="#b23">(Schlichtkrull et al. (2018)</ref>), RDF2Vec ) and WL <ref type="bibr" target="#b24">(Shervashidze et al. (2011);</ref><ref type="bibr" target="#b3">De Vries &amp; De Rooij (2015)</ref>) on the AIFB and MUTAG dataset ). Dataset statistics as well as training details are reported in the Appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">RESULTS AND DISCUSSION</head><p>In <ref type="table">Table 1</ref>, we report results for the graph (left-hand side) and node classification (right-hand side) tasks. Our provably powerful model, edGNN, reaches comparable performance with the state-ofthe-art. We observe that the kernel-based and gradient-based methods (R-GCN and edGNN) perform similarly without being able to clearly identify better models. We conjecture that the relatively small size of the datasets (e.g., only 188 graphs in the MUTAG dataset) does not allow to fully explore the potential of the most expressive models. This does not contradict our theoretical findings. In fact, the power of a learnable model does not guarantee its generalization nor that the best model can be learned. However, it is true that, in the best-case scenario, a more powerful model should perform better than a less powerful one, as shown by the results regarding the best-learned edGNN model (max). An interesting future research direction would be the study of all the proposed models fitting the MPNN framework in order to understand whether they can be as powerful as the WL test or whether, instead, they introduce a particular bias. <ref type="table">Table 1</ref>: Graph (left) and node (right) classification results in accuracy averaged over ten runs. For the proposed edGNN approach, we report both the average (avg) and the maximum accuracy (max). Results are expressed as percentages. For graph classification, following prior art, we performed 10-fold cross validation. For node classification, we used the split provided by  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">APPENDIX</head><p>We ran our graph classification experiments with a batch size of 8 and a learning rate of 10 −4 with a weight decay of 5 × 10 −4 . We then performed a parameter search over the number of layers and node embedding size. The best performance was reached by using two layers and 64 hidden units. We used a ReLu activation at each layer. The system was trained for at most 40 epochs with early stopping with respect to the validation set cross-entropy loss.</p><p>R-GCN for graph classification was also trained with a batch size of 8, a learning rate of 10 −4 with a weight decay of 5 × 10 −4 . We used three layers and 64 hidden units with learned initial embeddings for the nodes (instead of a one-hot encoding for edGNN). We used a basis decomposition with the number of basis set to the number of relations. Results for CSM <ref type="bibr" target="#b13">(Kriege &amp; Mutzel (2012)</ref>) and WLSP <ref type="bibr" target="#b24">(Shervashidze et al. (2011)</ref>) are based on the re-implementation of <ref type="bibr" target="#b13">Kriege &amp; Mutzel (2012)</ref>. All our experiments were performed with 10-fold cross validation as in <ref type="bibr" target="#b13">Kriege &amp; Mutzel (2012)</ref>.</p><p>Dataset statistics for the graph classification tasks are shown in <ref type="table" target="#tab_1">Table 2</ref>, whereas <ref type="table" target="#tab_2">Table 3</ref> shows the accuracy results together with the standard deviation.  The node classification experiments were run with a learning rate of 5 × 10 −3 without weight decay. We used dropout 0.5 on each layer with a ReLu activation. The best performance was achieved by using 2 layers and 64 hidden units. The maximum number of epochs was set to 400 with early stopping with respect to the validation set cross-entropy loss. Results with R-GCN <ref type="bibr" target="#b23">(Schlichtkrull et al. (2018)</ref>), RDF2Vec ) and WL <ref type="bibr" target="#b24">(Shervashidze et al. (2011)</ref>) are based on the re-implementation of <ref type="bibr" target="#b23">Schlichtkrull et al. (2018)</ref>.   <ref type="formula" target="#formula_4">(2015)</ref>), RDF2Vec ) and R-GCN <ref type="bibr" target="#b23">(Schlichtkrull et al. (2018)</ref> </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell cols="7">: Graph classification dataset statistics with the number of graphs (Graphs), the number of</cell></row><row><cell cols="7">classes (Classes), the average number of nodes per graph (Avg nodes), the average number of edges</cell></row><row><cell cols="7">per graph (Avg edges), the number of node labels (Node labels) and the number of edge labels (Edge</cell></row><row><cell>labels).</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Dataset</cell><cell cols="6">Graphs Classes Avg nodes Avg edges Node labels Edge labels</cell></row><row><cell>MUTAG</cell><cell>188</cell><cell>2</cell><cell>17.9</cell><cell>19.8</cell><cell>6</cell><cell>3</cell></row><row><cell>PTC FM</cell><cell>349</cell><cell>2</cell><cell>14.1</cell><cell>14.5</cell><cell>18</cell><cell>4</cell></row><row><cell>PTC FR</cell><cell>351</cell><cell>2</cell><cell>14.6</cell><cell>15.0</cell><cell>19</cell><cell>4</cell></row><row><cell>PTC MM</cell><cell>336</cell><cell>2</cell><cell>14.0</cell><cell>14.3</cell><cell>20</cell><cell>4</cell></row><row><cell>PTC MR</cell><cell>344</cell><cell>2</cell><cell>14.3</cell><cell>14.7</cell><cell>18</cell><cell>4</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Graph classification results in accuracy obtained with 10-fold cross validation. Results are expressed as percentages. edGNN is compared with the Subgraph Matching Kernel</figDesc><table><row><cell cols="6">(CSM) (Kriege &amp; Mutzel (2012)), Weisfeiler-Lehman Shortest Path Kernel (Shervashidze et al.</cell></row><row><cell cols="3">(2011)) and R-GCN (Schlichtkrull et al. (2018)).</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Model</cell><cell>MUTAG</cell><cell>PTC FM</cell><cell>PTC FR</cell><cell>PTC MM</cell><cell>PTC MR</cell></row><row><cell>CSM</cell><cell cols="3">85.4 ± 1.2 63.8 ± 1.0 65.5 ± 1.4</cell><cell>63.3 ± 1.7</cell><cell>58.1 ± 1.6</cell></row><row><cell>WLSP</cell><cell cols="5">85.4 ± 1.2 60.4 ± 1.32 65.7 ± 1.3 66.6 ± 1.1 59.7 ± 1.6</cell></row><row><cell>R-GCN</cell><cell>81.5 ± 2.1</cell><cell cols="3">60.7 ± 1.7 65.8 ± 0.6 64.7 ± 1.7</cell><cell>58.2 ± 1.7</cell></row><row><cell cols="3">edGNN (avg) 86.9 ± 1.0 59.8 ± 1.5</cell><cell>65.7 ± 1.3</cell><cell>64.4 ± 0.8</cell><cell>56.3 ± 1.9</cell></row><row><cell>edGNN (max)</cell><cell>88.8</cell><cell>62.2</cell><cell>68.0</cell><cell>66.1</cell><cell>59.4</cell></row><row><cell cols="2">4.3.2 NODE CLASSIFICATION</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Node classification dataset statistics with the number of classes (Classes), the total number of nodes (Nodes), the total number of edges (Edges) and the number of edge labels (Edge labels).</figDesc><table><row><cell>Dataset</cell><cell cols="3">Classes Nodes Edges Edge labels</cell></row><row><cell>AIFB</cell><cell>4</cell><cell>8,285 29,043</cell><cell>45</cell></row><row><cell>MUTAG</cell><cell>2</cell><cell>23,644 74,227</cell><cell>23</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>Node classification results in accuracy averaged over ten runs. Results are expressed as percentages.</figDesc><table /><note>edGNN is compared with WL (De Vries &amp; De Rooij</note></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">PROOF OF THEOREM 2.2</head><p>For a given vertex v, we define E I v := {l <ref type="bibr">E (u, v)</ref> : ∃(u, v) ∈ E} as the set of labels of edges incoming into the vertex v. We then define L I v := Concat n I v (e), e : ∀e ∈ E I v . That is, for each vertex v, we create a label by concatenating all the labels of the incoming edges together with their multiplicities n I v (e). Similarly, we define E O v and L O v for the outgoing edges. Note that the pairs n I v (e), e and n O v (e), e take values in L := N × Z. Therefore,</p><p>For all vertices v, we can construct a function h v :</p><p>Note that, as we are considering graphs with finite vertex degree,</p><p>is a countable set because the finite Cartesian product of countable sets is itself countable. Thus, as we built the function h v to be bijective, the sets Y v , and their countable union Y := v∈V Y v , are also countable (for results on countable sets, refer for example to <ref type="bibr" target="#b19">Patterson &amp; Warner (1967)</ref>).</p><p>We can then construct an injective hash function g ′ such that</p><p>where the right-hand side is the relabeling function defined in Eq.</p><p>(2).</p><p>These constructions highlight the fact that an iteration of the WL algorithm on a directed labeled graph is the same as performing an iteration of the WL algorithm on a undirected node-only-labeled graph, where node labels take values in an appropriately augmented label set Y.</p><p>The same equivalence can be highlighted between the GNN update functions in Eqs.</p><p>(3) and (4). In fact, Eq. (4) can be rewritten as</p><p>where f (t)</p><p>is the embedding resulting from the (horizontal) concatenation of</p><p>The reformulations presented in Eqs. (8) and (9) allow us to treat our problem as one of undirected graphs with labels only for nodes. We can therefore prove this theorem by directly using the proof of Theorem 2 in .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">DETAILS OF TRAINING AND MORE RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">INITIALIZATION</head><p>We initialize the node and edge features with a one-hot encoding of their input label. For node classification, we use the in-degree as input label of the nodes. To model the outgoing edges of the node classification graphs, we create new artificial relations by reversing each directed edge. We also report results without reversing the edges (reg). and with learned embeddings (emb) instead of a one-hot encoding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">GRAPH CLASSIFICATION</head><p>The tasks predict the mutagenicity <ref type="bibr" target="#b4">(Debnath et al. (1991)</ref>; <ref type="bibr" target="#b13">Kriege &amp; Mutzel (2012)</ref>) (MUTAG) and the toxicity <ref type="bibr" target="#b10">(Helma et al. (2003)</ref>) of chemical compounds (PTC).</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Graph-to-Sequence Learning using Gated Graph Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gholamreza</forename><surname>Haffari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="273" to="283" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Spectral Networks and Deep Locally Connected Networks on Graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joan</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">An optimal lower bound on the number of variables for graph identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin</forename><forename type="middle">Yi</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Fürer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Immerman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Combinatorica</title>
		<imprint>
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Substructure counting graph kernels for machine learning from RDF data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerben Klaas Dirk De</forename><surname>Vries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>De Rooij</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Web Semantics</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Structure-Activity Relationship of Mutagenic Aromatic and Heteroaromatic Nitro Componds. Correlation with Modelcular Orbital Energies and Hydrophobicity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asim</forename><surname>Kumar Debnath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rosa</forename><forename type="middle">L</forename><surname>Lopez De Compadre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gargi</forename><surname>Debnath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">J</forename><surname>Shusterman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Corwin</forename><surname>Hansch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Med. Chem</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="786" to="797" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michaël</forename><surname>Defferrard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Bresson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Neural Message Passing for Quantum Chemistry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Gilmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><forename type="middle">S</forename><surname>Schoenholz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><forename type="middle">F</forename><surname>Riley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><forename type="middle">E</forename><surname>Dahl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1273" to="1272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Color Refinement and its Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Grohe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristian</forename><surname>Kersting</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Mladenov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Schweitzer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Inductive Representation Learning on Large Graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rex</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Representation Learning on Graphs: Methods and Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rex</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<idno>1476-4687</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Data Engineering Bulletin</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The Predictive Toxicology Challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Helma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R D</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kramer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Srinivasan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1179" to="82" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Predicting Organic Reaction Outcomes with Weisfeiler-Lehman Network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wengong</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Connor</forename><forename type="middle">W</forename><surname>Coley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tommi</forename><surname>Jaakkola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Semi supervised classification with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Subgraph Matching Kernels for Attributed Graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nils</forename><surname>Kriege</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petra</forename><surname>Mutzel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Deriving Neural Architectures from Sequence and Graph Kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wengong</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tommi</forename><surname>Jaakkola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Gated Graph Sequence Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yujia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Tarlow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Brockschmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Weisfeiler and Leman Go Neural: Higher-order Graph Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Ritzert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Fey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><forename type="middle">Eric</forename><surname>Lenssen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaurav</forename><surname>Rattan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Grohe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">33rd AAAI Conference on Artificial Intelligence (AAAI)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning Convolutional Neural Networks for Graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathias</forename><surname>Niepert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantin</forename><surname>Kutzkov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2014" to="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Graph invariant kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesco</forename><surname>Orsini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Frasconi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc De</forename><surname>Raedt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Artificial Intelligence (IJCAI)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Modern Algebra</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Patterson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seth</forename><surname>Warner</surname></persName>
		</author>
		<ptr target="http://www.journals.cambridge.org/abstract{_}S0013091500012098" />
		<imprint>
			<date type="published" when="1965-12" />
			<publisher>Cambridge University Press</publisher>
			<biblScope unit="volume">15</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">RDF2Vec: RDF graph embeddings for data mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petar</forename><surname>Ristoski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heiko</forename><surname>Paulheim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Lecture Notes in Computer Science</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A collection of benchmark datasets for systematic evaluations of machine learning on the semantic web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petar</forename><surname>Ristoski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerben Klaas Dirk De</forename><surname>Vries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heiko</forename><surname>Paulheim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Lecture Notes in Computer Science</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The graph neural network model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franco</forename><surname>Scarselli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Gori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ah</forename><surname>Chung Tsoi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Hagenbuchner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriele</forename><surname>Monfardini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Modeling Relational Data with Graph Convolutional Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Schlichtkrull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Bloem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rianne</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Titov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Extended Semantic Web Conference</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Weisfeiler-Lehman Graph Kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nino</forename><surname>Shervashidze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Schweitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><forename type="middle">Jan</forename><surname>Van Leeuwen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Mehlhorn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karsten</forename><forename type="middle">M</forename><surname>Borgwardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2539" to="2561" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Dynamic edge-conditioned filters in convolutional neural networks on graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Simonovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Komodakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings -30th IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>-30th IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petar</forename><surname>Veličković</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillem</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arantxa</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adriana</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Liò</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<title level="m">Graph Attention Networks. International Conference on Learning Representations (ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A reduction of a graph to a canonical form and an algebra arising during this reduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Weisfeiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A A</forename><surname>Leman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Nauchno-Technicheskaya Informatsia</title>
		<imprint>
			<date type="published" when="1968" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="2" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">How Powerful are Graph Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keyulu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weihua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanie</forename><surname>Jegelka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Hierarchical Graph Representation Learning with Differentiable Pooling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rex</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaxuan</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
