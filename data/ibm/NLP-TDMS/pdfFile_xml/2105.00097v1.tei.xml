<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Self-supervised Augmentation Consistency for Adapting Semantic Segmentation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikita</forename><surname>Araslanov</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">TU</orgName>
								<address>
									<settlement>Darmstadt 2 hessian.AI</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Roth</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">TU</orgName>
								<address>
									<settlement>Darmstadt 2 hessian.AI</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Self-supervised Augmentation Consistency for Adapting Semantic Segmentation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T12:25+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We propose an approach to domain adaptation for semantic segmentation that is both practical and highly accurate. In contrast to previous work, we abandon the use of computationally involved adversarial objectives, network ensembles and style transfer. Instead, we employ standard data augmentation techniques -photometric noise, flipping and scaling -and ensure consistency of the semantic predictions across these image transformations. We develop this principle in a lightweight self-supervised framework trained on co-evolving pseudo labels without the need for cumbersome extra training rounds. Simple in training from a practitioner's standpoint, our approach is remarkably effective. We achieve significant improvements of the state-ofthe-art segmentation accuracy after adaptation, consistent both across different choices of the backbone architecture and adaptation scenarios.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Unsupervised domain adaptation (UDA) is a variant of semi-supervised learning <ref type="bibr" target="#b5">[6]</ref>, where the available unlabelled data comes from a different distribution than the annotated dataset <ref type="bibr" target="#b3">[4]</ref>. A case in point is to exploit synthetic data, where annotation is more accessible compared to the costly labelling of real-world images <ref type="bibr" target="#b58">[59,</ref><ref type="bibr" target="#b59">60]</ref>. Along with some success in addressing UDA for semantic segmentation <ref type="bibr" target="#b66">[67,</ref><ref type="bibr" target="#b68">69,</ref><ref type="bibr" target="#b79">80,</ref><ref type="bibr" target="#b90">91]</ref>, the developed methods are growing increasingly sophisticated and often combine style transfer networks, adversarial training or network ensembles <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b67">68,</ref><ref type="bibr" target="#b76">77]</ref>. This increase in model complexity impedes reproducibility, potentially slowing further progress.</p><p>In this work, we propose a UDA framework reaching state-of-the-art segmentation accuracy (measured by the Intersection-over-Union, IoU) without incurring substantial training efforts. Toward this goal, we adopt a simple semisupervised approach, self-training <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b90">91]</ref>, used in recent works only in conjunction with adversarial training or Code is available at https://github.com/visinf/da-sac. <ref type="bibr" target="#b35">36</ref>  PyCDA <ref type="bibr" target="#b46">[47]</ref> LSE <ref type="bibr" target="#b64">[65]</ref> PIT <ref type="bibr" target="#b52">[53]</ref> FDA <ref type="bibr" target="#b79">[80]</ref> TIR <ref type="bibr" target="#b38">[39]</ref> LDR <ref type="bibr" target="#b76">[77]</ref> FADA <ref type="bibr" target="#b69">[70]</ref> CD-AM <ref type="bibr" target="#b77">[78]</ref> SA-I2I <ref type="bibr" target="#b54">[55]</ref> Ours network ensembles <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b69">70,</ref><ref type="bibr" target="#b79">80,</ref><ref type="bibr" target="#b86">87,</ref><ref type="bibr" target="#b85">86]</ref>. By contrast, we use self-training standalone. Compared to previous selftraining methods <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b64">65,</ref><ref type="bibr" target="#b90">91,</ref><ref type="bibr" target="#b91">92]</ref>, our approach also sidesteps the inconvenience of multiple training rounds, as they often require expert intervention between consecutive rounds. We train our model using co-evolving pseudo labels end-to-end without such need. Our method leverages the ubiquitous data augmentation techniques from fully supervised learning <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b84">85]</ref>: photometric jitter, flipping and multi-scale cropping. We enforce consistency of the semantic maps produced by the model across these image perturbations. The following assumption formalises the key premise:</p><p>Assumption 1. Let f : I → M represent a pixelwise mapping from images I to semantic output M. Denote ρ : I → I a photometric image transform and, similarly, τ : I → I a spatial similarity transformation, where , ∼ p(·) are control variables following some predefined density (e.g., p ≡ N (0, 1)). Then, for any image I ∈ I, f is invariant under ρ and equivariant under τ , i.e. f (ρ (I)) = f (I) and f (τ (I)) = τ (f (I)).</p><p>Next, we introduce a training framework using a momentum network -a slowly advancing copy of the original model.</p><p>The momentum network provides stable, yet recent targets for model updates, as opposed to the fixed supervision in model distillation <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b86">87,</ref><ref type="bibr" target="#b85">86]</ref>. We also re-visit the problem of long-tail recognition in the context of generating pseudo labels for self-supervision. In particular, we maintain an exponentially moving class prior used to discount the confidence thresholds for those classes with few samples and increase their relative contribution to the training loss. Our framework is simple to train, adds moderate computational overhead compared to a fully supervised setup, yet sets a new state of the art on established benchmarks (cf. <ref type="figure">Fig. 1</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Most of the work on scene adaptation for semantic segmentation has been influenced by a parallel stream of work on domain adaptation (DA) and semi-supervised learning for image classification <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b49">50]</ref>. The main idea behind these methods is to formulate an upper bound on the target risk using the so-called H∆H-divergence <ref type="bibr" target="#b2">[3]</ref>. In a nutshell, it defines the discrepancy between the marginals of the source and target data by means of a binary classifier. In the following, we briefly review implementation variants of this idea in the context of semantic segmentation. Learning domain-invariant representations.</p><p>Adversarial feature alignment follows the GAN framework <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b25">26]</ref> and minimises the gap between the source and target feature representations in terms of some distance (e.g., Wasserstein in <ref type="bibr" target="#b40">[41]</ref>). The discriminator can be employed at multiple scales <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b66">67,</ref><ref type="bibr" target="#b76">77]</ref> and use local spatial priors <ref type="bibr" target="#b82">[83]</ref>; it can be conditional <ref type="bibr" target="#b32">[33]</ref> and class-specific <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b51">52]</ref>, or align the features of 'hard' and 'easy' target samples <ref type="bibr" target="#b55">[56]</ref>. Often, self-supervised losses, such as entropy minimisation <ref type="bibr" target="#b68">[69]</ref>, or a 'conservative loss' <ref type="bibr" target="#b89">[90]</ref> assist in this alignment.</p><p>The alternative to adversarial feature alignment are more interpretable constraints, such as feature priors <ref type="bibr" target="#b50">[51]</ref>, bijective source-target association <ref type="bibr" target="#b36">[37]</ref> or aligning the domains directly in the image space with style transfer <ref type="bibr" target="#b88">[89]</ref> used either alone <ref type="bibr" target="#b73">[74]</ref> or, most commonly, jointly with adversarial feature alignment <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b77">78,</ref><ref type="bibr" target="#b78">79,</ref><ref type="bibr" target="#b81">82]</ref>. One issue with style translation is to ensure semantic consistency despite the changes in appearance. To address this, Hoffman et al. <ref type="bibr" target="#b31">[32]</ref> use semantic and cycle-consistency losses, while Yang et al. <ref type="bibr" target="#b76">[77]</ref> reconstruct the original image from its label-space representation.</p><p>These methods tend to be computationally costly and challenging to train, since they require concurrent training of one or more independent networks, e.g. discriminators or style transfer networks. Although Yang and Soatto <ref type="bibr" target="#b79">[80]</ref> obviate the need for style networks by incorporating the phase of a Fourier-transformed target image into a source sample, multiple networks have to be trained, each with its own predefined phase band.</p><p>Features PIT <ref type="bibr" target="#b52">[53]</ref> LDR <ref type="bibr" target="#b76">[77]</ref> SA-I2I <ref type="bibr" target="#b54">[55]</ref> IAST <ref type="bibr" target="#b53">[54]</ref> RPT <ref type="bibr" target="#b82">[83]</ref>   <ref type="table">Table 1</ref>. Relation to state of the art. Previous work reaches the state of the art in terms of IoU either with VGG-16 (SOTA-VGG) or ResNet-101 (SOTA-ResNet). Our framework uses neither adversarial training nor multiple training rounds (given in parentheses), yet outperforms the state of the art consistently in both cases.</p><p>Self-training on pseudo labels. As a more computationally lightweight approach, self-training seeks high-quality pseudo supervision coming in the form of class predictions with high confidence. Our work belongs to this category. Most of such previous methods pre-compute the labels 'offline', used subsequently to update the model, and repeat this process for several rounds <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b64">65,</ref><ref type="bibr" target="#b90">91,</ref><ref type="bibr" target="#b91">92]</ref>. More recent frameworks following this strategy have a composite nature: they rely on adversarial (pre-)training <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b85">86]</ref>, style translation <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b79">80]</ref> or both <ref type="bibr" target="#b53">[54,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b69">70,</ref><ref type="bibr" target="#b72">73]</ref>.</p><p>Training on co-evolving pseudo labels can be computationally unstable, hence requires additional regularisation. Chen et al. <ref type="bibr" target="#b12">[13]</ref> minimise the entropy with improved behaviour of the gradient near the saturation points. Using fixed representations, be it from a 'frozen' network <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b85">86]</ref>, a fixed set of global <ref type="bibr" target="#b52">[53]</ref> or self-generated local labels <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b67">68,</ref><ref type="bibr" target="#b80">81]</ref>, further improves training robustness.</p><p>Overconfident predictions <ref type="bibr" target="#b27">[28]</ref> have direct consequences for the quality of pseudo labels. Zou et al. <ref type="bibr" target="#b91">[92]</ref> attain some degree of confidence calibration via regularising the loss with prediction smoothing akin to temperature scaling <ref type="bibr" target="#b27">[28]</ref>. Averaging the predictions of two classifiers <ref type="bibr" target="#b86">[87]</ref>, or using Dropout-based sampling <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b87">88]</ref>, achieves the same goal.</p><p>Spatial priors. Different from DA for classification, the characteristic feature of adaptation methods for segmentation is the use of spatial priors. Local priors have been enforced patch-wise <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b67">68]</ref> and in the form of precomputed super-pixels <ref type="bibr" target="#b80">[81,</ref><ref type="bibr" target="#b82">83]</ref>. Although global spatial priors have also been used <ref type="bibr" target="#b90">[91]</ref>, their success hinges on the similarity of the semantic layout in the current benchmarks.</p><p>Relation to our approach. As shown in <ref type="table">Table 1</ref>, our work streamlines the training process. First, we do not use adversarial training, as feature invariance alone does not guarantee label invariance <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b83">84]</ref>. Second, we train our model with co-evolving pseudo labels in one round. Our framework bears resemblance to the noisy mean teacher <ref type="bibr" target="#b75">[76]</ref> and combines consistency regularisation <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b60">61,</ref><ref type="bibr" target="#b63">64,</ref><ref type="bibr" target="#b74">75]</ref> with self-ensembling <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b65">66]</ref>. Similar approaches have been explored in medical imaging <ref type="bibr" target="#b43">[44,</ref><ref type="bibr" target="#b57">58]</ref> and concurrent UDA work <ref type="bibr" target="#b70">[71]</ref>, albeit limited in the scope of admissible aug-  <ref type="figure">Figure 2</ref>. Overview. The segmentation network in our framework (a) maintains a slow copy of itself, the momentum network, which provides stable targets for self-supervision. In addition to encouraging semantic invariance w.r.t. the photometric noise, we facilitate consistent predictions across multiple scales and flips by first (b) feeding random multi-scale crops and flips to the momentum network and then (c) fusing the predictions by simple averaging to produce the pseudo-supervision targets.</p><p>mentations. We leverage photometric invariance, scale and flip equivariance <ref type="bibr" target="#b71">[72]</ref> to extract high-fidelity pseudo supervision instead of more computationally expensive sampling techniques <ref type="bibr" target="#b37">[38]</ref>. Contrary to <ref type="bibr" target="#b64">[65]</ref>, we find that scale alone is not predictive of the label quality, hence we average the predictions produced at multiple scales and flips. This parallels uncertainty estimation using test-time augmentation <ref type="bibr" target="#b0">[1]</ref>, but at training time <ref type="bibr" target="#b4">[5]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Self-Supervised Augmentation Consistency</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Framework overview</head><p>Shown in <ref type="figure">Fig. 2a</ref>, our framework comprises a segmentation network, which we intend to adapt to a target domain, and its slowly changing copy updated with a momentum, a momentum network. To perform self-supervised scene adaptation, we first supply a batch of random crops and horizontal flips from a sample image of the target domain to both networks. For each pixel we average the predictions (i.e. semantic masks) from the momentum network after the appropriate inverse spatial transformation. We then create a pseudo ground truth by selecting confident pixels from the averaged map using thresholds based on running statistics, which are capable of adapting to individual samples. Finally, the segmentation network uses stochastic gradient descent to update its parameters w.r.t. these pseudo labels.</p><p>Our approach closely resembles the mean teacher framework <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b65">66]</ref> and temporal ensembling <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b39">40]</ref>. However, as we will show empirically, the ensembling property itself plays only an auxiliary role. More importantly, akin to the critic network in reinforcement learning <ref type="bibr" target="#b47">[48]</ref> and the momentum encoder in unsupervised learning <ref type="bibr" target="#b29">[30]</ref>, our momentum network provides stable targets for self-supervised training of the segmentation network. This view allows us to focus on the target-generating process, detailed next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Batch construction</head><p>For each sampled target image, we generate N crops with random scales, flips and locations, but preserving the aspect ratio. We re-scale the crops as well as the original image to a fixed input resolution h×w and pass them as the in-put to the networks. <ref type="figure">Fig. 2b</ref> demonstrates this process. Following the noisy student model in image classification <ref type="bibr" target="#b75">[76]</ref>, the input to the segmentation network additionally undergoes a photometric augmentation: we add random colour jitter and smooth the images with a Gaussian filter at random. The momentum network, on the other hand, receives a 'clean' input, i.e. without such augmentations. This is to encourage model invariance to photometric perturbations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Self-supervision</head><p>Multi-scale fusion. We re-project the output masks from the momentum network back to the original image canvas of size h × w, as illustrated in <ref type="figure">Fig. 2c</ref>. For each pixel, the overlapping areas average their predictions. Note that some pixels may lie outside the crops, hence contain the result of a single forward pass with the original image. We keep these predictions intact. The merged maps are then used to extract the pseudo masks for self-supervision. A short long-tail interlude. Handling rare classes (i.e. classes with only a few training samples) is notoriously difficult in recognition <ref type="bibr" target="#b28">[29]</ref>. For semantic segmentation, we here distinguish between the classes with low image-level (e.g., "truck", "bus") and pixel-level (e.g., "traffic light", "pole") frequency. While generating self-supervision, we take special care of these cases and encourage (i) lower thresholds for selecting their pseudo labels, (ii) increased contributions to the gradient with a focal loss, and (iii) employ importance sampling. We describe these in detail next. Sample-based moving threshold. Most previous work with self-training employs multi-round training that requires interrupting the training process and re-generating the pseudo labels <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b64">65,</ref><ref type="bibr" target="#b90">91]</ref>. One of the reasons is the need to re-compute the thresholds for filtering the pseudo labels for supervision, which requires traversing the predictions for the complete target dataset with the model parameters fixed. In pursuit of our goal of enabling end-to-end training without expert intervention, we take a different approach and compute the thresholds on-the-go. As the main ingredient, we maintain an exponentially moving class prior. In detail, for each softmax prediction of the momentum network, we first compute a prior estimate of the probability that a pixel in sample n belongs to class c as</p><formula xml:id="formula_0">χ c,n = 1 hw i,j m c,n,i,j ,<label>(1)</label></formula><p>where m c,n,:,: is the mask prediction for class c (with resolution h × w). We keep an exponentially moving average after each training iteration t with a momentum γ χ ∈ [0, 1]:</p><formula xml:id="formula_1">χ t+1 c = γ χ χ t c + (1 − γ χ )χ c,n .<label>(2)</label></formula><p>Our sample-based moving threshold θ c,n takes lower values when the moving prior χ c ≈ 0 (i.e. for long-tail classes), but is bounded from above as χ c → 1. We define it as</p><formula xml:id="formula_2">θ c,n = ζ 1 − e −χc/β m * c,n ,<label>(3)</label></formula><p>where β and ζ are hyperparameters and m * c,n is the predicted peak confidence score for class c, i.e. For predominant classes (e.g., "road"), the exponential term has nearly no effect; the threshold is static w.r.t. the peak class confidence, i.e. θ c,n ≈ ζm * c,n . However, for long-tail classes such that χ c ≈ β, the threshold is lower than this upper bound, hence more pixels for these classes are selected for supervision. To obtain the pseudo labels, we apply the threshold θ c,n to the peak predictions of the merged output from the momentum network:</p><formula xml:id="formula_3">m * c,n = max i,j m c,n,i,j .<label>(4)</label></formula><formula xml:id="formula_4">m n,i,j = c * m c * ,n,i,j &gt; θ c,n ignore otherwise,<label>(5)</label></formula><p>where c * = arg max c m c,n,i,j is the dominant class for that pixel. Note that the pixels with confidence values lower than the threshold, as well as non-dominant predictions, will be ignored in the self-supervised loss.</p><p>Focal loss with confidence regularisation. Our loss function incorporates a focal multiplier <ref type="bibr" target="#b48">[49]</ref> to further increase the contribution of the long-tail classes in the gradient signal. Unlike previous work <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b64">65]</ref>, however, our moving class prior χ c regulates the focal term:</p><formula xml:id="formula_5">L t n (m, m | φ) = −m c * ,n (1 − χ c * ) λ log(m c * ,n ),<label>(6)</label></formula><p>wherem is the prediction of the segmentation network with parameters φ, the pseudo label c * derives fromm in Eq. (5) and λ is a hyperparameter of the focal term. Recall that low values of χ c signify a long-tail category, hence should have a higher weight. High values of λ (i.e. &gt; 1) increase the relative weighting on the long-tail classes, while setting λ = 0 disables the focal term. Note that we also regularise our loss with the confidence value of the momentum network, m c * ,n (Eq. 4). In case of an incorrect pseudo label, we expect this confidence to be low and to regularise the training owing to its calibration with the multi-scale fusion. We minimise the loss in Eq. <ref type="formula" target="#formula_5">(6)</ref>, applied for each pixel, w.r.t. φ.  <ref type="figure" target="#fig_2">Figure 3</ref>. Sample-based moving threshold. Our thresholding scheme has two hyperparameters, ζ and β. In this example, m * c,n = 1 and ζ = 0.75. Predominant classes (e.g., "road") have χc 0, hence their threshold approximates ζm * c,n . Long-tail classes (e.g., "traffic light") have χc ≈ 0 and their thresholds are further reduced with a steepness controlled by β (see Eq. 3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Training</head><p>Pre-training with source-only loss. Following <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b82">83]</ref>, we use Adaptive Batch Normalisation (ABN) <ref type="bibr" target="#b44">[45]</ref> to jumpstart our model on the segmentation task by minimising the cross-entropy loss on the source data only. In our experiments, we found it unnecessary to re-compute the mean and the standard deviation only at the end of the training. Instead, in pre-training we alternate batches of source and target images, but ignore the loss for the latter. For a target batch, this implies updating the running mean and the standard deviation in the Batch Normalisation (BN) <ref type="bibr" target="#b33">[34]</ref> layers and leaving the remaining model parameters untouched. Importance sampling. Our loss function in Eq. (6) accounts for long-tail classes with a high image frequency (e.g., "traffic light", "pole"), and may not be effective for the classes appearing in only few samples (e.g., "bus", "train"). To alleviate this imbalance, we use importance sampling <ref type="bibr" target="#b20">[21]</ref> and increase the sample frequency of these long-tail classes. We minimise the expected target loss by re-sampling the target images using the density p t :</p><formula xml:id="formula_6">min φ E n∼pt L t n (φ) .<label>(7)</label></formula><p>To obtain p t , we use our pre-trained segmentation network and pre-compute χ c,n , the class prior estimate, for each image n using Eq. (1). At training time, we (i) sample a semantic class c uniformly, and then (ii) obtain a target sample l with probabilityχ</p><formula xml:id="formula_7">c,l = χ c,l n χ c,n .<label>(8)</label></formula><p>This two-step sampling process ensures that all images have non-zero sample probability owing to the prevalent classes for whichχ c,l &gt; 0 for all l (e.g., "road" in urban scenes). Joint target-source training. We train the segmentation network with stochastic gradient descent using the crossentropy loss for the source and our focal loss for the target  In this image sample (a) and its crops, the segmentation network (b) tends to mistake the "motorcycle" for a "bicycle". The momentum network (c) improves on this prediction, but may still produce an inconsistent labelling. Averaging the predictions over multiple scales (d) corrects this inconsistency, allowing to produce high-precision pseudo labels (e) for self-supervision.</p><p>data sampled from p t , as defined by Eqs. <ref type="formula" target="#formula_5">(6)</ref> and <ref type="formula" target="#formula_6">(7)</ref>. <ref type="figure" target="#fig_5">Fig. 4</ref> illustrates the synthesis of pseudo labels. We periodically update the parameters ψ of the momentum network as</p><formula xml:id="formula_8">ψ t+1 = γ ψ ψ t + (1 − γ ψ )φ,<label>(9)</label></formula><p>where φ are the parameters of the segmentation network. γ ψ regulates the pace of the updates: low values result in faster, but unstable training, while high γ ψ leads to a premature and suboptimal convergence. We keep γ ψ moderate, but update the momentum network only every T iterations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>Datasets. In our experiments we use three datasets. The Cityscapes dataset <ref type="bibr" target="#b17">[18]</ref> contains 2048 × 1024 images from real-world traffic scenes, split into 2975 images for training and 500 for validation. The GTA5 dataset <ref type="bibr" target="#b58">[59]</ref> contains 24 966 synthetic scenes with resolution 1914 × 1052 and pixelwise annotation aided by the GTA5 game engine. We also use the SYNTHIA-RAND-CITYSCAPES subset of the SYNTHIA dataset <ref type="bibr" target="#b59">[60]</ref>, which contains 9400 synthetic images with resolution 1280 × 760 and a semantic annotation compatible with Cityscapes. Setup. We adopt the established evaluation protocol from previous work <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b66">67,</ref><ref type="bibr" target="#b68">69]</ref>. The synthetic traffic scenes from GTA5 <ref type="bibr" target="#b58">[59]</ref> and SYNTHIA <ref type="bibr" target="#b59">[60]</ref> serve as the source data, and the real images from the Cityscapes dataset as the target (obviously ignoring the available semantic labels). This results in two domain adaptation scenarios depending on the choice of the source data: GTA5 → Cityscapes and SYNTHIA → Cityscapes. As in previous work, at training time we only use the training split of the Cityscapes dataset and report the results on the validation split. We measure the segmentation accuracy with per-class Intersection-over-Union (IoU) and its average, the mean IoU (mIoU).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Implementation details</head><p>We implement our framework in PyTorch <ref type="bibr" target="#b56">[57]</ref>. We adopt DeepLabv2 <ref type="bibr" target="#b9">[10]</ref> as the segmentation architecture, and evaluate our method with two backbones, ResNet-101 [31] and VGG16 <ref type="bibr" target="#b62">[63]</ref>, following recent work <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b66">67,</ref><ref type="bibr" target="#b67">68,</ref><ref type="bibr" target="#b68">69,</ref><ref type="bibr" target="#b72">73]</ref>. Both backbones initialise from the models pre-trained on ImageNet <ref type="bibr" target="#b18">[19]</ref>. We first train the models with ABN <ref type="bibr" target="#b44">[45]</ref> (cf. Sec. 3.4), implemented via SyncBN <ref type="bibr" target="#b56">[57]</ref>, on multiscale crops resized to 640 × 640 and a batch size of 16. Next, training proceeds with the self-supervised target loss (cf. Sec. 3.3) and the BatchNorm layers <ref type="bibr" target="#b33">[34]</ref> frozen. The batch size of 16 comprises 8 source images and 8 target images at resolution 1024 × 512, which is a common practice <ref type="bibr" target="#b69">[70,</ref><ref type="bibr" target="#b79">80]</ref>. The target batch contains only two image samples along with 3 random crops each (i.e. N = 3 in Sec. 3.2), downscaled up to a factor of 0.5. As the photometric noise, we use colour jitter, random blur and greyscaling (see Appendix B for details). The optimisation uses SGD with a constant learning rate of 2.5 × 10 −4 , momentum 0.9 and weight decay of 5×10 −4 . We accumulate the gradient in alternating source-target forward passes to keep the memory footprint in check. Since the focal term in Eq. (6) reduces the target loss magnitude w.r.t. the source loss, we scale it up by a factor of 5 (2 for VGG-16). We train our VGGbased framework on two TITAN X GPUs (12GB), while the ResNet-based variant requires four. This is a substantially reduced requirement compared to recent work (e.g.,  FADA <ref type="bibr" target="#b69">[70]</ref> requires 4 Tesla P40 GPUs with 24GB memory). Note that the momentum network is always in evaluation mode, has gradient tracking disabled, hence adds only around 35% memory overhead. For the momentum network, we fix γ ψ = 0.99 and T = 100 in all our experiments. For the other hyperparameters, we use γ χ = 0.99, ζ = 0.75, β = 10 −3 and λ = 3. Appendix C.2 provides further detail on hyperparameter selection, as well as a sensitivity analysis of our framework w.r.t. ζ and β. The inference follows the usual procedure of a single forward pass through the segmentation network at the original image resolution without any post-processing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Comparison to state of the art</head><p>We compare our approach to the current state of the art on the two domain adaptation scenarios: GTA5 → Cityscapes in <ref type="table" target="#tab_3">Table 2</ref> and SYNTHIA → Cityscapes in <ref type="table" target="#tab_5">Table 3</ref>. For a fair comparison, all numbers originate from single-scale inference. In both cases, our approach, denoted as SAC ("Self-supervised Augmentation Consistency"), substantially outperforms our baseline (i.e. the source-only loss model with ABN, see Sec. 3.4), and, in fact, sets a new state of the art in terms of mIoU. Importantly, while the ranking of previous works depends on the backbone choice and the source data, we reach the top rank consistently in all settings.</p><p>GTA5 → Cityscapes ( <ref type="table" target="#tab_3">Table 2)</ref>. Our method achieves a clear improvement over the best published results <ref type="bibr" target="#b54">[55,</ref><ref type="bibr" target="#b82">83]</ref> of +3.4% and +1.2% using the VGG-16 and ResNet-101 backbones, respectively. Note that RPT <ref type="bibr" target="#b82">[83]</ref> and SA-I2I <ref type="bibr" target="#b54">[55]</ref> have a substantially higher model complexity. RPT <ref type="bibr" target="#b82">[83]</ref> uses PSPNet <ref type="bibr" target="#b84">[85]</ref>, which has a higher upper bound than DeepLabv2 in a fully supervised setup (e.g., +5.7% IoU on PASCAL VOC <ref type="bibr" target="#b84">[85]</ref>); it requires extracting superpixels and training an encoder-decoder LSTM, thus increasing the model capacity and the computational overhead. SA-I2I <ref type="bibr" target="#b54">[55]</ref> initialises from a stronger baseline, BDL <ref type="bibr" target="#b45">[46]</ref>, and relies on a style transfer network and adversarial training. While both RPT <ref type="bibr" target="#b82">[83]</ref> and SA-I2I <ref type="bibr" target="#b54">[55]</ref> require multiple rounds of training, 3 and 6 (from BDL <ref type="bibr" target="#b45">[46]</ref>), respectively, we train with the target loss in a single pass. Notably, compared to the previous best approach for VGG with a ResNet evaluation, SA-I2I <ref type="bibr" target="#b54">[55]</ref>, our improvement with ResNet-101 is substantial, +3.4%, and is comparable to the respective margin on VGG-16.</p><p>SYNTHIA → Cityscapes <ref type="table" target="#tab_5">(Table 3)</ref>. Here, the result is consistent with the previous scenario. Our approach attains state-of-the-art accuracy for both backbones, improving by 7.6% and 1.4% with VGG-16 and ResNet-101 backbones over the best results previously published <ref type="bibr" target="#b54">[55,</ref><ref type="bibr" target="#b82">83]</ref>. Again, our method with ResNet-101 outperforms the previous best method with full evaluation, PyCDA <ref type="bibr" target="#b46">[47]</ref>, by 5.9% IoU. ( † ) denotes the use of PSPNet <ref type="bibr" target="#b84">[85]</ref> instead of DeepLabv2 <ref type="bibr" target="#b9">[10]</ref>. mIoU 13 is the average IoU over 13 classes (i.e. excluding "wall", "fence" and "pole").  <ref type="table">Table 4</ref>. Ablation study. We use the GTA5 → Cityscapes setting with the VGG-based model to study the effect of the components of our framework by individually removing each. We report the mean IoU for the Cityscapes validation split.</p><p>Remarkably, in both settings our approach is more accurate or competitive with many recent works <ref type="bibr" target="#b64">[65,</ref><ref type="bibr" target="#b69">70,</ref><ref type="bibr" target="#b76">77]</ref> even when using a weaker backbone, i.e. VGG-16 instead of ResNet-101. This is significant, as these improvements are not due to increased training complexity or model capacity, in contrast to these previous works. Additional results, including the evaluation on Cityscapes test, are shown in Appendices C and D.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Ablation study</head><p>To understand what makes our framework effective, we conduct an ablation study using the GTA5 → Cityscapes setting with the VGG-16 backbone. We independently switch off each component and report the results in <ref type="table">Table 4</ref>. We find that two components, augmentation consistency and the momentum network, play a crucial role. Disabling the momentum network leads to a 6.4% IoU decrease, while abolishing augmentation consistency leads to a drop of 8.0% IoU. Recall that augmentation consistency comprises three augmentation techniques: photometric noise, multi-scale fusion and random flipping. We further assess their individual contributions. Training without the photometric jitter deteriorates the IoU more severely, by 3.9%, compared to disabling the multi-scale fusion (−2.6%) or flipping (−0.6%). We hypothesise that encouraging model robustness to photometric noise additionally alleviates the inductive bias inherited from the source domain to rely on strong appearance cues (e.g., colour and texture), which can be substantially different from the target domain.</p><p>Following the intuition that high-confidence predictions should be preferred <ref type="bibr" target="#b64">[65]</ref>, we study an alternative implementation of the multi-scale fusion. For overlapping pixels, instead of averaging the predictions, we pool the prediction with the minimum entropy. The accuracy drop by 1.9% is somewhat expected. Averaging predictions via data augmentation has previously been shown to produce wellcalibrated uncertainty estimates <ref type="bibr" target="#b0">[1]</ref>. This is important for our method, since it relies on the confidence values to select the predictions for use in self-supervision. Importance sampling contributes 1.5% IoU to the total accuracy. This is surprisingly significant despite that our estimates χ c,l are only approximate (cf. Sec. 3.4), but the overall benefit is in line with previous work <ref type="bibr" target="#b28">[29]</ref>. Recall from Eq. (3) that our confidence thresholds are computed per class to encourage lower values for long-tail classes. Disabling this scheme is equivalent to setting β → 0 in Eq. <ref type="formula" target="#formula_2">(3)</ref>, which reduces the mean IoU by 1.7%. This confirms our observation that the model tends to predict lower confidences for the classes occupying only few pixels. Similarly, the loss in Eq. (6) without the focal term (λ = 0) and confidence regularisation (m c * ,n = 1) are 2.4% and 1.6% IoU inferior. This is a surprisingly significant contribution at a negligible computational cost. <ref type="figure" target="#fig_6">Fig. 5</ref> presents a few qualitative examples, comparing our approach to the naive baseline (i.e. source-only loss with ABN). Particularly prominent are the refinements of the classes "road", "sidewalk" and "sky", but even small-scale elements improve substantially (e.g., "person", "fence" in the leftmost column). This is perhaps not surprising, owing to our multi-scale training and the thresholding technique, which initially ignores incorrectly predicted pixels in self-supervision (as they initially tend to have low confidence). Remarkably, the segment boundaries tend to align well with the object boundaries in the image, although our framework has no explicit encoding of spatial priors, which was previously deemed necessary <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b67">68,</ref><ref type="bibr" target="#b80">81,</ref><ref type="bibr" target="#b82">83]</ref>. We believe that enforcing semantic consistency with data augmentation makes our method less prone to the contextual bias <ref type="bibr" target="#b61">[62]</ref>, often blamed for coarse boundaries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Qualitative assessment</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>We presented a simple and accurate approach for domain adaptation of semantic segmentation. With ordinary augmentation techniques and momentum updates, we achieve state-of-the-art accuracy, yet make no sacrifice of the modest training or model complexity. No components of our framework are strictly specialised; they build on a relatively weak and broadly applicable assumption (cf. Sec. 1). Although this work focuses on semantic segmentation, we are keen to explore the potential of the proposed techniques for adaptation of other dense prediction tasks, such as optical flow, monocular depth, panoptic and instance segmentation, or even compositions of these multiple tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Self-supervised Augmentation Consistency</head><p>for Adapting Semantic Segmentation -Supplemental Material -Nikita Araslanov 1 Stefan Roth 1,2 1 Department of Computer Science, TU Darmstadt 2 hessian.AI</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Overview</head><p>In this appendix, we first provide further training and implementation details of our framework. We then take a closer look at the accuracy of long-tail classes, before and after adaptation. Next, we discuss our strategy for hyperparameter selection and perform a sensitivity analysis. We also evaluate our framework using another segmentation architecture, FCN8s <ref type="bibr" target="#b98">[98]</ref>. Finally, we discuss the limitations of the current evaluation protocol and propose a revision based on the best practices in the field at large.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Further Technical Details</head><p>Photometric noise. Recall that our framework uses random Gaussian smoothing, greyscaling and colour jittering to implement the photometric noise. We re-use the parameters for these operations from the MoCo-v2 framework <ref type="bibr" target="#b93">[93]</ref>. In detail, the kernel radius for the Gaussian blur is sampled uniformly from the range [0.1, 2.0]. Note that this does not correspond to the actual filter size. <ref type="bibr" target="#b0">1</ref> The colour jitter, applied with probability 0.5, implements a perturbation of the image brightness, contrast and saturation with a factor sampled uniformly from [0.6, 1.4], while the hue factor is sampled uniformly at random in the range of [0.9, 1.1]. We convert a target image to its greyscale version with probability 0.2. <ref type="figure">Fig. 6</ref> demonstrates an example implementation of this procedure in Python.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Constraint-free data augmentation.</head><p>Similarly to the multi-scale cropping of the target images, we scale the source images randomly with a factor sampled uniformly from [0.5, 1.0] prior to cropping. However, we do not enforce the semantic consistency for the source data, since the ground truth of the source images is available. For both the target and source images we also use random horizontal flipping. We additionally experimented with moderate rotation (both with and without semantic consistency), but did not observe a significant effect on the mean accuracy. <ref type="bibr" target="#b0">1</ref> The Pillow Library <ref type="bibr" target="#b94">[94]</ref> internally converts the radius r to the box length as L = √ 3 * r 2 + 1.</p><p>1 import random 2 import PIL 3 import torchvision . transforms as tf 4 import torchvision . transforms . functional as F Training schedule. Our framework typically needs 150 − 200K iterations in total (i.e. including the source-only pretraining) until convergence, as determined on a random subset of 500 images from the training set (see our discussion in Appendix D below). This varies slightly depending on the backbone and the source data used. This schedule translates to approximately 3 days of training with standard GPUs (e.g., Titan X Pascal with 12 GB memory) for both VGG-16 and ResNet-101 backbones. Recall that we used 4 GPUs for our ResNet version of the framework, hence its training time is comparable to the VGG variant, which uses only 2 GPUs. All our experiments use a constant learning rate for simplicity, but more advanced schedules, such as cyclical learning rates <ref type="bibr" target="#b34">[35]</ref>, the cosine schedule <ref type="bibr" target="#b93">[93,</ref><ref type="bibr" target="#b95">95]</ref> or ramp-ups <ref type="bibr" target="#b39">[40]</ref>, may further improve the accuracy of our framework.  <ref type="table">Table 5</ref>. Per-class IoU (%) on Cityscapes val using a VGG-16 backbone in the GTA5 → Cityscapes setting. We study three components in more detail: class-based thresholding (CBT), importance sampling (IS) and the focal loss (FL). The mIoU of the settings in the last four rows are reproduced from the main text. Here, we elaborate on the per-class accuracy in a broader context of the supplementary experiments in the first four rows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Additional Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.1. A closer look at long-tail adaptation</head><p>Recall that our framework features three components to attune the adaptation process to the long-tail classes: classbased thresholding (CBT), importance sampling (IS) and the focal loss (FL), which we summarily refer to as the longtail components in the following. Disabling the long-tail components individually is equivalent to setting β → 0 for CBT, using uniform sampling of the target images instead of IS or assigning λ to 0 for the FL. Here, we extend our ablation study of the GTA5 → Cityscapes setup with VGG-16 (cf. <ref type="table">Table 4</ref> from the main text) and experiment with different combinations of the long-tail components. <ref type="table">Table 5</ref> details the per-class accuracy of the possible compositions.</p><p>We observe that the ubiquitous classes -"road", "building", "vegetation", "sky", "person" and "car" -are hardly affected; it is primarily the long-tail categories that change in accuracy. Furthermore, our long-tail components are mutually complementary. The mean IoU improves when one of the components is active, from 44.5% to up to 46.8%. It is boosted further with two of the components enabled to 48.4%, and reaches its maximum for our model, 49.9%, when all three components are in place.</p><p>We further identify the following tentative patterns. FL tends to improve classes "wall", "fence" and "pole". CBT increases the accuracy of the "traffic light" category (which has high image frequency and occupies only a few pixels), but also rare classes, such as "rider", "bus" and "train" benefit from CBT, especially in conjunction with IS. IS also enhances the mask quality of the classes "bicycle" and "motorcycle". Nevertheless, we urge caution against interpreting the results for each class in isolation, despite such widespread practice in the literature. Today's semantic segmentation models do not possess the notion of an 'ambiguous' class prediction and each pixel receives a meaningful label. By the pigeon's hole principle, this implies that the changes in the IoU of one class have an immediate effect on the IoU of the other classes. Therefore, the benefits of individual framework components have to be understood in the context of their aggregated effect on multiple classes, e.g. using the mean IoU. For instance, consider the class "train" for which IS appears to also decrease the IoU: while CBT together with FL achieve 29.2% IoU, adding IS decreases the IoU to 17.3%. However, the IoU of other classes increases (e.g., "motorcycle", "bicycle"), as does the mean IoU. Furthermore, only few classes reach their maximum accuracy when we enable all three long-tail components. Yet, it is the setting with the best accuracy trade-off between the individual classes, i.e. with the highest mean IoU. Overall, the long-tail components improve our framework by 5.4% mean IoU combined, a substantial margin.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2. Hyperparameter search and sensitivity</head><p>To select ζ and β, we first experimented with a few reasonable choices (ζ ∈ (0.7, 0.8), β ∈ (0.0001, 0.01)) 2 using a more lightweight backbone (MobileNetV2 <ref type="bibr" target="#b97">[97]</ref>). To measure performance, we use the mean IoU on the validation set (500 images from Cityscapes train, as in the main text).</p><p>Here, we study our framework's sensitivity to the particular choice of ζ and β. To make the results comparable to our previous experiments, we use VGG-16 and report the mean IoU on Cityscapes val in <ref type="table">Table 7</ref>. We observe moderate deviation of the IoU w.r.t. ζ. A more tangible drop in accuracy with β = 0.01 is expected, as it leads to lowconfidence predictions, which are likely to be inaccurate, to be included into the pseudo label. We note that while a suboptimal choice of these hyperparameters leads to inferior results (with a standard deviation of ±1.4% mIoU), even the weakest model with ζ = 0.8 and β = 0.01 did not fail to considerably improve over the baseline (by 8.5% IoU, cf. <ref type="table" target="#tab_3">Table 2</ref> in the main text). <ref type="bibr" target="#b1">2</ref> While ζ may seem more interpretable (the maximum confidence threshold), a reasonable range for β can be derived from χc for the longtail classes, which is simply the fraction of pixels these classes tend to occupy in the image (see Eq. 3). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.3. VGG-16 with FCN8s</head><p>A number of previous works (e.g., <ref type="bibr" target="#b54">[55,</ref><ref type="bibr" target="#b76">77,</ref><ref type="bibr" target="#b79">80]</ref>) used the FCN8s <ref type="bibr" target="#b98">[98]</ref> architecture with VGG-16, as opposed to DeepLabv2 <ref type="bibr" target="#b9">[10]</ref>, adopted in other works (e.g., <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b69">70]</ref>) and ours. Such architecture exchange appears to have been dismissed in previous work as minor, which used only one of the architectures in the experiments. However, the segmentation architecture alone may contribute to the observed differences in accuracy of the methods and, more critically, to the improvements otherwise attributed to other aspects of the approach. To facilitate such transparency in our work, we replace DeepLabv2 with its FCN8s counterpart in our framework (with the VGG-16 backbone) and repeat the adaptation experiments from Sec. 4, i.e. using two source domains, GTA5 and SYNTHIA, and Cityscapes as the target domain. We keep the values of the hyperparameters the same, with an exception of the learning rate, which we increase by a factor of 2 to 5 × 10 4 . <ref type="table">Table 6</ref> reports the results of the adaptation, which clearly show that our framework generalises well to other segmentation architectures. Despite the FCN8s baseline model (source-only loss with ABN) achieving a slightly inferior accuracy compared to DeepLabv2 (e.g., 31.6% vs. 34.4% IoU for SYN-THIA → Cityscapes), our self-supervised training still attains a remarkably high accuracy, 46.8% IoU (vs. 49.1% with DeepLabv2). This is substantially higher than the previous best method using FCN8s with the VGG-16 backbone, SA-I2I <ref type="bibr" target="#b54">[55]</ref>: +3.4% on GTA5 → Cityscapes and +5.3% on SYNTHIA → Cityscapes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Towards Best-practice Evaluation</head><p>The current strategy to evaluate domain adaptation (DA) methods for semantic segmentation is to use the ground truth of 500 randomly selected images from the Cityscapes train split for model selection and to report the final model accuracy on the 500 Cityscapes val images <ref type="bibr" target="#b46">[47]</ref>. In this work, we adhered to this procedure to enable a fair comparison to previous work. However, this evaluation approach is evidently in discord with the established best practice in machine learning and with the benchmarking practice on Cityscapes <ref type="bibr" target="#b17">[18]</ref>, in particular.</p><p>The test set is holdout data to be used only for an unbiased performance assessment (e.g., segmentation accuracy) of the final model <ref type="bibr" target="#b96">[96]</ref>. While it is conceivable to consult the test set for verifying a number of model variants, such access cannot be unrestrained. This is infeasible to ensure when the test set annotation is public, as is the case with Cityscapes val, however. Benchmark websites traditionally enable a restricted access to the test annotation through impartial submission policies (e.g., limited number of submissions per time window and user), and Cityscapes officially provides one. <ref type="bibr" target="#b2">3</ref> We, therefore, suggest a simple revision of the evaluation protocol for evaluating future DA methods. As before, we use Cityscapes train as the training data for the target domain, naturally without the ground truth. For model selection, however, we use Cityscapes val images with the ground-truth labels. The holdout test set for reporting the final segmentation accuracy after adaptation becomes Cityscapes test, with the results obtained via submitting the predicted segmentation masks to the official Cityscapes benchmark server.</p><p>An additional advantage of this strategy is a clear interpretation of the final accuracy in the context of fully supervised methods that routinely use the same evaluation setup. Also note that Cityscapes val contains images from different cities than Cityscapes train (which are also different from Cityscapes test). Therefore, it is more suitable for detecting cases of model overfitting on particularities of the city, since the validation set was previously a subset of the <ref type="table">Table 8</ref>. Per-class IoU (%) on Cityscapes test. In the last column, the numbers in parentheses report the mean IoU on Cityscapes val from the previous evaluation scheme (cf. Tables 2 and 3 from the main text) for reference. SAC-FCN denotes our VGG-based model with FCN8s <ref type="bibr" target="#b98">[98]</ref> from Appendix C. <ref type="bibr">3.</ref> training images.</p><p>For future reference, we evaluate our framework (both the DeepLabv2 and FCN8s variants) in the proposed setup and report the results in <ref type="table">Table 8</ref>. To ease the comparison, we juxtapose our validation results reported in the main text (from <ref type="table">Table 6</ref> for FCN8s). <ref type="bibr" target="#b3">4</ref> As we did not finetune our method to Cityscapes val following the previous evaluation protocol, we expect the test accuracy on Cityscapes test to be on a par with our previously reported accuracy on Cityscapes val. The results in <ref type="table">Table 8</ref> clearly confirm this expectation: the segmentation accuracy on Cityscapes test is comparable to the accuracy on Cityscapes val (SYN-THIA → Cityscapes) or even tangibly higher (GTA5 → Cityscapes). We remark that the remaining accuracy gap to the fully supervised model is still considerable (70.4% vs. 55.7% IoU achieved by our best DeepLabv2 model and 65.3% vs. 51.0% IoU compared to our best FCN8s variant), which invites further effort from the research community.</p><p>We hope that future UDA methods for semantic segmentation will follow suit in reporting the results on Cityscapes</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Mean 2021 Figure 1 .</head><label>20211</label><figDesc>IoU on Cityscapes (val) after adaptation from GTA5 with VGG-16 2019 2020 Results preview. Unlike much recent work that combines multiple training paradigms, such as adversarial training and style transfer, our approach retains the modest single-round training complexity of self-training, yet improves the state of the art for adapting semantic segmentation by a significant margin.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>photometric noise</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 plots</head><label>3</label><figDesc>Eq. (3) as a function of the moving class prior χ c for a selection of β.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>(a) Input (b) Segmentation net output (c) Momentum net output (d) Fused prediction (e) Pseudo labels</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 .</head><label>4</label><figDesc>Self-supervision example.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 .</head><label>5</label><figDesc>Qualitative examples. Our approach rectifies an appreciable amount of erroneous predictions from the baseline.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>5 6 # 8 9 24 #Figure 6 .</head><label>68246</label><figDesc>Load the image 7 image = PIL . Image . open (...) # Gaussian blur 10 # with a randomly sampled radius 11 radius = random . uniform (.1 ,2.) 12 gaussian = PIL . ImageFilter . GaussianBlur ( radius ) 13 image = image . filter ( gaussian ) 14 15 # Colour jitter 16 # with probability .5 17 if .5 &gt; random . random () : 18 jitter = tf . ColorJitter ( brightness = .4 , Convert to greyscale 25 # with probability .2 26 if .2 &gt; random . random () : 27 image = F . to_grayscale ( image ) Python implementation of the photometric noise.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Method road sidew build wall fence pole light sign veg terr sky pers ride car truck bus train moto bicy mIoU Backbone: VGG-16 CyCADA [32] 85.2 37.2 76.5 21.8 15.0 23.8 22.9 21.5 80.5 31.3 60.7 50.5 9.0 76.9 17.1 28.2 4.5 9.8 0.0 35.4 ADVENT [69] 86.9 28.7 78.7 28.5 25.2 17.1 20.3 10.9 80.0 26.4 70.2 47.1 8.4 81.5 26.0 17.2 18.9 11.7 1.6 36.1 CBST [91] 90.4 50.8 72.0 18.3 9.5 27.2 8.6 14.1 82.4 25.1 70.8 42.6 14.5 76.9 5.9 12.5 1.2 14.0 28.6 36.1 PyCDA [47] 86.7 24.8 80.9 21.4 27.3 30.2 26.6 21.1 86.6 28.9 58.8 53.2 17.9 80.4 18.8 22.4 4.1 9.7 6.2 37.2 PIT [53] 86.2 35.0 82.1 31.1 22.1 23.2 29.4 28.5 79.3 31.8 81.9 52.1 23.2 80.4 29.5 26.9 30.7 20.5 1.2 41.8 FDA [80] 86.1 35.1 80.6 30.8 20.4 27.5 30.0 26.0 82.1 30.3 73.6 52.5 21.7 81.7 24.0 30.5 29.9 14.6 24.0 42.2 LDR [77] 90.1 41.2 82.2 30.3 21.3 18.3 33.5 23.0 84.1 37.5 81.4 54.2 24.3 83.0 27.6 32.0 8.1 29.7 26.9 43.6 FADA [70] 92.3 51.1 83.7 33.1 29.1 28.5 28.0 21.0 82.6 32.6 85.3 55.2 28.8 83.5 24.4 37.4 0.0 21.1 15.2 43.8 CD-AM [78] 90.1 46.7 82.7 34.2 25.3 21.3 33.0 22.0 84.4 41.4 78.9 55.5 25.8 83.1 24.9 31.4 20.6 25.2 27.8 44.9 SA-I2I [55] 91.1 46.4 82.9 33.2 27.9 20.6 29.0 28.2 84.5 40.9 82.3 52.4 24.4 81.2 21.8 44.8 31.5 26.5 33.7 53.1 86.2 33.8 32.7 38.2 46.0 40.3 84.2 26.4 88.4 65.8 28.0 85.6 40.6 52.9 17.3 13.7 23.8 49.9</figDesc><table><row><cell></cell><cell></cell><cell>46.5</cell></row><row><cell>Baseline (ours)</cell><cell>81.5 28.6 79.5 23.2 21.1 31.3 28.2 18.5 75.6 14.9 72.2 58.0 17.1 81.1 19.7 26.3 13.7 12.9 2.1</cell><cell>37.1</cell></row><row><cell cols="2">SAC (ours) 90.0 Backbone: ResNet-101</cell><cell></cell></row><row><cell>PyCDA  † [47]</cell><cell>90.5 36.3 84.4 32.4 28.7 34.6 36.4 31.5 86.8 37.9 78.5 62.3 21.5 85.6 27.9 34.8 18.0 22.9 49.3</cell><cell>47.4</cell></row><row><cell>CD-AM [78]</cell><cell>91.3 46.0 84.5 34.4 29.7 32.6 35.8 36.4 84.5 43.2 83.0 60.0 32.2 83.2 35.0 46.7 0.0 33.7 42.2</cell><cell>49.2</cell></row><row><cell>FADA [70]</cell><cell>92.5 47.5 85.1 37.6 32.8 33.4 33.8 18.4 85.3 37.7 83.5 63.2 39.7 87.5 32.9 47.8 1.6 34.9 39.5</cell><cell>49.2</cell></row><row><cell>LDR [77]</cell><cell>90.</cell><cell></cell></row></table><note>8 41.4 84.7 35.1 27.5 31.2 38.0 32.8 85.6 42.1 84.9 59.6 34.4 85.0 42.8 52.7 3.4 30.9 38.1 49.5 FDA [80] 92.5 53.3 82.4 26.5 27.6 36.4 40.6 38.9 82.3 39.8 78.0 62.6 34.4 84.9 34.1 53.1 16.9 27.7 46.4 50.5 SA-I2I [55] 91.2 43.3 85.2 38.6 25.9 34.7 41.3 41.0 85.5 46.0 86.5 61.7 33.8 85.5 34.4 48.7 0.0 36.1 37.8 50.4 PIT [53] 87.5 43.4 78.8 31.2 30.2 36.3 39.9 42.0 79.2 37.1 79.3 65.4 37.5 83.2 46.0 45.6 25.7 23.5 49.9 50.6 IAST [54] 93.8 57.8 85.1 39.5 26.7 26.2 43.1 34.7 84.9 32.9 88.0 62.6 29.0 87.3 39.2 49.6 23.2 34.7 39.6 51.5 RPT† [83] 89.2 43.3 86.1 39.5 29.9 40.2 49.6 33.1 87.4 38.5 86.0 64.4 25.1 88.5 36.6 45.8 23.9 36.5 56.8 52.6 Baseline (ours) 80.2 29.3 76.8 23.8 21.9 37.7 35.4 21.1 79.8 21.3 75.0 59.5 17.5 83.5 22.4 33.4 13.0 30.7 12.3 40.8 SAC (ours) 90.4 53.9 86.6 42.4 27.3 45.1 48.5 42.7 87.4 40.1 86.1 67.5 29.7 88.5 49.1 54.6 9.8 26.6 45.3 53.8( † ) denotes the use of PSPNet [85] instead of DeepLabv2 [10].</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 .</head><label>2</label><figDesc></figDesc><table /><note>Per-class IoU (%) comparison on GTA5 → Cityscapes adaptation, evaluated on the Cityscapes validation set.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>6</head><label></label><figDesc>Method road sidew build wall fence pole light sign veg sky pers ride car bus moto bicy mIoU 13 mIoU 18.1 13.7 14.2 80.8 71.0 48.0 19.0 72.3 22.5 12.1 18.1 -35.9 PIT [53] 81.7 26.9 78.4 6.3 0.2 19.8 13.4 17.4 76.7 74.1 47.5 22.4 76.0 21.7 19.6 27.7 -38.1 FADA [70] 80.4 35.9 80.9 2.5 0.3 30.4 7.9 22.3 81.8 83.6 48.9 16.8 77.7 31.1 13.5 17.9</figDesc><table><row><cell>Backbone: VGG-16</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>PyCDA [47]</cell><cell>80.6 26.6 74.5 2.0</cell><cell cols="3">0.1 -</cell><cell>39.5</cell></row><row><cell>FDA [80]</cell><cell>84.2 35.1 78.0 6.1</cell><cell cols="2">0.4 27.0 8.5 22.1 77.2 79.6 55.5 19.9 74.8 24.9 14.3 40.7</cell><cell>-</cell><cell>40.5</cell></row><row><cell>CD-AM [78]</cell><cell>73.0 31.1 77.1 0.2</cell><cell cols="2">0.5 27.0 11.3 27.4 81.2 81.0 59.0 25.6 75.0 26.3 10.1 47.4</cell><cell>-</cell><cell>40.8</cell></row><row><cell>LDR [77]</cell><cell>73.7 29.6 77.6 1.0</cell><cell cols="2">0.4 26.0 14.7 26.6 80.6 81.8 57.2 24.5 76.1 27.6 13.6 46.6</cell><cell>-</cell><cell>41.1</cell></row><row><cell>SA-I2I [55]</cell><cell>79.1 34.0 78.3 0.3</cell><cell cols="2">0.6 26.7 15.9 29.5 81.0 81.1 55.5 21.9 77.2 23.5 11.8 47.5</cell><cell>-</cell><cell>41.5</cell></row><row><cell>Baseline (ours)</cell><cell>60.7 26.9 67.1 8.3</cell><cell cols="2">0.0 33.5 11.9 18.3 66.4 70.4 52.1 16.1 64.6 15.5 11.5 26.4</cell><cell>39.1</cell><cell>34.4</cell></row><row><cell>SAC (ours)</cell><cell>77.9 38.6 83.5 15.8</cell><cell cols="2">1.5 38.2 41.3 27.9 80.8 83.0 64.3 21.2 78.3 38.5 32.6 62.1</cell><cell>56.2</cell><cell>49.1</cell></row><row><cell>Backbone: ResNet-101</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>ADVENT [69]</cell><cell>85.6 42.2 79.7 8.7</cell><cell cols="2">0.4 25.9 5.4 8.1 80.4 84.1 57.9 23.8 73.3 36.4 14.2 33.0</cell><cell>-</cell><cell>41.2</cell></row><row><cell>PIT [53]</cell><cell>83.1 27.6 81.5 8.9</cell><cell cols="2">0.3 21.8 26.4 33.8 76.4 78.8 64.2 27.6 79.6 31.2 31.0 31.3</cell><cell>-</cell><cell>44.0</cell></row><row><cell>PyCDA  † [47]</cell><cell>75.5 30.9 83.3 20.8</cell><cell cols="2">0.7 32.7 27.3 33.5 84.7 85.0 64.1 25.4 85.0 45.2 21.2 32.0</cell><cell>-</cell><cell>46.7</cell></row><row><cell>CD-AM [78]</cell><cell>82.5 42.2 81.3 -</cell><cell>-</cell><cell>-18.3 15.9 80.6 83.5 61.4 33.2 72.9 39.3 26.6 43.9</cell><cell>52.4</cell><cell>-</cell></row><row><cell>FDA [80]</cell><cell>79.3 35.0 73.2 -</cell><cell>-</cell><cell>-19.9 24.0 61.7 82.6 61.4 31.1 83.9 40.8 38.4 51.1</cell><cell>52.5</cell><cell>-</cell></row><row><cell>LDR [77]</cell><cell>85.1 44.5 81.0 -</cell><cell>-</cell><cell>-16.4 15.2 80.1 84.8 59.4 31.9 73.2 41.0 32.6 44.7</cell><cell>53.1</cell><cell>-</cell></row><row><cell>SA-I2I [55]</cell><cell>87.7 49.7 81.6 -</cell><cell>-</cell><cell>-19.3 18.5 81.1 83.7 58.7 31.8 73.3 47.9 37.1 45.7</cell><cell>55.1</cell><cell>-</cell></row><row><cell>FADA [70]</cell><cell>84.5 40.1 83.1 4.8</cell><cell cols="2">0.0 34.3 20.1 27.2 84.8 84.0 53.5 22.6 85.4 43.7 26.8 27.8</cell><cell>-</cell><cell>45.2</cell></row><row><cell>IAST [54]</cell><cell>81.9 41.5 83.3 17.7</cell><cell cols="2">4.6 32.3 30.9 28.8 83.4 85.0 65.5 30.8 86.5 38.2 33.1 52.7</cell><cell>-</cell><cell>49.8</cell></row><row><cell>RPT  † [83]</cell><cell>88.9 46.5 84.5 15.1</cell><cell cols="2">0.5 38.5 39.5 30.1 85.9 85.8 59.8 26.1 88.1 46.8 27.7 56.1</cell><cell>-</cell><cell>51.2</cell></row><row><cell>Baseline (ours)</cell><cell>63.9 25.9 71.0 11.0</cell><cell cols="2">0.2 36.9 7.6 20.0 72.9 75.5 46.7 16.7 74.5 15.8 20.8 21.7</cell><cell>41.0</cell><cell>36.3</cell></row><row><cell>SAC (ours)</cell><cell>89.3 47.2 85.5 26.5</cell><cell cols="2">1.3 43.0 45.5 32.0 87.1 89.3 63.6 25.4 86.9 35.6 30.4 53.0</cell><cell>59.3</cell><cell>52.6</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 .</head><label>3</label><figDesc>Per-class IoU (%) comparison on SYNTHIA → Cityscapes adaptation, evaluated on the Cityscapes validation set.</figDesc><table><row><cell>∆</cell><cell>mIoU</cell><cell>Configuration</cell></row><row><cell>-8.0</cell><cell>41.9</cell><cell>No augmentation consistency</cell></row><row><cell>-6.4</cell><cell>43.5</cell><cell>No momentum net (γ ψ = 0, T = 1)</cell></row><row><cell>-3.9</cell><cell>46.0</cell><cell>No photometric noise</cell></row><row><cell>-2.6</cell><cell>47.3</cell><cell>No multi-scale fusion</cell></row><row><cell>-2.4</cell><cell>47.5</cell><cell>No focal loss (λ = 0)</cell></row><row><cell>-1.9</cell><cell>48.0</cell><cell>Min. entropy fusion (vs. averaging)</cell></row><row><cell>-1.7</cell><cell>48.2</cell><cell>No class-based thresholding (β → 0)</cell></row><row><cell>-1.6</cell><cell>48.3</cell><cell>No confidence regularisation</cell></row><row><cell>-1.5</cell><cell>48.4</cell><cell>No importance sampling</cell></row><row><cell>-0.6</cell><cell>49.3</cell><cell>No horizontal flipping</cell></row><row><cell>0.0</cell><cell>49.9</cell><cell>Full framework (VGG-16)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>i CBT IS FL road sidew build wall fence pole light sign veg terr sky pers ride car truck bus train moto bicy mIoU 88.1 41.0 85.7 30.8 30.6 33.1 37.0 22.9 86.6 36.8 90.7 67.1 27.1 86.8 34.4 30.4 8.5 7.5 0.0 44.5 89.4 52.3 86.0 34.0 32.6 38.5 43.3 30.6 85.2 30.9 88.5 66.7 28.0 85.7 35.6 39.6 0.0 6.6 0.0 46.0 90.0 47.1 85.6 31.3 24.9 32.3 38.9 28.2 87.3 39.8 89.4 67.7 28.6 88.1 40.1 50.0 7.3 9.9 2.2 46.8 89.3 39.0 85.1 33.2 26.1 32.4 41.8 25.2 86.3 27.4 90.4 66.4 28.2 87.5 32.9 45.4 11.0 7.6 0.0 45.0 89.3 52.6 86.0 33.4 30.0 38.0 44.9 34.3 86.9 35.3 88.0 65.4 27.3 86.2 37.6 44.0 20.9 9.6 6.5 48.2 89.3 52.2 86.1 34.2 31.5 37.0 43.4 36.3 85.2 30.7 86.6 66.2 30.3 85.3 36.2 43.9 29.2 6.8 8.6 48.4 89.7 45.1 85.6 29.6 28.3 31.7 41.9 27.5 87.2 37.4 89.8 66.9 29.2 87.5 37.3 31.6 24.7 11.9 20.2 47.5 90.0 53.1 86.2 33.8 32.7 38.2 46.0 40.3 84.2 26.4 88.4 65.8 28.0 85.6 40.6 52.9 17.3 13.7 23.8 49.9</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 6 .Table 7 .</head><label>67</label><figDesc>ii Method road sidew build wall fence pole light sign veg terr sky pers ride car truck bus train moto bicy mIoU GTA5 → Cityscapes Baseline (ours) 76.7 28.2 74.4 12.7 19.0 27.2 28.7 12.2 77.0 18.0 70.6 54.8 20.6 79.6 19.0 19.2 20.6 27.9 11.2 36.7 (37.1) SAC-FCN (ours) 86.3 45.6 84.4 30.3 27.1 24.8 42.8 35.2 86.9 39.7 88.0 62.3 32.1 84.1 28.4 43.7 31.9 29.4 45.8 49.9(49.9)    Per-class IoU (%) on Cityscapes val using VGG-16 with FCN8s. For reference, the numbers in parentheses in the last column report the mean IoU of the DeepLabv2 architecture (cf. Tables 2 and 3 from the main text). Mean IoU (%) on GTA5 → Cityscapes (val) with varying ζ and β. Our framework maintains strong accuracy under different settings of ζ and β. Even with a poor choice (e.g., ζ = 0.8, β = 0.01), it fares well w.r.t. the state of the art and outperforms many previous works (cf.Table 2from the main text).</figDesc><table><row><cell cols="2">SYNTHIA → Cityscapes</cell><cell></cell><cell></cell></row><row><cell>Baseline (ours)</cell><cell cols="3">50.7 23.8 60.9 1.8 0.1 27.7 10.5 15.7 60.1 -72.4 50.1 16.0 66.5 -13.7 -</cell><cell>8.5 26.8</cell><cell>31.6 (34.4)</cell></row><row><cell>SAC-FCN (ours)</cell><cell cols="4">74.7 34.2 81.4 19.8 1.9 27.2 34.8 27.2 80.0 -86.3 61.5 20.8 82.5 -31.2 -32.0 53.9</cell><cell>46.8 (49.1)</cell></row><row><cell cols="2">↓ ζ / β → 0.0001</cell><cell>0.001</cell><cell>0.01</cell></row><row><cell>0.7</cell><cell>47.9</cell><cell>48.8</cell><cell>46.7</cell></row><row><cell>0.75</cell><cell>48.6</cell><cell>49.9</cell><cell>46.3</cell></row><row><cell>0.8</cell><cell>48.2</cell><cell>49.8</cell><cell>45.6</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">https://www.cityscapes-dataset.com iii Method road sidew build wall fence pole light sign veg terr sky pers ride car truck bus train moto bicy mIoU</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">To our best knowledge, no previous work published their results in this evaluation setting before.test. Owing to the regulated access to the test set, we believe this setting to offer more transparency and fairness to the benchmarking process, and will successfully drive the progress of UDA for semantic segmentation, as it has done in the past for the fully supervised methods.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements.</head><p>This work has been co-funded by the LOEWE initiative (Hesse, Germany) within the emergenCITY center. Calculations for this research were partly conducted on the Lichtenberg high performance computer of TU Darmstadt.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Test-time data augmentation for estimation of heteroscedastic aleatoric uncertainty in deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Murat Seckin Ayhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Berens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In MIDL</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Learning with pseudo-ensembles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ouais</forename><surname>Alsharif</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Doina</forename><surname>Precup</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3365" to="3373" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A theory of learning from different domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shai</forename><surname>Ben-David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koby</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Kulesza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><forename type="middle">Wortman</forename><surname>Vaughan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="151" to="175" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Analysis of representations for domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shai</forename><surname>Ben-David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koby</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="137" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">MixMatch: A holistic approach to semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avital</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5050" to="5060" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Combining labeled and unlabeled data with co-training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avrim</forename><surname>Blum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLT</title>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="92" to="100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Generalizing hand segmentation in egocentric videos with uncertainty-guided model adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minjie</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoichi</forename><surname>Sato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="14380" to="14389" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">All about structure: Adapting structural information across domains for boosting semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Lun</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui-Po</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Hsiao</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Chen</forename><surname>Chiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="1900" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Naive-student: Leveraging semi-supervised learning in video sequences for urban scene segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raphael</forename><forename type="middle">Gontijo</forename><surname>Lopes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxwell</forename><forename type="middle">D</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ekin</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">IX</biblScope>
			<biblScope unit="page" from="695" to="714" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">DeepLab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected CRFs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iasonas</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Encoder-decoder with atrous separable convolution for semantic image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Liang-Chieh Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">VII</biblScope>
			<biblScope unit="page" from="833" to="851" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Cotraining for domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minmin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Kilian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Blitzer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="2456" to="2464" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Domain adaptation for semantic segmentation with maximum squares loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minghao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyang</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deng</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2090" to="2099" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">No more discrimination: Cross city adaptation of road scene segmenters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Hsin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Yu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo-Cheng</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Chiang Frank</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">ROAD: Reality oriented adaptation for semantic segmentation of urban scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhua</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="7892" to="7901" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">CrDoCo: Pixel-level domain transfer with crossdomain consistency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun-Chun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yen-Yu</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia-Bin</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1791" to="1800" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Selfensembling with GAN-based data augmentation for domain adaptation in semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaehoon</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taekyung</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changick</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="6829" to="6839" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The Cityscapes dataset for semantic urban scene understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>Cordts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Omran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Ramos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Rehfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Enzweiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>Benenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uwe</forename><surname>Franke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3213" to="3223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">ImageNet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei-Fei</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">CSCL: Critical semantic-consistent learning for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiahua</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Cong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gan</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuyang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaowei</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">VIII</biblScope>
			<biblScope unit="page" from="745" to="762" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">An introduction to sequential Monte Carlo methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arnaud</forename><surname>Doucet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><forename type="middle">J</forename><surname>Nando De Freitas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gordon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Sequential Monte Carlo Methods in Practice</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="3" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">SSF-DAN: Separated semantic feature based domain adaptation network for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingang</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongye</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyang</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qibao</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoqing</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolin</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="982" to="991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Self-ensembling for visual domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>French</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Mackiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><forename type="middle">H</forename><surname>Fisher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Domain-adversarial training of neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaroslav</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniya</forename><surname>Ustinova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hana</forename><surname>Ajakan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Germain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">François</forename><surname>Laviolette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Marchand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2096" to="2030" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">DLOW: Domain flow for adaptation and generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhua</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2477" to="2486" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Semi-supervised learning by entropy minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yves</forename><surname>Grandvalet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="529" to="536" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">On calibration of modern neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoff</forename><surname>Pleiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICML</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1321" to="1330" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">LVIS: A dataset for large vocabulary instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agrim</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="5356" to="5364" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Momentum contrast for unsupervised visual representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="9726" to="9735" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">CyCADA: Cycle-consistent adversarial domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judy</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taesung</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Yan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Conditional generative adversarial network for structured domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weixiang</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenzhen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junsong</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1335" to="1344" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Batch Normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Averaging weights leads to wider optima and better generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Izmailov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitrii</forename><surname>Podoprikhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timur</forename><surname>Garipov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dmitry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Gordon</forename><surname>Vetrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wilson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">UAI</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="876" to="885" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Sontag, and Rajesh Ranganath. Support and invertibility in domain-invariant representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fredrik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Johansson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>David</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AISTATS</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="page" from="527" to="536" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Pixel-level cycle association: A new perspective for domain adaptive semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoliang</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunchao</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yueting</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">G</forename><surname>Hauptmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="3569" to="3580" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">What uncertainties do we need in Bayesian deep learning for computer vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Kendall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yarin</forename><surname>Gal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5574" to="5584" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Learning texture invariant representation for domain adaptation of semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myeongjin</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyeran</forename><surname>Byun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="12972" to="12981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Temporal ensembling for semisupervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuli</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Aila</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Sliced Wasserstein discrepancy for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen-Yu</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tanmay</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><forename type="middle">Haris</forename><surname>Baig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Ulbricht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="10285" to="10295" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong-Hyun</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICML Workshops</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Content-consistent matching for domain adaptive semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangrui</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoliang</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunchao</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">XIV</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Semi-supervised skin lesion segmentation via transformation consistent self-ensembling model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaomeng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lequan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi-Wing</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pheng-Ann</forename><surname>Heng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In BMVC</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Adaptive batch normalization for practical domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanghao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naiyan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodi</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaying</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Bidirectional learning for domain adaptation of semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunsheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nuno</forename><surname>Vasconcelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="6936" to="6945" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Constructing self-motivated pyramid curriculums for crossdomain semantic segmentation: A non-adversarial approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qing</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lixin</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fengmao</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boqing</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Continuous control with deep reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">P</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><forename type="middle">J</forename><surname>Hunt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Pritzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Heess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Erez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuval</forename><surname>Tassa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Kaiming He, and Piotr Dollár. Focal loss for dense object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="318" to="327" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Conditional adversarial domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingsheng</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhangjie</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1647" to="1657" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Significance-aware information bottleneck for domain adaptive semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yawei</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junqing</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6778" to="6787" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Taking a closer look at domain shift: Category-level adversaries for semantics consistent domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yawei</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junqing</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2507" to="2516" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Cross-domain semantic segmentation via domain-invariant interactive relation transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fengmao</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guosheng</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="4333" to="4342" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Instance adaptive self-training for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuang</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaqi</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shanghang</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">XXVI</biblScope>
			<biblScope unit="page" from="415" to="430" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Semantically adaptive image-to-image translation for domain adaptation of semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luigi</forename><surname>Musto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Zinelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Seokju Lee, and In So Kweon. Unsupervised intra-domain adaptation for semantic segmentation through self-supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Inkyu</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">François</forename><surname>Rameau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="3763" to="3772" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Py-Torch: An imperative style, high-performance deep learning library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8024" to="8035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation for medical imaging segmentation with self-ensembling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><forename type="middle">S</forename><surname>Perone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pedro</forename><forename type="middle">L</forename><surname>Ballester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><forename type="middle">C</forename><surname>Barros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Cohen-Adad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">194</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Playing for data: Ground truth from computer games</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><forename type="middle">R</forename><surname>Richter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vibhav</forename><surname>Vineet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">II</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">The SYNTHIA dataset: A large collection of synthetic images for semantic segmentation of urban scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Germán</forename><surname>Ros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Sellart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joanna</forename><surname>Materzynska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Vázquez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><forename type="middle">M</forename><surname>López</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Regularization with stochastic transformations and perturbations for deep semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Sajjadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehran</forename><surname>Javanmardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tolga</forename><surname>Tasdizen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1163" to="1171" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Not using the car to see the sidewalk -quantifying and controlling the effects of context in classification and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rakshith</forename><surname>Shetty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Fritz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8218" to="8226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">FixMatch: Simplifying semisupervised learning with consistency and confidence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zizhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Ekin Dogus Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun-Liang</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="596" to="608" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Learning from scaleinvariant examples for domain adaptation in semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammad</forename><surname>Subhani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohsen</forename><surname>Ali</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">XXII</biblScope>
			<biblScope unit="page" from="290" to="306" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antti</forename><surname>Tarvainen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harri</forename><surname>Valpola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Learning to adapt structured output space for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Hsuan</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Chih</forename><surname>Hung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Schulter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manmohan</forename><surname>Chandraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="7472" to="7481" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Domain adaptation for structured output via discriminative patch representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Hsuan</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Schulter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manmohan</forename><surname>Chandraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1456" to="1465" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">ADVENT: Adversarial entropy minimization for domain adaptation in semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tuan-Hung</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Himalaya</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxime</forename><surname>Bucher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Cord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Pérez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Classes matter: A fine-grained adversarial approach to cross-domain semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoran</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingyu</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">XIV</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Consistency regularization with high-dimensional nonadversarial source-guided perturbation for unsupervised domain adaptation in segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaihong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenhongyi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margrit</forename><surname>Betke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AAAI</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Self-supervised equivariant attention mechanism for weakly supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yude</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meina</forename><surname>Kan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiguang</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xilin</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="12272" to="12281" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Differential treatment for stuff and things: A simple unsupervised domain adaptation method for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhonghao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunchao</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rogério</forename><surname>Feris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinjun</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Mei</forename><surname>Hwu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honghui</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">DCAN: Dual channel-wise alignment networks for unsupervised scene adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zuxuan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xintong</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yen-Liang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mustafa</forename><forename type="middle">Gökhan</forename><surname>Uzunbas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Goldstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ser-Nam</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry</forename><forename type="middle">S</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">V</biblScope>
			<biblScope unit="page" from="535" to="552" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Unsupervised data augmentation for consistency training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qizhe</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zihang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><forename type="middle">H</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="6256" to="6268" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Self-training with noisy student improves imagenet classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qizhe</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><forename type="middle">H</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Label-driven reconstruction for domain adaptation in semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinyu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weizhi</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinliang</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaochao</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junzhou</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">XXVII</biblScope>
			<biblScope unit="page" from="480" to="498" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Context-aware domain adaptation in semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinyu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weizhi</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaochao</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peilin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junzhou</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WACV</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="514" to="524" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Phase consistent ecological domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanchao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Lao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ganesh</forename><surname>Sundaramoorthi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Soatto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="9008" to="9017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">FDA: Fourier domain adaptation for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanchao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Soatto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Curriculum domain adaptation for semantic segmentation of urban scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boqing</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="2039" to="2049" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Fully convolutional adaptation networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaofan</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="6810" to="6818" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Transferring and regularizing prediction for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaofan</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chong-Wah</forename><surname>Ngo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="9618" to="9627" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">On learning invariant representations for domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Remi</forename><surname>Tachet Des Combes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">J</forename><surname>Gordon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="7523" to="7532" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Pyramid scene parsing network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojuan</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="6230" to="6239" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Unsupervised scene adaptation with memory regularization in vivo</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhedong</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1076" to="1082" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Rectifying pseudo label learning via uncertainty estimation for domain adaptive semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhedong</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1106" to="1120" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<monogr>
		<title level="m" type="main">Uncertainty-aware consistency regularization for cross-domain semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qianyu</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengyang</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangliang</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lizhuang</forename><surname>Ma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.08878[cs.CV],2020.2</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Unpaired image-to-image translation using cycleconsistent adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Yan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taesung</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2242" to="2251" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Penalizing top performers: Conservative loss for semantic segmentation adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinge</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ceyuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dahua</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">VII</biblScope>
			<biblScope unit="page" from="568" to="583" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation for semantic segmentation via class-balanced self-training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiding</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">V K</forename><surname>Vijaya Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinsong</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">III</biblScope>
			<biblScope unit="page" from="297" to="313" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Confidence regularized self-training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiding</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaofeng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">V K</forename><surname>Vijaya Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinsong</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="5981" to="5990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Synthia → Cityscapes</surname></persName>
		</author>
		<idno>SAC-FCN (ours) 66.9 25.9 80.8 12.1 2.0 24.4 37.1 27.5 78.8 -88.9 63.9 25.0 84.7 -27.4 -36.9 50.2 45.8 (46.8) SAC-VGG (ours) 70.4 29.7 83.6 11.6 1.8 34.2 41.2 29.2 81.0 -87.1 67.9</idno>
		<imprint/>
	</monogr>
	<note>4 75.9 -34.3 -42.5 57.5 48.3 (49.1) SAC-ResNet (ours) 87.4 41.0 85.5 17.5 2.6 40.5 44.7 34.4 87.9 -91.2 68.0 31.0 89.3 -33.2 -38.6 49.9 52.7 (52.6</note>
</biblStruct>

<biblStruct xml:id="b93">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinlei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.04297</idno>
		<title level="m">Improved baselines with momentum contrastive learning</title>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
	<note>cs.CV</note>
</biblStruct>

<biblStruct xml:id="b94">
	<monogr>
		<title level="m" type="main">Pillow (PIL fork) documentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Clark</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">SGDR: Stochastic gradient descent with warm restarts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><forename type="middle">D</forename><surname>Ripley</surname></persName>
		</author>
		<title level="m">Pattern Recognition and Neural Networks</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">G</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menglong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrey</forename><surname>Zhmoginov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<title level="m">MobileNetV2: Inverted residuals and linear bottlenecks</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4510" to="4520" />
		</imprint>
	</monogr>
	<note>CVPR</note>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">Fully convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="640" to="651" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
