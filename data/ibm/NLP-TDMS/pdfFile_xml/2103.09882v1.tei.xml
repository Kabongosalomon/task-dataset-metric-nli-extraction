<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Hierarchical Attention-based Age Estimation and Bias Estimation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shakediel</forename><surname>Hiba</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Ilan University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yosi</forename><surname>Keller</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Ilan University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Hierarchical Attention-based Age Estimation and Bias Estimation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T22:19+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Age estimation based on facial images is a common task conducted by human observers on a daily basis. It has been long researched in the computer vision and bio-metrics comminutes, as accurate age estimation relates to a broad span of applications, such as e-commerce <ref type="bibr" target="#b20">[21]</ref>, age-based face recognition and retrieval <ref type="bibr" target="#b24">[25]</ref>, to name a few. Accurate age estimation entails multiple computational challenges, uncommon to face detection or recognition. First, the face appearance variations due to aging are unknown, complex and may be affected by multiple intrinsic and extrinsic factors, such as ethnicity, gender, and lifestyle. Second, the appearance aging process changes gradually making the appearance of nearby ages similar, but notable age differences result in significant appearance changes. Lastly, available datasets are mostly small, and highly imbalanced with respect to age and gender. Facebased age estimation is commonly formulated as either a classification problem, where an age a corresponding to the face x is classified as either one of {a i } c 1 , a i ∈ Z + discrete values <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b17">18]</ref>, or as a scalar regression of a ∈ R + , given a high-dimensional embedding of the face x <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b43">44]</ref>. The common approach to facebased biometric analysis is to first align the face image to a canonical spatial frame <ref type="bibr" target="#b12">[13]</ref>, and analyze the cropped region of interest. Early approaches utilized local image descriptors <ref type="bibr" target="#b34">[35]</ref> to encode the face images in high-dimensional representations used for regression by Kernel PLS <ref type="bibr" target="#b18">[19]</ref>. The successful use of Deep Learning-based approaches in a gamut of computer vision tasks, paved the way for de-riving end-to-end trainable age estimation schemes <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b37">38]</ref> using either classification or regression losses. Metric learning was used in both shallow <ref type="bibr" target="#b19">[20]</ref> and CNN-based <ref type="bibr" target="#b27">[28]</ref> schemes, where local features were learned using their age difference as a metric measure. Ranking-based approaches <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b46">47]</ref> apply ordinal classification to utilize the ordinal structure of the age labels to improve accuracy.</p><p>In this work, we present a CNN-based architecture for facial image-based age estimation, that is depicted in <ref type="figure" target="#fig_1">Fig. 1</ref>. First, we introduce a novel attention-based image embedding based on joint augmentation and task-specific embedding aggregation implemented by a Transformer Encoder <ref type="bibr" target="#b40">[41]</ref>. Our approach is inspired by Encoder-based semantic analysis schemes <ref type="bibr" target="#b13">[14]</ref>, where a sequence of word embeddings is aggregated in a single embedding vector by a Transformer Encoder. Similarly, in the first phase (and contribution) of our approach, we improve the CNN-based face embedding by augmenting the input image multiple times in each CNN pass and fusing the different embeddings using a Transformer Encoder. The focal point is to learn an attention-based aggregated image embedding, that is invariant to appearance and geometrical variations, in each training iteration. In contrast to common approaches, that encode a single augmentation per image, and aggregate the appearance invariance over multiple training epochs. Second, we introduce a hierarchical probabilistic regression scheme that jointly learns age classification and regression models. In that, we utilize the robustness of classification-based age estimation, with the accuracy of age regressors ensembles, each related to a limited age estimation domain. We also present a bias analysis of the proposed age estimation scheme, with respect to ethnicity and gender. This is a fundamental issue in biometrics in this day and age that was mainly studied in the context of face recognition <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b15">16]</ref>. To the best of our knowledge, ours is the first bias analysis in face-based age estimation using a scheme achieving state-of-the-art (SOTA) accuracy.</p><p>In particular, we propose the following contributions:</p><p>• We propose a novel joint augmentation and embedding aggregation architecture to improve image embedding.</p><p>• We derive a probabilistic hierarchical age estimation scheme where, a probabilistic age estimate allows to optimally weigh the results of an ensemble of local age regressors.</p><p>• Both the proposed novel feature extraction and regression framework are of general applicability, and can be applied, together, or separately to any highdimensional regression problem.</p><p>• The proposed scheme is shown to achieve new SOTA accuracy when applied to contemporary age estimation datasets MORPH II <ref type="bibr" target="#b35">[36]</ref>.</p><p>• The proposed scheme is analyzed for bias with respect to gender and ethnicity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Face-based age estimation is easily handled by human observers on a daily basis, despite the inherent difficulties induced by the varying facial aging characteristics, and variations across ethnicities, gender and lifestyles. The significance of ethnicity and gender in face analysis and recognition was exemplified in the seminal work of Buolamwini and Gebru <ref type="bibr" target="#b1">[2]</ref> and is of particular interest. Guo and Mu <ref type="bibr" target="#b17">[18]</ref> proposed a two-step procedure where gender and ethnicity are first classified, and the age is separately estimated for each gender and ethnicity group. Shallow approaches utilized face embeddings based on local image features, followed by statistical inference. Thus, Balmaseda et al. <ref type="bibr" target="#b34">[35]</ref> used Local Binary Pattern (LBP) features and SVM classifiers to compute multiscale normalized face images, alongside their local context. Ranking was used by Zheng and Sun <ref type="bibr" target="#b2">[3]</ref> using a Ranking SVM, where the age is estimated by first learning ranking relationships, that were used alongside the reference set to estimate the age. Eidinger et al. <ref type="bibr" target="#b16">[17]</ref> proposed a gender and age classification scheme for non-frontal face images acquired under uncontrolled conditions. Regression-based approaches formulate the age estimation problem as a scalar regression given a high-dimensional image embedding. Chen and Gong <ref type="bibr" target="#b7">[8]</ref> introduced a cumulative attribute for learning a regression model when only sparse and imbalanced data are available to estimate age and crowd density. Low-level visual features extracted from sparse and imbalanced image samples are mapped onto a cumulative attribute space where each dimension is related to a semantic interpretation.</p><p>CNN-based schemes forgo the use of handcrafted image descriptors, in favor of learnt image embeddings. Thus, Wang and Kambhamettu <ref type="bibr" target="#b42">[43]</ref> proposed a hierarchical unsupervised neural network architecture to learn low-level translation-invariant features, used as inputs to a set of Recursive Neural Networks (RNNs). Manifold learning was applied to capture the underlying face aging manifold by projecting the feature vector into a low-dimensional, better discriminative subspace. Hassner and Levi <ref type="bibr" target="#b25">[26]</ref>, and Yi et al. <ref type="bibr" target="#b43">[44]</ref> reported significant accuracy improvements by formulating the age estimation as a classification problem, and applying CNNs. Deep metric learning was applied by Sendik et al. <ref type="bibr" target="#b37">[38]</ref> to face features computed by a CNN, while a Support Vector Regressor (SVR) was applied to estimate the age. Deep metric learning was also used by Liu et al. <ref type="bibr" target="#b27">[28]</ref>, who proposed a hard quadruplet mining scheme to improve the resulting embedding, while a regression-based loss was applied to estimate the age. Rothe et al. <ref type="bibr" target="#b36">[37]</ref> derived a classification scheme where the class probability distribution of the Softmax function was used to compute the empirical expectancy of estimated age. Pan et al. <ref type="bibr" target="#b32">[33]</ref> proposed a multi-task approach, by first computing the empirical estimation probability of each age using the Softmax activation function. The L 2 loss, as well as the empirical variance of the age estimation error were minimized. Malli at al. <ref type="bibr" target="#b30">[31]</ref> suggested an ensemble of CNN-based classification models, where each ensemble model was trained to classify within a different age domain. The final inference was computed by averaging over the models' outputs. Treebased approaches were also proposed <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b38">39]</ref>. A hybrid deep Regression Forests approach by Shen et al. <ref type="bibr" target="#b38">[39]</ref> utilizes both Regression Forests and deep learning inference. The forest nodes learn input-adaptive data partitions, and are connected to fully connected CNN layers. The Random Forests and CNN were jointly optimized in an endto-end approach. Li et al. <ref type="bibr" target="#b26">[27]</ref> used a tree-based structure where adjacent tree leaves in nearby branches were jointly connected to create a continuous transition, as well as an ensemble of local regressors. Each leaf is connected to a particular local regressor. The ordinality of the estimated ages was utilized by encoding the age labels is an ordinalitypreserving representation <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b3">4]</ref>, where each model output determines whether an estimated age is higher than a given threshold. Such approaches were shown to improve the age classification accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Attention and Transformers</head><p>The Attention mechanism [1] is a class of contemporary neural network layers that aggregate the information within input sequences. The inputs are aggregated by computing aggregation (attention) weights using the inner products between the input sequences. Attention layers are often stacked to improve the inference capacity, and were applied in both sequence-to-sequence (NLP translation) and sequence-to-one (sentiment analysis) problems. In selfattention, the attention weights are computed with respect to a single input series, and the module is denoted as an Encoder. By computing the inner products between the (single) input sequence and itself, the encoder maps the input sequence into a higher dimensional space. The inputs to a Decoder are Key and Query sequences used to compute the attention weights, to aggregate the Value sequence. Attention models allow to computationally emphasize the contribution of the task-informative image cues, in contrast to the visual clutter present in most images. Transformers were introduced by Vaswani et al. <ref type="bibr" target="#b40">[41]</ref> as a novel formulation of attention-based stacked layers, allowing encoding sequences without RNN layers such as LSTM and GRU. Transformers-based Encoders and Decoders utilize multiple stacked Multi-Head Attention (MHA) and Feed Forward layers. In contrast to the sequentially-structured RNNs, the relative position and sequential order of the sequence elements are induced by positional encodings, that are added to the Attention embeddings. Transformers were shown to provide a computationally efficient framework for most NLP tasks <ref type="bibr" target="#b13">[14]</ref>, achieving SOTA performance, and were also applied in a gamut of computer vision tasks <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b14">15]</ref>. In this work we were inspired by recent attention-based single sentence classification tasks in NLP <ref type="bibr" target="#b13">[14]</ref>, such as sentiment analysis. The gist of such approaches is to aggregate and encode an ordered sequence of word embeddings in a single embedding used for inference. Multiple such NLP tasks <ref type="bibr" target="#b13">[14]</ref> use the same sequence (sentence) Transformer Encoder-based aggregation, and differ on the particular dataset and training loss per task. In our approach the sequence of augmented image embeddings is unordered. Thus, there is no need for positional encoding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Bias Analysis</head><p>The significant accuracy improvement of face-based biometrics, such as face recognition, gender and ethnicity identification and age estimation, has resulted in a proliferation in their deployment in a gamut of applications. In particular, face-based biometrics were deployed by law-enforcement agencies and commercial vendors. In their seminal work, Buolamwini and Gebru <ref type="bibr" target="#b1">[2]</ref> showed the inherent bias of contemporary SOTA face recognition systems with respect to gender and ethnicity. Similarly, Wang et al. <ref type="bibr" target="#b41">[42]</ref> studied the ethnicity bias for multiple SOTA commercial and academic face recognition schemes. For that they proposed the Racial Faces in-the-Wild (RFW) database for which the ethnicity of each subject was thoroughly validated. They also propose a domain adaptation scheme, shown to reduce the ethnical bias in face recognition. The accuracy bias of face recognition due to ethnicity or skin tone was also studied by Krishnapriya at al. <ref type="bibr" target="#b23">[24]</ref> who showed that for a fixed decision threshold, Caucasian face images have a higher false non-matching rate, while the face image of African-Americans are characterized by a higher false matching rate. In particular, one-to-many identification might have a low false-negative identification rate, while having significant false-positive identification rates. A thorough survey of recent results in biometrics algorithmic bias was presented by Drozdowski at al. <ref type="bibr" target="#b15">[16]</ref>.</p><p>The bias in face-based age estimation was first studied by Puc et al. <ref type="bibr" target="#b33">[34]</ref>, who showed that age estimation accuracy is consistently higher for men than for women, while ethnicity does not seem to have a significant or consistent effects. Unfortunately, their analysis was conducted using non-SOTA approaches, such that MAE≈ 7, compared to MAE≈ 2.5 in contemporary schemes. Also, their analysis was not applied to contemporary age estimation datasets such as the MORPH Album II <ref type="bibr" target="#b35">[36]</ref>. Hence, to the best of our knowledge, our work is the first to report SOTA age estimation results with bias analysis. using a backbone CNN. The embeddings are aggregated by a Transformer Encoder, where the output is given by the cls token.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Hierarchical attention-based age estimation</head><p>In this work we propose a deep-learning-based scheme to estimate a subject's age a given the face image x. An overview of the proposed scheme is shown in <ref type="figure" target="#fig_1">Fig. 1</ref>. It consists of two main building blocks: the first is a novel image embedding architecture based on a self-attention Transformer Encoder. The second is a hierarchical regression framework. In the image embedding phase, detailed in Section 3.1, given an input image x, we create K corresponding augmentations {x i } K 1 , and compute their corresponding embeddings {x i } K 1 using a backbone CNN. The embeddings {x i } K 1 are aggregated by a self-attention Transformer Encoder yielding a fused embedding vectorx. The fused embedding is processed by a hierarchical regression that jointly utilizes a probabilistic age classifier, and a corresponding ensemble of age regressors, such that the regressors' output is adaptively weighted by the classification probabilities, as detailed in Section 3.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Self Attention-based Image Embedding</head><p>We propose a novel augmentation and attention-based image embedding to compute an image embedding that is robust to appearance variations, as shown in <ref type="figure" target="#fig_0">Fig. 2</ref>. For that, each input image x is augmented K times to create the set of augmented images {x i } K 1 ∈ R 224×224 . The image augmentations that are used, follow previous works and are detailed in Section 4.2. We also experimented in learning the augmentations using RandAugment <ref type="bibr" target="#b10">[11]</ref>, but this did not improve the accuracy. Each of these image augmentation x k ∈ {x k } K 1 is embedded by a CNN backbone. Any CNN can be used, and we evaluated multiple backbones, as detailed in Section 4, to compare against contemporary schemes in which they were used. The set of embeddings {x i } K 1 ∈ R 512 is aggregated into a single embedding vectorx using a Transformer Encoder. As the sequence of augmentations embeddings are unordered, there is no need for positional encoding, and the encoding is derived by adding a fully-learnt class token ∈ R 512 to the encoded series. The aggregated representationx is the Transformer Encoder's output corresponding to the cls token, as in <ref type="figure" target="#fig_0">Fig. 2</ref>. The proposed aggregation scheme is of general applicability and can be applied to any task where the input can be is augmented.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Hierarchical probabilistic age regression</head><p>The inference phase in deep learning-based age estimation schemes is based on either classification <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b43">44]</ref> or regression <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b3">4]</ref>. Classification-based schemes aim to classify a face image to one of {a c } C 1 ages. The accuracy of regression schemes can be improved by using an ensemble of regressors {R c ( x)} C 1 <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b38">39]</ref>, where each regressor R c ( x) estimates the residual regression with respect to the discrete label a c such that the estimated age a is given by</p><formula xml:id="formula_0">a = a c + R c ( x) .<label>(1)</label></formula><p>We propose to jointly utilize the upside of both classification and regression approaches using the framework shown in <ref type="figure">Fig. 3</ref>. We simultaneously apply both an age classifier over a set of ages {a c } </p><p>The classifier is optimized by a multiple losses: the first is the Cross Entropy loss L ce , and the second is the Mean-Variance Loss <ref type="bibr" target="#b32">[33]</ref> consisting of two terms</p><formula xml:id="formula_2">L m = 1 2N N i=1 C c=1 P (a = a c ) · c − a 0 i 2<label>(3)</label></formula><p>and   </p><formula xml:id="formula_3">L v = 1 N N i=1 C c=1 P (a = a c ) c − C c=1 c · P (a = a c ) 2 ,<label>(4)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mean-Variance Loss</head><formula xml:id="formula_4">F C R 1 F C R C R 1 (x) R C (x) {R i (x)} C 1 {c i } C 1 {â i } C 1â L 2 Loss</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The regression ensemble {R</head><formula xml:id="formula_5">c ( x)} C 1 is optimizes by a corresponding set of L 2 losses {L c 2 } C 1 .</formula><p>The overall loss is that given by</p><formula xml:id="formula_6">L = λ 1 L ce + λ 2 L m + λ 3 L v + λ 4 c L c 2 ,<label>(5)</label></formula><p>where {λ i } 4 1 are predefined weights discussed in Section 4.2.</p><p>Our approach implicitly assumes that the facial aging process is episodic, implying that although aging is a continuous process, faces related to nearby ages are more related than far away ones, and that the aging process differs notably at different life episodes. Thus, each age episode is locally analyzed by a particular regressor R c ( x). Even though the aging process is episodic it is still continuous, and restricting each local regressor </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental Results</head><p>The proposed scheme was experimentally evaluated by applying it to the contemporary face image datasets detailed in Section 4.1, and comparing to the results of state-of-theart (SOTA) approaches in Section 4.3. The implementation details and evaluation metrics are reported in Section 4.2, and an ablation study that reviews different variations of our scheme is given in Section 4.4. The bias analysis is reported in Section 4.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Datasets</head><p>MORPH Album II <ref type="bibr" target="#b35">[36]</ref> is one of the largest longitudinal face databases available. It contains about 55k facial images of 13.5k subjects whose ages range from 16 to 77, such that each subject is depicted in multiple images. The identity of the subject in each image is known. All images are mugshots taken in a controlled environment of good image quality, centered faces poses and neutral face expressions. The dataset depicts both genders, and multiple ethnic groups, mostly white and black. Its demographic and gender breakdown is reported in <ref type="table">Table 1</ref>.</p><p>We follow two evaluation protocols used in previous works to define the training and testing sets, The first, is the Random-Split (RS) protocol, in which the face images are randomly split to train and test, such that the images of the same person of the same age, might appear in both train and test sets. This creates a leakage between the train and test sets, as it essentially mixes age estimation with age recognition. Thus, a face recognition scheme, with no age estimation training, can achieve perfect age estimation accuracy. The Second protocol is the Subject-Exclusive (SE) protocol, where identities are randomly split to be either train or test, but not both, to avoid leakage. Due to the leakage, the RS accuracy is significantly higher than the SE scores for all schemes and datasets. Hence, we submit that the RS metric should be considered less reliable and avoided in future works when possible. In this work we report RS results due to legacy results we have to compare with. The MORPH II can be used to evaluate the age estimation accuracy using both protocols. We avoided using the AFAD dataset <ref type="bibr" target="#b31">[32]</ref>, where the identities of the subjects are unknown, implying that only the RS protocol can be applied. Similarly, the FG-NET dataset <ref type="bibr" target="#b9">[10]</ref> consisting of only 1,002 images of 82 subjects, which is too small for our Transformer-driven approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Black</head><p>White </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Implementation Details</head><p>The age estimation accuracy is evaluated by the standard Mean Absolute Error (MAE) that was used in all previous works. The MAE is calculated using the mean absolute error between the predicted age a i and the ground truth a 0</p><formula xml:id="formula_7">i M AE= 1 N i | a i − a 0 i |,<label>(6)</label></formula><p>where N is the number of test images. The lower the MAE the better the accuracy. We used the Vgg-16 <ref type="bibr" target="#b39">[40]</ref> and ResNet-34 <ref type="bibr" target="#b21">[22]</ref> CNN backbones that were used in previous SOTA age estimation schemes, such that the comparison could be based only on the proposed architecture rather than the backbone. Each backbone was first trained for recognition over the training set using the Arcface loss <ref type="bibr" target="#b11">[12]</ref>. The input face images were first detected, cropped and aligned by the RetinaFace detector <ref type="bibr" target="#b12">[13]</ref> and then resized to a size of 224×224. The proposed attention-based aggregation was implemented using a Transformer-Encoder with four blocks, a dropout of p = 0.1, where each block contains an MHA layer with four heads. Each input image was augmented to K = 10 images, such that multiple augmentations were randomly applied with a probability of 0.5: horizontal flips, color jittering, random affine transformation and randomly erasing small parts of the image, adapted from <ref type="bibr" target="#b22">[23]</ref>. We also applied the RandAugment <ref type="bibr" target="#b10">[11]</ref> approach, but achieved no accuracy improvement. The classifier in Section 3.2 and the corresponding ensemble of classifiers {R c ( x)} C 1 were applied with {a c } C 1 = {1, 2, ..., 75}. We used the Ranger optimizer, a combination of Rectified Adam <ref type="bibr" target="#b28">[29]</ref> with the Lookahead technique <ref type="bibr" target="#b45">[46]</ref>, and a Cosine Annealing learning rate decay <ref type="bibr" target="#b29">[30]</ref>. All experiments are conducted using a single NVIDIA GTX 1080 TI, and the PyTorch framework. The loss hyper-parameters λ i in Equ. 5 are set to: 0.2, 0.05, 1, 1 accordingly, where the parameters λ 1 , λ 2 , λ 3 were taken from <ref type="bibr" target="#b32">[33]</ref>, and λ 4 =1 is in accordance with λ 3 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">MORPH II results</head><p>We compare our approach with multiple SOTA methods using the MORPH II dataset, and the results are reported in <ref type="table">Table 2</ref>, respectively. The results of previous schemes are quoted from their respective publications that used the same protocol specifications as our. Following previous works, we randomly split the datasets to 80% train and 20% test in both the RS and SE protocols. <ref type="table">Table 2</ref> shows that our approach outperforms all previous methods on the MORPH II dataset using both the RS and SE protocols. The RS accuracy (MAE = 1.13) is significantly higher than the SE accuracy (MAE = 2.53). We attribute that, as mentioned before, to the leakage in the RS protocol, making the RS results less indicative. shown in <ref type="figure">Fig. 4</ref> resembles a Gaussian distribution around zero, where most estimation errors (≈ 77%) are within an interval of three years. In particular, our hierarchical probabilistic approach outperforms Li et al. <ref type="bibr" target="#b26">[27]</ref>, that also divide the age axis into multiple overlapping sub-domains and employ local regressors over those sub-domains, while using the same backbone as ours. We also outperform the Mean-Variance approach <ref type="bibr" target="#b32">[33]</ref> that employs the same backbone and losses.</p><p>0HDQ(VWLPDWLRQ(UURU&gt;DJH@ 3UREDELOLW\ <ref type="figure">Figure 4</ref>: The distribution of the age estimation errors. The proposed scheme was applied to the Morph II dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Ablation study</head><p>In order to evaluate the contribution of each of the proposed algorithmic components, we conducted multiple ablation studies. In each ablation experiment we modified a single algorithmic component or hyper-parameter to evaluate it, and applied the resulting implementation to the MORPH II dataset that allows to apply both the RS and SE protocols. The baseline scheme is the one in <ref type="table">Table 2</ref>.  <ref type="table">Table 3</ref>: Ablation study of the proposed attention-based augmentation-aggregation scheme. We compare the performance of our proposed architecture with different number of augmentations at input (K). '1 no-encoder' reffers to using a single augmentation without an encoder. '10 averagepool' reffers to using 10 augmentations that are aggregated by averaging the activations maps.</p><p>We first evaluated the attention-based augmentationaggregation scheme detailed in Section 3.1. For that we implemented two additional variations: the first (1 noencoder), is a naive baseline without augmentations and aggregations, where we only uses a single replica of the input image. This results in the lowest accuracy of 2.63. When we apply 10 augmentations using average pooling (10 averagepool), the accuracy improved to 2.58 compared to the our SOTA of 2.58. As for the number of augmentations used.</p><p>The results, shown in <ref type="table">Table 3</ref>   <ref type="table">Table 4</ref>: Ablation study of varying Transformer Encoder parameters: the number of encoder layers and attention heads.</p><p>The Encoder configuration was examined by trying out multiple configurations. The more encoder layers are used, the larger the network's learning capacity. But, this might also lead to overfitting. Indeed, the results in <ref type="table">Table 4</ref> show that the 'sweet spot' is achieved for four layers and four MHA. Using a deeper configuration leads to overfitting. We also verified the choice of the age classification bin size and corresponding classification ensemble {R c ( x)} C 1 . It follow that the best accuracy is achieved for binsize = 1.</p><p>Bin size MAE 10 2.56 5 2.56 1 2.53 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Bias Analysis</head><p>Following the discussion in Section 2.2, we present a statistical bias analysis based on the MORPH II dataset, whose gender and ethnicity breakdown are given in <ref type="table">Table 1</ref>. The MORPH II dataset is imbalanced in terms of the age, gender and ethnicity. Our approach, as well as all prior schemes, was trained by randomly sampling the dataset, resulting in an ethnically and gender-wise unbalanced and biased training and test sets. We report for the first time, to the best of our knowledge, bias estimates that are also applicable to previous works. In our bias analysis we use the SE protocol and the proposed SOTA network as in <ref type="table">Table 2</ref>.</p><p>Age bias. The error distribution vs. the estimated age is reported in <ref type="table" target="#tab_6">Table 6</ref>. The age estimation errors relate to the given number of training samples per age range, and the age-related appearance changes, that are difficult to quantify. The lowest estimation error is for the 15-25 age range. As the number of training samples is relatively small, We at-tribute that to the accelerated rate of physiological appearance changes making the age estimation easier. The error flattens for the 30-50 age range that contains most of the training samples, and increases for the 55-70 age range in which here are a limited number of samples.  Gender and ethnicity bias. The most common source of estimation bias in biometrics is due to gender and ethnicity. We study the bias due to ethnicity, as reported in <ref type="figure">Fig. 5</ref>, where there seems to be no apparent estimation bias. We present the gender-only estimation accuracies in <ref type="figure">Fig. 6</ref>, where the rate of low estimation errors is higher for man by close to 10%. We attribute that to a notably larger number of male training samples. The breakdown of the bias due to gender and ethnicity is given in <ref type="figure">Fig. 7</ref>, where the error for female subjects is higher for all ethnicities. In particular, it is higher by close to 0.8 and 0.5 years for black and while female subjects, respectively. The proposed scheme was shown to be non-biased with respect to ethnicity, despite the imbalanced training set. But is biased towards female subjects by an average error of 0.7 years. Our findings coincide with those of Puc et al. <ref type="bibr" target="#b33">[34]</ref> that used different schemes and evaluation datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions</head><p>In this work we presented a novel deep-learning approach for age estimation based on face images. First, we show that multiple image augmentations can be jointly encoded and aggregated by a Transformer-Encoder yielding a robust image embedding. Second, we propose a probabilistic hierarchical age estimation framework that applies a deep classifier to estimate the age probabilities. The probability estimates are used to weigh a corresponding ensemble of local regressors, each adapted to a particular age subdomain. The proposed scheme is shown to outperform con- temporary SOTA schemes. We also introduce, for the first time to our knowledge, a bias analysis of SOTA results in face-based age estimation. We hope that the proposed bias analysis would be used by others in the field.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>The proposed augmentation self-attention-based image embedding. We create K augmentations {x 1 } K 1 of the input image x, and compute their embeddings { x 1 } K 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>C 1 ,</head><label>1</label><figDesc>and an ensemble of residual regressors {R c ( x)} C 1 as in Eq. 1. The classifier robustly estimates the age probabilities P (a = a c ) that are used to estimate the age as the expectancy a = c P (a = a c ) R c ( x) .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>where N is the number of points in a batch. Equation 3 minimizes the mean square error (MSE) between the empirical expectancy and the ground truth a 0 i , while Equ. 4 minimizes the empirical variance of the estimate.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :C 1 .</head><label>31</label><figDesc>The proposed hierarchical regression framework. The input feature vectorx is jointly processed by two parallel branches: the upper is the classifier, while the lower is the regression ensemble {R c ( x)} The age estimate a is given by the empirical expectancy of { a i } C 1 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>R c ( x) might cause significant marginal effects. The formulation in Eq. 2 allows the classifier and the regressors ensemble {R c ( x)} C 1 to communicate via their joint optimization and the end-toend training.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 :Figure 6 :Figure 7 :</head><label>567</label><figDesc>Ethnicity bias. The MAE per ethnicity over the Morph II dataset. There is no apparent ethnicity-related estimation bias. Gender bias. Estimation MAE probability per gender over the Morph II dataset. The probability of low age estimation errors is higher by close to 10% for male images. Gender and ethnicity bias. Age MAE per ethnicity and gender. The age MAE for men subjects is better by 0.5-0.7 years.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>exemplify the effectivity of the proposed augmentation-aggregation. In particular, using additional augmentations per image improves the estimation accuracy up to 10 augmentations, applying additional augmentations does not improve the accuracy.</figDesc><table><row><cell cols="3"># layers # heads MAE</cell></row><row><cell>8</cell><cell>8</cell><cell>2.57</cell></row><row><cell>4</cell><cell>4</cell><cell>2.53</cell></row><row><cell>2</cell><cell>2</cell><cell>2.55</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>Ablation study of the classification bin size and corresponding regression ensemble {R c ( x)}</figDesc><table /><note>C 1 .</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 :</head><label>6</label><figDesc>Age bias. The number of MORPH II samples per age category, and the corresponding MAE and standard deviation of the age estimation error in each category.</figDesc><table /><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3rd International Conference on Learning Representations</title>
		<editor>Yoshua Bengio and Yann Le-Cun</editor>
		<meeting><address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-05-07" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Gender shades: Intersectional accuracy disparities in commercial gender classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joy</forename><surname>Buolamwini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timnit</forename><surname>Gebru</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st Conference on Fairness, Accountability and Transparency</title>
		<editor>Sorelle A. Friedler and Christo Wilson</editor>
		<meeting>the 1st Conference on Fairness, Accountability and Transparency<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-02" />
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Human age estimation using ranking svm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiwei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stan</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Biometric Recognition</title>
		<editor>Wei-Shi Zheng, Zhenan Sun, Yunhong Wang, Xilin Chen, Pong C. Yuen, and Jianhuang Lai</editor>
		<meeting><address><addrLine>Berlin, Heidelberg; Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="324" to="331" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Rank consistent ordinal regression for neural networks with application to age estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenzhi</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vahid</forename><surname>Mirjalili</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Raschka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">140</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">End-to-end object detection with transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Carion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Synnaeve</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kirillov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Zagoruyko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision -ECCV 2020</title>
		<editor>Andrea Vedaldi, Horst Bischof, Thomas Brox, and Jan-Michael Frahm</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="213" to="229" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Accuracy comparison across face recognition algorithms: Where are we on measuring race bias?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">G</forename><surname>Cavazos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Phillips</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Castillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>O&amp;apos;toole</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Biometrics, Behavior, and Identity Science</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="101" to="111" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Ordinal hyperplanes ranker with cost sensitivities for age estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuang-Yu</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chu-Song</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Ping</forename><surname>Hung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2011 IEEE Conference on</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="585" to="592" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Cumulative attribute space for age and crowd density estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaogang</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Loy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="2467" to="2474" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Using ranking-cnn for age estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="742" to="751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">The fg-net aging database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Cootes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Lanitis</surname></persName>
		</author>
		<ptr target="http://www-prima.inrialpes.fr/FGnet/.6" />
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Randaugment: Practical automated data augmentation with a reduced search space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR Workshops 2020</title>
		<meeting><address><addrLine>Seattle, WA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Arcface: Additive angular margin loss for deep face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4685" to="4694" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Retinaface: Singleshot multi-level face localisation in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiankang</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evangelos</forename><surname>Ververas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irene</forename><surname>Kotsia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanos</forename><surname>Zafeiriou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting><address><addrLine>Seattle, WA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-06" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">An image is worth 16x16 words: Transformers for image recognition at scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mostafa</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Minderer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Heigold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sylvain</forename><surname>Gelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Houlsby</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Demographic bias in biometrics: A survey on an emerging challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Drozdowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rathgeb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dantcheva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Damer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Busch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Technology and Society</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Age and gender estimation of unfiltered faces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Eidinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Enbar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hassner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Forensics and Security</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2170" to="2179" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Human age estimation: What is the influence across race and gender?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guowang</forename><surname>Mu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition Workshops (CVPRW), 2010 IEEE Computer Society Conference on</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="71" to="78" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Simultaneous dimensionality reduction and human age estimation via kernel partial least squares regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guowang</forename><surname>Mu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2011 IEEE Conference on</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="657" to="664" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Dimensionality reduction by learning an invariant mapping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR&apos;06)</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1735" to="1742" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Zeeshan Rasheed, and Niels Haering. Video analytics for business intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asaad</forename><surname>Hakeem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Himaanshu</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Atul</forename><surname>Kanaujia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tae</forename><forename type="middle">Eun</forename><surname>Choe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kiran</forename><surname>Gunda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">W</forename><surname>Scanlon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Péter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Venetianer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Video Analytics for Business Intelligence</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Bag of tricks for image classification with convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="558" to="567" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Issues related to face recognition accuracy varying based on race and skin tone</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">S</forename><surname>Krishnapriya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Albiero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Vangara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">W</forename><surname>Bowyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Technology and Society</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="8" to="20" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Comparing different classifiers for automatic age estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Lanitis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chrisina</forename><surname>Draganova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chr</forename><surname>Christodoulou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="621" to="628" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Age and gender classification using convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Levi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hassner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition Workshops (CVPRW), 2015 IEEE Conference on</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="34" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Bridgenet: A continuity-aware probabilistic network for age estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Label-sensitive deep metric learning for facial age estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Forensics and Security</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">On the variance of the adaptive learning rate and beyond</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoming</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengcheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<idno>abs/1908.03265</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">SGDR: stochastic gradient descent with warm restarts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">5th International Conference on Learning Representations</title>
		<meeting><address><addrLine>Toulon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-04-24" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings. OpenReview.net</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Apparent age estimation using ensemble of deep learning models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehmet</forename><surname>Refik Can Malli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hazim Kemal</forename><surname>Aygun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ekenel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Ordinal regression with multiple output cnn for age estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="4920" to="4928" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Mean-variance loss for deep age estimation from a face</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyu</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hu</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiguang</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xilin</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting><address><addrLine>Salt Lake City, UT, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-06-18" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Analysis of race and gender bias in deep age estimation models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Puc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Štruc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Grm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 28th European Signal Processing Conference</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="830" to="834" />
		</imprint>
		<respStmt>
			<orgName>EU-SIPCO</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Gender classification in large databases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enrique</forename><surname>Ramón-Balmaseda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Lorenzo-Navarro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Modesto</forename><surname>Castrillón-Santana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Progress in Pattern Recognition, Image Analysis, Computer Vision, and Applications</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="74" to="81" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Morph: a longitudinal image database of normal adult age-progression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ricanek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tesafaye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">7th International Conference on Automatic Face and Gesture Recognition (FGR06)</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Dex: Deep expectation of apparent age from a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rothe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Timofte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE International Conference on Computer Vision Workshop (ICCVW)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Deepage: Deep learning of face-based age estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omry</forename><surname>Sendik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yosi</forename><surname>Keller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Signal Processing: Image Communication</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">78</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Deep regression forests for age estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3rd International Conference on Learning Representations</title>
		<meeting><address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-05-07" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017</title>
		<editor>Isabelle Guyon, Ulrike von Luxburg, Samy Bengio, Hanna M. Wallach, Rob Fergus, S. V. N. Vishwanathan, and Roman Garnett</editor>
		<meeting><address><addrLine>Long Beach, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Racial faces in the wild: Reducing racial bias by information maximization adaptation network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="692" to="702" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Age estimation via unsupervised neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kambhamettu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Automatic Face and Gesture Recognition (FG), 2015 11th IEEE International Conference and Workshops on</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Age estimation by multi-scale convolutional network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stan</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision-ACCV 2014</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Soft-ranking label encoding for robust facial age estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="134209" to="134218" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Lookahead optimizer: k steps forward, 1 step back</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems</title>
		<editor>Hanna M. Wallach, Hugo Larochelle, Alina Beygelzimer, Florence d&apos;Alché-Buc, Emily B. Fox, and Roman Garnett</editor>
		<meeting><address><addrLine>NeurIPS; Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-12-08" />
			<biblScope unit="page" from="9593" to="9604" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Distilling ordinal relation and dark knowledge for facial age estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qilu</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyu</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
	<note>PP</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
