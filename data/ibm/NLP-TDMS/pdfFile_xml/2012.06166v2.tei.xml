<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Few-Shot Segmentation Without Meta-Learning: A Good Transductive Inference Is All You Need?</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Malik</forename><surname>Boudiaf</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">CentraleSupélec</orgName>
								<orgName type="institution">CNRS Université Paris-Saclay</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ets</forename><surname>Montreal</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">CentraleSupélec</orgName>
								<orgName type="institution">CNRS Université Paris-Saclay</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hoel</forename><surname>Kervadeć</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">CentraleSupélec</orgName>
								<orgName type="institution">CNRS Université Paris-Saclay</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ets</forename><surname>Montreal</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">CentraleSupélec</orgName>
								<orgName type="institution">CNRS Université Paris-Saclay</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziko</forename><forename type="middle">Imtiaz</forename><surname>Masud</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">CentraleSupélec</orgName>
								<orgName type="institution">CNRS Université Paris-Saclay</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ets</forename><surname>Montreal</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">CentraleSupélec</orgName>
								<orgName type="institution">CNRS Université Paris-Saclay</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pablo</forename><surname>Piantanida</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">CentraleSupélec</orgName>
								<orgName type="institution">CNRS Université Paris-Saclay</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ismail</forename><forename type="middle">Ben</forename><surname>Ayed</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">CentraleSupélec</orgName>
								<orgName type="institution">CNRS Université Paris-Saclay</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ets</forename><surname>Montreal</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">CentraleSupélec</orgName>
								<orgName type="institution">CNRS Université Paris-Saclay</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jose</forename><surname>Dolź</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">CentraleSupélec</orgName>
								<orgName type="institution">CNRS Université Paris-Saclay</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ets</forename><surname>Montreal</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">CentraleSupélec</orgName>
								<orgName type="institution">CNRS Université Paris-Saclay</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Few-Shot Segmentation Without Meta-Learning: A Good Transductive Inference Is All You Need?</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T20:01+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We show that the way inference is performed in few-shot segmentation tasks has a substantial effect on performances-an aspect often overlooked in the literature in favor of the meta-learning paradigm. We introduce a transductive inference for a given query image, leveraging the statistics of its unlabeled pixels, by optimizing a new loss containing three complementary terms: i) the crossentropy on the labeled support pixels; ii) the Shannon entropy of the posteriors on the unlabeled query-image pixels; and iii) a global KL-divergence regularizer based on the proportion of the predicted foreground. As our inference uses a simple linear classifier of the extracted features, its computational load is comparable to inductive inference and can be used on top of any base training. Foregoing episodic training and using only standard cross-entropy training on the base classes, our inference yields competitive performances on standard benchmarks in the 1-shot scenarios. As the number of available shots increases, the gap in performances widens: on PASCAL-5 i , our method brings about 5% and 6% improvements over the state-ofthe-art, in the 5-and 10-shot scenarios, respectively. Furthermore, we introduce a new setting that includes domain shifts, where the base and novel classes are drawn from different datasets. Our method achieves the best performances in this more realistic setting. Our code is freely available online:</p><p>https://github.com/mboudiaf/ RePRI-for-Few-Shot-Segmentation.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Few-shot learning, which aims at classifying instances from unseen classes given only a handful of training ex-* Corresponding author: malik.boudiaf.1@etsmtl.net amples, has witnessed a rapid progress in the recent years. To quickly adapt to novel classes, there has been a substantial focus on the meta-learning (or learning-to-learn) paradigm <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b34">35]</ref>. Meta-learning approaches popularized the need of structuring the training data into episodes, thereby simulating the tasks that will be presented at inference. Nevertheless, despite the achieved improvements, several recent image classification works <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b43">44]</ref> observed that meta-learning might have limited generalization capacity beyond the standard 1-or 5-shot classification benchmarks. For instance, in more realistic settings with domain shifts, simple classification baselines may outperform much more complex meta-learning methods <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b11">12]</ref>.</p><p>Deep-learning based semantic segmentation has been generally nurtured from the methodological advances in image classification. Few-shot segmentation, which has gained popularity recently <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b41">42]</ref>, is no exception. In this setting, a deep segmentation model is first pre-trained on base classes. Then, model generalization is assessed over few-shot tasks and novel classes unseen during base training. Each task includes an unlabeled test image, referred to as the query, along with a few labeled images (the support set). The recent literature in few-shot segmentation follows the learning-tolearn paradigm, and substantial research efforts focused on the design of specialized architectures and episodic-training schemes for base training. However, i) episodic training itself implicitly assumes that testing tasks have a structure (e.g., the number of support shots) similar to the tasks used at the meta-training stage; and ii) base and novel classes are often assumed to be sampled from the same dataset.</p><p>In practice, those assumptions may limit the applicability of the existing few-shot segmentation methods in realistic scenarios <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref>. In fact, our experiments proved consistent with findings in few-shot classification when going beyond the standard settings and benchmarks. Particularly, we ob-served among state-of-the-art methods a saturation in performances <ref type="bibr" target="#b2">[3]</ref> when increasing the number of labeled samples (See <ref type="table" target="#tab_2">Table 3</ref>). Also, in line with very recent observations in image classification <ref type="bibr" target="#b3">[4]</ref>, existing meta-learning methods prove less competitive in cross-domains scenarios (See <ref type="table" target="#tab_3">Table 4</ref>). This casts doubts as to the viability of the current few-shot segmentation benchmarks and datasets; and motivates re-considering the relevance of the meta-learning paradigm, which has become the de facto choice in the fewshot segmentation litterature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Contributions</head><p>In this work, we forego meta-learning, and re-consider a simple cross-entropy supervision during training on the base classes for feature extraction. Additionally, we propose a transductive inference that better leverages the support-set supervision than the existing methods. Our contributions can be summarized as follows:</p><p>• We present a new transductive inference-RePRI (Region Proportion Regularized Inference)-for a given few-shot segmentation task. RePRI optimizes a loss integrating three complementary terms: i) a standard cross-entropy on the labeled pixels of the support images; ii) the entropy of the posteriors on the query pixels of the test image; and iii) a global KL divergence regularizer based on the proportion of the predicted foreground pixels within the test image. RePRI can be used on top of any trained feature extractor, and uses exactly the same information as standard inductive methods for a given few-shot segmentation task.</p><p>• Although we use a basic cross-entropy training on the base classes, without complex meta-learning schemes, RePRI yields highly competitive performances on the standard few-shot segmentation benchmarks, PASCAL-5 i and COCO-20 i , with gains around 5% and 6% over the state-of-the-art in the 5-and 10shot scenarios, respectively.</p><p>• We introduce a more realistic setting where, in addition to the usual shift on classes between training and testing data distributions, a shift on the images' feature distribution is also introduced. Our method achieves the best performances in this scenario.</p><p>• We demonstrate that a precise region-proportion information on the query object improves substantially the results, with an average gain of 13% on both datasets. While assuming the availability of such information is not realistic, we show that inexact estimates can still lead to drastic improvements, opening a very promising direction for future research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Few-Shot Learning for classification Meta-learning has become the de facto solution to learn novel tasks from a few labeled samples. Even though the idea is not new <ref type="bibr" target="#b27">[28]</ref>, it has been revived recently by several popular works in few-shot classification <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b34">35]</ref>. These works can be categorized into gradient-or metric-learning-based methods. Gradient approaches resort to stochastic gradient descent (SGD) to learn the commonalities among different tasks <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b8">9]</ref>. Metric-learning approaches <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b30">31]</ref> adopt deep networks as feature-embedding functions, and compare the distances between the embeddings. Furthermore, in a recent line of works, the transductive setting has been investigated for few-shot classification <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b43">44]</ref>, and yielded performance improvements over inductive inference. These results are in line with established facts in classical transductive inference <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b4">5]</ref>, well-known to outperform its inductive counterpart on small training sets.</p><p>To a large extent, these transductive classification works follow well-known concepts in semi-supervised learning, such as graph-based label propagation <ref type="bibr" target="#b19">[20]</ref>, entropy minimization <ref type="bibr" target="#b5">[6]</ref> or Laplacian regularization <ref type="bibr" target="#b43">[44]</ref>. While the entropy is a part of our transductive loss, we show that it is not sufficient for segmentation tasks, typically yielding trivial solutions.</p><p>Few-shot segmentation Segmentation can be viewed as a classification at the pixel level, and recent efforts mostly went into the design of specialized architectures. Typically, the existing methods use a two-branch comparison framework, inspired from the very popular prototypical networks for few-shot classification <ref type="bibr" target="#b30">[31]</ref>. Particularly, the support images are employed to generate class prototypes, which are later used to segment the query images via a prototypequery comparison module. Early frameworks followed a dual-branch architecture, with two independent branches <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b24">25]</ref>, one generating the prototypes from the support images and the other segmenting the query images with the learned prototypes. More recently, the dual-branch setting has been unified into a single-branch, employing the same embedding function for both the support and query sets <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b20">21]</ref>. These approaches mainly aim at exploiting better guidance for the segmentation of query images <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b39">40]</ref>, by learning better class-specific representations <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b29">30]</ref> or iteratively refining these <ref type="bibr" target="#b40">[41]</ref>. Graph CNNs have also been employed to establish more robust correspondences between the support and query images, enhancing the learned prototypes <ref type="bibr" target="#b35">[36]</ref>. Alternative solutions to learn better class representations include: imprinting the weights for novel classes <ref type="bibr" target="#b29">[30]</ref>, decomposing the holistic class representation into a set of part-aware prototypes <ref type="bibr" target="#b20">[21]</ref> or mixing several prototypes, each corresponding to diverse image regions <ref type="bibr" target="#b37">[38]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Formulation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Few-shot Setting</head><p>Formally, we define a base dataset D base with base semantic classes Y base , employed for training. Specifically, D base = {(x n , y n )} N n=1 , Ω ⊂ R 2 an image space, x n : Ω → R 3 an input image, and y n : Ω → {0, 1} |Y base | its corresponding pixelwise one-hot annotation. At inference, we test our model through a series of K-shots tasks. Each K-shots task consists of a support set S = {(x k , y k )} K k=1 , i.e. K fully annotated images, and one unlabelled query image x Q , all from the same novel class. This class is randomly sampled from a set of novel classes Y novel such that Y base ∩ Y novel = ∅. The goal is to leverage the supervision provided by the support set in order to properly segment the object of interest in the query image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Base training</head><p>Inductive bias in episodic training There exist different ways of leveraging the base set D base . Meta-learning, or learning to learn, is the dominant paradigm in the few-shot literature. It emulates the test-time scenario during training by structuring D base into a series of training tasks. Then, the model is trained on these tasks to learn how to best leverage the supervision from the support set in order to enhance its query segmentation. Recently, Cao et al. <ref type="bibr" target="#b2">[3]</ref> formally proved that the number of shots K train used in train-ing episodes in the case of prototypical networks represents a learning bias, and that the testing performance saturates quickly when K test differs from K train . Empirically, we observed the same trend for current few-shot segmentation methods, with minor improvements from 1-shot to 5-shot performances ( <ref type="table" target="#tab_0">Table 1)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Standard training</head><p>In practice, the format of the test tasks may be unknown beforehand. Therefore, we want to take as little assumptions as possible on this. This motivates us to employ a feature extractor f φ trained with standard crossentropy supervision on the whole D base set instead, without resorting to episodic training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Inference</head><p>Objective In what follows, we use as a placeholder to denote either a support subscript k ∈ {1, ..., K} or the query subscript Q. At inference, we consider the 1-way segmentation problem: y : Ω → {0, 1} 2 is the function representing the dense background/foreground (B/F) mask in image x . For both support and query images, we extract features z := f φ (x ) and z : Ψ → R C , where C is the channel dimension in the feature space Ψ, with lower pixel resolution |Ψ| &lt; |Ω|.</p><p>Using features z , our goal is to learn the parameters θ of a classifier that properly discriminates foreground from background pixels. Precisely, our classifier p : Ψ → [0, 1] 2 assigns a (B/F) probability vector to each pixel j ∈ Ψ in the extracted feature space.</p><p>For each test task, we find the parameters θ of the classifier by optimizing the following transductive objective:</p><formula xml:id="formula_0">min θ CE + λ H H + λ KL D KL ,<label>(1)</label></formula><p>where λ H , λ KL ∈ R are non-negative hyper-parameters balancing the effects of the different terms. We now describe in details each of the terms in Eq. <ref type="formula" target="#formula_0">(1)</ref>:</p><formula xml:id="formula_1">CE = − 1 K|Ψ| K k=1 j∈Ψ y k (j) log(p k (j))</formula><p>is the cross-entropy between the downsampled labels y k from support images and our classifier's soft predictions. Simply minimizing this term will often lead to degenerate solutions, especially in the 1-shot setting, as observed in <ref type="figure" target="#fig_0">Figure 1</ref>-the classifier θ typically overfits the support set S, translating into small activated regions on the query image.</p><formula xml:id="formula_2">H = − 1 |Ψ| j∈Ψ p Q (j) log (p Q (j))</formula><p>is the Shannon entropy of the predictions on the queryimage pixels. The role of this entropy term is to make the model's predictions more confident on the query image. The use of H originates from the semi-supervised literature <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b0">1]</ref>. Intuitively, it pushes the decision boundary drawn by the linear classifier towards low-density regions of the extracted query feature space. While this term plays a crucial role in conserving object regions that were initially predicted with only medium confidence, its sole addition to CE does not solve the problem of degenerate solutions, and may even worsen it in some cases.</p><formula xml:id="formula_3">D KL = p Q log p Q π , with p Q = 1 |Ψ| j∈Ψ p Q (j)</formula><p>, is a Kullback-Leibler (KL) Divergence term that encourages the B/F proportion predicted by the model to match a parameter π ∈ [0, 1] 2 . Notice that the division inside the log applies element-wise. The joint estimation of parameter π in our context is further discussed in a following paragraph. Here, we argue that this term plays a key role in our loss. First, in the case where parameter π does not match the exact B/F proportion of the query image, this term still helps avoiding the degenerate solutions stemming from CE and H minimization. Second, should an accurate estimate of the B/F proportion in the query image be available, it could easily be embedded through this term, resulting in a substantial performance boost, as discussed in Section 4.</p><p>Choice of the classifier As we optimize θ for each task at inference, we want our method to add as little computational load as possible. In this regard, we employ a simple linear classifier with learnable parameters θ (t) = {w (t) , b (t) }, with t the current step of the optimization procedure, w (t) ∈ R C the foreground prototype and b (t) ∈ R the corresponding bias. Thus, the probabilities p (t) k and p (t) Q at iteration t, for pixel j ∈ Ψ can be obtained as follow:</p><formula xml:id="formula_4">p (t) (j) := 1 − s (t) (j) s (t) (j) ,<label>(2)</label></formula><p>where</p><formula xml:id="formula_5">s (t) (j) = sigmoid τ cos z (j), w (t) − b (t) ,</formula><p>τ ∈ R is a temperature hyper-parameter and cos the cosine similarity. The same classifier is used to estimate the support set probabilities p k and the query predicted probabilities p Q . At initialization, we set prototype w (0) to be the average of the foreground support features, Q in order to learn π jointly with classifier parameters. Note that minimizing Eq. (1) with respect to π yields π (t) = p (t) Q . Empirically, we found that, after initialization, updating π only once during optimization, at a later iteration, t π was enough:</p><formula xml:id="formula_6">i.e. w (0) = 1 K|Ψ| K k=1 j∈Ψ y k (j) 1 z k (j), with y k (j) 1 the foreground component of the one-hot label of image x k at pixel j. Initial bias b (0) is</formula><formula xml:id="formula_7">π (t) =    p (0) Q 0 ≤ t ≤ t π p (tπ) Q t &gt; t π .<label>(3)</label></formula><p>Intuitively, the entropy term H helps gradually refine initially blurry soft predictions (third column in <ref type="figure" target="#fig_0">Fig. 1</ref>), which turns p (t) Q into an improving estimate of the true B/F proportion. A quantitative study of this phenomenon is provided in Section 4.3. Therefore, our inference can be seen as a joint optimization over θ and π, with D KL serving as a selfregularization that prevents the model's marginal distribution p (t) Q from diverging.</p><p>Oracle case with a known π As an upper bound, we also investigate the oracle case, where we have access to the true B/F proportion in x Q :</p><formula xml:id="formula_8">π * = 1 |Ψ| j∈Ψ y Q (j).<label>(4)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>Datasets We resort to two public few-shot segmentation benchmarks, PASCAL-5 i and COCO-20 i , to evaluate our method. PASCAL-5 i is built from PASCALVOC 2012 <ref type="bibr" target="#b7">[8]</ref>, and contains 20 object categories split into 4 folds. For each fold, 15 classes are used for training and the remaining 5 categories for testing. COCO-20 i is built from MS-COCO <ref type="bibr" target="#b17">[18]</ref> and is more challenging, as it contains more samples, more classes and more instances per image. Similar to PASCAL-5 i , COCO-20 i dataset is divided into 4folds with 60 base classes and 20 test classes in each fold.</p><p>Training We build our model based on PSPNet <ref type="bibr" target="#b42">[43]</ref> with Resnet-50 and Resnet-101 <ref type="bibr" target="#b12">[13]</ref> as backbones. We train the feature extractor with standard cross-entropy over the base classes during 100 epochs on PASCAL-5 i , and 20 epochs on COCO-20 i , with batch size set to 12. We use SGD as optimizer with the initial learning rate set to 2.5e−3 and we use cosine decay. Momentum is set to 0.9, and weight decay to 1e−4. Label smoothing is used with smoothing parameter = 0.1. We did not use multi-scaling, nor deep supervision, unlike the original PSPNet paper <ref type="bibr" target="#b42">[43]</ref>. As for data augmentations, we only use random mirror flipping.</p><p>Inference At inference, following previous works <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b36">37]</ref>, all images are resized to a fixed 417 × 417 resolution. For each task, the classifier θ is built on top of the features from the penultimate layer of the trained network. For our model with ResNet-50 as backbone, this results in a 53 × 53 × 512 feature map. SGD optimizer is used to train θ, with a learning rate of 0.025. For each task, a total of 50 iterations are performed. The parameter t π is set to 10. For the main method, the weights λ H and λ KL are both initially set to 1/K, such that the CE term plays a more important role as the number of shots K grows. For t ≥ t π , λ KL is increased by 1 to further encourage the predicted proportion close to π (tπ) . Finally, the temperature τ is set to 20.</p><p>Evaluation We employ the widely adopted mean Intersection over Union (mIoU). Specifically, for each class, the classwise-IoU is computed as the sum over all samples within the class of the intersection over the sum of all unions. Then, the mIoU is computed as the average over all classes of the classwise-IoU. Following previous works <ref type="bibr" target="#b20">[21]</ref>, 5 runs of 1000 tasks each are computed for each fold, and the average mIoU over runs is reported.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Benchmark results</head><p>Main method First, we investigate the performance of the proposed method in the popular 1-shot and 5-shot settings on both PASCAL-5 i and COCO-20 i , whose results are reported in <ref type="table" target="#tab_0">Table 1</ref> and 2. Overall, we found that our method compares competitively with state-of-the-art approaches in the 1-shot setting, and significantly outperforms recent methods in the 5-shot scenario. Additional qualitative results on PASCAL-5 i are shown in the supplemental material.</p><p>Beyond 5-shots In the popular learning-to-learn paradigm, the number of shots leveraged during the metatraining stage has a direct impact on the performance at inference <ref type="bibr" target="#b2">[3]</ref>. Particularly, to achieve the best performance, meta-learning based methods typically require the numbers of shots used during meta-training to match those employed during meta-testing. To demonstrate that the proposed method is more robust against differences on the number of labeled support samples between the base and test sets, we further investigate the 10-shot scenario. Particularly, we trained the methods in <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b37">38]</ref> by using one labeled sample per class, i.e., 1-shot task, and test the models on a 10-shots task. Interestingly, we show that the gap between our method and current state-of-the-art becomes larger as the number of support images increases <ref type="table" target="#tab_2">(Table  3)</ref>, with significant gains of 6% and 4% on PASCAL-5 i and COCO-20 i , respectively. These results suggest that our transductive inference leverages more effectively the information conveyed in the labeled support set of a given task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Oracle results</head><p>We now investigate the ideal scenario where an oracle provides the exact foreground/background proportion in the query image, such that π (t) = π * , ∀t. Reported results in this scenario, referred to as Oracle <ref type="table" target="#tab_0">(Table  1</ref> and 2) show impressive improvements over both our current method and all previous works, with a consistent gain across datasets and tasks. Particularly, these values range from 11% and 14 % on both PASCAL-5 i and COCO-20 i and in both 1-shot and 5-shot settings. We believe that these findings convey two important messages. First, it proves that there exists a simple linear classifier that can largely outperform state-of-the-art meta-learning models, while being built on top of a feature extractor trained with a standard cross-entropy loss. Second, these results indicate that having a precise size of the query object of interest acts as a strong regularizer. This suggests that more efforts could be directed towards properly constraining the optimization process of w and b, and opens a door to promising avenues.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Domain shift</head><p>We introduce a more realistic, cross-domain setting (COCO-20 i to PASCAL-VOC). We argue that such setting is a step towards a more realistic evaluation of these methods, as it can assess the impact on performances caused by a domain shift between the data training distribution and the testing one. We believe that this scenario can be easily found in practice, as even slight alterations in the data collection process might result in a distributional shift. We   reproduce the scenario where a large labeled dataset is available (e.g., COCO-20 i ), but the evaluation is performed on a target dataset with a different feature distribution (e.g., PASCAL-VOC). As per the original work <ref type="bibr" target="#b17">[18]</ref>, significant differences exist between the two original datasets. For instance, images in MS-COCO have on average 7.7 instances of objects coming from 3.5 distinct categories, while PASCAL-VOC only has an average of 3 instances from 2 distinct categories.</p><p>Evaluation We reuse models trained on each fold of COCO-20 i and generate tasks using images from all the classes in PASCAL-VOC that were not used during train- Results We reproduced and compared to the two best performing methods <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b20">21]</ref> using their respective official GitHub repositories. <ref type="table" target="#tab_3">Table 4</ref> summarizes the results for the 1-shot and 5-shot cross-domain experiments. We observe that in the presence of domain-shift, our method outperforms existing methods in both 1-shot and 5-shot scenarios, with again the improvement jumping from 2% in 1-shot to 4% in 5-shot.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Ablation studies</head><p>Impact of each term in the main objective While <ref type="figure" target="#fig_0">Fig. 1</ref> provides qualitative insights on how each term in Eq. (1) affects the final prediction, this section provides a quantitative evaluation of their impact, evaluated on PASCAL-5 i ( <ref type="table" target="#tab_4">Table 5</ref>). Quantitative results confirm the qualitative insights observed in <ref type="figure" target="#fig_0">Fig. 1</ref>, as both CE and CE + H losses drastically degrade the performance compared to the proportionregularized loss, i.e., CE + H + D KL . For example, in the 1-shot scenario, simply minimizing the CE results in more than 20% of difference compared to the proposed model. In this case, the prototype w tends to overfit the support sample and only activates regions of the query object that strongly correlate with the support object. Such behavior hampers the performance when the support and query objects exhibit slights changes in shape or histogram colors, for example, which may be very common in practice. Adding the entropy term H to CE partially alleviates this problem, as it tends to reinforce the model in being confident on positive pixels initially classified with mid or low confidence. Nevertheless, despite improving the naive CE based model, the gap with the proposed model remains considerably large, with 10% difference. One may notice that the differences between CE and CE + H + D KL decrease in the 5-shot setting, since overfitting 5 support samples si-multaneously becomes more difficult. The results from this ablation experiment reinforce our initial hypothesis that the proposed KL term based on the size parameter π acts as a strong regularizer.</p><p>Influence of the parameter t π <ref type="figure" target="#fig_2">In Fig. 2</ref>, we plot the averaged mIoU (over 4 folds) as a function of t π varying over the full range t π ∈ <ref type="bibr" target="#b0">[1,</ref><ref type="bibr">50]</ref>. For 5-shot, the performances are stable and remain largely above SOTA for all t π . As for the 1-shot case, the range <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b14">15]</ref> yields roughly similar results. While selection of optimal t π would lead to performance gains in each setting, in the paper, we used a single value of t π = 10 for all the settings. Influence of parameter π misestimation Precisely knowing the foreground/background (B/F) proportion of the query object is unrealistic. To quantify the deviation from the exact B/F proportion π * , we introduce the relative error on the foreground size:</p><formula xml:id="formula_9">δ (t) = π (t) 1 π * 1 − 1,<label>(5)</label></formula><p>where π * 1 represents the exact foreground proportion in the query image, extracted from its corresponding ground truth, and π (t)  (a) Relative error δ distribution of our current method, at initialization δ (0) and after 10 gradient iterations δ <ref type="bibr" target="#b9">(10)</ref> .   experiments where, instead of computing π (t) with Eq.</p><p>(3), we use a δ-perturbed oracle at initialization, such that π (t) 1 = π * 1 (1+δ). Each point in <ref type="figure" target="#fig_5">Fig. 3b</ref> represents the mIoU obtained over 5000 tasks for a given perturbation δ. <ref type="figure" target="#fig_5">Fig.  3b</ref> reveals that exact B/F proportion is not required to significantly close the gap with the oracle. Specifically, foreground size estimates ranging from -10% to +30% with respect to the oracle proportion are sufficient to achieve 70%+ of mIoU, which represents an improvement of 10% over the current state-of-the art. This suggests that more refined size estimation methods may significantly increase the performance of the proposed method.</p><p>Computational efficiency We now inspect the computational cost of the proposed model, and compare to recent existing methods. Unlike prior work, we solve an optimization problem at inference, which naturally slows down the inference process. However, in our case, only a single prototype vector w ∈ R C , where we recall C is the feature channel dimension, and a bias b ∈ R need to be optimized for each task. Furthermore, in our setting C = 512, and therefore the problem can still be solved relatively efficiently, leading to reasonable inference times. In <ref type="table" target="#tab_5">Table 6</ref>, we summarize the FPS rate at inference for our method, as well as for two competing approaches that only require a forward pass. We can observe that, unsurprisingly, our method reports lower FPS rates, without becoming unacceptably slower. The reported values indicate that the differences in inference times are small compared to, for example, the approach in <ref type="bibr" target="#b32">[33]</ref>. Particularly, in the 1-shot scenario, our method processes tasks 3 FPS slower than <ref type="bibr" target="#b32">[33]</ref>, whereas this gap narrows down to 0.7 FPS in the 5-shot setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>Without resorting to the popular meta-learning paradigm, our proposed RePRI achieves new state-of-theart results on standard 5-shot segmentation benchmarks, while being close to best performing approaches in the 1-shot setting. RePRI is modular and can, therefore, be used in conjunction with any feature extractor regardless how the base training was performed. Supported by the findings in this work, we believe that the relevance of the episodic training should be re-considered in the context of few-shot segmentation, and we provide a strong baseline to stimulate future research on this topic. Our results indicate that current state-of-the-art methods may have difficulty with more challenging settings, when dealing with domain shift or conducting inference on tasks whose structures are different from those seen in trainingscenarios that have been overlooked in the literature. These findings align with recent observations in few shot classification <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b2">3]</ref>. Furthermore, embedding more accurate foreground-background proportion estimates appears to be a very promising way of constraining the inference, as demonstrated with the significantly improved results obtained by the oracle. Our implementation is publicly available online: https://github.com/mboudiaf/ RePRI-for-Few-Shot-Segmentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Domain shift experiment</head><p>In <ref type="table" target="#tab_6">Table 7</ref>, we show the details of the cross-domain folds used for the domain-shift experiments. Also, in <ref type="table">Table 8</ref>, the per-fold results of the same experiment are available. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Qualitative results</head><p>In <ref type="figure">Figure 4</ref>, we provide some qualitative results on PASCAL-5 i that show how our method helps refining the initial predictions of the classifier. <ref type="figure">Figure 4</ref>: Qualitative results on PASCAL 5 i . Initial column refers to the predictions right after initializing the prototypes, while Final column refers to the prediction after running our inference. Best viewed in colors in high resolution.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Probability maps for several 1-shot tasks. For each task, the two first columns show the ground truth of support and query. Initial column represents the probability map with the initial classifier θ (0) , and the last three columns show the final soft predicted segmentation after finetuning with each of the three losses. Best viewed in colors.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>set as the mean of the foreground's soft predictions on the query image: b (0) = 1 |Ψ| j∈Ψ p Q (j) 1 . Then, w (t) and b (t) are optimized with gradient descent. The computational footprint of this pertask optimization is discussed in Section 4. Joint estimation of B/F proportion π Without additional information, we leverage the model's label-marginal distribution over the query image p (t)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Average mIoU (over 4 folds) as a function of t π on PASCAL-5 i (left) and COCO-20 i (right) .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Mean-IoU versus enforced relative foreground size error δ in the parameter π (0) .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 3 :</head><label>3</label><figDesc>Experiments on π misestimation. Both figures are computed using 5 runs of 1000 1-shot tasks, each on the fold-0 of PASCAL5 i .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Results of 1-way 1-shot and 1-way 5-shot segmentation on PASCAL-5 i using the mean-IoU. Best results in bold.</figDesc><table><row><cell>1 shot</cell><cell>5 shot</cell></row></table><note>* We report the results where no additional unlabeled data is employed.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Results of 1-way 1-shot and 1-way 5-shot segmentation on COCO-20 i using mean-IoU metric. Best results in bold.</figDesc><table><row><cell>1 shot</cell><cell>5 shot</cell></row></table><note>* We report the results where no additional unlabeled data is employed.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Aggregated results for 1-way 1-, 5-and 10-shot tasks with Resnet50 as backbone and averaged over 4 folds. Per fold results are available in the supplementary material.</figDesc><table><row><cell></cell><cell cols="3">PASCAL-5 i</cell><cell></cell><cell cols="2">COCO-20 i</cell></row><row><cell>Method</cell><cell>1-S</cell><cell>5-S</cell><cell>10-S</cell><cell>1-S</cell><cell>5-S</cell><cell>10-S</cell></row><row><cell>RPMM [38]</cell><cell cols="6">56.3 57.3 57.6 30.6 35.5 33.1</cell></row><row><cell>PFENet [33]</cell><cell cols="6">60.8 61.9 62.1 35.8 39.0 39.7</cell></row><row><cell>RePRI (ours)</cell><cell cols="6">59.1 66.8 68.2 34.0 42.1 44.4</cell></row><row><cell cols="7">Oracle-RePRI 73.3 77.9 78.6 45.1 55.5 58.7</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Aggregated domain-shift results, averaged over 4 folds, on COCO-20 i to PASCAL-VOC. Best results in bold. Per-fold results are available in the supplementary material.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">COCO → PASCAL</cell></row><row><cell>Method</cell><cell cols="2">Backbone 1 shot</cell><cell>5 shot</cell></row><row><cell>RPMM [38]</cell><cell></cell><cell>49.6</cell><cell>53.8</cell></row><row><cell>PFENet [33]</cell><cell>ResNet50</cell><cell>61.1</cell><cell>63.4</cell></row><row><cell>RePRI (ours)</cell><cell></cell><cell>63.2</cell><cell>67.7</cell></row><row><cell cols="2">Oracle-RePRI Resnet-50</cell><cell>76.2</cell><cell>79.7</cell></row><row><cell cols="4">ing. For instance, fold-0 of this setting means the model</cell></row><row><cell cols="4">was trained on fold-0 of COCO-20 i and tested on the whole</cell></row><row><cell cols="4">PASCAL-VOC dataset, after removing the classes seen in</cell></row><row><cell cols="4">training. A complete summary of all the folds is available</cell></row><row><cell cols="2">in the Supplemental material.</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>Ablation study on the effect of each term in our loss in Eq. (1), evaluated on PASCAL-5 i .</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>1 shot</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>5 shot</cell><cell></cell></row><row><cell>Loss</cell><cell></cell><cell cols="10">Fold-0 Fold-1 Fold-2 Fold-3 Mean Fold-0 Fold-1 Fold-2 Fold-3 Mean</cell></row><row><cell>CE</cell><cell></cell><cell>39.7</cell><cell>49.3</cell><cell>37.3</cell><cell>27.5</cell><cell>38.5</cell><cell>56.5</cell><cell>66.4</cell><cell>60.1</cell><cell>49.0</cell><cell>58.0</cell></row><row><cell>CE + H</cell><cell></cell><cell>45.7</cell><cell>61.7</cell><cell>48.2</cell><cell>36.4</cell><cell>48.0</cell><cell>56.8</cell><cell>68.5</cell><cell>61.3</cell><cell>47.0</cell><cell>58.4</cell></row><row><cell cols="2">CE + H + DKL</cell><cell>60.2</cell><cell>67.0</cell><cell>61.7</cell><cell>47.5</cell><cell>59.1</cell><cell>64.5</cell><cell>70.8</cell><cell>71.7</cell><cell>60.3</cell><cell>66.8</cell></row><row><cell>(0)</cell><cell>(10)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 :</head><label>6</label><figDesc>Number of tasks performed per second, and the corresponding mIoU performances on PASCAL-5 i .</figDesc><table><row><cell></cell><cell cols="2">1-shot</cell><cell cols="2">5-shot</cell></row><row><cell>Method</cell><cell cols="4">FPS mIoU FPS mIoU</cell></row><row><cell cols="2">RPMMS [38] 18.2</cell><cell>51.5</cell><cell>9.4</cell><cell>57.3</cell></row><row><cell>PFENet [33]</cell><cell>15.9</cell><cell>60.8</cell><cell>5.1</cell><cell>61.9</cell></row><row><cell>RePRI (ours)</cell><cell>12.8</cell><cell>59.1</cell><cell>4.4</cell><cell>66.8</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 7 :</head><label>7</label><figDesc>Cross-domain folds.</figDesc><table><row><cell></cell><cell>Dataset</cell><cell>Fold 0</cell><cell>Fold 1</cell><cell>Fold 2</cell><cell>Fold 3</cell></row><row><cell>Excluded</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>from</cell><cell>MS-COCO</cell><cell></cell><cell></cell><cell></cell></row><row><cell>training</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">our estimate at iteration t, which is derived from the soft predicted segmentation. As observed fromFig. 1, the initial prototype often results in a blurred probability map, from which only a very coarse estimate of the query proportion can be inferred and used as π (0) . The distribution of δ over 5000 tasks is presented inFig. 3a. It clearly shows that the initial prediction typically provides an overestimate of the actual query foreground size, while finetuning the classifier θ for 10 iterations with our main loss (Eq. 1) already provides a strictly more accurate estimate, as conveyed by the right box plot inFig. 3a, with an average δ around 0.7. Now, a natural question remains: how good does the estimate need to be in order to approach the oracle results? To answer this, we carry out a series of controlled</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Mixmatch: A holistic approach to semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avital</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><forename type="middle">A</forename><surname>Raffel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Transductive information maximization for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Malik</forename><surname>Boudiaf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jérôme</forename><surname>Ziko Imtiaz Masud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">José</forename><surname>Rony</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pablo</forename><surname>Dolz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ismail</forename><surname>Piantanida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ben Ayed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A theoretical analysis of the number of shots in few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianshi</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Law</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanja</forename><surname>Fidler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A closer look at few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Yu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yen-Cheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zsolt</forename><surname>Kira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Chiang Frank</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia-Bin</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Learning with local and global consistency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhou</forename><surname>Dengyong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Bousquet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Lal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A baseline for fewshot image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guneet</forename><surname>Singh Dhillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pratik</forename><surname>Chaudhari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avinash</forename><surname>Ravichandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Soatto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Few-shot semantic segmentation with prototype learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nanqing</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">British Machine Vision Conference (BMVC)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">The pascal visual object classes (voc) challenge. International journal of computer vision (IJCV)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Everingham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">I</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zisserman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Model-agnostic meta-learning for fast adaptation of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">SimPropNet: Improved similarity propagation for few-shot image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddhartha</forename><surname>Gairola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mayur</forename><surname>Hemani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ayush</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balaji</forename><surname>Krishnamurthy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Artificial Intelligence (IJCAI)</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Semisupervised learning by entropy minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yves</forename><surname>Grandvalet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A broader study of cross-domain few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunhui</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noel</forename><surname>Codella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonid</forename><surname>Karlinsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">V</forename><surname>Codella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">R</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tajana</forename><surname>Rosing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rogerio</forename><surname>Feris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition (CVPR)</title>
		<meeting>the IEEE conference on computer vision and pattern recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Cross attention network for few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruibing</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Bingpeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiguang</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xilin</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Transductive inference for text classification using support vector machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Edge-labeling graph neural network for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jongmin</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taesup</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungwoong</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang D</forename><surname>Yoo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">FSS-1000: A 1000-class dataset for few-shot segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianhan</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Wing</forename><surname>Yau Pun Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi-Keung</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Microsoft coco: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision (ECCV)</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">CRNet: Cross-reference networks for few-shot segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weide</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guosheng</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fayao</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Learning to propagate labels: Transductive propagation network for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanbin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juho</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minseop</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saehoon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunho</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sung</forename><forename type="middle">Ju</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Songyang Zhang, and Xuming He. Part-aware prototype network for fewshot semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongfei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyi</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Virtual adversarial training: a regularization method for supervised and semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeru</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masanori</forename><surname>Shin-Ichi Maeda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shin</forename><surname>Koyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ishii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Feature weighting and boosting for few-shot segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khoi</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sinisa</forename><surname>Todorovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Transductive episodicwise adaptive metric for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Limeng</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yemin</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaowei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiejun</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonghong</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Conditional networks for few-shot semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Rakelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alyosha</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR) Workshop</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Optimization as a model for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sachin</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Meta-learning for semi-supervised few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengye</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eleni</forename><surname>Triantafillou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sachin</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jake</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Evolutionary principles in selfreferential learning, or on learning how to learn: the meta-meta</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987" />
		</imprint>
		<respStmt>
			<orgName>Technische Universität München</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Irfan Essa, and Byron Boots. One-shot learning for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amirreza</forename><surname>Shaban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shray</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">British Machine Vision Conference (BMVC)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">AMP: Adaptive masked proxies for fewshot segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mennatullah</forename><surname>Siam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Boris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Oreshkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jagersand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Prototypical networks for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jake</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Rethinking few-shot image classification: a good embedding is all you need?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonglong</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilip</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.11539</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Prior guided feature enrichment network for few-shot segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuotao</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michelle</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhicheng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruiyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">An overview of statistical learning theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Vladimir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Neural Networks (TNN)</title>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Matching networks for one shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Few-shot semantic segmentation with democratic attention networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haochen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xudong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutao</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yandan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianbin</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiantong</forename><surname>Zhen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV, 2020. 1</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">PANet: Few-shot image semantic segmentation with prototype alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaixin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Hao Liew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingtian</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daquan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ternational Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Prototype mixture models for few-shot semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boyu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bohao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianbin</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qixiang</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A new local transformation module for few-shot segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuwei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fanman</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongliang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingbo</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuai</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Multimedia Modeling (ICMM)</title>
		<imprint>
			<publisher>Springer</publisher>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Pyramid graph networks with connection attentions for region-based one-shot semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guosheng</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fayao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiushuang</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingyao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">CANet: Class-agnostic segmentation networks with iterative refinement and attentive fewshot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guosheng</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fayao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">SG-one: Similarity guidance network for oneshot semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunchao</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Cybernetics</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Pyramid scene parsing network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojuan</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
		<idno>2017. 5</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Eric Granger, and Ismail Ben Ayed. Laplacian regularized few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jose</forename><surname>Imtiaz Masud Ziko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dolz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Method Backbone Fold-0 Fold-1 Fold-2 Fold-3 Mean Fold-0 Fold-1 Fold-2 Fold-3 Mean</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Per-fold 10-shots results on PASCAL-5 i and COCO-20 i . Best results in bold. PASCAL-5 i COCO-20 i Method Backbone Fold-0 Fold-1 Fold-2 Fold-3 Mean Fold-0</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Table</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
		</imprint>
	</monogr>
	<note>Results of the 10-shot experiments In Table 9, we give the per-fold results of the 10-shot experiments. Fold-1 Fold-2 Fold-3 Mean</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
