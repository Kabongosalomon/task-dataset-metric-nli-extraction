<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">COMPOSITION-BASED MULTI-RELATIONAL GRAPH CONVOLUTIONAL NETWORKS</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shikhar</forename><surname>Vashishth</surname></persName>
							<email>svashish@cs.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Indian Institute of Science</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumya</forename><surname>Sanyal</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Indian Institute of Science</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vikram</forename><surname>Nitin</surname></persName>
							<email>vikram.nitin@columbia.edu</email>
							<affiliation key="aff2">
								<orgName type="institution">Columbia University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Partha</forename><surname>Talukdar</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Indian Institute of Science</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">COMPOSITION-BASED MULTI-RELATIONAL GRAPH CONVOLUTIONAL NETWORKS</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>Published as a conference paper at ICLR 2020</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T17:22+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Graph Convolutional Networks (GCNs) have recently been shown to be quite successful in modeling graph-structured data. However, the primary focus has been on handling simple undirected graphs. Multi-relational graphs are a more general and prevalent form of graphs where each edge has a label and direction associated with it. Most of the existing approaches to handle such graphs suffer from over-parameterization and are restricted to learning representations of nodes only. In this paper, we propose COMPGCN, a novel Graph Convolutional framework which jointly embeds both nodes and relations in a relational graph. COMPGCN leverages a variety of entity-relation composition operations from Knowledge Graph Embedding techniques and scales with the number of relations. It also generalizes several of the existing multi-relational GCN methods. We evaluate our proposed method on multiple tasks such as node classification, link prediction, and graph classification, and achieve demonstrably superior results. We make the source code of COMPGCN available to foster reproducible research.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Graphs are one of the most expressive data-structures which have been used to model a variety of problems. Traditional neural network architectures like Convolutional Neural Networks <ref type="bibr" target="#b19">(Krizhevsky et al., 2012)</ref> and Recurrent Neural Networks <ref type="bibr" target="#b15">(Hochreiter &amp; Schmidhuber, 1997)</ref> are constrained to handle only Euclidean data. Recently, Graph Convolutional Networks (GCNs) <ref type="bibr" target="#b4">(Bruna et al., 2013;</ref><ref type="bibr" target="#b8">Defferrard et al., 2016)</ref> have been proposed to address this shortcoming, and have been successfully applied to several domains such as social networks <ref type="bibr" target="#b14">(Hamilton et al., 2017)</ref>, knowledge graphs <ref type="bibr" target="#b32">(Schlichtkrull et al., 2017)</ref>, natural language processing <ref type="bibr" target="#b20">(Marcheggiani &amp; Titov, 2017)</ref>, drug discovery <ref type="bibr" target="#b28">(Ramsundar et al., 2019)</ref>, crystal property prediction <ref type="bibr" target="#b31">(Sanyal et al., 2018)</ref>, and natural sciences <ref type="bibr" target="#b11">(Fout et al., 2017)</ref>.</p><p>However, most of the existing research on GCNs <ref type="bibr" target="#b18">(Kipf &amp; Welling, 2016;</ref><ref type="bibr" target="#b14">Hamilton et al., 2017;</ref><ref type="bibr" target="#b40">Veličković et al., 2018)</ref> have focused on learning representations of nodes in simple undirected graphs. A more general and pervasive class of graphs are multi-relational graphs 1 . A notable example of such graphs is knowledge graphs. Most of the existing GCN based approaches for handling relational graphs <ref type="bibr" target="#b20">(Marcheggiani &amp; Titov, 2017;</ref><ref type="bibr" target="#b32">Schlichtkrull et al., 2017)</ref> suffer from overparameterization and are limited to learning only node representations. Hence, such methods are not directly applicable for tasks such as link prediction which require relation embedding vectors. Initial attempts at learning representations for relations in graphs <ref type="bibr" target="#b22">(Monti et al., 2018;</ref><ref type="bibr" target="#b1">Beck et al., 2018)</ref> have shown some performance gains on tasks like node classification and neural machine translation.</p><p>There has been extensive research on embedding Knowledge Graphs (KG) <ref type="bibr" target="#b41">Wang et al., 2017)</ref> where representations of both nodes and relations are jointly learned. These methods are restricted to learning embeddings using link prediction objective. Even though GCNs can tions due to over-parameterization. <ref type="bibr" target="#b32">Schlichtkrull et al. (2017)</ref> address this shortcoming by proposing basis and block-diagonal decomposition of relation specific filters. Weighted Graph Convolutional Network <ref type="bibr" target="#b33">(Shang et al., 2019)</ref> utilizes learnable relational specific scalar weights during GCN aggregation. While these methods show performance gains on node classification and link prediction, they are limited to embedding only the nodes of the graph. Contemporary to our work, <ref type="bibr">Ye et al. (2019)</ref> have also proposed an extension of GCNs for embedding both nodes and relations in multirelational graphs. However, our proposed method is a more generic framework which can leverage any KG composition operator. We compare against their method in Section 6.1.</p><p>Knowledge Graph Embedding: Knowledge graph (KG) embedding is a widely studied field <ref type="bibr" target="#b41">Wang et al., 2017)</ref> with application in tasks like link prediction and question answering <ref type="bibr" target="#b3">(Bordes et al., 2014)</ref>. Most of KG embedding approaches define a score function and train node and relation embeddings such that valid triples are assigned a higher score than the invalid ones. Based on the type of score function, KG embedding method are classified as translational <ref type="bibr">(Bordes et al., 2013;</ref><ref type="bibr" target="#b43">Wang et al., 2014b)</ref>, semantic matching based <ref type="bibr" target="#b46">(Yang et al., 2014;</ref> and neural network based <ref type="bibr" target="#b35">(Socher et al., 2013;</ref><ref type="bibr" target="#b9">Dettmers et al., 2018)</ref>. In our work, we evaluate the performance of COMPGCN on link prediction with methods of all three types.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">BACKGROUND</head><p>In this section, we give a brief overview of Graph Convolutional Networks (GCNs) for undirected graphs and its extension to directed relational graphs.</p><p>GCN on Undirected Graphs: Given a graph G = (V, E, X ), where V denotes the set of vertices, E is the set of edges, and X ∈ R |V|×d0 represents d 0 -dimensional input features of each node. The node representation obtained from a single GCN layer is defined as:</p><formula xml:id="formula_0">H = f (ÂX W ). Here, A = D − 1 2 (A + I) D − 1 2</formula><p>is the normalized adjacency matrix with added self-connections and D is defined as D ii = j (A + I) ij . The model parameter is denoted by W ∈ R d0×d1 and f is some activation function. The GCN representation H encodes the immediate neighborhood of each node in the graph. For capturing multi-hop dependencies in the graph, several GCN layers can be stacked, one on the top of another as follows: H k+1 = f (ÂH k W k ), where k denotes the number of layers, W k ∈ R d k ×d k+1 is layer-specific parameter and H 0 = X .</p><p>GCN on Multi-Relational Graphs: For a multi-relational graph G = (V, R, E, X ), where R denotes the set of relations, and each edge <ref type="bibr">(u, v, r)</ref> represents that the relation r ∈ R exist from node u to v. The GCN formulation as devised by <ref type="bibr" target="#b20">Marcheggiani &amp; Titov (2017)</ref> is based on the assumption that information in a directed edge flows along both directions. Hence, for each edge (u, v, r) ∈ E, an inverse edge (v, u, r −1 ) is included in G. The representations obtained after k layers of directed GCN is given by</p><formula xml:id="formula_1">H k+1 = f (ÂH k W k r ).<label>(1)</label></formula><p>Here, W k r denotes the relation specific parameters of the model. However, the above formulation leads to over-parameterization with an increase in the number of relations and hence, <ref type="bibr" target="#b20">Marcheggiani &amp; Titov (2017)</ref> use direction-specific weight matrices. <ref type="bibr" target="#b32">Schlichtkrull et al. (2017)</ref> address overparameterization by proposing basis and block-diagonal decomposition of W k r .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">COMPGCN DETAILS</head><p>In this section, we provide a detailed description of our proposed method, COMPGCN. The overall architecture is shown in <ref type="figure">Figure 1</ref>. We represent a multi-relational graph by G = (V, R, E, X , Z) as defined in Section 3 where Z ∈ R |R|×d0 denotes the initial relation features. Our model is motivated by the first-order approximation of GCNs using Chebyshev polynomials <ref type="bibr" target="#b18">(Kipf &amp; Welling, 2016)</ref>. Following <ref type="bibr" target="#b20">Marcheggiani &amp; Titov (2017)</ref>, we also allow the information in a directed edge to flow along both directions. Hence, we extend E and R with corresponding inverse edges and relations, i.e.,  <ref type="bibr">GCN Marcheggiani &amp; Titov (2017)</ref> O(Kd 2 ) Weighted- <ref type="bibr">GCN Shang et al. (2019)</ref> O(Kd 2 + K|R|) Relational- <ref type="bibr">GCN Schlichtkrull et al. (2017)</ref> O(BKd 2 + BK|R|)  <ref type="bibr">(Bordes et al., 2013;</ref>, which are of the form</p><formula xml:id="formula_2">E = E ∪ {(v, u, r −1 ) | (u, v, r) ∈ E} ∪ {(u, u, ) | u ∈ V)}, and R = R ∪ R inv ∪ { }, where R inv = {r −1 | r ∈ R}</formula><formula xml:id="formula_3">COMPGCN (Proposed Method) O(Kd 2 + Bd + B|R|)</formula><formula xml:id="formula_4">e o = φ(e s , e r ).</formula><p>Here, φ : R d × R d → R d is a composition operator, s, r, and o denote subject, relation and object in the knowledge graph and e (·) ∈ R d denotes their corresponding embeddings. In this paper, we restrict ourselves to non-parameterized operations like subtraction <ref type="bibr">(Bordes et al., 2013)</ref>, multiplication <ref type="bibr" target="#b46">(Yang et al., 2014)</ref> and circular-correlation . However, COMPGCN can be extended to parameterized operations like Neural Tensor Networks (NTN) <ref type="bibr" target="#b35">(Socher et al., 2013)</ref> and ConvE <ref type="bibr" target="#b9">(Dettmers et al., 2018)</ref>. We defer their analysis as future work.</p><p>As we show in Section 6, the choice of composition operation is important in deciding the quality of the learned embeddings. Hence, superior composition operations for Knowledge Graphs developed in future can be adopted to improve COMPGCN's performance further.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">COMPGCN UPDATE EQUATION</head><p>The GCN update equation (Eq. 1) defined in Section 3 can be re-written as</p><formula xml:id="formula_5">h v = f (u,r)∈N (v) W r h u ,</formula><p>where N (v) is a set of immediate neighbors of v for its outgoing edges. Since this formulation suffers from over-parameterization, in COMPGCN we perform composition (φ) of a neighboring node u with respect to its relation r as defined above. This allows our model to be relation aware while being linear (O(|R|d)) in the number of feature dimensions. Moreover, for treating original, inverse, and self edges differently, we define separate filters for each of them. The update equation of COMPGCN is given as:</p><formula xml:id="formula_6">h v = f (u,r)∈N (v) W λ(r) φ(x u , z r ) ,<label>(2)</label></formula><p>where x u , z r denotes initial features for node u and relation r respectively, h v denotes the updated representation of node v, and W λ(r) ∈ R d1×d0 is a relation-type specific parameter. In COMPGCN, we use direction specific weights, i.e., λ(r) = dir(r), given as: Further, in COMPGCN, after the node embedding update defined in Eq. 2, the relation embeddings are also transformed as follows:</p><formula xml:id="formula_7">W dir(r) =    W O , r ∈ R W I , r ∈ R inv W S , r = (self-loop) (3) Methods W k λ(r) φ(h k u , h k r ) Kipf-GCN (Kipf &amp; Welling, 2016) W k h k u Relational-GCN (Schlichtkrull et al., 2017) W k r h k u Directed-GCN (Marcheggiani &amp; Titov, 2017) W k dir(r) h k u Weighted-GCN (Shang et al., 2019) W k α k r h k u</formula><formula xml:id="formula_8">h r = W rel z r ,<label>(4)</label></formula><p>where W rel ∈ R d1×d0 is a learnable transformation matrix which projects all the relations to the same embedding space as nodes and allows them to be utilized in the next COMPGCN layer. In <ref type="table" target="#tab_1">Table 1</ref>, we present a contrast between COMPGCN and other existing methods in terms of their features and parameter complexity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Scaling with Increasing Number of Relations</head><p>To ensure that COMPGCN scales with the increasing number of relations, we use a variant of the basis formulations proposed in <ref type="bibr" target="#b32">Schlichtkrull et al. (2017)</ref>. Instead of independently defining an embedding for each relation, they are expressed as a linear combination of a set of basis vectors. Formally, let {v 1 , v 2 , ..., v B } be a set of learnable basis vectors. Then, initial relation representation is given as:</p><formula xml:id="formula_9">z r = B b=1 α br v b .</formula><p>Here, α br ∈ R is relation and basis specific learnable scalar weight.</p><p>On Comparison with Relational-GCN Note that this is different from the basis formulation in <ref type="bibr" target="#b32">Schlichtkrull et al. (2017)</ref>, where a separate set of basis matrices is defined for each GCN layer. In contrast, COMPGCN uses embedding vectors instead of matrices, and defines basis vectors only for the first layer. The later layers share the relations through transformations according to Equation <ref type="formula" target="#formula_8">4</ref>. This makes our model more parameter efficient than Relational-GCN.</p><p>We can extend the formulation of Equation 2 to the case where we have k-stacked COMPGCN layers. Let h k+1 v denote the representation of a node v obtained after k layers which is defined as</p><formula xml:id="formula_10">h k+1 v = f (u,r)∈N (v) W k λ(r) φ(h k u , h k r ) .<label>(5)</label></formula><p>Similarly, let h k+1 r denote the representation of a relation r after k layers. Then,</p><formula xml:id="formula_11">h k+1 r = W k rel h k r .</formula><p>Here, h 0 v and h 0 r are the initial node (x v ) and relation (z r ) features respectively.  <ref type="bibr" target="#b32">(Schlichtkrull et al., 2017)</ref> .248 -.417 .151 ----KBGAN <ref type="bibr" target="#b5">(Cai &amp; Wang, 2018)</ref> .278 -.458 -.214 -.472 --ConvE <ref type="bibr" target="#b9">(Dettmers et al., 2018)</ref> . <ref type="formula" target="#formula_6">325</ref>   datasets. The results of all the baseline methods are taken directly from the previous papers ('-' indicates missing values). We find that COMPGCN outperforms all the existing methods on 4 out of 5 metrics on FB15k-237 and 3 out of 5 metrics on WN18RR. Please refer to Section 6.1 for more details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTAL SETUP</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">EVALUATION TASKS</head><p>In our experiments, we evaluate COMPGCN on the below-mentioned tasks.</p><p>• Link Prediction is the task of inferring missing facts based on the known facts in Knowledge Graphs. In our experiments, we utilize FB15k-237 <ref type="bibr" target="#b38">(Toutanova &amp; Chen, 2015)</ref> and WN18RR <ref type="bibr" target="#b9">(Dettmers et al., 2018)</ref> datasets for evaluation. Following <ref type="bibr">Bordes et al. (2013)</ref>, we use filtered setting for evaluation and report Mean Reciprocal Rank (MRR), Mean Rank (MR) and Hits@N. • Node Classification is the task of predicting the labels of nodes in a graph based on node features and their connections. Similar to <ref type="bibr" target="#b32">Schlichtkrull et al. (2017)</ref>, we evaluate COMPGCN on MUTAG (Node) and AM  datasets. • Graph Classification, where, given a set of graphs and their corresponding labels, the goal is to learn a representation for each graph which is fed to a classifier for prediction. We evaluate on 2 bioinformatics dataset: MUTAG (Graph) and PTC <ref type="bibr" target="#b45">(Yanardag &amp; Vishwanathan, 2015)</ref>.</p><p>A summary statistics of the datasets used is provided in Appendix A.2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">BASELINES</head><p>Across all tasks, we compare against the following GCN methods for relational graphs: (1) Relational-GCN (R-GCN) <ref type="bibr" target="#b32">(Schlichtkrull et al., 2017)</ref> which uses relation-specific weight matrices that are defined as a linear combinations of a set of basis matrices.</p><p>(2) Directed-GCN (D-GCN) <ref type="bibr" target="#b20">(Marcheggiani &amp; Titov, 2017)</ref> has separate weight matrices for incoming edges, outgoing edges, and self-loops. It also has relation-specific biases.</p><p>(3) Weighted-GCN (W-GCN) <ref type="bibr" target="#b33">(Shang et al., 2019)</ref> assigns a learnable scalar weight to each relation and multiplies an incoming "message" by this weight. Apart from this, we also compare with several task-specific baselines mentioned below. Node and Graph Classification: For node classification, following <ref type="bibr" target="#b32">Schlichtkrull et al. (2017)</ref>, we compare with Feat <ref type="bibr" target="#b27">(Paulheim &amp; Fümkranz, 2012)</ref>, WL <ref type="bibr" target="#b34">(Shervashidze et al., 2011)</ref>, and RDF2Vec . Finally, for graph classification, we evaluate against PACHYSAN <ref type="bibr" target="#b26">(Niepert et al., 2016)</ref>, Deep Graph CNN (DGCNN) <ref type="bibr" target="#b48">(Zhang et al., 2018)</ref>, and Graph Isomorphism Network (GIN) <ref type="bibr" target="#b44">(Xu et al., 2019)</ref>.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">RESULTS</head><p>In this section, we attempt to answer the following questions.</p><p>Q1. How does COMPGCN perform on link prediction compared to existing methods? (6.1) Q2. What is the effect of using different GCN encoders and choice of the compositional operator in COMPGCN on link prediction performance? (6.1) Q3. Does COMPGCN scale with the number of relations in the graph? (6.3) Q4. How does COMPGCN perform on node and graph classification tasks? (6.4)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">PERFORMANCE COMPARISON ON LINK PREDICTION</head><p>In this section, we evaluate the performance of COMPGCN and the baseline methods listed in Section 5.2 on link prediction task. The results on FB15k-237 and WN18RR datasets are presented in <ref type="table" target="#tab_5">Table 3</ref>. The scores of baseline methods are taken directly from the previous papers <ref type="bibr" target="#b37">(Sun et al., 2019;</ref><ref type="bibr" target="#b5">Cai &amp; Wang, 2018;</ref><ref type="bibr" target="#b33">Shang et al., 2019;</ref><ref type="bibr" target="#b0">Balažević et al., 2019;</ref><ref type="bibr" target="#b16">Jiang et al., 2019;</ref><ref type="bibr">Ye et al., 2019)</ref>. However, for ConvKB, we generate the results using the corrected evaluation code 2 . Overall, we find that COMPGCN outperforms all the existing methods in 4 out of 5 metrics on FB15k-237 and in 3 out of 5 metrics on WN18RR dataset. We note that the best performing baseline RotatE uses rotation operation in complex domain. The same operation can be utilized in a complex variant of our proposed method to improve its performance further. We defer this as future work.  <ref type="figure">Figure 5</ref>: Performance of COMPGCN with different number of relations on link prediction task. We report the relative change in MRR on pruned versions of FB15k-237 dataset. Overall, COMPGCN gives comparable performance even with limited parameters. Refer to Section 6.2 for details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Number of Relations</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">COMPARISON OF DIFFERENT GCN ENCODERS ON LINK PREDICTION PERFORMANCE</head><p>Next, we evaluate the effect of using different GCN methods as an encoder along with a representative score function (shown in <ref type="figure">Figure 2</ref>) from each category: TransE (translational), DistMult (semantic-based), and ConvE (neural network-based). In our results, X + M (Y) denotes that method M is used for obtaining entity embeddings (and relation embeddings in the case of COMPGCN) with X as the score function as depicted in <ref type="figure">Figure 2</ref>. Y denotes the composition operator in the case of COMPGCN. We evaluate COMPGCN on three non-parametric composition operators inspired from TransE <ref type="bibr">(Bordes et al., 2013)</ref>, DistMult <ref type="bibr" target="#b46">(Yang et al., 2014)</ref>, and HolE   The overall results are summarized in <ref type="table" target="#tab_7">Table 4</ref>. Similar to <ref type="bibr" target="#b32">Schlichtkrull et al. (2017)</ref>, we find that utilizing Graph Convolutional based method as encoder gives a substantial improvement in performance for most types of score functions. We observe that although all the baseline GCN methods lead to some degradation with TransE score function, no such behavior is observed for COMPGCN. On average, COMPGCN obtains around 6%, 4% and 3% relative increase in MRR with TransE, DistMult, and ConvE objective respectively compared to the best performing baseline. The superior performance of COMPGCN can be attributed to the fact that it learns both entity and relation embeddings jointly thus providing more expressive power in learned representations. Overall, we find that COMPGCN with ConvE (highlighted using · ) is the best performing method for link prediction. 3</p><p>Effect of composition Operator: The results on link prediction with different composition operators are presented in <ref type="table" target="#tab_7">Table 4</ref>. We find that with DistMult score function, multiplication operator (Mult) gives the best performance while with ConvE, circular-correlation surpasses all other operators. Overall, we observe that more complex operators like circular-correlation outperform or perform comparably to simpler operators such as subtraction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">SCALABILITY OF COMPGCN</head><p>In this section, we analyze the scalability of COMPGCN with varying numbers of relations and basis vectors. For analysis with changing number of relations, we create multiple subsets of FB15k-237 dataset by retaining triples corresponding to top-m most frequent relations, where m = {10, 25, 50, 100, 237}. For all the experiments, we use our best performing model (ConvE + COMPGCN (Corr)).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Effect of Varying Relation Basis</head><p>Vectors: Here, we analyze the performance of COMPGCN on changing the number of relation basis vectors (B) as defined in Section 4. The results are summarized in <ref type="figure">Figure 3</ref>. We find that our model performance improves with the increasing number of basis  vectors. We note that with B = 100, the performance of the model becomes comparable to the case where all relations have their individual embeddings. In <ref type="table" target="#tab_7">Table 4</ref>, we report the results for the best performing model across all score function with B set to 50. We note that the parameter-efficient variant also gives a comparable performance and outperforms the baselines in all settings.</p><p>Effect of Number of Relations: Next, we report the relative performance of COMPGCN using 5 relation basis vectors (B = 5) against COMPGCN, which utilizes a separate vector for each relation in the dataset. The results are presented in <ref type="figure">Figure 5</ref>. Overall, we find that across all different numbers of relations, COMPGCN, with a limited basis, gives comparable performance to the full model. The results show that a parameter-efficient variant of COMPGCN scales with the increasing number of relations.</p><p>Comparison with R-GCN: Here, we perform a comparison of a parameter-efficient variant of COMPGCN (B = 5) against R-GCN on different number of relations. The results are depicted in <ref type="figure" target="#fig_2">Figure 4</ref>. We observe that COMPGCN with limited parameters consistently outperforms R-GCN across all settings. Thus, COMPGCN is parameter-efficient and more effective at encoding multirelational graphs than R-GCN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">EVALUATION ON NODE AND GRAPH CLASSIFICATION</head><p>In this section, we evaluate COMPGCN on node and graph classification tasks on datasets as described in Section 5.1. The experimental results are presented in <ref type="table" target="#tab_9">Table 5</ref>. For node classification task, we report accuracy on test split provided by , whereas for graph classification, following <ref type="bibr" target="#b45">Yanardag &amp; Vishwanathan (2015)</ref> and <ref type="bibr" target="#b44">Xu et al. (2019)</ref>, we report the average and standard deviation of validation accuracies across the 10 folds cross-validation. Overall, we find that COMPGCN outperforms all the baseline methods on node classification and gives a comparable performance on graph classification task. This demonstrates the effectiveness of incorporating relations using COMPGCN over the existing GCN based models. On node classification, compared to the best performing baseline, we obtain an average improvement of 3% across both datasets while on graph classification, we obtain an improvement of 3% on PTC dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION</head><p>In this paper, we proposed COMPGCN, a novel Graph Convolutional based framework for multirelational graphs which leverages a variety of composition operators from Knowledge Graph embedding techniques to jointly embed nodes and relations in a graph. Our method generalizes several existing multi-relational GCN methods. Moreover, our method alleviates the problem of over-parameterization by sharing relation embeddings across layers and using basis decomposition.</p><p>Through extensive experiments on knowledge graph link prediction, node classification, and graph classification tasks, we showed the effectiveness of COMPGCN over existing GCN based methods and demonstrated its scalability with increasing number of relations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A APPENDIX A.1 EVALUATION BY RELATION CATEGORY</head><p>In this section, we investigate the performance of COMPGCN on link prediction for different relation categories on FB15k-237 dataset. Following <ref type="bibr" target="#b42">Wang et al. (2014a)</ref>; <ref type="bibr" target="#b37">Sun et al. (2019)</ref>, based on the average number of tails per head and heads per tail, we divide the relations into four categories: one-to-one, one-to-many, many-to-one and many-to-many. The results are summarized in <ref type="table" target="#tab_11">Table 6</ref>. We observe that using GCN based encoders for obtaining entity and relation embeddings helps to improve performance on all types of relations. In the case of one-to-one relations, COMPGCN gives an average improvement of around 10% on MRR compared to the best performing baseline (ConvE + W-GCN). For one-to-many, many-to-one, and many-to-many the corresponding improvements are 10.5%, 7.5%, and 4%. These results show that COMPGCN is effective at handling both simple and complex relations.   <ref type="figure">1-1)</ref>, one-to-many (1-N), manyto-one (N-1), and many-to-many (N-N). We find that COMPGCN helps to improve performance on all types of relations compared to existing methods. Please refer to Section A.1 for more details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 DATASET DETAILS</head><p>In this section, we provide the details of the different datasets used in the experiments. For link prediction, we use the following two datasets:</p><p>• FB15k-237 <ref type="bibr" target="#b38">(Toutanova &amp; Chen, 2015)</ref> is a pruned version of FB15k <ref type="bibr">(Bordes et al., 2013)</ref> dataset with inverse relations removed to prevent direct inference. • WN18RR <ref type="bibr" target="#b9">(Dettmers et al., 2018)</ref>, similar to FB15k-237, is a subset from WN18 <ref type="bibr">(Bordes et al., 2013)</ref> dataset which is derived from WordNet <ref type="bibr" target="#b21">(Miller, 1995)</ref>.</p><p>For node classification, similar to <ref type="bibr" target="#b32">Schlichtkrull et al. (2017)</ref>, we evaluate on the following two datasets:</p><p>• MUTAG (Node) is a dataset from DL-Learner toolkit 4 . It contains relationship between complex molecules and the task is to identify whether a molecule is carcinogenic or not. • AM dataset contains relationship between different artifacts in Amsterdam Museum <ref type="bibr" target="#b6">(de Boer et al., 2012)</ref>. The goal is to predict the category of a given artifact based on its links and other attributes.</p><p>Finally, for graph classification, similar to <ref type="bibr" target="#b44">Xu et al. (2019)</ref>, we evaluate on the following datasets:</p><p>• MUTAG (Graph) Debnath et al. <ref type="formula" target="#formula_1">(1991)</ref> is a bioinformatics dataset of 188 mutagenic aromatic and nitro compounds. The graphs need to be categorized into two classes based on their mutagenic effect on a bacterium.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Link Prediction Node Classification Graph Classification</head><p>FB15k-237 WN18RR MUTAG (Node) AM MUTAG (Graph) PTC  <ref type="table">Table 7</ref>: The details of the datasets used for node classification, link prediction, and graph classification tasks. Please refer to Section 5.1 for more details.</p><p>• PTC <ref type="bibr" target="#b36">Srinivasan et al. (1997)</ref> is a dataset consisting of 344 chemical compounds which indicate carcinogenicity of male and female rats. The task is to label the graphs based on their carcinogenicity on rodents.</p><p>A summary statistics of all the datasets used is presented in <ref type="table">Table 7</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 HYPERPARAMETERS</head><p>Here, we present the implementation details for each task used for evaluation in the paper. For all the tasks, we used COMPGCN build on PyTorch geometric framework <ref type="bibr" target="#b10">(Fey &amp; Lenssen, 2019)</ref>.</p><p>Link Prediction: For evaluation, 200-dimensional embeddings for node and relation embeddings are used. For selecting the best model we perform a hyperparameter search using the validation data over the values listed in <ref type="table" target="#tab_14">Table 8</ref>. For training link prediction models, we use the standard binary cross entropy loss with label smoothing <ref type="bibr" target="#b9">Dettmers et al. (2018)</ref>.</p><p>Node Classification: Following Schlichtkrull et al. <ref type="formula" target="#formula_1">(2017)</ref>, we use 10% training data as validation for selecting the best model for both the datasets. We restrict the number of hidden units to 32. We use cross-entropy loss for training our model.</p><p>Graph Classification: Similar to <ref type="bibr" target="#b45">Yanardag &amp; Vishwanathan (2015)</ref>; <ref type="bibr" target="#b44">Xu et al. (2019)</ref>, we report the mean and standard deviation of validation accuracies across the 10 folds cross-validation. Crossentropy loss is used for training the entire model. For obtaining the graph-level representation, we use simple averaging of embedding of all nodes as the readout function, i.e.,</p><formula xml:id="formula_12">h G = 1 |V| v∈V h v ,</formula><p>where h v is the learned node representation for node v in the graph.</p><p>For all the experiments, training is done using Adam optimizer <ref type="bibr" target="#b17">(Kingma &amp; Ba, 2014)</ref> and Xavier initialization <ref type="bibr" target="#b13">(Glorot &amp; Bengio, 2010)</ref> is used for initializing parameters.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Link prediction: For evaluating COMPGCN, we compare against several non-neural and neural baselines: TransEBordes et al. (2013), DistMult<ref type="bibr" target="#b46">(Yang et al., 2014)</ref>, ComplEx<ref type="bibr" target="#b39">(Trouillon et al., 2016)</ref>, R-GCN<ref type="bibr" target="#b32">(Schlichtkrull et al., 2017)</ref>, KBGAN<ref type="bibr" target="#b5">(Cai &amp; Wang, 2018)</ref>, ConvE<ref type="bibr" target="#b9">(Dettmers et al., 2018</ref>), ConvKB (Nguyen et al., 2018, SACN<ref type="bibr" target="#b33">(Shang et al., 2019)</ref>, HypER<ref type="bibr" target="#b0">(Balažević et al., 2019)</ref>, RotatE<ref type="bibr" target="#b37">(Sun et al., 2019)</ref>, ConvR<ref type="bibr" target="#b16">(Jiang et al., 2019)</ref>, and VR-GCN(Ye et al., 2019).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :Figure 3 :</head><label>23</label><figDesc>Knowledge Graph link prediction with COMPGCN and other methods. COMPGCN generates both entity and relation embedding as opposed to just entity embeddings for other models. For more details, please refer to Section 6Performance of COMPGCN with different number of relation basis vectors on link prediction task. We report the relative change in MRR on FB15k-237 dataset. Overall, COMPGCN gives comparable performance even with limited parameters. Refer to Section 6.3 for details.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Comparison of COMPGCN (B = 5) with R-GCN for pruned versions of Fb15k-237 dataset containing different number of relations. COMPGCN with 5 relation basis vectors outperforms R-GCN across all setups. For more details, please refer to Section 6</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>defined as • Subtraction (Sub): φ(e s , e r ) = e s − e r . • Multiplication (Mult): φ(e s , e r ) = e s * e r . • Circular-correlation (Corr): φ(e s , e r )=e s e r</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>denotes the inverse relations and indicates the self loop.</figDesc><table><row><cell>Methods</cell><cell>Node Embeddings</cell><cell>Directions Relations</cell><cell>Relation Embeddings</cell><cell>Number of Parameters</cell></row><row><cell>GCN Kipf &amp; Welling (2016)</cell><cell></cell><cell></cell><cell></cell><cell>O(Kd 2 )</cell></row><row><cell>Directed-</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Comparison of our proposed method, COMPGCN with other Graph Convolutional methods. Here, K denotes the number of layers in the model, d is the embedding dimension, B represents the number of bases and |R| indicates the total number of relations in the graph.</figDesc><table><row><cell>Overall,</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Reduction of COMPGCN to several existing Graph Convolutional methods. Here, α k r is a relation specific scalar, W k r denotes a separate weight for each relation, and W k dir(r) is as defined in Equation 3. Please refer to Proposition 4.1 for more details.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>Proposition 4.1. COMPGCN generalizes the following Graph Convolutional based methods: Kipf-GCN (Kipf &amp; Welling, 2016), Relational GCN<ref type="bibr" target="#b32">(Schlichtkrull et al., 2017)</ref>, Directed GCN<ref type="bibr" target="#b20">(Marcheggiani &amp; Titov, 2017)</ref>, and Weighted GCN<ref type="bibr" target="#b33">(Shang et al., 2019)</ref>.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>FB15k-237</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>WN18RR</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="5">MRR MR H@10 H@3 H@1</cell><cell>MRR</cell><cell>MR</cell><cell cols="3">H@10 H@3 H@1</cell></row><row><cell>TransE (Bordes et al., 2013)</cell><cell>.294</cell><cell>357</cell><cell>.465</cell><cell>-</cell><cell>-</cell><cell>.226</cell><cell>3384</cell><cell>.501</cell><cell>-</cell><cell>-</cell></row><row><cell>DistMult (Yang et al., 2014)</cell><cell>.241</cell><cell>254</cell><cell>.419</cell><cell>.263</cell><cell>.155</cell><cell>.43</cell><cell>5110</cell><cell>.49</cell><cell>.44</cell><cell>.39</cell></row><row><cell>ComplEx (Trouillon et al., 2016)</cell><cell>.247</cell><cell>339</cell><cell>.428</cell><cell>.275</cell><cell>.158</cell><cell>.44</cell><cell>5261</cell><cell>.51</cell><cell>.46</cell><cell>.41</cell></row><row><cell>R-GCN</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>Proof. For Kipf-GCN, this can be trivially obtained by making weights (W λ(r) ) and composition function (φ) relation agnostic in Equation 5, i.e., W λ(r) = W and φ(h u , h r ) = h u . Similar reductions can be obtained for other methods as shown in Table 2.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>Link prediction performance of COMPGCN and several recent models on FB15k-237 and WN18RR</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 4 :</head><label>4</label><figDesc>Performance on link prediction task evaluated on FB15k-237 dataset. X + M (Y) denotes that method M is used for obtaining entity (and relation) embeddings with X as the scoring function. In the case of COMPGCN, Y denotes the composition operator used. B indicates the number of relational basis vectors used. Overall, we find that COMPGCN outperforms all the existing methods across different scoring functions. ConvE + COMPGCN (Corr) gives the best performance across all settings (highlighted using · ). Please refer to Section 6.1 for more details.</figDesc><table><row><cell></cell><cell></cell><cell>Entity</cell><cell></cell></row><row><cell></cell><cell></cell><cell>Embeddings</cell><cell></cell></row><row><cell></cell><cell>CompGCN</cell><cell></cell><cell>TransE</cell></row><row><cell></cell><cell></cell><cell>Relation</cell><cell></cell></row><row><cell></cell><cell></cell><cell>Embeddings</cell><cell></cell></row><row><cell>Knowledge Graph Knowledge Graph</cell><cell>R-GCN/ WGCN</cell><cell>Entity Embeddings</cell><cell>TransE</cell></row><row><cell></cell><cell></cell><cell>Relation</cell><cell></cell></row><row><cell></cell><cell></cell><cell>Embeddings</cell><cell></cell></row><row><cell></cell><cell>Encoder (M)</cell><cell></cell><cell>Score Function (X)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 5 :</head><label>5</label><figDesc>Performance comparison on node classification (Left) and graph classification (Right) tasks. * and †</figDesc><table><row><cell>indicate that results are directly taken from Schlichtkrull et al. (2017) and Xu et al. (2019) respectively. Overall,</cell></row><row><cell>we find that COMPGCN either outperforms or performs comparably compared to the existing methods. Please</cell></row><row><cell>refer to Section 6.4 for more details.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 6 :</head><label>6</label><figDesc>Results on link prediction by relation category on FB15k-237 dataset. Following Wang et al. (2014a), the relations are divided into four categories: one-to-one (</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 8 :</head><label>8</label><figDesc>Details of hyperparameters used for link prediction task. Please refer to Section A.3 for more details.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://github.com/KnowledgeBaseCompleter/eval-ConvKB</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">We further analyze the best performing method for different relation categories in Appendix A.1.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">http://www.dl-learner.org</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>1. We propose COMPGCN, a novel framework for incorporating multi-relational information in Graph Convolutional Networks which leverages a variety of composition operations from knowledge graph embedding techniques to jointly embed both nodes and relations in a graph. 2. We demonstrate that COMPGCN framework generalizes several existing multi-relational GCN methods (Proposition 4.1) and also scales with the increase in number of relations in the graph (Section 6.3). 3. Through extensive experiments on tasks such as node classification, link prediction, and graph classification, we demonstrate the effectiveness of our proposed method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>We thank the anonymous reviewers for their constructive comments. This work is supported in part by the Ministry of Human Resource Development (Government of India) and Google PhD Fellowship.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Hypernetwork knowledge graph embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivana</forename><surname>Balažević</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Neural Networks</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Graph-to-sequence learning using gated graph neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gholamreza</forename><surname>Haffari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL 2018 -The 56th Annual Meeting of the Association for Computational Linguistics</title>
		<editor>Iryna Gurevych and Yusuke Miyao</editor>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="273" to="283" />
		</imprint>
	</monogr>
	<note>ISBN 9781948087322</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Translating embeddings for modeling multi-relational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Garcia-Duran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oksana</forename><surname>Yakhnenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>C. J. C. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K. Q. Weinberger</editor>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="2787" to="2795" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Question answering with subgraph embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/D14-1067</idno>
		<ptr target="https://www.aclweb.org/anthology/D14-1067" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014-10" />
			<biblScope unit="page" from="615" to="620" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joan</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<idno>abs/1312.6203</idno>
		<ptr target="http://arxiv.org/abs/1312.6203" />
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">KBGAN: Adversarial learning for knowledge graph embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liwei</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">Yang</forename><surname>Wang</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/N18-1133" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1470" to="1480" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Supporting linked data production for cultural heritage institutes: The amsterdam museum case study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Victor De Boer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judith</forename><surname>Wielemaker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michiel</forename><surname>Van Gent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Hildebrand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacco</forename><surname>Isaac</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guus</forename><surname>Van Ossenbruggen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schreiber</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-30284-8_56</idno>
		<ptr target="http://dx.doi.org/10.1007/978-3-642-30284-8_56" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th International Conference on The Semantic Web: Research and Applications, ESWC&apos;12</title>
		<meeting>the 9th International Conference on The Semantic Web: Research and Applications, ESWC&apos;12<address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="733" to="747" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Structure-activity relationship of mutagenic aromatic and heteroaromatic nitro compounds. correlation with molecular orbital energies and hydrophobicity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asim</forename><surname>Kumar Debnath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rosa</forename><forename type="middle">L</forename><surname>Lopez De Compadre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gargi</forename><surname>Debnath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">J</forename><surname>Shusterman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Corwin</forename><surname>Hansch</surname></persName>
		</author>
		<idno type="DOI">10.1021/jm00106a046</idno>
		<ptr target="https://doi.org/10.1021/jm00106a046" />
	</analytic>
	<monogr>
		<title level="j">Journal of Medicinal Chemistry</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="786" to="797" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Convolutional neural networks on graphs with fast localized spectral filtering. CoRR, abs/1606.09375</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michaël</forename><surname>Defferrard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Bresson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Vandergheynst</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1606.09375" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Convolutional 2d knowledge graph embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Dettmers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minervini</forename><surname>Pasquale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stenetorp</forename><surname>Pontus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1707.01476" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32th AAAI Conference on Artificial Intelligence</title>
		<meeting>the 32th AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2018-02" />
			<biblScope unit="page" from="1811" to="1818" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Fast graph representation learning with PyTorch Geometric</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Fey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><forename type="middle">E</forename><surname>Lenssen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR Workshop on Representation Learning on Graphs and Manifolds</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Protein interface prediction using graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Fout</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Byrd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Basir</forename><surname>Shariat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asa</forename><surname>Ben-Hur</surname></persName>
		</author>
		<ptr target="http://papers.nips.cc/paper/7231-protein-interface-prediction-using-graph-convolutional-networks.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="6530" to="6539" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Neural message passing for quantum chemistry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Gilmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><forename type="middle">S</forename><surname>Schoenholz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><forename type="middle">F</forename><surname>Riley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><forename type="middle">E</forename><surname>Dahl</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=3305381.3305512" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="1263" to="1272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Understanding the difficulty of training deep feedforward neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<ptr target="http://proceedings.mlr.press/v9/glorot10a.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics</title>
		<editor>Yee Whye Teh and Mike Titterington</editor>
		<meeting>the Thirteenth International Conference on Artificial Intelligence and Statistics<address><addrLine>Sardinia, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-05" />
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="13" to="15" />
		</imprint>
		<respStmt>
			<orgName>Chia Laguna Resort</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Inductive representation learning on large graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rex</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
		<idno type="DOI">10.1162/neco.1997.9.8.1735</idno>
		<ptr target="http://dx.doi.org/10.1162/neco.1997.9.8.1735" />
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Adaptive convolution for multi-relational learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaotian</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Wang</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/N19-1103" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Semi-supervised classification with graph convolutional networks. CoRR</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
		<idno>abs/1609.02907</idno>
		<ptr target="http://arxiv.org/abs/1609.02907" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<ptr target="http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>F. Pereira, C. J. C. Burges, L. Bottou, and K. Q. Weinberger</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2012" />
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Encoding sentences with graph convolutional networks for semantic role labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diego</forename><surname>Marcheggiani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Titov</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/D17-1159" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1506" to="1515" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Wordnet: A lexical database for english</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><forename type="middle">A</forename><surname>Miller</surname></persName>
		</author>
		<idno type="DOI">http:/doi.acm.org/10.1145/219717.219748</idno>
		<ptr target="http://doi.acm.org/10.1145/219717.219748" />
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="39" to="41" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Dual-primal graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federico</forename><surname>Monti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleksandr</forename><surname>Shchur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksandar</forename><surname>Bojchevski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Or</forename><surname>Litany</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Günnemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
		<idno>abs/1806.00770</idno>
		<ptr target="http://arxiv.org/abs/1806.00770" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A novel embedding model for knowledge base completion based on convolutional neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tu</forename><forename type="middle">Dinh</forename><surname>Dai Quoc Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dat</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dinh</forename><surname>Quoc Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Phung</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N18-2053</idno>
		<ptr target="http://aclweb.org/anthology/N18-2053" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="327" to="333" />
		</imprint>
	</monogr>
	<note>Short Papers</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A review of relational machine learning for knowledge graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Tresp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Gabrilovich</surname></persName>
		</author>
		<idno type="DOI">10.1109/JPROC.2015.2483592</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE</title>
		<meeting>the IEEE</meeting>
		<imprint>
			<date type="published" when="2016-01" />
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="page" from="11" to="33" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Holographic embeddings of knowledge graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maximilian</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenzo</forename><surname>Rosasco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomaso</forename><surname>Poggio</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=3016100.3016172" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence, AAAI&apos;16</title>
		<meeting>the Thirtieth AAAI Conference on Artificial Intelligence, AAAI&apos;16</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1955" to="1961" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Learning convolutional neural networks for graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathias</forename><surname>Niepert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantin</forename><surname>Kutzkov</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=3045390.3045603" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd International Conference on International Conference on Machine Learning</title>
		<meeting>the 33rd International Conference on International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="2014" to="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Unsupervised generation of data mining features from linked open data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heiko</forename><surname>Paulheim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Fümkranz</surname></persName>
		</author>
		<idno type="DOI">http:/doi.acm.org/10.1145/2254129.2254168</idno>
		<ptr target="http://doi.acm.org/10.1145/2254129.2254168" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2Nd International Conference on Web Intelligence, Mining and Semantics, WIMS &apos;12</title>
		<meeting>the 2Nd International Conference on Web Intelligence, Mining and Semantics, WIMS &apos;12<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Deep Learning for the Life Sciences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bharath</forename><surname>Ramsundar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Eastman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Walters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Pande</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Leswing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenqin</forename><surname>Wu</surname></persName>
		</author>
		<ptr target="https://www.amazon.com/Deep-Learning-Life-Sciences-Microscopy/dp/1492039837" />
		<imprint>
			<date type="published" when="2019" />
			<pubPlace>O&apos;Reilly Media</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Rdf2vec: Rdf graph embeddings for data mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petar</forename><surname>Ristoski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heiko</forename><surname>Paulheim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Semantic Web Conference</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="498" to="514" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A collection of benchmark datasets for systematic evaluations of machine learning on the semantic web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petar</forename><surname>Ristoski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerben</forename><surname>Klaas Dirk De Vries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heiko</forename><surname>Paulheim</surname></persName>
		</author>
		<idno>978-3-319-46547-0</idno>
	</analytic>
	<monogr>
		<title level="m">The Semantic Web -ISWC 2016</title>
		<editor>Paul Groth, Elena Simperl, Alasdair Gray, Marta Sabou, Markus Krötzsch, Freddy Lecue, Fabian Flöck, and Yolanda Gil</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="186" to="194" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Mt-cgcnn: Integrating crystal graph convolutional neural network with multitask learning for material property prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumya</forename><surname>Sanyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janakiraman</forename><surname>Balachandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naganand</forename><surname>Yadati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Padmini</forename><surname>Rajagopalan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suchismita</forename><surname>Sanyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Partha</forename><surname>Talukdar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.05660</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Modeling relational data with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Schlichtkrull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rianne</forename><surname>Bloem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Titov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.06103</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">End-to-end structureaware convolutional networks for knowledge base completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinbo</forename><surname>Bi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Zhou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Weisfeiler-lehman graph kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nino</forename><surname>Shervashidze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Schweitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><forename type="middle">Jan</forename><surname>Van Leeuwen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Mehlhorn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karsten</forename><forename type="middle">M</forename><surname>Borgwardt</surname></persName>
		</author>
		<idno>1532-4435</idno>
		<ptr target="http://dl.acm.org/citation.cfm?id=1953048" />
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2539" to="2561" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Reasoning with neural tensor networks for knowledge base completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
		<ptr target="http://papers.nips.cc/paper/5028-reasoning-with-neural-tensor-networks-for-knowledge-base-completion.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>C. J. C. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K. Q. Weinberger</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="926" to="934" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">The predictive toxicology evaluation challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">H</forename><surname>Muggleton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J E</forename><surname>Sternberg</surname></persName>
		</author>
		<idno>1-555860-480-4</idno>
		<ptr target="http://dl.acm.org/citation.cfm?id=1624162.1624163" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th International Joint Conference on Artifical Intelligence</title>
		<meeting>the 15th International Joint Conference on Artifical Intelligence<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="1997" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4" to="9" />
		</imprint>
	</monogr>
	<note>IJCAI&apos;97</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Rotate: Knowledge graph embedding by relational rotation in complex space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiqing</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi-Hong</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Yun</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Tang</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=HkgEQnRqYQ" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Observed versus latent features for knowledge base and text inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd Workshop on Continuous Vector Space Models and their Compositionality</title>
		<meeting>the 3rd Workshop on Continuous Vector Space Models and their Compositionality</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="57" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Complex embeddings for simple link prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Théo</forename><surname>Trouillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Welbl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Éric</forename><surname>Gaussier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Bouchard</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=3045390" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd International Conference on International Conference on Machine Learning</title>
		<meeting>the 33rd International Conference on International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="2071" to="2080" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petar</forename><surname>Veličković</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillem</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arantxa</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adriana</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Liò</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=rJXMpikCZ.acceptedasposter" />
		<title level="m">Graph Attention Networks. International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Knowledge graph embedding: A survey of approaches and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
		<idno type="DOI">10.1109/TKDE.2017.2754499</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2724" to="2743" />
			<date type="published" when="2017-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Knowledge graph embedding by translating on hyperplanes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianwen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianlin</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Chen</surname></persName>
		</author>
		<ptr target="https://www.aaai.org/ocs/index.php/AAAI/AAAI14/paper/view/8531" />
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Knowledge graph embedding by translating on hyperplanes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianwen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianlin</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Chen</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=2893873.2894046" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Eighth AAAI Conference on Artificial Intelligence, AAAI&apos;14</title>
		<meeting>the Twenty-Eighth AAAI Conference on Artificial Intelligence, AAAI&apos;14</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1112" to="1119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">How powerful are graph neural networks?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keyulu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weihua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanie</forename><surname>Jegelka</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=ryGs6iA5Km" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Deep graph kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pinar</forename><surname>Yanardag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">V N</forename><surname>Vishwanathan</surname></persName>
		</author>
		<idno type="DOI">http:/doi.acm.org/10.1145/2783258.2783417</idno>
		<ptr target="http://doi.acm.org/10.1145/2783258.2783417" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;15</title>
		<meeting>the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;15<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1365" to="1374" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Embedding entities and relations for learning and inference in knowledge bases. CoRR, abs/1412</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bishan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1412.6575" />
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">6575</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">A vectorized relational graph convolutional network for multi-relational network alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yujie</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyu</forename><surname>Zang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingzhong</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.24963/ijcai.2019/574</idno>
		<ptr target="https://doi.org/10.24963/ijcai.2019/574" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI-19</title>
		<meeting>the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI-19</meeting>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">2019</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">An end-to-end deep learning architecture for graph classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhicheng</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marion</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixin</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4438" to="4445" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
