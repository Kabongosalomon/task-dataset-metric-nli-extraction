<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Batch-normalized Maxout Network in Network</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia-Ren</forename><surname>Chang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">National Chiao Tung University</orgName>
								<address>
									<settlement>Hsinchu</settlement>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong-Sheng</forename><surname>Chen</surname></persName>
							<email>yschen@cs.nctu.edu.tw*</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science National</orgName>
								<orgName type="institution">Chiao Tung University</orgName>
								<address>
									<settlement>Hsinchu</settlement>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Batch-normalized Maxout Network in Network</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T21:22+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper reports a novel deep architecture referred to as Maxout network In Network (MIN), which can enhance model discriminability and facilitate the process of information abstraction within the receptive field. The proposed network adopts the framework of the recently developed Network In Network structure, which slides a universal approximator, multilayer perceptron (MLP) with rectifier units, to exact features. Instead of MLP, we employ maxout MLP to learn a variety of piecewise linear activation functions and to mediate the problem of vanishing gradients that can occur when using rectifier units. Moreover, batch normalization is applied to reduce the saturation of maxout units by pre-conditioning the model and dropout is applied to prevent overfitting. Finally, average pooling is used in all pooling layers to regularize maxout MLP in order to facilitate information abstraction in every receptive field while tolerating the change of object position. Because average pooling preserves all features in the local patch, the proposed MIN model can enforce the suppression of irrelevant information during training. Our experiments demonstrated the state-of-the-art classification performance when the MIN model was applied to MNIST, CIFAR-10, and CIFAR-100 datasets and comparable performance for SVHN dataset.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Deep convolutional neural networks (CNNs) <ref type="bibr" target="#b12">[13]</ref> have recently been applied to large image datasets, such as MNIST <ref type="bibr" target="#b13">[14]</ref>, CIFAR-10/100 <ref type="bibr" target="#b11">[12]</ref>, SVHN <ref type="bibr" target="#b21">[22]</ref>, and Ima-geNet <ref type="bibr" target="#b1">[2]</ref> for image classification <ref type="bibr" target="#b9">[10]</ref>. A deep CNN is able to learn basic filters automatically and combine them hierarchically to enable the description of latent concepts for pattern recognition. In <ref type="bibr" target="#b29">[30]</ref>, Zeiler et al. illustrated how deep CNN organizes feature maps and the discrimination among classes.</p><p>Despite the advances that have been made in the development of this technology, many issues related to deep learning remain, including: (1) model discriminability and the robustness of learned features in early layers <ref type="bibr" target="#b29">[30]</ref>; <ref type="bibr" target="#b1">(2)</ref> the vanishing gradients and saturation of activation units during training <ref type="bibr" target="#b5">[6]</ref>; and (3) limited training data, which may lead to overfitting <ref type="bibr" target="#b24">[25]</ref>.</p><p>Because data are usually distributed on nonlinear manifolds, they are not separable by linear filters. For enhancing model discriminability, the Network In Network (NIN) <ref type="bibr" target="#b17">[18]</ref> model uses a sliding micro neural network, multilayer perceptron (MLP), to increase the nonlinearity of local patches in order to enable the abstraction of greater quantities of information within the receptive fields. Similarly, Deeply Supervised Nets (DSN) <ref type="bibr" target="#b14">[15]</ref> provides companion objective functions to constrain hidden layers, such that robust features can be learned in the early layers of a deep CNN structure.</p><p>The problem of vanishing gradients is essentially the shrinking of gradients backward through hidden layers. Some activation functions, such as sigmoid, are susceptible to vanishing gradients and saturation during the training of deep networks, due to the fact that higher hidden units become saturated at -1 or 1. Current solutions involve the use of rectified linear units (ReLU) to prevent vanishing gradients <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b20">21]</ref> because ReLU activates above 0 and its partial derivative is 1. Thus gradients flow through while ReLU activates. Unfortunately, ReLU has a potential disadvantage. The constant 0 will block the gradient flowing through inactivated ReLUs, such that some units may never activate. Recently, the maxout network <ref type="bibr" target="#b6">[7]</ref> provided a remedy to this problem. Even when maxout output is 0, this value is from a maxout hidden unit and this unit may be adjusted to become positive afterwards. Another issue involves changes of data distribution during the training of deep networks that are likely to saturate the activation function. This changed data distribution can move input data into the saturated regime of the activation function and slow down the training process. This phenomenon is referred to as internal covariate shift <ref type="bibr" target="#b23">[24]</ref>. Ioffe et al. <ref type="bibr" target="#b10">[11]</ref> addressed this problem by applying batch normalization to the input of each layer.</p><p>Dropout <ref type="bibr" target="#b24">[25]</ref> and Dropconnect <ref type="bibr" target="#b26">[27]</ref> techniques are widely used to regularize deep networks in order to prevent overfitting. The idea of the technique is to randomly drop units or connections to prevent units from co-adapting, which has been shown to improve classification accuracy in numerous studies <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b24">25]</ref>.</p><p>The previous deep learning methods used max pooling to retain the most valuable features in the local patch. The max pooling mimics the spatial selective attention mechanism of human and attends to the important and discriminable areas of the input image. Lin et al. <ref type="bibr" target="#b17">[18]</ref> proposed a strategy referred to as global average pooling for the replacement of fully-connected layers to enable the summing of spatial information of feature maps, thereby making it more robust to spatial translation. This strategy is close to human visual process, in which retinotopic response can be predicted by linear spatial summation <ref type="bibr" target="#b8">[9]</ref>. The spatial summation enables the tolerance to the changes in object position and size, which is an essential characteristic to object recognition. In this work, we extend the global average pooling strategy to local spatial average pooling in order to aggregate local information from feature maps.</p><p>However, the spatial average pooling keeps the irrelevant features together with the relevant ones and may deteriorate the classification performance. This problem can be tackled by applying the maxout MLP to select the most prominent features from local patches before spatial average pooling. During the training process, therefore, the back-propagation enforces the maxout MLP to learn the most relevant features in every local patches. From neuroscience perspective, there is a similar mechanism in visual system. Within the same receptive field, the features of objects compete with each other in the object recognition process <ref type="bibr" target="#b2">[3]</ref>.</p><p>In this study, we aimed to increase nonlinearity within local patches and alleviate the problem of vanishing gradients. Based on the NIN <ref type="bibr" target="#b17">[18]</ref> structure, we employ a maxout MLP for feature extraction and refer to the proposed model as Maxout network In Network (MIN). The MIN model uses batch normalization to reduce saturation and uses dropout to prevent overfitting. To increase the robustness to spatial translation of objects, furthermore, average pooling is applied in all pooling layers to aggregate the essential features obtained by maxout MLP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Design of Deep Architecture</head><p>This section presents previous works related to the proposed MIN structure, including NIN, Maxout Network, and batch normalization, followed by the design of the MIN ar-chitecture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">NIN</head><p>The NIN model <ref type="bibr" target="#b17">[18]</ref> uses the universal approximator MLP for the extraction of features from local patches. Compared to CNN, MLP, wherein an ReLU is used as the activation function, enables the abstraction of information that is more representative for the latent concepts. The NIN model introduced the mlpconv layer which consists of a linear convolutional layer and a two-layer MLP. The calculation performed by the mlpconv layer is as follows:</p><formula xml:id="formula_0">f 1 i,j,n1 = max w 1 n1 T x i,j + b n1 , 0 , f 2 i,j,n2 = max w 2 n2 T f 1 i,j + b n2 , 0 , f 3 i,j,n3 = max w 3 n3 T f 2 i,j + b n3 , 0 ,<label>(1)</label></formula><p>where (i, j) is the pixel index in the feature maps, x i,j represents the input patch centered at location (i, j), and n 1 , n 2 , and n 3 are used to index the channels of the feature maps. From another perspective, the mlpconv layer can be viewed as equivalent to a cascaded cross-channel parametric pooling layer on a convolutional layer. The cascaded cross-channel parametric pooling layer linearly combines feature maps and then passes through ReLUs, thereby allowing the cross-channel flow of information. However, the constant 0 will block the gradients flowing through the inactivated ReLUs and these ReLUs will not be updated during the training process. In this work, we adopted a similar universal approximator, maxout MLP, to overcome this problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Maxout Network</head><p>Maxout MLP has previously been proven as a universal approximator <ref type="bibr" target="#b6">[7]</ref>, wherein a maxout unit is implemented by the following function:</p><formula xml:id="formula_1">f i,j,n = max m∈[1,k] w T nm x i,j + b nm ,<label>(2)</label></formula><p>where (i, j) is the pixel index in the feature maps, x i,j represents the input patch centered at location (i, j), and n is used to index the channels of the feature maps, f i,j,n , which are constructed by taking the maximum across k maxout hidden pieces. From another perspective, maxout unit is equivalent to a cross-channel max pooling layer on a convolutional layer. The cross-channel max pooling layer selects the maximal output to be fed into the next layer. The maxout unit is helpful to tackle the problem of vanishing gradients because the gradient is able to flow through every maxout unit. Internal covariate shift is defined as changes in the distribution of network activations resulting from the updating of network parameters during training <ref type="bibr" target="#b10">[11]</ref>. When more weights and biases in a network are changed, internal covariate shift is severer. A greater number of inputs move to the saturated regime of nonlinearity and thereby slow down the training process. Internal covariate shift is a serious problem for maxout MLP because it is k times larger than a classical MLP. In this study, we applied batch normalization to reduce the effects of covariate shift.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Batch Normalization</head><p>Batch normalization <ref type="bibr" target="#b10">[11]</ref> is used to independently normalize each channel toward zero mean and unit variance:</p><formula xml:id="formula_2">x i,j,n = x i,j,n − E [x n ] Var [x n ] ,<label>(3)</label></formula><p>whereupon the normalized value undergoes scaling and shifting:</p><formula xml:id="formula_3">f i,j,n = γ nxi,j,n + β n .<label>(4)</label></formula><p>Here x i,j stands for the value at location (i, j), n is used to index the channels of the feature map, and scaling and shifting parameters γ n , β n are new parameters that join in network training. Batch normalization layer can be applied to a convolutional network immediately before the activation function, such as ReLU or maxout. In this case, the nonlinearity units tends to produce activation with a stable distribution, which reduces saturation. Normalization also exists in biological neural network, which is a canonical neural computation well-studied in neuroscience field <ref type="bibr" target="#b0">[1]</ref>. This mechanism explains how primary visual neurons control the strength of input at which responses saturate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Proposed MIN Architecture</head><p>The NIN <ref type="bibr" target="#b17">[18]</ref> has capability to abstract representative features within the receptive field and thereby achieve good results in image classification. As described in Section 2.1, NIN uses ReLU as the activation function in mlpconv layer. In this study, we replaced the ReLU activation functions in the two-layer MLP in NIN with the maxout units to overcome the vanishing gradient problem commonly encountered when using ReLU. Furthermore, we applied batch normalization immediately after convolutional calculation to avoid the covariate shift problem caused by the changes of data distribution. Specifically, we removed the activation function of the convolutional layer, thereby rendering it a pure feature extractor. The architecture of the proposed MIN model is presented in <ref type="figure" target="#fig_0">Figure 1</ref>. Feature maps in a MIN block are calculated as follows:</p><formula xml:id="formula_4">f 1 i,j,n1 = BN w 1 n1 T x i,j + b 1 nj , f 2 i,j,n 2 = max m∈[1,k1] BN w 2 nm T f 1 i,j + b 2 nm , f 3 i,j,n3 = max m∈[1,k2] BN w 3 nm T f 2 i,j + b 3 nm ,<label>(5)</label></formula><p>where BN (·) denotes the batch normalization layer, (i, j) is the pixel index in the feature map, x i,j represents the input patch centered at location (i, j), and n is used to index the channels of the feature maps that are constructed by taking the maximum across k maxout hidden pieces. Montufar et al. <ref type="bibr" target="#b17">[18]</ref> demonstrated that the complexity of maxout networks increases with the number of maxout pieces or layers. By increasing the number of maxout pieces, the proposed model expands the ability to capture the latent concepts for various inputs. From another perspective, a MIN block is equivalent to a cascaded cross-channel parametric pooling layer and a cross-channel max pooling on a convolutional layer. The MIN block linearly combines feature maps and selects the combinations that are the most informational to be fed into the next layer. The MIN block reduces saturation by applying batch normalization and makes it possible to encode information on pathways or in the activation patterns of maxout pieces <ref type="bibr" target="#b27">[28]</ref>. This makes it possible to enhance the discrimination capability of deep architectures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Experiments</head><p>In the following experiments, the proposed method was evaluated using four benchmark datasets: MNIST <ref type="bibr" target="#b13">[14]</ref>, CIFAR-10 <ref type="bibr" target="#b11">[12]</ref>, CIFAR-100 <ref type="bibr" target="#b11">[12]</ref>, and SVHN <ref type="bibr" target="#b21">[22]</ref>. The proposed model consists of three stacked MIN blocks followed by a softmax layer. A MIN block includes a convolutional layer, a two-layer maxout MLP, and a spatial pooling layer. Dropout is applied between MIN blocks for regularization. <ref type="table">Table 1</ref> details the parameter settings which, for the sake of a fair comparison, are the same as those used in NIN <ref type="bibr" target="#b17">[18]</ref>. The network was implemented using the MatConvNet <ref type="bibr" target="#b25">[26]</ref> toolbox in the Matlab environment. We adopted the training procedure proposed by Goodfellow et al. <ref type="bibr" target="#b6">[7]</ref> to determine the hyper-parameters of the model, such as momentum, weight decay, and learning rate decay.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">MNIST</head><p>The MNIST dataset <ref type="bibr" target="#b13">[14]</ref> consists of handwritten digit images, 28 x 28 pixels in size, organized into 10 classes (0 to 9) with 60,000 training and 10,000 test samples. Testing on this dataset was performed without data augmentation. <ref type="table" target="#tab_0">Table 2</ref> compares the results obtained in this study with those obtained in previous works. Despite the fact that many methods can achieve very low error rates for MNIST dataset, we achieved a test error rate of 0.24%, which set a new state-of-the-art performance without data augmentation. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">CIFAR-10</head><p>The CIFAR-10 dataset <ref type="bibr" target="#b11">[12]</ref> consists of color natural images, 32 x 32 pixels in size, from 10 classes with 50,000 training and 10,000 test images. For this dataset, we applied global contrast normalization and whitening in accordance with the methods outlined in <ref type="bibr" target="#b6">[7]</ref>. To enable a comparison with previous works, the dataset was augmented by zeropadding 2 pixels on each side, which resulted in images 36 x 36 pixels in size. We then performed random corner cropping back to 32 x 32 pixels as well as random flipping on the fly during training. <ref type="table" target="#tab_1">Table 3</ref> compares our results with those obtained in previous works. We obtained an error rate of 7.85% without data augmentation and 6.75% with data augmentation. These are the best results achieved to our knowledge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">CIFAR-100</head><p>The CIFAR-100 dataset <ref type="bibr" target="#b11">[12]</ref> is the same size and format as the CIFAR-10; however, it contains 100 classes. Thus, the number of images in each class is only one tenth of that of CIFAR-10. As a result, this dataset is far more challenging. We applied the hyper-parameters used for CIFAR-10, but re-tuned the learning rate decay. This resulted in an error rate of 28.86% without data augmentation, which represents the state-of-the-art performance. <ref type="table" target="#tab_2">Table 4</ref> presents a summary of the best results obtained in previous works and the current work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">SVHN</head><p>The SVHN dataset consists of color images of house numbers (32 x 32 pixels) collected by Google Street View. There are 73,257 and 531,131 digits in the training and additional sets, respectively. In accordance with previous works <ref type="bibr" target="#b6">[7]</ref>, we selected 400 samples per class from the train- <ref type="table">Table 1</ref>. Parameter settings of the proposed MIN architecture used in the experiments. The convolutional kernel is defined as (height) x (width) x (number of units). Below, we present the stride (st.), padding (pad) and batch normalization (BN) of the convolution kernel. In maxout MLP layers (MMLP), k indicates the number of maxout pieces used in one maxout unit. A softmax layer is applied to the last layer in the model (not shown here). The top row lists the parameters used in CIFAR-10/100 and SVHN, whereas the bottom row lists those used in MNIST. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MNIST</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CIFAR-10(100) SVHN</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conv</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Error (%) Stochastic pooling <ref type="bibr" target="#b28">[29]</ref> 0.47 Maxout network (k=2) <ref type="bibr" target="#b6">[7]</ref> 0.47 NIN <ref type="bibr" target="#b17">[18]</ref> 0.45 DSN <ref type="bibr" target="#b14">[15]</ref> 0.39 MIM (k=2) <ref type="bibr" target="#b16">[17]</ref> 0.35±0.03 RCNN-96 <ref type="bibr" target="#b15">[16]</ref> 0.31 MIN (k=5) 0.24</p><p>ing set and 200 samples per class from the additional set for validation. The remaining 598,388 images were used for training. Moreover, there are 26,032 digits in the test set. For SVHN dataset, we applied the hyper-parameters as those used in the experiments mentioned previously, but re-tuned the learning rate decay. We also preprocessed the dataset using local contrast normalization, in accordance with the method outlined by Goodfellow et al. <ref type="bibr" target="#b6">[7]</ref>. Without data augmentation, we achieved a test error rate of 1.81%, which is comparable to the best result obtained in previous works. <ref type="table">Table 5</ref> presents a comparison of our test results  <ref type="bibr" target="#b28">[29]</ref> 15.13 Maxout network (k=2) <ref type="bibr" target="#b6">[7]</ref> 11.68 NIN <ref type="bibr" target="#b17">[18]</ref> 10.41 DSN <ref type="bibr" target="#b14">[15]</ref> 9.69 RCNN-160 <ref type="bibr" target="#b15">[16]</ref> 8.69 MIM (k=2) <ref type="bibr" target="#b16">[17]</ref> 8.52±0.20 MIN (k=5) 7.85 Data augmentation Maxout network (k=2) <ref type="bibr" target="#b6">[7]</ref> 9.38 NIN <ref type="bibr" target="#b17">[18]</ref> 8.81 DSN <ref type="bibr" target="#b14">[15]</ref> 8.22 RCNN-160 <ref type="bibr" target="#b15">[16]</ref> 7.09 MIN (k=5) 6.75  <ref type="bibr" target="#b28">[29]</ref> 42.51 Maxout network (k=2) <ref type="bibr" target="#b6">[7]</ref> 38.57 NIN <ref type="bibr" target="#b17">[18]</ref> 35.68 DSN <ref type="bibr" target="#b14">[15]</ref> 34.57 RCNN-160 <ref type="bibr" target="#b15">[16]</ref> 31.75 MIM (k=2) <ref type="bibr" target="#b16">[17]</ref> 29.20±0.2 MIN (k=5)</p><p>28.86 <ref type="table">Table 5</ref>. Comparison of test errors on SVHN. Note that Dropconnet <ref type="bibr" target="#b26">[27]</ref> uses data augmentation and multiple model voting</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Error (%) Maxout network (k=2) <ref type="bibr" target="#b6">[7]</ref> 2.47 NIN <ref type="bibr" target="#b17">[18]</ref> 2.35 Human performance <ref type="bibr" target="#b22">[23]</ref> 2.00 MIM (k=2) <ref type="bibr" target="#b16">[17]</ref> 1.97±0.08 Dropconnect <ref type="bibr" target="#b26">[27]</ref> 1.94 DSN <ref type="bibr" target="#b14">[15]</ref> 1.92 MIN (k=5) 1.81 RCNN-192 <ref type="bibr" target="#b15">[16]</ref> 1.77 with those obtained in recent studies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Model capacity</head><p>According to Montufar et al. <ref type="bibr" target="#b19">[20]</ref>, a deep neural network using ReLU activation function with n 0 input and L hidden layers of width n ≥ n 0 can have Ω (n/n 0 ) (L−1)n0 n n0 grows with the number of maxout pieces. Moreover, the number of linear regions in both ReLU and maxout networks grows exponentially with the number of layers. From this perspective, the Maxout network In Maxout network (MIM) model <ref type="bibr" target="#b16">[17]</ref> is indeed more complex than the proposed method. However, the maxout network is prone to overfitting to the training dataset without model regularization. This can be attributed to the fact that the maxout network identifies the most valuable representations in the input during training, and it is prone to feature co-adaption. Therefore, MIM model in which three maxout layers are stacked in one MIM block may lead to overfitting and increasing the number of maxout pieces may not improve performance. We tested the proposed method on CIFAR-10 dataset using various numbers of maxout pieces. <ref type="figure" target="#fig_1">Figure 2</ref> illustrates how increasing the number of maxout pieces can improve the performance of our method, by which point the MIM model has already reached saturation. This figure also shows the saturation of maxout units due to the growing number of maxout pieces without batch normalization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.">Regularization of average pooling in MIN</head><p>Most of the previous methods used max pooling for down sampling. Max pooling extracts the features within local patches that are the most representative of the class. In this study, the MIN block is able to abstract representative information from every local patch such that more discriminable information is embedded in the feature map. Thus, we are able to use spatial average pooling in each pooling layer to aggregate local spatial information. We then compared the results using average pooling in the first two pooling layers with those using max pooling, whereas the last pooling layer was fixed to global average pooling. <ref type="table" target="#tab_3">Table 6</ref> presents the test error associated with different pooling methods. The use of average pooling in all pooling layers was shown particularly effective. The irrelevant information in the input image can be inhibited by average pooling, but may be discarded by max pooling. Average pooling is an extension of global average pooling in which the model seeks to extract information from every local patch to facilitate abstraction to the feature maps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7.">Visualization of learned features</head><p>Average pooling was applied in all pooling layers to facilitate the abstraction of input images. We extracted feature maps from models trained using CIFAR-10 to illustrate these effects. <ref type="figure" target="#fig_3">Figure 3</ref> presents examplar images and their corresponding feature maps, which were selected from the CIFAR-10 test set. For each method, the first column illustrates the selected feature maps related to the objects per se, whereas the second column shows the selected feature maps for the background. Note that only the top 50% of the data in each channel are shown in this figure. The learned feature maps produced using the proposed MIN method appear to be more intuitive than the other methods when dealing with both foreground and background. This finding demonstrates the effectiveness of MIN and its potential for object segmentation. <ref type="figure" target="#fig_4">Figure 4</ref> presents examplar images selected from SVHN test set and their corresponding feature maps extracted in the last convolutional layer by using the MIN and NIN models. Only the top 10% of the data are presented. One of the major difficulties in the classification on SVHN dataset is that there are a large portion of images containing distractors, which may confuse the model during training. After all, the distractors are also digits and should be recognized by the model during testing as well as the targeted digit in the center. Therefore, the model should recognize the distractors as the runners-up, besides classifying the targeted digit as the first candidate. In <ref type="figure" target="#fig_4">Figure 4</ref>, we presented the images containing targeted digits from 0 to 9 and distractors on the side and highlighted the first and second candidates of the output determined by the softmax layer. These results show that the proposed approach is able to recognize distractors in input images with high accuracy. This indicates that the MIN can robustly preserve information  of each category because of the pathway encoding in maxout MLP and spatial average pooling. When convolutional filters slide onto the distractor, the MIN model can extract features of the distractor along its own pathway. Moreover, the MIN model downscale the feature maps by using spatial average pooling and this pooling method keeps all information of a local patch, whereas max pooling only passes the maximal part. These results suggest the possibility of applying the MIN method to multiple object recognition using a more comprehensive image dataset, such as ImageNet.</p><p>In human visual system, the competing process of distractors has been investigated by the Eriksen flanker task <ref type="bibr" target="#b3">[4]</ref>. In this task, subjects are instructed to respond with one hand if the presented central letter is 'H' and with the other hand if the letter is 'S'. In general, subjects respond faster and more accurately when the center and flankers are the same (e.g., HHHHH or SSSSS) than when they are different (e.g., HHSHH or SSHSS). Psychophysiological analysis <ref type="bibr" target="#b7">[8]</ref> supported the theory indicating that the flankers activate the incorrect response competing with the correct response <ref type="bibr" target="#b4">[5]</ref>. That is, visual system processes all of the ob-jects in the visual field and inhibits responses of incongruent objects. This suggests that the proposed MIN model resembles the human visual system such that the distractors are recognized and inhibited as runner-ups.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Conclusions</head><p>This paper presents a novel deep architecture, MIN. A MIN block, consisting of a convolutional layer and a twolayer maxout MLP, is used to convolve the input and average pooling is applied in all pooling layers. In neuroscience perspective, the proposed architecture is similar to the mechanism of visual system in the brain. The proposed method outperforms others because of the following improvements: the MIN block facilitates the information abstraction of local patches, batch normalization prevents covariate shift, and average pooling acts as a spatial regularizer tolerating changes of object positions. Our experiments showed that the MIN method achieves state-of-theart or comparable performance on the MNIST, CIFAR-10, CIFAR-100, and SVHN datasets. Moreover, the extracted feature maps demonstrate the efficacy of categorical representation by using the MIN method, as well as its potential to multiple object recognition.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>The architecture of the proposed MIN model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>linear regions. A deep maxout network with L layers of width n and k maxout pieces can compute functions in at least k L−1 k n linear regions. This theoretical result indicates that the number of linear regions in a maxout network Performance related to the number of maxout pieces. We fixed the hyper-parameters when training the MIN model with different maxout pieces. Our method dramatically reduces test error of CIFAR-10 dataset with increasing the number of maxout pieces.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 .</head><label>3</label><figDesc>Visualization of learned feature maps before the first pooling layer obtained using the MIN, MIM, and NIN methods. Only the top 50% of the data in each channel are presented.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 .</head><label>4</label><figDesc>Visualization of the learned feature maps before the global average pooling layer obtained using the MIN and NIN methods. Only the top 10% of the data are presented. The first and second candidates of the output are highlighted in red and green boxes. These results demonstrate the possibility applying the proposed MIN method to multiple object recognition.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 2 .</head><label>2</label><figDesc>Comparison of test errors on MNIST without data augmentation, in which k denotes the number of maxout pieces.</figDesc><table><row><cell>-1</cell><cell>5x5x128 / st. 1 / pad 0</cell><cell>5x5x192 / st. 1/ pad 2</cell></row><row><cell></cell><cell>BN</cell><cell>BN</cell></row><row><cell>MMLP-1-1</cell><cell>1x1x96 / st. 1 / pad 0</cell><cell>1x1x160 / st. 1 / pad 0</cell></row><row><cell></cell><cell>k=5 / BN</cell><cell>k=5 / BN</cell></row><row><cell>MMLP-1-2</cell><cell>1x1x48 / st. 1 / pad 0</cell><cell>1x1x96 / st. 1 / pad 0</cell></row><row><cell></cell><cell>k=5 / BN</cell><cell>k=5 / BN</cell></row><row><cell></cell><cell>3x3 avg. pool / st.2</cell><cell>3x3 avg. pool / st.2</cell></row><row><cell></cell><cell>dropout 0.5</cell><cell>dropout 0.5</cell></row><row><cell>Conv-2</cell><cell>5x5x128 / st. 1 / pad 2</cell><cell>5x5x192 / st. 1 / pad 2</cell></row><row><cell></cell><cell>BN</cell><cell>BN</cell></row><row><cell>MMLP-2-1</cell><cell>1x1x96 / st. 1 / pad 0</cell><cell>1x1x192 / st. 1 / pad 0</cell></row><row><cell></cell><cell>k=5 / BN</cell><cell>k=5 / BN</cell></row><row><cell>MMLP-2-2</cell><cell>1x1x48 / st. 1 / pad 0</cell><cell>1x1x192 / st. 1 / pad 0</cell></row><row><cell></cell><cell>k=5 / BN</cell><cell>k=5 / BN</cell></row><row><cell></cell><cell>3x3 avg. pool / st.2</cell><cell>3x3 avg. pool / st.2</cell></row><row><cell></cell><cell>dropout 0.5</cell><cell>dropout 0.5</cell></row><row><cell>Conv-3</cell><cell>3x3x128 / st. 1 / pad 1</cell><cell>3x3x192 / st. 1 / pad 1</cell></row><row><cell></cell><cell>BN</cell><cell>BN</cell></row><row><cell>MMLP-3-1</cell><cell>1x1x96 / st. 1 / pad 0</cell><cell>1x1x192 / st. 1 / pad 0</cell></row><row><cell></cell><cell>k=5 / BN</cell><cell>k=5 / BN</cell></row><row><cell>MMLP-3-2</cell><cell>1x1x10 / st. 1 / pad 0</cell><cell>1x1x10(100) / st. 1 / pad 0</cell></row><row><cell></cell><cell>k=5 / BN</cell><cell>k=5 / BN</cell></row><row><cell></cell><cell>7x7 avg. pool</cell><cell>8x8 avg. pool</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 3 .</head><label>3</label><figDesc>Comparison of test errors on CIFAR-10 dataset</figDesc><table><row><cell>Method</cell><cell>Error (%)</cell></row><row><cell>No data augmentation</cell><cell></cell></row><row><cell>Stochastic pooling</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 4 .</head><label>4</label><figDesc>Comparison of test errors on CIFAR-100 dataset</figDesc><table><row><cell>Method</cell><cell>Error (%)</cell></row><row><cell>Stochastic pooling</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 6 .</head><label>6</label><figDesc>Comparison of test errors on CIFAR-10 dataset without data augmentation using max/average pooling in the first two pooling layers</figDesc><table><row><cell>Method</cell><cell>Test error (%)</cell></row><row><cell>MIN (k=5) + max pooling</cell><cell>8.78</cell></row><row><cell>MIN (k=5) + avg pooling</cell><cell>7.85</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Normalization as a canonical neural computation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Carandini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Heeger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Reviews Neuroscience</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="51" to="62" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR09</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Neural mechanisms of selective visual attention. Annual review of neuroscience</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Desimone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Duncan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="193" to="222" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Effects of noise letters upon the identification of a target letter in a nonsearch task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">A</forename><surname>Eriksen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">W</forename><surname>Eriksen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception &amp; psychophysics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="143" to="149" />
			<date type="published" when="1974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Information processing in visual search: A continuous flow conception and experimental results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">W</forename><surname>Eriksen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">W</forename><surname>Schultz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception &amp; Psychophysics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="249" to="263" />
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Understanding the difficulty of training deep feedforward neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on artificial intelligence and statistics</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Maxout networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th International Conference on Machine Learning (ICML 2013</title>
		<meeting>the 30th International Conference on Machine Learning (ICML 2013</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="1319" to="1327" />
		</imprint>
	</monogr>
	<note>JMLR.org</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Pre-and poststimulus activation of response channels: a psychophysiological analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gratton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G</forename><surname>Coles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Sirevaag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">W</forename><surname>Eriksen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Donchin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Human perception and performance</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">331</biblScope>
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Parametric reverse correlation reveals spatial linearity of retinotopic human v1 bold response</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">A</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">V</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Gallant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="233" to="241" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Improving neural networks by preventing co-adaptation of feature detectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<idno>abs/1207.0580</idno>
		<imprint>
			<date type="published" when="2012" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
	<note>JMLR.org</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Gradientbased learning applied to document recognition. Proceedings of the IEEE</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Deeplysupervised nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Gallagher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AISTATS 2015</title>
		<meeting>AISTATS 2015</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Recurrent convolutional neural network for object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">On the importance of normalisation layers in deep learning with piecewise linear activation units</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Carneiro</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1508.00330</idno>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<idno>abs/1312.4400</idno>
		<title level="m">Network in network. International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Rectifier nonlinearities improve neural network acoustic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Maas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Hannun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">On the number of linear regions of deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">F</forename><surname>Montufar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2924" to="2932" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Rectified linear units improve restricted boltzmann machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Machine Learning (ICML 2010)</title>
		<meeting>the 27th International Conference on Machine Learning (ICML 2010)</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Reading digits in natural images with unsupervised feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Netzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bissacco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS workshop on deep learning and unsupervised feature learning</title>
		<meeting><address><addrLine>Granada, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">2011</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Convolutional neural networks applied to house numbers digit classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21th International Conference on Pattern Recognition (ICPR 2012)</title>
		<meeting>the 21th International Conference on Pattern Recognition (ICPR 2012)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="3288" to="3291" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Improving predictive inference under covariate shift by weighting the log-likelihood function</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Shimodaira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of statistical planning and inference</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="227" to="244" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Dropout: A simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lenc</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.4564</idno>
		<title level="m">Matconvnet-convolutional neural networks for matlab</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Regularization of neural networks using dropconnect</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zeiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">L</forename><surname>Cun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th International Conference on Machine Learning (ICML 2013</title>
		<meeting>the 30th International Conference on Machine Learning (ICML 2013</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">From maxout to channel-out: Encoding information on sparse pathways</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jaja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial Neural Networks and Machine Learning-ICANN 2014</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="273" to="280" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Zeiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3557</idno>
		<title level="m">Stochastic pooling for regularization of deep convolutional neural networks</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Visualizing and understanding convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Zeiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision-ECCV 2014</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="818" to="833" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
