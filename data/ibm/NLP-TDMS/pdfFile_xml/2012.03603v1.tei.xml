<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Ada-Segment: Automated Multi-loss Adaptation for Panoptic Segmentation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gengwei</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Sen University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Gao</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Sen University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Xu</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Huawei Noah&apos;s Ark Lab</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Zhang</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenguo</forename><surname>Li</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Huawei Noah&apos;s Ark Lab</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodan</forename><surname>Liang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Sen University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Ada-Segment: Automated Multi-loss Adaptation for Panoptic Segmentation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T20:44+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Panoptic segmentation that unifies instance segmentation and semantic segmentation has recently attracted increasing attention. While most existing methods focus on designing novel architectures, we steer toward a different perspective: performing automated multi-loss adaptation (named Ada-Segment) on the fly to flexibly adjust multiple training losses over the course of training using a controller trained to capture the learning dynamics. This offers a few advantages: it bypasses manual tuning of the sensitive loss combination, a decisive factor for panoptic segmentation; it allows to explicitly model the learning dynamics, and reconcile the learning of multiple objectives (up to ten in our experiments); with an end-to-end architecture, it generalizes to different datasets without the need of re-tuning hyperparameters or readjusting the training process laboriously. Our Ada-Segment brings 2.7% panoptic quality (PQ) improvement on COCO val split from the vanilla baseline, achieving the state-of-theart 48.5% PQ on COCO test-dev split and 32.9% PQ on ADE20K dataset. The extensive ablation studies reveal the ever-changing dynamics throughout the training process, necessitating the incorporation of an automated and adaptive learning strategy as presented in this paper.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Capitalized on advances from traditional semantic segmentation and instance segmentation, the vision community recently steps forward to resolve a more challenging task, panoptic segmentation <ref type="bibr" target="#b20">(Kirillov et al. 2018)</ref>, which targets at simultaneously segmenting both foreground instance things (e.g., person, car and dog) and background semantic stuff (e.g., sky, river and sea), achieving a more unified understanding of images. Hence, panoptic segmentation is usually formulated as a multi-objective problem for jointly optimizing for semantic and instance segmentation. To solve this problem, many existing methods <ref type="bibr" target="#b19">(Kirillov et al. 2019;</ref><ref type="bibr" target="#b38">Xiong et al. 2019;</ref><ref type="bibr" target="#b31">Porzi et al. 2019;</ref>) have designed multi-branched network architectures, while each branch mapping to an instance or semantic segmentation objective and resulted in many (up to ten in our experiments) individual losses that need to be reconciled during training.  <ref type="figure">Figure 1</ref>: Our Ada-Segment aims at automatically adjusting the weights of multiple objectives in panoptic segmentation during training for achieving the balanced learning dynamics, in contrast to existing works that rely on carefully handtuned weights after tediously re-training multiple times. It adjusts the training loss every training epochs on the fly via a weight controller within a single training procedure. Ada-Segment can achieve remarkably better results than results without loss tuning and also perform significant better than other hyperparameter tuning methods.</p><p>Various network modules or fusing strategies <ref type="bibr" target="#b19">(Kirillov et al. 2019;</ref><ref type="bibr" target="#b38">Xiong et al. 2019;</ref><ref type="bibr" target="#b28">Liu et al. 2019;</ref><ref type="bibr" target="#b22">Lazarow et al. 2020)</ref> have been proposed to deal with the consistency of learning or predictions from instance segmentation and semantic segmentation branches. As reported in many literatures <ref type="bibr" target="#b19">(Kirillov et al. 2019;</ref><ref type="bibr" target="#b38">Xiong et al. 2019)</ref>, the performance of a panoptic segmentation architecture exhibits extreme sensitivity and variability with respect to the multi-objective loss weights. Therefore, previous works relied on exhaustive hyper-parameter search over such weights. For example, Panoptic FPN <ref type="bibr" target="#b19">(Kirillov et al. 2019</ref>) uses a grid search to find better loss weights on two datasets; UPSNet <ref type="bibr" target="#b38">(Xiong et al. 2019</ref>) carefully investigates the weighting scheme of loss functions. In our experiments, different loss weights may yield 2% performance difference (measured in PQ). It is thus hard to disentangle the advantages of an improved method from a better hyperparameter setting.</p><p>Moreover, previous works only apply static loss weights throughout the training, skipping chances for the appropriate adaptation to the dynamically-varying convergence be-haviors, as observed in our experiments. Finally, hand-tuned loss weights, whenever changing to a different dataset, must be carefully re-tuned, prohibiting the generalization across different data distributions.</p><p>To address these limitations, we present Ada-Segement, an efficient automated multi-loss adaptation framework to dynamically adjust the loss weight with respect to each sub-objective, seeking an improved optimization schedule during training. In <ref type="figure">Figure 1</ref>, Ada-Segment introduces an end-to-end weight controller to automatically generate loss weights to adjust model's training loss. Departing from fixing a group of static weights during training, Ada-Segment adjusts the loss weights based on the training conditions with the weight controller. Specifically, the weight controller is firstly trained with several models training in parallel. It gathers training information from all models after a few training iterations (e.g., an epoch) and produces new weights for training. Besides, we find the trained controller is of the capability to capture the ever-changing training dynamics so that we can directly re-use it to automatically adjust training loss when training models on different datasets, training schedules and backbone networks.</p><p>Our main contributions are summarized as follows: <ref type="formula" target="#formula_1">(1)</ref> We propose Ada-Segment as a framework to automatically balance the multiple objectives in panotpic segmentation, bypassing tedious manual tuning of loss combination weights. (2) We introduce a novel weight controller within the multi-loss adaptation strategy that can capture the learning dynamics to adjust the loss weights during training, which is of the capability to transfer between different backbone network, training schedule and datasets. 3) We empirically demonstrate the significance of the convergence dynamics in panoptic segmentation model training.</p><p>(4) Ada-Segment significantly outperforms previous stateof-the-art methods on COCO test-dev dataset with 48.5% PQ and ADE20K with 32.9% PQ, and brings 2.7% panoptic quality (PQ) improvement on COCO val split. Extensive ablation studies verify the importance of automated multi-loss adaptation and the generalizability of the framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Related Work</head><p>Panoptic Segmentation. The recently proposed panoptic segmentation task <ref type="bibr" target="#b20">(Kirillov et al. 2018</ref>) departs from traditional multi-task problem <ref type="bibr" target="#b34">(Tu et al. 2005;</ref><ref type="bibr" target="#b9">Farhadi et al. 2009</ref>) by introducing a unified task with meticulously designed task metrics, which requires algorithms to output unified results in a single model. Several works <ref type="bibr" target="#b19">(Kirillov et al. 2019;</ref><ref type="bibr" target="#b31">Porzi et al. 2019</ref>) approach this problem via combining well-developed instance segmentation models ) with a semantic segmentation decoder, and fusing the results together <ref type="bibr" target="#b19">Kirillov et al. 2019;</ref><ref type="bibr" target="#b31">Porzi et al. 2019)</ref>. Besides, some works improve the interaction between sub-tasks through reasoning modules <ref type="bibr" target="#b36">(Wu et al. 2020a)</ref>, attention mechanisms <ref type="bibr" target="#b4">(Chen et al. 2020;</ref><ref type="bibr" target="#b25">Li et al. 2019b)</ref>, unified head <ref type="bibr" target="#b38">(Xiong et al. 2019)</ref>, automated neural architecture search <ref type="bibr" target="#b37">(Wu et al. 2020b)</ref> or even deploy a bottom-up approach . However, none of them have developed an effective or automated way to alleviate the imbalance caused by multiple subtasks; Instead, they spend a numerous amount of time trying to adjust the loss weights by hand. In this work, we aim at tackling this problem with an automated adaptation strategy. Multi-objective Learning. Panoptic Segmentation is a unified computer vision task derived from multi-objective learning. However, when lacking systematic treatments, using a single model to handle multiple tasks may downgrade the performance (Kokkinos 2017) of the target task. Some optimization technics are proposed by previous works <ref type="bibr" target="#b17">(Kendall et al. 2018;</ref><ref type="bibr" target="#b5">Chen et al. 2017)</ref>, however, they are still unstable and even lead to divergence. Accordingly, for panotpic segmentation, some works <ref type="bibr" target="#b38">(Xiong et al. 2019;</ref><ref type="bibr" target="#b19">Kirillov et al. 2019;</ref><ref type="bibr" target="#b28">Liu et al. 2019</ref>) try to manually find weights to adjust the training process and balance among subtasks, expecting to get higher performance, which, however, is time-intensive and cannot generalize across datasets -a problem that this paper tries to address. Adaptive Learning. Adaptive learning is a widely researched topic. Curriculum Learning <ref type="bibr" target="#b1">(Bengio et al. 2009;</ref><ref type="bibr" target="#b27">Lin et al. 2018;</ref><ref type="bibr" target="#b32">Ren et al. 2018)</ref> proposes to gradually increase the difficulty of training samples during training. Along this line, closest to ours is AutoLoss <ref type="bibr" target="#b39">(Xu et al. 2018)</ref>, which uses reinforcement learning to learn update schedules in alternate optimization problems. Hyperparameter Tuning. Hyperparameter tuning is of a long history <ref type="bibr" target="#b10">(Feurer and Hutter 2019)</ref>. Traditional samplebased methods like grid or random search are computationally costly. PBT <ref type="bibr" target="#b16">(Jaderberg et al. 2017)</ref> partly relieves this problem by tuning hyperparameters during training but cannot achieve satisfactory results. Bayes Optimization-based methods like GP-BO <ref type="bibr" target="#b33">(Snoek et al. 2012)</ref> and SMAC <ref type="bibr" target="#b15">(Hutter et al. 2011)</ref> utilize Bayes Optimization to achieve better tuning performance but are also computationally inefficient. BOHB <ref type="bibr" target="#b8">(Falkner et al. 2018</ref>) proposes a more efficient BO-based method that combines Bayes Optimization with Hyperband ) to accelerate to the searching process. However, it is not applicable for searching hyperparameters dynamically. Gradient-based methods <ref type="bibr" target="#b41">(Zeiler 2012;</ref><ref type="bibr" target="#b0">Baydin et al. 2017;</ref><ref type="bibr" target="#b30">Pedregosa 2016)</ref> benefit the tuning of some hyperparameters like learning rate during training but are hard to generalize well to the scenario of multiobjective weighting. RL-based methods like ) designs specific search space for parameters within classification and metric learning loss functions, which cannot generalize to the scenario of multi-objective weighting; AM-LFS <ref type="bibr" target="#b23">(Li et al. 2019a</ref>) directly tunes specific hyperparameters with greedy strategy, which ignores the training conditions and results in a sub-optimal solution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Automated Online Multi-loss Adaptation Overview</head><p>The common architectures <ref type="bibr" target="#b19">(Kirillov et al. 2019;</ref><ref type="bibr" target="#b38">Xiong et al. 2019)</ref> tackle panoptic segmentation using a multi-objective model with several additional losses (e.g., losses from box head, segmentation head etc.). Given the loss vector l ∈ R n and their corresponding loss weight vector λ ∈ R n where n is the number of training losses, we define the weighted loss of our panoptic segmentation framework as L =</p><formula xml:id="formula_0">n i=1 λ i l i . Λ +1 1 with 1 Training in Parallel Model Eval Best model 1 2 2 with 2 with checkpoint t Training timeline t =1 t =2 t t =T-1 t =T q iters</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Automated Exploration and Adaptation</head><p>Weight Controller +1 = +1~( +1 ) <ref type="figure">Figure 2</ref>: Illustration of the Automated Exploration and Adaptation in our Ada-Segment framework. It views the whole training process as a series of checkpoints ( T checkpoints in total). The weight controller is trained interactively with m models trained in parallel and evaluated at each checkpoint.</p><p>As stated previously, multi-loss weighting is essential but difficult in panotpic segmentation. Inspired by the adaptive learning and automated machine learning methods, the goal of our automated multi-loss adaptation (named Ada-Segment) framework is to automatically adjust λ during training via a controller. As <ref type="figure">Figure 2</ref> shows, the controller is jointly trained with m models (i.e., panotpic segmentation networks) {M 1 , M 2 , ..., M m } training in parallel on a proxy training dataset (training set in short). After that, it can be used for controlling single model training at anytime.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Weight Controller</head><p>The weight controller is proposed to capture the training dynamics and automatically adjust loss weights during training. At the t th checkpoint, suppose the network produces the loss vector l t , and we want to find a weight vector λ t+1 to adjust the loss value so that the weighted loss can guide the network towards better optimization. Directly determine λ is impossible since we have no prior about it. However, since we know that the weighted loss vector is formulated as η t = λ t+1 l t where is the element-wise multiplication. We introduce the weight controller to estimate the weighted loss vector as the transformation of the current loss vector as η t = π(l t ; θ), where θ is the learnable parameter in the weight controller π. Therefore, we can obtain the weight vector λ t+1 by</p><formula xml:id="formula_1">λ t+1 = η t l t = π(l t ; θ) l t .<label>(1)</label></formula><p>Weight Controller Optimization. In this work, we use a policy network as the weight controller to predict the estimated weighted loss based on the loss at each time checkpoint. Since the loss weights directly determine the training loss, it may get into a dilemma if we use training loss to optimize the policy network through backpropagation. Some optimization technics are proposed by previous works <ref type="bibr" target="#b17">(Kendall et al. 2018;</ref><ref type="bibr" target="#b5">Chen et al. 2017)</ref>, however, they are still unstable and even lead to divergence when directly using training gradients to optimize weights on complex tasks like panoptic segmentation. Therefore, we optimize the policy network towards the evaluation metric (i.e., PQ in panoptic segmentation) via the validation set through REINFORCE <ref type="bibr" target="#b35">(Williams 1992)</ref>. State Space: During training, at any time checkpoint t, the policy network takes the loss vector l t to represent the optimization state of the model, and outputs the estimated weighted loss η t to calculate λ t+1 .</p><p>Action Space: Exploration is of great importance to find improved solution via an action space design. We sample</p><formula xml:id="formula_2">loss weight candidatesΛ t+1 = {λ t+1 1 ,λ t+1 2 , ...,λ t+1 m } to train m models from a Normal distribution λ t+1 ∼ N (λ t+1 , σ),<label>(2)</label></formula><p>in which λ t+1 is uesd as the mean value and σ is the sampling standard deviation. Rewards: Reward function r(·) measures the quality of the generated actions. Intuitively, after applying the actions, we can use the models' performances (PQ) as the policy rewards to guide the training of the policy network. We refer this as the local reward function</p><formula xml:id="formula_3">r local (v t ) = v t − mean(v t ) std(v t ) ,<label>(3)</label></formula><p>which normalizes the validation performances v t ∈ R m at checkpoint t to zero mean and unit variance as rewards. Furthermore, we include the relative improvement from the previous checkpoint as the policy rewards:</p><formula xml:id="formula_4">r imp (v t imp ) = v t imp std(v t imp ) ,<label>(4)</label></formula><p>which calculates the normalized absolute improvement from the previous checkpoint to introduce long-range influences</p><formula xml:id="formula_5">where v t imp = v t − v t−1</formula><p>best . This is non-trivial because only using the differences between temporal samples would overlook the training dynamics between checkpoints.</p><p>Therefore, the overall rewards are calculated as</p><formula xml:id="formula_6">r(v t ) = t T (r local (v t ) + r imp (v t imp )),<label>(5)</label></formula><p>where the scale factor t T controls the magnitude of the overall reward according to the training process since the early training stages are less important with more randomness.</p><p>Parameter Updates: Given the sample rewards, the parameter θ of the policy network π is updated by the gradients</p><formula xml:id="formula_7">∇ θ R t (θ) = 1 m m j=1 r t j (v t )∇ θ log s(λ t+1 j ; π(l t ; θ) l t , σ),<label>(6)</label></formula><p>where s(·; µ, σ) is the probability density function of the Normal distribution. It is worth noting that we only consider the situation that all loss values are nonnegative, which is the common scenario in panoptic segmentation. Therefore, when sampling from the Normal distribution, samples contain negative values would be given −1 as the reward directly to increase the training stability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ada-Segment Algorithm</head><p>In this section, we introduce how the overall Ada-Segment framework works in detail. Initial State. Since the policy network requires training losses as input. At the very beginning, one pseudo training epoch is performed with all loss weights equal to 1 before the exact training schedule to obtain the initial loss l 1 . Policy Initilaization The initial policy is crucial for training stability. All layers in the policy network are randomly initialized by the Normal distribution with mean value equal to 1/n c instead of 0 to avoid the loss weights to be non-positive at the beginning (except the bias parameters is initialized to 0), where n c is the number of input channels of each layer. Automated Exploration and Adaptation. In this phase, the controller and m models are jointly trained as shown in <ref type="figure">Figure 2</ref>. Between two checkpoints, we train models in parallel with separate loss weights generated by the weight controller and track the training losses. At each checkpoint, we evaluate all models on the validation set, obtaining the model performances v t (i.e., PQ value on validation for panoptic segmentation) to calculate rewards following Equatin 5. The policy network is updated by gradients descent via Equation 6. To continue training, we broadcast the bestperformed model to all other models, thus we can use l t best as the training condition at each time checkpoint. Policy Transfer. We can get the best-performed model M T best after the exploration phase. However, we take it a step further and propose the policy transfer. Our framework, once finished one exploration process, also produces the trained controller that gives us the chance to re-use it at anytime, saving the time and computational cost when the dataset or training schedule changes.</p><p>Along with the training of the model, the policy network is changing accordingly, causing the policy π T may favor the latest training condition but partly forget former loss situations. Besides, earlier states of policy may suffer from the under-fitting problem with few update iterations. Therefore, to make full use of the controller, we proposed to combine all states of the policy network during exploration phase i.e., π 1 to π T , via a weighted policy ensemble strategy.</p><p>When training a model M p for E epochs and adjusting loss weights every training epoch, with E is not necessary to be equal to T . By calculating the distance between a training epoch e and corresponding update checkpoint t, we can assign a weight to each policy state at different training epochs controlled by a discount factor γ = 0.9. Therefore, we have</p><formula xml:id="formula_8">λ e+1 = 1 Z T t γ | e×T E −t| π t (l e ; θ) l e ,<label>(7)</label></formula><p>where T E align the training procedure with the number of exploration checkpoints and Z = T t γ | e×T E −t| is the normalizing factor. By combining policy states at different stages, the training dynamics captured by the policy network can be preserved to a large extend. To sum up, the paradigm of our Ada-Segment is summarized in Algorithm 1. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Class Loss Class Loss Box Loss Class Loss</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Class Loss Box Loss Class Loss</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Class Loss Box Loss</head><p>Semantic Head</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Class Loss</head><p>Merge <ref type="figure">Figure 3</ref>: The network structure of our baseline. For detection branch, we use the three-stage Cascade R-CNN <ref type="bibr" target="#b2">(Cai and Vasconcelos 2018)</ref>, which contains three pairs of losses. The semantic segmentation branch is a simple SemanticFPN in <ref type="bibr" target="#b19">(Kirillov et al. 2019</ref>). The overall architecture has ten losses to be jointly optimized. <ref type="figure">Figure 3</ref> shows the network structure used in our experiments, which extends Cascade Mask R-CNN (Cai and Vasconcelos 2018) with a semantic segmentation branch. Backbone Networks. We use a ResNet <ref type="bibr" target="#b12">(He et al. 2015a</ref>) with a Feature Pyramid Network (FPN) . and add deformable convolution <ref type="bibr" target="#b7">(Dai et al. 2017)</ref> in stage 3 ∼ 5 of the backbone networks. Instance Segmentation Head. We use three cascaded detection heads after region proposal network in our network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Network Structure</head><p>To get the instance segmentation results, each stage of head outputs bounding box regression, classification and mask results for objects in an image. Semantic Segmentation Head. We use a semantic segmentation head following Panotic FPN <ref type="bibr" target="#b19">(Kirillov et al. 2019</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiments</head><p>Datasets and Evaluation COCO. Following the competition setting in 2019 Microsoft COCO panoptic segmentation, which consists of 133 classes with 80 things classes and 53 stuff classes. We only use train2017 split with approximately 118k images for training and report the results on val split with 5k images. We also report our results on COCO test-dev split for comparison with other state-of-the-art methods. ADE20K. ADE20K is a challenging dataset with densely labeled 22k images, with 100 things classes and 50 stuff classes. It contains heavier occlusions, more tiny objects and class ambiguities than COCO, and thus more challenging. Proxy Dataset Setting. In the practice of automated machine learning, for evaluation during training, it is necessary to construct a proxy validation dataset instead of using the original validation set. For COCO, we randomly sample 10k images from the 118k training set for validation and the rest part as the proxy training set. For ADE20K, we train on 20k training images in which 2k images are randomly sampled images for validation during training. Evaluation Setup. We follow the panoptic segmentation evaluation metrics proposed in <ref type="bibr" target="#b20">(Kirillov et al. 2018</ref>) to evaluate our models in terms of panoptic quality (PQ), segmentation quality (SQ) and recognition quality (RQ). Note that PQ is the weighted sum of PQ th and PQ st for things and stuff classes respectively. We report these two metrics for demonstrating the effectiveness of our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Implementation Details</head><p>Model Training. We follow the commonly used hyperparameter settings as stated in Panoptic FPN (Kirillov et al. 2019) within our experiments. We set the initial learning rate as 0.02 and weight decay as 0.0001 with stochastic gradient descent (SGD) for all experiments. To provide more stable information to train the policy network, we decrease learning rate with cosine policy, which is more smooth than decrease the learning rate at specific iterations. We initialize the backbone network with ImageNet pretrained model while the remaining parameters are initialized following <ref type="bibr" target="#b13">(He et al. 2015b</ref>). For each model, we train totally 12 epochs (so called 1x setting) for COCO and 24 epochs for ADE20K on 8 GPUs with 2 images per GPU using PyTorch <ref type="bibr" target="#b29">(Paszke et al. 2017)</ref>. Automated Multi-loss Adaptation. During joint training, we deploy m = 8 models, where each model contains n = 10 losses: three pairs of instance detection losses (bounding box loss, classification loss and mask loss) and a single semantic segmentation loss. In the weight controller, we set the sampling standard deviation σ = 0.2, and we use three-layer MLP with hidden layer size 16 as the policy network. We use Adam (Kingma and Ba 2014) optimizer with learning rate 5e −2 and weight decay 5e −4 to optimize the policy network. For the overall Ada-Segement framework, we simply train 1 Epoch between two checkpoints for both COCO and ADE20K datasets. When adjusting loss weight, we re-scale the learning rate of the i th head by 1 λi for i = 1, 2, ..., n to ensure the head networks to be fully trained so that the loss weights only influence the shared backbone and the detection losses are averaged among three cascade stages. Inference. The panoptic results are obtained in the way proposed in <ref type="bibr" target="#b20">(Kirillov et al. 2018)</ref>. Specifically, after merging instance masks on the non-overlap canvas, the remaining pixels are assigned according to semantic segmentation results (with areas less than 4096 being ignored). Baseline Setup. The baseline method means setting equaling weights (with value 1) during training. As to be shown in the following sections, although a strong baseline network is used, it only produces unsatisfactory results, which is inhibited by the improper weight setting. Without particular notions, we report results with ResNet-50 backbone.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ablation Studies</head><p>Main Results. We compare with different baselines in Table 1. Compared with the vanilla baseline using all weights equal to 1, our method achieves 43.7% PQ, bringing 2.7% performance gain. One may argue that whether the vanilla   <ref type="table">Table 4</ref>: Multi-loss adaptation for Panoptic FPN <ref type="bibr" target="#b19">(Kirillov et al. 2019</ref>) on COCO, †: our re-implementation with all loss weights equal to 1; ‡: our re-implementation with loss weights used in the paper; : results reported in the paper.</p><p>baseline is appropriate since we introduce more computational cost and the vanilla weight setting may have bias on different network structures. Therefore, we provide an alternate baseline named baseline-G following the way used in <ref type="bibr" target="#b19">(Kirillov et al. 2019)</ref>, which treats detection losses as a single group and performs grid search on detection and segmentation loss weights. It can be seen that our Ada-Segment also achieves 1.5% performance gains. Effectiveness of Weight Controller. To validate the effectiveness of the weight controller, in the top part of Table 1, we remove the weight controller to see whether it could work well when only synchronize all models at each time checkpoints with different loss weights generated by an evolution strategy. This setting resembles Population Based Training <ref type="bibr" target="#b16">(Jaderberg et al. 2017)</ref>, and is also used as a baseline named by baseline-P. The results suggest that the controller contributes most in the loss weights adaption.</p><p>Besides, we can obtain the best-performed model M T best after Automated Exploration and Adaptation phase. We also report the performance of M T best as Ada-Segment-A in table 1, which can already brings 1.9% PQ gain compared with the vanilla baseline and outperforms baseline-G by 0.9%. When train model with the controller using policy ensemble, additional 0.6% performance gain is obtained, demonstrating that the controller did learn the potential training pattern and benefit the model training. Superiority of Training Dynamics. Different from the a static weighting strategy, we leverage the weight controller to dynamically adjust training loss weights. One may have the question that whether it is enough to use the policy net-work to give a static weight setting that benefits the whole training process. We validate this concern by trying the following settings: 1) Final: training with the final loss weights λ T best of the Exploration and Adaptation phase. 2) Pred: using the final policy network to predict a static loss weights (based on the initial loss) to train the model. 3) Single-dy: using the final policy network to guide the training process. 4) Comb-dy: using the weight controller with the policy ensemble strategy during the training process.</p><p>The results in <ref type="table">Table 2</ref> demonstrate the significant advantage of dynamically adapting the loss weights during training. Using policy ensemble to combine all states of policy networks improves the final state of policy network π T by 0.6%. This is not surprising since the policy network is continuous updating in the exploration phase, and the final state may not well suite for the begining stages. It also suggests that there do exists ever-chaning convergence dynamics during panoptic model training. Generalization Capability across Network Structures. The main results of our method are carried our on a welldeveloped network to show the problem that loss weighting inhibits the network-level design. One may curios about whether our framework can also work well on a simple network with less losses. To validate the generalization capability of our framework, we apply our Ada-Segment strategy to the simple Panoptic FPN <ref type="bibr" target="#b19">(Kirillov et al. 2019)</ref>, which uses Mask R-CNN ) as base detector with three detection losses (bounding box regression / classification, mask segmentation losses) and uses the same segmentation head as used in our network, and the results are shown in <ref type="table">Table 4</ref>.</p><p>It can be seen that although the network contains fewer losses than the network used in our method (4 vs 10 losses), the imbalance problem is also serious since it degrades 0.9% PQ and 2.3% PQ th . With our Ada-Segment, we boost the performance of both PQ th and PQ st and improve the final performance by 1.8% PQ from the vanilla weighting and 0.9% from the well-tuned baseline. Policy Transferability. In <ref type="table" target="#tab_4">Table 3</ref>, we evaluate the transferability of the policy network on different backbones, training schedules and datasets. It can be found that, 1) the policy benefits model training when transfer from ADE20K to COCO. 2) Policy from COCO also has a positive effect on    <ref type="bibr" target="#b8">(Falkner et al. 2018</ref>), on COCO val set based on our baseline network (R-50 backbone). G: Gradient-Based, S: Sample-Based B: BO-Based, R: RL-guided. We ran Ada-Segment 3 times with different random seeds and report in format of mean±std. ADE20K (32.0% vs. 31.6% baseline) and comparable with grid-search baseline (32.1%). 3) Policy trained along with small backbone network also works well on larger backbone. 4) Policy obtained from short training schedule can also be apply on longger training schedule, suggesting that the training dynamics of different training schedules are similar. Reward Function Design. When only using r local as rewards, the controller learns from the relative differences between sampled actions but overlooks the training dynamics between checkpoints, which only get 42.6% PQ finnally. With r imp , the controller is trained much well to get 43.7% PQ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Comparison with other methods</head><p>Panoptic Segmentation on COCO. We compare our proposed network with other state-of-the-art methods on COCO test-dev split in <ref type="table" target="#tab_6">Table 5</ref>. With the proposed method, we achieve the PQ performance 48.5%, which is the state-ofthe-art results produced by a single model without extra training data. It is worth noting that although our method does not report top performance on neither PQ th nor PQ st on test-dev set, we achieve the best things-stuff trade-off to get best final PQ results with our Ada-Segment to reconcile Image Baseline Ours <ref type="figure">Figure 4</ref>: Qualitative comparison of the results produced by our baseline and the results using Ada-Segment for training. multiple subtask losses during training while previous works may favor one of the metrics and degrade another. Automated Tuning Methods. Our method can be seen as an online hyperparameter tuning framework. In <ref type="table" target="#tab_7">Table 6</ref>, we compare our Ada-Segment with different types of automated tuning methods to show the practicability and effectiveness of our method. Grid search and PBT <ref type="bibr" target="#b16">(Jaderberg et al. 2017)</ref> are used as special baselines of as showed in the previous sections. GradNorm <ref type="bibr" target="#b5">(Chen et al. 2017</ref>) is an effective multi-objective learning method that adjusts subtask gradients during back-propagation. We implement AM-LFS <ref type="bibr" target="#b23">(Li et al. 2019a</ref>) to directly optimize the loss weights, which performs poorly on P Q st , which suggests that our weight controller perfors much better than the greedy optimization.</p><p>Besides, when treating the loss weights as hyperparameters, we compare with BOHB <ref type="bibr" target="#b8">(Falkner et al. 2018)</ref>, the stateof-the-art hyperparameter optimization method, which performs much worse than our automated adaptation strategy since it only searches for a static parameter setting, missing the chance to adjust losses at different training stages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Qualitative Results</head><p>In <ref type="figure">Figure 4</ref>, the results produced by our method are visually precise and coherent for both foreground objects and background stuff and the results output by our baseline contain some fuzzy part due to inappropriate training. More qualitative results can be found in the Appendix.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Algorithm 1 The Ada-Segment framework. Input: Iterations between two checkpoints q, Initial Loss State l 1 , Number of checkpoints T , Number of training epochs E Initialize m models {M 1 , M 2 , ...M m }</figDesc><table><row><cell>Initialize policy network π</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>l 1 best ← l 1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">for t ← 1 to T , do Generate λ t+1 by Equation 1 with π and l t best Sample m candidates by Equation 2 with λ t+1</cell></row><row><cell cols="6">Train all models for q iterations withΛ t+1 Collect model performances v t and save l t best</cell></row><row><cell cols="5">Obtain policy rewards by Equation 5</cell><cell></cell></row><row><cell cols="2">Update θ in π via Equation 6</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Save π t ← π</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">Update all models with M t best end for</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Initialize a model M p</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">for e ← 1 to E, do Generate λ e+1 by Equation 7 with l e</cell><cell></cell></row><row><cell cols="2">Train model M p with λ e+1</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>end for</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>return M p</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>M1</cell><cell>B1</cell><cell>M1</cell><cell>B1</cell><cell>M1</cell><cell>B1</cell></row><row><cell>Backbone Network</cell><cell>Pool</cell><cell>Pool</cell><cell></cell><cell>Pool</cell><cell></cell></row><row><cell>RPN</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Panoptic Output</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>+1.0 48.7 +1.6 31.1 +0.1 Baseline-P COCO p 41.1 +0.4 48.8 +1.7 29.4 −1.6 Ada-Segment-A COCO p 42.6 +1.9 49.5 +2.4 32.1 +1.1 Ada-Segment COCO p 43.2 +2.5 50.5 +3.4 32.3 +1.3</figDesc><table><row><cell>Method</cell><cell>training set</cell><cell>PQ</cell><cell>PQ th</cell><cell>PQ st</cell></row><row><cell>Baseline</cell><cell>COCO p</cell><cell>40.7</cell><cell>47.1</cell><cell>31.0</cell></row><row><cell cols="3">Baseline-G COCO p 41.7 Baseline COCO 41.0</cell><cell>47.2</cell><cell>31.5</cell></row><row><cell>Baseline-G</cell><cell cols="4">COCO 42.1 +1.1 49.0 +1.8 31.6 +0.1</cell></row><row><cell>Ada-Segment</cell><cell cols="4">COCO 43.7 +2.7 51.2 +4.0 32.5 +1.0</cell></row><row><cell cols="5">Table 1: Comparison with different baselines on COCO</cell></row><row><cell cols="5">val split. All models are trained on the proxy training</cell></row><row><cell cols="5">set. Baseline-G: using coarse grid search to optimize loss</cell></row><row><cell cols="5">weights with multiple runs. Baseline-P: applying a PBT-</cell></row><row><cell cols="5">like (Jaderberg et al. 2017) framework to tune loss weights</cell></row><row><cell cols="5">during training, which can be viewed as our method without</cell></row><row><cell cols="5">the weight controller. COCO p represents the proxy dataset.</cell></row><row><cell cols="5">and bi-linear upsample function to gradually upsample each</cell></row><row><cell cols="5">FPN feature to 1/4 of input image size. All upsampled fea-</cell></row><row><cell cols="5">tures are summed up and transformed into the final segmen-</cell></row><row><cell cols="2">tation map by a 1x1 convolution.</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>). It</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>takes the FPN features as inputs and uses 1x1 convolution</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Method Weighting Type PQ PQ th PQ st</figDesc><table><row><cell>Baseline</cell><cell>static</cell><cell>41.0 47.2 31.5</cell></row><row><cell>Baseline-G</cell><cell>static</cell><cell>42.1 49.0 31.6</cell></row><row><cell>Final</cell><cell>static</cell><cell>42.2 50.0 30.4</cell></row><row><cell>Pred</cell><cell>static</cell><cell>42.6 50.3 31.0</cell></row><row><cell>Single-dy</cell><cell>dynamic</cell><cell>43.1 50.1 32.4</cell></row><row><cell>Comb-dy</cell><cell>dynamic</cell><cell>43.7 51.2 32.5</cell></row><row><cell cols="3">Table 2: Comparison of different static weighting strategy</cell></row><row><cell cols="3">and different dynamical adaptation strategy on COCO.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>Train Arch. Trans. Arch Train Data Trans. Data Train. Sche. Tran. Sche. PQ PQ th PQ st</figDesc><table><row><cell>R-50</cell><cell>R-50</cell><cell>ADE20K p</cell><cell>COCO</cell><cell>1x</cell><cell>1x</cell><cell>42.7 49.0 33.1</cell></row><row><cell>R-50</cell><cell>R-50</cell><cell>COCO p</cell><cell>COCO</cell><cell>1x</cell><cell>1x</cell><cell>43.7 51.2 32.5</cell></row><row><cell>R-50</cell><cell>R-50</cell><cell>COCO p</cell><cell>ADE20K</cell><cell>1x</cell><cell>1x</cell><cell>32.0 34.3 27.4</cell></row><row><cell>R-50</cell><cell>R-50</cell><cell cols="2">ADE20K p ADE20K</cell><cell>1x</cell><cell>1x</cell><cell>32.9 35.6 27.9</cell></row><row><cell>R-50</cell><cell>R-101</cell><cell>COCO p</cell><cell>COCO</cell><cell>1x</cell><cell>1x</cell><cell>45.1 52.7 33.6</cell></row><row><cell>R-101</cell><cell>R-101</cell><cell>COCO p</cell><cell>COCO</cell><cell>1x</cell><cell>1x</cell><cell>45.2 52.2 34.7</cell></row><row><cell>R-50</cell><cell>R-50</cell><cell>COCO p</cell><cell>COCO</cell><cell>1x</cell><cell>2x</cell><cell>44.3 51.3 33.7</cell></row><row><cell>R-50</cell><cell>R-50</cell><cell>COCO p</cell><cell>COCO</cell><cell>2x</cell><cell>2x</cell><cell>44.4 50.9 34.5</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Transferability of the policy network across different backbones, training schedules and datasets. D p means searching and training on the proxy dataset. 1x: 12 epochs on COCO or 24 epochs on ADE20K; 2x: training for 24 epochs on COCO. +0.9 46.1 +2.3 28.3 −1.1 Panoptic FPN 39.0 +0.9 45.9 +2.1 28.7 −0.7 w Ada-Segment 39.9 +1.8 46.6 +2.8 29.7 +0.3</figDesc><table><row><cell>Method</cell><cell>PQ</cell><cell>PQ th</cell><cell>PQ st</cell></row><row><cell>Panoptic FPN  †</cell><cell>38.1</cell><cell>43.8</cell><cell>29.4</cell></row><row><cell cols="2">Panoptic FPN  ‡ 39.0</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 :</head><label>5</label><figDesc>Results on COCO test-dev split. In the table, '-D' represents methods using deformable convolution in the backbone networks. We achieve the best things-stuff trade-off to get best final PQ results. ±0.1 51.2 ±0.07 32.5 ±0.14 R ∼8x+1x</figDesc><table><row><cell>Method</cell><cell>PQ</cell><cell>PQ th</cell><cell cols="3">PQ st Type Cost</cell></row><row><cell>Baseline</cell><cell>41.0</cell><cell>47.2</cell><cell>31.5</cell><cell>-</cell><cell>1x</cell></row><row><cell>GradNorm</cell><cell>41.8</cell><cell>48.0</cell><cell>32.4</cell><cell>G</cell><cell>∼2x</cell></row><row><cell>Grid Search</cell><cell>42.1</cell><cell>49.0</cell><cell>31.6</cell><cell>S</cell><cell>∼20x</cell></row><row><cell>PBT</cell><cell>41.4</cell><cell>49.1</cell><cell>29.8</cell><cell>S</cell><cell>∼8x</cell></row><row><cell>AM-LFS</cell><cell>41.7</cell><cell>50.1</cell><cell>28.9</cell><cell>R</cell><cell>∼8x</cell></row><row><cell>BOHB</cell><cell>42.0</cell><cell>50.0</cell><cell>29.9</cell><cell>B</cell><cell>∼8x</cell></row><row><cell cols="2">Ada-Segment 43.7</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 6 :</head><label>6</label><figDesc>Comparison with different types of automated tuning methods on COCO val split, including GradNorm (Chen et al. 2017), Grid Search, PBT (Jaderberg et al. 2017), AM-LFS (Li et al. 2019a) and BOHB</figDesc><table /><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>In this work, we propose a novel automated online multiloss adaptation framework named Ada-Segment for panoptic segmentation. We emphasize the importance of dynamically adjusting the loss weights and propose the online multi-loss adaptation strategy with an effective and efficient weight controller, which achieves state-of-the-art performances on COCO and ADE20K panoptic segmentation benchmarks. We hope our work will give researchers in this area new insights to focus on the training level design.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Online learning rate adaptation with hypergradient descent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Baydin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cornish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Rubio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wood</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.04782</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Curriculum learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Louradour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th annual international conference on machine learning</title>
		<meeting>the 26th annual international conference on machine learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="41" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Cascade R-CNN: Delving into High Quality Object Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Vasconcelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cheng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.08787</idno>
		<title level="m">SpatialFlow: Bridging All Tasks for Panoptic Segmentation</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">BANet: Bidirectional Aggregation Network with Occlusion Handling for Panoptic Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Bourahla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="3793" to="3802" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Gradnorm: Gradient normalization for adaptive loss balancing in deep multitask networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Badrinarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rabinovich</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.02257</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-C</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.10194</idno>
		<title level="m">Panoptic-DeepLab: A Simple, Strong, and Fast Baseline for Bottom-Up Panoptic Segmentation</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Deformable convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="764" to="773" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Falkner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.01774</idno>
		<title level="m">BOHB: Robust and efficient hyperparameter optimization at scale</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Describing objects by their attributes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Endres</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hoiem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Forsyth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Hyperparameter optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Feurer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Automated Machine Learning</title>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3" to="33" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Mask r-cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gkioxari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2961" to="2969" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1512.03385</idno>
		<title level="m">Deep Residual Learning for Image Recognition</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Delving deep into rectifiers: Surpassing human-level performance on imagenet classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1026" to="1034" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Talbott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Bautista</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Guestrin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Susskind</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.05895</idno>
		<title level="m">Addressing the Loss-Metric Mismatch with Adaptive Loss Alignment</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Sequential model-based optimization for general algorithm configuration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">H</forename><surname>Hoos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Leyton-Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on learning and intelligent optimization</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="507" to="523" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jaderberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Dalibard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">M</forename><surname>Czarnecki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Razavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Dunning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.09846</idno>
		<title level="m">Population based training of neural networks</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Multi-task learning using uncertainty to weigh losses for scene geometry and semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kendall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cipolla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7482" to="7491" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kirillov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.02446</idno>
		<title level="m">Panoptic Feature Pyramid Networks</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kirillov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rother</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.00868</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">Panoptic segmentation. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Ubernet: Training a universal convolutional neural network for low-, mid-, and high-level vision using diverse datasets and limited memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kokkinos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6129" to="6138" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Learning instance occlusion for panoptic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lazarow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="10720" to="10729" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Am-lfs: Automl for loss function search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ouyang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8410" to="8419" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Hyperband: A novel bandit-based approach to hyperparameter optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Jamieson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Desalvo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rostamizadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Talwalkar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="6765" to="6816" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Attention-guided unified network for panoptic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Feature pyramid networks for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2117" to="2125" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Focal loss for dense object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">An End-to-End Network for Panoptic Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Automatic differentiation in PyTorch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lerer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS Workshop</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.02355</idno>
		<title level="m">Hyperparameter optimization with approximate gradient</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Seamless scene segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Porzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Bulo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Colovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kontschieder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8277" to="8286" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.09050</idno>
		<title level="m">Learning to reweight examples for robust deep learning</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Practical bayesian optimization of machine learning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Snoek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">P</forename><surname>Adams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="2951" to="2959" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Image parsing: Unifying segmentation, detection, and recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-C</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="113" to="140" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Simple statistical gradient-following algorithms for connectionist reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="229" to="256" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Bidirectional Graph Reasoning Network for Panoptic Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="9080" to="9089" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Auto-Panoptic: Cooperative Multi-Component Architecture Search for Panoptic Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yumer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.03784</idno>
		<title level="m">UPSNet: A Unified Panoptic Segmentation Network</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Xing</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.02442</idno>
		<title level="m">AutoLoss: Learning Discrete Schedules for Alternate Optimization</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.07527</idno>
		<title level="m">SOGNet: Scene Overlap Graph Network for Panoptic Segmentation</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Zeiler</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1212.5701</idno>
		<title level="m">Adadelta: an adaptive learning rate method</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Deformable convnets v2: More deformable, better results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9308" to="9316" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
