<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Session-based Recommendation with Graph Neural Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Wu</surname></persName>
							<email>shu.wu@nlpr.ia.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Automation</orgName>
								<orgName type="laboratory">Center for Research on Intelligent Perception and Computing National Laboratory of Pattern Recognition</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuyuan</forename><surname>Tang</surname></persName>
							<email>tangyyuanr@gmail.com</email>
							<affiliation key="aff2">
								<orgName type="department">School of Computer and Communication Engineering</orgName>
								<orgName type="institution">University of Science and Technology</orgName>
								<address>
									<settlement>Beijing</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanqiao</forename><surname>Zhu</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">School of Software Engineering</orgName>
								<orgName type="institution">Tongji University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Wang</surname></persName>
							<email>wangliang@nlpr.ia.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Automation</orgName>
								<orgName type="laboratory">Center for Research on Intelligent Perception and Computing National Laboratory of Pattern Recognition</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Xie</surname></persName>
							<email>xing.xie@microsoft.com</email>
							<affiliation key="aff4">
								<orgName type="institution">Microsoft Research Asia</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tieniu</forename><surname>Tan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Automation</orgName>
								<orgName type="laboratory">Center for Research on Intelligent Perception and Computing National Laboratory of Pattern Recognition</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Session-based Recommendation with Graph Neural Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T07:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The problem of session-based recommendation aims to predict user actions based on anonymous sessions. Previous methods model a session as a sequence and estimate user representations besides item representations to make recommendations. Though achieved promising results, they are insufficient to obtain accurate user vectors in sessions and neglect complex transitions of items. To obtain accurate item embedding and take complex transitions of items into account, we propose a novel method, i.e. Session-based Recommendation with Graph Neural Networks, SR-GNN for brevity. In the proposed method, session sequences are modeled as graphstructured data. Based on the session graph, GNN can capture complex transitions of items, which are difficult to be revealed by previous conventional sequential methods. Each session is then represented as the composition of the global preference and the current interest of that session using an attention network. Extensive experiments conducted on two real datasets show that SR-GNN evidently outperforms the state-of-the-art session-based recommendation methods consistently.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>With the rapid growth of the amount of information on the Internet, recommendation systems become fundamental for helping users alleviate the problem of information overload and select interesting information in many Web applications, e.g., search, e-commerce, and media streaming sites. Most of the existing recommendation systems assume that the user profile and past activities are constantly recorded. However, in many services, user identification may be unknown and only the user behavior history during an ongoing session is available. Thereby, it is of great importance to model limited behavior in one session and generate the recommendation accordingly. Conversely, conventional recommendation methods relying on adequate user-item interactions have problems in yielding accurate results under this circumstance.</p><p>Due to the highly practical value, increasing research interests in this problem can be observed, and many kinds of proposals for session-based recommendation have been developed. Based on Markov chains, some work <ref type="bibr">(Shani, Copyright © 2019</ref>, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. <ref type="bibr" target="#b19">Brafman, and Heckerman 2002;</ref><ref type="bibr" target="#b16">Rendle, Freudenthaler, and Schmidt-Thieme 2010)</ref> predicts the user's next behavior based on the previous one. With a strong independence assumption, independent combinations of the past components confine the prediction accuracy.</p><p>In recent years, the majority of research <ref type="bibr" target="#b4">(Hidasi et al. 2016a;</ref><ref type="bibr" target="#b22">Tuan and Phuong 2017;</ref><ref type="bibr" target="#b8">Li et al. 2017a)</ref> apply Recurrent Neural Networks (RNNs) for session-based recommendation systems and obtain promising results. The work <ref type="bibr" target="#b4">(Hidasi et al. 2016a</ref>) proposes a recurrent neural network approach at first, then the model is enhanced by data augmentation and considering temporal shift of user behavior . Recently, NARM <ref type="bibr" target="#b8">(Li et al. 2017a</ref>) designs a global and local RNN recommender to capture user's sequential behavior and main purposes simultaneously. Similar to NARM, STAMP ) also captures users' general interests and current interests, by employing simple MLP networks and an attentive net.</p><p>Although the methods above achieve satisfactory results and become the state-of-the-arts, they still have some limitations. Firstly, without adequate user behavior in one session, these methods have difficulty in estimating user representations. Usually, the hidden vectors of these RNN methods are treated as the user representations, such that recommendations can be then generated based on these representations, for instance, the global recommender of NARM. In session-based recommendation systems, however, sessions are mostly anonymous and numerous, and user behavior implicated in session clicks is often limited. It is thus difficult to accurately estimate the representation of each user from each session. Secondly, previous work reveals that patterns of item transitions are important and can be used as a local factor <ref type="bibr" target="#b8">(Li et al. 2017a;</ref>) in session-based recommendation, but these methods always model singleway transitions between consecutive items and neglect the transitions among the contexts, i.e. other items in the session. Thus, complex transitions among distant items are often overlooked by these methods.</p><p>To overcome the limitations mentioned above, we propose a novel method for Session-based Recommendation with Graph Neural Networks, SR-GNN for brevity, to explore rich transitions among items and generate accurate latent vectors of items. Graph Neural Networks (GNNs)  <ref type="figure">Figure 1</ref>: The workflow of the proposed SR-GNN method. We model all session sequences as session graphs. Then, each session graph is proceeded one by one and the resulting node vectors can be obtained through a gated graph neural network. After that, each session is represented as the combination of the global preference and current interests of this session using an attention net. Finally, we predict the probability of each item that will appear to be the next-click one for each session. <ref type="bibr" target="#b17">(Scarselli et al. 2009;</ref><ref type="bibr" target="#b8">Li et al. 2015)</ref> are designed for generating representations for graphs. Recently, it has been employed to model graph-structured dependencies for natural language processing and computer vision applications flourishingly, e.g., script event prediction <ref type="bibr" target="#b10">(Li, Ding, and Liu 2018)</ref>, situation recognition <ref type="bibr" target="#b9">(Li et al. 2017b)</ref>, and image classification <ref type="bibr" target="#b13">(Marino, Salakhutdinov, and Gupta 2017)</ref>. For the session-based recommendation, we first construct directed graphs from historical session sequences. Based on the session graph, GNN is capable of capturing transitions of items and generating accurate item embedding vectors correspondingly, which are difficult to be revealed by the conventional sequential methods, like MC-based and RNNbased methods. Based on accurate item embedding vectors, the proposed SR-GNN constructs more reliable session representations and the next-click item can be inferred. <ref type="figure">Figure 1</ref> illustrates the workflow of the proposed SR-GNN method. At first, all session sequences are modeled as directed session graphs, where each session sequence can be treated as a subgraph. Then, each session graph is proceeded successively and the latent vectors for all nodes involved in each graph can be obtained through gated graph neural networks. After that, we represent each session as a composition of the global preference and the current interest of the user in that session, where these global and local session embedding vectors are both composed by the latent vectors of nodes. Finally, for each session, we predict the probability of each item to be the next click. Extensive experiments conducted on real-world representative datasets demonstrate the effectiveness of the proposed method over the state-ofarts. The main contributions of this work are summarized as follows:</p><formula xml:id="formula_0">v 1 → v 2 → v 4 → v 3 v 2 → v 5 → v 6 → v 7 v 5 → v 4 → v 3 → v 6 …… Graph Neural Network v 1 v 2 v 4 v 3 Attention Network s g s l Linear Transformation s h Softmax Layer v 1 v 2 v 4 v 5 v 6 v 3 v 7 … … … v 1 v 4 v 2 v 5 v 6 v 3 v</formula><p>• We model separated session sequences into graphstructured data and use graph neural networks to capture complex item transitions. To best of our knowledge, it presents a novel perspective on modeling in the sessionbased recommendation scenario. • To generate session-based recommendations, we do not rely on user representations, but use the session embedding, which can be obtained merely based on latent vectors of items involved in each single session.</p><p>• Extensive experiments conducted on real-world datasets show that SR-GNN evidently outperforms the state-of-art methods.</p><p>To make our results fully reproducible, all the relevant source codes have been made public at https:// github.com/CRIPAC-DIG/SR-GNN.</p><p>The rest of this paper is organized as follows. We review prior related literature in Section 2. Section 3 presents the proposed method of session-based recommendation with graph neural networks. Detailed experiment results and analysis are shown in Section 4. Finally, we conclude this paper in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>In this section, we review some related work on sessionbased recommendation systems, including conventional methods, sequential methods based on Markov chains, and RNN-based methods. Then, we introduce the neural networks on graphs.</p><p>Conventional recommendation methods. Matrix factorization <ref type="bibr" target="#b15">(Mnih and Salakhutdinov 2007;</ref><ref type="bibr" target="#b7">Koren, Bell, and Volinsky 2009;</ref><ref type="bibr" target="#b6">Koren and Bell 2011)</ref> is a general approach to recommendation systems. The basic objective is to factorize a user-item rating matrix into two low-rank matrices, each of which represents the latent factors of users or items. It is not very suitable for the session-based recommendation, because the user preference is only provided by some positive clicks. The item-based neighborhood methods <ref type="bibr" target="#b16">(Sarwar et al. 2001</ref>) is a natural solution, in which item similarities are calculated on the co-occurrence in the same session. These methods have difficulty in considering the sequential order of items and generate prediction merely based on the last click.</p><p>Then, the sequential methods based on Markov chains are proposed, which predict users' next behavior based on the previous ones. Treating recommendation generation as a sequential optimization problem, <ref type="bibr" target="#b19">Shani, Brafman, and Heckerman (2002)</ref> employ Markov decision processes (MDPs) for the solution. Via factorization of the personalized probability transition matrices of users, FPMC (Rendle, Freudenthaler, and Schmidt-Thieme 2010) models sequential behav-ior between every two adjacent clicks and provides a more accurate prediction for each sequence. However, the main drawback of Markov-chain-based models is that they combine past components independently. Such an independence assumption is too strong and thus confines the prediction accuracy.</p><p>Deep-learning-based methods. Recently, some prediction models, especially language models <ref type="bibr" target="#b14">(Mikolov et al. 2013)</ref> are proposed based on neural networks. Among numerous language models, the recurrent neural network (RNN) has been the most successful one in modeling sentences <ref type="bibr" target="#b14">(Mikolov et al. 2010</ref>) and has been flourishingly applied in various natural language processing tasks, such as machine translation <ref type="bibr" target="#b0">(Cho et al. 2014)</ref>, conversation machine <ref type="bibr" target="#b18">(Serban et al. 2016)</ref>, and image caption <ref type="bibr" target="#b13">(Mao et al. 2015)</ref>. RNN also has been applied successfully in numerous applications, such as the sequential click prediction (Zhang et al. 2014), location prediction , and next basket recommendation <ref type="bibr" target="#b23">(Yu et al. 2016)</ref>.</p><p>For session-based recommendation, the work of <ref type="bibr" target="#b4">(Hidasi et al. 2016a)</ref> proposes the recurrent neural network approach, and then extends to an architecture with parallel RNNs <ref type="bibr" target="#b4">(Hidasi et al. 2016b)</ref> which can model sessions based on the clicks and features of the clicked items. After that, some work is proposed based on these RNN methods.  enhances the performance of recurrent model by using proper data augmentation techniques and taking temporal shifts in user behavior into account. Jannach and Ludewig (2017) combine the recurrent method and the neighborhood-based method together to mix the sequential patterns and co-occurrence signals. <ref type="bibr" target="#b22">Tuan and Phuong (2017)</ref> incorporates session clicks with content features, such as item descriptions and item categories, to generate recommendations by using 3-dimensional convolutional neural networks. Besides, A list-wise deep neural network (Wu and Yan 2017) models the limited user behavior within each session, and uses a list-wise ranking model to generate the recommendation for each session. Furthermore, a neural attentive recommendation machine with an encoder-decoder architecture, i.e. NARM <ref type="bibr" target="#b8">(Li et al. 2017a)</ref>, employs the attention mechanism on RNN to capture users' features of sequential behavior and main purposes. Then, a short-term attention priority model (STAMP) ) using simple MLP networks and an attentive net, is proposed to efficiently capture both users' general interests and current interests.</p><p>Neural network on graphs. Nowadays, neural network has been employed for generating representation for graphstructured data, e.g., social network and knowledge bases. Extending the word2vec <ref type="bibr" target="#b14">(Mikolov et al. 2013)</ref>, an unsupervised algorithm DeepWalk (Perozzi, Al-Rfou, and Skiena 2014) is designed to learn representations of graph nodes based on random walk. Following DeepWalk, unsupervised network embedding algorithms LINE <ref type="bibr" target="#b21">(Tang et al. 2015)</ref> and node2vec <ref type="bibr" target="#b3">(Grover and Leskovec 2016)</ref> are most representative methods. On the another hand, the classical neural network CNN and RNN are also deployed on graph-structured data. <ref type="bibr" target="#b1">(Duvenaud et al. 2015)</ref> introduces a convolutional neural network that operates directly on graphs of arbitrary sizes and shapes. A scalable approach <ref type="bibr" target="#b5">(Kipf and Welling 2016)</ref> chooses the convolutional architecture via a localized approximation of spectral graph convolutions, which is an efficient variant and can operate on graphs directly as well. However, these methods can only be implemented on undirected graphs. Previously, in form of recurrent neural networks, Graph Neural Networks (GNNs) <ref type="bibr" target="#b2">(Gori, Monfardini, and Scarselli 2005;</ref><ref type="bibr" target="#b17">Scarselli et al. 2009</ref>) are proposed to operate on directed graphs. As a modification of GNN, gated GNN <ref type="bibr" target="#b8">(Li et al. 2015)</ref> uses gated recurrent units and employs back-propagation through time (BPTT) to compute gradients. Recently, GNN is broadly applied for the different tasks, e.g., script event prediction <ref type="bibr" target="#b10">(Li, Ding, and Liu 2018)</ref>, situation recognition <ref type="bibr" target="#b9">(Li et al. 2017b)</ref>, and image classification (Marino, Salakhutdinov, and Gupta 2017).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The Proposed Method</head><p>In this section, we introduce the proposed SR-GNN which applies graph neural networks into session-based recommendation. We formulate the problem at first, then explain how to construct the graph from sessions, and finally describe the SR-GNN method thoroughly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Notations</head><p>Session-based recommendation aims to predict which item a user will click next, solely based on the user's current sequential session data without accessing to the long-term preference profile. Here we give a formulation of this problem as below.</p><p>In session-based recommendation, let V = {v 1 , v 2 , . . . , v m } denote the set consisting of all unique items involved in all the sessions. An anonymous session sequence s can be represented by a list s = [v s,1 , v s,2 , . . . , v s,n ] ordered by timestamps, where v s,i ∈ V represents a clicked item of the user within the session s. The goal of the session-based recommendation is to predict the next click, i.e. the sequence label, v s,n+1 for the session s. Under a session-based recommendation model, for the session s, we output probabilitiesŷ for all possible items, where an element value of vectorŷ is the recommendation score of the corresponding item. The items with top-K values inŷ will be the candidate items for recommendation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Constructing Session Graphs</head><p>Each session sequence s can be modeled as a directed graph</p><formula xml:id="formula_1">G s = (V s , E s ). In this session graph, each node represents an item v s,i ∈ V . Each edge (v s,i−1 , v s,i ) ∈ E s means that a user clicks item v s,i after v s,i−1 in the session s.</formula><p>Since several items may appear in the sequence repeatedly, we assign each edge with a normalized weighted, which is calculated as the occurrence of the edge divided by the outdegree of that edge's start node. We embed every item v ∈ V into an unified embedding space and the node vector v ∈ R d indicates the latent vector of item v learned via graph neural networks, where d is the dimensionality. Based on node vectors, each session s can be represented by an embedding vector s, which is composed of node vectors used in that graph.</p><p>Then, we present how to obtain latent vectors of nodes via graph neural networks. The vanilla graph neural network is proposed by <ref type="bibr" target="#b17">Scarselli et al. (2009)</ref>, extending neural network methods for processing the graph-structured data. <ref type="bibr" target="#b8">Li et al. (2015)</ref> further introduce gated recurrent units and propose gated GNN. Graph neural networks are well-suited for session-based recommendation, because it can automatically extract features of session graphs with considerations of rich node connections. We first demonstrate the learning process of node vectors in a session graph. Formally, for the node v s,i of graph G s , the update functions are given as follows:</p><formula xml:id="formula_2">a t s,i = A s,i: v t−1 1 , . . . , v t−1 n H + b,<label>(1)</label></formula><formula xml:id="formula_3">z t s,i = σ W z a t s,i + U z v t−1 i ,<label>(2)</label></formula><formula xml:id="formula_4">r t s,i = σ W r a t s,i + U r v t−1 i ,<label>(3)</label></formula><formula xml:id="formula_5">v t i = tanh W o a t s,i + U o r t s,i v t−1 i ,<label>(4)</label></formula><formula xml:id="formula_6">v t i = 1 − z t s,i v t−1 i + z t s,i v t i ,<label>(5)</label></formula><p>where H ∈ R d×2d controls the weight, z s,i and r s,i are the reset and update gates respectively, v t−1 1 , . . . , v t−1 n is the list of node vectors in session s, σ(·) is the sigmoid function, and is the element-wise multiplication operator. v i ∈ R d represents the latent vector of node v s,i . The connection matrix A s ∈ R n×2n determines how nodes in the graph communicate with each other and A s,i: ∈ R 1×2n are the two columns of blocks in A s corresponding to node v s,i .</p><p>Here A s is defined as the concatenation of two adjacency matrices A (out) s and A (in) s , which represents weighted connections of outgoing and incoming edges in the session graph respectively. For example, consider a session s = [v 1 , v 2 , v 3 , v 2 , v 4 ], the corresponding graph G s and the matrix A s are shown in <ref type="figure" target="#fig_0">Figure 2</ref>. Please note that SR-GNN can support different connection matrices A for various kinds of constructed session graphs. If different strategies of constructing the session graph are used, the connection matrix A s will be changed accordingly. Moreover, when there exists content features of node, such as descriptions and categorical information, the method can be further generalized.</p><p>To be specific, we can concatenate features with node vector to deal with such information.</p><p>For each session graph G s , the gated graph neural network proceeds nodes at the same time. Eq. (1) is used for information propagation between different nodes, under restrictions given by the matrix A s . Specifically, it extracts the latent vectors of neighborhoods and feeds them as input into the graph neural network. Then, two gates, i.e. update and reset gate, decide what information to be preserved and discarded respectively. After that, we constructs the candidate state by the previous state, the current state, and the reset gate as described in Eq. (4). The final state is then the combination of the previous hidden state and the candidate state, under the control of the update gate. After updating all nodes in session graphs until convergence, we can obtain the final node vectors. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Generating Session Embeddings</head><p>Previous session-based recommendation methods always assume there exists a distinct latent representation of user for each session. On the contrary, the proposed SR-GNN method does not make any assumptions on that vector. Instead, a session is represented directly by nodes involved in that session. To better predict the users' next clicks, we plan to develop a strategy to combine long-term preference and current interests of the session, and use this combined embedding as the session embedding. After feeding all session graphs into the gated graph neural networks, we obtain the vectors of all nodes. Then, to represent each session as an embedding vector s ∈ R d , we first consider the local embedding s l of session s. For session s = [v s,1 , v s,2 , . . . , v s,n ], the local embedding can be simply defined as v n of the last-clicked item v s,n , i.e. s l = v n .</p><p>Then, we consider the global embedding s g of the session graph G s by aggregating all node vectors. Consider information in these embedding may have different levels of priority, we further adopt the soft-attention mechanism to better represent the global session preference:</p><formula xml:id="formula_7">α i = q σ(W 1 v n + W 2 v i + c), s g = n i=1 α i v i ,<label>(6)</label></formula><p>where parameters q ∈ R d and W 1 , W 2 ∈ R d×d control the weights of item embedding vectors. Finally, we compute the hybrid embedding s h by taking linear transformation over the concatenation of the local and global embedding vectors:</p><formula xml:id="formula_8">s h = W 3 [s l ; s g ] ,<label>(7)</label></formula><p>where matrix W 3 ∈ R d×2d compresses two combined embedding vectors into the latent space R d .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Making Recommendation and Model Training</head><p>After obtained the embedding of each session, we compute the scoreẑ i for each candidate item v i ∈ V by multiplying its embedding v i by session representation s h , which can be defined as:</p><formula xml:id="formula_9">ẑ i = s h v i .<label>(8)</label></formula><p>Then we apply a softmax function to get the output vector of the modelŷ:ŷ = softmax (ẑ) ,</p><p>whereẑ ∈ R m denotes the recommendation scores over all candidate items andŷ ∈ R m denotes the probabilities of nodes appearing to be the next click in session s. For each session graph, the loss function is defined as the cross-entropy of the prediction and the ground truth. It can be written as follows: <ref type="formula" target="#formula_2">(10)</ref> where y denotes the one-hot encoding vector of the ground truth item.</p><formula xml:id="formula_11">L(ŷ) = − m i=1 y i log (ŷ i ) + (1 − y i ) log (1 −ŷ i ),</formula><p>Finally, we use the Back-Propagation Through Time (BPTT) algorithm to train the proposed SR-GNN model. Note that in session-based recommendation scenarios, most sessions are of relatively short lengths. Therefore, it is suggested to choose a relatively small number of training steps to prevent overfitting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments and Analysis</head><p>In this section, we first describe the datasets, compared methods, and evaluation metrics used in the experiments. Then, we compare the proposed SR-GNN with other comparative methods. Finally, we make detailed analysis of SR-GNN under different experimental settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Datasets</head><p>We evaluate the proposed method on two real-world representative datasets, i.e. Yoochoose 1 and Diginetica 2 . The Yoochoose dataset is obtained from the RecSys Challenge 2015, which contains a stream of user clicks on an e-commerce website within 6 months. The Diginetica dataset comes from CIKM Cup 2016, where only its transactional data is used.</p><p>For fair comparison, following <ref type="bibr" target="#b8">(Li et al. 2017a;</ref>, we filter out all sessions of length 1 and items appearing less than 5 times in both datasets. The remaining 7,981,580 sessions and 37,483 items constitute the Yoochoose dataset, while 204,771 sessions and 43097 items construct the Diginetica dataset. Furthermore, similar to , we generate sequences and corresponding labels by splitting the input sequence. To be specific, we set the sessions of subsequent days as the test set for Yoochoose, and the sessions of subsequent weeks as the test set for Diginetiva. For example, for an input session s = [v s,1 , v s,2 , . . . , v s,n ], we generate a series of sequences and labels <ref type="bibr">([v s,1</ref> </p><formula xml:id="formula_12">], v s,2 ), ([v s,1 , v s,2 ], v s,3 ), . . . , ([v s,1 , v s,2 , . . . , v s,n−1 ], v s,n ), where [v s,1 , v s,2 , . . . , v s,n−1 ]</formula><p>is the generated sequence and v s,n denotes the next-clicked item, i.e. the label of the sequence. Following <ref type="bibr" target="#b8">(Li et al. 2017a;</ref>, we also use the most recent fractions 1/64 and 1/4 of the training sequences of Yoochoose. The statistics of datasets are summarized in <ref type="table" target="#tab_1">Table 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Baseline Algorithms</head><p>To evaluate the performance of the proposed method, we compare it with the following representative baselines:</p><p>• POP and S-POP recommend the top-N frequent items in the training set and in the current session respectively.</p><p>• Item- <ref type="bibr">KNN (Sarwar et al. 2001</ref>) recommends items similar to the previously clicked item in the session, where similarity is defined as the cosine similarity between the vector of sessions.</p><p>• BPR-MF <ref type="bibr" target="#b16">(Rendle et al. 2009</ref>) optimizes a pairwise ranking objective function via stochastic gradient descent.</p><p>• FPMC (Rendle, Freudenthaler, and Schmidt-Thieme 2010) is a sequential prediction method based on markov chain.</p><p>• GRU4REC <ref type="bibr" target="#b4">(Hidasi et al. 2016a</ref>) uses RNNs to model user sequences for the session-based recommendation.</p><p>• NARM <ref type="bibr" target="#b8">(Li et al. 2017a</ref>) employs RNNs with attention mechanism to capture the user's main purpose and sequential behavior.</p><p>• STAMP ) captures users' general interests of the current session and current interests of the last click.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evaluation Metrics</head><p>Following metrics are used to evaluate compared methods. P@20 (Precision) is widely used as a measure of predictive accuracy. It represents the proportion of correctly recommended items amongst the top-20 items.</p><p>MRR@20 (Mean Reciprocal Rank) is the average of reciprocal ranks of the correctly-recommended items. The reciprocal rank is set to 0 when the rank exceeds 20. The MRR measure considers the order of recommendation ranking, where large MRR value indicates that correct recommendations in the top of the ranking list.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Parameter Setup</head><p>Following previous methods <ref type="bibr" target="#b8">(Li et al. 2017a;</ref>, we set the dimensionality of latent vectors d = 100 for both datasets. Besides, we select other hyper-parameters on a validation set which is a random 10% subset of the training set. All parameters are initialized using a Gaussian distribution with a mean of 0 and a standard deviation of 0.1. The mini-batch Adam optimizer is exerted to optimize these parameters, where the initial learning rate is set to 0.001 and will decay by 0.1 after every 3 epochs. Moreover, the batch size and the L2 penalty is set to 100 and 10 −5 respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Comparison with Baseline Methods</head><p>To demonstrate the overall performance of the proposed model, we compare it with other state-of-art session-based recommendation methods. The overall performance in terms of P@20 and MRR@20 is shown in <ref type="table" target="#tab_2">Table 2</ref>, with the best results highlighted in boldface. Please note that, as in <ref type="bibr" target="#b8">(Li et al. 2017a</ref>), due to insufficient memory to initialize FPMC, the performance on Yoochoose 1/4 is not reported. SR-GNN aggregates separated session sequences into graph-structured data. In this model, we jointly consider the global session preference as well as the local interests. According to the experiments, it is obvious that the proposed SR-GNN method achieves the best performance on all three datasets in terms of P@20 and MRR@20. This verifies the effectiveness of the proposed method.</p><p>Regarding those traditional algorithms like POP and S-POP, their performance is relatively poor. Such simple models make recommendations solely based on repetitive cooccurred items or successive items, which is problematic in session-based recommendation scenarios. Even so, S-POP still outperforms its opponents such as POP, BPR-MF, and FPMC, demonstrating the importance of session contextual information. Item-KNN achieves better results than FPMC which is based on Markov chains. Please note that, Item-KNN only utilizes the similarity between items without considering sequential information. This indicates that the assumption on the independence of successive items, which traditional MC-based methods mostly rely on, is not realistic.</p><p>Neural-network-based methods, such as NARM and STAMP, outperform the conventional methods, demonstrating the power of adopting deep learning in this domain. Short/long-term memory models, like GRU4REC and NARM, use recurrent units to capture a user's general interest while STAMP improves the short-term memory by utilizing the last-clicked item. Those methods explicitly model the users' global behavioral preferences and consider transitions between users' previous actions and the next click, leading to superior performance against these traditional methods. However, their performance is still inferior to that of the proposed method. Compared with the state-of-art methods like NARM and STAMP, SR-GNN further considers transitions between items in a session and thereby models every session as a graph, which can capture more complex and implicit connections between user clicks. Whereas in NARM and GRU4REC, they explicitly model each user and obtain the user representations through separated session sequences, with possible interactive relationships between items ignored. Therefore, the proposed model is more powerful to model session behavior.</p><p>Besides, SR-GNN adopts the soft-attention mechanism to generate a session representation which can automatically select the most significant item transitions, and neglect noisy and ineffective user actions in the current session. On the contrary, STAMP only uses the transition between the lastclicked item and previous actions, which may not be sufficient. Other RNN models, such as GRU4REC and NARM, fail to select impactful information during the propagation process as well. They use all previous items to obtain a vector representing the user's general interest. When a user's behavior is aimless, or his interests drift quickly in the current session, conventional models are ineffective to cope with noisy sessions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Comparison with Variants of Connection Schemes</head><p>The proposed SR-GNN method is flexible in constructing connecting relationships between items in the graph. Since user behavior in sessions is limited, we propose in this section another two connection variants in order to augment limited relationships between items in each session graph. Firstly, we aggregate all session sequences together and model them as a directed whole item graph, which is termed as the global graph hereafter. In the global graph, each node denotes a unique item, and each edge denotes a directed transition from one item to another. Secondly, we model all high-order relationships between items within one session as direct connections explicitly. In summary, the following two connection schemes are proposed to compare with SR-GNN:</p><p>• SR-GNN with normalized global connections (SR-GNN-NGC) replaces the connection matrix with edge weights extracted from the global graph on the basis of SR-GNN. • SR-GNN with full connections (SR-GNN-FC) represents all higher-order relationships using boolean weights and appends its corresponding connection matrix to that of SR-GNN. The results of different connection schemes are shown in <ref type="figure">Figure 3</ref>. From the figures, it is seen that all three connection schemes achieve better or almost the same performance as the state-of-the-art STAMP and NARM methods, confirming the usefulness of modeling sessions as graphs.</p><p>Compared with SR-GNN, for each session, SR-GNN-NGC takes the impact of other sessions into considerations in addition to items in the current session, which subsequently reduces the influence of edges that are connected to nodes with high degree within the current session graph. Such a fusion method notably affects the integrity of the current session, especially when the weight of the edge in the graph varies, leading to performance downgrade. In regard to SR-GNN and SR-GNN-FC, the former one only models the exact relationship between consecutive items, and the latter one further explicitly regards all highorder relationships as direct connections. It is reported that SR-GNN-FC performs worse than SR-GNN, though the experimental results of the two methods are not of much difference. Such a small difference in results suggests that in most recommendation scenarios, not every high-order transitions can be directly converted to straight connections and intermediate stages between high-order items are still necessities. For instance, considering that the user has viewed the following pages when browsing a website: A → B → C, it is not appropriate to recommend page C directly after A without intermediate page B, due to the lack of a direct connection between A and C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Comparison with Different Session Embeddings</head><p>We compare the session embedding strategy with the following three approaches: (1) local embedding only (SR-GNN-L), (2) global embedding with average pooling (SR-GNN-AVG), and (3) global embedding with the attention mechanism (SR-GNN-ATT). The results of methods with three different embedding strategies are given in <ref type="figure" target="#fig_1">Figure 4</ref>.</p><p>From the figures, it can be observed that the hybrid embedding method SR-GNN achieves best results on all three datasets, which validates the importance of explicitly incorporating current session interests with the long-term preference. Furthermore, the figures show that SR-GNN-ATT performs better than SR-GNN-AVG with average pooling on three datasets. It indicates that the session may contain some noisy behavior, which cannot be treated independently. Besides, it is shown that attention mechanisms are helpful in extracting the significant behavior from the session data to construct the long-term preference.</p><p>Please note that SR-GNN-L, a downgraded version of SR-GNN, still outperforms SR-GNN-AVG and achieves almost the same performance as that of SR-GNN-ATT, supporting that both the current interest and long-term preference are crucial for session-based recommendation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analysis on Session Sequence Lengths</head><p>We further analyze the capability of different models to cope with sessions of different lengths. For comparison, we partition sessions of Yoochoose 1/64 and Diginetica into two groups, where "Short" indicates that the length of sessions is less than or equal to 5, while each session has more than 5 items in "Long". The pivot value 5 is chosen because it is the closest integer to the average length of total sessions in all datasets. The percentages of session belonging to short group and long group are 0.701 and 0.299 on the Yoochoose data, and 0.764 and 0.236 on the Diginetica data. For each method, we report the results evaluated in terms of P@20 in <ref type="table" target="#tab_3">Table 3</ref>.</p><p>Our proposed SR-GNN and its variants perform stably on two datasets with different session lengths. It demonstrates the superior performance of the proposed method and the adaptability of graph neural networks in session-based recommendation. On the contrary, the performance of STAMP changes greatly in short and long groups. STAMP ) explains such a difference according to replicated actions. It adopts the attention mechanism, so replicated items can be ignored when obtaining user representations. Similar to STAMP, on Yoochoose, NARM achieves good performance on the short group, but the performance drops quickly with the length of the sessions increasing, which is partially because RNN models have difficulty in coping with long sequences.</p><p>Then we analyze the performance of SR-GNN-L, SR-GNN-ATT, and SR-GNN with different session representations. These three methods achieve promising results comparing with STAMP and NARM. It is probably because that based on the learning framework of graph neural networks, our methods can attain more accurate node vectors. Such node embedding not only captures the latent features of nodes but also models the node connections globally. On such basis, the performance is stable among variants of SR-GNN, while the performance of two state-of-art methods fluctuate considerably on short and long datasets. Moreover, the table shows that SR-GNN-L can also achieve good results, although this variant only uses local session embedding vectors. It is maybe because that SR-GNN-L also implicitly considers the properties of the first-order and higherorder nodes in session graphs. Such results are also validated by <ref type="figure" target="#fig_1">Figure 4</ref>, where both SR-GNN-L and SR-GNN-ATT achieve the close-to-optimal performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>Session-based recommendation is indispensable where users' preference and historical records are hard to obtain. This paper presents a novel architecture for session-based recommendation that incorporates graph models into representing session sequences. The proposed method not only considers the complex structure and transitions between items of session sequences, but also develops a strategy to combine long-term preferences and current interests of sessions to better predict users' next actions. Comprehensive experiments confirm that the proposed algorithm can consistently outperform other state-of-art methods.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>A example of a session graph and the connection matrix A s</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 :</head><label>4</label><figDesc>The performance of different session representations</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Statistics of datasets used in the experiments</figDesc><table><row><cell>Statistics</cell><cell cols="3">Yoochoose 1/64 Yoochoose 1/4 Diginetica</cell></row><row><cell># of clicks</cell><cell>557,248</cell><cell>8,326,407</cell><cell>982,961</cell></row><row><cell># of training sessions</cell><cell>369,859</cell><cell>5,917,745</cell><cell>719,470</cell></row><row><cell># of test sessions</cell><cell>55,898</cell><cell>55,898</cell><cell>60,858</cell></row><row><cell># of items</cell><cell>16,766</cell><cell>29,618</cell><cell>43,097</cell></row><row><cell>Average length</cell><cell>6.16</cell><cell>5.71</cell><cell>5.12</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>The performance of SR-GNN with other baseline methods over three datasets</figDesc><table><row><cell>Method</cell><cell cols="2">Yoochoose 1/64</cell><cell cols="2">Yoochoose 1/4</cell><cell cols="2">Diginetica</cell></row><row><cell></cell><cell cols="6">P@20 MRR@20 P@20 MRR@20 P@20 MRR@20</cell></row><row><cell>POP</cell><cell>6.71</cell><cell>1.65</cell><cell>1.33</cell><cell>0.30</cell><cell>0.89</cell><cell>0.20</cell></row><row><cell>S-POP</cell><cell>30.44</cell><cell>18.35</cell><cell>27.08</cell><cell>17.75</cell><cell>21.06</cell><cell>13.68</cell></row><row><cell cols="2">Item-KNN 51.60</cell><cell>21.81</cell><cell>52.31</cell><cell>21.70</cell><cell>35.75</cell><cell>11.57</cell></row><row><cell>BPR-MF</cell><cell>31.31</cell><cell>12.08</cell><cell>3.40</cell><cell>1.57</cell><cell>5.24</cell><cell>1.98</cell></row><row><cell>FPMC</cell><cell>45.62</cell><cell>15.01</cell><cell>-</cell><cell>-</cell><cell>26.53</cell><cell>6.95</cell></row><row><cell cols="2">GRU4REC 60.64</cell><cell>22.89</cell><cell>59.53</cell><cell>22.60</cell><cell>29.45</cell><cell>8.33</cell></row><row><cell>NARM</cell><cell>68.32</cell><cell>28.63</cell><cell>69.73</cell><cell>29.23</cell><cell>49.70</cell><cell>16.17</cell></row><row><cell>STAMP</cell><cell>68.74</cell><cell>29.67</cell><cell>70.44</cell><cell>30.00</cell><cell>45.64</cell><cell>14.32</cell></row><row><cell>SR-GNN</cell><cell>70.57</cell><cell>30.94</cell><cell>71.36</cell><cell>31.89</cell><cell>50.73</cell><cell>17.59</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>The performance of different methods with different session lengths evaluated in terms of P@20</figDesc><table><row><cell>Method</cell><cell cols="2">Yoochoose 1/64</cell><cell>Diginetica</cell></row><row><cell></cell><cell>Short</cell><cell>Long</cell><cell>Short Long</cell></row><row><cell>NARM</cell><cell>71.44</cell><cell>60.79</cell><cell>51.22 45.75</cell></row><row><cell>STAMP</cell><cell>70.69</cell><cell>64.73</cell><cell>47.26 40.39</cell></row><row><cell>SR-GNN-L</cell><cell>70.11</cell><cell>69.73</cell><cell>49.04 50.97</cell></row><row><cell cols="2">SR-GNN-ATT 70.31</cell><cell>70.64</cell><cell>50.35 51.05</cell></row><row><cell>SR-GNN</cell><cell>70.47</cell><cell>70.70</cell><cell>50.49 51.27</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">http://2015.recsyschallenge.com/challege. html 2 http://cikm2016.cs.iupui.edu/cikm-cup</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>The first two authors Shu Wu and Yuyuan Tang contribute to this work equally. The work is done during the internship of Yanqiao Zhu and Yuyuan Tang at CRIPAC, CASIA. The correspondence author is Yanqiao Zhu.</p><p>This work is jointly supported by National Natural Science Foundation of China (61772528), National Key Research and Development Program (2016YFB1001000), and National Natural Science Foundation of China (U1435221).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Learning phrase representations using rnn encoder-decoder for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>References</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cho</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1724" to="1734" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Convolutional networks on graphs for learning molecular fingerprints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Duvenaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A new model for learning in graph domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Monfardini</forename><surname>Gori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Scarselli ; Gori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Monfardini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Scarselli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCNN</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="729" to="734" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Node2vec: Scalable feature learning for networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Grover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<meeting><address><addrLine>Leskovec</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="855" to="864" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Parallel recurrent neural network architectures for feature-rich session-based recommendations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Hidasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">RecSys</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="306" to="310" />
		</imprint>
	</monogr>
	<note>RecSys</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Semisupervised classification with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>and Welling</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Advances in collaborative filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Recommender Systems Handbook</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="145" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Matrix factorization techniques for recommender systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Volinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="30" to="37" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Neural attentive session-based recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<editor>ICLR. [Li et al. 2017a</editor>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1419" to="1428" />
		</imprint>
	</monogr>
	<note>Gated graph sequence neural networks</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Situation recognition with graph neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4183" to="4192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Constructing narrative event evolutionary graph for script event prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ding</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Predicting the next location: A recurrent model with spatial and temporal contexts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="194" to="200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Stamp: Short-term attention/memory priority model for session-based recommendation</title>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1831" to="1839" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Deep captioning with multimodal recurrent neural networks (m-rnn). ICLR</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Mao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="20" to="28" />
		</imprint>
	</monogr>
	<note>The more you know: Using knowledge graphs for image classification</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INTERSPEECH</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
	<note>NIPS</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Deepwalk: Online learning of social representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Perozzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Skiena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="701" to="710" />
		</imprint>
	</monogr>
	<note>KDD</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Factorizing personalized markov chains for next-basket recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Rendle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">UAI</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="811" to="820" />
		</imprint>
	</monogr>
	<note>WWW</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The graph neural network model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Scarselli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TNN</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="61" to="80" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Building end-to-end dialogue systems using generative hierarchical neural network models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Serban</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3776" to="3784" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">An mdp-based recommender system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brafman</forename><surname>Shani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Brafman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">I</forename><surname>Heckerman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">UAI</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="453" to="460" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Improved recurrent neural networks for session-based recommendations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Liu ; Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">DLRS</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="17" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Line: Large-scale information network embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1067" to="1077" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">3d convolutional networks for session-based recommendation with content features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">X</forename><surname>Tuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phuong</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">RecSys</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2379" to="2382" />
		</imprint>
	</monogr>
	<note>CIKM</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Sequential click prediction for sponsored search with recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR. ACM</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1369" to="1376" />
		</imprint>
	</monogr>
	<note>AAAI</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
