<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">GRADIENT PENALTY FROM A MAXIMUM MARGIN PER- SPECTIVE</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexia</forename><surname>Jolicoeur-Martineau</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computer Science</orgName>
								<orgName type="department" key="dep2">Department of Computer Science</orgName>
								<orgName type="institution" key="instit1">University of Montreal Ioannis Mitliagkas</orgName>
								<orgName type="institution" key="instit2">University of Montreal</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">GRADIENT PENALTY FROM A MAXIMUM MARGIN PER- SPECTIVE</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T07:36+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>A popular heuristic for improved performance in Generative adversarial networks (GANs) is to use some form of gradient penalty on the discriminator. This gradient penalty was originally motivated by a Wasserstein distance formulation. However, the use of gradient penalty in other GAN formulations is not well motivated. We present a unifying framework of expected margin maximization and show that a wide range of gradient-penalized GANs (e.g., Wasserstein, Standard, Least-Squares, and Hinge GANs) can be derived from this framework. Our results imply that employing gradient penalties induces a large-margin classifier (thus, a large-margin discriminator in GANs). We describe how expected margin maximization helps reduce vanishing gradients at fake (generated) samples, a known problem in GANs. From this framework, we derive a new L ∞ gradient norm penalty with Hinge loss which generally produces equally good (or better) generated output in GANs than L 2 -norm penalties (based on the Fréchet Inception Distance).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Generative adversarial networks (GANs) <ref type="bibr" target="#b0">(Goodfellow et al., 2014)</ref> are a very successful class of generative models. Their most common formulation involves a game played between two competing neural networks, the discriminator D and the generator G. D is a classifier trained to distinguish real from fake examples, while G is trained to generate fake examples that will confuse D into recognizing them as real. When the discriminator's objective is maximized, it yields the value of a specific divergence (i.e., a distance between probability distributions) between the distributions of real and fake examples. The generator then aims to minimize that divergence (although this interpretation is not perfect; see <ref type="bibr" target="#b1">Jolicoeur-Martineau (2018a)</ref>). Importantly, many GANs apply some form of gradient norm penalty to the discriminator <ref type="bibr" target="#b2">(Gulrajani et al., 2017;</ref><ref type="bibr" target="#b3">Fedus et al., 2017a;</ref><ref type="bibr" target="#b4">Mescheder et al., 2018;</ref><ref type="bibr" target="#b5">Karras et al., 2019)</ref>. Gradient norm penalty has been widely adopted by the GAN community as a useful heuristic to improve the stability of GANs and the quality of the generated outputs. This penalty was originally motivated by a Wasserstein distance formulation in <ref type="bibr" target="#b2">Gulrajani et al. (2017)</ref>. However, its use in other GAN formulations is not well motivated. Given its success, one might wonder how one could derive an arbitrary GAN formulation with a gradient penalty?</p><p>In this paper, we derive a framework which shows that gradient penalty arises in GANs from using a maximum margin classifier as discriminator. We then use this framework to better understand GANs and devise better gradient penalties.</p><p>The main contributions of this paper are: 1. A unifying framework of expected margin maximization and showing that gradient-penalized versions of most discriminator/classifier loss functions (Wasserstein, Cross-entropy, Least-Squares, Hinge-Loss) can be derived from this framework. 2. A new method derived from our framework, a L ∞ gradient norm penalty with Hinge function. We hypothesize and show that this method works well in GAN. 3. We describe how margin maximization (and thereby gradient penalties) helps reduce vanishing gradients at fake (generated) samples, a known problem in many GANs.</p><p>4. We derive the margins of Relativistic paired and average GANs <ref type="bibr" target="#b6">(Jolicoeur-Martineau, 2018b;</ref><ref type="bibr" target="#b7">2019)</ref>.</p><p>The paper is organized as follows. In Section 2, we show how gradient penalty arises from the Wasserstein distance in the GAN literature. In Section 3, we explain the concept behind maximummargin classifiers (MMCs) and how they lead to some form of gradient penalty. In Section 4, we present our generalized framework of maximum-margin classification and experimentally validate it. In Section 5, we discuss of the implications of this framework on GANs and hypothesize that L 1 -norm margins may lead to more robust classifiers. Finally, in Section 6, we provide experiments to test the different GANs resulting from our framework. Note that due to space constraints, we relegated the derivations of the margins of Relativistic GANs to Appendix C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">GRADIENT PENALTY FROM THE GAN LITERATURE</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">NOTATION</head><p>We focus on binary classifiers. Let f be the classifier and (x, y) ∼ D the distribution (of a dataset D) with n data samples x and labels y. As per SVM literature, y = 1 when x is sampled from class 1 and y = −1 when x is sampled from class 2. Furthermore, we denote x 1 = x|(y = 1) ∼ P and x 2 = x|(y = −1) ∼ Q as the data samples from class 1 and class 2 respectively (with distributions P and Q). When discussing GANs, x 1 ∼ P (class 1) refer to real data samples and x 2 ∼ Q (class 2) refer to fake data samples (produced by the generator). The L ∞ -norm is defined as:</p><formula xml:id="formula_0">||x|| ∞ = max(|x 1 |, |x 2 |, . . . , |x k |).</formula><p>The critic (C) is the discriminator (D) before applying any activation function (i.e., D(x) = a(C(x)), where a is the activation function). For consistency with existing literature, we will generally refer to the critic rather than the discriminator.</p><p>where Π(P, Q) is the set of all distributions with marginals P and Q and we call π a coupling.</p><p>The Wasserstein distance has been highly popular in GANs due to the fact that it provides good gradient for the generator in GANs which allows more stable training.</p><p>IPM-based GANs <ref type="bibr" target="#b2">Gulrajani et al., 2017)</ref> attempt to solve the following problem</p><formula xml:id="formula_1">min G max C∈F E x2∼P [C(x 1 )] − E z∼Z [C(G(z))].</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">GRADIENT PENALTY AS A WAY TO ESTIMATE THE WASSERSTEIN DISTANCE</head><p>To estimate the Wasserstein distance using its dual form (as a IPM), one need to enforce the 1-Lipschitz property on the critic. <ref type="bibr" target="#b2">Gulrajani et al. (2017)</ref> showed that one could impose a gradient penalty, rather than clamping the weights as originally done , and that this led to better GANs. More specifically, they showed that if the optimal critic f * (x) is differentiable everywhere and thatx = αx 1 + (1 − α)x 2 for 0 ≤ α ≤ 1, we have that ||∇C * (x)|| 2 = 1 almost everywhere for all pair (x 1 , x 2 ) which comes from the optimal coupling π * .</p><p>Sampling from the optimal coupling is difficult so they suggested to softly penalize Ex(||∇xC(x)|| 2 − 1) 2 , wherex = αx 1 + (1 − α)x 2 , α ∼ U (0, 1), x 1 ∼ P, and x 2 ∼ Q. They called this approach Wasserstein GAN with gradient-penalty (WGAN-GP). However, note that this approach does not necessarily estimate the Wasserstein distance since we are not sampling from π * and f * does not need to be differentiable everywhere <ref type="bibr" target="#b12">(Petzka et al., 2017)</ref>.</p><p>Of importance, gradient norm penalties of the form E x (||∇ x D(x)|| 2 − δ) 2 , for some δ ∈ R are very popular in GANs. Remember that D(x) = a(C(x)); in the case of IPM-based-GANs, we have that D(x) = C(x). It has been shown that the GP-1 penalty (δ = 1), as in WGAN-GP, also improves the performance of non-IPM-based GANs <ref type="bibr" target="#b13">(Fedus et al., 2017b)</ref>. Another successful variant is GP-0 (δ = 0 and x ∼ P) <ref type="bibr" target="#b4">(Mescheder et al., 2018;</ref><ref type="bibr" target="#b5">Karras et al., 2019)</ref>. Although there are explanations to why gradient penalties may be helpful <ref type="bibr" target="#b4">(Mescheder et al., 2018;</ref><ref type="bibr" target="#b14">Kodali et al., 2017;</ref><ref type="bibr" target="#b2">Gulrajani et al., 2017)</ref>, the theory is still lacking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">MAXIMUM-MARGIN CLASSIFIERS</head><p>In this section, we define the concepts behind maximum-margin classifiers (MMCs) and show how it leads to a gradient penalty.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">DECISION BOUNDARY AND MARGIN</head><p>The decision boundary of a classifier is defined as the set of points x 0 such that f (x 0 ) = 0.</p><p>The margin is either defined as i) the minimum distance between a sample and the boundary, or ii) the minimum distance between the closest sample to the boundary and the boundary. The former thus corresponds to the margin of a sample and the latter corresponds to the margin of a dataset . In order to disambiguate the two cases, we refer to the former as the margin and the latter as the minimum margin.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">GEOMETRIC MARGIN AND GRADIENT PENALTY</head><p>The first step towards obtaining a MMC is to define the L p -norm margin:</p><formula xml:id="formula_2">γ(x) = min x0 ||x 0 − x|| p s.t. f (x 0 ) = 0<label>(3)</label></formula><p>With a linear classifier (i.e., f (x) = w T x), there is a close form solution. However, the formulation of the L p -norm margin equation 3 has no closed form for arbitrary non-linear classifiers. A way to derive an approximation of the margin is to use Taylor's approximation before solving the problem (as done by <ref type="bibr" target="#b15">Matyasko and Chau (2017)</ref> and <ref type="bibr" target="#b16">Elsayed et al. (2018)</ref>):</p><formula xml:id="formula_3">γ p (x) = min r ||r|| p s.t. f (x + r) = 0 ≈ min r ||r|| p s.t. f (x) + ∇ x f (x) T r = 0 = |f (x)| ||∇ x f (x)|| q ,</formula><p>where || · || q is the dual norm <ref type="bibr" target="#b17">(Boyd and Vandenberghe, 2004)</ref> of || · || p . By Hölder's inequality <ref type="bibr" target="#b18">(Hölder, 1889;</ref><ref type="bibr" target="#b19">Rogers, 1888)</ref>, we have that 1/p + 1/q = 1. This means that if p = 2, we still get q = 2; if p = ∞, we get q = 1; if p = 1, we get q = ∞.</p><p>The goal of MMCs is to maximize a margin, but also to obtain a classifier. To do so, we simply replace α(x) = |f (x)| by α(x, y) = yf (x). We call α the functional margin. After replacement, we obtain the geometric margin:</p><formula xml:id="formula_4">γ(x, y) = yf (x) ||∇ x f (x)|| q</formula><p>If p = 2 and f (x) is linear, this leads to the same geometric margin used in Support Vector-Machines (SVMs). <ref type="bibr" target="#b15">Matyasko and Chau (2017)</ref> used this result to generalize Soft-SVMs to arbitrary classifiers by simply penalizing the L p -norm of the gradient rather than penalizing the L p -norm of the model's weights (as done in SVMs). Meanwhile, <ref type="bibr" target="#b16">Elsayed et al. (2018)</ref> used this result in a multi-class setting and maximized the geometric margin directly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">GENERALIZED FRAMEWORK OF MAXIMUM-MARGIN CLASSIFICATION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">FRAMEWORK</head><p>Here we show how to generalize the idea behind maximizing the geometric margin into arbitrary loss functions with a gradient penalty. Directly maximizing the geometric margin is an ill-posed problem. The numerator and denominator are dependent on one another; increasing the functional margin also increases the norm of the gradient (and vice-versa). Thereby, there are infinite solutions which maximize the geometric margin. For this reason, the common approach (as in SVM literature; see <ref type="bibr" target="#b20">Cortes and Vapnik (1995)</ref>) is to: i) constrain the numerator and minimize the denominator, or ii) constrain the denominator and maximize the numerator.</p><p>Approach i) consists of minimizing the denominator and constraining the numerator using the following formulation:</p><formula xml:id="formula_5">min f ||∇ x f (x)|| p s.t. yf (x) ≥ 1 ∀ (x, y) ∈ D<label>(4)</label></formula><p>The main limitation of this approach is that it only works when the data are separable. However, if we take the opposite approach of maximizing a function of yf (x) and constraining the denominator ||f (x)|| 2 , we can still solve the problem with non-separable data. This corresponds to approach ii):</p><formula xml:id="formula_6">max f E (x,y)∼D [yf (x)] s.t. ||∇ x f (x)|| q ≤ 1 or ||∇ x f (x)|| q = 1.<label>(5)</label></formula><p>The constraint chosen can be enforced by either i) using a KKT multiplier <ref type="bibr" target="#b21">(Kuhn and Tucker, 1951;</ref><ref type="bibr" target="#b22">Karush, 1939)</ref> or ii) approximately imposing it with a soft-penalty. Furthermore, one can use any margin-based loss function rather than directly maximize yf (x). Thus, we can generalize this idea by using the following formulation:</p><formula xml:id="formula_7">min f E (x,y)∼D [L(yf (x)) + λg(||∇ x f (x)|| q )] .<label>(6)</label></formula><p>where L, g : R → R and λ is a scalar penalty term. There are many potential choices of L and g which we can use.</p><p>If L is chosen to be the hinge function (i.e., L(z) = max(0, 1 − z)), we ignore samples far from the boundary (as in Hard-Margin SVMs). For general choices of L, every sample may influence the solution. The identity function L(z) = z, cross entropy with sigmoid activation L(z) = − log(sigmoid(z))) and least-squares L(z) = (1 − z) 2 are also valid choices.</p><p>A standard choice of g is g(z) = (z 2 − 1). This corresponds to constraining ||∇ x f (x)|| 2 2 = 1 or ||∇ x f (x)|| 2 2 ≤ 1 for all x (by KKT conditions). As an alternative, we can also consider soft constraints of the form g(z) = (z − 1) 2 or g(z) = max(0, z − 1). The first function enforces a soft equality constraint so that z ≈ 1 while the second function enforces a soft inequality constraint so that z ≤ 1. Soft constraints are useful if the goal is not to obtain the maximum margin solution but to obtain a solution that leads to a large-enough margin.</p><p>Of importance, MMCs can be seen as a generalization of Support Vector Machines (SVMs). When p = 2 and f is linear (f (x) = w T x), equation 4 corresponds exactly to Hard-Margin SVMs and equation 6 with L(z) = max(0, 1 − z) and g(z) = (z 2 − 1) corresponds exactly to Soft-Margin SVMs <ref type="bibr" target="#b20">(Cortes and Vapnik, 1995)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">EXPERIMENTAL EVIDENCE OF LARGE MARGIN FROM GRADIENT PENALTIES</head><p>We ran experiments to empirically show that gradient-penalized classifiers (trained to optimize equation 6) maximize the expected margin. We used the swiss-roll dataset <ref type="bibr" target="#b23">(Marsland, 2015)</ref> to obtain two classes (one is the swiss-roll and one is the swiss-roll scaled by 1.5). The results are shown in <ref type="table" target="#tab_0">Table 1</ref> (Details of the experiments are in Appendix A). We observe that we obtain much larger expected margins (generally 2 to 3 times bigger) when using a gradient penalty; this is true for all types of gradient penalties.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">IMPLICATIONS OF THE MAXIMUM MARGIN FRAMEWORK ON GANS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">GANS CAN BE DERIVED FROM THE MMC FRAMEWORK</head><p>Although not immediately clear given the different notations, let f (x) = C(x) and we have:</p><formula xml:id="formula_8">E (x,y)∼D [L(yf (x))] = E x1∼P [L(C(x 1 ))] + E z∼Z [L(−C(G(z)))].</formula><p>Thus, the objective functions of the discriminator/critic in many penalized GANs are equivalent to the ones from MMCs based on equation 6. We also have that L(z) = log(sigmoid(z)) corresponds to SGAN, L(z) = (1 − z) 2 corresponds to LSGAN, and L(z) = max(0, 1 − z) corresponds to HingeGAN. When g(z) = (z − 1) 2 , we also have that L(z) = z corresponds to WGAN-GP. Thus, most L p -norm gradient penalized GANs imply that the discriminator approximately maximize an expected L q -norm margin.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">WHY DO MAXIMUM-MARGIN CLASSIFIERS MAKE GOOD GAN DISCRIMINATORS/CRITICS?</head><p>To show that maximizing an expected margin leads to better GANs, we prove the following statements:</p><p>1. classifier maximizes an expected margin ⇐⇒ classifier has a fixed Lipschitz constant 2. MMC with a fixed Lipschitz constant =⇒ better gradients at fake samples 3. better gradients at fake samples =⇒ stable GAN training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">EQUIVALENCE BETWEEN GRADIENT NORM CONSTRAINTS AND LIPSCHITZ FUNCTIONS</head><p>As stated in Section 2.4, the WGAN-GP approach of softly enforcing ||∇xf (x)|| 2 ≈ 1 at all interpolations between real and fake samples does not ensure that we estimate the Wasserstein distance (W 1 ). On the other hand, we show here that enforcing ||∇ x f (x)|| 2 ≤ 1 is sufficient in order to estimate W 1 .</p><formula xml:id="formula_9">Assuming d(x 1 , x 2 ) is a L p -norm, p ≥ 2 and f (x) is differentiable, we have that: ||∇f (x)|| p ≤ K ⇐⇒ f is K-Lipschitz on L p .</formula><p>See appendix for the proof. <ref type="bibr" target="#b24">Adler and Lunz (2018)</ref> showed a similar result on dual norms.</p><p>This suggests that, in order to work on the set of Lipschitz functions, we should enforce that ||∇ x f (x)|| ≤ 1 for all x. This can be done, through equation 6, by choosing g(z) = (z 2 − 1) or, in approximation (using a soft-constraint), by choosing g(z) = max(0, z − 1). Petzka et al. <ref type="formula" target="#formula_32">(2017)</ref> suggested using a similar function (the square hinge) in order to only penalize gradient norms above 1.</p><p>If we let L(z) = z and g(z) = max(0, z − 1), we have an IPM over all Lipschitz functions. thus, we effectively approximate W 1 . This means that W 1 can be found through maximizing a geometric margin. Meanwhile, WGAN-GP only leads to a lower bound on W 1 .</p><p>Importantly, most successful GANs <ref type="bibr" target="#b25">(Brock et al., 2018;</ref><ref type="bibr" target="#b5">Karras et al., 2019;</ref> either enforce the 1-Lipschitz property using Spectral normalization <ref type="bibr" target="#b27">(Miyato et al., 2018)</ref> or use some form of gradient norm penalty <ref type="bibr" target="#b2">(Gulrajani et al., 2017;</ref><ref type="bibr" target="#b4">Mescheder et al., 2018)</ref>. Since 1-Lipschitz is equivalent to enforcing a gradient norm constraint (as shown above), we have that most successful GANs effectively train a discriminator/critic to maximize a geometric margin.</p><p>The above shows that training an MMC based on equation <ref type="formula" target="#formula_7">(6)</ref> is equivalent to training a classifier with a fixed Lipschitz constant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2">MMC LEADS TO BETTER GRADIENT AT FAKE SAMPLES</head><p>Consider a simple two-dimensional example where x = (x (1) , x (2) ). Let real data (class 1) be uniformly distributed on the line between (1, −1) and (1, 1). Let fake data (class 2) be uniformly distributed on the line between (−1, −1) and <ref type="figure">(−1, 1)</ref>. This is represented by <ref type="figure">Figure 1a</ref>. Clearly, the maximum-margin boundary is the line x (1) = 0 and any classifier should learn to ignore x (2) .</p><p>Consider a non-linear classifier of the form f (x) = sigmoid(w 1 x (1) + w 0 ) (See <ref type="figure">Figure 1b</ref>). To ensure we obtain an MMC, we need to enforce ||∇ x f (x)|| ≤ K.</p><p>The best classifier with Lipschitz constant K = 1 is obtained by choosing w 1 = 4. The maximummargin boundary is at x (1) = 0 (which we get by taking w 0 = 0; blue curve in <ref type="figure">Figure 1b</ref>); for this choice, we have that f (x r ) = .02 and f (x f ) = .98 for real (x r ) and fake (x f ) samples respectively. Meanwhile, if we take a slightly worse margin with boundary at x (1) = 1 4 (equivalent to choosing w 0 = −1; red curve in <ref type="figure">Figure 1b)</ref>, we have that f (x r ) = .01 and f (x f ) = .95 for real and fake samples respectively. Thus, both solutions almost perfectly classify the samples. However, the optimal margin has gradient .07, while the worse margin has gradient .03 at fake samples; this is why maximizing a margin lead to similar signal for real and fake samples. Furthermore, if we had enforced a bigger Lipschitz constant (K = 2), the best classifier would have been obtained with w 1 = 8 (green curve in <ref type="figure">Figure 1b</ref>); this would have caused vanishing gradients at fake samples unless we had scaled up the learning up. Thus, for a fixed or decreasing learning rate, it is important to fix K (and ideally to a small value) in order for the gradient signal to be strong at fake samples. Fake samples Real samples f(x(1))=sigmoid(4x(1)) f(x(1))=sigmoid(4x(1)−1) f(x(1))=sigmoid(8x(1)) (b) <ref type="figure">Figure 1</ref>: a) Two-dimensional GAN example with different choices of boundaries, b) ∇f (x (1) ) at different values of x (1) for the two-dimensional example assuming a sigmoid function.</p><p>In summary, the maximum-margin discriminator provides a stronger signal at fake samples by preventing a sharp change in the discriminator (i.e., small gradient near real/fake data and large gradient between real and fake data) and centering the classifier so that the gradients at real and fake samples are similar. This further suggests that imposing a gradient penalty in the interpolation between real and fake data (as done in WGAN-GP) is most sensible to ensure that the gradient norm remains small between real and fake data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.3">BETTER GRADIENTS AT FAKE SAMPLES IMPLIES STABLE GAN TRAINING</head><p>In GANs, the dynamics of the game depends in great part on ∇ x f f (x f ) where x f 's are samples from the fake, or generated, distribution. This is because the generator only learns through the discriminator/critic and it uses ∇ x f f (x f ) in order to improve its objective function. Thus, for stable training with a fixed or decreasing learning rate, ||∇ x f f (x f )|| should not be too small.</p><p>The above means that, in order to get stable GAN training, we need to ensure that we obtain a solution with a stable non-zero gradient around fake samples. Thus, it is preferable to solve the penalized formulation from equation equation 6 and choose a large penalty term λ in order to obtain a small-gradient solution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">ARE CERTAIN MARGINS BETTER THAN OTHERS?</head><p>It is well known that L p -norms (with p ≥ 1) are more sensitive to outliers as p increases which is why many robust methods minimize the L 1 -norm <ref type="bibr" target="#b28">(Bloomfield and Steiger, 1983)</ref>. Furthermore, minimizing the L 1 -norm loss results in a median estimator <ref type="bibr" target="#b28">(Bloomfield and Steiger, 1983)</ref>. This suggests that penalizing the L 2 gradient norm penalty (p = 2) may not lead to the most robust classifier. We hypothesize that L ∞ gradient norm penalties may improve robustness in comparison to L 2 gradient norm penalties since they correspond to maximizing L 1 -norm margin. In Section 6, we provide experimental evidence in support of our hypothesis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">EXPERIMENTS</head><p>Following our analysis and discussion in the previous sections, we hypothesized that L 1 margins, corresponding to a L ∞ gradient norm penalty, would perform better than L 2 margins (L 2 gradient norm penalty). As far as we know, researchers have not yet tried using a L ∞ gradient norm penalty in GANs. In addition, we showed that it would be more sensible to penalize violations of ||∇f (x)|| q ≤ 1 rather than ||∇f (x)|| q ≈ 1.</p><p>To test these hypotheses, we ran experiments on CIFAR-10 (a dataset of 60k images from 10 categories) <ref type="bibr" target="#b29">(Krizhevsky et al., 2009)</ref> using HingeGAN (L(z) = max(0, 1 − z)) and WGAN (L(z) = z) loss functions with L 1 , L 2 , L ∞ gradient norm penalties. We enforce either ||∇f (x)|| q ≈ 1 using Least Squares (LS) (g(z) = (z − 1) 2 ) or ||∇f (x)|| q ≤ 1 using Hinge (g(z) = max(0, z − 1)).</p><p>We used the standard hyperparameters: a learning rate (lr) of .0002, a batch size of 32, and the ADAM optimizer (Kingma and Ba, 2014) with parameters (α 1 , α 2 ) = (.50, .999) We used a DCGAN architecture <ref type="bibr" target="#b31">(Radford et al., 2015)</ref>. As per convention, we report the Fréchet Inception Distance (FID) <ref type="bibr" target="#b32">(Heusel et al., 2017)</ref>; lower values correspond to better generated outputs (higher quality and diversity). As per convention, all 50k images from the training part of the dataset were used for training and to calculate the FID. We ran all experiments using seed 1 and with gradient penalty λ = 20. Details on the architectures are in the Appendix. All models were trained using a single GPU. Code is available on https://github.com/AlexiaJM/MaximumMarginGANs. The results are shown in <ref type="table" target="#tab_1">Table 2</ref>. (||∇ x f (x))|| 1 − 1) 2 99.7 88.9 max(0, ||∇ x f (x))|| 1 − 1) 65.6 77.3</p><p>(||∇ x f (x))|| 2 − 1) 2 37.6 32.8 max(0, ||∇ x f (x))|| 2 − 1) 37.8 33.9</p><p>(</p><formula xml:id="formula_10">||∇ x f (x))|| ∞ − 1) 2 33.4 33.6 max(0, ||∇ x f (x))|| ∞ − 1) 36 27.1</formula><p>Due to space constraint, we only show the previously stated experiments in <ref type="table" target="#tab_1">Table 2</ref>. However, we also ran additional experiments on CIFAR-10 with 1) Relativistic paired and average HingeGAN, 2) β = (0, .90), 3) the standard CNN architecture from <ref type="bibr" target="#b27">Miyato et al. (2018)</ref>. Furthermore, we ran experiments on CAT <ref type="bibr" target="#b33">(Zhang et al., 2008)</ref> with 1) Standard CNN (in 32x32), and 2) DCGAN (in 64x64). These experiments correspond to <ref type="table">Table 3</ref>, 4, 5, 6, and 7 from the appendix.</p><p>In all sets of experiments, we generally observed that we obtain smaller FIDs by using: i) a larger q (as theorized), ii) the Hinge penalty to enforce an inequality gradient norm constraint (in both WGAN and HingeGAN), and iii) HingeGAN instead of WGAN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION</head><p>This work provides a framework in which to derive MMCs that results in very effective GAN loss functions. In the future, this could be used to derive new gradient norm penalties which further improve the performance of GANs. Rather than trying to devise better ways of enforcing 1-Lipschitz, researchers may instead want to focus on constructing better MMCs (possibly by devising better margins).</p><p>This research shows a strong link between GANs with gradient penalties, Wasserstein's distance, and SVMs. Maximizing the minimum L 2 -norm geometric margin, as done in SVMs, has been shown to lower bounds on the VC dimension which implies lower generalization error <ref type="bibr" target="#b34">(Vapnik and Vapnik, 1998;</ref><ref type="bibr" target="#b35">Mount, 2015)</ref>. This paper may help researchers bridge the gap needed to derive PAC bounds on Wasserstein's distance and GANs/IPMs with gradient penalty. Furthermore, it may be of interest to theoreticians whether certain margins lead to lower bounds on the VC dimension.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">ACKNOWLEDGEMENTS</head><p>This work was supported by Borealis AI through the Borealis AI Global Fellowship Award. We would also like to thank Compute Canada and Calcul Québec for the GPUs which were used in this work. This work was also partially supported by the FRQNT new researcher program (2019-NC-257943), the NSERC Discovery grant (RGPIN-2019-06512), a startup grant by IVADO, a grant by Microsoft Research and a Canada CIFAR AI chair. <ref type="table" target="#tab_0">A DETAILS ON EXPERIMENTS FOR TABLE 1</ref> The classifier was a 4 layers fully-connected neural network with ReLU activation functions. It was trained for 10K iterations with the cross-entropy loss, the ADAM optimizer, a batch size of 256, λ = 10, and a learning rate of .00005. The margins (as in equation 3) were estimated using Gradient Descent with the Augmented Lagrangian method <ref type="bibr" target="#b36">(Hestenes, 1969)</ref> until |f (x 0 )| &lt; .01. We estimated the expected margin using the average margin from 256 random samples of both classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDICES</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B ADDITIONAL EXPERIMENTS</head><p>Note that the smooth maximum is defined as</p><formula xml:id="formula_11">smax(x (1) , . . . , x (k) ) = k i=1 x (i) e xi k i=1 e xi .</formula><p>We sometime use the smooth maximum as a smooth alternative to the L ∞ -norm margin; results are worse with it. <ref type="table">Table 3</ref>: FID after 100k generator iterations on CIFAR-10 using the same setting as Table1, but we are using Relativistic paired and average GANs.</p><formula xml:id="formula_12">g(||∇ x f (x))|| q ) RpHinge RaHinge (||∇ x f (x))|| 1 − 1) 2 64.4 65.0 max(0, ||∇ x f (x))|| 1 − 1)</formula><p>60.3 68.5</p><p>(||∇ x f (x))|| 2 − 1) 2 32.8 31.9 max(0, ||∇ x f (x))|| 2 − 1) 32.6 35.0</p><p>(||∇ x f (x))|| ∞ − 1) 2 32.5 33.5 max(0, ||∇ x f (x))|| ∞ − 1)</p><p>28.2 28.4</p><p>(smax|∇ x f (x)| − 1) 2 133.7 124.0 max(0, smax|∇ x f (x)| − 1) 30.5 30.3 <ref type="table">Table 4</ref>: FID after 100k generator iterations on CIFAR-10 using the same setting as Table1, but we are using Adam β = (0, .90).</p><formula xml:id="formula_13">g(||∇ x f (x))|| q ) WGAN HingeGAN (||∇ x f (x))|| 1 − 1) 2 163.2 179.0 max(0, ||∇ x f (x))|| 1 − 1)</formula><p>66.9 66.1</p><p>(||∇ x f (x))|| 2 − 1) 2 34.6 33.8 max(0, ||∇ x f (x))|| 2 − 1) 37.0 34.9</p><p>(||∇ x f (x))|| ∞ − 1) 2 37.5 33.9 max(0, ||∇ x f (x))|| ∞ − 1)</p><p>38.3 28.6</p><p>(smax|∇ x f (x)| − 1) 2 31.9 283.1 max(0, smax|∇ x f (x)| − 1) 31.8 32.1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C MARGINS IN RELATIVISTIC GANS</head><p>Relativistic paired GANs (RpGANs) and Relativistic average GANs (RaGAN) <ref type="bibr" target="#b6">(Jolicoeur-Martineau, 2018b;</ref><ref type="bibr" target="#b7">2019)</ref> are GAN variants which tend to be more stable than their non-relativistic counterparts. These methods are not yet well understood and its unclear how to incorporate gradient penalty from our framework into these approach. In this subsection, we explain how we can link both approaches to MMCs. <ref type="table">Table 5</ref>: FID after 100k generator iterations on CIFAR-10 using the same setting as Table1, but we are using the standard CNN architecture.</p><formula xml:id="formula_14">g(||∇ x f (x))|| q ) WGAN HingeGAN (||∇ x f (x))|| 2 − 1) 2 30.2 26.1 max(0, ||∇ x f (x))|| 2 − 1) 31.8 27.3 max(0, ||∇ x f (x))|| ∞ − 1) 74.3 21.</formula><p>3 <ref type="table">Table 6</ref>: FID after 100k generator iterations on CAT (in 32x32) using the same setting as <ref type="table" target="#tab_0">Table  1</ref>, but we are using the standard CNN architecture. Exceptionally, this set of experiment showed convergence at around 10-40k iterations (this has not been the case in any of the other experiments).</p><p>For this reason, we show also the lowest FID obtained during training (FID was measured at every 10k iterations).</p><formula xml:id="formula_15">g(||∇ x f (x))|| q ) WGAN HingeGAN At 100k iterations (||∇ x f (x))|| 2 − 1) 2 27.3 19.5 max(0, ||∇ x f (x))|| 2 − 1) 21.4 23.9 max(0, ||∇ x f (x))|| ∞ − 1) 66.5 24.0 Lowest FID obtained (||∇ x f (x))|| 2 − 1) 2 20.9 16.2 max(0, ||∇ x f (x))|| 2 − 1) 19.4 17.0 max(0, ||∇ x f (x))|| ∞ − 1)</formula><p>32.32 9.5 <ref type="table">Table 7</ref>: FID after 100k generator iterations on CAT (in 64x64) using the same setting as <ref type="table" target="#tab_0">Table 1</ref>.</p><formula xml:id="formula_16">g(||∇ x f (x))|| q ) WGAN HingeGAN</formula><p>(||∇ x f (x))|| 2 − 1) 2 48.2 26.7 max(0, ||∇ x f (x))|| 2 − 1) 43.7 29.6 max(0, ||∇ x f (x))|| ∞ − 1) 18.3 17.5 </p><formula xml:id="formula_17">g(||∇ x f (x))|| q ) WGAN HingeGAN (smax|∇ x f (x)| − 1) 2 35.3 197.9 max(0, smax|∇ x f (x)| − 1) 31.4 29.5</formula><p>Relativistic paired GANs (RpGANs) are defined as:</p><formula xml:id="formula_18">max C:X →R E x1∼P z∼Z [f (C(x 1 ) − C(G(z)))] , max G E x1∼P z∼Z [f (C(G(z)) − C(x 1 ))] ,</formula><p>and Relativistic average GANs (RaGANs) are defined as:</p><formula xml:id="formula_19">max C:X →R E x1∼P [f 1 (C(x 1 ) − E z∼Z C(G(z))))] + E z∼Z [f 2 (C(G(z)) − E x1∼P C(x 1 ))] , max G E z∼Z [f 1 (C(G(z)) − E x1∼P C(x 1 )))] + E x1∼P [f 2 (C(x 1 ) − E z∼Z C(G(z)))] ,</formula><p>where f, f 1 , f 2 : R → R.</p><p>Most loss functions can be represented as RaGANs or RpGANs; SGAN, LSGAN, and HingeGAN all have relativistic counterparts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.1 RELATIVISTIC AVERAGE GANS</head><p>From the loss function of RaGAN, we can deduce its decision boundary. Contrary to typical classifiers, we define two boundaries, depending on the label. The two surfaces are defined as two sets of points (x 0 , y 0 ) such that:</p><formula xml:id="formula_20">f (x 0 ) = E x∼Q [f (x)], when y 0 = 1(real) f (x 0 ) = E x∼P [f (x)], when y 0 = −1(fake)</formula><p>It can be shown that the relativistic average geometric margin is approximated as:</p><formula xml:id="formula_21">γ Ra p (x, y) ≈ ((y + 1)/2)(f (x) − E x∼Q [f (x)]) ||∇ x f (x)|| q + ((y − 1)/2)(f (x) − E x∼P [f (x)]) ||∇ x f (x)|| q = α Ra (x, y) β(x) .</formula><p>Maximizing the boundary of RaGANs can be done in the following way:</p><formula xml:id="formula_22">min f E (x,y)∼D [L(α Ra (x, y)) + λg(||∇ x f (x)|| q )] .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2 RELATIVISTIC PAIRED GANS</head><p>From its loss function (as described in section 2.4), it is not clear what the boundary of RpGANs can be. However, through reverse engineering, it is possible to realize that the boundary is the same as the one from non-relativistic GANs, but using a different margin. We previously derived that the approximated margin (non-geometric) for any point is γ p (x) ≈ |f (x)| ||∇xf (x)||q . We define the geometric margin as the margin after replacing |f (x)| by yf (x) so that it depends on both x and y. However, there is an alternative way to transform the margin in order to achieve a classifier. We call it the relativistic paired margin:</p><formula xml:id="formula_23">γ * p (x 1 , x 2 ) = γ p (x 1 ) − γ p (x 2 ) ≈ f (x 1 ) ||∇ x1 f (x 1 )|| q − f (x 2 ) ||∇ x2 f (x 2 )|| q .</formula><p>where x 1 is a sample from P and x 2 is a sample from Q. This alternate margin does not depend on the label y, but only ask that for any pair of class 1 (real) and class 2 (fake) samples, we maximize the relativistic paired margin. This margin is hard to work with, but if we enforce ||∇ x1 f (x 1 )|| q ≈ ||∇ x2 f (x 2 )|| q , for all x 1 ∼ P,x 2 ∼ Q, we have that:</p><formula xml:id="formula_24">γ * p (x 1 , x 2 ) ≈ f (x 1 ) − f (x 2 ) ||∇ x f (x)|| q ,</formula><p>where x is any sample (from class 1 or 2).</p><p>Thus, we can train an MMC to maximize the relativistic paired margin in the following way:</p><formula xml:id="formula_25">min f E x1∼P z∼Z [L(f (x 1 ) − f (G(z)))] + λE (x,y)∼D [g(||∇ x f (x)|| q )] ,</formula><p>where g must constrains ||∇ x f (x)|| q to a constant.</p><p>This means that minimizing L(f (x 1 ) − f (x 2 )) without gradient penalty can be problematic if we have different gradient norms at samples from class 1 (real) and 2 (fake). This provides an explanation as to why RpGANs do not perform very well unless using a gradient penalty (Jolicoeur-Martineau, 2018b).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D PROOFS</head><p>Note that both of the following formulations represent the margin:</p><formula xml:id="formula_26">γ(x) = min x0 ||x 0 − x|| s.t. f (x 0 ) = 0 = min r ||r|| s.t. f (x + r) = 0 D.1 BOUNDED GRADIENT ⇐⇒ LIPSCHITZ</formula><p>Assume that f : X → R and X is a convex set.</p><formula xml:id="formula_27">Letx(α) = αx 1 + (1 − α)x 2 ,</formula><p>where α ∈ [0, 1] be the interpolation between any two points x 1 , x 2 ∈ X. We know thatx(α) ∈ X for any α ∈ [0, 1] by convexity of X.</p><formula xml:id="formula_28">f (x 1 ) − f (x 2 ) = f (x(1)) − f (x(0)) = 1 0 df (x(α)) dα dα = 1 0 ∇f (x(α))x (α) dα dα = 1 0 ∇f (x(α))(x 1 − x 2 )dα = (x 1 − x 2 ) 1 0 ∇f (x(α))dα 1) We show ||∇f (x)|| p ≤ K =⇒ |f (x)−f (y)| ||x−y||p ≤ K for all x, y:</formula><p>Let ||∇f (x)|| p ≤ K for all x ∈ X.</p><p>|f (x 1 ) − f (x 2 )| = ||(x 1 − x 2 ) Assume p ≥ 2 and 1 p + 1 q = 1.</p><formula xml:id="formula_29">||∇ x f (x)|| p ≤ ||∇ x f (x)|| q since p ≥ q = max v ∇ x f (x) T v s.t. ||v|| p ≤ 1 = ∇ x f (x) T v * where v * is the optimum = lim h→0 f (x + hv * ) − f (x) h ≤ lim h→0 |f (x + hv * ) − f (x)| h||v * || p = lim h→0 |f (x + hv * ) − f (x)| ||x + hv * − x|| p ≤ K</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2 TAYLOR APPROXIMATION</head><p>Let r = x 0 − x; at the boundary x 0 , we have that f (x 0 ) = f (x + r) = C, for some constant C. In the paper, we use generally assume C = 0. We will make use of the following Taylor approximations:</p><formula xml:id="formula_30">f (x + r) ≈ f (x) + ∇ x f (x) T r =⇒ f (x) − C ≈ −∇ x f (x) T r and f (x) ≈ f (x 0 ) + ∇ x0 f (x 0 ) T (x − x 0 ) =⇒ f (x) − C ≈ −∇ x0 f (x 0 ) T r</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.3 TAYLOR APPROXIMATION (AFTER SOLVING)</head><p>To make things easier, we maximize (γ 2 (x)) 2 instead of γ 2 (x). We also maximize with respect to x 0 instead of r:</p><formula xml:id="formula_31">γ 2 2 (x) = min x0 ||x 0 − x|| 2 2 s.t. f (x 0 ) = 0 = min x0 ||x 0 − x|| 2 2 − λf (x 0 ),</formula><p>where λ is a scalar (Lagrange multiplier). We can then differentiate with respect to x 0 : ∇ x0 γ 2 2 (x) = (x 0 − x) + λ∇ x0 f (x 0 ) = 0.</p><p>We will then use a inner product to be able to extract the optimal Lagrange multiplier:</p><formula xml:id="formula_33">=⇒ − ∇ x0 f (x 0 ) T (x 0 − x) = λ * ∇ x0 f (x 0 ) T ∇ x0 f (x 0 ) =⇒ λ * = − ∇ x0 f (x 0 ) T (x 0 − x) ∇ x0 f (x 0 ) T ∇ x0 f (x 0 ) =⇒ λ * = − ∇ x0 f (x 0 ) T (x 0 − x) ||∇ x0 f (x 0 )|| 2</formula><p>Now, we plug-in the optimal Langrange multiplier into equation equation 7 and we use a inner product: </p><formula xml:id="formula_34">=⇒ x 0 − x = −λ∇ x0 f (x 0 ) =⇒ x 0 − x = ∇ x0 f (x 0 ) T (x 0 − x) ||∇ x0 f (x 0 )|| 2 2 ∇ x0 f (x 0 ) =⇒ (x 0 − x) T (x 0 − x) = ∇ x0 f (x 0 ) T (x 0 − x) 2 ||∇ x0 f (x 0 )|| 2 2 =⇒ γ 2 2 (x) = ||x 0 − x|| 2 2 = ∇ x0 f (x 0 ) T (x 0 − x) 2 ||∇ x0 f (x 0 )|| 2 2 =⇒ γ 2 (x) = ∇ x0 f (x 0 ) T (x 0 − x)<label>||∇</label></formula></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>≤</head><label></label><figDesc>K||x 1 − x 2 || p 2) We show |f (x)−f (y)| ||x−y||p ≤ K for all x, y =⇒ ||∇f (x)|| p ≤ K for p ≥ 2:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>x0 f (x 0 )|| 2 D.4 TAYLOR APPROXIMATION (BEFORE SOLVING) min r ||r|| p s.t. f (x + r) = C ≈ min r ||r|| p s.t. f (x) + ∇ x f (x) T r = C =⇒ min r ||r|| p = |f (x) − C| max r |∇xf (x) T r| ||r||p = |f (x) − C| max r ∇xf (x) T r ||r||p = |f (x) − C| max r ∇ x f (x) T r ||r||p = |f (x) − C| max ||r||p≤1 ∇ x f (x) T r = |f (x) − C| ||∇ x f (x)|| q ,where 1 p + 1 q = 1 This is true because of the definition of the Dual norm<ref type="bibr" target="#b37">(Rudin, 1991)</ref>:||a|| * = max ||r||p≤1 a T r = max r a T r ||r|| p = ||a|| qFor a standard classifier, we have C = 0. For a RaGAN, we have C = E Q [f (x)] when y = 1 (real) and C = E P [f (x)] when y = −1 (fake).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Expected L p Margin for different types of gradient penalties (or none). Classifier was trained on the swiss-roll dataset with a cross-entropy loss function.</figDesc><table><row><cell></cell><cell cols="3">Expected L p Margin</cell></row><row><cell>Type of gradient penalty</cell><cell cols="3">p = 2 p = 1 p = ∞</cell></row><row><cell>No gradient penalty</cell><cell>.27</cell><cell>.25</cell><cell>.24</cell></row><row><cell>g(z) = (z − 1) 2</cell><cell></cell><cell></cell><cell></cell></row><row><cell>L 2 gradient penalty (L 2 margin)</cell><cell>.62</cell><cell>.75</cell><cell>.64</cell></row><row><cell>L ∞ gradient penalty (L 1 margin)</cell><cell>.43</cell><cell>.58</cell><cell>.33</cell></row><row><cell>L 1 gradient penalty (L ∞ margin)</cell><cell>.69</cell><cell>.85</cell><cell>.60</cell></row><row><cell>g(z) = max(0, z − 1)</cell><cell></cell><cell></cell><cell></cell></row><row><cell>L 2 gradient penalty (L 2 margin)</cell><cell>.43</cell><cell>.53</cell><cell>.37</cell></row><row><cell>L ∞ gradient penalty (L 1 margin)</cell><cell>.41</cell><cell>.56</cell><cell>.31</cell></row><row><cell>L 1 gradient penalty (L ∞ margin)</cell><cell>.43</cell><cell>.44</cell><cell>.42</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Fréchet Inception Distance (FID) after 100k generator iterations on CIFAR-10.</figDesc><table /><note>g(||∇ x f (x))|| q ) WGAN HingeGAN</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 8 :</head><label>8</label><figDesc>Extras from Table 1</figDesc><table /><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<ptr target="http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>Z. Ghahramani, M. Welling, C. Cortes, N. D. Lawrence, and K. Q. Weinberger</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexia</forename><surname>Jolicoeur-Martineau</surname></persName>
		</author>
		<title level="m">Gans beyond divergence minimization. arXiv preprint arXiv:xxxx</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Improved training of wasserstein gans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishaan</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Faruk</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Dumoulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron C</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">;</forename><forename type="middle">I</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><forename type="middle">V</forename><surname>Luxburg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vishwanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Garnett</surname></persName>
		</author>
		<ptr target="http://papers.nips.cc/paper/7159-improved-training-of-wasserstein-gans.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="5767" to="5777" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Many paths to equilibrium: Gans do not need to decrease a divergence at every step</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Fedus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihaela</forename><surname>Rosca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balaji</forename><surname>Lakshminarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shakir</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Goodfellow</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.08446</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Which training methods for gans do actually converge?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><surname>Mescheder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Nowozin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.04406</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A style-based generator architecture for generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tero</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuli</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Aila</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4401" to="4410" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">The relativistic discriminator: a key element missing from standard gan</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexia</forename><surname>Jolicoeur-Martineau</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.00734</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexia</forename><surname>Jolicoeur-Martineau</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.02474</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">On relativistic f -divergences. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Least squares generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xudong</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qing</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoran</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">K</forename><surname>Raymond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><forename type="middle">Paul</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smolley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2813" to="2821" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jae</forename><forename type="middle">Hyun</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jong</forename><surname>Chul Ye</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.02894</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">Geometric gan. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Integral probability metrics and their generating classes of functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alfred</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Applied Probability</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="429" to="443" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Wasserstein generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="214" to="223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asja</forename><surname>Henning Petzka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denis</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lukovnicov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.08894</idno>
		<title level="m">On the regularization of wasserstein gans</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Many paths to equilibrium: Gans do not need to decrease adivergence at every step</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Fedus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihaela</forename><surname>Rosca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balaji</forename><surname>Lakshminarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shakir</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Goodfellow</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.08446</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naveen</forename><surname>Kodali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Abernethy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zsolt</forename><surname>Kira</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.07215</idno>
		<title level="m">On convergence and stability of gans</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Margin maximization for robust classification using deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Matyasko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lap-Pui</forename><surname>Chau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 International Joint Conference on Neural Networks (IJCNN)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="300" to="307" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Large margin deep networks for classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gamaleldin</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilip</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hossein</forename><surname>Mobahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Regan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="842" to="852" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Convex optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lieven</forename><surname>Vandenberghe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>Cambridge university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Otto</forename><surname>Hölder</surname></persName>
		</author>
		<title level="m">via an averaging clause. Messages from the Society of Sciences and the Georg-Augusts-Universität zu Göttingen</title>
		<imprint>
			<date type="published" when="1889" />
			<biblScope unit="volume">1889</biblScope>
			<biblScope unit="page" from="38" to="47" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">An extension of a certain theorem in inequalities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonhard</forename><forename type="middle">James</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rogers</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Messenger of Math</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="145" to="150" />
			<date type="published" when="1888" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Support-vector networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Corinna</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="273" to="297" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Nonlinear programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Harold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert W</forename><surname>Kuhn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tucker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proceedings of the second berkeley symposium on mathematical statistics and probability</title>
		<editor>j. neyman</editor>
		<meeting>the second berkeley symposium on mathematical statistics and probability</meeting>
		<imprint>
			<date type="published" when="1951" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Karush</surname></persName>
		</author>
		<title level="m">Minima of functions of several variables with inequalities as side constraints. M. Sc. Dissertation. Dept. of Mathematics</title>
		<imprint>
			<date type="published" when="1939" />
		</imprint>
		<respStmt>
			<orgName>Univ. of Chicago</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Machine learning: an algorithmic perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Marsland</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CRC press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Banach wasserstein gan</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonas</forename><surname>Adler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Lunz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="6754" to="6763" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Large scale gan training for high fidelity natural image synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Brock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.11096</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Progressive growing of gans for improved quality, stability, and variation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tero</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Aila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuli</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaakko</forename><surname>Lehtinen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.10196</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeru</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toshiki</forename><surname>Kataoka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masanori</forename><surname>Koyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuichi</forename><surname>Yoshida</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.05957</idno>
		<title level="m">Spectral normalization for generative adversarial networks</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Least absolute deviations: theory, applications, and algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Bloomfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>William</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Steiger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>Citeseer</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Unsupervised representation learning with deep convolutional generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06434</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Gans trained by a two time-scale update rule converge to a local nash equilibrium</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Heusel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hubert</forename><surname>Ramsauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Nessler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6626" to="6637" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Cat head detection-how to effectively exploit shape and texture features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiwei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="802" to="816" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Statistical learning theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vlamimir</forename><surname>Vapnik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>Wiley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">How sure are you that large margin implies low vc dimension? Win-Vector Blog</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Mount</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Journal of optimization theory and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Magnus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hestenes</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1969" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="303" to="320" />
		</imprint>
	</monogr>
	<note>Multiplier and gradient methods</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Functional analysis, mcgrawhill. Inc</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Walter Rudin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991" />
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
