<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Jointly Learning Entity and Relation Representations for Entity Alignment</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuting</forename><surname>Wu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Wangxuan Institute of Computer Technology</orgName>
								<orgName type="institution" key="instit2">Peking University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Wangxuan Institute of Computer Technology</orgName>
								<orgName type="institution" key="instit2">Peking University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yansong</forename><surname>Feng</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Wangxuan Institute of Computer Technology</orgName>
								<orgName type="institution" key="instit2">Peking University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">The MOE Key Laboratory of Computational Linguistics</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Wang</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">School of Computing</orgName>
								<orgName type="institution">University of Leeds</orgName>
								<address>
									<country key="GB">U.K</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongyan</forename><surname>Zhao</surname></persName>
							<email>zhaodongyan@pku.edu.cnz.wang5@leeds.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Wangxuan Institute of Computer Technology</orgName>
								<orgName type="institution" key="instit2">Peking University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">The MOE Key Laboratory of Computational Linguistics</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Jointly Learning Entity and Relation Representations for Entity Alignment</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T07:14+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Entity alignment is a viable means for integrating heterogeneous knowledge among different knowledge graphs (KGs). Recent developments in the field often take an embeddingbased approach to model the structural information of KGs so that entity alignment can be easily performed in the embedding space. However, most existing works do not explicitly utilize useful relation representations to assist in entity alignment, which, as we will show in the paper, is a simple yet effective way for improving entity alignment. This paper presents a novel joint learning framework for entity alignment. At the core of our approach is a Graph Convolutional Network (GCN) based framework for learning both entity and relation representations. Rather than relying on pre-aligned relation seeds to learn relation representations, we first approximate them using entity embeddings learned by the GCN. We then incorporate the relation approximation into entities to iteratively learn better representations for both. Experiments performed on three real-world cross-lingual datasets show that our approach substantially outperforms state-of-the-art entity alignment methods. Recent studies have shown that jointly modeling entities and relations in a single framework can arXiv:1909.09317v1 [cs.CL]</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Knowledge graphs (KGs) transform unstructured knowledge into simple and clear triples of &lt;head entity, relation, tail entity&gt; for rapid response and reasoning of knowledge. They are an effective way for supporting various NLP-enabled tasks like machine reading <ref type="bibr" target="#b27">(Yang and Mitchell, 2017)</ref>, information extraction <ref type="bibr" target="#b23">(Wang et al., 2018a)</ref>, and question-answering .</p><p>Even though many KGs originate from the same resource, e.g., Wikipedia, they are usually created independently. Therefore, different KGs often use * Corresponding author. different expressions and surface forms to indicate equivalent entities and relations -let alone those built from different resources or languages. This common problem of heterogeneity makes it difficult to integrate knowledge among different KGs. A powerful technique to address this issue is Entity Alignment, the task of linking entities with the same real-world identity from different KGs.</p><p>Classical methods for entity alignment typically involve a labor-intensive and time-consuming process of feature construction <ref type="bibr" target="#b11">(Mahdisoltani et al., 2013)</ref> or rely on external information constructed by others <ref type="bibr" target="#b19">(Suchanek et al., 2011)</ref>. Recently, efforts have been devoted to the so-called embeddingbased approaches. Representative works of this direction include JE <ref type="bibr" target="#b5">(Hao et al., 2016)</ref>, MTransE <ref type="bibr" target="#b3">(Chen et al., 2017)</ref>, JAPE , IP-TransE <ref type="bibr" target="#b31">(Zhu et al., 2017)</ref>, and BootEA <ref type="bibr" target="#b21">(Sun et al., 2018)</ref>. More recent work <ref type="bibr" target="#b25">(Wang et al., 2018b)</ref> uses the Graph Convolutional Network (GCN) <ref type="bibr" target="#b8">(Kipf and Welling, 2017)</ref> to jointly embed multiple KGs.</p><p>Most of the recent works (e.g., JE, MTransE, JAPE, IPTransE and BootEA) rely on the translation-based models, such as TransE <ref type="bibr" target="#b1">(Bordes et al., 2013)</ref>, which enable these approaches to encode both entities and relations of KGs. These methods often put more emphasis on the entity embeddings, but do not explicitly utilize relation embeddings to help with entity alignment. Another drawback of such approaches is that they usually rely on pre-aligned relations <ref type="bibr">(JAPE and IPTransE)</ref> or triples <ref type="bibr">(MTransE)</ref>. This limits the scale at which the model can be effectively performed due to the overhead for constructing seed alignments for large KGs. Alternative methods like GCN-based models, unfortunately, cannot directly obtain relation representations, leaving much room for improvement. improve tasks like information extraction <ref type="bibr" target="#b13">(Miwa and Bansal, 2016;</ref><ref type="bibr" target="#b0">Bekoulis et al., 2018)</ref>. We hypothesize that this will be the case for entity alignment too; that is, the rich relation information could be useful for improving entity alignment as entities and their relations are usually closely related. Our experiments show that this is even a conservative target: by jointly learning entity and relation representations, we can promote the results of both entity and relation alignment.</p><p>In this work, we aim to build a learning framework that jointly learns entity and relation representations for entity alignment; and we want to achieve this with only a small set of pre-aligned entities but not relations. Doing so will allow us to utilize relation information to improve entity alignment without paying extra cost for constructing seed relation alignments.</p><p>Our work is enabled by the recent breakthrough effectiveness of GCNs <ref type="bibr" target="#b8">(Kipf and Welling, 2017)</ref> in extracting useful representations from graph structures. Although GCNs provide a good starting point, applying it to develop a practical and efficient framework to accurately capture relation information across KGs is not trivial. Because a vanilla GCN operates on the undirected and unlabeled graphs, a GCN-based model like <ref type="bibr" target="#b25">(Wang et al., 2018b)</ref> would ignore the useful relation information of KGs. While the Relational Graph Convolutional Network (R-GCN) <ref type="bibr" target="#b17">(Schlichtkrull et al., 2018)</ref> can model multi-relational graphs, existing R-GCNs use a weight matrix for each relation. This means that an R-GCN would require an excessive set of parameters to model thousands of relations in a typical real-world KG, making it difficult to learn an effective model on large KGs.</p><p>A key challenge of our joint learning framework is how to generate useful relation representations at the absence of seed relation alignments, and to ensure the framework can scale to a large number of types of relations. We achieve this by first approximating the relation representations using entity embeddings learned through a small amount of seed entity alignments. We go further by constructing a new joint entity representation consisting of both relation information and neighboring structural information of an entity. The joint representations allow us to iteratively improve the model's capability of generating better entity and relation representations, which lead to not only better entity alignment, but also more accurate re-lation alignment as a by-product.</p><p>We evaluate our approach by applying it to three real-world datasets. Experimental results show that our approach delivers better and more robust results when compared with state-of-the-art methods for entity and relation alignments. The key contribution of this paper is a novel joint learning model for entity and relation alignments. Our approach reduces the human involvement and the associated cost in constructing seed alignments, but yields better performance over prior works.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Entity Alignment</head><p>Until recently, entity alignment would require intensive human participation <ref type="bibr" target="#b22">(Vrandečić and Krötzsch, 2014)</ref> to design hand-crafted features <ref type="bibr" target="#b11">(Mahdisoltani et al., 2013)</ref>, rules, or rely on external sources <ref type="bibr" target="#b24">(Wang et al., 2017)</ref>. In a broader context, works in schema and ontology matching also seek help from additional information by using e.g., extra data sources <ref type="bibr" target="#b14">(Nguyen et al., 2011)</ref>, entity descriptions <ref type="bibr" target="#b9">(Lacoste-Julien et al., 2013;</ref><ref type="bibr" target="#b28">Yang et al., 2015)</ref>, or semantics of the web ontology language <ref type="bibr" target="#b6">(Hu et al., 2011)</ref>. Performance of such schemes is bounded by the quality and availability of the extra information about the target KG, but obtaining sufficiently good-quality annotated data could be difficult for large KGs.</p><p>Recently, embedding-based entity alignment methods were proposed to reduce human involvement. JE <ref type="bibr" target="#b5">(Hao et al., 2016)</ref> was among the first attempts in this direction. It learns embeddings of different KGs in a uniform vector space where entity alignment can be performed. MTransE <ref type="bibr" target="#b3">(Chen et al., 2017)</ref> encodes KGs in independent embeddings and learns transformation between KGs. BootEA <ref type="bibr" target="#b21">(Sun et al., 2018</ref>) exploits a bootstrapping process to learn KG embeddings. SEA <ref type="bibr" target="#b15">(Pei et al., 2019)</ref> proposes a degree-aware KG embedding model to embed KGs. KDCoE <ref type="bibr" target="#b2">(Chen et al., 2018)</ref> is a semi-supervised learning approach for co-training embeddings for multilingual KGs and entity descriptions. They all use translation-based models as the backbone to embed KGs.</p><p>Non-translational embedding-based methods include recent works on a GCN-based model <ref type="bibr" target="#b25">(Wang et al., 2018b)</ref> and NTAM <ref type="bibr" target="#b10">(Li et al., 2018)</ref>. Additionally, most recent work, RDGCN <ref type="bibr" target="#b26">(Wu et al., 2019)</ref>, introduces the dual relation graph to model the relation information of KGs. Through multiple rounds of interactions between the primal and dual graphs, RDGCN can effectively incorporate more complex relation information into entity representations and achieve promising results for entity alignment. However, existing methods only focus on entity embeddings and ignore the help that relation representations can provide on this task.</p><p>MTransE and NTAM are two of a few methods that try to perform both relation and entity alignments. However, both approaches require high-quality seed alignments, such as pre-aligned triples or relations, for relation alignment. Our approach advances prior works by jointly modeling entities and relations by using only a small set of pre-aligned entities (but not relations) to simultaneously perform entity and relation alignments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Graph Convolutional Networks</head><p>GCNs <ref type="bibr" target="#b4">(Duvenaud et al., 2015;</ref><ref type="bibr" target="#b7">Kearnes et al., 2016;</ref><ref type="bibr" target="#b8">Kipf and Welling, 2017)</ref> are neural networks operating on unlabeled graphs and inducing features of nodes based on the structures of their neighborhoods. Recently, GCNs have demonstrated promising performance in tasks like node classification (Kipf and Welling, 2017), relation extraction , semantic role labeling <ref type="bibr" target="#b12">(Marcheggiani and Titov, 2017)</ref>, etc. As an extension of GCNs, the R-GCNs <ref type="bibr" target="#b17">(Schlichtkrull et al., 2018)</ref> have recently been proposed to model relational data for link prediction and entity classification. However, R-GCNs usually require a large number of parameters that are often hard to train, when applied to multi-relational graphs.</p><p>In this work, we choose to use GCNs to first encode KG entities and to approximate relation representations based on entity embeddings. Our work is the first to utilize GCNs for jointly aligning entities and relations for heterogeneous KGs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Problem Formulation</head><p>We now introduce the notations used in this paper and define the scope of this work.</p><p>A KG is formalized as G = (E, R, T ), where E, R, T are the sets of entities, relations and triples, respectively. Let G 1 = (E 1 , R 1 , T 1 ) and G 2 = (E 2 , R 2 , T 2 ) be two different KGs. Usually, some equivalent entities between KGs are already known, defined as alignment seeds L = {(e i 1 , e i 2 )|e i 1 ∈ E 1 , e i 2 ∈ E 2 }.</p><p>We define the task of entity or relation align-ment as automatically finding more equivalent entities or relations based on known alignment seeds. In our model, we only use known aligned entity pairs as training data for both entity and relation alignments. The process of relation alignment in our framework is unsupervised, which does not need pre-aligned relation pairs for training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Our Approach</head><p>Given two target KGs, G 1 and G 2 , and a set of known aligned entity pairs L, our approach uses GCNs (Kipf and Welling, 2017) with highway network <ref type="bibr" target="#b18">(Srivastava et al., 2015)</ref> gates to embed entities of the two KGs and approximate relation semantics based on entity representations. By linking entity representations with relation representations, they promote each other in our framework and ultimately achieve better alignment results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Overall Architecture</head><p>As illustrated in <ref type="figure" target="#fig_0">Figure 1</ref>, our approach consists of three stages: (1) preliminary entity alignment, (2) approximating relation representations, and (3) joint entity and relation alignment.</p><p>In the first stage, we utilize GCNs to embed entities of various KGs in a unified vector space for preliminary entity alignment. Next, we use the entity embeddings to approximate relation representations which can be used to align relations across KGs. In the third stage, we incorporate the relation representations into entity embeddings to obtain the joint entity representations, and continue using GCNs to iteratively integrate neighboring structural information to achieve better entity and relation representations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Preliminary Entity Alignment</head><p>As shown in <ref type="figure" target="#fig_0">Figure 1</ref>, we put G 1 and G 2 in one graph G a = (E a , R a , T a ) to form our model's input. We utilize pre-aligned entity pairs to train our model and then discover latent aligned entities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Graph Convolutional Layers.</head><p>Our entity alignment model utilizes GCNs to embed entities in G a . Our model consists of multiple stacked GCN layers so that it can incorporate higher degree neighborhoods. The input for GCN layer l is a node feature matrix,</p><formula xml:id="formula_0">X (l) = {x (l) 1 , x (l) 2 , ..., x (l) n |x (l) i ∈ R d (l) },</formula><p>where n is the number of nodes (entities) of G a , and d (l) is the number of features in layer l. X (l) is updated us- ing forward propagation as:</p><formula xml:id="formula_1">X (l+1) = ReLU(D − 1 2ÃD − 1 2 X (l) W (l) ), (1) whereÃ = A + I is the adjacency matrix of G a with self-connections, I is an identity matrix, D jj = kÃ jk , and W (l) ∈ R d (l) ×d (l+1) is a layer- specific trainable weight matrix.</formula><p>Inspired by <ref type="bibr" target="#b16">(Rahimi et al., 2018</ref>) that uses highway gates <ref type="bibr" target="#b18">(Srivastava et al., 2015)</ref> to control the noise propagation in GCNs for geographic localization, we also employ layer-wise highway gates to build a Highway-GCN (HGCN) model. Our layer-wise gates work as follow:</p><formula xml:id="formula_2">T (X (l) ) = σ(X (l) W (l) T + b (l) T ),<label>(2)</label></formula><formula xml:id="formula_3">X (l+1) = T (X (l) )·X (l+1) +(1−T (X (l) ))·X (l) (3) where X (l) is the input to layer l + 1; σ is a sig- moid function; · is element-wise multiplication; W (l) T and b (l)</formula><p>T are the weight matrix and bias vector for the transform gate T (X (l) ), respectively. Alignment. In our work, entity alignment is performed by simply measuring the distance between two entity nodes on their embedding space. With the output entity representations X = {x 1 , x 2 , ..., x n |x i ∈ Rd}, for entities e 1 from G 1 and e 2 from G 2 , their distance is calculated as:</p><formula xml:id="formula_4">d(e 1 , e 2 ) = x e 1 − x e 2 L 1 .<label>(4)</label></formula><p>Training. We use a margin-based scoring function as the training objective, to make the distance between aligned entity pairs to be as close as possible, and the distance between positive and negative alignment pairs to be as large as possible. The loss function is defined as:</p><formula xml:id="formula_5">L = (p,q)∈L (p ,q )∈L max{0, d(p, q)−d(p , q )+γ},<label>(5)</label></formula><p>where γ &gt; 0 is a margin hyper-parameter; L stands for the negative alignment set of L.</p><p>Rather than simply random sampling for negative instances, we look for more challenging negative samples, e.g., those with subtle differences from the positive ones, to train our model. Given a positive aligned pair (p, q), we choose the Knearest entities of p (or q) according to Eq. 4 in the embedding space to replace q (or p) as the negative instances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Approximating Relation Representations</head><p>At this stage, we expect to obtain relation representations, which can be used in the next stage for constructing joint representations and can also be used for preliminary relation alignment. Since we are unable to explicitly modeling relations within our GCN-based framework, we thus approximate the relation representations based on their head and tail entity representations produced by the entity alignment model described in Section 4.2. This strategy is based on our observation that the statistical information of the head and tail entities of a relation can more or less reflect the shallow semantics of the relation itself, such as the head or tail entities' type requirements of a relation. Our experiments in Section 6 suggest that this is a reasonable assumption.</p><p>Given a relation r ∈ R a , there is a set of triples of r,</p><formula xml:id="formula_6">T r = {(h i , r, t j )|h i ∈ H r , t j ∈ T r },</formula><p>where H r and T r are the sets of head entities and tail entities of relation r, respectively. For a relation r, its representation can be approximated as:</p><formula xml:id="formula_7">r = f (H r , T r ),<label>(6)</label></formula><p>where r is the approximated representation of relation r. H r and T r are the sets of HGCN-output embeddings of head entities and tail entities of relation r. f (·) is a function to produce relation representations with input entity vectors, which can take many forms such as mean, adding, concatenation or more complex models. In our model, we compute the relation representation for r by first concatenating its averaged head and tail entity representations, and then introducing a matrix W R ∈ R 2d×m as a learnable shared linear transformation on relation vectors. Here,d is the number of features in each HGCN-output entity embedding and m is the number of features in each relation representation.</p><p>With the relation representations in place, relation alignment can be performed by measuring the distance between two relation vectors. For relation r 1 from G 1 and r 2 from G 2 , their distance is computed as:</p><formula xml:id="formula_8">s(r 1 , r 2 ) = r 1 −r 2 L 1 −β |P r 1 r 2 | |HT r 1 ∪ HT r 2 | ,<label>(7)</label></formula><p>where r 1 and r 2 are the relation representations for r 1 and r 2 . In addition to calculating the distance between the two relation vectors, we believe that the more aligned entities exist in the entities that are connected to the two relations, the more likely the two relations are equivalent. Thus, for r 1 and r 2 , we collect the pre-aligned entities existing in the head/tail entities of these two relations as the set P r 1 r 2 = {(e i 1 , e i 2 )|e i 1 ∈ HT r 1 , e i 2 ∈ HT r 2 , (e i 1 , e i 2 ) ∈ L}. HT r 1 and HT r 2 are the sets of head/tail entities for relation r 1 and r 2 respectively. β is a hyper-parameter for balance. In our framework, relation alignment is explored in an unsupervised fashion, in which we do not have any pre-aligned relations as training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Joint Entity and Relation Alignment</head><p>The first two stages of our approach could already produce a set of entity and relation alignments, but we do not stop here. Instead, we attentively fuse the entity and relation representations and further jointly optimize them using the seed entity alignments. Our key insight is that entity and relation alignment tasks are inherently closely related. This is because aligned entities tend to have some relations in common, and similar relations should have similar categories of head and tail entities.</p><p>Specifically, we first pre-train the entity alignment model (Section 4.2) until its entity alignment performance has converged to be stable. We assume that both the pre-trained entity and approximate relation representations can provide rich information for themselves. Next, for each entity, we aggregate the representations of its relevant relations into a relation context vector, which is further combined with its pre-trained entity representation to form a new joint entity representation.</p><p>Formally, for each entity e ∈ E a , its new joint representation e joint can be calculated as:</p><formula xml:id="formula_9">e joint = g(e, R e ),<label>(8)</label></formula><p>where e is the HGCN-output representation of entity e. R e is the set of relation representations of e's relevant relations. g(·) is a function to produce the new joint entity representation by taking e and R e as input, which can also take many forms of operations. In our model, we calculate e joint by first summing all relation representations in R e and then concatenating e with the summed relation context vector. After getting the new joint entity representations, X joint , we continue optimizing our model against the seed entity alignments, where we use the joint entity representations to calculate the training loss according to Eq. 5 to continue updating HGCNs 1 . Note that the joint entity representations are composed of entity embeddings and relation representations, while the relation representations are also constructed based on the entity embeddings. Hence, after backpropagation of the loss calculated using the joint entity representations, we optimize the entity embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental Setup</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Datasets</head><p>We use DBP15K datasets from  to evaluate our approach. DBP15K contains three  cross-lingual datasets that were built from the English version to Chinese, Japanese and French versions of DBpedia. Each contains data from two KGs in different languages and provides 15K prealigned entity pairs. Besides, each dataset also provides some pre-aligned relations. We manually aligned more relations from the three datasets and removed the ambiguously aligned relation pairs to construct the test sets for relation alignment. Table 1 shows the statistics of the three datasets. We stress that our approach achieves entity and relation alignments simultaneously using only a small number of pre-aligned entities, and relation alignments are only used for testing. Following the previous works <ref type="bibr" target="#b25">Wang et al., 2018b;</ref><ref type="bibr" target="#b21">Sun et al., 2018)</ref>, we use 30% of the pre-aligned entity pairs as training data and 70% for testing. Our source code and datasets are freely available online 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Implementation Details</head><p>We set γ = 1, β = 20, and learning rate to 0.001. We sample K = 125 negative pairs every 50 epochs. We use entity names in different KGs for better model initialization. We translate non-English entity names to English via Google Translate, and the entity features are initialized with pretrained English word vectors glove.840B.300d 3 in our model. Note that Google Translate does not always give accurate translations for named entities. We inspected 100 English translations for Japanese and Chinese entity names, and discovered that around 20% of the translations are wrong. The errors are mainly attributed to the missing of titles/modifications and wrong interpretations for person/location names. The inaccurate translation poses further challenges for our model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Competitive Approaches</head><p>Entity Alignment. For entity alignment, we compare our approach against six embedding-based entity alignment methods discussed in Section 1: JE <ref type="bibr" target="#b5">(Hao et al., 2016)</ref>, MTransE <ref type="bibr" target="#b3">(Chen et al., 2017)</ref>, JAPE <ref type="bibr">(Sun et al., 2017) 4</ref> , IPTransE <ref type="bibr" target="#b31">(Zhu et al., 2017)</ref>, BootEA <ref type="bibr" target="#b21">(Sun et al., 2018)</ref> and GCN <ref type="bibr" target="#b25">(Wang et al., 2018b)</ref>. Among those, BootEA is the bestperforming model on DBP15K.</p><p>Relation Alignment. For relation alignment, we compare our approach with the state-of-the-art BootEA (denoted by BootEA-R), and MTransE (denoted by MTransE-R). Note that MTransE provides five implementation variants for its alignment model. To provide a fair comparison, we choose the one that does not use pre-aligned relations but gives the best performance for a triplewise alignment verification <ref type="bibr" target="#b3">(Chen et al., 2017</ref>) -a closely related task for relation alignment. Since BootEA and MTransE are translation-based models that encode both entities and relations, relation alignment can be done by measuring the similarities between two relation representations. Furthermore, to evaluate the effectiveness of our proposed relation approximation method, we also build BootEA-PR and MTransE-PR for relation alignment according to Section 4.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Evaluation Methodology</head><p>Model Variants. To evaluate our design choices, we provide different implementation variants with the following denotations. HGCN is our base GCN model with highway gates and entity name initialization. It has several variants, described as follows. HGCN-PE (Section 4.2) and HGCN-PR (Section 4.3) are our preliminary models for entity and relation alignments, respectively. HGCN-JE and HGCN-JR are our complete models that use joint representations to further improve entity alignment and relation alignment (Section 4.4). Finally, GCN-PE and GCN-PR are the preliminary GCN-based models for entity and relation alignments respectively, which use entity name initialization but no highway gates; GCN-JE and GCN-JR are the corresponding joint learning models; and GCN-JE-r is the randomly initialized version of GCN-JE without entity name initialization.</p><p>Metrics. Like prior works <ref type="bibr" target="#b25">Wang et al., 2018b;</ref><ref type="bibr" target="#b21">Sun et al., 2018)</ref>, we use Hits@k as our evaluation metric. A Hits@k score is computed by measuring the proportion of correctly aligned entities ranked in the top k list. Hence, we prefer higher Hits@k scores that indicate better performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiment Results</head><p>In this section, we first show that our complete model consistently outperforms all alternative methods across datasets, metrics and alignment tasks. We then analyze the impact of prior alignment data size on model performance, showing that our approach requires significantly less training data but achieves better performance over the best-performing prior method. Finally, we use a concrete example to discuss how jointly learned entity and relation representations can be used to improve both entity and relation alignments.  <ref type="table" target="#tab_2">Table 2</ref> shows how our proposed techniques, i.e., entity name initialization, joint embeddings and layer-wise highway gates, can be used within a GCN framework to improve entity alignment. After initialized with the machine-translated entity names, GCN-PE considerably improves GCN on all datasets. The improvement suggests that even rough translations of entity names (see Section 5.2) can still provide important evidence for entity alignment and finally boost the performance. By employing layer-wise highway gates, HGCN-PE further improves GCN-PE, giving a 34.31% improvement on Hits@1 on DBP15K F R−EN , and also outperforms the strongest baseline BootEA. This substantial improvement indicates that highway gates can effectively control the propagation of noisy information. Our complete framework HGCN-JE gives the best performance across all metrics   , we observe that joining entity and relation alignments improves the model performance. Even without entity name initialization, GCN-JE-r still has obvious advantages over JE, MTransE, JAPE, IPTransE and GCN. The results reinforce our claim that merging the relation information into entities can produce better entity representations. We stress that our proposed methods are not restricted to GCNs or HGCNs, but can be flexibly integrated with other KG representation models as well. <ref type="table" target="#tab_5">Table 3</ref> reports the results of relation alignment. Directly using the relation embeddings learned by MTransE to perform relation alignment leads to rather poor performance for MTransE-R, less than 4% for Hits@1 for all datasets. This is because the translation assumption, head + relation ≈ tail, used by MTransE focuses on modeling the overall relationship among heads, tails, and relations, but capturing little neighboring information and relation semantics. After approximating the relation representations using entity embeddings according to Eq 6, MTransE-PR substantially improves MTransE-R. This confirms our assumption that it is feasible to approximate a relation using the in- formation of its head and tail entities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Entity Alignment</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Relation Alignment</head><p>The strong entity alignment model BootEA also performs well for relation alignment. Using the relation embeddings from BootEA, BootEA-R delivers the best Hits@1 in MTransE and BootEA variants. Using our approximation strategy hurts BootEA-R in Hits@1, but we see improvements on Hits@10 across all datasets. This suggests that our approximation method can bring more related candidates, but may lack precision to select topranked candidates, comparing to explicitly relation modeling in translation-based models.</p><p>Our framework, HGCN-JR, delivers the best relation alignment results across datasets and metrics, except for Hits@10 on DBP15K F R−EN . Like entity alignment, we also observe that joining entity and relation alignments improves relation alignment, as evidenced by the better performance of HGCN-JR and GCN-JR over HGCN-PR and GCN-PR, respectively. That is, joint modeling produces better entity representations, which in turn provide better relation approximations. This can promote the results of both alignment tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Analysis</head><p>Impact of Available Seed Alignments. To explore the impact of the size of seed alignments on our model, we compare our HGCN with BootEA by varying the proportion of pre-aligned entities from 10% to 40% with a step of 10%. <ref type="figure" target="#fig_1">Figure 2</ref> (a-c) illustrate the Hits@1 for entity alignment of HGCN-JE and BootEA on three datasets. As the amount of seed alignments increases, the performances of both models on all three data sets gradually improve. HGCN-JE consistently obtains superior results compared to BootEA, and seems to be insensitive to the proportion of seed alignments. For example, HGCN-JE still achieves 86.40% for Hits@1 on DBP15K F R−EN when only using 10% of training data. This Hits@1 score is 17.84% higher than that of BootEA when BootEA uses 40% of seed alignments. <ref type="figure" target="#fig_1">Figure 2 (d-f)</ref> show the Hits@1 for relation alignment of HGCN-JR and BootEA-R. HGCN-JR also consistently outperforms BootEA-R, and gives more stable results with different ratios of seed entity alignments. These results further confirm the robustness of our model, especially with limited seed entity alignments. Case Study. <ref type="figure">Figure 3</ref> shows an example from DBP15K F R−EN . In the stages of preliminary entity alignment and relation alignment, our model correctly predicts the aligned entity pair (v 2 , v 5 ) and relation pair (r 2 , r 5 ). After examining the full experimental data 5 , we find that the entities with more neighbors, such as v 2 and v 5 (indicating Norway), and the high-frequency relations, such as r 2 and r 5 (indicating country), are easier to align, since such entities and relations have rich structural information that can be exploited by a GCN. After jointly learning entity and relation representations, the extra neighboring relation information [v 2 ; v 5 ] and [r 2 ; r 5 ] are respectively the aligned entities and aligned relations after performing preliminary entity and relation alignments.</p><p>[v F R ; v EN ] and [v 1 ; v 4 ] are the newly aligned entity pairs, and r 1 and r 4 are the newly aligned relations, which are discovered using jointly learned entity and relation representations. Jointly optimizing alignment tasks leads to the sucessful discovery of new aligned relation and entity pairs. (e.g., the aligned relations (r 2 , r 5 )) enables our model to successfully align v F R and v EN . If we keep updating the model to learn better entity and relation representations, our alignment framework can successfully uncover more entity and relation alignments such as (v 1 , v 4 ) and (r 1 , r 4 ). This shows that joint representations can improve both entity and relation alignments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions</head><p>This paper presents a novel framework for entity alignment by jointly modeling entities and relations of KGs. Our approach does not require prealigned relations as training data, yet it can simultaneously align entities and relations of heterogeneous KGs. We achieve this by employing gated GCNs to automatically learn high-quality entity and relation representations. As a departure from prior work, our approach constructs joint entity representations that contain both relation information and entity information. We demonstrate that the whole is greater than the sum of its parts, as the joint representations allow our model to iteratively improve the learned representations for both entities and relations. Extensive experiments on three real-world datasets show that our approach delivers better and more robust performance when compared to state-of-the-art methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Training Procedure of Our Approach</head><p>The detailed training procedure of our model is described in Algorithm 1.</p><p>Our framework takes as input G a that consists of the two target knowledge graphs (KGs), a set of prior aligned entity pairs. Like a standard neural network training process, we provide a set of tuneable parameters like the number of epochs, N .</p><p>As described in Section 4.1 of the main paper, the training of our framework consists of three stages: (1) preliminary entity alignment, (2) approximating relation representations, and (3) joint entity and relation alignment.</p><p>In the first stage, we utilize GCNs to learn entity representation, X , to embed entities of various KGs for preliminary entity alignment. Next, we use the entity embeddings to approximate relation representations (i.e., r at line 7) to align relations across KGs. When the performance of preliminary entity alignment model has become stable, we enter the third stage (lines 12-23). In this stage, we learn a model to try to incorporate the relation representations into entity embeddings (e joint at line 19) to obtain the joint entity representations (X joint at line 20), and continue using GCNs to iteratively integrate neighboring structural information to achieve better entity and relation representations. <ref type="table">Table 4</ref> displays the statistical characteristics of entities and relations which are correctly predicted in both preliminary and joint alignment stage, only in joint alignment stage, and in neither of the stages. From <ref type="table">Table 4a</ref>, it can be observed that the more neighbor entities and relations an entity has, the more likely and earlier it will be aligned. So the neighbor information is of great importance to entities, and our model utilizes this information effectively. Also, an entity has higher possibility to be aligned in the joint alignment stage if more entities and relations in its neighborhood have been aligned, for these entities and relations offer precise information and help the embedding of the current entity. <ref type="table">Table 4b</ref> shows the influence of neighbor entities to relation alignment. There is a gap in the frequency of occurrence in triples between relations that are aligned preliminarily or not, because relations with abundant objects are embedded accurately. Moreover, when a relation fails to be  <ref type="table">Table 4</ref>: Statistics of entity and relation alignments. Pre Joint indicates the set of entities or relations which are predicted correctly in both preliminary and joint alignment, and so on. #Nbr Ent. and #Nbr Rel. denote the average number of neighbor entities and relations, respectively. Freq. denotes the average frequency of occurrences of relations in each dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Statistical Information of Alignment</head><p>aligned in the preliminary stage, it is more likely to be aligned in the joint stage if it appears frequently, as the embedding of relations will improve with the embedding of entities together.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Overall architecture of our model. The blue dotted lines denote the process of preliminary entity alignment and preliminary relation alignment using approximate relation representations, and the black solid lines denote the process of continuing using GCNs to iteratively learn better entity and relation representations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>(a)-(c) report the performance for entity alignment of HGCN-JE and BootEA when they are trained with different proportions of seed entity alignments on the three DBP15K datasets. (d)-(f) show the relation alignment performance of HGCN-JR and BootEA-R under corresponding conditions. The x-axes are the proportions of seed alignments, and the y-axes are Hits@1 scores.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Figure 3: A real-world example from DBP15K F R−EN . [v 2 ; v 5 ] and [r 2 ; r 5 ] are respectively the aligned entities and aligned relations after performing preliminary entity and relation alignments. [v F R ; v EN ] and [v 1 ; v 4 ] are the newly aligned entity pairs, and r 1 and r 4 are the newly aligned relations, which are discovered using jointly learned entity and relation representations. Jointly optimizing alignment tasks leads to the sucessful discovery of new aligned relation and entity pairs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Summary of the DBP15K datasets.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell>reports the performance for entity align-</cell></row><row><cell>ment of all compared approaches. The top part</cell></row><row><cell>of the table shows the performance of prior ap-</cell></row><row><cell>proaches. By using a bootstrapping process to</cell></row><row><cell>expand the training data, BootEA clearly out-</cell></row><row><cell>performs all prior methods. By capturing the</cell></row><row><cell>rich neighboring structural information, GCN out-</cell></row><row><cell>performs all other translation-based models on</cell></row><row><cell>Hits@1, and over IPTransE, MTransE and JE on</cell></row><row><cell>Hits@10.</cell></row><row><cell>The bottom part of</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 :</head><label>2</label><figDesc>Performance on entity alignment.</figDesc><table><row><cell>Models</cell><cell cols="6">ZH-EN Hits@1 Hits@10 Hits@1 Hits@10 Hits@1 Hits@10 JA-EN FR-EN</cell></row><row><cell>MTransE-R</cell><cell>3.03</cell><cell>8.88</cell><cell>2.65</cell><cell>10.21</cell><cell>3.30</cell><cell>14.62</cell></row><row><cell>MTransE-PR</cell><cell>32.81</cell><cell>57.64</cell><cell>31.00</cell><cell>56.14</cell><cell>18.87</cell><cell>44.34</cell></row><row><cell>BootEA-R</cell><cell>55.17</cell><cell>70.00</cell><cell>47.83</cell><cell>67.67</cell><cell>36.79</cell><cell>58.49</cell></row><row><cell>BootEA-PR</cell><cell>45.28</cell><cell>85.37</cell><cell>41.40</cell><cell>79.77</cell><cell>30.19</cell><cell>60.38</cell></row><row><cell>GCN-PR</cell><cell>66.18</cell><cell>82.81</cell><cell>60.87</cell><cell>81.47</cell><cell>38.21</cell><cell>52.83</cell></row><row><cell>GCN-JR</cell><cell>70.22</cell><cell>84.38</cell><cell>63.89</cell><cell>81.10</cell><cell>41.98</cell><cell>53.77</cell></row><row><cell>HGCN-PR</cell><cell>69.33</cell><cell>84.49</cell><cell>63.14</cell><cell>81.26</cell><cell>41.51</cell><cell>54.25</cell></row><row><cell>HGCN-JR</cell><cell>70.34</cell><cell>85.39</cell><cell>65.03</cell><cell>83.55</cell><cell>42.45</cell><cell>56.60</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>Performance on relation alignment.</figDesc><table /><note>and datasets. Comparing HGCN-JE with HGCN- PE and GCN-JE with GCN-PE (2.36% and 4.19% improvements of Hits@1 on DBP15K ZH−EN re- spectively)</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>Algorithm 1 Training framework of our model. Graph Ga, set of aligned entity pairs L, number of epochs N , interval to regenerate negative samples T , number of negative samples K. Output: Parameters Ω.1: M ode = P reliminary, epoch = 0 2: while M odel has not stabilized do</figDesc><table><row><cell>3:</cell><cell cols="4">X = HighwayGCN (Ga, Ω)</cell></row><row><cell>4:</cell><cell cols="4">if epoch mod T == 0 then</cell></row><row><cell>5:</cell><cell cols="4">L = SampleN egative(X , L, K)</cell></row><row><cell>6:</cell><cell>end if</cell><cell></cell><cell></cell><cell></cell></row><row><cell>7:</cell><cell cols="3">r = f (Hr, Tr), ∀r ∈ Ra</cell><cell></cell></row><row><cell>8:</cell><cell cols="4">Lpre = M arginLoss(X , L, L )</cell></row><row><cell>9:</cell><cell cols="5">Back propagate errors and update parameters Ω</cell></row><row><cell>10:</cell><cell cols="3">epoch = epoch + 1</cell><cell></cell></row><row><cell cols="2">11: end while</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">12: M ode = Joint</cell><cell></cell><cell></cell></row><row><cell cols="4">13: while epoch &lt; N do</cell><cell></cell></row><row><cell>14:</cell><cell cols="4">X = HighwayGCN (Ga, Ω)</cell></row><row><cell>15:</cell><cell cols="4">if epoch mod T == 0 then</cell></row><row><cell>16:</cell><cell cols="4">L = SampleN egative(X , L, K)</cell></row><row><cell>17:</cell><cell>end if</cell><cell></cell><cell></cell><cell></cell></row><row><cell>18:</cell><cell cols="3">r = f (Hr, Tr), ∀r ∈ Ra</cell><cell></cell></row><row><cell>19:</cell><cell cols="4">ejoint = g(e, Re), ∀e ∈ Ea</cell></row><row><cell>20:</cell><cell cols="4">Ljoint = M arginLoss(Xjoint, L, L )</cell></row><row><cell>21:</cell><cell cols="5">Back propagate errors and update parameters Ω</cell></row><row><cell>22:</cell><cell cols="3">epoch = epoch + 1</cell><cell></cell></row><row><cell cols="2">23: end while</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">24: return Ω</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">(a) Entity Alignment</cell></row><row><cell></cell><cell>Statics</cell><cell></cell><cell>Pre Joint</cell><cell>Pre× Joint</cell><cell>Pre× Joint×</cell></row><row><cell cols="2">#Nbr Ent.</cell><cell>G1 G2</cell><cell>7.32 9.52</cell><cell>6.47 8.51</cell><cell>6.25 8.33</cell></row><row><cell cols="2">#Nbr Rel.</cell><cell>G1 G2</cell><cell>3.94 4.67</cell><cell>3.73 4.27</cell><cell>3.51 4.30</cell></row><row><cell cols="3">Pre Aligned Ent. (%)</cell><cell>83</cell><cell>79</cell><cell>75</cell></row><row><cell cols="3">Pre Aligned Rel. (%)</cell><cell>96</cell><cell>95</cell><cell>95</cell></row><row><cell></cell><cell></cell><cell cols="3">(b) Relation Alignment</cell></row><row><cell></cell><cell>Statics</cell><cell></cell><cell>Pre Joint</cell><cell>Pre× Joint</cell><cell>Pre× Joint×</cell></row><row><cell></cell><cell>Freq.</cell><cell>G1 G2</cell><cell>85.59 135.74</cell><cell>17.83 48.75</cell><cell>16.86 40.93</cell></row></table><note>Input:</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">The training procedure is detailed in Appendix A.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://github.com/StephanieWyt/HGCN-JE-JR 3 http://nlp.stanford.edu/projects/glove/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">We note that) also provides analysis by considering the outputs of a machine translator and JAPE, and using a theoretically perfect oracle predictor to correctly choose in between the results given by the machine translator and JAPE. As this only serves as an interesting up-bound analysis, but does not reflect the capability of JAPE (because it is impossible to build such a perfect predictor in the first place), we do not compare to this oracle implementation.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">A more detailed analysis of our experimental results can be found in Appendix B in the supplementary material.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work is supported in part by the National Hi-Tech R&amp;D Program of China (No. 2018YFB1005100), the NSFC Grants (No.  61672057, 61672058, 61872294), and a UK Royal Society International Collaboration Grant (IE161012). For any correspondence, please contact Yansong Feng.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Adversarial training for multi-context joint entity and relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giannis</forename><surname>Bekoulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Deleu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Demeester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Develder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2830" to="2836" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Translating embeddings for modeling multirelational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Garcia-Duran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oksana</forename><surname>Yakhnenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2787" to="2795" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Co-training embeddings of knowledge graphs and entity descriptions for cross-lingual entity alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingtao</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Skiena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlo</forename><surname>Zaniolo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence</title>
		<meeting>the Twenty-Seventh International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page">18</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Multilingual knowledge graph embeddings for cross-lingual knowledge alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingtao</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlo</forename><surname>Zaniolo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Joint Conference on Artificial Intelligence (IJCAI)</title>
		<meeting>the 26th International Joint Conference on Artificial Intelligence (IJCAI)</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Convolutional networks on graphs for learning molecular fingerprints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dougal</forename><surname>David K Duvenaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jorge</forename><surname>Maclaurin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rafael</forename><surname>Iparraguirre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Bombarell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Hirzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan P</forename><surname>Aspuru-Guzik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="2224" to="2232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A joint embedding method for entity alignment of knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanchao</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanzhe</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shizhu</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of China Conference on Knowledge Graph and Semantic Computing (CCKS2016)</title>
		<meeting>China Conference on Knowledge Graph and Semantic Computing (CCKS2016)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A self-training approach for resolving object coreference on the semantic web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuzhong</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th international conference on World wide web</title>
		<meeting>the 20th international conference on World wide web</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Molecular graph convolutions: moving beyond fingerprints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Kearnes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Mccloskey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Berndl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Pande</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Riley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer-Aided Molecular Design</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Semisupervised classification with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Sigma: Simple greedy matching for aligning large knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Lacoste-Julien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantina</forename><surname>Palla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Davies</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gjergji</forename><surname>Kasneci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thore</forename><surname>Graepel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zoubin</forename><surname>Ghahramani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 19th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Non-translational alignment for multi-relational networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengnan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingzhong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haiping</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingzi</forename><surname>Ou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence, IJCAI-18</title>
		<meeting>the Twenty-Seventh International Joint Conference on Artificial Intelligence, IJCAI-18</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4180" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Yago3: A knowledge base from multilingual wikipedias</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Farzaneh</forename><surname>Mahdisoltani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joanna</forename><surname>Biega</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian</forename><forename type="middle">M</forename><surname>Suchanek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIDR</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Encoding sentences with graph convolutional networks for semantic role labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diego</forename><surname>Marcheggiani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Titov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1506" to="1515" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">End-to-end relation extraction using LSTMs on sequences and tree structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Makoto</forename><surname>Miwa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1105" to="1116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Multilingual schema matching for wikipedia infoboxes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thanh</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Viviane</forename><surname>Moreira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huong</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hoa</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juliana</forename><surname>Freire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. VLDB Endow</title>
		<meeting>VLDB Endow</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Semi-supervised entity alignment via knowledge graph embedding with awareness of degree difference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shichao</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Hoehndorf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangliang</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The World Wide Web Conference, WWW &apos;19</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3130" to="3136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Semi-supervised user geolocation via graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Afshin</forename><surname>Rahimi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Baldwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2009" to="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Modeling relational data with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Schlichtkrull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rianne</forename><surname>Bloem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Titov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Semantic Web Conference</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="593" to="607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Rupesh Kumar Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Greff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schmidhuber</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1505.00387</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">Highway networks. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Paris: Probabilistic alignment of relations, instances, and schema</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian</forename><forename type="middle">M</forename><surname>Suchanek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Abiteboul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Senellart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. VLDB Endow</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="157" to="168" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Cross-lingual entity alignment via joint attributepreserving embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zequn</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengkai</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Semantic Web Conference</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="628" to="644" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Bootstrapping entity alignment with knowledge graph embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zequn</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuzhong</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence, IJCAI-18</title>
		<meeting>the Twenty-Seventh International Joint Conference on Artificial Intelligence, IJCAI-18</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4396" to="4402" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Wikidata: A free collaborative knowledgebase</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denny</forename><surname>Vrandečić</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Krötzsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="78" to="85" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Label-free distant supervision for relation extraction via knowledge graph embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guanying</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruoxu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yalin</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huajun</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2246" to="2255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Multisource knowledge bases entity alignment by leveraging semantic tags</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuepeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shizhu</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shulin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanzhe</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Chinese Journal of Computers</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="701" to="711" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Cross-lingual knowledge graph alignment via graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhichun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingsong</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohan</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="349" to="357" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Relation-aware entity alignment for heterogeneous knowledge graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuting</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yansong</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongyan</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI-19</title>
		<meeting>the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI-19</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5278" to="5284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Leveraging knowledge bases in lstms for improving machine reading</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bishan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Entity matching across heterogeneous sources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhou</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juanzi</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Graph convolution over pruned dependency trees improves relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing (EMNLP)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Variational reasoning for question answering with knowledge graph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanjun</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zornitsa</forename><surname>Kozareva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Second AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Iterative entity alignment via joint knowledge embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruobing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence, IJCAI-17</title>
		<meeting>the Twenty-Sixth International Joint Conference on Artificial Intelligence, IJCAI-17</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4258" to="4264" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
