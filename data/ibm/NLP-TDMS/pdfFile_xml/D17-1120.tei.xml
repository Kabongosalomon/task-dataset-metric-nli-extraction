<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/yhou/git/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2019-02-07T07:26+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Neural Sequence Learning Models for Word Sense Disambiguation</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>September 7-11, 2017. 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Raganato</surname></persName>
							<email>raganato@di.uniroma1.it</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Sapienza University of Rome</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claudio</forename><surname>Delli Bovi</surname></persName>
							<email>dellibovi@di.uniroma1.it</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Sapienza University of Rome</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Navigli</surname></persName>
							<email>navigli@di.uniroma1.it</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Sapienza University of Rome</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Neural Sequence Learning Models for Word Sense Disambiguation</title>
					</analytic>
					<monogr>
						<title level="m">Natural Language Processing</title>
						<meeting> <address><addrLine>Copenhagen, Denmark</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="1156" to="1167"/>
							<date type="published">September 7-11, 2017. 2017</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Word Sense Disambiguation models exist in many flavors. Even though supervised ones tend to perform best in terms of accuracy, they often lose ground to more flexible knowledge-based solutions, which do not require training by a word expert for every disambiguation target. To bridge this gap we adopt a different perspective and rely on sequence learning to frame the disambiguation problem: we propose and study in depth a series of end-to-end neural architectures directly tailored to the task, from bidirectional Long Short-Term Memory to encoder-decoder models. Our extensive evaluation over standard benchmarks and in multiple languages shows that sequence learning enables more versatile all-words models that consistently lead to state-of-the-art results, even against word experts with engineered features.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>As one of the long-standing challenges in Natural Language Processing (NLP), Word Sense Disambiguation <ref type="bibr" target="#b43">(Navigli, 2009</ref>, WSD) has received considerable attention over recent years. Indeed, by dealing with lexical ambiguity an effective WSD model brings numerous benefits to a variety of downstream tasks and applications, from Information <ref type="bibr">Retrieval and Extraction (Zhong and Ng, 2012;</ref><ref type="bibr" target="#b18">Delli Bovi et al., 2015)</ref> to Machine Translation <ref type="bibr" target="#b11">(Carpuat and Wu, 2007;</ref><ref type="bibr" target="#b66">Xiong and Zhang, 2014;</ref><ref type="bibr" target="#b47">Neale et al., 2016)</ref>. Recently, WSD has also been leveraged to build continuous vector representations for word senses <ref type="bibr" target="#b13">(Chen et al., 2014;</ref><ref type="bibr">Ia- cobacci et al., 2015;</ref><ref type="bibr" target="#b21">Flekova and Gurevych, 2016)</ref>.</p><p>Inasmuch as WSD is described as the task of associating words in context with the most suitable entries in a pre-defined sense inventory, the majority of WSD approaches to date can be grouped into two main categories: supervised (or semisupervised) and knowledge-based. Supervised models have been shown to consistently outperform knowledge-based ones in all standard benchmarks ( <ref type="bibr" target="#b53">Raganato et al., 2017)</ref>, at the expense, however, of harder training and limited flexibility. First of all, obtaining reliable sense-annotated corpora is highly expensive and especially difficult when non-expert annotators are involved (de <ref type="bibr" target="#b17">Lacalle and Agirre, 2015)</ref>, and as a consequence approaches based on unlabeled data and semisupervised learning are emerging <ref type="bibr" target="#b60">(Taghipour and Ng, 2015b;</ref><ref type="bibr" target="#b4">Bas¸kayaBas¸kaya and Jurgens, 2016;</ref><ref type="bibr" target="#b67">Yuan et al., 2016;</ref><ref type="bibr" target="#b48">Pasini and Navigli, 2017)</ref>.</p><p>Apart from the shortage of training data, a crucial limitation of current supervised approaches is that a dedicated classifier (word expert) needs to be trained for every target lemma, making them less flexible and hampering their use within endto-end applications. In contrast, knowledge-based systems do not require sense-annotated data and often draw upon the structural properties of lexicosemantic resources <ref type="bibr" target="#b1">(Agirre et al., 2014;</ref><ref type="bibr" target="#b41">Moro et al., 2014;</ref><ref type="bibr" target="#b65">Weissenborn et al., 2015)</ref>. Such systems construct a model based only on the underlying resource, which is then able to handle multiple target words at the same time and disambiguate them jointly, whereas word experts are forced to treat each disambiguation target in isolation.</p><p>In this paper our focus is on supervised WSD, but we depart from previous approaches and adopt a different perspective on the task: instead of framing a separate classification problem for each given word, we aim at modeling the joint disambiguation of the target text as a whole in terms of a sequence labeling problem. From this standpoint, WSD amounts to translating a sequence of words into a sequence of potentially sense-tagged tokens.</p><p>With this in mind, we design, analyze and compare experimentally various neural architectures of different complexities, ranging from a single bidirectional Long Short-Term Memory ( <ref type="bibr" target="#b23">Graves and Schmidhuber, 2005</ref>, LSTM) to a sequence-tosequence approach <ref type="bibr" target="#b58">(Sutskever et al., 2014)</ref>. Each architecture reflects a particular way of modeling the disambiguation problem, but they all share some key features that set them apart from previous supervised approaches to WSD: they are trained end-to-end from sense-annotated text to sense labels, and learn a single all-words model from the training data, without fine tuning or explicit engineering of local features.</p><p>The contributions of this paper are twofold. First, we show that neural sequence learning represents a novel and effective alternative to the traditional way of modeling supervised WSD, enabling a single all-words model to compete with a pool of word experts and achieve state-of-the-art results, while also being easier to train, arguably more versatile to use within downstream applications, and directly adaptable to different languages without requiring additional sense-annotated data (as we show in Section 6.2); second, we carry out an extensive experimental evaluation where we compare various neural architectures designed for the task (and somehow left underinvestigated in previous literature), exploring different configurations and training procedures, and analyzing their strengths and weaknesses on all the standard benchmarks for all-words WSD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>The literature on WSD is broad and comprehensive ( <ref type="bibr" target="#b0">Agirre and Edmonds, 2007;</ref><ref type="bibr" target="#b43">Navigli, 2009)</ref>: new models are continuously being <ref type="bibr">de- veloped (Yuan et al., 2016;</ref><ref type="bibr" target="#b61">Tripodi and Pelillo, 2017;</ref><ref type="bibr" target="#b10">Butnaru et al., 2017</ref>) and tested over a wide variety of standard benchmarks <ref type="bibr" target="#b19">(Edmonds and Cotton, 2001;</ref><ref type="bibr" target="#b56">Snyder and Palmer, 2004;</ref><ref type="bibr" target="#b51">Pradhan et al., 2007;</ref><ref type="bibr" target="#b45">Navigli et al., 2007</ref><ref type="bibr" target="#b44">Navigli et al., , 2013</ref><ref type="bibr" target="#b40">Moro and Navigli, 2015)</ref>. Moreover, the field has been explored in depth from different angles by means of extensive empirical studies and evaluation frameworks <ref type="bibr" target="#b49">(Pilehvar and Navigli, 2014;</ref><ref type="bibr" target="#b28">Iacobacci et al., 2016;</ref><ref type="bibr" target="#b34">McCarthy et al., 2016;</ref><ref type="bibr" target="#b53">Raganato et al., 2017)</ref>.</p><p>As regards supervised WSD, traditional approaches are generally based on extracting local features from the words surrounding the target, and then training a classifier ( <ref type="bibr" target="#b69">Zhong and Ng, 2010;</ref><ref type="bibr" target="#b55">Shen et al., 2013</ref>) for each target lemma. In their latest developments, these models include more complex features based on word embeddings <ref type="bibr" target="#b60">(Taghipour and Ng, 2015b;</ref><ref type="bibr" target="#b54">Rothe and Schütze, 2015;</ref><ref type="bibr" target="#b28">Iacobacci et al., 2016)</ref>.</p><p>The recent upsurge of neural networks has also contributed to fueling WSD research: <ref type="bibr" target="#b67">Yuan et al. (2016)</ref> rely on a powerful neural language model to obtain a latent representation for the whole sentence containing a target word w; their instance-based system then compares that representation with those of example sentences annotated with the candidate meanings of w. Similarly, <ref type="bibr">Context2Vec (Melamud et al., 2016</ref>) makes use of a bidirectional LSTM architecture trained on an unlabeled corpus and learns a context vector for each sense annotation in the training data. Finally, <ref type="bibr" target="#b29">Kågebäck and Salomonsson (2016)</ref> present a supervised classifier based on bidirectional LSTM for the lexical sample task <ref type="bibr" target="#b30">(Kilgarriff, 2001;</ref><ref type="bibr" target="#b36">Mihalcea et al., 2004</ref>). All these contributions have shown that supervised neural models can achieve state-of-the-art performances without taking advantage of external resources or language-specific features. However, they all consider each target word as a separate classification problem and, to the best of our knowledge, very few attempts have been made to disambiguate a text jointly using sequence learning ( <ref type="bibr" target="#b15">Ciaramita and Altun, 2006</ref>).</p><p>Sequence learning, especially using LSTM <ref type="bibr" target="#b25">(Hochreiter and Schmidhuber, 1997;</ref><ref type="bibr" target="#b23">Graves and Schmidhuber, 2005;</ref><ref type="bibr" target="#b22">Graves, 2013)</ref>, has become a well-established standard in numerous NLP tasks ( <ref type="bibr" target="#b71">Zhou and Xu, 2015;</ref><ref type="bibr" target="#b33">Ma and Hovy, 2016;</ref><ref type="bibr" target="#b64">Wang and Chang, 2016)</ref>. In particular, sequence-to-sequence models <ref type="bibr" target="#b58">(Sutskever et al., 2014</ref>) have grown increasingly popular and are used extensively in, e.g., Machine Translation ( <ref type="bibr" target="#b14">Cho et al., 2014;</ref><ref type="bibr" target="#b5">Bahdanau et al., 2015)</ref>, Sentence Representation ( <ref type="bibr" target="#b31">Kiros et al., 2015)</ref>, Syntactic Parsing ( , Conversation Modeling ( <ref type="bibr" target="#b63">Vinyals and Le, 2015)</ref>, Morphological Inflection ( <ref type="bibr" target="#b20">Faruqui et al., 2016)</ref> and Text Summarization ( <ref type="bibr" target="#b24">Gu et al., 2016)</ref>. In line with this trend, we focus on the (so far unexplored) context of supervised WSD, and investigate state-of-the-art all-words approaches that are based on neural sequence learning and capable of disambiguating all target content words within an input text, a key feature in several knowledge-based approaches.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Sequence Learning for Word Sense Disambiguation</head><p>In this section we define WSD in terms of a sequence learning problem. While in its classical formulation <ref type="bibr" target="#b43">(Navigli, 2009)</ref> WSD is viewed as a classification problem for a given word w in context, with word senses of w being the class labels, here we consider a variable-length sequence of input symbols x = x 1 , ..., x T and we aim at predicting a sequence of output symbols y = y 1 , ..., y T . 1 Input symbols are word tokens drawn from a given vocabulary V . 2 Output symbols are either drawn from a pre-defined sense inventory S (if the corresponding input symbols are open-class content words, i.e., nouns, verbs, adjectives or adverbs), or from the same input vocabulary V (e.g., if the corresponding input symbols are function words, like prepositions or determiners). Hence, we can define a WSD model in terms of a function that maps sequences of symbols x i ∈ V into sequences of symbols y j ∈ O = S ∪ V . Here all-words WSD is no longer broken down into a series of distinct and separate classification tasks (one per target word) but rather treated directly at the sequence level, with a single model handling all disambiguation decisions. In what follows, we describe three different models for accomplishing this: a traditional LSTMbased model (Section 3.1), a variant that incorporates an attention mechanism (Section 3.2), and an encoder-decoder architecture (Section 3.3). <ref type="bibr">1</ref> In general x and y might have different lengths, e.g., if x contains a multi-word expression (European Union) which is mapped to a unique sense identifier (European Union 1 n ). 2 V generalizes traditional vocabularies used in WSD and includes both word lemmas and inflected forms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Bidirectional LSTM Tagger</head><p>The most straightforward way of modeling WSD as formulated in Section 3 is that of considering a sequence labeling architecture that tags each symbol x i ∈ V in the input sequence with a label y j ∈ O. Even though the formulation is rather general, previous contributions ( <ref type="bibr" target="#b35">Melamud et al., 2016;</ref><ref type="bibr" target="#b29">Kågebäck and Salomonsson, 2016)</ref> have already shown the effectiveness of recurrent neural networks for WSD. We follow the same line and employ a bidirectional LSTM architecture: in fact, important clues for disambiguating a target word could be located anywhere in the context (not necessarily before the target) and for a model to be effective it is crucial that it exploits information from the whole input sequence at every time step.</p><p>Architecture. A sketch of our bidirectional LSTM tagger is shown in <ref type="figure" target="#fig_0">Figure 1</ref>. It consists of:</p><p>• An embedding layer that converts each word</p><formula xml:id="formula_0">x i ∈ x into a real-valued d-dimensional vector x i via the embedding matrix W ∈ R d × |V | ;</formula><p>• One or more stacked layers of bidirectional LSTM (Graves and <ref type="bibr" target="#b23">Schmidhuber, 2005</ref>). The hidden state vectors h i and output vectors o i at the i th time step are then obtained as the concatenations of the forward and backward pass vectors</p><formula xml:id="formula_1">− → h i , − → o i and ← − h i , ← − o i ;</formula><p>• A fully-connected layer with softmax activation that turns the output vector o i at the i th time step into a probability distribution over the output vocabulary O.</p><p>Training. The tagger is trained on a dataset of N labeled sequences {( x k , y k )} N k=1 directly obtained from the sentences of a sense-annotated corpus, where each x k is a sequence of word tokens, and each y k is a sequence containing both word tokens and sense labels. Ideally y k is a copy of x k where each content word is sense-tagged. This is, however, not the case in many real-world datasets, where only a subset of the content words is annotated; hence the architecture is designed to deal with both fully and partially annotated sentences. Apart from sentence splitting and tokenization, no preprocessing is required on the training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Attentive Bidirectional LSTM Tagger</head><p>The bidirectional LSTM tagger of Section 3.1 exploits information from the whole input sequence x, which is encoded in the hidden state h i . However, certain elements of x might be more discriminative than others in predicting the output label at a given time step (e.g., the syntactic subject and object when predicting the sense label of a verb).</p><p>We model this hunch by introducing an attention mechanism, already proven to be effective in other NLP tasks ( <ref type="bibr" target="#b5">Bahdanau et al., 2015;</ref>, into the sequence labeling architecture of Section 3.1. The resulting attentive bidirectional LSTM tagger augments the original architecture with an attention layer, where a context vector c is computed from all the hidden states h 1 , ..., h T of the bidirectional LSTM. The attentive tagger first reads the entire input sequence x to construct c, and then exploits c to predict the output label y j at each time step, by concatenating it with the output vector o j of the bidirectional LSTM ( <ref type="figure">Figure 2)</ref>.</p><p>We follow previous work <ref type="bibr" target="#b72">Zhou et al., 2016)</ref> and compute c as the weighted sum of the hidden state vectors h 1 , ..., h T . Formally, let H ∈ R n × T be the matrix of hidden state vectors [ h 1 , ..., h T ], where n is the hidden state dimension and T is the input sequence length (cf. Section 3). c is obtained as follows:</p><formula xml:id="formula_2">u = ω T tanh(H) a = sof tmax(u) c = Ha T (1)</formula><p>where ω ∈ R n is a parameter vector, and a ∈ R T is the vector of normalized attention weights.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Sequence-to-Sequence Model</head><p>The attentive tagger of Section 3.2 performs a two-pass procedure by first reading the input sequence x to construct the context vector c, and then predicting an output label y j for each element in x. In this respect, the attentive architecture can effectively be viewed as an encoder for x. A further generalization of this model would then be a complete encoder-decoder architecture ( <ref type="bibr" target="#b58">Sutskever et al., 2014</ref>) where WSD is treated as a sequence-to-sequence mapping (sequence-to-sequence WSD), i.e., as the "translation" of word sequences into sequences of potentially sense-tagged tokens. Figure 2: Attentive bidirectional LSTM sequence labeling architecture for WSD (2 hidden layers).</p><p>In the sequence-to-sequence framework, a variable-length sequence of input symbols x is represented as a sequence of vectors x = x 1 , ..., x T by converting each symbol x i ∈ x into a real-valued vector x i via an embedding layer, and then fed to an encoder, which generates a fixed-dimensional vector representation of the sequence. Traditionally, the encoder function is a Recurrent Neural Network (RNN) such that:</p><formula xml:id="formula_3">h t = f (h t−1 , x t ) c = q({h 1 , ..., h T })<label>(2)</label></formula><p>where h t ∈ R n is the n-dimensional hidden state vector at time t, c ∈ R n is a vector generated from the whole sequence of input states, and f and q are non-linear functions. 3 A decoder is then trained to predict the next output symbol y t given the encoded input vector c and all the previously predicted output symbols y 1 , ..., y t−1 . More formally, the decoder defines a probability over the output sequence y = y 1 , ..., y T by decomposing the joint probability into ordered conditionals:</p><formula xml:id="formula_4">p( y | x) = T t=1 p(y t | c, y 1 , ..., y t−1 )<label>(3)</label></formula><p>Typically a decoder RNN defines the hidden state at time t as s t = g(s t−1 , {c, y t−1 }) and then feeds s t to a softmax layer in order to obtain a conditional probability over output symbols.  <ref type="figure">Figure 3</ref>: Encoder-decoder architecture for sequence-to-sequence WSD, with 2 bidirectional LSTM layers and an attention layer.</p><p>In the context of WSD framed as a sequence learning problem, a sequence-to-sequence model takes as input a training set of labeled sequences (cf. Section 3.1) and learns to replicate an input sequence x while replacing each content word with its most suitable word sense from S. In other words, sequence-to-sequence WSD can be viewed as the combination of two sub-tasks:</p><p>• A memorization task, where the model learns to replicate the input sequence token by token at decoding time;</p><p>• The actual disambiguation task where the model learns to replace content words across the input sequence with their most suitable senses from the sense inventory S.</p><p>In the latter stage, multi-word expressions (such as nominal entity mentions or phrasal verbs) are replaced by their sense identifiers, hence yielding an output sequence that might have a different length than x.</p><p>Architecture. The encoder-decoder architecture generalizes over both the models in Sections 3.1 and 3.2. In particular, we include one or more bidirectional LSTM layers at the core of both the encoder and the decoder modules. The encoder utilizes an embedding layer (cf. Section 3.1) to convert input symbols into embedded representations, feeds it to the bidirectional LSTM layer, and then constructs the context vector c, either by simply letting c = h T (i.e., the hidden state of the bidirectional LSTM layer after reading the whole input sequence), or by computing the weighted sum described in Section 3.2 (if an attention mechanism is employed). In either case, the context vector c is passed over to the decoder, which generates the output symbols sequentially based on c and the current hidden state s t , using one or more bidirectional LSTM layers as in the encoder module. Instead of feeding c to the decoder only at the first time step <ref type="bibr" target="#b58">(Sutskever et al., 2014;</ref><ref type="bibr" target="#b63">Vinyals and Le, 2015)</ref>, we condition each output symbol y t on c, allowing the decoder to peek into the input at every step, as in <ref type="bibr" target="#b14">Cho et al. (2014)</ref>. Finally, a fully-connected layer with softmax activation converts the current output vector of the last LSTM layer into a probability distribution over the output vocabulary O. The complete encoder-decoder architecture (including the attention mechanism) is shown in <ref type="figure">Figure 3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Multitask Learning with Multiple Auxiliary Losses</head><p>Several recent contributions <ref type="bibr">(Søgaard and Gold- berg, 2016;</ref><ref type="bibr" target="#b9">Bjerva et al., 2016;</ref><ref type="bibr" target="#b32">Luong et al., 2016</ref>) have shown the effectiveness of multitask learning (Caruana, 1997, MTL) in a sequence learning scenario. In MTL the idea is that of improving generalization performance by leveraging training signals contained in related tasks, in order to exploit their commonalities and differences. MTL is typically carried out by training a single architecture using multiple loss functions and a shared representation, with the underlying intention of improving a main task by incorporating joint learning of one or more related auxiliary tasks. From a practical point of view, MTL works by including one task-specific output layer per additional task, usually at the outermost level of the architecture, while keeping the remaining hidden layers common across all tasks.</p><p>In line with previous approaches, and guided by the intuition that WSD is strongly linked to other NLP tasks at various levels, we also design and study experimentally a multitask augmentation of the models described in Section 3. In particular, we consider two auxiliary tasks:</p><p>• Part-of-speech (POS) tagging, a standard auxiliary task extensively studied in previous work . Predicting the part-of-speech tag for a given token can also be informative for word senses, and help in dealing with cross-POS lexical ambiguities (e.g., book a flight vs. reading a good book);</p><p>• Coarse-grained semantic labels (LEX) based on the WordNet ( <ref type="bibr" target="#b38">Miller et al., 1990)</ref> lexicographer files, 4 i.e., 45 coarse-grained semantic categories manually associated with all the synsets in WordNet on the basis of both syntactic and logical groupings (e.g., noun.location, or verb.motion). These very coarse semantic labels, recently employed in a multitask setting by <ref type="bibr" target="#b2">Alonso and Plank (2017)</ref>, group together related senses and help the model to generalize, especially over senses less covered at training time.</p><p>We follow previous work <ref type="bibr" target="#b2">Alonso and Plank, 2017)</ref> and define an auxiliary loss function for each additional task. The overall loss is then computed by summing the main loss (i.e., the one associated with word sense labels) and all the auxiliary losses taken into account.</p><p>As regards the architecture, we consider both the models described in Sections 3.2 and 3.3 and modify them by adding two softmax layers in addition to the one in the original architecture. <ref type="figure" target="#fig_1">Fig- ure 4</ref> illustrates this for the attentive tagger of Section 3.2, considering both POS and LEX as auxiliary tasks. At the j th time step the model predicts a sense label y j together with a part-of-speech tag POS j and a coarse semantic label LEX j . <ref type="bibr">5</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental Setup</head><p>In this section we detail the setup of our experimental evaluation. We first describe the training corpus and all the standard benchmarks for all-words WSD; we then report technical details on the architecture and on the training process for all the models described throughout Section 3 and their multitask augmentations (Section 4). <ref type="bibr">4</ref> https://wordnet.princeton.edu/man/ lexnames.5WN.html <ref type="bibr">5</ref> We use a dummy LEX label (other) for punctuation and function words.  Evaluation Benchmarks. We evaluated our models on the English all-words WSD task, considering both the fine-grained and coarsegrained benchmarks (Section 6.1). As regards fine-grained WSD, we relied on the evaluation framework of <ref type="bibr" target="#b53">Raganato et al. (2017)</ref>, which includes five standardized test sets from the Senseval/SemEval series: Senseval-2 (Edmonds and Cotton, 2001, SE2), Senseval-3 (Snyder and Palmer, 2004, SE3), <ref type="bibr">SemEval-2007</ref><ref type="bibr" target="#b51">(Pradhan et al., 2007</ref>, <ref type="bibr">SemEval-2013</ref><ref type="bibr" target="#b44">(Navigli et al., 2013</ref> and <ref type="bibr">SemEval-2015 (Moro and</ref><ref type="bibr">Navigli, 2015, SE15)</ref>. Due to the lack of a reasonably large development set for our setup, we considered the smallest among these test sets, i.e., SE07, as development set and excluded it from the evaluation of Section 6.1. As for coarse-grained WSD, we used the SemEval-2007 task 7 test set ( <ref type="bibr" target="#b45">Navigli et al., 2007</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Concatenation of All Test Datasets</head><p>Nouns Verbs Adj. Adv. All</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="70.2">56.3 75.2 84.4</head><p>68.9 71.0 58.4 75.2 83.5 69.7 71.6 57.1 75.6 83.2 69.9 71.5 57.5 75.0 83.8  <ref type="table">Table 1</ref>: F-scores (%) for English all-words fine-grained WSD on the test sets in the framework of Raganato et al. <ref type="formula" target="#formula_3">(2017)</ref> (including the development set SE07). The first system with a statistically significant difference from our best models is marked with (unpaired t-test, p &lt; 0.05).</p><note type="other">69.9 68.7 54.5 74.0 81.2 67.3 69.5 57.2 74.5 81.8 68.4 70.4 55.7 73.3 82.9 68.5 70.1 55.2 75.1 84.4 68.</note><p>At testing time, given a target word w, our models used the probability distribution over O, computed by the softmax layer at the corresponding time step, to rank the candidate senses of w; we then simply selected the top ranking candidate as output of the model. Architecture Details. To set a level playing field with comparison systems on English all-words WSD, we followed <ref type="bibr" target="#b53">Raganato et al. (2017)</ref> and, for all our models, we used a layer of word embeddings pre-trained 8 on the English ukWaC corpus ( <ref type="bibr" target="#b6">Baroni et al., 2009)</ref> as initialization, and kept them fixed during the training process. For all architectures we then employed 2 layers of bidirectional LSTM with 2048 hidden units (1024 units per direction).</p><p>As regards multilingual all-words WSD (Section 6.2), we experimented, instead, with two different configurations of the embedding layer: the pre-trained bilingual embeddings by Mrkši´ Training. We used SemCor 3.0 ( <ref type="bibr" target="#b39">Miller et al., 1993)</ref> as training corpus for all our experiments. Widely known and utilized in the WSD literature, SemCor is one of the largest corpora annotated manually with word senses from the sense inventory of WordNet ( <ref type="bibr" target="#b38">Miller et al., 1990</ref>) for all openclass parts of speech. We used the standardized version of SemCor as provided in the evaluation framework 9 which also includes coarse-grained POS tags from the universal tagset. All models were trained for a fixed number of epochs E = 40 using Adadelta <ref type="bibr" target="#b68">(Zeiler, 2012</ref>) with learning rate 1.0 and batch size 32. After each epoch we evaluated our models on the development set, and then compared the best iterations (E * ) on the development set with the reported state of the art in each benchmark.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experimental Results</head><p>Throughout this section we identify the models based on the LSTM tagger (Sections 3.1-3.2) by the label BLSTM, and the sequence-to-sequence models (Section 3.3) by the label Seq2Seq. <ref type="table">Table 1</ref> shows the performance of our models on the standardized benchmarks for all-words finegrained WSD. We report the F1-score on each in-  <ref type="table">Table 2</ref>: F-scores (%) for coarse-grained WSD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">English All-words WSD</head><p>dividual test set, as well as the F1-score obtained on the concatenation of all four test sets, divided by part-of-speech tag.</p><p>We compared against the best supervised and knowledge-based systems evaluated on the same framework. As supervised systems, we considered Context2Vec ( <ref type="bibr" target="#b35">Melamud et al., 2016)</ref> and It Makes Sense ( <ref type="bibr">Zhong and Ng, 2010, IMS)</ref>, both the original implementation and the best configuration reported by <ref type="bibr">Iacobacci et al. (2016, IMS+emb)</ref>, which also integrates word embeddings using exponential decay. 10 All these supervised systems were trained on the standardized version of SemCor. As knowledge-based systems we considered the embeddings-enhanced version of Lesk by <ref type="bibr">Basile et al. (2014, Lesk ext</ref> +emb), UKB (Agirre et al., 2014) (UKB gloss w2w) , and <ref type="bibr">Babelfy (Moro et al., 2014</ref>). All these systems relied on the Most Frequent Sense (MFS) baseline as back-off strategy. 11 Overall, both BLSTM and Seq2Seq achieved results that are either state-of-the-art or statistically equivalent (unpaired t-test, p &lt; 0.05) to the best supervised system in each benchmark, performing on par with word experts tuned over explicitly engineered features <ref type="bibr" target="#b28">(Iacobacci et al., 2016)</ref>. Interestingly enough, BLSTM models tended consistently to outperform their Seq2Seq counterparts, suggesting that an encoder-decoder architecture, despite being more powerful, might be suboptimal for WSD. Furthermore, introducing LEX (cf. Section 4) as auxiliary task was generally helpful; on the other hand, POS did not seem to help, corroborating previous findings <ref type="bibr" target="#b2">(Alonso and Plank, 2017;</ref><ref type="bibr" target="#b8">Bingel and Søgaard, 2017</ref>).</p><p>The overall performance by part of speech was consistent with the above analysis, showing that our models outperformed all knowledgebased systems, while obtaining results that are superior or equivalent to the best supervised mod- <ref type="bibr">10</ref> We are not including <ref type="bibr" target="#b67">Yuan et al. (2016)</ref>, as their models are not available and not replicable on the standardized test sets, being based on proprietary data. 11 Since each system always outputs an answer, F-score equals both precision and recall, and statistical significance can be expressed with respect to any of these measures.  <ref type="table">Table 3</ref>: F-scores (%) for multilingual WSD.</p><p>els. It is worth noting that RNN-based architectures outperformed classical supervised approaches ( <ref type="bibr" target="#b69">Zhong and Ng, 2010;</ref><ref type="bibr" target="#b28">Iacobacci et al., 2016</ref>) when dealing with verbs, which are shown to be highly ambiguous ( <ref type="bibr" target="#b53">Raganato et al., 2017)</ref>. The performance on coarse-grained WSD followed the same trend <ref type="table">(Table 2)</ref>. Both BLSTM and Seq2Seq outperformed UKB ( <ref type="bibr" target="#b1">Agirre et al., 2014)</ref> and IMS trained on SemCor ( <ref type="bibr" target="#b59">Taghipour and Ng, 2015a)</ref>, as well as recent supervised approaches based on distributional semantics and neural architectures ( <ref type="bibr" target="#b13">Chen et al., 2014;</ref><ref type="bibr" target="#b67">Yuan et al., 2016</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Multilingual All-words WSD</head><p>All the neural architectures described in this paper can be readily adapted to work with different languages without adding sense-annotated data in the target language. In fact, as long as the first layer (cf. <ref type="figure" target="#fig_0">Figures 1-3)</ref> is equipped with bilingual or multilingual embeddings where word vectors in the training and target language are defined in the same space, the training process can be left unchanged, even if based only on English data. The underlying assumption is that words that are translations of each other (e.g., house in English and casa in Italian) are mapped to word embeddings that are as close as possible in the vector space.</p><p>In order to assess this, we considered one of our best models (BLSTM+att.+LEX) and replaced the monolingual embeddings with bilingual and multilingual embeddings (as specified in Section 5), leaving the rest of the architecture unchanged. We then trained these architectures on the same English training data, and ran the resulting models on the multilingual benchmarks of SemEval-2013 for Italian, French, German and Spanish. While doing this, we exploited BabelNet's inter-resource mappings to convert WordNet sense labels (used at training time) into BabelNet synsets compliant with the sense inventory of the task.</p><p>F-score figures <ref type="table">(Table 3)</ref> show that bilingual and multilingual models, despite being trained only on English data, consistently outperformed the MFS baseline and achieved results that are competitive with the best participating systems in the task. We also note that the overall F-score performance did not change substantially (and slightly improved) when moving from bilingual to multilingual models, despite the increase in the number of target languages treated simultaneously.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Discussion and Error Analysis</head><p>All the neural models evaluated in Section 6.1 utilized the MFS back-off strategy for instances unseen at training time, which amounted to 9.4% overall for fine-grained WSD and 10.5% for coarse-grained WSD. Back-off strategy aside, 85% of the times the top candidate sense for a target instance lay within the 10 most probable entries in the probability distribution over O computed by the softmax layer. <ref type="bibr">12</ref> In fact, our sequence models learned, on the one hand, to associate a target word with its candidate senses (something word experts are not required to learn, as they only deal with a single word type at a time); on the other, they tended to generate softmax distributions reflecting the semantics of the surronding context. For example, in the sentence:</p><p>(a) The two justices have been attending federalist society events for years, our model correctly disambiguated justices with the WordNet sense justice 3 n (public official) rather than justice 1 n (the quality of being just), and the corresponding softmax distribution was heavily biased towards words and senses related to persons or groups (commissioners, defendants, jury, cabinet, directors). On the other hand, in the sentence:</p><p>(b) Xavi Hernandez, the player of Barcelona, has 106 matches, the same model disambiguated matches with the wrong WordNet sense match 1 n (tool for starting a fire). This suggests that the signal carried by discriminative words like player vanishes rather quickly. In order to enforce global coherence further, recent contributions have proposed more sophisticated models where recurrent architectures are combined with Conditional Random Fields ( <ref type="bibr" target="#b26">Huang et al., 2015;</ref><ref type="bibr" target="#b33">Ma and Hovy, 2016)</ref>. Finally, a number of errors were connected to shorter sentences with limited context for disambiguation: in fact, we noted that the average pre-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>In this paper we adopted a new perspective on supervised WSD, so far typically viewed as a classification problem at the word level, and framed it using neural sequence learning. To this aim we defined, analyzed and compared experimentally different end-to-end models of varying complexities, including augmentations based on an attention mechanism and multitask learning.</p><p>Unlike previous supervised approaches, where a dedicated model needs to be trained for every content word and each disambiguation target is treated in isolation, sequence learning approaches learn a single model in one pass from the training data, and then disambiguate jointly all target words within an input text. The resulting models consistently achieved state-of-the-art (or statistically equivalent) figures in all benchmarks for all-words WSD, both fine-grained and coarse-grained, effectively demonstrating that we can overcome the so far undisputed and long-standing word-expert assumption of supervised WSD, while retaining the accuracy of supervised word experts.</p><p>Furthermore, these models are sufficiently flexible to allow them, for the first time in WSD, to be readily adapted to languages different from the one used at training time, and still achieve competitive results (as shown in Section 6.2). This crucial feature could potentially pave the way for crosslingual supervised WSD, and overcome the shortage of sense-annotated data in multiple languages that, to date, has prevented the development of supervised models for languages other than English.</p><p>As future work, we plan to extend our evaluation to larger sense-annotated corpora ( <ref type="bibr" target="#b52">Raganato et al., 2016)</ref> as well as to different sense inventories and different languages. We also plan to exploit the flexibility of our models by integrating them into downstream applications, such as Machine Translation and Information Extraction.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Bidirectional LSTM sequence labeling architecture for WSD (2 hidden layers). We use the notation of Navigli (2009) for word senses: w i p</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Multitask augmentation (with both POS and LEX as auxiliary tasks) for the attentive bidirectional LSTM tagger of Section 3.2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Mrkši´c et al. (2017) for all the language pairs of interest (EN-IT, EN-FR, EN-DE, and EN-ES), and the pre-trained multilingual 512-dimensional em- beddings for 12 languages by Ammar et al. (2016).</figDesc></figure>

			<note place="foot" n="3"> For instance, Sutskever et al. (2014) used an LSTM as f , and q({h1, ..., hT }) = hT .</note>

			<note place="foot" n="6"> We utilized the original sense-key mappings available at http://wordnetcode.princeton.edu/3.0 for nouns and verbs, and the automatic mappings by Daudé et al. (2003) for the remaining parts of speech (not available in the original mappings). 7 http://babelnet.org</note>

			<note place="foot" n="8"> We followed Iacobacci et al. (2016) and used the Word2Vec (Mikolov et al., 2013) skip-gram model with 400 dimensions, 10 negative samples and a window size of 10.</note>

			<note place="foot" n="9"> http://lcl.uniroma1.it/wsdeval</note>

			<note place="foot" n="12"> We refer here to the same model considered in Section 6.2 (i.e., BLSTM+att.+LEX). cision of our model, without MFS back-off, increased by 6.2% (from 74.6% to 80.8%) on sentences with more than 20 word tokens.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors gratefully acknowledge the support of the ERC Consolidator Grant MOUSSE No. 726487.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Word sense disambiguation: Algorithms and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eneko</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Edmonds</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<publisher>Springer Science &amp; Business Media</publisher>
			<biblScope unit="volume">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Random Walks for Knowledge-Based Word Sense Disambiguation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eneko</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oier</forename><surname>Lopez De Lacalle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aitor</forename><surname>Soroa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Linguist</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="57" to="84" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">When is Multitask Learning Effective? Semantic Sequence Prediction under Varying Data Conditions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alonso</forename><surname>Héctor Martínez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Plank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="44" to="53" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Waleed</forename><surname>Ammar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Mulcaire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulia</forename><surname>Tsvetkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<idno>abs/1602.01925</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>Massively Multilingual Word Embeddings. CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Semisupervised Learning with Induced Word Senses for State of the Art Word Sense Disambiguation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Osman</forename><surname>Bas¸kayabas¸kaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Jurgens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Artif. Int. Res</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1025" to="1058" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Neural Machine Translation by Jointly Learning to Align and Translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR Workshop</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The WaCky wide web: a collection of very large linguistically processed web-crawled corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvia</forename><surname>Bernardini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adriano</forename><surname>Ferraresi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eros</forename><surname>Zanchetta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Language Resources and Evaluation</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="209" to="226" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">An Enhanced Lesk Word Sense Disambiguation Algorithm through a Distributional Semantic Model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierpaolo</forename><surname>Basile</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Annalina</forename><surname>Caputo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giovanni</forename><surname>Semeraro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of COLING</title>
		<meeting>of COLING</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1591" to="1600" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Identifying Beneficial Task Relations for Multi-task Learning in Deep Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joachim</forename><surname>Bingel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Søgaard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EACL</title>
		<meeting>of EACL</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="164" to="169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Semantic Tagging with Deep Residual Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Bjerva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Plank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johan</forename><surname>Bos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of COLING</title>
		<meeting>of COLING</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3531" to="3541" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">ShotgunWSD: an Unsupervised Algorithm for Global Word Sense Disambiguation Inspired by DNA Sequencing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><surname>Butnaru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tudor</forename><surname>Radu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florentina</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hristea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EACL</title>
		<meeting>of EACL</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="916" to="926" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Improving Statistical Machine Translation using Word Sense Disambiguation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marine</forename><surname>Carpuat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dekai</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="61" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Multitask learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rich</forename><surname>Caruana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="41" to="75" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A Unified Model for Word Sense Representation and Disambiguation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinxiong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1025" to="1035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Learning Phrase Representations using RNN EncoderDecoder for Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Merrienboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1724" to="1734" />
		</imprint>
	</monogr>
	<note>Fethi Bougares, Holger Schwenk, and Yoshua Bengio</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Broad-coverage Sense Disambiguation and Information Extraction with a Supersense Sequence Tagger</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimiliano</forename><surname>Ciaramita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yasemin</forename><surname>Altun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="594" to="602" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Validation and Tuning of WordNet Mapping Techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordi</forename><surname>Daudé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lluís</forename><surname>Padró</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">German</forename><surname>Rigau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of RANLP</title>
		<meeting>of RANLP</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="117" to="123" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A Methodology for Word Sense Disambiguation at 90% based on large-scale Crowd Sourcing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eneko</forename><surname>Oier Lopez De Lacalle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Agirre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SEM</title>
		<meeting>of SEM</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="61" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Large-Scale Information Extraction from Textual Definitions through Deep Syntactic and Semantic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claudio</forename><surname>Delli Bovi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Telesca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Navigli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Analysis. TACL</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="529" to="543" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Senseval-2: Overview</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Edmonds</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Cotton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SENSEVAL</title>
		<meeting>of SENSEVAL</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Morphological Inflection Generation Using Character Sequence to Sequence Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manaal</forename><surname>Faruqui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulia</forename><surname>Tsvetkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NAACL-HLT</title>
		<meeting>of NAACL-HLT</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="634" to="643" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Supersense embeddings: A unified model for supersense interpretation, prediction, and utilization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucie</forename><surname>Flekova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2029" to="2041" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Generating Sequences With Recurrent Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<idno>abs/1308.0850</idno>
		<imprint>
			<date type="published" when="2013" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Framewise phoneme classification with bidirectional LSTM and other neural network architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Networks</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="602" to="610" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Incorporating Copying Mechanism in Sequence-to-Sequence Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiatao</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><forename type="middle">O K</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1631" to="1640" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Long Short-Term Memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Yu</surname></persName>
		</author>
		<idno>abs/1508.01991</idno>
		<title level="m">Bidirectional LSTM-CRF Models for Sequence Tagging. CoRR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">SensEmbed: Learning Sense Embeddings for Word and Relational Similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ignacio</forename><surname>Iacobacci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><forename type="middle">Taher</forename><surname>Pilehvar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Navigli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="95" to="105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Embeddings for Word Sense Disambiguation: An Evaluation Study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ignacio</forename><surname>Iacobacci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><forename type="middle">Taher</forename><surname>Pilehvar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Navigli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="897" to="907" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Word Sense Disambiguation using a Bidirectional LSTM</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikael</forename><surname>Kågebäck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans</forename><surname>Salomonsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CogALex</title>
		<meeting>CogALex</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="51" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">English Lexical Sample Task Description</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Kilgarriff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SENSEVAL</title>
		<meeting>of SENSEVAL</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="17" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Skip-thought vectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanja</forename><surname>Fidler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NIPS</title>
		<meeting>of NIPS</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3294" to="3302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Multi-task sequence to sequence learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR Workshop</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">End-to-end Sequence Labeling via Bi-directional LSTM-CNNs-CRF</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuezhe</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1064" to="1074" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Word Sense Clustering and Clusterability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diana</forename><surname>Mccarthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marianna</forename><surname>Apidianaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katrin</forename><surname>Erk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Linguist</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="245" to="275" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Learning Generic Context Embedding with Bidirectional LSTM</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Melamud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Goldberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ido</forename><surname>Dagan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of CoNLL</title>
		<meeting>of CoNLL</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="51" to="61" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">The Senseval-3 English Lexical Sample Task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rada</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Chklovski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Kilgarriff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SENSEVAL</title>
		<meeting>of SENSEVAL</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="25" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR Workshop</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">WordNet: an online lexical database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><forename type="middle">A</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T</forename><surname>Beckwith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christiane</forename><forename type="middle">D</forename><surname>Fellbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Lexicography</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="235" to="244" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A semantic concordance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><forename type="middle">A</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claudia</forename><surname>Leacock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Randee</forename><surname>Tengi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><forename type="middle">T</forename><surname>Bunker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of HLT</title>
		<meeting>of HLT</meeting>
		<imprint>
			<date type="published" when="1993" />
			<biblScope unit="page" from="303" to="308" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">SemEval-2015 Task 13: Multilingual All-Words Sense Disambiguation and Entity Linking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Moro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Navigli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SemEval</title>
		<meeting>of SemEval</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="288" to="297" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Entity Linking meets Word Sense Disambiguation: a Unified Approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Moro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Raganato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Navigli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TACL</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="231" to="244" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Semantic Specialisation of Distributional Word Vector Spaces using Monolingual and Cross-Lingual Constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikola</forename><surname>Mrkši´mrkši´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Vuli´cvuli´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diarmuid´odiarmuid´</forename><forename type="middle">Diarmuid´o</forename><surname>Séaghdha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roi</forename><surname>Reichart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ira</forename><surname>Leviant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milica</forename><surname>Gaši´gaši´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Young</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>TACL</publisher>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Word sense disambiguation: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Navigli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">10</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">SemEval-2013 Task 12: Multilingual Word Sense Disambiguation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Navigli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Jurgens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniele</forename><surname>Vannella</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SemEval</title>
		<meeting>of SemEval</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="222" to="231" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">SemEval-2007 Task 07: Coarsegrained English All-words Task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Navigli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><forename type="middle">C</forename><surname>Litkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Orin</forename><surname>Hargraves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SemEval</title>
		<meeting>of SemEval</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="30" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">BabelNet: The Automatic Construction, Evaluation and Application of a Wide-Coverage Multilingual Semantic Network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Navigli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simone</forename><forename type="middle">Paolo</forename><surname>Ponzetto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">193</biblScope>
			<biblScope unit="page" from="217" to="250" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Word SenseAware Machine Translation: Including Senses as Contextual Features for Improved Translation Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Neale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lus</forename><surname>Gomes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eneko</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oier</forename><surname>Lopez De Lacalle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antnio</forename><surname>Branco</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of LREC</title>
		<meeting>of LREC</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2777" to="2783" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Train-O-Matic: Large-Scale Supervised Word Sense Disambiguation in Multiple Languages without Manual Training Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tommaso</forename><surname>Pasini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Navigli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">A Large-scale Pseudoword-based Evaluation Framework for State-of-the-art Word Sense Disambiguation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Taher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pilehvar</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Navigli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Linguist</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="837" to="881" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Multilingual Part-of-Speech Tagging with Bidirectional Long Short-Term Memory Models and Auxiliary Loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Plank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Søgaard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="412" to="418" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">SemEval-2007 Task 17: English Lexical Sample, SRL and All Words</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sameer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Pradhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitriy</forename><surname>Loper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><surname>Dligach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Palmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SemEval-2007</title>
		<meeting>of SemEval-2007</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="87" to="92" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Automatic Construction and Evaluation of a Large Semantically Enriched Wikipedia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Raganato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claudio</forename><forename type="middle">Delli</forename><surname>Bovi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Navigli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IJCAI</title>
		<meeting>of IJCAI</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2894" to="2900" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Word Sense Disambiguation: A Unified Evaluation Framework and Empirical Comparison</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Raganato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jose</forename><surname>Camacho-Collados</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Navigli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EACL</title>
		<meeting>of EACL</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="99" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">AutoExtend: Extending Word Embeddings to Embeddings for Synsets and Lexemes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sascha</forename><surname>Rothe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1793" to="1803" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Coarse to Fine Grained Sense Disambiguation in Wikipedia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Razvan</forename><surname>Bunescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rada</forename><surname>Mihalcea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SEM</title>
		<meeting>of SEM</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="22" to="31" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">The english all-words task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Snyder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Senseval-3</title>
		<meeting>of Senseval-3</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="41" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Deep multi-task learning with low level tasks supervised at lower layers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Søgaard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="231" to="235" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Sequence to Sequence Learning with Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NIPS</title>
		<meeting>of NIPS</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">One Million Sense-Tagged Instances for Word Sense Disambiguation and Induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaveh</forename><surname>Taghipour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwee Tou</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of CoNLL</title>
		<meeting>of CoNLL</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="338" to="344" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">SemiSupervised Word Sense Disambiguation Using Word Embeddings in General and Specific Domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaveh</forename><surname>Taghipour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwee Tou</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NAACL-HLT</title>
		<meeting>of NAACL-HLT</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="314" to="323" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">A GameTheoretic Approach to Word Sense Disambiguation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rocco</forename><surname>Tripodi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Pelillo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Linguist</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="31" to="70" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Grammar as a foreign language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terry</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Koo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NIPS</title>
		<meeting>of NIPS</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2773" to="2781" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">A Neural Conversational Model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICML, JMLR: W&amp;CP</title>
		<meeting>of ICML, JMLR: W&amp;CP</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">37</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Graph-based Dependency Parsing with Bidirectional LSTM</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baobao</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2306" to="2315" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Multi-Objective Optimization for the Joint Disambiguation of Nouns and Named Entities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonhard</forename><surname>Hennig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feiyu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans</forename><surname>Uszkoreit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="596" to="605" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">A Sense-Based Translation Model for Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyi</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1459" to="1469" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Semi-supervised Word Sense Disambiguation with Neural Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dayu</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Doherty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Altendorf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of COLING</title>
		<meeting>of COLING</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1374" to="1385" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">ADADELTA: An Adaptive Learning Rate Method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zeiler</surname></persName>
		</author>
		<idno>abs/1212.5701</idno>
		<imprint>
			<date type="published" when="2012" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">It Makes Sense: A Wide-Coverage Word Sense Disambiguation System for Free Text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwee Tou</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL: System Demonstrations</title>
		<meeting>of ACL: System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="78" to="83" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Word Sense Disambiguation Improves Information Retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwee Tou</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="273" to="282" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">End-to-End Learning of Semantic Role Labeling using Recurrent Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1127" to="1137" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">AttentionBased Bidirectional Long Short-Term Memory Networks for Relation Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenyu</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingchen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongwei</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="207" to="212" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
