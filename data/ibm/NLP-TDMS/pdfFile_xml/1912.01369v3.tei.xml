<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Multi-Objective Evolutionary Design of Deep Convolutional Neural Networks for Image Classification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Student Member, IEEE</roleName><forename type="first">Zhichao</forename><surname>Lu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Whalen</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yashesh</forename><surname>Dhebar</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Fellow, IEEE</roleName><forename type="first">Kalyanmoy</forename><surname>Deb</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Goodman</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Banzhaf</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vishnu</forename><surname>Naresh</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>IEEE</roleName><forename type="first">Boddeti</forename><surname>Member</surname></persName>
						</author>
						<title level="a" type="main">Multi-Objective Evolutionary Design of Deep Convolutional Neural Networks for Image Classification</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>1</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T06:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Convolutional neural networks (CNNs) are the backbones of deep learning paradigms for numerous vision tasks. Early advancements in CNN architectures are primarily driven by human expertise and by elaborate design processes. Recently, neural architecture search was proposed with the aim of automating the network design process and generating task-dependent architectures. While existing approaches have achieved competitive performance in image classification, they are not well suited to problems where the computational budget is limited for two reasons: (1) the obtained architectures are either solely optimized for classification performance, or only for one deployment scenario; (2) the search process requires vast computational resources in most approaches. To overcome these limitations, we propose an evolutionary algorithm for searching neural architectures under multiple objectives, such as classification performance and floating point operations (FLOPs). The proposed method addresses the first shortcoming by populating a set of architectures to approximate the entire Pareto frontier through genetic operations that recombine and modify architectural components progressively. Our approach improves computational efficiency by carefully down-scaling the architectures during the search as well as reinforcing the patterns commonly shared among past successful architectures through Bayesian model learning. The integration of these two main contributions allows an efficient design of architectures that are competitive and in most cases outperform both manually and automatically designed architectures on benchmark image classification datasets: CIFAR, ImageNet and human chest X-ray. The flexibility provided from simultaneously obtaining multiple architecture choices for different compute requirements further differentiates our approach from other methods in the literature. Code is available at https://github.com/mikelzc1990/nsganetv1.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Deep convolutional neural networks (CNNs) have been overwhelmingly successful in a variety of computer-visionrelated tasks like object classification, detection, and segmentation. One of the main driving forces behind this success is the introduction of many CNN architectures, including GoogLeNet <ref type="bibr" target="#b0">[1]</ref>, ResNet <ref type="bibr" target="#b1">[2]</ref>, DenseNet <ref type="bibr" target="#b2">[3]</ref>, etc., in the context of object classification. Concurrently, architecture designs, such as ShuffleNet <ref type="bibr" target="#b3">[4]</ref>, MobileNet <ref type="bibr" target="#b4">[5]</ref>, LBCNN <ref type="bibr" target="#b5">[6]</ref>, etc., have been developed with the goal of enabling real-world deployment of high-performance models on resource-constrained devices.</p><p>The authors are with Michigan State University, East Lansing, MI, 48824 USA, Corresponding author's e-mail: (luzhicha@msu.edu).</p><p>These developments are the fruits of years of painstaking efforts and human ingenuity.</p><p>Neural architecture search (NAS), on the other hand, presents a promising path to alleviate this painful process by posing the design of CNN architectures as an optimization problem. By altering the architectural components in an algorithmic fashion, novel CNNs can be discovered that exhibit improved performance metrics on representative datasets. The huge surge in research and applications of NAS indicates the tremendous academic and industrial interest NAS has attracted, as teams seek to stake out some of this territory. It is now well recognized that designing bespoke neural network architectures for various tasks is one of the most challenging and practically beneficial components of the entire Deep Neural Network (DNN) development process, and is a fundamental step toward automated machine learning.</p><p>Early methods for NAS relied on Reinforcement Learning (RL) to navigate and search for architectures with high performance. A major limitation of these approaches <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref> is the steep computational requirement for the search process itself, often requiring weeks of wall clock time on hundreds of Graphics Processing Unit (GPU) cards. Recent relaxation-based methods <ref type="bibr" target="#b8">[9]</ref>- <ref type="bibr" target="#b11">[12]</ref> seek to improve the computational efficiency of NAS approaches by approximating the connectivity between different layers in the CNN architectures by real-valued variables that are learned (optimized) through gradient descent together with the weights. However, such relaxation-based NAS methods suffer from excessive GPU memory requirements during search, resulting in constraints on the size of the search space (e.g., reduced layer operation choices).</p><p>In addition to being accurate in prediction, real-world applications demand that NAS methods find network architectures that are also efficient in computation-e.g., have low power consumption in mobile applications and low latency in autonomous driving applications. It has been a common observation that the predictive performance continuously improves as the complexity (i.e., # of layers, channels, etc.) of the network architectures increases <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b12">[13]</ref>. This alludes to the competing nature of trying to simultaneously maximize predictive performance and minimize network complexity, thereby necessitating multi-objective optimization. Despite recent advances in RL and relaxation-based NAS methods, they are still not readily applicable for multi-objective NAS.</p><p>Among the many different NAS methods being continually proposed, Evolutionary Algorithms (EAs) are getting a plethora of attention, due to their population-based nature and flexibility in encoding. They offer a viable alternative to conventional machine learning (ML)-oriented approaches, especially under the scope of multi-objective NAS. An EA, in general, is an iterative process in which individuals in a population are made gradually better by applying variations to selected individuals and/or recombining parts of multiple individuals. Despite the ease of extending them to handle multiple objectives, most existing EA-based NAS methods <ref type="bibr" target="#b13">[14]</ref>- <ref type="bibr" target="#b18">[19]</ref> are still singleobjective driven.</p><p>In this paper, we present NSGANetV1, a multi-objective evolutionary algorithm for NAS, extending on an earlier proofof-principle method <ref type="bibr" target="#b19">[20]</ref>, to address the aforementioned limitations of current approaches. The key contributions followed by the extensions made in this paper are summarized below: 1) NSGANetV1 populates a set of architectures to approximate the entire Pareto front in one run through customized genetic operations that recombine and modify architectural components progressively. NSGANetV1 improves computational efficiency by carefully downscaling the architectures during the search as well as reinforcing the emerging patterns shared among past successful architectures through a Bayesian Network based distribution estimation operator. Empirically, the obtained architectures, in most cases, outperform both manually and other automatically designed architectures on various datasets. 2) By obtaining a set of architectures in one run, NS-GANetV1 allows designers to choose a suitable network a-posteriori as opposed to a pre-defined preference weighting of objectives prior to the search. Further postoptimal analysis of the set of non-dominated architectures often reveals valuable design principles, which is another benefit of posing NAS as a multi-objective optimization problem, as is done in NSGANetV1. 3) From an algorithmic perspective, we extend our previous work <ref type="bibr" target="#b19">[20]</ref> in a number of ways: (i) an expanded search space to include five more layer operations and one more option that controls the width of the network, (ii) improved encoding, mutation and crossover operators accompanying the modified search space, and (iii) a more thorough lower-level optimization process for weight learning, resulting in better and more reliable performance. 4) From an evaluation perspective, we extend our previous work <ref type="bibr" target="#b19">[20]</ref> in two different ways: (i) adding three more tasks, including medical imaging, robustness to adversarial attacks, and car key-point estimation; and (ii) evaluating the searched architectures on five new datasets, including, ImageNet, ImageNet-V2, CIFAR-10.1, corrupted CIFAR-10 and corrupted CIFAR-100.</p><p>The remainder of this paper is organized as follows. Section II introduces and summarizes related literature. In Section III, we provide a detailed description of the main components of our approach. We describe the experimental setup to validate our approach along with a discussion of the results in Section IV, followed by further analysis and an application study in Sections V and VI, respectively. Finally, we conclude with a summary of our findings and comment on possible future directions in Section VII.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head><p>Recent years have witnessed growing interest in NAS. The promise of being able to automatically and efficiently search for task-dependent network architectures is particularly appealing as deep neural networks are widely deployed in diverse applications and computational environments. Early methods <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b21">[22]</ref> made efforts to simultaneously evolve the topology of neural networks along with weights and hyperparameters. These methods perform competitively with hand-crafted networks on control tasks with shallow fully connected networks. In the following, we present studies related to deep convolutional neural networks for image classification. Readers are referred to the supplementary materials for a more detailed review of the topic. Evolutionary NAS: Designing neural networks through evolution has been a topic of interest for a long time. Recent evolutionary approaches focus on evolving solely the topology while leaving the learning of weights to gradient descent algorithms, and using hyper-parameter settings that are manually tuned. Xie and Yuille's work of Genetic CNN <ref type="bibr" target="#b13">[14]</ref> is one of the early studies that shows the promise of using EAs for NAS. Real et al. <ref type="bibr" target="#b14">[15]</ref> introduce perhaps the first truly large scale application of a simple EA to NAS. The extension of this method presented in <ref type="bibr" target="#b16">[17]</ref>, called AmoebaNet, provides the first large scale comparison of EA and RL methods. Their EA, using an age-based selection similar to <ref type="bibr" target="#b22">[23]</ref>, has demonstrated faster convergence to an accurate network when compared to RL and random search. Concurrently, Liu et al. <ref type="bibr" target="#b15">[16]</ref> evolve a hierarchical representation that allows non-modular layer structures to emerge. Despite the impressive improvements achieved on various datasets, these EA methods are extremely computationally inefficient, e.g., one run of the regularized evolution method <ref type="bibr" target="#b16">[17]</ref> takes one week on 450 GPU cards.</p><p>Concurrently, another streamlining of EA methods for use in budgeted NAS has emerged. Suganuma et al. <ref type="bibr" target="#b23">[24]</ref> use Cartesian genetic programming to assemble an architecture from existing modular blocks (e.g., Residual blocks). Sun et al. in <ref type="bibr" target="#b18">[19]</ref> use a random forest as an offline surrogate model to predict the performance of architectures, partially eliminating the lowerlevel optimization via gradient descent. The reported results yield 3× savings in wall clock time with similar classification performance when compared to their previous works <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b24">[25]</ref>. However, results reported from these budgeted EA methods are far from state-of-the-art and only demonstrated on small-scale datasets-i.e., CIFAR-10 and CIFAR-100. Multi-objective NAS: In this work, the term multi-objective NAS refers to methods that simultaneously approximate the entire set of efficient trade-off architectures in one run <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b26">[27]</ref>. Kim et al. <ref type="bibr" target="#b27">[28]</ref> presented NEMO, one of the earliest evolutionary multi-objective approaches to evolve CNN architectures. NEMO uses NSGA-II <ref type="bibr" target="#b28">[29]</ref> to maximize classification performance and inference time of a network and searches over the space of the number of output channels from each layer within a restricted space of seven different architectures. DPP-Net <ref type="bibr" target="#b29">[30]</ref>, an extension from <ref type="bibr" target="#b30">[31]</ref>, progressively expands networks from simple structures and only trains the top-K (based on Pareto-optimality) networks that are predicted to be promising by a surrogate model. Elsken et al. <ref type="bibr" target="#b31">[32]</ref> present the LEMONADE method, which is formulated to develop networks with high predictive performance and lower resource constraints. LEMONADE reduces compute requirements through customdesigned approximate network morphisms <ref type="bibr" target="#b32">[33]</ref>, which allow newly generated networks to share parameters with their forerunners, obviating the need to train new networks from scratch. However, LEMONADE still requires nearly 100 GPUdays to search on the CIFAR datasets <ref type="bibr" target="#b33">[34]</ref>.</p><p>Search Efficiency: The main computation bottleneck of NAS resides in the lower-level optimization of learning the weights for evaluating the performance of architectures. One such evaluation typically requires hours to finish. To improve the practical utility of search under a constrained computational budget, NAS methods commonly advocate for substitute measurements without a full-blown lower-level optimization. A widely-used approach proceeds as follows: it reduces the depth (number of layers) and the width (number of channels) of the intended architecture to create a small-scale network-i.e., a proxy model. Proxy models require an order of magnitude less computation time (typically, minutes) to perform lower-level optimization, and the performance of proxy models is then used as surrogate measurements to guide the search. However, most existing NAS work <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b34">[35]</ref> follows simple heuristics to construct the proxy model, resulting in low correlation in prediction. For instance, NASNet <ref type="bibr" target="#b7">[8]</ref> has an additional re-ranking stage that trains the top 250 architectures for 300 epochs each (takes more than a year on a single GPU card) before picking the best one, and the reported NASNet-A model was originally ranked 70th among the top 250 according to the performance measured at proxy model scale. Similarly, AmoebaNet <ref type="bibr" target="#b16">[17]</ref> relies on evaluation of duplicate architectures to gauge representative performance, leading to 27K models being evaluated during search.</p><p>In this work, we focus on both the efficiency and the reliabil-ity aspects of the proxy model; through a series of systematic studies in a controlled setting, we empirically establish the trade-off between the correlation of proxy performance to true performance and the speed-up in estimation. We then implement a suitable setting that is specific to our search space and dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. PROPOSED APPROACH</head><p>Practical applications of NAS can rarely be considered from the point of view of a single objective of maximizing performance; rather, they must be evaluated from at least one additional, conflicting objective that is specific to the deployment scenario. In this work, we approach the problem of designing high-performance architectures with diverse complexities for different deployment scenarios as a multi-objective bilevel optimization problem * <ref type="bibr" target="#b35">[36]</ref>. We mathematically formulate the problem as,</p><formula xml:id="formula_0">minimize F (x) = f 1 (x; w * (x)), f 2 (x) T , subject to w * (x) ∈ argmin L(w; x), x ∈ Ω x , w ∈ Ω w ,<label>(1)</label></formula><p>where</p><formula xml:id="formula_1">Ω x = Π n i=1 [a i , b i ] ⊆ Z n is the architecture decision space, where a i , b i</formula><p>are the lower and upper bounds, x = (x 1 , . . . , x n ) T ∈ Ω x is a candidate architecture, and the lowerlevel variable w ∈ Ω w denotes its associated weights. The upper-level objective vector F comprises of the classification error (f 1 ) on the validation data D vld , and the complexity (f 2 ) of the network architecture. The lower level objective L(w; x) is the cross-entropy loss on the training data D trn .</p><p>Our proposed algorithm, NSGANetV1, is an iterative process in which initial architectures are made gradually better as a group, called a population. In every iteration, a group of offspring (i.e., new architectures) is created by applying variations through crossover and mutation to the more promising of the architectures already found, also known as parents, from the population. Every member in the population (including both * See the supplement, Section III, for more about bilevel optimization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1: General framework of NSGANetV1</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Input</head><p>: Complexity objectivef (see Eq. <ref type="formula" target="#formula_13">(3)</ref>), Max. number of generations G, Population size K, Crossover probability pc, Mutation probability pm, The starting generation of exploitation τ . 1 g ← 0 // initialize a generation counter. 2 ρ ← 1 // initialize the control parameter for exploration. <ref type="bibr" target="#b2">3</ref> A ← initialize an empty archive to keep track of evaluated archs. 4 P ← initialize the parent population by uniform sampling. 5 // compute accuracy through lower-level optimization in Algo. 2. 6 f ← Evaluate(P ) 7 // calculate domination rank and crowding distance. </p><formula xml:id="formula_2">8 [F 1 , F 2 , . . .] ← NondominatedSort(f,f (P )) 9 dist ← CrowdingDistance(F 1 , F 2 , . . .) 10 while g &lt; G do 11 k ← 0 // initialize</formula><formula xml:id="formula_3">Q ← Q ∪ q; k ← k + 1 26 end 27 f ← Evaluate(Q) // see line 5. 28 [F 1 , F 2 , . . .] ← NondominatedSort(f ∪ f ,f (P ) ∪f (Q)) 29 dist ← CrowdingDistance(F 1 , F 2 , . . .)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>30</head><p>// survive the top-K archs to next generation following the environmental selection procedures outlined in <ref type="bibr" target="#b28">[29]</ref>.  parents and offspring) compete for survival and reproduction (becoming a parent) in each iteration. The initial population may be generated randomly or guided by prior-knowledge, i.e., seeding the past successful architectures directly into the initial population. Subsequent to initialization, NSGANetV1 conducts the search in two sequential stages: (i) exploration, with the goal of discovering diverse ways to construct architectures, and (ii) exploitation that reinforces the emerging patterns commonly shared among the architectures successful during exploration. A set of architectures representing efficient tradeoffs between network performance and complexity is obtained at the end of evolution, through genetic operators and a Bayesian-model-based learning procedure. A flowchart and a pseudocode outlining the overall approach are shown in <ref type="figure" target="#fig_0">Fig. 1</ref> and Algorithm 1, respectively. In the remainder of this section, we provide a detailed description of the aforementioned components in Sections III-A -III-C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Search Space and Encoding</head><p>The search for optimal network architectures can be performed over many different search spaces. The generality of the chosen search space has a major influence on the quality of results that are even possible. Most existing evolutionary NAS approaches <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b31">[32]</ref> search only one aspect of the architecture space-e.g., the connections and/or hyper-parameters. In contrast, NSGANetV1 searches over both operations and connections-the search space is thus more comprehensive, including most of the previous successful architectures designed both by human experts and algorithmically.</p><p>Modern CNN architectures are often composed of an outer structure (network-level) design where the width (i.e., # of channels), the depth (i.e., # of layers) and the spatial resolution changes (i.e., locations of pooling layers) are decided; and an inner structure (block-level) design where the layer-wise connections and computations are specified, e.g., Inception block <ref type="bibr" target="#b0">[1]</ref>, ResNet block <ref type="bibr" target="#b1">[2]</ref>, and DenseNet block <ref type="bibr" target="#b2">[3]</ref>, etc. As seen in the CNN literature, the network-level decisions are mostly hand-tuned based on meta-heuristics from prior knowledge and the task at hand, as is the case in this work. For block-level design, we adopt the one used in <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b30">[31]</ref> to be consistent with previous work.</p><p>A block is a small convolutional module, typically repeated multiple times to form the entire neural network. To construct scalable architectures for images of different resolutions, we use two types of blocks to process intermediate information: <ref type="bibr" target="#b0">(1)</ref> the Normal block, a block type that returns information of the same spatial resolution; and (2) the Reduction block, another block type that returns information with spatial resolution halved by using a stride of two. See <ref type="figure" target="#fig_3">Fig. 2a</ref> for a pictorial illustration.</p><p>We use directed acyclic graphs (DAGs) consisting of five nodes to construct both types of blocks (a Reduction block uses a stride of two). Each node is a two-branched structure, mapping two inputs to one output. For each node in block i, we need to pick two inputs from among the output of the previous block h i−1 , the output of the previous-previous block h i−2 , and the set of hidden states created in any previous nodes of block i. For pairs of inputs chosen, we choose a computation operation from among the following options, collected based on their prevalence in the CNN literature:</p><p>• identity • 3x3 max pooling • 3x3 average pooling • squeeze-and-excitation <ref type="bibr" target="#b36">[37]</ref> • 3x3 local binary conv <ref type="bibr" target="#b5">[6]</ref> • 5x5 local binary conv <ref type="bibr" target="#b5">[6]</ref> • 3x3 dilated convolution</p><formula xml:id="formula_4">• 5x5 dilated convolution • 3x3 depthwise-separable conv • 5x5 depthwise-separable conv • 7x7 depthwise-separable conv • 1x7 then 7x1 convolution</formula><p>The results computed from both branches are then added together to create a new hidden state, which is available for subsequent nodes in the same block. See <ref type="figure" target="#fig_3">Fig. 2b-2d</ref> for pictorial illustrations. The search space we consider in this paper is an expanded version of the micro search space used in our previous work <ref type="bibr" target="#b19">[20]</ref>. Specifically, the current search space (i) search for a factor that gradually increments the channel size of each block with depth (see <ref type="figure" target="#fig_3">Fig. 2b</ref>) as opposed to sharply doubling the channel size when down-sampling. (ii) considers an expanded set of primitive operations to include both more recent advanced layer primitives such as squeeze-and-excitation <ref type="bibr" target="#b36">[37]</ref> and more parameter-efficient layer primitives like local binary convolution <ref type="bibr" target="#b5">[6]</ref>.</p><p>With the above-mentioned search space, there are in total 20 decisions to constitute a block structure-i.e., choose two pairs of input and operation for each node, and repeat for five nodes. The resulting number of combinations for a block structure is:</p><formula xml:id="formula_5">B = (n + 1)! 2 · (n_ops) 2n</formula><p>where n denotes the number of nodes, n_ops denotes the number of considered operations. Therefore, with one Normal block and one Reduction block with five nodes in each, the overall size of the encoded search space is approximately 10 33 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Performance Estimation Strategy</head><p>To guide NSGANetV1 towards finding more accurate and efficient architectures, we consider two metrics as objectives, namely, classification accuracy and architecture complexity. Assessing the classification accuracy of an architecture during search requires another optimization to first identify the optimal values of the associated weights via Stochastic Gradient Descent (SGD; Algorithm 2). Even though there exist wellestablished gradient descent algorithms to efficiently solve this optimization, repeatedly executing such an algorithm for every candidate architecture renders the overall process computationally very prohibitive. Therefore, to overcome this computational bottleneck, we carefully (using a series of ablation studies) down-scale the architectures to create their proxy models <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b16">[17]</ref>, which can be optimized efficiently in the lower-level through SGD. Their performances become surrogate measurements to select architectures during search. Details are provided in Section V-C.</p><p>A number of metrics can serve as proxies for complexity, including: the number of active nodes, number of active connections between the nodes, number of parameters, inference time and number of floating-point operations (FLOPs) needed to execute the forward pass of a given architecture. Our initial experiments considered each of these metrics in turn. We concluded from extensive experimentation that inference time cannot be estimated reliably due to differences and inconsistencies in the computing environment, GPU manufacturer, ambient temperature, etc. Similarly, the number of parameters, active connections or active nodes only relate to one aspect of the complexity. In contrast, we found an estimate of FLOPs to be a more accurate and reliable proxy for network complexity. Therefore, classification accuracy and FLOPs serve as our choice of twin objectives to be traded off for selecting architectures. To simultaneously compare and select architectures based on these two objectives, we use the non-dominated ranking and the "crowded-ness" concepts proposed in <ref type="bibr" target="#b28">[29]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Creation of New Generation</head><p>Exploration: Given a population of architectures, parents are selected from the population with a fitness bias. This choice is dictated by two observations, (1) offspring created around better parents are expected to have higher fitness on average than those created around worse parents, with the assumption of some level of gradualism in the solution space; (2) occasionally (although not usually), offspring perform better than their parents, through inheriting useful traits from both parents. Because of this, one might demand that the best architecture in the population should always be chosen as one of the parents. However, the deterministic and greedy nature of that approach would likely lead to premature convergence due to loss of diversity in the population <ref type="bibr" target="#b37">[38]</ref>. To address this problem, we use binary tournament selection <ref type="bibr" target="#b38">[39]</ref> to promote parent architectures in a stochastic fashion. At each iteration, binary tournament selection randomly picks two architectures from the population, then the one favored by the multi-objective selection criterion described in Section III-B becomes one of the parents. This process is repeated to select a second parent architecture; the two parent architectures then undergo a crossover operation.</p><formula xml:id="formula_6">!"#$ %&amp;'( )*+ #&amp;&amp;, *-- node 1 -.,$/ %&amp;'( *(0 #&amp;&amp;, *-- node 2 !"#$ %&amp;'( *(0 #&amp;&amp;, *-- node 5 ! ! -.,$/ %&amp;'( )*+ #&amp;&amp;, *-- node 1 .-"1 '2.23 !45" "+%. *-- node 2 -.,$/ %&amp;'( *(0 #&amp;&amp;, *-- node 5 ! ! exchange (Parent 1) (Parent 2)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fig. 3: Illustration of node-level crossover.</head><p>In NSGANetV1, we use two types of crossover (with equal probability of being chosen) to efficiently exchange substructures between two parent architectures. The first type is at the block level, in which the offspring architectures are created by recombining the Normal block from the first parent with the Reduction block from the other parent and vice versa. The second type is at the node level, where a node from one parent is randomly chosen and exchanged with another node at the same position from the other parent. We apply the node-level crossover to both Normal and Reduction blocks. <ref type="figure">Fig. 3</ref> illustrates an example of node-level crossover. Note that two offspring architectures are generated after each crossover operation, and only one of them (randomly chosen) is added to the offspring population. In each generation, an offspring population of the same size as the parent population is generated.  To enhance the diversity of the population and the ability to escape from local attractors, we use a discretized version of the polynomial mutation (PM) operator <ref type="bibr" target="#b39">[40]</ref> subsequent to crossover. We allow mutation to be applied on both the input hidden states and the choice of operations. <ref type="figure" target="#fig_5">Figure 4</ref> shows an example of each type of mutation using the parentcentric PM operator, in which the offspring are intentionally created around the parents in the decision space. In association with PM, we sort our discrete encoding of input hidden states chronologically and choice of operations in ascending order of computational complexity. In the context of neural architecture, this step results in the mutated input hidden states in offspring architectures to more likely be close to the input hidden states in parent architectures in a chronological manner. For example, h</p><formula xml:id="formula_7">!"#$% &amp;'() *+, -''# +!! node 3 ! "#$ ! "#% ! " &amp;'( !"#$% &amp;'() *+, -''# +!! node 3 ! "#$ ! " &amp;$( ! " &amp;'( mutate input node 3 !"#$% &amp;'() *+, -''# +!! ! "#$ ! "#% ! " &amp;'( !"#$% &amp;'() +). -''# +!! node 3 ! "#$ ! "#% ! " &amp;'( mutate operation</formula><p>(2) i is more likely to be mutated to h (1) i than to h i−2 by PM. A similar logic is applied in case of mutation on layer operations.</p><formula xml:id="formula_8">Sampling !"!#$ %&amp;'( )*" +&amp;&amp;, *-- ! " .-/' 0.01 *(2 +&amp;&amp;, *-- ! # 3"3$ %&amp;'( )*" +&amp;&amp;, *-- ! $ 4"5 5"4 !"! %&amp;'( *-- ! % &amp; &amp; 5"5$ %&amp;'( .-/' 0.01 *-- ! '</formula><p>All node structures explored:</p><formula xml:id="formula_9">Selection Sampling ! " #$% ! " #&amp;% ! " #'% ! " #(%</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>All architectures</head><p>Past successful architectures</p><formula xml:id="formula_10">A new architecture BN !"# ! " $ ! # ! # # ! " $ ! # ! $ # ! # &amp; # ! " $ ' Performance Estimation Arch ID ! ! "#$ ! ! "%$ ! ! "&amp;$ ! ! "'$ "##$% (%) &amp;'()* (M) + ,&amp; ,%( ,' ,# -- +./ . ,#) ,#) ,* ,#+ 0. 1// 1 ,#' ,, ,#% ,% -. .// 2 ,# ,%+ ,&amp; ,## -3 2./ 4 4 4 4 4 4 4 5 ,%' ,+ ,* ,#+ 0- 3// Arch ID ! ! "#$ " #$$%&amp; (%) '()*+ (M) , -% " .. ,/0 / -#&amp; " 1/ 200 3 3 3 3 3 4 -# "</formula><p>10 520 Exploitation: After a sufficient number of architectures has been explored (consuming 2/3 of the total computational budget; i.e., τ in Algorithm 1), we start to enhance the exploitation aspect of the search. The key idea is to reinforce and reuse the patterns commonly shared among past successful architectures. We use the Bayesian Network (BN) <ref type="bibr" target="#b40">[41]</ref> as the probabilistic model to estimate the distribution of the Pareto set (of architectures). In the context of our search space and encoding, this translates to learning the correlations among the operations and connections of nodes within a block. Our exploitation step uses a subset (top-100 architectures selected based on domination rank and crowding distance <ref type="bibr" target="#b28">[29]</ref>) of the past evaluated architectures to guide the final part of the search. More specifically, say we are designing a Normal block with three nodes, namely α</p><formula xml:id="formula_11">Arch ID ! ! "#$ ! ! "%$ ! ! "&amp;$ ! ! "'$ "##$% (%) &amp;'()* (M) + , - .( .#) .# .* - /</formula><formula xml:id="formula_12">(1) n , α<label>(2)</label></formula><p>n , and α</p><p>n . We would like to know the relationship among these three nodes. For this purpose, we construct a BN relating these variables, modeling the probability of Normal blocks beginning with a particular node α <ref type="bibr" target="#b0">(1)</ref> n , the probability that α <ref type="bibr" target="#b1">(2)</ref> n follows α <ref type="bibr" target="#b0">(1)</ref> n , and the probability that α     by using the population history, and update these estimates during the exploitation process. New offspring architectures are created by sampling from this BN. A pictorial illustration of this process is provided in <ref type="figure" target="#fig_7">Fig. 5</ref>. This BN-based exploitation strategy is used in addition to the genetic operators, where we initially (i.e., at the beginning of exploitation) assign 25% of the offspring (line 34 in Algorithm 1) to be created by BN and we update this probability adaptively (line 36 in Algorithm 1). To be more specific, we calculate the probabilities of using genetic operators and sampling from the BN model at generation t based on the survival rates of offspring created using them in the previous generation, following the softmax function:</p><formula xml:id="formula_14">ρ (i) t = exp(s (i) t−1 ) 2 i=1 exp(s (i) t−1 ) (2) where ρ (i) t</formula><p>are the probabilities of using genetic operators (i = 1) and sampling from the learned BN model (i = 2); and s (i) t−1 are the survival rates of the offspring created by genetic operators (i = 1) and the learned BN model (i = 2) at the previous generation t − 1. Note that ρ (i=1) t corresponds to ρ in Algorithm 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTAL SETUP AND RESULTS</head><p>In this section, we will evaluate the efficacy of NSGANetV1 on multiple benchmark image classification datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Baselines</head><p>To demonstrate the effectiveness of the proposed algorithm, we compare the non-dominated architectures achieved at the conclusion of NSGANetV1's evolution with architectures reported by various peer methods published in top-tier venues. The chosen peer methods can be broadly categorized into three groups: architectures manually designed by human experts, non-EA-(mainly RL or relaxation)-based, and EA-based. Human engineered architectures include ResNet <ref type="bibr" target="#b1">[2]</ref>, ResNeXt <ref type="bibr" target="#b41">[42]</ref>, and DenseNet <ref type="bibr" target="#b2">[3]</ref>, etc. The second and third groups range from earlier methods <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref> that are oriented towards "proofof-concept" for NAS, to more recent methods <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b42">[43]</ref>, many of which improve state-of-the-art results on various computer vision benchmarks at the time they were published. The effectiveness of the different architectures is judged on both classification accuracy and computational complexity. For comparison on classification accuracy, three widely used natural object classification benchmark datasets are considered, namely, CIFAR-10, CIFAR-100 and ImageNet. More details and a gallery of examples from these three datasets are provided in <ref type="figure" target="#fig_3">Fig. 2</ref> in supplementary materials under Section V.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Implementation Details</head><p>Motivated by efficiency and practicality considerations most existing NAS methods, including <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b43">[44]</ref>, carry out the search process on the CIFAR-10 dataset. However, as we demonstrate through ablation studies in Section V-C the CIFAR-100 provides a more reliable measure of an architecture's efficacy in comparison to CIFAR-10. Based on this observation, in contrast to existing approaches, we use the more challenging CIFAR-100 dataset for the search process. Furthermore, we split the original CIFAR-100 training set (80%-20%) to create a training and validation set to prevent over-fitting to the training set and improve the generalizability. We emphasize that the original testing set is never used to guide the selection of architectures in any form during the search. The search itself is repeated five times with different initial random seeds. We select and report the performance of the median run as measured by hypervolume (HV). Such a procedure ensures the reproducibility of our NAS experiments and mitigates the concerns that have arisen in recent NAS studies <ref type="bibr" target="#b44">[45]</ref>, <ref type="bibr" target="#b45">[46]</ref>. We use the standard SGD algorithm for learning the associated weights for each architecture. Other hyperparameter settings related to the search space, the gradient descent training and the search strategy are summarized in <ref type="table" target="#tab_1">Table I</ref>. We provide analysis aimed at justifying some of the hyper-parameter choices in Section V-C. All experiments are performed on 8 Nvidia 2080Ti GPU cards.</p><p>Our post-search training settings largely follow <ref type="bibr" target="#b8">[9]</ref>: We extend the number of epochs to 600 with a batch size of 96 to thoroughly re-train the selected models from scratch. We also incorporate a data pre-processing technique cutout <ref type="bibr" target="#b46">[47]</ref>, and a regularization technique scheduled path dropout introduced in <ref type="bibr" target="#b7">[8]</ref>. In addition, to further improve the training process, an auxiliary head classifier <ref type="bibr" target="#b0">[1]</ref> is appended to the architecture at approximately 2/3 depth (right after the second resolutionreduction operation). The loss from this auxiliary head classifier, scaled by a constant factor 0.4, is aggregated with the loss from the original architecture before back-propagation during training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Effectiveness of NSGANetV1</head><p>We first present the objective space distribution of all architectures generated by NSGANetV1 during the course of evolution on CIFAR-100, in <ref type="figure" target="#fig_15">Fig. 6a</ref>. We include architectures generated by the original NSGA-II algorithm and uniform random sampling as references for comparison. Details of these two methods are provided in Section IV-D. From the set of nondominated solutions (outlined by red box markers in <ref type="figure" target="#fig_15">Fig. 6a</ref>), we select five architectures based on the ratio of the gain on accuracy over the sacrifice on FLOPs. For reference purposes, we name these five architectures as NSGANetV1-A0 to -A4 in ascending FLOPs order. See <ref type="figure" target="#fig_0">Fig. 1</ref> in the supplementary materials for a visualization of the searched architectures.</p><p>For comparison with other peer methods, we follow the training procedure in <ref type="bibr" target="#b8">[9]</ref> and re-train the weights of NSGANetV1-A0 to -A4 on CIFAR-100, following the steps outlined in Section IV-B. We would like to mention that since most existing approaches do not report the number of FLOPs for the architectures used on the CIFAR-100 dataset, we instead compare their computational complexity through number of parameters to prevent potential discrepancies from re-implementation.   shows the post-search architecture comparisons, NSGANetV1-A0 to A4, i.e., the algorithms derived in this paper, jointly dominate all other considered peer methods with a clear margin. More specifically, NSGANetV1-A1 is more accurate than peer EA method, AE-CNN-E2EPP <ref type="bibr" target="#b18">[19]</ref>, while being 30x more efficient in network parameters; NSGANetV1-A2 achieves better performance than AmoebaNet <ref type="bibr" target="#b16">[17]</ref> and NSGA-Net <ref type="bibr" target="#b19">[20]</ref> with 3x fewer parameters. Furthermore, NSGANetV1-A4 exceeds the classification accuracy of Shake-Even 29 2x4x64d + SE <ref type="bibr" target="#b36">[37]</ref> using 8x fewer parameters. More comparisons can be found in <ref type="table" target="#tab_1">Table IIb</ref>. Following the practice adopted in most previous approaches <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b43">[44]</ref>, we measure the transferability of the obtained architectures by allowing the architectures evolved on one dataset (CIFAR-100 in this case) to be inherited and used on other datasets, by retraining the weights from scratch on the new dataset-in our case, on CIFAR-10 and ImageNet.</p><p>The effectiveness of NSGANetV1 is further validated by the transferred performance on the CIFAR-10 dataset. As we show in Figs. 7a, the trade-off frontier established by NSGANetV1-A0 to -A4 completely dominates the frontiers obtained by the peer EMO methods, both DPP-Net <ref type="bibr" target="#b29">[30]</ref> and LEMONADE <ref type="bibr" target="#b31">[32]</ref>, as well as those obtained with other single-objective peer methods. More specifically, NSGANetV1-A0 uses 27x fewer parameters and achieves higher classification accuracy than Large-scale Evo. <ref type="bibr" target="#b14">[15]</ref>. NSGANetV1-A1 outperforms Hierarchical NAS <ref type="bibr" target="#b15">[16]</ref> and DenseNet <ref type="bibr" target="#b2">[3]</ref> in classification, while saving 122x and 51x in parameters. NSGANetV1-A2 uses 4x less parameters to achieve similar performance as compared to NSGA-Net <ref type="bibr" target="#b19">[20]</ref>. Furthermore, NSGANetV1-A4 exceeds previous state-of-the-art results reported by Proxyless NAS <ref type="bibr" target="#b42">[43]</ref> while being 1.4x more compact. Refer to <ref type="table" target="#tab_1">Table IIa for  more comparisons.</ref> For transfer performance comparison on the ImageNet dataset, we follow previous work <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b43">[44]</ref> and use the ImageNet-mobile setting, i.e., the setting where number of FLOPs is less than 600M. The NSGANetV1-A0 is too simple for the ImageNet dataset and NSGANetV1-A4 exceeds the 600M FLOPs threshold for the mobile setting, so we provide results only for NSGANetV1-A1, -A2 and -A3. <ref type="figure" target="#fig_16">Fig. 7b</ref> compares the objective space with the other peer methods. Clearly, NSGANetV1 can achieve a better trade-off between the objectives. NSGANetV1-A2 dominates a wide range of peer methods including ShuffleNet <ref type="bibr" target="#b3">[4]</ref> by human experts, NASNet-A <ref type="bibr" target="#b7">[8]</ref> by RL, DARTS <ref type="bibr" target="#b8">[9]</ref> by relaxation-based methods, and AmoebaNet-A <ref type="bibr" target="#b16">[17]</ref> by EA. Moreover, NSGANetV1-A3 surpasses previous state-of-the-art performance reported by MobileNet-V2 <ref type="bibr" target="#b4">[5]</ref> and AmoebaNet-C [17] on mobile-setting with a marginal overhead in FLOPs (1% -3%).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Efficiency of NSGANetV1</head><p>Comparing the search phase contribution to the success of different NAS algorithms can be difficult and ambiguous due to substantial differences in search spaces and training procedures used during the search. Therefore, we use vanilla NSGA-II and uniform random sampling as comparisons to demonstrate the efficiency of the search phase in NSGANetV1. All three methods use the same search space and performance estimation strategy as described in Section III. The vanilla NSGA-II is implemented by discretizing the crossover and mutation operators in the original NSGA-II <ref type="bibr" target="#b28">[29]</ref> algorithm with all hyperparameters set to default values; and it does not utilize any additional enhancements-e.g., the Bayesian-Network-modelbased exploitation. The uniform random sampling method is implemented by replacing the crossover and mutation operators in the original NSGA-II algorithm with an initialization method that uniformly samples the search space. We run each of the three methods five times and record the 25-percentile, median and 75-percentile of the normalized HV (NHV) that we obtain. The NHV measurements shown in <ref type="figure" target="#fig_17">Fig. 8a</ref> suggest that NSGANetV1 is capable of finding more accurate and simpler architectures than vanilla NSGA-II or uniform random sampling (even with an extended search budget), in a more efficient manner.</p><p>Apart from the HV metric, another important aspect of demonstrating the efficiency of NAS is the computational complexity of the methods. Since theoretical analysis of the computational complexity of different NAS methods is challenging, we compare the computation time spent on Graphics   <ref type="bibr" target="#b43">[44]</ref> and DARTS <ref type="bibr" target="#b8">[9]</ref> are from <ref type="bibr" target="#b10">[11]</ref>. #Params for AE-CNN+E2EPP are from <ref type="bibr" target="#b17">[18]</ref>.</p><p>Processing Units (GPUs), GPU-Days, by each approach to arrive at the reported architectures. The number of GPU-Days is calculated by multiplying the number of employed GPU cards by the execution time (in units of days).</p><p>One run of NSGANetV1 on the CIFAR-100 dataset takes approximately 27 GPU-Days to finish, averaged over five runs. The search costs of most of the peer methods are measured on the CIFAR-10 dataset, except for Block-QNN <ref type="bibr" target="#b34">[35]</ref> which is measured on CIFAR-100. From the search cost comparison in <ref type="figure" target="#fig_17">Fig. 8b</ref>, we observe that our proposed algorithm is more efficient at identifying a set of architectures than a number of other approaches, and the set of architectures obtained has higher performance. More specifically, NSGANetV1 simultaneously finds multiple architectures while using 10x to 100x less GPU-days in searching than most of the considered peer methods, including Hierarchical NAS <ref type="bibr" target="#b15">[16]</ref>, AmoebaNet <ref type="bibr" target="#b16">[17]</ref>, NASNet <ref type="bibr" target="#b7">[8]</ref>, and Proxyless NAS <ref type="bibr" target="#b42">[43]</ref>, all of which find a single architecture at a time. When compared to the peer multi-objective NAS method, LEMONADE <ref type="bibr" target="#b31">[32]</ref>, NSGANetV1 manages to obtain a better (in the Pareto dominance sense) set of architectures than LEMONADE with 3x fewer GPU-Days. Further experiments and comparisons are provided in the supplementary materials under Section VII-A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Observations on Evolved Architectures</head><p>Population-based approaches with multiple conflicting objectives often lead to a set of diverse solution candidates, which can be "mined" for commonly shared design principles <ref type="bibr" target="#b49">[50]</ref>. In order to discover any patterns for more efficient architecture design, we analyzed the entire history of architectures generated by NSGANetV1. We make the following observations:</p><p>• Non-parametric operations-e.g., skip connections (identity) and average pooling (avg_pool_3x3)-are effective in trading off performance for complexity. Empirically, we notice that three out of the four most frequently used operations in non-dominated architectures are nonparametric, as shown in <ref type="figure" target="#fig_18">Fig. 9a</ref> (see also supplementary materials under Section VII-B for our follow-up study). • Larger kernel size and parallel operations improve classification accuracy, as shown in <ref type="figure" target="#fig_18">Fig. 9a</ref> and <ref type="figure" target="#fig_18">Fig. 9b</ref> respectively. In particular, the frequencies of convolutions with large kernel sizes (e.g., dil_conv_5x5, conv_7x1_1x7) are significantly higher in the top-20% most accurate architectures than in non-dominated architectures in general, which must also balance FLOPs. Similar findings are also reported in previous work <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b41">[42]</ref>. The above common properties of multiple final nondominated solutions stay as important knowledge for future applications. It is noteworthy that such a post-optimal knowledge extraction process is possible only from a multi-objective  optimization study, another benefit that we enjoy for posing NAS as a multi-objective optimization problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. FURTHER ANALYSIS</head><p>The overarching goal of NAS is to find architecture models that generalize to new instances of what the models were trained on. We usually quantify generalization by measuring the performance of a model on a held-out testing set. Since many computer vision benchmark datasets, including the three datasets used in this paper-i.e. CIFAR-10, CIFAR-100, and ImageNet, have been the focus of intense research for almost a decade, does the steady stream of promising empirical results from NAS simply arise from overfitting of these excessively re-used testing sets? Does advancement on these testing sets imply better robustness vis-a-vis commonly observable corruptions in images and adversarial images by which the human vision system is more robust? To answer these questions in a quantitative manner, in this section, we provide systematic studies on newly proposed testing sets from the CNN literature, followed by hyper-parameter analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Generalization</head><p>By mimicking the documented curation process of the original CIFAR-10 and ImageNet datasets, Recht et al. <ref type="bibr" target="#b50">[51]</ref> propose two new testing sets, CIFAR-10.1 and ImageNet-V2. Refer to supplementary materials under Section V-A for details and examples of the new testing sets. Representative architectures are selected from each of the main categories (i.e., RL, EA, relaxation-based, and manual). The selected architectures are similar in number of parameters or FLOPs, except DenseNet-BC <ref type="bibr" target="#b2">[3]</ref> and Inception-V1 <ref type="bibr" target="#b0">[1]</ref>. All architectures are trained on the original CIFAR-10 and ImageNet training sets as in Section IV-C, then evaluated on CIFAR-10.1 and ImageNet-V2, respectively.</p><p>It is evident from the results summarized in Figs. 10a and 10b that there is a significant drop in accuracy of 3% -7% on CIFAR-10.1 and 8% to 10% on ImageNet-V2 across architectures. However, the relative rank-order of accuracy on the original testing sets translates well to the new testing sets, i.e., the architecture with the highest accuracy on the original testing set (NSGANetV1 in this case) is also the architecture with the highest accuracy on new testing sets. Additionally, we observe that the accuracy gains on the original testing sets translate to larger gains on the new testing sets, especially in the case of CIFAR-10 (curvatures of red vs. blue markers in <ref type="figure" target="#fig_0">Fig. 10</ref>). These results provide evidence that extensive benchmarking on the original testing sets is an effective way to measure the progress of architectures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Robustness</head><p>The vulnerability to small changes in query images may very likely prevent the deployment of deep learning vision systems in safety-critical applications at scale. Understanding the architectural advancements under the scope of robustness against various forms of corruption is still in its infancy. Hendrycks and Dietterich <ref type="bibr" target="#b51">[52]</ref> recently introduced two new testing datasets, CIFAR-10-C and CIFAR-100-C, by applying commonly observable corruptions (e.g., noise, weather, compression, etc.) to the clean images from the original datasets. We use prediction accuracy on the corrupted test images (from each dataset) as a measurement of robustness.</p><p>Each dataset contains images perturbed by 19 different types of corruption at five different levels of severity. More details and visualizations are provided in supplementary materials under Section V-B. In addition, we include adversarial images as examples of worst-case corruption. We use the fast gradient signed method (FGSM) <ref type="bibr" target="#b52">[53]</ref> to construct adversarial examples for both the CIFAR-10 and -100 datasets. The severity of the attack is controlled via a hyper-parameter as shown below:</p><formula xml:id="formula_15">x = x + sign(∇ x L(x, y true )),</formula><p>where x is the original image, x is the adversarial image, y true is the true class label, and L is the cross-entropy loss. Following the previous section, we pick representative architectures of similar complexities from each of the main categories. Using the weights learned on the clean images from the original CIFAR-10/100 training sets, we evaluate each architecture's classification performance on the corrupted datasets as our measure of robustness. Our empirical findings summarized in Figs. 11a and 11b appear to suggest that a positive correlation exists between the generalization performance on clean data and data under commonly observable corruptions -i.e., we observe that NSGANetV1 architectures perform noticeably better than other peer methods' architectures on corrupted datasets even though the robustness measurement was never a part of the architecture selection process in NSGANetV1. However, we emphasize that no architectures are considered robust to corruption, especially under adversarial attacks. We observe that the architectural advancements have translated to minuscule improvements in robustness against adversarial examples. The classification accuracy of all selected architectures deteriorates drastically with minor increments in adversarial attack severity , leading to the question of whether architecture is the "right" ingredient to investigate in pursuit of adversarial robustness. A further step towards answering this question is provided in supplementary materials under Section V-C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Ablation Studies</head><p>Dataset for Search: As previously mentioned in Section III-B, our proposed method differs from most of the existing peer methods in the choice of datasets on which the search is carried out. Instead of directly following the current practice of using the CIFAR-10 dataset, we investigated the utility of search on multiple benchmark datasets in terms of their ability to provide reliable estimates of classification accuracy and generalization. We carefully selected four datasets, SVHN <ref type="bibr" target="#b53">[54]</ref>, fashionMNIST <ref type="bibr" target="#b54">[55]</ref>, CIFAR-10, and CIFAR-100 for comparison. The choice was based on a number of factors including the number of classes, numbers of training examples, resolutions and required training times. We uniformly sampled 40 architectures from the search space (described in Section III) along with five architectures generated by other peer NAS methods. We trained every architecture three times with different initial random seeds and report the averaged classification accuracy on each of the four datasets in <ref type="figure" target="#fig_0">Fig. 12a</ref>. Empirically, we observe that the CIFAR-100 dataset is challenging enough for architectural differences to affect predicted performance. This can be observed in <ref type="figure" target="#fig_0">Fig. 12a</ref> where the variation (blue boxes) in classification accuracy across architectures is noticeably larger on CIFAR-100 than on the other three datasets. In addition, we observe that mean differences in classification accuracy on CIFAR-100 between randomly generated architectures and architectures from principle-based methods have higher deviations, suggesting that it is less likely to find a good architecture on CIFAR-100 by chance.</p><p>Proxy Models: The main computational bottleneck of NAS approaches resides in evaluating the classification accuracy of the architectures by invoking the lower-level weight optimization. One such evaluation typically takes hours to finish, which limits the practical utility of the search under a constrained search budget. In our proposed algorithm, we adopt the concept of a proxy model <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b16">[17]</ref>. Proxy models are small-scale versions of the intended architectures, where the number of layers (N in <ref type="figure" target="#fig_3">Fig. 2a</ref>) and the number of channels (Ch init in <ref type="figure" target="#fig_3">Fig. 2a</ref>) in each layer are reduced. Due to the downscaling, proxy models typically require much less compute time to train † . However, there exists a trade-off between gains in computation efficiency and loss of prediction accuracy. Therefore, it is not necessary that the performance of an architecture measured at proxy-model scale can serve as a reliable indicator of the architecture's performance measured at the desired scale. † Small architecture size allows larger batch size to be used and a lower number of epochs to converge under Algorithm 2.     To determine the smallest proxy model that can provide a reliable estimate of performance at a larger scale, we conducted parametric studies that gradually reduced the sizes of the proxy models of 100 randomly sampled architectures from our search space. Then, we measured the rank-order correlation and the savings in lower-level optimization compute time between the proxy models and the same architectures at the full scale. <ref type="figure" target="#fig_0">Figures 12b, 12c and 12d</ref> show the effect of numbers of channels, layers and epochs, respectively, on the training time, and the Spearman rank-order correlation between the proxy and full scale models. We make the following observations, (1) increasing the number of channels does not significantly affect the wall clock time, and (2) reducing the number of layers or training epochs significantly reduces the wall clock time but also reduces the rank-order correlation. Based on these observations and the exact trade-offs from the plots, for our proxy model, we set the number of channels to 36 (maximum desired), number of epochs to 36, and number of layers to 14. Empirically, we found that this choice of parameters offers a good trade-off between practicality of search and reliability of proxy models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. AN APPLICATION TO CHEST X-RAY CLASSIFICATION</head><p>The ChestX-Ray14 benchmark was recently introduced in <ref type="bibr" target="#b55">[56]</ref>. The dataset contains 112,120 high resolution frontalview chest X-ray images from 30,805 patients, and each image is labeled with one or multiple common thorax diseases, or "Normal", otherwise. More details are provided in supplementary materials under Section V-C . Past approaches <ref type="bibr" target="#b55">[56]</ref>- <ref type="bibr" target="#b57">[58]</ref> typically extend from existing architectures, and the current state-of-the-art method <ref type="bibr" target="#b57">[58]</ref> uses a variant of the DenseNet <ref type="bibr" target="#b2">[3]</ref> architecture, which is designed manually by  human experts. For reference purpose, we call the obtained architecture NSGANetV1-X, and we re-train the weights thoroughly from scratch with an extended number of epochs. The learning rate is gradually reduced when the AUROC on the validation set plateaus. <ref type="table" target="#tab_1">Table III</ref> compares the performance of NSGANetV1-X with peer methods that are extended from existing manually designed architectures. This includes architectures used by the authors who originally introduced the ChestX-Ray14 dataset <ref type="bibr" target="#b55">[56]</ref>, and the CheXNet <ref type="bibr" target="#b57">[58]</ref>, which is the current state-of-theart on this dataset. We also include results from commercial AutoML systems, i.e., Google AutoML <ref type="bibr" target="#b58">[59]</ref>, and LEAF <ref type="bibr" target="#b59">[60]</ref>, as comparisons with NAS-based methods. The setup details of these two AutoML systems are available in <ref type="bibr" target="#b59">[60]</ref>. Noticeably, the performance of NSGANetV1-X exceeds Google AutoML's by a large margin of nearly 4 AUROC points. In addition, NSGANetV1-X matches the state-of-the-art results from human engineered CheXNet, while using 3.2x fewer parameters. For completeness, we also include the result from NSGANetV1-A3, which is evolved on CIFAR-100, to demonstrate the transfer learning capabilities of NSGANetV1.</p><p>More detailed results showing the disease-wise ROC curve of NSGANetV1-X and disease-wise AUROC comparison with other peer methods are provided in <ref type="figure" target="#fig_0">Figs. 13a and 13b</ref>, respectively. To understand the pattern behind the disease classification decisions of NSGANetV1-X, we visualize the class activation map (CAM) <ref type="bibr" target="#b60">[61]</ref>, which is commonly adopted for localizing the discriminative regions for image classification.</p><p>In the examples shown in <ref type="figure" target="#fig_0">Fig. 14a -14f</ref>, stronger CAM areas are covered with warmer colors. We also outline the bounding boxes provided by the ChestX-Ray14 dataset <ref type="bibr" target="#b55">[56]</ref> as references.</p><p>These results further validate the ability of our proposed algorithm to generate task-dependent architectures automatically. Conventional approaches, e.g., transfer learning from existing architectures, can be effective in yielding similar performance, however, as demonstrated by NSGANetV1, simultaneously considering complexity along with performance in an algorithmic fashion allows architectures to be practically deployed in resource-constrained environments. We observe this phenomenon in another application of NSGANetV1 to keypoint prediction on cars (see the supplementary materials under Section V-D).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. CONCLUSIONS</head><p>In this paper, we have presented NSGANetV1, an evolutionary multi-objective algorithm for neural architecture search. NSGANetV1 explores the design space of architectures through recombining and mutating architectural components. NSGANetV1 further improves the search efficiency by exploiting the patterns among the past successful architectures via distribution estimation through a Bayesian Network model. Experiments on CIFAR-10, CIFAR-100, and ImageNet datasets have demonstrated the effectiveness of NSGANetV1. Further analysis towards validating the generalization and robustness aspects of the obtained architectures is also provided along with an application to common thorax disease classification on human chest X-rays. We believe these results are encouraging and demonstrate the importance of customized and efficient evolutionary algorithms for neural architecture search in achieving superior performance compared to other contemporary machine learning methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX</head><p>In this supplementary document, we provide additional details on (1) related works in Section A; (2) multi-objective related issues in NAS in Section B; (3) bilevel optimization in Section C; (4) layer operations in Section D; (5) datasets in Section E; (6) implementation in Section F; <ref type="bibr" target="#b6">(7)</ref> other potential utilities of our proposed algorithm in Section G; (8) hypervolume in Section H.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Related Work Continued</head><p>Existing NAS approaches can be broadly classified into evolutionary algorithm (EA), reinforcement learning (RL), and relaxation-based approaches -with a few additional methods falling outside these categories. Reinforcement Learning (RL): Q-learning <ref type="bibr" target="#b61">[62]</ref> is a widelyused value iteration method used for RL. The MetaQNN method <ref type="bibr" target="#b48">[49]</ref> employs an -greedy Q-learning strategy with experience replay to search connections between convolution, pooling, and fully connected layers, and the operations carried out inside the layers. Zhong et al. <ref type="bibr" target="#b34">[35]</ref> extended this idea with the BlockQNN method. BlockQNN searches the design of a computational block with the same Q-learning approach. The block is then repeated to construct a network, resulting in a much more general network that achieves better results than its predecessor on CIFAR-10 <ref type="bibr" target="#b33">[34]</ref>. A policy gradient method seeks to approximate non-differentiable reward functions to train a model that requires parameter gradients, like a neural network architecture. Zoph and Le <ref type="bibr" target="#b6">[7]</ref> first apply this method in NAS to train a recurrent neural network controller that constructs networks. The original method in <ref type="bibr" target="#b6">[7]</ref> uses the controller to generate the entire network at once. This contrasts with its successor, NASNet <ref type="bibr" target="#b7">[8]</ref>, which designs a convolutional and pooling block that is repeated to construct a network. NASNet outperforms its predecessor and produces a network achieving state-of-the-art performance on CIFAR-10 and ImageNet. Relaxation-based Approaches and Others: Approximating the connectivity between different layers in CNN architectures by real-valued variables weighting the importance of each layer is the common principle of relaxation-based NAS methods. Liu et al. first implement this idea in the DARTS algorithm <ref type="bibr" target="#b8">[9]</ref>. DARTS seeks to improve search efficiency by fixing the weights while updating the architectures, showing convergence on both CIFAR-10 and Penn Treebank <ref type="bibr" target="#b62">[63]</ref> within one day in wall clock time on a single GPU card. Subsequent approaches in this line of research include <ref type="bibr" target="#b9">[10]</ref>- <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b63">[64]</ref>. The search efficiency of these approaches stems from weight sharing during the search process. This idea is complementary to our approach and can be incorporated into NSGANetV1 as well. However, it is beyond the scope of this paper and is a topic of future study.</p><p>Methods not covered by the EA-, RL-or relaxation-based paradigms have also shown success in architecture search. Liu et al. <ref type="bibr" target="#b30">[31]</ref> proposed a method that progressively expands networks from simple cells and only trains the best K networks that are predicted to be promising by a RNN meta-model of the encoding space. PPP-Net <ref type="bibr" target="#b64">[65]</ref> extended this idea to use a multi-objective approach, selecting the K networks based on their Pareto-optimality when compared to other networks. Li and Talwalkar <ref type="bibr" target="#b44">[45]</ref> show that an augmented random search approach is an effective alternative to NAS. Kandasamy et al. <ref type="bibr" target="#b65">[66]</ref> present a Gaussian-process-based approach to optimize network architectures, viewing the process through a Bayesian optimization lens.</p><p>Multi-obj NAS through Scalarization: A portfolio of works that aims to design hardware-specific network architectures emerges. This include, ProxylessNAS <ref type="bibr" target="#b42">[43]</ref>, MnasNet <ref type="bibr" target="#b66">[67]</ref>, FBNet <ref type="bibr" target="#b11">[12]</ref>, and MobileNetV3 <ref type="bibr" target="#b67">[68]</ref> which use a scalarized objective that encourages high accuracy and penalizes compute inefficiency at the same time, e.g., maximize Acc * (Latency/T arget) −0.07 . These methods require a pre-defined preference weighting of the importance of different objectives before the search, which in itself requires a number of trials.</p><p>Weight Sharing: Another recently proposed approach for improving the search efficiency of NAS is through weight sharing. Approaches in this category involve training a supernet that contains all searchable architectures as its subnets. They can be broadly classified into two categories depending on whether the supernet training is coupled with architecture search or decoupled into a two-stage process. Approaches of the former kind <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b42">[43]</ref>, <ref type="bibr" target="#b43">[44]</ref> are computationally efficient but return sub-optimal models. Numerous studies <ref type="bibr" target="#b44">[45]</ref>, <ref type="bibr" target="#b45">[46]</ref>, <ref type="bibr" target="#b68">[69]</ref> allude to weak correlation between performance at the search and final evaluation stages. Methods of the latter kind <ref type="bibr" target="#b69">[70]</ref>, <ref type="bibr" target="#b70">[71]</ref> use performance of subnets (obtained by sampling the trained supernet) as a metric to select architectures during search. However, training a supernet beforehand for each new task is computationally prohibitive.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Multi-objective Optimization in NAS</head><p>In addition to high predictive accuracy, real-world applications demand NAS algorithms to simultaneously balance a few other network complexity related objectives that are specific to the deployment scenarios. For instance, mobile or embedded devices often have restrictions in terms of model size, multiply-adds, latency, power consumption, and memory footprint.</p><p>It has been a common observation in the Deep Learning literature that classification performance is positively correlated with the complexity of the neural network. Since we want to maximize one (performance) while minimizing the other (FLOPS), they constitute a conflicting scenario. Optimization of a single composite objective obtained by weighting two objectives into one will produce a neural architecture and weight combination which may be too complex (requiring more FLOPS) or too inaccurate (having less accuracy). A generative approach of simply applying a single-obj optimization does not solve the issue: (i) many common scalarization methods do not work if the interesting optimal solutions lie on the non-convex part of the efficient frontier, and (ii) Generative methods are more computationally expensive (due to the lack of any parallel search efforts) than simultaneous methods, such as the method used in this paper.</p><p>In particular, ResNet <ref type="bibr" target="#b1">[2]</ref> showed the classification accuracy on ImageNet continuously to improve as the number of layers increases from 18 (2G FLOPs) to 152 (11G FLOPs). Similar trends are also observed in DenseNet <ref type="bibr" target="#b2">[3]</ref>, NASNet <ref type="bibr" target="#b7">[8]</ref>, EfficientNet <ref type="bibr" target="#b12">[13]</ref>, etc. The aforementioned observation implies the competing nature of these objectives of simultaneously maximizing classification performance and minimizing complexity in terms of FLOPs. Additionally, posing NAS as a multi-objective problem is beneficial from the decisionmaking perspective, as it allows designers to choose a suitable network architecture a posteriori as opposed to requiring a pre-defined preference weighting of each objective prior to the search. Empirically, we also observe that the type of diversity provided by multi-objective optimization contributes to its outperforming on the classification accuracy objective achieved relative to single-objective optimization. (This can be seen, for example, in comparing NSGANetV1-Ax from the main paper and NSGANetV1-Bx from Table V in this supplementary materials.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Bilevel Optimization in NAS</head><p>Recall that we formulate the problem of designing custom architectures for different deployment scenarios as a bilevel multi-objective NAS problem, mathematically as below:</p><formula xml:id="formula_16">minimize F (x) = f 1 (x; w * (x)), f 2 (x) T , subject to w * (x) ∈ argmin L(w; x), x ∈ Ω x , w ∈ Ω w ,<label>(3)</label></formula><p>The bilevel formulation used above arises from the problem nature of NAS, where one objective function f 1 evaluation at the upper-level requires both an architecture x and its weights w. f 1 is not meaningfully defined at any arbitrary w; rather, it requires w to be a member of the set that minimize the crossentropy loss L (in the case of image classification) on training data given x, mathematically as w * (x) ∈ argmin L(w; x). For simplicity, we use w * (x) to denote weights that satisfy the previously specified condition. However, w * (x) is typically not analytically computable due to non-linearities in layers and from activation functions in encoded by x, requiring another (lower) level of optimization.</p><p>The principle of a bilevel optimization is that the upperlevel objectives and constraints must be computed using the optimal lower level variables (w * (x)) for the corresponding upper-level variables (x). Thus, in an implicit manner, f 1 becomes a function of x alone, making f 1 (x; w * (x)). Using a (1, 1) evolution strategy search as an illustration, when x t+1 ← x t + ∆x is altered at iteration t in the upper-level, we first optimize the corresponding lower-level problem of L(w; x t+1 ) to find w * (x t+1 ) (through SGD). We then compute f 1 (x t+1 , w * (x t+1 )), and update the current</p><formula xml:id="formula_17">x t ← x t+1 if f 1 x t+1 , w * (x t+1 ) is better than f 1 x t , w * (x t ) , i.e., f 1 x t+1 , w * (x t+1 ) &lt; f 1 x t , w * (x t )</formula><p>. A bilevel problem allows a more convenient way to optimize a hierarchical problem having two distinct hierarchical variable sets (such as, a weight vector only makes sense when an architecture is provided) than a single level in which both x and w are considered in the same level. First, the search space becomes huge and second, a good x may be deleted simply because the respective w is not good.</p><p>Our NSGANetV1 algorithm has two types of optimization problems put together: 1) A bilevel optimization having a upper-level optimization problems in which architectures (x) are decision variables and a lower level problem in which weight vector (w) for the given architecture is the decision variable. 2) upper-level problem uses two conflicting objectives providing a Pareto-optimal front and the lower level problem uses a single objective of minimizing the crossentropy loss on the validation data.</p><p>Thus, the final outcome of our approach is a set of tradeoff architectures and their associated weight vectors, thereby completely specifying neural networks. For upper-level, we employ a customized and advanced NSGA-II-like evol. multiobjective algorithm, so that a set of non-dominated trade-off solutions is obtained at each iteration. The lower level uses the stochastic gradient based back-propagation algorithm for weight learning. Despite the fact that our approach also hybridizes a global search (EMO algorithm at the upper-level) and a local search (SGD) into a unified paradigm, which is also done in memetic algorithms, our bilevel approach is conceptually very different from memetic computing. To be more specific, the local search used in memetic algorithms is mainly to improve an individual's fitness within its local neighborhood, while the local search (SGD) used in our approach is to find the remaining set of variables (lower-level variables; weights), which jointly with the upper-level variables (architectures) compute the objective function (classification error).</p><p>Our bilevel approach is nested in nature, meaning that for each x at the upper-level, a respective optimized w * is found by using the back-propagation method. However, the NAS at the upper-level is expedited by using a Bayesian learning method of already found good solutions and by using customized coding and genetic operators. Although more sophisticated surrogateassisted bilevel algorithms, such as BLEAQ or BLEAQ2 <ref type="bibr" target="#b71">[72]</ref>, <ref type="bibr" target="#b72">[73]</ref> can be used, in this work we keep the methods relatively simple and use learning-assisted EMO and use only 1,200 architecture evaluations to achieve the results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Details of the Considered Layer Operations</head><p>As described in Section III-A, we form a operation pool consists of 12 different choices of convolution, pooling and etc., based on their prevalence in the CNN literature. Most of these operations can be directly called from standard Deep Learning libraries, like Pytorch, TensorFLow, Caffe, etc. Here we provide demo Pytorch codes for less commonly used ‡ operations, including depth-wise separable convolutions, local binary convolutions and 1x7 then 7x1 convolution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Datasets Details</head><p>Examples from CIFAR-10, CIFAR-100, and ImageNet are provided in <ref type="figure" target="#fig_0">Fig. 16</ref>.</p><p>1) CIFAR-10.1 and ImageNet-V2: In this work, we use the MatchedFrequency version of the ImageNet-V2 dataset. The curation details along with the discussion of the difference among the three versions are available in <ref type="bibr" target="#b50">[51]</ref>. Examples randomly sampled from these two new testing sets are provided in <ref type="figure" target="#fig_0">Figs. 17a and 17b</ref>, repectively. The CIFAR-10.1 is available for download at https://github.com/modestyachts/CIFAR-10.1. And the ImageNet-V2 is available at https://github.com/ modestyachts/ImageNetV2.</p><p>2) CIFAR-10-C and CIFAR-100-C: There are in total 19 different commonly observable corruption types considered in both CIFAR-10-C and CIFAR-100-C, including Gaussian noise, shot noise, impulse noise, de-focus blur, frosted glass blur, motion blur, zoom blur, snow, frost, fog, brightness, contrast, elastic, pixelate, jpeg, speckle noise, Gaussian blur, spatter and saturate. <ref type="figure" target="#fig_0">Fig. 18a</ref> provides examples for visualization. For every corruption type, there are five different levels of severity, see <ref type="figure" target="#fig_0">Fig. 18b</ref> for visualization. Both datasets are available from the original authors' GitHub page at https://github.com/hendrycks/robustness. A demo visualization of adversarial examples created by applying FGSM <ref type="bibr" target="#b52">[53]</ref> on MNIST dataset is provided in <ref type="figure" target="#fig_0">Fig. 18c</ref>.</p><p>3) ChestX-Ray14: ChestX-Ray 14 are hospital-scale Chest X-ray database containing 112,120 frontal-view X-ray images of size 1,024 x 1,024 pixels from 30,805 unique patients. The database is labeled using natural language processing techniques from the associated radiological reports stored in hospitals' Picture Archiving and Communication Systems (PACS). Each image can have one or multiple common thoracic diseases, or "Normal" otherwise. Visualization of example X-ray images from the database is provided in <ref type="figure" target="#fig_0">Fig. 19</ref>. The dataset is publicly available from NIH at https://nihcc.app.box.com/v/ChestXray-NIHCC. We follow the train_val_list.txt and test_list.txt provided along with the X-ray images to split the database for training, validation and testing. ‡ refer to both less frequently used operations and operations under less commonly followed setups. Examples of blocks that are designed manually by experts <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b4">[5]</ref> and from other peer methods <ref type="bibr" target="#b7">[8]</ref> are also included in (d) -(f) for comparison. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Implementation Details Continued</head><p>Evaluating a neural network architecture's performance is computationally expensive-e.g., one evaluation on the CIFAR-10 dataset takes more than 30 minutes. In general, our (GArelated) hyper-parameter choices represent the minimal number of function evaluations required to reproduce the claimed performance. To be more specific, in our proposed algorithm, each architecture is encoded with a 40-position, integer-valued string. Our choice of population size at 40 corresponds to one individual per variable dimension, which follows one of the common suggestions in the GA literature on minimal required population size. Empirically, we observed that the hypervolume stabilized by generation 30 (see <ref type="figure" target="#fig_18">Fig.9a</ref> in the revised main paper), hence, we chose to terminate the proposed algorithm at generation 30. Other hyper-parameter choices are discussed in Section V.C of the revised main paper. G. Follow-up Studies 1) Single-Objective NSGANetV1: Despite the superior effectiveness and efficiency of the proposed algorithm, the computation overheads of 27 GPU-days of NSGANetV1 can be infeasible for users with few GPU cards. Towards understanding of the overall search wall time limit of NSGANetV1, as well as comparison to the peer methods that use less GPU-days to execute the search, the following experiment has been performed. We minimized the search setup differences by dropping the second objective of minimizing FLOPs and changing the search dataset to CIFAR-10. We also reduce the population size by half and perform early-termination at one and four GPU-days. The obtained architectures are named as NSGANetV1-B0 and NSGANetV1-B1, respectively.   <ref type="bibr" target="#b55">[56]</ref>. <ref type="table" target="#tab_7">Table V</ref> confirm that our proposed algorithm can be more efficient in GPU-days than the other two EA-based peer methods, Genetic CNN <ref type="bibr" target="#b13">[14]</ref> and AE-CNN-E2EPP <ref type="bibr" target="#b18">[19]</ref>. Specifically, NSGANetV1 obtains the architecture B1 in 3 less GPU-days than AE-CNN-E2EPP, in addition to the B1 architecture being more accurate in CIFAR-10 classification and less complex in number of parameters. Due to the use of weight sharing that partially eliminates the back-propagation weight learning process, ENAS <ref type="bibr" target="#b43">[44]</ref> and DARTS <ref type="bibr" target="#b8">[9]</ref> are still more efficient in GPU-days than our proposed method. The weight sharing method could in principle be applied to NSGANetV1 as well, however this is beyond the scope of this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results in</head><p>2) Effectiveness of Non-learnable Operations: Our postoptimization analysis on the evolved architectures, shown in Section IV-E, has revealed some interesting findings, one of which being the effectiveness of non-parametric operations, e.g. identity mapping, average/max pooling, etc., in trading off classification performance for architectural complexity. To further validate this observation, we consider a expanded range of operations including both non-parametric and weight-fixed operations, which we name as non-learnable operations in this paper. We manually construct such layers by concatenate multiple non-learnable operations in parallel. The obtained results are shown in Figs. 20a -20c.</p><p>Our preliminary results on manual construction of nonlearnable layers are very encouraging. In additional to the comparative performance to regular fully learned layers, nonlearnable layers offer unique advantages in terms of re-usable weights for multi-tasking network architectures, as the weights are agnostic (not specifically learned on a particular task). We believe designing dedicated search algorithm to shape the construction of these non-learnable layers is a promising direction for NAS towards automatic design for multi-tasking architectures.</p><p>3) Robustness Against Adversarial Attacks: Based on our analysis in Section V-B, years of architectural advancements have translated to minuscule improvements in robustness against adversarial examples. Simple one-iteration attack strategy like FGSM <ref type="bibr" target="#b52">[53]</ref> is enough to constructing examples that turn many modern DNN classifiers to random-guess (see <ref type="figure" target="#fig_0">Fig.  12</ref> for examples). In this section, we make an effort to improve adversarial robustness from the architectural perspective. The search space used in the main paper searches over both layer operations and layer connections (see Section III-A). To isolate the effect of these two aspects to the adversarial robustness, we fix the layer operation to basic residual module <ref type="bibr" target="#b1">[2]</ref> and search over the connections among these modules to improve both classification accuracy on clean images and robustness against adversarial examples.</p><p>Designing a measure/objective for robustness against adversarial robustness is an area of active research (e.g., <ref type="bibr" target="#b73">[74]</ref>). For our purposes, we present a possible measure here, illustrated in <ref type="figure" target="#fig_0">Fig. 21</ref>. Using the FSGM presented by <ref type="bibr" target="#b52">[53]</ref>, this robustness objective progressively increases noise produced by FSGM. The axis in <ref type="figure" target="#fig_0">Fig. 21</ref> refers to the hyper-parameter in the FSGM equation, where x is the original image, x is adversarial image, y true is true class label, and L cross-entropy loss. Therefore, for this experiment, we seek to maximize two objectives, namely, classification accuracy and the robustness objective defined above.</p><formula xml:id="formula_18">x = x + sign(∇ x L(x, y true )),</formula><p>The setup for the robustness experiment is as follows. For training we use 40,000 CIFAR-10 images from the official CIFAR-10 training data, 10,000 of which are reserved for validation. Each network is encoded with three blocks using the macro space encoding from our previous work <ref type="bibr" target="#b19">[20]</ref>. In each phase a maximum of size nodes may be active-where the computation at each node is 3x3 convolution followed by ReLU and batch normalization. Each network is trained for 20 epochs with SGD on a cosine annealed learning rate  <ref type="bibr" target="#b52">[53]</ref> attack as follows: 1) obtain classification accuracy on adversarial images generated by FGSM as we vary , 2) compute the area under the curve (blue line), approximated by the area of the green region; 2) normalize the robustness value to the rectangular area formed by the Ideal point and Nadir point; 3) Ideal point is defined at 100% accuracy at pre-defined maximum value, and the nadir point is defined as the accuracy of random guessing at = 0 (clean images).</p><p>schedule. The epsilon values used in the FSGM robustness calculation are [0.0, 0.01, 0.03, 0.05, 0.07, 0.1, 0.15]. As before, NSGANetV1 initiates the search with 40 randomly created network architecture, and 40 new network architectures are created at each generation (iteration) via genetic operations (see main paper for details). The search is terminated at 30 generations. <ref type="figure" target="#fig_3">Fig. 22</ref>: Trade-off frontier of the robustness experiments. Color indicates the generation (iteration) at which a network architecture is eliminated from the surviving parent population. The size of each point is proportional to the network architecture's number of trainable parameters. We note that networks for latter generations form the Pareto front (dark blue points).</p><p>Empirically, we observe a clear trade-off between accuracy and robustness, as shown in <ref type="figure" target="#fig_3">Fig. 22</ref>. Visualization of the nondominated architectures are provided in <ref type="figure" target="#fig_3">Fig. 23c</ref>. In our opinion, NSGANetV1 is useful in capturing patterns that differentiate architectures that are good for competing objectives. We find that the "wide" networks (like ResNeXt <ref type="bibr" target="#b41">[42]</ref> or Inception blocks <ref type="bibr" target="#b0">[1]</ref>) appear to provide good accuracy on standard benchmark images, but are fragile to the FSGM attack. On the other hand, "deep" networks (akin to ResNet <ref type="bibr" target="#b1">[2]</ref> or VGG <ref type="bibr" target="#b74">[75]</ref>) are more robust to FSGM attack, while having less accuracy. This phenomenon is illustrated with examples in <ref type="figure" target="#fig_3">Figs. 23a and 23b</ref>, respectively. Furthermore, the skip connection of skipping the entire block's computation appears to be critical in obtaining a network that is robust to adversarial attacks; see <ref type="figure" target="#fig_3">Fig. 24a</ref> and 24b. 4) An Application to Multi-view Car Alignment: In addition to object classification, dense image prediction (e.g. object alignment, human body pose estimation and semantic segmentation, etc.) is another class of problems that is of great importance to computer vision. Dense image prediction assigns a class label to each pixel in the query images, as opposed to one label to the entire image in case of classification. In this section, we apply NSGANetV1 to the problem of multi-view car key-points alignment.</p><p>We use the CMU-Car dataset originally introduced in <ref type="bibr" target="#b75">[76]</ref>. The dataset contains around 10,000 car images in different orientations, environments, and occlusion situations. In this case, we search for the path of image resolution changes, similar to <ref type="bibr" target="#b63">[64]</ref>. The node-level structure is kept fixed, using the basic residual unit <ref type="bibr" target="#b1">[2]</ref>. The performance of architectures in this case is calculated using the root mean square (RMS) error between the predicted heatmap and ground truth for each key-point, more details are available in <ref type="bibr" target="#b75">[76]</ref>. We use FLOPs as the second objective for architecture complexity measurement. The obtained architectures are named as NSGANetV1-C0 and -C1. The obtained results are provided in <ref type="table" target="#tab_1">Table VI and</ref>    <ref type="figure" target="#fig_3">Fig. 25</ref>: Spatial-resolution-change path of the NSGANetV1-C0 architecture. Each circle encodes a residual module <ref type="bibr" target="#b1">[2]</ref>. Circles colored in white are always executed at the beginning. The arrows and blues circles are parts of the search decisions. The total number of layers (L) are set to be nine.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5) Ablation Study on Exploitation</head><p>Operator: Recall that we use Bayesian Network (BN) as a probabilistic model to estimate the distribution of the Pareto set (of architectures). In this section, we first explain the connection of our proposed BN-based distribution estimation operator to the existing works <ref type="bibr" target="#b77">[78]</ref>- <ref type="bibr" target="#b79">[80]</ref> of large-scale multi-objective optimization algorithms for general numerical problems. The common theme behind these works is to learn the correlation among decision variables to reduce the dimension either through grouping (optimize a subset of variables at a time) or embedding (projection to lower-dimensional space). In our work, we exploit the problem information (i.e., network architectures are variants of directed acyclic graphs) explicitly in the form of a BN to learn the correlations (i.e., BN edge weights) among architectural variables. The learned BN is then used (as a probabilistic model) to generate the remaining variables given the observed variables, as a form of dimension reduction. Thus, in this work, we take advantage of learning algorithms to capture the properties of good solutions to deal with the large dimensionality of the problem. In short, our approach in NAS application and general-purpose EMO algorithms shares a similar concept of dimensional reduction to handle large-scale problems.</p><p>Secondly, we study the effectiveness of the proposed BNbased exploitation operator. The experimental setup follows a two objective NAS optimization to maximize top-1 validation accuracy on the FashionMNIST dataset <ref type="bibr" target="#b54">[55]</ref> and minimize #FLOPs simultaneously. We study five different settings of the proposed exploitation operator, namely: 1) No exploitation 2) Exploitation activate after 1/3 computation budget spent.</p><p>3) Exploitation activate after 1/2 computation budget spent. 4) Exploitation activate after 2/3 computation budget spent. 5) Exploitation activate after 3/4 computation budget spent. We use the same population size of 40 and a maximum number of 30 generations for each of the considered settings. And we repeat 11 runs with different random seeds to capture the variance from different initial population. The obtained results are provided in <ref type="figure" target="#fig_3">Fig. 26</ref>. Empirically, we observe that our proposed exploitation operator provides a noticeable improvement to the overall algorithm's performance, measured by hypervolume. However, the margin of improvement quickly diminishes as we activate the operator too early (i.e. before 1/3 of the computation budget spent) or too close to the total budget (i.e. after 3/4 of the computation budget spent).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H. Hypervolume Calculation</head><p>For the two-objective experiments presented in Section IV of the main paper, the reference point used in computing the hypervolume metric is <ref type="figure" target="#fig_0">(100, 1, 000)</ref>, where 100 is the worst error rate in percentage, and 1, 000 is the highest #FLOPs, in millions, of any architecture that our search space can encode. We then normalize the hypervolume by the rectangular area formed by the reference point and the ideal point-i.e. (0, 0).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 :</head><label>1</label><figDesc>Overview: Given a dataset and objectives, NSGANetV1 designs a set of custom architectures spanning the trading-off front. NSGANetV1 estimate the performance of an architecture through its proxy model, optimized by Stochastic Gradient Descent (SGD) in the lower-level. The search proceeds in exploration via genetic operations, followed by exploitation via distribution estimation. See Algorithm 1 for pseudocode and colors are in correspondence.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>31 P 32 g 33 if g = τ then 34 ρ</head><label>31323334</label><figDesc>← Selection(P ∪ Q, [F 1 , F 2 , . . .], dist, K) ← g + 1; A ← A ∪ Q ← 0.75 // assign 25% of the offspring to be created by BN.<ref type="bibr" target="#b34">35</ref> else if g &gt; τ then<ref type="bibr" target="#b35">36</ref> update ρ according to Eq. (2).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>37 else 38 ρ</head><label>3738</label><figDesc>← 1 // remain unchanged from initial value. 39 end 40 end 41 Return parent population P .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 2 :</head><label>2</label><figDesc>Schematic of the NSGANetV1 search space motivated from [8]: (a) An architecture is composed of stacked blocks. (b)The number of channels in each block is gradually increased with depth of the network. (c) Each block is composed of five nodes, where each node is a two-branched computation applied to outputs from either previous blocks or previous nodes within the same block. (d) A graphical visualization of (c).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Algorithm 2 : 4 η ← 1 2 ηmax 1 + cos t T π ; 5 for each data-batch in Dtrn do 6 L← 7 ∇ω← 8 ω 9 end 10 t</head><label>245678910</label><figDesc>Performance Evaluation of a CNNInput: The architecture α, training data Dtrn, validation data D vld , number of epochs T , weight decay λ, initial learning rate ηmax. 1 ω ← Randomly initialize the weights in α; 2 t ← 0; 3 while t &lt; T do Cross-entropy loss on the data-batch; Compute the gradient by ∂L/∂ω; ← (1 − λ)ω − η∇ω; ← t + 1; 11 end 12 acc ← Compute accuracy of α(ω) on D vld ;<ref type="bibr" target="#b12">13</ref> Return the classification accuracy acc.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 4 :</head><label>4</label><figDesc>Input and Operation Mutation: Dashed line boxes with red color highlight the mutation. h i−2 and h i−1 are outputs from previous-previous and previous blocks, respectively. h</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>node 3 of the current block.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 5 :</head><label>5</label><figDesc>Illustrative example of BN-based exploitation step in NSGANetV1: given past successful architectures, we construct a BN relating the dependencies between the four nodes inside the Normal block. A new architecture is then sampled from this BN and proceeds forward for performance estimation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>other words, we estimate the conditional distributions p α</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head></head><label></label><figDesc>Fig. 6b</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head></head><label></label><figDesc>Number of FLOPs (Millions, log-scale) Top 1 accuracy (%) on validation set (a) During search (Millions, log-scale) Top 1 accuracy (%) (b) Post search</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Fig. 6 :</head><label>6</label><figDesc>(a) Accuracy vs. FLOPs of all architectures generated by NSGANetV1 during the course of evolution on CIFAR-100. A subset of non-dominated architectures (see text), named NSGANetV1-A0 to A4, are re-trained thoroughly and compared with other peer methods in (b).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Fig. 7 :</head><label>7</label><figDesc>Transferability of the NSGANetV1 architectures to (a) CIFAR-10, and (b) ImageNet. We compare Top-1 Accuracy vs. Computational Complexity. Architectures joined by dashed lines are from multi-objective algorithms.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Fig. 8 :</head><label>8</label><figDesc>Search efficiency comparison between NSGANetV1 and other baselines in terms of (a) HV, and (b) the required compute time in GPU-Days. The search cost is measured on CIFAR-10 for most methods, except NSGANetV1 and Block-QNN<ref type="bibr" target="#b34">[35]</ref>, where the CIFAR-100 dataset is used for.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Fig. 9 :</head><label>9</label><figDesc>channels to concatenation Validation accuracy (%) (b) Concatenation dimension vs. Accuracy Post-Search Analysis: (a) Frequency of each operation selected during the search. (b) Effect of number of input channels that are concatenation on the validation accuracy. More channels improve the predictive performance of the architectures, but adversely affect the computational efficiency.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>Fig. 11 :</head><label>11</label><figDesc>Robustness: Effect of commonly observable corruptions and adversarial attacks on (a) CIFAR-10, and (b) CIFAR-100. Higher values of indicate more severe adversarial attacks.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head></head><label></label><figDesc>Effect of dataset choice.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head></head><label></label><figDesc>Effect of proxy model's width.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head></head><label></label><figDesc>Effect of proxy model's depth.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><head></head><label></label><figDesc>Effect of training epochs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_24"><head>Fig. 12 :</head><label>12</label><figDesc>(a) Mean classification accuracy distribution of randomly generated architectures and architectures from peer NAS methods on four datasets. Correlation in performance (red lines) vs. Savings in gradient descent wall time (blue boxes) by reducing (b) the number of channels in layers, (c) the number of layers, and (d) the number of epochs to train. Note that (b), (c) and (d) have two y-axis labels corresponding to the color of the lines.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_25"><head>Fig. 13 :</head><label>13</label><figDesc>(a) NSGANetV1-X multi-label classification performance on ChestX-Ray14 and (b) the class-wise mean test AUROC comparison with peer methods.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_26"><head>Fig. 14 :</head><label>14</label><figDesc>Examples of class activation map<ref type="bibr" target="#b60">[61]</ref> of NSGANetV1-X, highlighting the class-specific discriminative regions. The ground truth bounding boxes are plotted over the heatmaps.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_27"><head>Fig. 15 :</head><label>15</label><figDesc>Visualization of block-level structures for different architectures. The Normal and Reduction blocks are shown in the first and second rows, respectively for NSGANetV1 architectures.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_28"><head>Fig. 16 :</head><label>16</label><figDesc>Examples from CIFAR-10, CIFAR-100 and ImageNet datasets. Images in each row belong to the same class with label names shown to the left.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_29"><head>Fig. 17 :</head><label>17</label><figDesc>Visualization of CIFAR-10.1 (a) and ImageNet-V2 (b). Examples are randomly sampled from the datsets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_30"><head>Fig. 21 :</head><label>21</label><figDesc>Robustness Objective: We define a robustness objective under the FGSM</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_31"><head>Fig. 23 :</head><label>23</label><figDesc>(a) Examples of the computational blocks discovered with high classification accuracy. For these networks, the mean accuracy and robustness objectives are 0.8543 and 0.0535, respectively; (b) Examples of the computational blocks discovered with high robustness against FGSM attack, the mean accuracy and robustness objectives are 0.8415 and 0.1036, respectively; (c) Examples of the computational blocks discovered along the pareto-front that provides an efficient tradeoff between classification accuracy and adversarial robustness. They are arranged in the order of descending accuracy and ascending robustness.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_32"><head>Fig. 24 :</head><label>24</label><figDesc>Parallel coordinate plots of the 1,200 network architectures sampled by NSGANetV1. Each line represents a network architecture, each vertical line is an attribute associated with the network. (a) Networks that have the skip connection bit inactive, we can see that none of them have good measurement on robustness against adversarial attacks. (b) Networks that have the skip connection bit active. This skip connection bit refers to the connection that goes past all computation within a phase, as a normal residual connection would. When the skip connection is active, the networks cover the full range of adversarial robustness.visualization of the architectures is provided inFig. 25.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_33"><head>N o E x p lo it a t io n A ft e r 1 / 3 F E b u d g e t A ft e r 1 / 2 F E b u d g e t A ft e r 2 / 3 F E b u d g e t A ft e r 3 / 4 FFig. 26 :</head><label>1312233426</label><figDesc>Ablation study on effectiveness of our proposed exploitation operator under different settings.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>an individual counter. BinaryTournamentSelection(P, [F 1 , F 2 , . . .], dist)</figDesc><table><row><cell>12</cell><cell>Q ← ∅ // offspring population.</cell></row><row><cell>13</cell><cell>while k &lt; K do</cell></row><row><cell>14</cell><cell>// one offspring is created in each iteration k.</cell></row><row><cell>15</cell><cell>if rand() &lt; ρ then</cell></row><row><cell>16</cell><cell>// choose two parents for mating.</cell></row><row><cell>18</cell><cell>q ← Crossover(p, pc)</cell></row><row><cell>19</cell><cell>q ← Mutation(q, pm)</cell></row><row><cell>20</cell><cell>else</cell></row><row><cell>21</cell><cell>// estimate the distribution of the Pareto set.</cell></row></table><note>17 p ←22 BN ← construct a Bayesian Network from A.23 q ← sample an offspring from BN .24 end 25</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE I :</head><label>I</label><figDesc>Summary of Hyper-parameter Settings.</figDesc><table><row><cell>Categories</cell><cell>Parameters</cell><cell>Settings</cell></row><row><cell></cell><cell># of initial channels (Chinit)</cell><cell>32</cell></row><row><cell>search space</cell><cell># of channel increments (Chinc)</cell><cell>6</cell></row><row><cell></cell><cell># of repetitions of Normal blocks (N )</cell><cell>4/5/6</cell></row><row><cell></cell><cell>batch size</cell><cell>128</cell></row><row><cell>gradient descent</cell><cell>weight decay (L2 regularization) epochs</cell><cell>5.00E-04 36/600</cell></row><row><cell></cell><cell>learning rate schedule</cell><cell>Cosine Annealing [48]</cell></row><row><cell></cell><cell>population size</cell><cell>40</cell></row><row><cell>search strategy</cell><cell># of generations crossover probability</cell><cell>30 0.9</cell></row><row><cell></cell><cell>mutation probability</cell><cell>0.1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE II :</head><label>II</label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">(b) CIFAR-100</cell></row><row><cell>Architecture</cell><cell>Search Method</cell><cell>GPU-Days</cell><cell cols="2">Top-1 Acc. #Params</cell><cell cols="2">Ratio-to-NSGANetV1</cell><cell>Architecture</cell><cell></cell><cell>Search Method</cell><cell>GPU-Days</cell><cell cols="2">Top-1 Acc. #Params</cell><cell>Ratio-to-NSGANetV1</cell></row><row><cell>NSGANetV1-A0</cell><cell>EA</cell><cell>27</cell><cell>95.33%</cell><cell>0.2M</cell><cell>1x</cell><cell></cell><cell>NSGANetV1-A0</cell><cell></cell><cell>EA</cell><cell>27</cell><cell>74.83%</cell><cell>0.2M</cell><cell>1x</cell></row><row><cell>CGP-CNN [24]</cell><cell>EA</cell><cell>27</cell><cell>94.02%</cell><cell>1.7M</cell><cell>8.5x</cell><cell></cell><cell>Genetic CNN [14]</cell><cell></cell><cell>EA</cell><cell>17</cell><cell>70.95%</cell><cell>-</cell><cell>-</cell></row><row><cell>Large-scale Evo. [15]</cell><cell>EA</cell><cell>2,750</cell><cell>94.60%</cell><cell>5.4M</cell><cell>27x</cell><cell></cell><cell>MetaQNN [49]</cell><cell></cell><cell>RL</cell><cell>90</cell><cell>72.86%</cell><cell>11.2M</cell><cell>56x</cell></row><row><cell>AE-CNN+E2EPP [19] ResNet [2]</cell><cell>EA manual</cell><cell>7 -</cell><cell>94.70% 95.39%</cell><cell>4.3M 1.7M</cell><cell>21x 8.5x</cell><cell></cell><cell cols="2">NSGANetV1-A1 Large-scale Evo. [15]</cell><cell>EA EA</cell><cell>27 2,750</cell><cell>80.77% 77.00%</cell><cell>0.7M 40.4M</cell><cell>1x 58x</cell></row><row><cell>NSGANetV1-A1</cell><cell>EA</cell><cell>27</cell><cell>96.51%</cell><cell>0.5M</cell><cell>1x</cell><cell></cell><cell>ResNet [2]</cell><cell></cell><cell>manual</cell><cell>-</cell><cell>77.90%</cell><cell>1.7M</cell><cell>2.4x</cell></row><row><cell>Hierarchical NAS [16]</cell><cell>EA</cell><cell>300</cell><cell>96.37%</cell><cell>61.3M</cell><cell>122x</cell><cell></cell><cell cols="2">AE-CNN+E2EPP [19]</cell><cell>EA</cell><cell>10</cell><cell>77.98%</cell><cell>20.9M</cell><cell>30x</cell></row><row><cell>PNAS [31]</cell><cell>SMBO</cell><cell>150</cell><cell>96.37%</cell><cell>3.2M</cell><cell>6.4x</cell><cell></cell><cell>NSGA-Net [20]</cell><cell></cell><cell>EA</cell><cell>8</cell><cell>79.26%</cell><cell>3.3M</cell><cell>4.7x</cell></row><row><cell>DenseNet [3]</cell><cell>manual</cell><cell>-</cell><cell>96.54%</cell><cell>25.6M</cell><cell>51x</cell><cell></cell><cell>CNN-GA [25]</cell><cell></cell><cell>EA</cell><cell>40</cell><cell>79.47%</cell><cell>4.1M</cell><cell>5.9x</cell></row><row><cell>NSGANetV1-A2 CNN-GA [25]</cell><cell>EA EA</cell><cell>27 35</cell><cell>97.35% 96.78%</cell><cell>0.9M 2.9M</cell><cell>1x 3.2x</cell><cell></cell><cell>PNAS [31] ENAS [44]</cell><cell></cell><cell>SMBO RL</cell><cell>150 0.5</cell><cell>80.47% 80.57%</cell><cell>3.2M 4.6M</cell><cell>4.6x 6.6x</cell></row><row><cell>AmoebaNet-A [17]</cell><cell>EA</cell><cell>3,150</cell><cell>96.88%</cell><cell>3.1M</cell><cell>3.4x</cell><cell></cell><cell>NSGANetV1-A2</cell><cell></cell><cell>EA</cell><cell>27</cell><cell>82.58%</cell><cell>0.9M</cell><cell>1x</cell></row><row><cell>DARTS [9]</cell><cell>relaxation</cell><cell>1</cell><cell>97.18%</cell><cell>3.4M</cell><cell>3.8x</cell><cell></cell><cell>AmoebaNet-A [17]</cell><cell></cell><cell>EA</cell><cell>3,150</cell><cell>81.07%</cell><cell>3.1M</cell><cell>3.4x</cell></row><row><cell>NSGA-Net [20]</cell><cell>EA</cell><cell>4</cell><cell>97.25%</cell><cell>3.3M</cell><cell>3.7x</cell><cell></cell><cell>GDAS [11]</cell><cell></cell><cell>relaxation</cell><cell>0.2</cell><cell>81.62%</cell><cell>3.4M</cell><cell>3.8x</cell></row><row><cell>NSGANetV1-A3</cell><cell>EA</cell><cell>27</cell><cell>97.78%</cell><cell>2.2M</cell><cell>1x</cell><cell></cell><cell>DARTS [9]</cell><cell></cell><cell>relaxation</cell><cell>1</cell><cell>82.46%</cell><cell>3.4M</cell><cell>3.8x</cell></row><row><cell>NASNet-A [8]</cell><cell>RL</cell><cell>1,575</cell><cell>97.35%</cell><cell>3.3M</cell><cell>1.5x</cell><cell></cell><cell>NSGANetV1-A3</cell><cell></cell><cell>EA</cell><cell>27</cell><cell>82.77%</cell><cell>2.2M</cell><cell>1x</cell></row><row><cell>LEMONADE [32]</cell><cell>EA</cell><cell>90</cell><cell>97.42%</cell><cell>13.1M</cell><cell>6.0x</cell><cell></cell><cell>NSGANetV1-A4</cell><cell></cell><cell>EA</cell><cell>27</cell><cell>85.62%</cell><cell>4.1M</cell><cell>1x</cell></row><row><cell>NSGANetV1-A4</cell><cell>EA</cell><cell>27</cell><cell>97.98%</cell><cell>4.0M</cell><cell>1x</cell><cell></cell><cell>DenseNet [3]</cell><cell></cell><cell>manual</cell><cell>-</cell><cell>82.82%</cell><cell>25.6M</cell><cell>6.2x</cell></row><row><cell>AmoebaNet-B [17]</cell><cell>EA</cell><cell>3,150</cell><cell>97.87%</cell><cell>34.9M</cell><cell>8.7x</cell><cell></cell><cell>SENet [37]</cell><cell></cell><cell>manual</cell><cell>-</cell><cell>84.59%</cell><cell>34.4M</cell><cell>8.4x</cell></row><row><cell>Proxyless NAS [43]</cell><cell>RL</cell><cell>1,500</cell><cell>97.92%</cell><cell>5.7 M</cell><cell>1.4x</cell><cell></cell><cell>Block-QNN [35]</cell><cell></cell><cell>RL</cell><cell>32</cell><cell>85.17%</cell><cell>33.3M</cell><cell>8.1x</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">(c) ImageNet</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Architecture</cell><cell cols="3">Search Method GPU-Days</cell><cell cols="3">Top-1 Acc. Top-5 Acc.</cell><cell cols="3">#Params Ratio-to-NSGANetV1</cell><cell>#FLOPs</cell><cell cols="2">Ratio-to-NSGANetV1</cell></row><row><cell>NSGANetV1-A1</cell><cell></cell><cell>EA</cell><cell>27</cell><cell cols="2">70.9%</cell><cell>90.0%</cell><cell>3.0M</cell><cell>1x</cell><cell></cell><cell>270M</cell><cell>1x</cell></row><row><cell>MobileNet-V2 [5]</cell><cell></cell><cell>manual</cell><cell>-</cell><cell cols="2">72.0%</cell><cell>91.0%</cell><cell>3.4M</cell><cell>1.1x</cell><cell></cell><cell>300M</cell><cell>1.1x</cell></row><row><cell>NSGANetV1-A2</cell><cell></cell><cell>EA</cell><cell>27</cell><cell cols="2">74.5%</cell><cell>92.0%</cell><cell>4.1M</cell><cell>1x</cell><cell></cell><cell>466M</cell><cell>1x</cell></row><row><cell>ShuffleNet [4]</cell><cell></cell><cell>manual</cell><cell>-</cell><cell cols="2">73.7%</cell><cell>-</cell><cell>5.4M</cell><cell>1.3x</cell><cell></cell><cell>524M</cell><cell>1.1x</cell></row><row><cell>NASNet-A [8]</cell><cell></cell><cell>RL</cell><cell>1,575</cell><cell cols="2">74.0%</cell><cell>91.3%</cell><cell>5.3M</cell><cell>1.3x</cell><cell></cell><cell>564M</cell><cell>1.2x</cell></row><row><cell>PNAS [31]</cell><cell></cell><cell>SMBO</cell><cell>150</cell><cell cols="2">74.2%</cell><cell>91.9%</cell><cell>5.1M</cell><cell>1.2x</cell><cell></cell><cell>588M</cell><cell>1.3x</cell></row><row><cell cols="2">AmoebaNet-A [17]</cell><cell>EA</cell><cell>3,150</cell><cell cols="2">74.5%</cell><cell>92.0%</cell><cell>5.1M</cell><cell>1.2x</cell><cell></cell><cell>555M</cell><cell>1.2x</cell></row><row><cell>DARTS [9]</cell><cell></cell><cell>relaxation</cell><cell>1</cell><cell cols="2">73.1%</cell><cell>91.0%</cell><cell>4.9M</cell><cell>1.2x</cell><cell></cell><cell>595M</cell><cell>1.3x</cell></row><row><cell>NSGANetV1-A3</cell><cell></cell><cell>EA</cell><cell>27</cell><cell cols="2">76.2%</cell><cell>93.0%</cell><cell>5.0M</cell><cell>1x</cell><cell></cell><cell>585M</cell><cell>1x</cell></row><row><cell cols="2">MobileNetV2 (1.4) [5]</cell><cell>manual</cell><cell>-</cell><cell cols="2">74.7%</cell><cell>92.5%</cell><cell>6.06M</cell><cell>1.2x</cell><cell></cell><cell>582M</cell><cell>1x</cell></row><row><cell cols="2">AmoebaNet-C [17]</cell><cell>EA</cell><cell>3,150</cell><cell cols="2">75.7%</cell><cell>92.4%</cell><cell>6.4M</cell><cell>1.3x</cell><cell></cell><cell>570M</cell><cell>1x</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>Comparison between NSGANetV1 and other baseline methods. NSGANetV1 architectures are obtained by searching on CIFAR-100. NSGANetV1 results on CIFAR-10 and ImageNet are obtained by re-training the weights with images from their respective datasets. Ratio-to-NSGANetV1 indicates the resulting savings on #Params and #FLOPs. The search cost is compared in GPU-days, calculated by multiplying the number of GPU cards deployed with the execution time in days.(a) CIFAR-10† SMBO stands for sequential model-based optimization. SENet is the abbreviation for Shake-Even 29 2x4x64d + SE.‡ The CIFAR-100 accuracy and #params for ENAS</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE III :</head><label>III</label><figDesc>AUROC on ChestX-Ray14 testing set. NSGANetV1-A3 represents results under the standard transfer learning setup.</figDesc><table><row><cell></cell><cell cols="2">Method</cell><cell></cell><cell></cell><cell>Type</cell><cell cols="4">#Params Test AUROC (%)</cell></row><row><cell></cell><cell cols="3">Wang et al. (2017) [56]</cell><cell cols="2">manual</cell><cell>-</cell><cell></cell><cell cols="2">73.8</cell></row><row><cell></cell><cell cols="3">Yao et al. (2017) [57]</cell><cell cols="2">manual</cell><cell>-</cell><cell></cell><cell cols="2">79.8</cell></row><row><cell></cell><cell cols="3">CheXNet (2017) [58]</cell><cell cols="2">manual</cell><cell>7.0M</cell><cell></cell><cell cols="2">84.4</cell></row><row><cell></cell><cell cols="4">Google AutoML (2018) [59]</cell><cell>RL</cell><cell>-</cell><cell></cell><cell cols="2">79.7</cell></row><row><cell></cell><cell cols="3">LEAF (2019) [60]</cell><cell></cell><cell>EA</cell><cell>-</cell><cell></cell><cell cols="2">84.3</cell></row><row><cell></cell><cell cols="3">NSGANetV1-A3</cell><cell></cell><cell>EA</cell><cell>5.0M</cell><cell></cell><cell cols="2">84.7</cell></row><row><cell></cell><cell cols="3">NSGANetV1-X</cell><cell></cell><cell>EA</cell><cell>2.2M</cell><cell></cell><cell cols="2">84.6</cell></row><row><cell></cell><cell cols="5">† Google AutoML result is from [60].</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>True Positive Rate</cell><cell>0.2 0.4 0.6 0.8 1  0 0</cell><cell>0.2</cell><cell>0.4 False Positive Rate 0.6</cell><cell>Atelectasis Cardiomegaly Effusion Infiltration Mass Nodule Pneumonia Pneumothorax Consolidation Edema Emphysema Fibrosis Pleural_Thickening 0.8 Hernia</cell><cell>1</cell><cell>Em ph yse ma He rni a Ca rdi om eg Ed em a Pn aly</cell><cell>eu mo tho rax Eff us ion Ma ss Fib ros</cell><cell>is Ate lec</cell><cell>tas is Co ns oli da tio n No du le Ple ura l_T hic ke nin g Pn eu mo nia Inf iltr ati on</cell></row><row><cell></cell><cell></cell><cell></cell><cell>(a)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>‡</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE IV :</head><label>IV</label><figDesc>Demo Pytorch implementation of separable convolution (a), local binary convolution (b) and 1x7 then 7x1 convolution (c) used in NSGANetV1. class SepConv(nn.Module) # depth-wise separable convolution in NSGANetV1 # consists of two regular depth-wise separable convolutions in series.</figDesc><table><row><cell>def __init__(self, C_in, C_out, kernel_size, stride, padding, affine=True)</cell></row><row><cell>super(SepConv, self).__init__()</cell></row><row><cell>self.op = nn.Sequential(</cell></row><row><cell>nn.ReLU(inplace=False),</cell></row><row><cell>nn.Conv2d(C_in, C_in, kernel_size=kernel_size, stride=stride,</cell></row><row><cell>padding=padding, groups=C_in, bias=False),</cell></row><row><cell>nn.Conv2d(C_in, C_in, kernel_size=1, padding=0, bias=False),</cell></row><row><cell>nn.BatchNorm2d(C_in, affine=affine),</cell></row><row><cell>nn.ReLU(inplace=False),</cell></row><row><cell>nn.Conv2d(C_in, C_in, kernel_size=kernel_size, stride=1,</cell></row><row><cell>padding=padding, groups=C_in, bias=False),</cell></row><row><cell>nn.Conv2d(C_in, C_out, kernel_size=1, padding=0, bias=False),</cell></row><row><cell>nn.BatchNorm2d(C_out, affine=affine),</cell></row><row><cell>)</cell></row><row><cell>def forward(self, x)</cell></row><row><cell>return self.op(x)</cell></row><row><cell>(a) Separable Convolution</cell></row><row><cell># The weight values of local binary convolution filters</cell></row><row><cell># either -1, 1, or 0, and kept fixed during back-propagation.</cell></row><row><cell># Number of 0-valued weights are controlled by sparsity argument.</cell></row><row><cell>def LBConv(in_planes, out_planes, kernel_size=3, stride=1,</cell></row><row><cell>padding=1, dilation=1, groups=1, bias=False, sparsity=0.5)</cell></row><row><cell>conv2d = nn.Conv2d(</cell></row><row><cell>in_planes, out_planes, kernel_size=kernel_size,</cell></row><row><cell>stride=stride, padding=padding, dilation=dilation,</cell></row><row><cell>groups=groups, bias=bias,</cell></row><row><cell>)</cell></row><row><cell>conv2d.weight.requires_grad = False</cell></row><row><cell>conv2d.weight.fill_(0.0)</cell></row><row><cell>num = conv2d.weight.numel()</cell></row><row><cell>shape = conv2d.weight.size()</cell></row><row><cell>index = torch.Tensor(math.floor(sparsity * num)).random_(num).int()</cell></row><row><cell>conv2d.weight.resize_(num)</cell></row><row><cell>for i in range(index.numel())</cell></row><row><cell>conv2d.weight[index[i]] = torch.bernoulli(torch.Tensor([0.5])) * 2 -1</cell></row><row><cell>conv2d.weight.resize_(shape)</cell></row><row><cell>return conv2d</cell></row><row><cell>(b) Local Binary Convolution</cell></row><row><cell>class Conv1x7Then7x1</cell></row><row><cell>def __init__(self, C, stride, affine=True)</cell></row><row><cell>super(Conv1x7Then7x1, self).__init__()</cell></row><row><cell>self.op = nn.Sequential(</cell></row><row><cell>nn.ReLU(inplace=False),</cell></row><row><cell>nn.Conv2d(C, C, (1, 7), stride=(1, stride), padding=(0, 3), bias=False),</cell></row><row><cell>nn.Conv2d(C, C, (7, 1), stride=(stride, 1), padding=(3, 0), bias=False),</cell></row><row><cell>nn.BatchNorm2d(C, affine=affine)</cell></row><row><cell>)</cell></row><row><cell>def forward(self, x)</cell></row><row><cell>return self.op(x)</cell></row><row><cell>(c) 1x7 convolution then 7x1 convolution</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE V :</head><label>V</label><figDesc>NSGANetV1 with single objective of maximizing classification accuracy on CIFAR-10 and early terminations.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>(a) Types of corruptions</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>(b) Severity of corruptions</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Eps: 0</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Eps: 0.15</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Eps: 0.3</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>(c) Adversarial examples from FGSM [53] on MNIST.</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Fig. 18: Visualization of different types of corruptions and</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>different levels of severity. Examples are from [52]. Both</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>CIFAR-10-C and CIFAR-100-C are constructed by applying</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>corruptions to the original testing sets. A demo visualization</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>of adversarial examples from FGSM on MNIST is shown in</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>(c).</cell></row><row><cell>Method</cell><cell>Type</cell><cell cols="3">#Params Top-1 Acc. GPU-Days</cell></row><row><cell>Genetic CNN [14]</cell><cell>EA</cell><cell>-</cell><cell>92.90%</cell><cell>17</cell></row><row><cell>AE-CNN+E2EPP [19]</cell><cell>EA</cell><cell>4.3M</cell><cell>94.70%</cell><cell>7</cell></row><row><cell>ENAS [44]</cell><cell>RL</cell><cell>4.6M</cell><cell>97.11%</cell><cell>0.5</cell></row><row><cell>DARTS [9]</cell><cell>differential</cell><cell>3.3M</cell><cell>97.24%</cell><cell>1</cell></row><row><cell>NSGANetV1-B0</cell><cell>EA</cell><cell>3.3M</cell><cell>96.15%</cell><cell>1</cell></row><row><cell>NSGANetV1-B1</cell><cell>EA</cell><cell>3.3M</cell><cell>97.25%</cell><cell>4</cell></row></table><note>Fig. 19: Visualization of ChestXray14 datasets. Examples showing eight common thoracic diseases are from</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>TABLE VI :</head><label>VI</label><figDesc>Preliminary results on the CMU-Car alignment<ref type="bibr" target="#b75">[76]</ref>. Notably, our proposed algorithm is able to find architectures with competitive performance while having 2x less parameters when compared to human-designed architecture<ref type="bibr" target="#b76">[77]</ref>.</figDesc><table><row><cell>Architectures</cell><cell cols="3">Params. FLOPs Regression</cell></row><row><cell></cell><cell>(M)</cell><cell>(M)</cell><cell>Error (%)</cell></row><row><cell>Hourglass[77]</cell><cell>3.38</cell><cell>3613</cell><cell>7.80</cell></row><row><cell>NSGANetV1-C0</cell><cell>1.53</cell><cell>2584</cell><cell>8.66</cell></row><row><cell>NSGANetV1-C1</cell><cell>1.61</cell><cell>2663</cell><cell>8.64</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>This material is based in part upon work supported by the National Science Foundation under Cooperative Agreement No. DBI-0939454. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Going deeper with convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Densely connected convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Shufflenet: An extremely efficient convolutional neural network for mobile devices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zhmoginov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-C</forename><surname>Chen</surname></persName>
		</author>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>MobileNetV2: Inverted residuals and linear bottlenecks</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Local binary convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Juefei-Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">N</forename><surname>Boddeti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Savvides</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Neural Architecture Search with Reinforcement Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Learning transferable architectures for scalable image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">DARTS: Differentiable architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">SNAS: stochastic neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Searching for a robust neural architecture in four GPU hours</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">FBNet: Hardware-aware efficient convnet design via differentiable neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vajda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Keutzer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Efficientnet: Rethinking model scaling for convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Genetic CNN</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Large-scale evolution of image classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Real</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Selle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Saxena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">L</forename><surname>Suematsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kurakin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Hierarchical representations for efficient architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fernando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Regularized evolution for image classifier architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Real</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Completely automated CNN architecture design based on blocks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">G</forename><surname>Yen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1242" to="1254" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Surrogateassisted evolutionary deep learning using an end-to-end random forestbased performance predictor</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">G</forename><surname>Yen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="350" to="364" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">NSGA-Net: Neural architecture search using multi-objective genetic algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Whalen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Boddeti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Dhebar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Banzhaf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Genetic and Evolutionary Computation Conference (GECCO)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Evolving artificial neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1423" to="1447" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Evolving neural networks through augmenting topologies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">O</forename><surname>Stanley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Miikkulainen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="99" to="127" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">ALPS: the age-layered population structure for reducing the problem of premature convergence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Hornby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Genetic and Evolutionary Computation Conference (GECCO)</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A genetic programming approach to designing convolutional neural network architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Suganuma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shirakawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Nagao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Genetic and Evolutionary Computation Conference (GECCO)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Automatically designing CNN architectures using the genetic algorithm for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">G</forename><surname>Yen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lv</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Cybernetics</title>
		<imprint>
			<biblScope unit="page" from="1" to="15" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Pareto-based multiobjective machine learning: An overview and case studies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sendhoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="397" to="415" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Multi-objective evolutionary federated learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1310" to="1322" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">NEMO: Neuro-evolution with multiobjective optimization of deep neural network for speed and accuracy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Seo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML) AutoML Workshop</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A fast and elitist multiobjective genetic algorithm: NSGA-II</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pratap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Meyarivan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="182" to="197" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">DPP-Net: Device-aware progressive search for pareto-optimal neural architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-D</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A.-C</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-C</forename><surname>Juan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Progressive neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Efficient multi-objective neural architecture search via lamarckian evolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Elsken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Metzen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Network morphism</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Rui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">W</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Citeseer, Tech. Rep</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Practical blockwise neural network architecture generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-L</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Multiobjective bilevel optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Eichfelder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical Programming</title>
		<imprint>
			<biblScope unit="volume">123</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="419" to="449" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Squeeze-and-excitation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Degree of population diversity-a perspective on premature convergence in genetic algorithms and its markov chain analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z.-B</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1165" to="1176" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Genetic algorithms, tournament selection, and the effects of noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">L</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">E</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Complex systems</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="193" to="212" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Simulated binary crossover for continuous search space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Complex systems</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="115" to="148" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">BOA: The bayesian optimization algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pelikan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">E</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Cantú-Paz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Genetic and Evolutionary Computation Conference (GECCO)</title>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Aggregated residual transformations for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">ProxylessNAS: Direct neural architecture search on target task and hardware</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Efficient neural architecture search via parameters sharing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Random search and reproducibility for neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Talwalkar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.07638</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Exploring randomly wired neural networks for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kirillov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1284" to="1293" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Improved regularization of convolutional neural networks with cutout</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Devries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">W</forename><surname>Taylor</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.04552</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Sgdr: Stochastic gradient descent with warm restarts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Designing neural network architectures using reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Naik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Raskar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Innovization: Innovating design principles through optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Srinivasan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Genetic and Evolutionary Computation Conference (GECCO)</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Recht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Roelofs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Shankar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.10811</idno>
		<title level="m">Do imagenet classifiers generalize to imagenet?</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Benchmarking neural network robustness to common corruptions and perturbations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Dietterich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Explaining and harnessing adversarial examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6572</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Reading digits in natural images with unsupervised feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Netzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bissacco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS) Workshop on Deep Learning and Unsupervised Feature Learning</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Fashion-MNIST: A novel image dataset for benchmarking machine learning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Rasul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vollgraf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.07747</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">ChestX-ray8: Hospital-scale chest x-ray database and benchmarks on weakly-supervised classification and localization of common thorax diseases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bagheri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Summers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Learning to diagnose from scratch by exploiting dependencies among labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Poblenz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dagunts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Covington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bernard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lyman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.10501</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Irvin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bagul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Langlotz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Shpanskaya</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.05225</idno>
		<title level="m">CheXNet: Radiologist-level pneumonia detection on chest x-rays with deep learning</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Automl for large scale image classification and object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">R</forename><surname>Blog</surname></persName>
		</author>
		<ptr target="https://research.googleblog.com/2017/11/automl-for-large-scaleimage.html" />
	</analytic>
	<monogr>
		<title level="j">Google Research</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Evolutionary neural automl for deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Meyerson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hodjat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mutch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Miikkulainen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Genetic and Evolutionary Computation Conference (GECCO)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Learning deep features for discriminative localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lapedriza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Learning from delayed rewards</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J C H</forename><surname>Watkins</surname></persName>
		</author>
		<ptr target="http://www.cs.rhul.ac.uk/~chrisw/new_thesis.pdf" />
		<imprint>
			<date type="published" when="1989-05" />
			<pubPlace>King&apos;s College, Cambridge, UK</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">The penn treebank: annotating predicate argument structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Marcinkiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Macintyre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bies</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ferguson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schasberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the workshop on Human Language Technology</title>
		<meeting>the workshop on Human Language Technology</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="1994" />
			<biblScope unit="page" from="114" to="119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Auto-deeplab: Hierarchical neural architecture search for semantic image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">PPP-Net: Platform-aware progressive search for pareto-optimal neural architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-D</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A.-C</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-C</forename><surname>Juan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Neural architecture search with bayesian optimisation and optimal transport</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kandasamy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Neiswanger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Poczos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Mnasnet: Platform-aware neural architecture search for mobile</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Searching for mobilenetv3</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Adam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Evaluating the search phase of neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sciuto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jaggi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Musat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Salzmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR</title>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">SMASH: One-shot model architecture search through hypernetworks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Brock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ritchie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Understanding and simplifying one-shot architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-J</forename><surname>Kindermans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Evolutionary bilevel optimization based on covariance matrix adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="258" to="272" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Evolutionary algorithm for bilevel optimization using approximations of the lower level optimal solution mapping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Malo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<ptr target="http://www.sciencedirect.com/science/article/pii/S0377221716306634" />
	</analytic>
	<monogr>
		<title level="j">European Journal of Operational Research</title>
		<imprint>
			<biblScope unit="volume">257</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="395" to="411" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Towards evaluating the robustness of neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wagner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Symposium on Security and Privacy (SP)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Very Deep Convolutional Networks for Large-scale Image Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Correlation filters for object alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Boddeti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Vijaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Stacked hourglass networks for human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Newell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">A study of multiobjective metaheuristics when solving parameter scalable problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Durillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Nebro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A C</forename><surname>Coello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Garcia-Nieto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Luna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Alba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="618" to="635" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">A framework for large-scale multiobjective optimization based on problem transformation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ishibuchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mostaghim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Nojima</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="260" to="275" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">A scalable indicator-based evolutionary algorithm for large-scale multiobjective optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ishibuchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="525" to="537" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
