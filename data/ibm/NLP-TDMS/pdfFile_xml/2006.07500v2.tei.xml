<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Domain Generalization using Causal Matching</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Divyat</forename><surname>Mahajan</surname></persName>
							<email>divyatmahajan@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Microsoft Research Bangalore</orgName>
								<address>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shruti</forename><surname>Tople</surname></persName>
							<email>shtople@microsoft.com</email>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft Research Cambridge</orgName>
								<address>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amit</forename><surname>Sharma</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Microsoft Research Bangalore</orgName>
								<address>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Domain Generalization using Causal Matching</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T12:18+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Learning invariant representations has been proposed as a key technique for addressing the domain generalization problem. However, the question of identifying the right conditions for invariance remains unanswered. In this work, we propose a causal interpretation of domain generalization that defines domains as interventions under a data-generating process. Based on a general causal model for data from multiple domains, we show that prior methods for learning an invariant representation optimize for an incorrect objective. We highlight an alternative condition: inputs across domains should have the same representation if they are derived from the same base object. Inputs that share the same base object may be available through data augmentation or in some specific contexts, but base object information is not always available. Hence we propose an iterative algorithm called MatchDG that approximates base object similarity by using a contrastive loss formulation adapted for multiple domains. We then match inputs that are similar under the resultant representation to build an invariant classifier. We evaluate our matching-based methods on rotated MNIST, Fashion-MNIST, PACS and Chest X-ray datasets and find that they outperform prior work on out-of-domain accuracy. In particular, top-10 matches from MatchDG have over 50% overlap with groundtruth matches in MNIST and Fashion-MNIST. Code repository can be accessed here:</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Machine learning models are often deployed in applications where the test (inference time) data distributions differ from their training dataset. For example, a model trained on data from one hospital is used for prediction at other hospitals or an image classification model is deployed on pictures with slightly different orientations. These applications require that a model generalizes well to new data distributions in addition to the training distribution, unlike standard machine learning tasks that focus on minimizing same-distribution error. One approach for generalizing to unseen domains is to learn representations that remain invariant across domains, by enforcing that their distributions stay the same across domains, either marginally <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b2">3]</ref> or conditional on the class label <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5]</ref>. Other methods frame invariance in terms of accuracy of the classifier on different domains <ref type="bibr" target="#b5">[6]</ref>. However, it is unclear how to evaluate these different invariance conditions for their applicability, e.g., under class imbalance or other differences between domains.</p><p>To this end, we introduce a formal causal framework for the domain generalization task that allows an easy and coherent characterization of the invariance conditions. Specifically, we construct a model for the data generation process that assumes each input is constructed from a mix of inherent (causal) and domain-dependent (non-causal) features. Building on prior work <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8]</ref>, we consider domain as a special intervention that changes the non-causal features of an input, and posit that an ideal classifier should be based only on the causal features. Using this model, we show that methods based on enforcing same distribution of representations across domains are inconsistent, confirming claims from past work <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b8">9]</ref>. Furthermore, we show that methods that enforce the same distribution conditional on class label are also insufficient, unless additional assumptions are made. The same causal model also provides us with the right condition that an invariant representation should satisfy. Our invariance condition depends on a special object variable that defines a collection of inputs that share the same causal features. For example, photos of the same person from different viewpoints correspond to a single object, and so do augmentations of an image in different rotations, color or background. We show that the correct invariance condition is that the learnt representation be the same for each object across domains. When the object variable is available (e.g., in self-collected data or by dataset augmentation), we propose a perfect-match regularizer for domain generalization that minimizes the distance between representations of the same object across domains.</p><p>In practice, however, the underlying objects are not always known or replicated across domains. We therefore propose an approximation of the above invariant condition that uses class labels as a proxy, under the assumption that inputs from the same class have more similar causal features than those from different classes. Our algorithm, MatchDG has two phases. First, it constructs a representation such that inputs sharing the same causal features are closer to one another, and matches pairs of inputs that are most similar. Second, it uses these learnt matches as a regularizer when building the classifier. In datasets with data augmentations, we extend MatchDG to also use the object matches obtained from pairs of original and augmented images (MatchDGHybrid).</p><p>We evaluate our matching-based methods on rotated MNIST and Fashion-MNIST, PACS and Chest Xray datasets. On all datasets, MatchDG and MatchDGHybrid outperform state-of-the-art methods for out-of-domain accuracy. On the rotated MNIST and Fashion-MNIST datasets where the ground-truth objects are known, MatchDG learns to makes the representation more similar to their ground-truth matches (about 50% overlap for top-10 matches), even though the method does not have access to them. Our superior results with simple matching methods show the importance of enforcing the correct invariance condition.</p><p>Contributions. To summarize, our contributions include:</p><p>• Invariance Condition. We propose an object-invariant condition for learning a common representation for domain generalization and justify its correctness compared to prior approaches. • MatchDG Algorithm. When object information is not available, we provide a novel twophase algorithm using contrastive loss formulation that learns a matching function between inputs and approximates object-based matches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">A Causal View of Domain Generalization</head><p>Consider a classification task where the learning algorithm has access to i.i.d. data from m domains, {(d i , x i , y i )} n i=1 ∼ (D m , X , Y) n where d i ∈ D m and D m ⊂ D is a set of m domains. Each training input (d, x, y) is sampled from an unknown distribution P m (D, X, Y ). The domain generalization task is to learn a single classifier that generalizes well to unseen domains d ∈ D m and to new data from the same domains <ref type="bibr" target="#b9">[10]</ref>. The optimum classifier can be written as: f * = arg min f ∈F E (d,x,y)∼P [l(y (d) , f (x (d) ))], where (d, x, y) ∼ P over (D, X , Y).</p><p>However, we only have access to D m domains during training. The plug-in estimator replaces P by P m following the Empirical Risk Minimization (ERM) principle.</p><formula xml:id="formula_0">f ERM = arg min f ∈FÊ S∼Pm [l(y (d) , f (x (d) ))]<label>(1)</label></formula><p>where S = (d, x, y) n is a training data of size n = d∈Dm n d . Proof for the next Proposition is in Suppl. A.3. Proposition 1. The ERM estimator from (1) learns the true f * , as the set of training domains D m = D and number of data samples n → ∞.</p><p>However, when D m ⊂ D, ERM can overfit to the training domains. To avoid overfitting, a popular technique is to learn a common feature representation across all training domains that can be subsequently used to train a classifier <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b11">12]</ref>. Due to a lack of formal definition of the problem, different learning objectives have been proposed, such as minimizing the distributional distance between learnt feature representations from different domains <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b2">3]</ref> or minimizing the distance between class-conditional feature representations <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b13">13]</ref>. We provide a causal framework that provides a correct invariant condition needed for domain generalization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Data-generating process</head><p>Consider a task of classifying the type of item or screening an image for a medical condition. To build a classifier, a train set is generated by taking photos. Due to human variability or by design (using data augmentation), the data generation process yields variety of images for each class, sometimes multiple images for the same object. In this example, the domain generalization task is to build a classifier that is robust to different views of any new object. <ref type="figure" target="#fig_1">Figure 1a</ref> shows a structural causal model (SCM) that describes the data-generating process. Here each view can be considered as a different domain D, the label for item type or medical condition as the class Y , and the image pixels as the features X. Photos of the same item or the same person correspond to a common object variable <ref type="bibr" target="#b7">[8]</ref>, denoted by O. To create an image, the data-generating process first samples an object and view (domain) that may be correlated to each other (shown with dashed arrows). The pixels in the photo are caused by both the object and the view, as shown by the two incoming arrows to X. The object also corresponds to high-level causal features X C that are common to any image of the same object, which in turn are used by humans to label the class Y .  dashed arrows denote correlated nodes. Object has a dotted outline since it may not be observed.</p><p>The above example is typical of a domain generalization problem; a general SCM is shown in <ref type="figure" target="#fig_1">Figure 1b</ref>. In general, the underlying object for each input x (d) i may not be observed. Analogous to the causal features X C , we introduce a node for domain-dependent high-level features of the object X A . Changing the domain can be seen as an intervention: for each observed x where d = d , such that all correspond to the same object (and thus share the same X C ). For completeness, we also show the true unobserved label of the object which led to its generation as Y true (additional motivation for the causal graph is in Suppl. A.1). Like the object O, Y may be correlated with the domain D. Extending the model in <ref type="bibr" target="#b7">[8]</ref>, we allow that objects can be correlated with the domain conditioned on Y true . As we shall see, considering the relationship of the Object node becomes the key piece for developing the invariant condition. We can write the following non-parametric equations corresponding to the SCM.</p><formula xml:id="formula_1">o := g o (y true , o ) x c = g xc (o) x a := g xa (d, o, xa ) x := g x (x c , x a , x )y := h(x c , y )</formula><p>where g o , g xc , g xa , g x and h are general non-parametric functions. The error o is correlated with domain d whereas xa , x and y are mutually independent error terms that are independent of all other variables. Thus, noise in the class label is independent of domain. Since x c is common to all inputs of the same object, g xc is a deterministic function of o. In addition to these equations, the SCM provides conditional-independence conditions that all data distributions P must satisfy, through the concept of d-separation A.2 and the perfect map assumption <ref type="bibr" target="#b14">[14]</ref>.</p><p>Definition 1. d-separation <ref type="bibr" target="#b14">[14]</ref>: Let A,B,C be the three non-intersecting subsets of nodes in a causal graph G. For any path between two nodes, a collider is a node where arrows of the path meet head-to-head. A path from A to B is said to be blocked by C if either a non-collider on the path is in C, or there is a collider on the path and neither the collider nor its descendants are in C.</p><p>If all paths from A to B are blocked, then A is d-separated from B by C: dsep(A, B, C) ⇒ A ⊥ ⊥ B|C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Identifying the invariance condition</head><p>From <ref type="figure" target="#fig_1">Figure 1b</ref>, X C is the node that causes Y . Further, by d-separation, the class label is independent of domain conditioned on X C , Y ⊥ ⊥ D|X C . Thus our goal is to learn y as h(x c ) where h : C → Y. The ideal loss-minimizing function f * can be rewritten as (assuming x c is known):</p><formula xml:id="formula_2">arg min f E (d,x,y) l(y, f (x)) = arg min h E[l(y, h(x c ))]<label>(2)</label></formula><p>Since X C is unobserved, this implies that we need to learn it too through a representation function Φ : X → C. Together, h(Φ(x)) leads to the desired classifer f : X → Y.</p><p>Conditional independencies from the SCM identify the correct learning goal for learning X C . By the d-separation criterion, we see that X C satisfies two conditions:</p><formula xml:id="formula_3">1) X C ⊥ ⊥ D|O, 2) X C ⊥ ⊥ O;</formula><p>where O refers to the object variable and D refers to a domain. The first is an invariance condition: X C does not change with different domains for the same object. To enforce this, we stipulate that the average pairwise distance between Φ(x) for inputs across domains for the same object is 0,</p><formula xml:id="formula_4">Ω(j,k)=1;d =d dist(Φ(x (d) j ), Φ(x (d ) k )) = 0.</formula><p>Here Ω : X × X → {0, 1} is a matching function that is 1 for pairs of inputs across domains corresponding to the same object, and 0 otherwise. However, just the above invariance will not work: we need the representation to be informative of the object O too (otherwise even a constant Φ minimizes the above loss). Therefore, the second condition stipulates that X C should be informative of the object, and hence about Y . We add the standard classification loss, leading to constrained optimization, k )) = 0 contains the optimal Φ(x) = X C that minimizes the domain generalization loss in (2). 2. Assuming that P (X a |O, D) &lt; 1 for every high-level feature X a that is directly caused by domain, and for P-admissible loss functions <ref type="bibr" target="#b15">[15]</ref> whose minimization is conditional expectation (e.g., 2 or cross-entropy), a loss-minimizing classifier for the following loss is the true function f * , for some value of λ.</p><formula xml:id="formula_5">f perfectmatch = arg min h,Φ m d=1 L d (h(Φ(X)), Y ) s.t. Ω(j,k)=1;d =d dist(Φ(x (d) j ), Φ(x (d ) k )) = 0 (3) where L d (h(Φ(X), Y )) = n d i=1 l(h(Φ(x (d) i ), y (d) i ). Here f represents the composition h • Φ.</formula><formula xml:id="formula_6">f perfectmatch = arg min h,Φ m d=1 L d (h(Φ(X)), Y ) + λ Ω(j,k)=1;d =d dist(Φ(x (d) j ), Φ(x (d ) k )) (4)</formula><p>While Theorem 1 shows the consistency of the PerfectMatch condition, it does not identify X C uniquely since there can be multiple X C (e.g., linear transformations) that satisfy the condition and are equally good for the predictive task. Identification of causal features is a non-trivial problem <ref type="bibr" target="#b16">[16]</ref>, especially when features are latent, that we leave for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Past work: Learning common representation</head><p>Using our model, we now compare the proposed invariance condition to three main representation learning objectives: domain-invariant, class-conditional domain-invariant, and invariant-optimalclassifier representations.</p><p>Domain-invariant representations. The goal is to learn a representation Φ such that its distribution P (Φ(x)) is the same across domains <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b2">3]</ref>, assuming that the ideal representation (X C ) is independent of domain. However, using d-separation on the SCM from <ref type="figure" target="#fig_1">Figure 1b</ref>, Y ⊥ ⊥ D is not sufficient since O blocks the path between X C and D. While <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b17">17]</ref> argue that this condition fails when Y is correlated with D, our analysis shows that domain-invariant methods require a stronger condition that both class label and actual objects sampled be independent of domain.</p><p>Class-conditional domain-invariant Φ. As a better objective, class-conditional methods by <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b13">13,</ref><ref type="bibr" target="#b6">7]</ref> aim to obtain representations such that P (Φ(x (d) )|Y ) is the same across domains, through minimizing distribution divergence measures. However, even in the ideal case where we observe Y true , d-separation on the SCM reveals that X C ⊥ ⊥ D|Y true due to a path through O. Thus, having the same distribution per class is not consistent with properties of X C .</p><p>The above discussion indicates that prior representation learning methods optimize an incorrect objective: even with infinite data across domains, they will not learn the true X C . We state it formally as a corollary with its proof in the section A.5. Corollary 1. The conditions enforced by domain-invariant (Φ(x) ⊥ ⊥ D) or class-conditional domaininvariant (Φ(x) ⊥ ⊥ D|Y ) methods are not satisfied by the causal representation X C . Thus, without additional assumptions, the set of representations that satisfy any of these conditions does not contain X C , even as n → ∞. Invariant-optimal-classifier Φ. Recently, <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b18">18]</ref> assume that P (Y |X C ) remains the same across domains and thus a single classifier over the optimal Φ(x) should be optimal for all domains. That is, Y ⊥ ⊥ D|Φ(x) which is also satisfied by X C in the SCM. However, enforcing this condition is difficult in practice and thus the resultant method is restricted to a linear classifier over Φ. To this end, we propose a simple condition that supports any architecture and is consistent with the SCM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">MatchDG: Proposed algorithm</head><p>When object information is available, Eq. (4) provides a loss objective to build a classifer using causal features. However, object information is not always available, and in many datasets there may not be a perfect "counterfactual" match based on same object across domains. Therefore, we provide an invariance condition using only (X, Y ) that is consistent with the conditional independencies of X C and propose a two-phase contrastive learning method to learn such an X C .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Match loss consistent with properties of X C</head><p>The object-invariant condition from Section 2.2 can be interpreted as matching pairs of inputs from different domains that share the same X C . To approximate it, our goal is to learn a matching Ω : X × X → {0, 1} such that pairs having Ω(x, x ) = 1 have low difference in x c and x c . One simple way is to use the class label and match every input to a random input from the same class. Assuming X C of inputs from the same class is bounded by δ, we show that this simple matching strategy does include X C as a possible solution. We obtain the following random match regularizer.</p><formula xml:id="formula_7">f randommatch = arg min h,Φ m d=1 L d (h(Φ(X)), Y ) + λ Ω Y (j,k)=1;d =d dist(Φ(x (d) j ), Φ(x (d ) k )) (5)</formula><p>where Ω Y randomly matches pairs from the same class. a,k ) ≥ δ a where x a is any high-level feature that is caused directly by domain. Further, assume that the distance over X C between same-class inputs from different domains is bounded:</p><formula xml:id="formula_8">dist(x (d) c,j , x (d ) c,k ) ≤ δ c and δ c &lt; δ a (δ c , δ a ∈ R + )</formula><p>. Then for some λ, a loss-minimizing classifier for the loss from (5) is the true function f * , given a P-admissible loss function and a finite number of domains m with n d → ∞ in each domain.</p><p>The proof substitutes X C in the match condition and uses Lagrange multipliers, detailed in Suppl. A.6. Compared to class-conditional domain-invariant condition, a key distinction is that we enforce the difference in individual representations for same-class inputs to be low, not just to have the same distribution. That is, we minimize the variance of the class-conditional distribution. A variation of this loss is used as a contrastive regularizer in <ref type="bibr" target="#b19">[19,</ref><ref type="bibr" target="#b20">20]</ref>. However, Theorem 2 cannot guarantee that X C will be returned by the optimization. The key parameter is δ c . If a dataset has low δ c , then there is a high chance of learning a good representation that is close to X C (if δ c = 0, we obtain perfect match). But as δ c increases, the matching condition loses any discriminative power. Hence we need to learn a matching Ω such that δ c is minimized. for batch ∼ M do 7:</p><p>Minimize contrastive loss <ref type="bibr" target="#b5">(6)</ref>. 8:</p><p>if epoch % t == 0 then 9:</p><p>Update match pairs using Φ epoch . 10: Compute matching based on Φ.</p><p>Phase 2. 11: Minimize the loss (5) to obtain f .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Two-phase method with learnt matches</head><p>To learn such a Ω, we use unsupervised contrastive learning from <ref type="bibr" target="#b21">[21,</ref><ref type="bibr" target="#b22">22]</ref> and adapt it to domain generalization in our MatchDG algorithm. MatchDG relies on the property that two inputs from the same class have more similar causal features than inputs from different classes. We optimize a contrastive representation learning loss that minimizes distance between same-class inputs from different domains in comparison to inputs from different classes across domains. This technique is likely to have lower δ c than a simple class-based random match. Adapting the contrastive loss for a single domain <ref type="bibr" target="#b21">[21]</ref>, we consider positive matches as two inputs with the same class but different domains, and negative matches as pairs with different classes. For every positive match pair (x j , x k ), we propose a loss where τ is a hyperparameter, B is the batch size, and sim(a, b)</p><formula xml:id="formula_9">= Φ(x a ) T Φ(x b )/ Φ(x a ) Φ(x b ) is the cosine similarity. l(x j , x k ) = − log e sim(j,k)/τ e sim(j,k)/τ + B i=0,yi =yj e sim(j,i)/τ<label>(6)</label></formula><p>Our key insight is to update matches during training. Instead of using the standard contrastive loss where matches are pre-decided, we start training with a random match based on classes. After every t epochs, we update the matches based on nearest same-class pairs in representation space, and iterate until convergence. Under assumption that inputs of same class are closer in causal features, optimizing for the initial random matches should lead to a representation wherein similarity correlates more to similarity in causal features. This completes Phase I of the algorithm. In Phase 2, we utilize the final representation to compute a new match function based on closest same-class pairs and then apply <ref type="bibr" target="#b4">(5)</ref> to obtain a classifier regularized on those matches. In Suppl. C.6, we compare the gains due to the proposed iterative matching versus standard contrastive training.</p><p>To implement MatchDG we build a p × q data matrix containing q − 1 positive matches for each input and then sample mini-batches from this matrix. The last layer of the contrastive loss network is considered as the learnt representation. Algorithm 1 provides an overview; details are in Suppl. B.1. We implement MatchDG as a 2-phase method, unlike previous methods <ref type="bibr" target="#b19">[19,</ref><ref type="bibr" target="#b20">20]</ref> that employed classbased contrastive loss as a regularizer with ERM. This is to avoid the classification loss interfering with the goal of learning an invariant representation across domains (e.g., in datasets where one of the domains has many more samples than others). Therefore, we first learn the match function using only the contrastive loss. Our results in Suppl. C.4 show that the two-phase method provides better overlap with ground-truth perfect matches than optimizing classification and matching simultaneously.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation</head><p>We evaluate MatchDG on out-of-domain accuracy for two simulated benchmarks from CSD by <ref type="bibr" target="#b23">[23]</ref>(Rotated MNIST and Fashion-MNIST) where the same objects are rotated across domains, and on real world datasets (PACS) <ref type="bibr" target="#b24">[24]</ref> and (ChestXRay) <ref type="bibr" target="#b25">[25]</ref> . In addition, using the simulated datasets, we inspect the quality of matches learnt by MatchDG by comparing them to ground-truth object-based matches. For the real world datasets, we also implement MatchDGHybrid that uses augmentations commonly done while training neural networks. We compare to 1) ERM: Standard empirical risk minimization, 2) ERM-RandMatch that implements the loss from Eq. (5), 3) other state-of-the-art methods for each dataset. For all matching-based methods, we use the cross-entropy loss for L d and 2 distance for dist in Eq.(4), <ref type="bibr" target="#b4">(5)</ref>. Details of implementation and the datasets are in Suppl. B.1. All the numbers are averaged over 3 runs with standard deviation in brackets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Rotated MNIST &amp; Fashion-MNIST.</head><p>The datasets contain rotations of grayscale MNIST handwritten digits and fashion article images from 0 • to 90 • with an interval of 15 • <ref type="bibr" target="#b26">[26]</ref>, where each rotation angle represents a domain and the task is to predict the class label. Since different domains' images are generated from the same base image (object), there exist perfect matches across domains. Following CSD, we report accuracy on 0 • and 90 • together as the test domain and the rest as the train domains; since these test angles, being extreme, are the hardest to generalize to.</p><p>PACS. This dataset contains total 9991 images from four domains: Photos (P), Art painting (A), Cartoon (C) and Sketch (S). The task is to classify objects over 7 classes. Following <ref type="bibr" target="#b20">[20]</ref>, we train 4 models with each domain as the target using Resnet-18, Resnet-50 and Alexnet.</p><p>Chest X-ray. We evaluate on a harder real-world dataset. We use Chest X-rays images from three different sources: NIH <ref type="bibr" target="#b25">[25]</ref>, ChexPert <ref type="bibr" target="#b27">[27]</ref> and RSNA <ref type="bibr" target="#b28">[28]</ref>. The task is to detect whether the image corresponds to a patient with Pneumonia (1) or not (0). For ease of interpretation, we balance the data such that there are equal number of images per class in each domain. To create spurious correlation, all images of class 0 in the training domains (NIH, ChexPert) are translated vertically downwards; no such translation is done for the test domain (RSNA).</p><p>Model Selection. While using a validation set from the test domain may improve classification accuracy, it goes against the problem motivation of generalization to unseen domains. Hence, we use only data from source domains to construct a validation set (except when explicitly mentioned in <ref type="table" target="#tab_4">Table 3</ref>, to compare to past methods that use test domain validation). <ref type="table" target="#tab_1">Table 1</ref> shows classification accuracy on rotMNIST and rotFashionMNIST for test domains 0 • &amp; 90 • using Resnet-18 model. On both datasets, MatchDG outperforms all baselines. The last column shows the accuracy for an oracle method, ERM-PerfMatch that has access to ground-truth perfect matches across domains. MatchDG's accuracy lies between ERM-RandMatch and ERM-PerfMatch, indicating the benefit of learning a matching function. As the number of training domains decrease, the gap between MatchDG and baselines is highlighted: with 3 source domains for rotFashionMNIST, MatchDG achieves accuracy of 45.6% whereas the next best method ERM-RandMatch achieves 38.8%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Results: Rotated MNIST (rotMNIST) and Fashion MNIST (rotFashionMNIST)</head><p>We evaluate on a simpler 2-layer LeNet <ref type="bibr" target="#b19">[19]</ref>, and the model from <ref type="bibr" target="#b29">[29]</ref> to compare MatchDG to prior works <ref type="bibr" target="#b30">[30,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b31">31]</ref>. Results are in Suppl. C.1, C.2.</p><p>Why MatchDG works? We compare the matches returned by MatchDG Phase I (on Resnet-18 network) to the ground-truth perfect matches and find that it has significantly higher overlap than matching based on ERM loss ( <ref type="table" target="#tab_2">Table 2)</ref>. We report three metrics on the representation learnt: percentage of MatchDG matches that are perfect matches, %-age of inputs for which the perfect match is within the top-10 ranked MatchDG matches, and mean rank of perfect matches measured by distance over the MatchDG representation.</p><p>On all three metrics, MatchDG finds a representation whose matches are more consistent with groundtruth perfect matches. For both rotMNIST and rotFashionMNIST datasets, about 50% of the inputs have their perfect match within top-10 ranked matches based on the representation learnt by MatchDG Phase I. About 25% of all matches learnt by MatchDG are perfect matches. For comparison, we also show metrics for an (oracle) MatchDG method that is initialized with perfect matches: it achieves better overall and Top-10 values. Similar results for MatchDG Phase 2 are in Suppl. C.4. Mean rank for rotFashionMNIST may be higher because of the larger sample size 10, 000 per domain; metrics for training with 2000 samples are in Suppl. C.5. Finally, to see how the overlap with perfect matches affects accuracy, we simulate random matches with 25%, 50% and 75% overlap with perfect matches (Suppl <ref type="table">. Table C.</ref>3). Accuracy increases as the fraction of perfect matches increase, indicating the importance of capturing good matches.</p><p>The case with zero training error. Since neural networks often achieve zero training error, we also evaluate the effectiveness of the MatchDG regularization under this regime. <ref type="figure" target="#fig_4">Fig. 2</ref> shows the matching loss term as training proceeds for rotMNIST and rotFashionMNIST. Even after the model achieves  Suppl. D.1 gives the results with AlexNet network and comparison to prior work <ref type="bibr" target="#b13">[13,</ref><ref type="bibr" target="#b34">34,</ref><ref type="bibr" target="#b24">24,</ref><ref type="bibr" target="#b35">35,</ref><ref type="bibr" target="#b36">36]</ref> and a t-SNE plot <ref type="figure" target="#fig_14">(Figure 4)</ref> to show the quality of representation learnt by MatchDG. Chest X-rays. When evaluated on the source domains, methods like ERM and IRM obtain higher accuracy than matching-based methods. However, on the test domain RSNA, MatchDGHybrid obtains highest classification accuracy (7 %-age points above ERM), followed by CSD and MatchDG ( </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>There are four main approaches for the domain generalization task: learning a common representation, dataset augmentation, meta-learning and sharing common parameters.</p><p>Learning common representation. To learn a generalizable classifier, several methods enforce same distribution of Φ(x) across domains marginally or conditional on class label, using divergence measures such as maximum mean discrepancy <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b3">4]</ref>, adversarial training with a domain discriminator <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b13">13]</ref>, use discriminant analysis <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b11">12]</ref>, and other techniques <ref type="bibr" target="#b26">[26]</ref>. In Section 2.3, we identified limitations of the above methods. A more recent line of work <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b18">18]</ref> enforces domain-invariance of the optimal P (Y |Φ(x) that we compare to in the evaluation. There is work on use of causal reasoning for domain adaptation <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b16">16,</ref><ref type="bibr" target="#b49">49]</ref> that assumes Y → X direction and other work <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b50">50]</ref> on connecting causality that assumes X → Y . Our SCM model unites these streams by introducing Y true and labelled Y and develop an invariance condition for domain generalization that is valid under both interpretations. Perhaps the closest to our work is by Heinze-Deml and Meinshausen <ref type="bibr" target="#b7">[8]</ref> who use the object concept in generation of input for a single domain but assume that objects are observed. We provide an algorithm that does not depend on observed objects. In doing so, we provide theoretical justification for the past uses of contrastive loss in domain generalization based on the class label <ref type="bibr" target="#b19">[19,</ref><ref type="bibr" target="#b20">20]</ref> or using augmented data <ref type="bibr" target="#b51">[51]</ref>.  <ref type="bibr" target="#b34">[34]</ref>, S-MLDG <ref type="bibr" target="#b37">[37]</ref>, D-SAM <ref type="bibr" target="#b38">[38]</ref>, MMLD <ref type="bibr" target="#b39">[39]</ref>, DDAIG <ref type="bibr" target="#b40">[40]</ref> SagNet <ref type="bibr" target="#b41">[41]</ref>, DANN <ref type="bibr" target="#b2">[3]</ref>, C-DANN <ref type="bibr" target="#b13">[13]</ref>, DRO <ref type="bibr" target="#b42">[42]</ref>, Mixup <ref type="bibr" target="#b43">[43,</ref><ref type="bibr" target="#b44">44,</ref><ref type="bibr" target="#b45">45]</ref>, IRM <ref type="bibr" target="#b5">[6]</ref>, MLDG <ref type="bibr" target="#b35">[35]</ref>, MMD <ref type="bibr" target="#b1">[2]</ref>, CORAL <ref type="bibr" target="#b46">[46]</ref>, were taken from the DomainBed <ref type="bibr" target="#b29">[29]</ref> paper. For G2DM <ref type="bibr" target="#b47">[47]</ref>, CSD <ref type="bibr" target="#b23">[23]</ref>, MASF <ref type="bibr" target="#b20">[20]</ref>, EpiFCR <ref type="bibr" target="#b36">[36]</ref>, MetaReg <ref type="bibr" target="#b48">[48]</ref>, it was taken from the respective paper.   <ref type="bibr" target="#b20">[20,</ref><ref type="bibr" target="#b35">35,</ref><ref type="bibr" target="#b48">48]</ref>. While we showed that a contrastive training only can achieve promising results, combining meta-learning with our approach is an interesting future direction.</p><p>Dataset augmentation.: The data augmentation methods create more out-of-domain samples, from distributions within a bounded distance <ref type="bibr" target="#b52">[52]</ref> or on a continuous space of domain interventions <ref type="bibr" target="#b9">[10]</ref>.</p><p>Parameter Decomposition. Finally there is work that focuses on identifying common model parameters across domains <ref type="bibr" target="#b23">[23,</ref><ref type="bibr" target="#b24">24,</ref><ref type="bibr" target="#b53">53]</ref>, rather than a common input representation. We compared our work against one such recent method based on low-rank decomposition (CSD) <ref type="bibr" target="#b23">[23]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We presented a causal interpretation of domain generalization and used it to derive a method that matches representations of input pairs that share causal features. We find that combining ERM with a simple invariance condition performs better on benchmarks than prior work, and hope to investigate matching-based methods with domain-dependent noise on class label and object in future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Theory and Proofs</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Constructing the causal graph</head><p>When considering classification tasks, there are two viewpoints on whether the features cause the class label, or whether the class labels cause the features. <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b16">16,</ref><ref type="bibr" target="#b49">49</ref>] assume a generative process where the true class label determines the features in the observed data. In contrast, <ref type="bibr" target="#b50">[50,</ref><ref type="bibr" target="#b5">6]</ref> consider a generative process where the features are used to assign a label, e.g., when manually labelling a set of images. We believe that both mechanisms are possible, depending on the context. In particular, it is plausible that the true class label Y true causes the features, but it is not observed. Instead, what is observed is the output of a manual labelling process, where the features are used to label each input with its class Y <ref type="bibr" target="#b5">[6]</ref>.</p><p>Given these differences, we construct a causal graph <ref type="figure" target="#fig_1">(Figure 1</ref>) that includes both Y true and Y (as in <ref type="bibr" target="#b7">[8]</ref>), and is consistent with both viewpoints about the direction of the causal mechanism. Importantly, all d-separation results reported in the main text hold true irrespective of whether we choose Y or Y true as the class label. We use Y as the label in the main text, since it corresponds to many settings where the observed class label is a result of a (possibly noisy) manual labelling process.</p><p>In addition, we chose to represent X C and X A as near-to-final features, that are combined using a simple operation to generate the observed features X. Under this representation, the object O does cause X A ; X A is produced by combination of the domain and the object. Another equally valid construction is to assume that X A contains only the domain information, and a more complex operation generates the observed features using X C (object information) and X A . The corresponding causal graph will omit the edge from object O to X A . Both these graphs are allowed by our framework. All d-separation results reported in the main text hold true irrespective of whether there exists an edge from O to X A .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 D-separation</head><p>We first expand on the d-separation definition, providing a few examples that illustrate conditional independence implications of specific graph structures in <ref type="figure">Figure 3</ref>. We use these three conditions for all the proofs below. Proof. Expanding on (1), the ERM estimator can be written as:</p><formula xml:id="formula_10">A B C (a) Chain: A ⊥ ⊥ B; A ⊥ ⊥ B|C A B C (b) Fork: A ⊥ ⊥ B; A ⊥ ⊥ B|C A B C (c) Collider: A ⊥ ⊥ B; A ⊥ ⊥ B|C</formula><formula xml:id="formula_11">f ERM = arg min f ∈F 1 m d=1 n d m d=1 n d i=1 l(y (d) i , f (x (d) i )) = arg min f ∈F 1 n n d,x,y∼Pm l(y (d) , f (x (d) )) = arg min f ∈FÊ d,x,y∼Pm l(y (d) , f (x (d) )) = arg min f ∈FÊ Sn∼Pm [l(y (d) , f (x (d) ))]<label>(7)</label></formula><p>where number of samples n = m d=1 n d and S n ∼ P m (D, X, Y ) is the training dataset of size n. Since D m = D ⇒ P = P m . As n → ∞,</p><formula xml:id="formula_12">f ∞ ERM = arg min f ∈F lim n→∞Ê Sn∼P l(y (d) , f (x (d) )) = arg min f ∈F E d,x,y∼P l(y (d) , f (x (d) )) = f * (8)</formula><p>where the last equality is due to the definition of f * in Section 2. k )) = 0 contains the optimal Φ(x) = X C that minimizes the domain generalization loss in (2). 2. Assuming that P (X a |O, D) &lt; 1 for every high-level feature X a that is directly caused by domain, and for P-admissible loss functions <ref type="bibr" target="#b15">[15]</ref> whose minimization is conditional expectation (e.g., 2 or cross-entropy), a loss-minimizing classifier for the following loss is the true function f * , for some value of λ.</p><formula xml:id="formula_13">f perfectmatch = arg min h,Φ m d=1 L d (h(Φ(X)), Y ) + λ Ω(j,k)=1;d =d dist(Φ(x (d) j ), Φ(x (d ) k )) (4)</formula><p>Proof. CLAIM 1. The matching condition can be written as:</p><formula xml:id="formula_14">C(Φ) = min Φ d,d ∈Dm lim n d →∞ n d →∞ Ω(j,k)=1;d =d dist(Φ(x (d) j ), Φ(x (d ) k ))<label>(9)</label></formula><p>where Ω(j, k) = 1 for pairs of inputs x j and x k from two different domains d and d that correspond to the same object. The distance metric dist is non-negative, so the optimal Φ is when C(Φ) is zero.</p><p>As in the SCM from <ref type="figure" target="#fig_1">Figure 1b</ref>, let X c represent a feature vector such that it is generated based only on the object O and that it leads to the optimal classifier in (2). From Sections 2.1 and 2.2, we know that X c ⊥ ⊥ D|O and that x c = g xc (o). Thus, x c is the same for inputs from the same object and we can write:</p><formula xml:id="formula_15">dist(x (d) c,j , x (d ) c,k ) = 0 ∀d, d ∈ D m such that Ω(j, k) = 1<label>(10)</label></formula><p>Hence, Φ(x) = x c leads to zero regularizer term and is one of the optimal minimizers for C(Φ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CLAIM 2.</head><p>Further, we show that any other optimal Φ is either a function of x c or a constant for all inputs. We prove by contradiction.</p><p>Let X A represent the set of unobserved high-level features that are generated based on both the object O and the domain D. From the SCM from <ref type="figure" target="#fig_1">Figure 1b</ref>, a feature vector X a ⊆ X A is independent of X c given the object, X a ⊥ ⊥ X c |O, and x a = g xa (d, o, xa ). Further, let there be an optimal Φ a (x) for C(Φ) such that it depends on some X a ⊆ X A (and is not trivially a constant function). Since Φ a is optimal, Φ a (x ). Due to domain-dependent variation, with non-zero probability, the high-level X a features are not the same for these two input data points, x (d) a,l = x (d ) a,i . Since Φ is a deterministic function of x that is not independent of X a , if an input x has a different X a , its value of Φ(x) will also be different. Thus, with non-zero probability, we obtain that Φ(x</p><formula xml:id="formula_16">(d) l ) = Φ(x (d ) i</formula><p>), unless the effect of X a is a constant function. Hence, a contradiction and optimal Φ cannot depend on any X a ⊆ X A that are generated based on the domain. Therefore, an optimal solution to C(Φ) can only depend on X c . However, any function of X c is optimal, including trivial functions like the constant function (that will have low accuracy). Below we show that using the ERM term in (4) ensures that the optimal solution contains only those functions of X C that also maximize accuracy.</p><p>Using <ref type="formula">(3)</ref>, the empirical optimizer function can be written as (where we scale the loss by a constant n = d n d , the total number of training data points):</p><formula xml:id="formula_17">f pmatch = arg min h,Φ 1 n m d=1 lim n d →∞ L d (h(Φ(X)), Y ) s.t. Ω(j,k)=1;d =d dist(Φ(x (d) j ), Φ(x (d ) k )) = 0 (11) = arg min h,ψ 1 n m d=1 lim n d →∞ L d (h(ψ(X c )), Y ) = arg min f 1 n m d=1 lim n d →∞ L d (f (X c ), Y )<label>(12)</label></formula><p>where ψ(X c ) denotes all functions of X c that are optimal for (9), and the last equality is because h • ψ can be written as f = h • ψ. Since we assume that L is a P-admissible loss function, its minimizer is the conditional expected value. Thus, for any domain d, arg min f lim n d →∞</p><formula xml:id="formula_18">1 n d L d (f (X c ), Y ) = E[Y |X c , D]. Further, by d-separation, Y ⊥ ⊥ D|X c . Therefore, E[Y |X c , D] = E[Y |X c ].</formula><p>The above equation indicates that the loss minimizer function on any domain is independent of the domain. Thus, for the m training domains, we can write:</p><formula xml:id="formula_19">arg min f ∈F lim n d →∞ 1 n d L d (f (X c ), Y ) = arg min f ∈F E[l(f (x c ), y)] = E[Y |X c ] ∀d ∈ D m<label>(13)</label></formula><p>Now <ref type="formula" target="#formula_0">(12)</ref> can be rewritten as,</p><formula xml:id="formula_20">f pmatch = arg min f 1 n m d=1 lim n d →∞ L d (f (X c ), Y ) n d n d = arg min f m d=1 lim n d →∞ L d (f (X c ), Y ) n d n d n<label>(14)</label></formula><p>From the equation above, the loss forf pmatch can be considered as a weighted sum of the average loss on each training domain where the weights are all positive. Since E[Y |X c ] minimizes the average loss on each domain as n d → ∞, it will also minimize the overall weighted loss for all values of the weights. Therefore, for any dataset over m domains in D m , E[Y |X c ] is the optimal function that minimizes the overall loss.</p><p>Moreover, we can also write f * as: </p><p>where we utilize <ref type="bibr" target="#b13">(13)</ref> and that the loss function is P-admissible. Hence, f * = E[Y |X c ] is the loss-miniziming function for the loss in <ref type="bibr" target="#b11">(12)</ref>.</p><p>Finally, using a Lagrangian multiplier, minimizing the following soft constraint loss is equivalent to minimizing (11), for some value of λ.</p><formula xml:id="formula_22">f pmatch = lim ∀d∈Dmn d →∞ arg min h,Φ m d=1 L d (h(Φ(X)), Y ) + λ Ω(j,k)=1;d =d dist(Φ(x (d) j ), Φ(x (d ) k ))<label>(16)</label></formula><p>The result follows.</p><p>Comment on Theorem 1. In the case where the effect of a domain is also deterministic, it is possible that P (X a |O, D) = 1 (e.g., in artificially created domains like Rotated-MNIST where every object is rotated by the exact same amount in each domain). In that case Theorem 1 does not apply and it is possible to learn a representation Φ a that depends on X a ⊆ X A and still minimizes C(Φ) to attain C(Φ) = 0. For example, with two training domains on Rotated-MNIST dataset (0 • , α • ), it is possible to learn a representation that simply memorizes to "un-rotate " the α angle back to 0 • . Such a representation will fail to generalize to domains with different rotation angles, but nonetheless minimizes C(Φ) by attaining the exact same representation for each object.</p><p>In practice, we conjecture that such undesirable Φ a are avoided by model-size regularization during training. As the number of domains increase, it may be simpler to learn a single transformation (representation) based on X c (and independent of X c features like angle) than learn separate anglewise transformations for each train domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.5 Proof of Corollary 1</head><p>Corollary 1. The conditions enforced by domain-invariant (Φ(x) ⊥ ⊥ D) or class-conditional domaininvariant (Φ(x) ⊥ ⊥ D|Y ) methods are not satisfied by the causal representation X C . Thus, without additional assumptions, the set of representations that satisfy any of these conditions does not contain X C , even as n → ∞.</p><p>Proof. As in the SCM from <ref type="figure" target="#fig_1">Figure 1b</ref>, let X c represent an unobserved high-level feature vector such that it is generated based only on the object O and that it leads to the optimal classifier in (2). From Sections 2.1 and 2.2, we know that X c ⊥ ⊥ D|O and that x c = g xc (o). Following a similar proof to Theorem 1 (Claim 1), we check whether Φ(x) = x c satisfies the invariance conditions required by the two methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Domain-invariant:</head><p>The required condition for a representation is that Φ DI (x) ⊥ ⊥ D. But using the d-separation criteria on the SCM in <ref type="figure" target="#fig_1">Figure 1b</ref>, we find that X c ⊥ ⊥ D due to a path through Object O.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Class-conditional domain-invariant:</head><p>The required condition for a representation is that Φ CDI ⊥ ⊥ D|Y . However using the d-separation criteria on the SCM, we find that X c ⊥ ⊥ D|Y due to a path through Object O that is not blocked by Y (nor by Y true if it is observed).</p><p>Therefore, under the conditions proposed by these methods, X c or any function of X c is not an optimal solution without making any additional assumptions. Hence, even with infinite samples, a method optimizing for these conditions will not retrieve X c .</p><p>A.6 Proof of Theorem 2 Theorem 2. Assume training domains such that for any two same-class inputs x a,k ) ≥ δ a where x a is any high-level feature that is caused directly by domain. Further, assume that the distance over X C between same-class inputs from different domains is bounded: dist(x Proof. Since δ c is a constant for a dataset, the loss from (5) can be written as,</p><formula xml:id="formula_23">f randommatch = arg min h,Φ m d=1 L d (h(Φ(X)), Y ) + λ Ω Y (j,k)=1;d =d dist(Φ(x (d) j ), Φ(x (d ) k )) − Jδ c (17)</formula><p>where we added a scaling constant J for the total number of matches. For some value of λ, the above optimization is equivalent to,</p><formula xml:id="formula_24">arg min h,Φ m d=1 L d (h(Φ(X)), Y ) s.t. Ω Y (j,k)=1;d =d dist(Φ(x (d) j ), Φ(x (d ) k )) ≤ Jδ c<label>(18)</label></formula><p>where δ c is the maximum difference in X C between two inputs with the same class but different domains.</p><p>We first show that Φ(x) = x c satisfies the constraint in <ref type="bibr" target="#b18">(18)</ref>, where x c is any feature vector that is generated based only on the object (x c = g xc (o)), as defined in the proof of Theorem 1. Now since</p><formula xml:id="formula_25">dist(x (d) c,l , x (d )</formula><p>c,i ) ≤ δ c for any two inputs x l and x i with the same class and different domains, the constraint from <ref type="formula" target="#formula_0">(18)</ref> is satisfied by Φ(x) = x c .</p><p>In addition, let x a be a feature vector that is generated based on both the object and a domain (x a = g xa (d, o, xa )) and that is conditionally independent of x c , X A ⊥ ⊥ X c |O. Since we assume that dist(x</p><formula xml:id="formula_26">(d) a,l , x (d )</formula><p>a,i ) ≥ δ a and δ c ≤ δ a , such an x a cannot satisfy the constraint in <ref type="bibr" target="#b18">(18)</ref>. Hence, the solution to the constraint in <ref type="bibr" target="#b18">(18)</ref> can only include x c features that are not caused by the domain (or some function of x c , ψ(x c )). Thus, <ref type="bibr" target="#b18">(18)</ref> can be rewritten as,</p><formula xml:id="formula_27">= arg min h,ψ 1 n m d=1 lim n d →∞ L d (h(ψ(X c )), Y ) = arg min f 1 n m d=1 lim n d →∞ L d (f (X c ), Y )<label>(19)</label></formula><p>Note that the above equation is the same as (12) from Theorem 1 proof. Following the same steps as in Theorem 1 proof, we find that f * = E[Y |X c ] is the loss-minimizing classifier for <ref type="bibr" target="#b18">(18)</ref>, and hence for (5) at some value of λ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Evaluation and implementation details</head><p>In this section we describe implementation details for our proposed methods. We also discuss the evaluation protocol, including details about hyperparameters and cross-validation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1 Implementation details</head><p>For the implementation of ERM-RandMatch in Eq. (5) , ERM-PerfMatch in Eq. (4); we use the cross-entropy loss for L d and l 2 distance for dist in Eq. <ref type="bibr" target="#b3">(4,</ref><ref type="bibr" target="#b4">5)</ref>. For both methods, we consider the representation Φ(x) to be the last layer of the network. That is, we take h to be identity function in Eq. (4, 5) for simplicity. It is also possible to use the second-last or any other previous layer as a representation, but the last layer performed well in our experiments.</p><p>We use SGD to optimize the loss for all the datasets, with details about learning rate, epochs, batch size, weight decay etc. provided in the section B.3 ahead. For all the different methods, we sample batches from the data matrix consisting of data points matched across domains; hence we ensure an equal number of data points from each source domain in a batch. When training with MatchDG, the underlying architecture for Phase 2 is kept the same for ERM, RandMatch, PerfMatch for the respective task; with the details mentioned below for each dataset. The details for the Phase-1 architecture are specified in section B.3, <ref type="table" target="#tab_9">Table 6</ref>.</p><p>Rotated MNIST &amp; Fashion-MNIST. The datasets contain rotations of grayscale MNIST handwritten digits and fashion article images from 0 • to 90 • with an interval of 15 • <ref type="bibr" target="#b26">[26]</ref>, where each rotation angle represents a domain and the task is to predict the class label. For <ref type="table" target="#tab_1">Table 1</ref>, we follow the setup in CSD <ref type="bibr" target="#b23">[23]</ref>, we report accuracy on 0 • and 90 • together as the test domain and the rest as the train domains. We use 2, 000 and 10, 000 training samples from each domain for rotated MNIST and Fashion-MNIST, and train models using Resnet-18 architecture (without pre training). We choose this as our primary setup and select 0 • and 90 • as our target domain, since these are known to be the most difficult domains to generalize <ref type="bibr" target="#b23">[23,</ref><ref type="bibr" target="#b19">19]</ref>.</p><p>Further, we also evaluate on other setups of Rotated MNIST in prior works <ref type="bibr" target="#b19">[19,</ref><ref type="bibr" target="#b29">29]</ref>, which involve six domains (0 • , 15 • , 30 • , 45 • , 60 • , 75 • ), and evaluate for each domain being the target domains with the remaining five used as source domains. We sample 1000 data points for each domain and evaluate using the LeNet architecture <ref type="table" target="#tab_7">(Table 8)</ref> as per the setup proposed by <ref type="bibr" target="#b19">[19]</ref>. Similarly, we sample all the 70,000 images in MNIST and evaluate using the custom architecture <ref type="table">(Table 9</ref>) as per the setup proposed by <ref type="bibr" target="#b29">[29]</ref>.</p><p>Another important distinction between different setups above is the use of different digits for the source and the target domains ( <ref type="bibr" target="#b23">[23]</ref>, <ref type="bibr" target="#b29">[29]</ref>), as opposed to the use of same digits across the source and the target domains in setup of <ref type="bibr" target="#b19">[19]</ref> which makes the task easier as it leaks information about the target domains.</p><p>Finally, for all the different setups proposed above, we create an additional validation set for each domain with 20% percent size as of the training set for that domain. We use the validation set from the source domains for hyper parameter tuning.</p><p>PACS. This dataset contains total 9991 images from four domains: Photos (P), Art painting (A), Cartoon (C) and Sketch (S). The task is to classify objects over 7 classes. Following <ref type="bibr" target="#b20">[20]</ref>, we train 4 models with each domain as the target using Resnet-18 <ref type="table" target="#tab_4">(Table 3)</ref>, Resnet-50 <ref type="table" target="#tab_4">(Table 3)</ref> and Alexnet <ref type="table" target="#tab_1">(Table 14)</ref>, with each architecture pre-trained on ImageNet. We also the following data augmentations <ref type="bibr" target="#b29">[29]</ref> while training: Random Crop, Horizontal Flip, Color Jitter, and Random Gray Scale.</p><p>Chest X-ray. We use Chest X-rays images from three different sources: NIH <ref type="bibr" target="#b25">[25]</ref>, ChexPert <ref type="bibr" target="#b27">[27]</ref> and RSNA <ref type="bibr" target="#b28">[28]</ref>. The task is to detect whether the image corresponds to a patient with Pneumonia <ref type="bibr" target="#b0">(1)</ref> or not (0). For ease of interpretation, we balance the data such that there are equal number of images per class in each domain. Since majority of the images in each domain correspond to the class (0), we sample a subset of the images to ensure that there is no class imbalance in each domain. For each domain, we first utilize all the images for the class (1) and choose 30% percent of them for test set, with the remaining 70% for the training set. Further, we create a validation set from the training set with 25% size as that of training set. Then for each of the training/validation/test split, we sample an equal number of images from class (0) to remove class imbalance. The dataset size for the different splits on each domain are described below: Following prior works <ref type="bibr" target="#b54">[54]</ref>, we use the pre-trained DenseNet-121 architecture for classification. We use the following data augmentations: Random Crop, Horizontal Flip, and Affine Transformations. We further create spurious correlations, all the images of the class 0 in the training domains (NIH, ChexPert) are translated vertically downwards; while no such translation is done for the test domain (RSNA). We translate the images in each source domain by a fixed amount, which varies over different source domains. For the images in the source domain NIH, we translate all the pixels of each image downwards by 45 units, whereas for the source domain ChexPert, we translate 30 units. This leads to a downward shift in the position of lungs in the images for the class 0 as compared to those for class 1, which could lead to models utilizing this spurious relative difference in position of lungs for the classifications task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1.1 MatchDG implementation details:</head><p>The MatchDG algorithm proceeds in two phases. Initialization: We construct matches of pairs of same-class data points from different domains. Hence, given each data point we randomly select another data point with the same class from another domain. The matching for each class across domains is done relative to a base domain; which is chosen by taking the domain that has the highest number of samples for that class. This is done to avoid missing out on data points when there is class imbalance across domains. Specifically, we iterate over classes and for each class, we match data points randomly across domains w.r.t a base domain for that class. This leads to matrix M of size (N , K), where N refers to the updated domain size ( sum of the size of base domain for all the classes ) and K refers to the total number of domains. We describe the two phases below:</p><p>Phase 1: We samples batches (B, K) from the matched data matrix M, where B is the batch size. For each data point x i in the batch, we minimize the contrastive loss from (6) by selecting its matched data points across domains as the positive matches and consider every data point with a different class label from x i to be a negative match.</p><p>After every t epochs, we periodically update the matched data matrix by using the representations learnt by contrastive loss minimization. We follow the same procedure of selecting a base domain for each class, but instead of randomly matching data points across domains, we find the nearest neighbour for the data point in base domain among the data points in the other domains with the same class label based on the l 2 distance between their representations.</p><p>At the end of Phase I, we update the matched data matrix based on l 2 distance over the final representations learnt. We call these matches as the inferred matches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Phase 2:</head><p>We train using the loss from Eq. (5), but instead of random matches, we use the inferred matches generated from Phase 1 (ERM + Inferred Match). We train the network from scratch in Phase 2 and use the representations learnt in Phase 1 to only update the matched data matrix.</p><p>The updated data matrix based on representations learnt in Phase 1 may lead to many-to-one matches from the base domain to the other domains. This can lead to certain data points being excluded from the training batches. Therefore, we construct batches such that each batch consists of two parts. The first is sampled as in Phase 1 from the matched data matrix. The second part is sampled randomly from all train domains. Specifically, for each batch (B, K) sampled from the matched data matrix, we sample an additional part of size B with data points selected randomly across domains. The loss for the second part of the batch is simply ERM, along with ERM + InferredMatch Loss on the first part of the batch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 Metrics for evaluating quality of learnt matches</head><p>Here we describe the three metrics used for measuring overlap of the learnt matches with ground-truth "perfect" matches.</p><p>Overlap %: Percentage of matches (j, k) as per the perfect match strategy Ω that are also consistent with the learnt match strategy Ω .</p><formula xml:id="formula_28">Ω(j,k)=1;d =d Ω (j, k) Ω(j,k)=1;d =d 1<label>(20)</label></formula><p>Top-10 Overlap %: Percentage of matches (j, k) as per the perfect match strategy Ω that are among the Top-10 matches for the data point j w.r.t the learnt match strategy Ω i.e. S 10 Ω (j)</p><formula xml:id="formula_29">Ω(j,k)=1;d =d 1[k ∈ S 10 Ω (j)] Ω(j,k)=1;d =d 1<label>(21)</label></formula><p>Mean Rank: For the matches (j, k) as per the perfect match strategy Ω, compute the mean rank for the data point j w.r.t the learnt match strategy Ω i.e. S Ω (j)</p><formula xml:id="formula_30">Ω(j,k)=1;d =d Rank[k ∈ S Ω (j)] Ω(j,k)=1;d =d 1<label>(22)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.3 HyperParameter Tuning</head><p>To select hyperparameters, prior works <ref type="bibr" target="#b20">[20,</ref><ref type="bibr" target="#b34">34,</ref><ref type="bibr" target="#b35">35]</ref> use leave-one-domain-out validation, which means that the hyperparameters are tuned after looking at data from the unseen domain. Such a setup is violates the premise of the domain generalization task that assumes that a model should have no access to the test domain. Therefore, in this work, we construct a validation set using only the source domains and use it for hyper parameter tuning. In the case of PACS, we already have access to the validation indices for each domain and use them to construct a validation set based on the source domains. For Rotated &amp; Fashion MINST, Chest X-ray datasets, we create validation set for each source domain as described in the section B.1 above. Hence, the model does not have access to the data points from the target/test domains at the time of training and validation.</p><p>We perform a grid search over pre-defined values for each hyper parameter and report the optimal values along with the values used for grid search in <ref type="table">Table 5</ref>. Further, we do early stopping based on the validation accuracy on source domains and use the models which obtain the best validation accuracy.</p><p>For the case of MatchDG Phase-1, we do not perform grid search and use default values for each hyper parameter ( <ref type="table" target="#tab_9">Table 6</ref>). We still do early stopping for MatchDG Phase-1, based on the metric Top-10 Overlap (Section B.2) over the validation set of source domains. Since we require perfect matches for the evaluation of the metric Top-10 Overlap, we create prefect matches using the self augmentations (Section B.1) for each dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.4 Reproducing Results from Prior Work</head><p>MNIST and Fashion MNIST The results for MASF, CSD in <ref type="table" target="#tab_1">Table 1</ref> are taken from <ref type="bibr" target="#b23">[23]</ref>; except IRM where we used the implementation available online 1 to generate the results. The results for prior approaches in <ref type="table" target="#tab_7">Table 8</ref> are taken from <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b30">[30]</ref>. For the results using DomainBed setup in <ref type="table">Table 9</ref>, the results for prior approaches are taken from <ref type="bibr" target="#b29">[29]</ref>.</p><p>For ResNet-18 architecture <ref type="table" target="#tab_1">(Table 1)</ref>; the results for the reduced number of domains for CSD and MASF were computed using their code which is available online <ref type="bibr" target="#b23">23</ref> . The MASF code was hardcoded to run for PACS dataset; which has 3 source domains that gets divided into 2 meta train and 1 meta test domain. Their code requires atleast 2 meta train domains; which leads to an issue for only 2 source domains <ref type="bibr" target="#b30">(30,</ref><ref type="bibr" target="#b45">45)</ref>. In <ref type="table" target="#tab_1">Table 1</ref> when there are only 2 source domains; their code considers only 1 meta train domain. To resolve this issue; we create a copy of the 1 meta train domain and thus run MASF for source domains 30, 45 on MNIST.</p><p>PACS We did not generate results for the prior approaches for PACS by developing or using existing implementations. All the results for the prior approaches on PACS were taken from the respective papers as specified in the <ref type="table" target="#tab_1">Table 3, 14</ref>.</p><p>Chest X-ray The results for the prior approaches CSD, IRM were generated using the implementations of both of the methods available on github 1,2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Additional Evaluation on Rotated MNIST and Fashion-MNIST</head><p>Here we present results for additional experiments on Rotated MNIST and Fashion-MNIST datasets using MatchDG.  <ref type="table">Table 5</ref>: Hyper parameter selection details for all the datasets. We mention the Optimal Value for each hyper parameter and the Range used for grid search. We leave the optimal value for Epochs as blank since we do early stopping based on validation loss, with the total number of epochs for model training specified in the Range column. For the dataset PACS, since the optimal values differ for different test domains, we represent them separately in <ref type="table" target="#tab_10">Table 7</ref> Dataset</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.1 Comparing MatchDG with prior work on the LeNet Network</head><p>Hyper  <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b30">30,</ref><ref type="bibr" target="#b26">26,</ref><ref type="bibr" target="#b19">19,</ref><ref type="bibr" target="#b31">31]</ref>. <ref type="table">Table 9</ref> compares the accuracy results for MatchDG with prior work on the setup proposed by <ref type="bibr" target="#b29">[29]</ref>. This setup is similar to the setup in the section C.1, however, it uses a custom CNN architecture and all the 70, 000 images for each domain. We observe that RandMatch and MatchDG outperform prior work on different test domains. MatchDG obtains the highest overall accuracy 98.3%, and provides significant improvement for the test domain 0 • (97.1%) as compared to the best prior approach MMD <ref type="bibr" target="#b1">[2]</ref> (96.6%).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2 Comparing MatchDG on Domain Bed Benchmark</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.3 Accuracy Results using a fraction of perfect matches</head><p>To show the importance of learning a good match function, we present the results of approaches with match function capturing some fixed percentage of perfect matches in the <ref type="table" target="#tab_1">Table 10</ref>. For both Rotated &amp; Fashion MNIST, we observe that the approaches that contain a higher proportion of perfect matches perform better in terms of accuracy on target domains. Hence, the quality of the match function leads to monotonic effect on the generalization performance of the matching approaches.</p><p>Interestingly, the accuracy for the range between 25-50% overlap roughly predicts the reported accuracy for MatchDG (which had about 35% and 25% overlap on the two datasets). These results confirm that in addition to high accuracy, Phase I of MatchDG allows for learning a representation where inputs with the same causal features are closer.    <ref type="table" target="#tab_7">Table 8</ref>: Accuracy for Rotated MNIST datasets using the LeNet architecture as proposed in <ref type="bibr" target="#b19">[19]</ref>. The results for the prior approaches CCSA <ref type="bibr" target="#b19">[19]</ref>, D-MTAE <ref type="bibr" target="#b26">[26]</ref>, LabelGrad <ref type="bibr" target="#b31">[31]</ref>, DAN <ref type="bibr" target="#b2">[3]</ref>, and CrossGrad <ref type="bibr" target="#b9">[10]</ref> are taken from <ref type="table">Table 9</ref> in <ref type="bibr" target="#b9">[10]</ref>. The results for DIVA <ref type="bibr" target="#b30">[30]</ref> are taken from the <ref type="table" target="#tab_1">Table 1</ref>   <ref type="table">Table 9</ref>: Accuracy for Rotated MNIST datasets using the DomainBed setup as proposed in <ref type="bibr" target="#b29">[29]</ref>.</p><p>The results for the approaches IRM <ref type="bibr" target="#b5">[6]</ref>, DRO <ref type="bibr" target="#b42">[42]</ref>, Mixup <ref type="bibr" target="#b43">[43,</ref><ref type="bibr" target="#b44">44,</ref><ref type="bibr" target="#b45">45]</ref>, MLDG <ref type="bibr" target="#b35">[35]</ref>, CORAL <ref type="bibr" target="#b46">[46]</ref>, MMD <ref type="bibr" target="#b1">[2]</ref>, DANN <ref type="bibr" target="#b2">[3]</ref>, C-DANN <ref type="bibr" target="#b13">[13]</ref> are taken from <ref type="bibr" target="#b29">[29]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.4 Quality of representation learnt in the classification phase</head><p>In addition to <ref type="table" target="#tab_2">Table 2</ref> that shows metrics for Phase 1 of MatchDG, we compute the metrics for the classification phase (Phase 2) of MatchDG. Specifically, we compute the Overlap, Top-10 overlap and the Mean Rank metrics (Section B.2) for matched pairs of inputs based on the representation learnt at the end of the classification phase. <ref type="table" target="#tab_1">Table 11</ref> shows the matching metrics for MatchDG and compares it to the matches based on the representations (last layers) learnt by the ERM-PerfMatch and ERM-RandMatch methods. For both Rotated-MNIST and Fashion-MNIST datasets, MatchDG obtains mean rank, Top 10 overlap and total overlap between ERM-PerfMatch and ERM-RandMatch. As the Fashion-MNIST dataset is more complex than the digits dataset, we observe that the mean rank with different training techniques is higher than the corresponding values for the Rotated-MNIST dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.5 Matching metrics for Fashion-MNIST dataset with 2000 training samples per domain</head><p>In the main text ( We compute the metric for the default instantiation of Phase 1 of MatchDG initialized with random matches and compare it to an oracle version of MatchDG initialized with perfect matches. In addition, we compare the metrics for matches generated using baseline ERM (last layer of the network) in  order to understand its effectiveness as a matching strategy in Phase 1. <ref type="table" target="#tab_1">Table 12</ref> shows the metrics for Phase 1 of MatchDG with 2K images from the Fashion-MNIST dataset, and reproduces the metrics for the 10K dataset from <ref type="table" target="#tab_2">Table 2</ref> for ease of comparison. We observe that the mean rank of perfect matches improves for the smaller dataset. Similarly, the overlap and top-10 overlap also increase for the smaller dataset. A possible reason is that there are fewer alternative matches to the perfect match as the number of samples is reduced. That said, while the overlap with perfect matches may decrease as sample size increases, the accuracy of the resultant classifier may still increase due to higher sample size. In Section 3.2, we proposed Phase 1 of the MatchDG algorithm with iterative updates to the computed matches. Here we compare the quality of matches learnt at the end of Phase 1 with or without using the iterative updating. Without the iterative updates, the matches always remain the same as the random matches with which the algorithm was initialized. <ref type="table" target="#tab_1">Table 13</ref> shows metrics computed at the end of Phase 1 of MatchDG using both an iterative approach vs. a non-iterative approach. The iterative approach provides a 3× improvement on the overlap with perfect matches for rotated MNIST and Fashion-MNIST datasets. Since higher overlap in the inferred matches results in better classification accuracy in Phase 2 (as shown in <ref type="table" target="#tab_1">Table 10</ref>), we conclude that using the iterative approach improves the domain generalization capability of MatchDG. Finally, we compare RandMatch and MatchDG to prior work on generalization accuracy for the PACS dataset using the AlexNet architecture. As in <ref type="table" target="#tab_4">Table 3</ref>, the task is to generalize to a test domain after training on the remaining three domains.</p><p>For all test domains, <ref type="table" target="#tab_1">Table 14</ref> shows that both RandMatch and MatchDG outperform the baseline ERM method. Averaging over the test domains, MatchDG obtains slightly higher accuracy than RandMatch (72.08 versus 71.18). Also, MDGHybrid provides improvement over MatchDG (72.73 versus 72.08). Moreover, on average MatchDG, MDGHybrid are better than many previous approaches <ref type="bibr" target="#b26">[26,</ref><ref type="bibr" target="#b24">24,</ref><ref type="bibr" target="#b35">35,</ref><ref type="bibr" target="#b13">13,</ref><ref type="bibr" target="#b36">36,</ref><ref type="bibr" target="#b55">55,</ref><ref type="bibr" target="#b32">32]</ref>, but some other methods like MASF <ref type="bibr" target="#b20">[20]</ref> achieve higher accuracy than MatchDG. Since MatchDG outperforms all prior work on the same dataset when trained using ResNet-18, ResNet-50 architecture <ref type="table" target="#tab_4">(Table 3)</ref>, we speculate that MatchDG requires a powerful underlying network architecture to use matches effectively for classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2 T-SNE Plots</head><p>Beyond accuracy, we investigate the quality of representations learnt by MatchDG using t-SNE <ref type="bibr" target="#b56">[56]</ref> in <ref type="figure" target="#fig_14">Figure 4</ref>. Comparing the Phase I models for the easiest (Photo) and hardest (Sketch) unseen domains <ref type="figure" target="#fig_14">(Figs. 4a,b</ref>), we find that MatchDG achieves a higher overlap between train and test domains for Photo than Sketch, highlighting the difficulty of generalizing to the Sketch domain, even as classes are well-separated in the training domains for both models <ref type="figure" target="#fig_14">(Figs. 4c,d</ref>).</p><p>E Evaluation on Chest X-ray <ref type="table" target="#tab_3">Table 4</ref> provides the results for evaluation on Chest X-ray dataset, with NIH, ChexPert as the source domains and RSNA being the target domains. Since we have the spurious correlations among the source domains, it could lead to models relying on the unstable trend related to the difference in the position of lungs between class (0) and class <ref type="bibr" target="#b0">(1)</ref>. This could lead to high accuracy on the source domains, however, the models would not perform well on the target domain as no such correlation  <ref type="bibr" target="#b24">[24]</ref>, MTSSL <ref type="bibr" target="#b57">[57]</ref>, CIDDG <ref type="bibr" target="#b13">[13]</ref>, HEX <ref type="bibr" target="#b58">[58]</ref>, Feature-Critic <ref type="bibr" target="#b55">[55]</ref>, MLDG <ref type="bibr" target="#b35">[35]</ref>, REx <ref type="bibr" target="#b32">[32]</ref>, CAADG <ref type="bibr" target="#b59">[59]</ref>, Epi-FCR <ref type="bibr" target="#b36">[36]</ref>, MASF <ref type="bibr" target="#b20">[20]</ref> were taken from the DomainBed <ref type="bibr" target="#b29">[29]</ref> paper. The results for DANN <ref type="bibr" target="#b2">[3]</ref>, IRM <ref type="bibr" target="#b5">[6]</ref>, G2DM <ref type="bibr" target="#b47">[47]</ref> were taken from the G2DM paper. The results for D-MTAE <ref type="bibr" target="#b26">[26]</ref>, MetaReg <ref type="bibr" target="#b48">[48]</ref>, JiGen <ref type="bibr" target="#b34">[34]</ref> were taken from the respective paper. in present in the target domain. We observe in <ref type="table" target="#tab_3">Table 4</ref>, models like ERM, IRM get higher accuracy on source domains, while they obtain worse accuracy on the target domain as compared to the other methods. This implies that ERM, IRM rely more on the unstable correlations present in the source domains.</p><p>The failure of IRM to capture stable trends can be attributed to the presence of spurious correlations without any noise or variation across source domains. This leads to obtaining optimal accuracy on source domains by relying on the spurious features, which would satisfy the IRM penalty as it relies on the loss on the source domains to learn invariant predictors. Hence, minimizing the IRM penalty does not lead to recovering invariant features in this case. In the case of evaluation of IRM on colored MNIST as in the original paper <ref type="bibr" target="#b5">[6]</ref>, the spurious correlation among source domains was present with some noise, which led to IRM penalty recovering the stable/invariant features. In contrast, matching-based methods learn to build a representation using more of the causal features since the regularization objective aims to reduce the differences in representation between inputs belonging to the same object.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>General SCM for domain generalization task.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Structural causal models for the datagenerating process. Observed variables are shaded;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>are a set of (possibly unobserved) counterfactual inputs x (d ) j</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>For example, a neural network with Φ(x) as its rth layer, and h being the rest of the layers. The proof for the next theorem is in Suppl. A.4. Theorem 1. For a finite number of domains m, as the number of examples in each domain n d → ∞, 1. The set of representations that satisfy the condition Ω(j,k)=1;d =d dist(Φ(x</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Theorem 2 .</head><label>2</label><figDesc>Assume training domains such that for any two same-class inputs x</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 2 :</head><label>2</label><figDesc>(a) MatchDG Penalty during the training process (b) IRM Penalty during the training process MatchDG regularization penalty is not trivially minimized even as the training error goes to zero.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 3 :Proposition 1 .</head><label>31</label><figDesc>Causal graphs with the node C as a chain, fork, or a collider. By the d-separation criteria, A and B are conditionally independent given C in (a) and (b). In (c) however, A and B are independent but become conditionally dependent given C.A.3 Proof of Proposition 1 The ERM estimator from (1) learns the true f * , as the set of training domains D m = D and number of data samples n → ∞.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>A. 4 Theorem 1 .</head><label>41</label><figDesc>Proof of Theorem 1 For a finite number of domains m, as the number of examples in each domain n d → ∞, 1. The set of representations that satisfy the condition Ω(j,k)=1;d =d dist(Φ(x (d) j ), Φ(x (d )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>(d) j ) = Φ a (x(d ) k ) for all d, d such that Ω(j, k) = 1, where inputs x j and x k correspond to the same object. Let us assume that there exists at least one object o for which the effect of domain is stochastic. That is, due to domain-dependent variation, P (X a = x a |D = d, O = o) &lt; 1. for some d and o. Now consider a pair of inputs x (d) l and x (d ) i from the same object o such that Ω(l, i) = 1, and their corresponding representations are Φ a (x (d) l ) and Φ a (x (d ) i</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>f * = arg min f ∈F E</head><label>∈F</label><figDesc>(d,x,y) [l(y, f (x))] = arg min h∈F E (d,x,y) [l(y, h(x c ))] = arg min h∈F E (x,y) [l(y, h(x c )] = E[Y |X c ]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>d and d , dist(x (d) a,j , x (d )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>(d) c,j , x (d ) c,k ) ≤ δ c and δ c &lt; δ a (δ c , δ a ∈ R + ). Then for some λ, a loss-minimizing classifier for the loss from(5)is the true function f * , given a P-admissible loss function and a finite number of domains m with n d → ∞ in each domain.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>•</head><label></label><figDesc>NIH: Train (800), Validation (200), Test (430) • ChexPert: Train (2618), Validation (654), Test (1402) • RSNA: Train (3368), Validation (841), Test (1803)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>1 3</head><label>13</label><figDesc>0.1) 99.0 (0.1) 98.9 (0.0) 99.1 (0.1) 99.0 (0.0) 96.7 (0.2RandMatch 96.6 (0.3) 99.1 (0.2) 99.1 (0.1) 98.8 (0.1) 99.1 (0.2) 95.9 (0.2) 98.MatchDG 97.1 (0.1) 99.1 (0.1) 98.9 (0.1) 99.2 (0.2) 99.0 (0.2) 96.5 (0.2) 98.PerfMatch 97.8 (0.2) 99.2 (0.2) 99.1 (0.1) 99.2 (0.1) 99.1 (0.1) 97.2 (0.3) 98.6</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 4 :</head><label>4</label><figDesc>The t-SNE plots for visualizing features learnt in MatchDG Phase 1. (a)-(c) are for Photo as the target domain and (b)-(d) are for Sketch.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Accuracy for Rotated MNIST &amp; Fashion-MNIST datasets on target domains of 0 • and 90 • . Accuracy for CSD [23], MASF [20], IRM [6] are reproduced from their code. (0.67) 93.2 (0.2) 94.7 (0.2) 94.2 (0.32) 95.9 (0.18) 96.1 (0.34) 97.5 (0.17)</figDesc><table><row><cell cols="2">Dataset Source</cell><cell>ERM</cell><cell>MASF</cell><cell>CSD</cell><cell>IRM</cell><cell>RandMatch MatchDG PerfMatch (Oracle)</cell></row><row><cell>Rotated MNIST</cell><cell cols="6">15, 30, 45, 60, 75 93.9 30, 45, 77.9 (2.44) 69.4 (1.32) 79.2 (2.47) 77.6 (1.68) 81.4 (0.77) 86.3 (1.14)</cell><cell>92.0 (0.83)</cell></row><row><cell></cell><cell>60</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>30, 45</cell><cell cols="5">64.6 (3.23) 60.8 (1.53) 68.7 (1.01) 63.1 (3.14) 68.4 (1.78) 74.3 (2.47)</cell><cell>81.7 (2.79)</cell></row><row><cell>Rotated Fashion</cell><cell>15, 30, 45, 60, 75</cell><cell cols="5">78.6 (1.17) 72.4 (2.9) 78.0 (1.5) 79.6 (1.82) 79.4 (0.81) 82.8 (0.27)</cell><cell>86.2 (0.69)</cell></row><row><cell>MNIST</cell><cell>30, 45,</cell><cell cols="5">33.7 (2.24) 25.7 (1.73) 37.2 (1.15) 35.5 (1.51) 38.8 (2.28) 45.6 (1.74)</cell><cell>55.3 (1.54)</cell></row><row><cell></cell><cell>60</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>30, 45</cell><cell cols="5">22.1 (2.36) 20.8 (1.26) 24.9 (1.78) 24.4 (1.01) 25.1 (1.89) 34.9 (1.56)</cell><cell>41.4 (1.58)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Overlap with perfect matches. top-10 overlap and the mean rank for perfect matches for MatchDG and ERM over all training domains. Lower is better for mean rank. , we see that plain ERM objective is unable to minimize the matching loss (and thus MatchDG penalty is needed). This is because MatchDG regularization depends on comparing the (last layer) representations, and zero training error does not mean that the representations within each class are the same. In contrast, regularizations that are based on comparing loss between training domains such as the IRM penalty<ref type="bibr" target="#b5">[6]</ref> can be satisfied by plain ERM as the training error goes to zero(Fig. 2b); similar to Fig. (5) from [32] where ERM can minimize IRM penalty on Colored MNIST.4.2 PACS dataset and Chest X-rays datasetsPACS. On the PACS dataset, our methods are competitive to state-of-the-art results averaged over all domains (Table 3). Given that training procedures often involve data augmentations, we use the augmentations as a separate source of "perfect" matches that are added to learnt matches from MatchDG. The resultant method, MatchDGHybrid has the highest average accuracy across domains, except compared to<ref type="bibr" target="#b33">[33]</ref>. However it is not a fair comparison since Asadi et al. use additional style transfer data from Behance BAM! dataset during training. It is also unclear whether they used source domain or test domain data for model selection, which is why we include them in a separate category in the table. If the validation mechanism used by them includes data from the target domain during validation, then MatchDG (Test), MDGHybrid (Test) obtain better accuracy than them.For comparison with G2DM, we compute average accuracy using the test domain as validation set, where MatchDG obtains a higher accuracy. Finally, we implement MatchDG on Resnet50 model used by the ERM in DomainBed. We find that adding MatchDG loss regularization improves the accuracy of DomainBed, from 85.7 to 87.6 with MatchDGHybrid. Also, MatchDGHybridperforms better than the prior approaches using Resnet50 architecture.</figDesc><table><row><cell cols="2">Dataset Method</cell><cell>Overlap (%)</cell><cell>Top 10 Overlap (%)</cell><cell>Mean Rank</cell></row><row><cell></cell><cell>ERM</cell><cell>18.9 (1.01)</cell><cell>52.4 (1.91)</cell><cell>25.1 (1.43)</cell></row><row><cell>MNIST</cell><cell>MatchDG (Default)</cell><cell>35.1 (5.23)</cell><cell>69.6 (5.97)</cell><cell>14.3 (4.16)</cell></row><row><cell></cell><cell>MatchDG (PerfMatch)</cell><cell>47.6 (5.61)</cell><cell>81.5 (4.70)</cell><cell>8.2 (3.17)</cell></row><row><cell>Fashion MNIST</cell><cell>ERM MatchDG (Default)</cell><cell>3.1 (0.20) 23.9 (2.61)</cell><cell cols="2">14.4 (0.68) 190.6 (7.92) 50.1 (3.29) 79.7 (9.91)</cell></row><row><cell></cell><cell>MatchDG (PerfMatch)</cell><cell>54.7 (4.38)</cell><cell>82.5 (3.07)</cell><cell>15.5 (3.54)</cell></row><row><cell>zero training error</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4</head><label>4</label><figDesc>, last column). The models relying on spurious correlations could get high accuracy on the source domains, however, such models would not perform well on the target domain as no such correlation in present in the target domain. This indicates that approaches like ERM, IRM captured spurious correlations more than MDGHybrid, MatchDG and CSD. Details are in Suppl. E.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Accuracy on PACS with ResNet 18 (default), Resnet 18 with test domain validation, and ResNet 50. The results for JiGen</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>MDGHybrid (ResNet50) 97.98 (0.06) 86.12 (0.73) 83.59 (0.55) 82.77 (0.78) 87.57</figDesc><table><row><cell></cell><cell>Photo</cell><cell>Art Painting</cell><cell>Cartoon</cell><cell>Sketch</cell><cell>Average.</cell></row><row><cell>ERM</cell><cell cols="4">95.84 (0.27) 77.86 (1.29) 76.91 (0.64) 75.43 (0.37)</cell><cell>81.51</cell></row><row><cell>JiGen</cell><cell>96.0</cell><cell>79.42</cell><cell>75.25</cell><cell>71.35</cell><cell>80.41</cell></row><row><cell>MASF</cell><cell cols="4">94.99 (0.09) 80.29 (0.18) 77.17 (0.08) 71.69 (0.22)</cell><cell>81.04</cell></row><row><cell>G2DM</cell><cell>93.75</cell><cell>77.78</cell><cell>75.54</cell><cell>77.58</cell><cell>81.16</cell></row><row><cell>CSD</cell><cell>94.1 (0.2)</cell><cell>78.9 (1.1)</cell><cell>75.8 (1.0)</cell><cell>76.7 (1.2)</cell><cell>81.4</cell></row><row><cell>EpiFCR</cell><cell>93.9</cell><cell>82.1</cell><cell>77.0</cell><cell>73.0</cell><cell>81.5</cell></row><row><cell>MetaReg</cell><cell>95.5 (0.24)</cell><cell>83.7 (0.19)</cell><cell>77.2 (0.31)</cell><cell>70.3 (0.28)</cell><cell>81.7</cell></row><row><cell>S-MLDG</cell><cell>94.80</cell><cell>80.50</cell><cell>77.80</cell><cell>72.80</cell><cell>81.50</cell></row><row><cell>D-SAM</cell><cell>94.30</cell><cell>79.48</cell><cell>77.13</cell><cell>75.30</cell><cell>81.55</cell></row><row><cell>MMLD</cell><cell>96.09</cell><cell>81.28</cell><cell>77.16</cell><cell>72.29</cell><cell>81.83</cell></row><row><cell>DDAIG</cell><cell>95.30</cell><cell>84.20</cell><cell>78.10</cell><cell>74.70</cell><cell>83.10</cell></row><row><cell>SagNet</cell><cell>95.47</cell><cell>83.58</cell><cell>77.66</cell><cell>76.30</cell><cell>83.25</cell></row><row><cell>RandMatch</cell><cell cols="4">96.15 (0.27) 78.99 (0.97) 78.65 (0.68) 76.70 (1.22)</cell><cell>82.62</cell></row><row><cell>MatchDG</cell><cell cols="4">96.47 (0.40) 79.28 (1.01) 79.47 (0.48) 76.94 (1.65)</cell><cell>83.04</cell></row><row><cell>MDGHybrid</cell><cell cols="4">96.77 (0.32) 81.20 (0.18) 80.38 (0.40) 77.23 (1.21)</cell><cell>83.89</cell></row><row><cell>Asadi et al.</cell><cell>96.93</cell><cell>83.01</cell><cell>79.39</cell><cell>78.62</cell><cell>84.46</cell></row><row><cell>G2DM (Test)</cell><cell>94.63</cell><cell>81.44</cell><cell>79.35</cell><cell>79.52</cell><cell>83.34</cell></row><row><cell>RandMatch (Test)</cell><cell cols="4">96.58 (0.32) 80.21 (1.21) 80.06 (0.71) 81.44 (0.58)</cell><cell>84.58</cell></row><row><cell>MatchDG (Test)</cell><cell cols="4">96.73 (0.27) 80.79 (0.39) 81.06 (0.55) 80.34 (0.43)</cell><cell>84.63</cell></row><row><cell>MDGHybrid (Test)</cell><cell></cell><cell></cell><cell></cell><cell>35)</cell><cell>85.11</cell></row><row><cell cols="2">DomainBed (ResNet50) 97.8 (0.0)</cell><cell>88.1 (0.1)</cell><cell>77.9 (1.3)</cell><cell>79.1 (0.9)</cell><cell>85.7</cell></row><row><cell>MASF (ResNet50)</cell><cell cols="4">95.01 (0.10) 82.89 (0.16) 80.49 (0.21) 72.29 (0.15)</cell><cell>82.67</cell></row><row><cell>C-DANN (ResNet50)</cell><cell>97.0 (0.4)</cell><cell>84.0 (0.9)</cell><cell>78.5 (1.5)</cell><cell>71.8 (3.9)</cell><cell>82.8</cell></row><row><cell>MetaReg (ResNet50)</cell><cell>97.6 (0.31)</cell><cell>87.2 (0.13)</cell><cell>79.2 (0.27)</cell><cell>70.3 (0.18)</cell><cell>83.6</cell></row><row><cell>DRO (ResNet50)</cell><cell>98.0 (0.3)</cell><cell>86.4 (0.3)</cell><cell>79.9 (0.8)</cell><cell>72.1 (0.7)</cell><cell>84.1</cell></row><row><cell>Mixup (ResNet50)</cell><cell>97.7 (0.2)</cell><cell>86.5 (0.4)</cell><cell>76.6 (1.5)</cell><cell>76.5 (1.2)</cell><cell>84.3</cell></row><row><cell>IRM (ResNet50)</cell><cell>96.7 (0.3)</cell><cell>85.0 (1.6)</cell><cell>77.6 (0.9)</cell><cell>78.5 (2.6)</cell><cell>84.4</cell></row><row><cell>DANN (ResNet50)</cell><cell>97.6 (0.2)</cell><cell>85.9 (0.5)</cell><cell>79.9 (1.4)</cell><cell>75.2 (2.8)</cell><cell>84.6</cell></row><row><cell>MLDG (ResNet50)</cell><cell>97.0 (0.9)</cell><cell>89.1 (0.9)</cell><cell>78.8 (0.7)</cell><cell>74.4 (2.0)</cell><cell>84.8</cell></row><row><cell>MMD (ResNet50)</cell><cell>97.5 (0.4)</cell><cell>84.5 (0.6)</cell><cell>79.7 (0.7)</cell><cell>78.1 (1.3)</cell><cell>85.0</cell></row><row><cell>CORAL (ResNet50)</cell><cell>97.6 (0.0)</cell><cell>87.7 (0.6)</cell><cell>79.2 (1.1)</cell><cell>79.4 (0.7)</cell><cell>86.0</cell></row><row><cell cols="5">RandMatch (ResNet50) 97.78 (0.18) 83.82 (0.55) 79.44 (0.82) 80.76 (0.38)</cell><cell>85.33</cell></row><row><cell>MatchDG (ResNet50)</cell><cell cols="4">97.93 (0.23) 84.75 (0.78) 81.64 (0.45) 79.36 (0.25)</cell><cell>85.87</cell></row></table><note>97.17 (0.12) 81.90 (0.22) 81.68 (0.11) 79.67 (0.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>Chest X-Rays data. As an upper bound, training ERM on the target domain RSNA yields</figDesc><table><row><cell>73% accuracy.</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="3">NIH (Source) Chex (Source) RSNA (Target)</cell></row><row><cell>ERM</cell><cell>78.9 (0.34)</cell><cell>84.3 (3.52)</cell><cell>55.2 (2.27)</cell></row><row><cell>IRM</cell><cell>79.1 (1.01)</cell><cell>83.4 (2.42)</cell><cell>56.6 (2.04)</cell></row><row><cell>CSD</cell><cell>73.2 (3.35)</cell><cell>83.3 (2.03)</cell><cell>60.5 (0.82)</cell></row><row><cell>RandMatch</cell><cell>75.3 (1.87)</cell><cell>83.6 (1.84)</cell><cell>57.4 (1.76)</cell></row><row><cell>MatchDG</cell><cell>74.7 (0.66)</cell><cell>82.2 (0.68)</cell><cell>58.4 (0.62)</cell></row><row><cell>MDGHybrid</cell><cell>74.3 (0.91)</cell><cell>82.4 (1.03)</cell><cell>62.6 (0.72)</cell></row></table><note>Meta-learning. Meta-learning can be applied to domain generalization, by creating meta-train and meta-test domains within each mini-batch and ensuring that the weight updates perform well on the meta-test domains</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 8 compares</head><label>8</label><figDesc>the accuracy results for MatchDG with prior work on the LeNet architecture [19]. In this setup, there are six domains in total (0 • , 15 • , 30 • , 45 • , 60 • , 75 • ). For each test domain, the remaining five domains are used as source training domains. We observe that matching-based training methods RandMatch and MatchDG outperform prior work. They achieve accuracy almost equal to</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>PerfMatch for target angles (15 • to 60 • ) that lie in between the source domains. For the harder extreme angles of 0 • and 75 • , MatchDG establishes new state-of-the-art accuracy results when compared to all other prior work</figDesc><table><row><cell></cell><cell>Parameter</cell><cell>Optimal Value</cell><cell>Range</cell></row><row><cell>Rotated &amp; Fashion MNIST Table 1 (ResNet-18)</cell><cell>Total Epochs Learning Rate Batch Size</cell><cell>-0.01 16</cell><cell>25 [0.01] [16]</cell></row><row><cell></cell><cell>Weight Decay</cell><cell>0.0005</cell><cell>[0.0005]</cell></row><row><cell></cell><cell>Match Penalty</cell><cell>0.1</cell><cell>[0.1, 1.0]</cell></row><row><cell></cell><cell>IRM Penalty</cell><cell>1.0 (RotMNIST); 0.05 (FashionMNIST)</cell><cell>[0.05, 0.1, 0.5, 1.0, 5.0]</cell></row><row><cell></cell><cell>IRM Threshold</cell><cell>5 (RotMNIST), 0 (FashionMNIST)</cell><cell>[0, 5, 15, 20]</cell></row><row><cell>Rotated MNIST Table 8 (LeNet)</cell><cell>Total Epochs Learning Rate Batch Size</cell><cell>-0.01 16</cell><cell>50 [0.01] [16]</cell></row><row><cell></cell><cell>Weight Decay</cell><cell>0.0005</cell><cell>[0.0005]</cell></row><row><cell></cell><cell>Match Penalty</cell><cell>1.0</cell><cell>[0.1, 1.0]</cell></row><row><cell>Rotated MNIST Table 9 (DomainBed)</cell><cell>Total Epochs Learning Rate Batch Size</cell><cell>-0.01 64</cell><cell>25 [0.01] [16, 32, 64]</cell></row><row><cell></cell><cell>Weight Decay</cell><cell>0.0005</cell><cell>[0.0005]</cell></row><row><cell></cell><cell>Match Penalty</cell><cell>1.0</cell><cell>[0.1, 1.0]</cell></row><row><cell>PACS</cell><cell>Total Epochs</cell><cell>-</cell><cell>50</cell></row><row><cell>Table 3, 14</cell><cell>Learning Rate</cell><cell>Table 7</cell><cell>[0.01, 0.001, 0.0005]</cell></row><row><cell>(ResNet-18, ResNet-50, AlexNet)</cell><cell>Batch Size</cell><cell>16</cell><cell>[16]</cell></row><row><cell></cell><cell>Weight Decay</cell><cell>0.001</cell><cell>[0.001, 0.0005]</cell></row><row><cell></cell><cell>Match Penalty</cell><cell>Table 7</cell><cell>[0.01, 0.1, 0.5, 1.0, 5.0]</cell></row><row><cell>Chest X-ray Table 4 (DenseNet-121)</cell><cell>Total Epochs Learning Rate Batch Size</cell><cell>-0.001 16</cell><cell>40 [0.01, 0.001] [16]</cell></row><row><cell></cell><cell>Weight Decay</cell><cell>0.0005</cell><cell>[0.001, 0.0005]</cell></row><row><cell></cell><cell>Match Penalty</cell><cell>10.0 (RandMatch), 50.0 (MatchDG, MDGHybrid)</cell><cell>[0.1, 1.0, 10.0, 50.0]</cell></row><row><cell></cell><cell>IRM Penalty</cell><cell>10.0</cell><cell>[0.1, 1.0, 10.0, 50.0]</cell></row><row><cell></cell><cell>IRM Threshold</cell><cell>5</cell><cell>[0, 5, 15, 20]</cell></row><row><cell>the oracle case</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 6 :</head><label>6</label><figDesc>MatchDG Phase 1 training details for all the datasets.We did not do hyper parameter tuning as we did for other methods, hence we mention the default value for each hyper parameter that we used. Please note we still did early stopping, the Total Epochs in the table reflects the max budget for training. The specific archiecture used for Phase 1 training is also mentioned for each dataset.</figDesc><table><row><cell>Dataset</cell><cell>Hyper Parameter</cell><cell>Default Value</cell></row><row><cell></cell><cell>Total Epochs</cell><cell>100</cell></row><row><cell></cell><cell>Learning Rate</cell><cell>0.01</cell></row><row><cell>Rotated &amp; Fashion MNIST</cell><cell>Batch Size</cell><cell>256 (Rotated MNIST), 64 (Fashion MNIST)</cell></row><row><cell>Table 1, 8, 9</cell><cell>Weight Decay</cell><cell>0.0005</cell></row><row><cell></cell><cell>τ</cell><cell>0.05</cell></row><row><cell></cell><cell>Architecture</cell><cell>ResNet-18</cell></row><row><cell></cell><cell>Total Epochs</cell><cell>100</cell></row><row><cell></cell><cell>Learning Rate</cell><cell>0.01</cell></row><row><cell>PACS</cell><cell>Batch Size</cell><cell>64</cell></row><row><cell>Table 3, 14</cell><cell>Weight Decay</cell><cell>0.0005</cell></row><row><cell></cell><cell>τ</cell><cell>0.05</cell></row><row><cell></cell><cell>Architecture</cell><cell>ResNet-50</cell></row><row><cell></cell><cell>Total Epochs</cell><cell>100</cell></row><row><cell></cell><cell>Learning Rate</cell><cell>0.01</cell></row><row><cell>Chest X-ray</cell><cell>Batch Size</cell><cell>64</cell></row><row><cell>Table 4</cell><cell>Weight Decay</cell><cell>0.0005</cell></row><row><cell></cell><cell>τ</cell><cell>0.05</cell></row><row><cell></cell><cell>Architecture</cell><cell>DenseNet-121</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 7 :</head><label>7</label><figDesc>Optimal values for hyper parameters on PACS. Batch Size<ref type="bibr" target="#b16">(16)</ref>, Weight Decay (0.001) was consistent across different cases. The Match Penalty for the method MDGHybrid corresponds to (MatchDG penalty, PerfMatch penalty).</figDesc><table><row><cell cols="3">Architecture Hyper Parameter Test Domain ERM</cell><cell cols="3">RandMatch MatchDG(Phase 2) MDGHybrid</cell></row><row><cell></cell><cell>Photo</cell><cell cols="2">0.0005 0.001</cell><cell>0.0005</cell><cell>0.0005</cell></row><row><cell>Learning Rate</cell><cell>Art Painting Cartoon</cell><cell>0.01 0.001</cell><cell>0.01 0.01</cell><cell>0.001 0.001</cell><cell>0.001 0.001</cell></row><row><cell>ResNet-18</cell><cell>Sketch</cell><cell>0.01</cell><cell>0.01</cell><cell>0.01</cell><cell>0.01</cell></row><row><cell>Table 3</cell><cell>Photo</cell><cell>0</cell><cell>0.1</cell><cell>0.1</cell><cell>(0.1, 0.1)</cell></row><row><cell>Match Penalty</cell><cell>Art Painting Cartoon</cell><cell>0 0</cell><cell>0.5 0.1</cell><cell>0.5 1.0</cell><cell>(0.01, 0.1) (0.1, 0.1)</cell></row><row><cell></cell><cell>Sketch</cell><cell>0</cell><cell>0.1</cell><cell>0.5</cell><cell>(0.5, 0.1)</cell></row><row><cell></cell><cell>Photo</cell><cell cols="2">0.0005 0.0005</cell><cell>0.0005</cell><cell>0.0005</cell></row><row><cell>Learning Rate</cell><cell>Art Painting Cartoon</cell><cell>0.001 0.001</cell><cell>0.001 0.0005</cell><cell>0.001 0.0005</cell><cell>0.001 0.0005</cell></row><row><cell>ResNet-50</cell><cell>Sketch</cell><cell>0.01</cell><cell>0.01</cell><cell>0.001</cell><cell>0.001</cell></row><row><cell>Table 3</cell><cell>Photo</cell><cell>0</cell><cell>0.1</cell><cell>0.1</cell><cell>(0.1, 0.1)</cell></row><row><cell>Match Penalty</cell><cell>Art Painting Cartoon</cell><cell>0 0</cell><cell>0.5 0.5</cell><cell>0.1 1.0</cell><cell>(0.01, 0.1) (0.01, 0.1)</cell></row><row><cell></cell><cell>Sketch</cell><cell>0</cell><cell>0.1</cell><cell>0.5</cell><cell>(0.01, 0.1)</cell></row><row><cell>AlexNet</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 2 )</head><label>2</label><figDesc>, we computed matching metrics for MatchDG (Phase 1) over the Fashion-MNIST dataset with 10000 samples per domain. Here we compute the same metrics for a smaller dataset with 2000 samples per domain.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 10 :</head><label>10</label><figDesc>Accuracy results using a fraction of perfect matches during training</figDesc><table><row><cell></cell><cell>MNIST</cell><cell>Fashion-MNIST</cell></row><row><cell>RandMatch</cell><cell>95.9 (0.18)</cell><cell>79.4 (0.81)</cell></row><row><cell>Approx 25%</cell><cell>96.2 (0.35)</cell><cell>80.2 (1.21)</cell></row><row><cell>Approx 50%</cell><cell>96.3 (0.51)</cell><cell>81.8 (0.91)</cell></row><row><cell>Approx 75%</cell><cell>96.6 (0.10)</cell><cell>83.3 (0.63)</cell></row><row><cell cols="2">PerfMatch (100%) 97.5 (0.17)</cell><cell>86.2 (0.69)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 11 :</head><label>11</label><figDesc>Mean rank, Top-10 overlap, and overlap metrics for the matches learnt in the classification phase (Phase 2), when trained on all five source domains in the Rotated MNIST and FashionMNIST datasets.</figDesc><table><row><cell>Dataset</cell><cell>Method</cell><cell cols="2">Overlap (%) Top 10 Overlap (%)</cell><cell>Mean Rank</cell></row><row><cell>Rotated MNIST</cell><cell>RandMatch MatchDG (Phase 2)</cell><cell>2.7 (0.58) 23.9 (2.24)</cell><cell>13.7 (1.88) 48.7 (4.01)</cell><cell>76.2 (4.61) 34.6 (3.66)</cell></row><row><cell></cell><cell>PerfMatch (Oracle)</cell><cell>88.6 (1.57)</cell><cell>98.5 (0.31)</cell><cell>0.59 (0.13)</cell></row><row><cell>Fashion MNIST (10k)</cell><cell>RandMatch MatchDG (Phase 2)</cell><cell>1.0 (0.13) 2.3 (0.03)</cell><cell>5.6 (0.42) 11.1 (0.06)</cell><cell>346.0 (12.80) 241.0 (6.14)</cell></row><row><cell></cell><cell>PerfMatch (Oracle)</cell><cell>7.4 (0.40)</cell><cell>26.9 (0.93)</cell><cell>114.7 (3.04)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table 12 :</head><label>12</label><figDesc>Metrics computed at MatchDG (Phase 1) for Fashion-MNIST dataset with 2K and 10K sample size used for training. Lower is better for mean rank.</figDesc><table><row><cell>Dataset</cell><cell>Method</cell><cell cols="3">Overlap (%) Top 10 Overlap (%) Mean Rank</cell></row><row><cell>Fashion MNIST (2k)</cell><cell>ERM MatchDG (Default)</cell><cell>8.7 (0.14) 61.5 (2.11)</cell><cell>36.0 (1.41) 88.2 (0.91)</cell><cell>36.1 (1.66) 5.9 (0.54)</cell></row><row><cell></cell><cell>MatchDG (PerfMatch)</cell><cell>69.5 (10.8)</cell><cell>91.9 (5.8)</cell><cell>3.3 (2.4)</cell></row><row><cell>Fashion MNIST</cell><cell>ERM MatchDG (Default)</cell><cell>3.1 (0.20) 23.9 (2.61)</cell><cell>14.4 (0.68) 50.1 (3.29)</cell><cell>190.6 (7.92) 79.7 (9.91)</cell></row><row><cell></cell><cell>MatchDG (PerfMatch)</cell><cell>54.7 (4.38)</cell><cell>82.5 (3.07)</cell><cell>15.5 (3.54)</cell></row><row><cell cols="3">C.6 Iterative updating of matches in Phase-1 of MatchDG</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table 13 :</head><label>13</label><figDesc>Overlap with perfect matches. top-10 overlap and the mean rank for perfect matches for Iterative and Non Iterative MatchDG over all training domains. Lower is better for mean rank.</figDesc><table><row><cell>Dataset</cell><cell>Method (Phase 1)</cell><cell cols="3">Overlap (%) Top 10 Overlap (%) Mean Rank</cell></row><row><cell></cell><cell>MatchDG(Iterative)</cell><cell>35.1 (5.23)</cell><cell>69.6 (5.97)</cell><cell>14.3 (4.16)</cell></row><row><cell>MNIST</cell><cell>MatchDG(Non Iterative)</cell><cell>13.5 (0.80)</cell><cell>38.0 (1.27)</cell><cell>39.9 (1.99)</cell></row><row><cell>Fashion</cell><cell>MatchDG(Iterative)</cell><cell>23.9 (2.61)</cell><cell>50.1 (3.29)</cell><cell>79.7 (9.91)</cell></row><row><cell>MNIST (10k)</cell><cell>MatchDG(Non Iterative)</cell><cell>7.3 (0.41)</cell><cell>23.7 (1.55)</cell><cell>150.9 (7.77)</cell></row><row><cell cols="2">D Additional Evaluation on PACS</cell><cell></cell><cell></cell><cell></cell></row></table><note>D.1 AlexNet Results</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18"><head>Table 14 :</head><label>14</label><figDesc>Accuracy results on the PACS dataset trained with Alexnet (Default), Alexnet with test domain validation. The results for DBADG</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/facebookresearch/InvariantRiskMinimization 2 https://github.com/vihari/CSD 3 https://github.com/biomedia-mira/masf</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We would like to thank Adith Swaminathan, Aditya Nori, Emre Kiciman, Praneeth Netrapalli, Tobias Schnabel, and Vineeth Balasubramanian who provided us valuable feedback on this work. We also thank Vihari Piratla who helped us with reproducing the CSD method and other baselines.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Domain generalization via invariant feature representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krikamol</forename><surname>Muandet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Balduzzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="10" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Domain generalization with adversarial feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoliang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiqi</forename><surname>Sinno Jialin Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><forename type="middle">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5400" to="5409" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Domain-adversarial training of neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaroslav</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniya</forename><surname>Ustinova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hana</forename><surname>Ajakan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Germain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">François</forename><surname>Laviolette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Marchand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2096" to="2030" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Domain generalization via conditional invariant representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ya</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingming</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinmei</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tongliang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dacheng</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Second AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Scatter component analysis: A unified framework for domain adaptation and domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammad</forename><surname>Ghifary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Balduzzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengjie</forename><surname>Bastiaan Kleijn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="1414" to="1430" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishaan</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.02893</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">Invariant risk minimization. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Domain adaptation with conditional transferable components</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingming</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tongliang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dacheng</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clark</forename><surname>Glymour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2839" to="2848" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christina</forename><surname>Heinze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-Deml</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolai</forename><surname>Meinshausen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.11469</idno>
		<title level="m">Conditional variance penalties and domain shift robustness</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">On learning invariant representation for domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Remi</forename><surname>Tachet Des Combes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">J</forename><surname>Gordon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.09453</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Generalizing across domains via cross-gradient training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiv</forename><surname>Shankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vihari</forename><surname>Piratla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumen</forename><surname>Chakrabarti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddhartha</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preethi</forename><surname>Jyothi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sunita</forename><surname>Sarawagi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Simultaneous deep transfer across domains and tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judy</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="4068" to="4076" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Domain generalization via multidomain discriminant analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shoubo</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhitang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laiwan</forename><surname>Chan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Uncertainty in artificial intelligence: proceedings of the</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<title level="m">Conference on Uncertainty in Artificial Intelligence</title>
		<imprint>
			<publisher>NIH Public Access</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">35</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Deep domain generalization via conditional invariant adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ya</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinmei</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingming</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yajing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tongliang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dacheng</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="624" to="639" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judea</forename><surname>Pearl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Causality</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>Cambridge university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">On loss functions which minimize to conditional expected values and posterior probabilities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rod</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Padhraic</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smyth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1404" to="1408" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Domain adaptation by using causal inference to predict invariant conditional distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sara</forename><surname>Magliacane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Thijs Van Ommen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Claassen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Bongers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joris M</forename><surname>Versteeg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mooij</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="10846" to="10856" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Support and invertibility in domaininvariant representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Fredrik D Johansson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajesh</forename><surname>Sontag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ranganath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 22nd International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="527" to="536" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kartik</forename><surname>Ahuja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karthikeyan</forename><surname>Shanmugam</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.04692</idno>
		<title level="m">Kush Varshney, and Amit Dhurandhar. Invariant risk minimization games</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Unified deep supervised domain adaptation and generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saeid</forename><surname>Motiian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Piccirilli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Donald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gianfranco</forename><surname>Adjeroh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Doretto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5715" to="5725" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Domain generalization via model-agnostic learning of semantic features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Coelho De Castro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantinos</forename><surname>Kamnitsas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Glocker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6447" to="6458" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.05709</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Momentum contrast for unsupervised visual representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.05722</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Efficient domain generalization via common-specific low-rank decomposition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vihari</forename><surname>Piratla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Praneeth</forename><surname>Netrapalli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sunita</forename><surname>Sarawagi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference of Machine Learning (ICML) 2020</title>
		<meeting>the International Conference of Machine Learning (ICML) 2020</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Deeper, broader and artier domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Da</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Zhe</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5542" to="5550" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Chestx-ray8: Hospital-scale chest x-ray database and benchmarks on weaklysupervised classification and localization of common thorax diseases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaosong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifan</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammadhadi</forename><surname>Bagheri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronald M</forename><surname>Summers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2097" to="2106" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Domain generalization for object recognition with multi-task autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammad</forename><surname>Ghifary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengjie</forename><surname>Bastiaan Kleijn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Balduzzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2551" to="2559" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Chexpert: A large chest radiograph dataset with uncertainty labels and expert comparison</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeremy</forename><surname>Irvin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Ko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silviana</forename><surname>Ciurea-Ilcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Chute</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henrik</forename><surname>Marklund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Behzad</forename><surname>Haghgoo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robyn</forename><surname>Ball</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katie</forename><surname>Shpanskaya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="590" to="597" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Kaggle: Rsna pneumonia detection challenge</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishaan</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.01434</idno>
		<title level="m">search of lost domain generalization</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Diva: Domain invariant variational autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maximilian</forename><surname>Ilse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jakub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christos</forename><surname>Tomczak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Louizos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Medical Imaging with Deep Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="322" to="348" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Explaining and harnessing adversarial examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Szegedy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6572</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Out-of-distribution generalization via risk extrapolation (rex)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ethan</forename><surname>Caballero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joern-Henrik</forename><surname>Jacobsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amy</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Binas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Remi</forename><surname>Le Priol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.00688</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Towards shape biased unsupervised representation learning for domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nader</forename><surname>Asadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Amir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehrdad</forename><surname>Sarfi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zahra</forename><surname>Hosseinzadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mahdi</forename><surname>Karimpour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Eftekhari</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.08245</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Domain generalization by solving jigsaw puzzles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fabio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio D&amp;apos;</forename><surname>Carlucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvia</forename><surname>Innocente</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Bucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tatiana</forename><surname>Caputo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tommasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2229" to="2238" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Learning to generalize: Meta-learning for domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Da</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Zhe</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Second AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Episodic training for domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Da</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianshu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Zhe</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1446" to="1455" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Sequential learning for domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Da</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Zhe</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Hospedales</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.01377</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Domain generalization with domain-specific aggregation modules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Antonio D&amp;apos;innocente</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Caputo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">German Conference on Pattern Recognition</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="187" to="198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Domain generalization using a mixture of multiple latent domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toshihiko</forename><surname>Matsuura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tatsuya</forename><surname>Harada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="11749" to="11756" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Deep domain-adversarial image generation for domain generalisation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiyang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Xiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="13025" to="13032" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Reducing domain gap via style-agnostic networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyeonseob</forename><surname>Nam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyunjae</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jongchan</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wonjun</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donggeun</forename><surname>Yoo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.11645</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Distributionally robust neural networks for group shifts: On the importance of regularization for worst-case generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiori</forename><surname>Sagawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pang</forename><surname>Wei Koh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Tatsunori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Liang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.08731</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minghao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingbing</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Teng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengjie</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjun</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.01805</idno>
		<title level="m">Adversarial domain adaptation with domain mixup</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Improve unsupervised domain adaptation with mixup training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huan</forename><surname>Shen Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nanxiang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lincan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liu</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ren</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.00677</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Heterogeneous domain generalization via domain mixup</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yufei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoliang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><forename type="middle">C</forename><surname>Kot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="3622" to="3626" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Deep coral: Correlation alignment for deep domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baochen</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="443" to="450" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Generalizing to unseen domains via distribution matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">João</forename><surname>Isabela Albuquerque</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Monteiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Darvishi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Tiago</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Falk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mitliagkas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Metareg: Towards domain generalization using meta-regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yogesh</forename><surname>Balaji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Swami</forename><surname>Sankaranarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rama</forename><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="998" to="1008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Invariant models for causal transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mateo</forename><surname>Rojas-Carulla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Turner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonas</forename><surname>Peters</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1309" to="1342" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Causal inference by using invariant prediction: identification and confidence intervals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonas</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Bühlmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolai</forename><surname>Meinshausen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society: Series B (Statistical Methodology)</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="947" to="1012" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonglong</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilip</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.05849</idno>
		<title level="m">Contrastive multiview coding</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Generalizing to unseen domains via adversarial data augmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Riccardo</forename><surname>Volpi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongseok</forename><surname>Namkoong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ozan</forename><surname>Sener</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vittorio</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Murino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5334" to="5344" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Frustratingly easy semi-supervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hal</forename><surname>Daumé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avishek</forename><surname>Saha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 Workshop on Domain Adaptation for Natural Language Processing</title>
		<meeting>the 2010 Workshop on Domain Adaptation for Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="53" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">On the limits of cross-domain generalization in automated x-ray prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Paul Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Hashir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rupert</forename><surname>Brooks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hadrien</forename><surname>Bertrand</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.02497</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Feature-critic networks for heterogeneous domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiying</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.11448</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Visualizing data using t-sne</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Improving out-of-distribution generalization via multi-task self-supervised pretraining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikhil</forename><surname>Isabela Albuquerque</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junnan</forename><surname>Naik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Keskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Socher</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.13525</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haohan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zexue</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zachary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Lipton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xing</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.06256</idno>
		<title level="m">Learning robust representations by projecting superficial statistics out</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Correlation-aware adversarial domain adaptation and generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clinton</forename><surname>Mohammad Mahfujur Rahman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mahsa</forename><surname>Fookes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sridha</forename><surname>Baktashmotlagh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sridharan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="page">107124</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
