<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Pixel Consensus Voting for Panoptic Segmentation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haochen</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruotian</forename><surname>Luo</surname></persName>
							<email>rluo@ttic.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
							<email>mmaire@uchicago.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Shakhnarovich</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">TTI-Chicago</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">University of Chicago</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">TTI-Chicago</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Pixel Consensus Voting for Panoptic Segmentation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T09:49+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The core of our approach, Pixel Consensus Voting, is a framework for instance segmentation based on the Generalized Hough transform. Pixels cast discretized, probabilistic votes for the likely regions that contain instance centroids. At the detected peaks that emerge in the voting heatmap, backprojection is applied to collect pixels and produce instance masks. Unlike a sliding window detector that densely enumerates object proposals, our method detects instances as a result of the consensus among pixel-wise votes. We implement vote aggregation and backprojection using native operators of a convolutional neural network. The discretization of centroid voting reduces the training of instance segmentation to pixel labeling, analogous and complementary to FCN-style semantic segmentation, leading to an efficient and unified architecture that jointly models things and stuff. We demonstrate the effectiveness of our pipeline on COCO and Cityscapes Panoptic Segmentation and obtain competitive results. Code will be open-sourced.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The development of visual recognition algorithms has followed the evolution of recognition benchmarks. PAS-CAL VOC <ref type="bibr" target="#b12">[13]</ref> standardizes the task of bounding box object detection and the associated IoU/Average Precision metrics. At the time, the approaches defining the state-ofthe-art, DPM <ref type="bibr" target="#b13">[14]</ref> and later the R-CNN family <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b48">49]</ref>, address object detection by reasoning about densely enumerated box proposals, following the sliding window classification approach of earlier detectors <ref type="bibr" target="#b53">[54,</ref><ref type="bibr" target="#b52">53]</ref>. SDS <ref type="bibr" target="#b18">[19]</ref> expands the scope of object detection to include instance mask segmentation, and introduces early versions of mAP bbox and mAP mask , subsequently popularized by the COCO dataset <ref type="bibr" target="#b35">[36]</ref>. Bounding boxes, however, remain the primary vehicle for object reasoning.</p><p>The more recently introduced task of panoptic segmentation <ref type="bibr" target="#b23">[24]</ref> removes the notion of boxes altogether. It treats * Work done when Haochen was at UChicago and working at TTI-C both "things" and "stuff" in a unified format, in which ground truth and predictions are expressed as labelled segment masks: instance and category for objects ("things"), and category only for "stuff" <ref type="bibr" target="#b4">[5]</ref>.</p><p>Our work focuses on this particular framework of image understanding. We propose an approach, Pixel Consensus Voting (PCV), that in line with this updated task definition, elevates pixels to first class citizen status. Every pixel contributes evidence for the presence, identity, and location of an object to which it may belong. PCV aggregates and backprojects this evidence, in a Hough transformlike framework, so that detections emerge from the consensus among pixels that vote for consistent object hypotheses. <ref type="figure">Figure 1</ref> summarizes our approach.</p><p>Notably, and in contrast to the currently dominant line of detection work derived from the R-CNN family <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b6">7]</ref>, our approach does not involve reasoning about bounding boxes. It can be seen as a descendant of early Hough-based methods such as the Implicit Shape Model (ISM) <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b28">29]</ref>, traditionally referred to as "bottom-up". We extend these earlier works and leverage the power of convolutional networks for feature extraction. Since these features have large receptive fields and presumably capture high-level semantic concepts, it is unclear whether the bottom-up designation remains appropriate. Another distinction from prior attempts to use voting is our vote representation. Traditional methods treat voting as offset regression, and suffers from the problem of "regressing to the mean", where prediction is conflated with uncertainty. In PCV, we treat voting for object location as classification over discretized spatial cells. This allows for the representation of uncertainty and for "abstention" votes by non-object pixels. It also lends itself to efficient vote aggregation and backprojection using (dilated <ref type="bibr" target="#b57">[58]</ref>) convolutional mechanisms.</p><p>Despite its simplicity, PCV achieves competitive results on COCO and Cityscapes panoptic segmentation benchmarks. On COCO, PCV outperforms all existing proposalfree or single-stage detection methods. Our work revisits a classic idea from a modern perspective, and we expect that future research extending our approach will yield major performance gains and novel insights.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discretization &amp; Classification</head><p>Voting as Transposed Convolution Backprojection as Filtering <ref type="figure">Figure 1</ref>: An overview of PCV. Left: A large region around each pixel is discretized into spatial cells according to the Voting Filter. The size of the cells expands the farther they are from the pixel. A convnet votes for the location of the instance to which the pixel belongs, in the form of a probability distribution over the cells that might contain the instance centroid; a pixel can also vote for "abstaining" (not belonging to any object). Middle: The votes from each pixel are aggregated into a voting heatmap, using dilated deconvolution (transposed conv). Peak Regions of the heatmap are treated as initial instance detection hypotheses. Right: Query Filter, the spatial inversion of the Voting Filter, is convolved with each peak region to backproject an instance mask for that peak. Not shown: the semantic segmentation branch assigns categories to things and stuff. See also <ref type="figure" target="#fig_6">Fig. 7</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>Sliding window detection Over the last two decades, most approaches to object detection and instance segmentation have followed the general pipeline by ranking sliding window proposals. In a typical setup, a large number of candidate regions are sampled from an input image and a predictor (usually a convolutional network) scores each region's likelihood to intersect with objects. For highly ranked proposals, the network also predicts their categories, bounding box coordinates, and optionally generates instance masks. Two stage methods, such as Faster/Mask R-CNN <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b19">20]</ref> use regional feature pooling as an attention mechanism to enhance prediction accuracy, while single stage methods, including YOLO <ref type="bibr" target="#b46">[47]</ref>, RetinaNet <ref type="bibr" target="#b34">[35]</ref> and SSD <ref type="bibr" target="#b37">[38]</ref>, combine all network decisions in a single feedforward pass. Another line of work eschews object proposals and predicts keypoint heatmap as a proxy for object localization <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b60">61,</ref><ref type="bibr" target="#b51">52,</ref><ref type="bibr" target="#b59">60]</ref>.</p><p>Instances from pixels Many attempts have been made to establish a direct connection between image pixels and instance segmentations. A natural idea to group pixels into instances is to obtain some measure of pixel affinity for clustering. In <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b42">43]</ref>, a network is trained to produce pixel embeddings that are similar within and different across instances, and an off-the-shelf clustering algorithm is used for grouping. RPE <ref type="bibr" target="#b25">[26]</ref> integrates the clustering step into the learning process by formulating mean-shift clustering as a recurrent neural network. AdaptIS <ref type="bibr" target="#b50">[51]</ref> further improves the training of discriminative embeddings by a novel scheme that provides end-to-end supervision. In addition, exploit-ing the sparsity in pairwise pixel affinity makes it possible to instantiate the clustering step as a graph-cut. Learning the sparse pixel affinity can be formulated as boundary detection <ref type="bibr" target="#b24">[25]</ref>, or a richer multi-hop dilated connectivity prediction <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b38">39]</ref>. Alternatively, instances may be generated sequentially using a recurrent neural network <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b49">50]</ref>, or treated as watershed basins through a learned boundary distance transform <ref type="bibr" target="#b1">[2]</ref>.</p><p>Detections via Generalized Hough transform The Hough transform <ref type="bibr" target="#b11">[12]</ref> frames the task of detecting analytical shapes as identifying peaks in a dual parametric space; this idea can be generalized <ref type="bibr" target="#b2">[3]</ref> to arbitrary objects. The gist of the Generalized Hough transform is to collect local evidence as votes for the likely location, scale, and pose of potential instances. Works in this vein such as Implicit Shape Models <ref type="bibr" target="#b27">[28]</ref> rely on memorized mapping from image patches to offsets, and is later improved by the use of more advanced learning techniques <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b14">15]</ref>. It has been applied to a variety of problems including pose estimation <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b3">4]</ref>, tracking <ref type="bibr" target="#b14">[15]</ref> and 3D object detection <ref type="bibr" target="#b45">[46]</ref>. Our work can be seen as a descendant of these earlier efforts. Some recent works follow broadly similar philosophy, but differ from ours in many ways. Most <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b56">57]</ref> treat learning to vote for object centroids as a regression task. Our work avoids the potential limitations of offset regression and uses discretized region classification to capture pixel-level uncertainty. We design convolutional mechanisms for efficient vote aggregation and backprojection under this classification setting.</p><p>To our knowledge, the only prior work using transposed convolution i.e. deconv for classification-based pixel voting is <ref type="bibr" target="#b32">[33]</ref>, applied to single person pose estimation. We take inspiration from their work, but differ in motivation and implementation.</p><p>Panoptic Segmentation Most existing work address panoptic segmentation by merging the outputs from specialized components designed for instance <ref type="bibr" target="#b19">[20]</ref> and semantic segmentation <ref type="bibr" target="#b58">[59,</ref><ref type="bibr" target="#b5">6]</ref> with greedy heuristics <ref type="bibr" target="#b23">[24]</ref>. PFPN <ref type="bibr" target="#b22">[23]</ref> establishes a strong single network baseline by sharing the FPN <ref type="bibr" target="#b33">[34]</ref> feature for Mask R-CNN <ref type="bibr" target="#b19">[20]</ref> and FCN <ref type="bibr" target="#b39">[40]</ref> sub-branches. <ref type="bibr" target="#b55">[56,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b36">37]</ref> improve the segment overlap resolution with learned modules. <ref type="bibr" target="#b54">[55,</ref><ref type="bibr" target="#b10">11]</ref> trade off the performance for speed by using single-stage object detectors. Proposal-free methods <ref type="bibr" target="#b50">[51,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b7">8]</ref> provide novel perspectives that directly model instances from pixels, but in general lag behind the performance of those leveraging mature engineering solutions, with an especially large gap on the challenging COCO <ref type="bibr" target="#b35">[36]</ref> benchmark.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Pixel Consensus Voting</head><p>Given an input image, PCV starts with a convolutional neural network extracting a shared representation (feature tensor) that is fed to two independent sub-branches <ref type="figure" target="#fig_1">(Fig. 2)</ref>. The semantic segmentation branch predicts the category label for every pixel. The instance voting branch predicts for every pixel whether the pixel is part of an instance mask, and if so, the relative location of the instance mask centroid. This prediction is framed as classification over a set of grid cells around a pixel according to the Voting Filter. Both branches are trained with standard cross-entropy loss.</p><p>The predictions from the voting branch are aggregated into a voting heatmap (accumulator array in the Hough transform terminology). A key technical innovation of PCV is a dilated convolutional mechanism that implements this efficiently. Local maxima of the heatmap are detection candidates. At each peak region, we convolve a Query Filter to backproject the pixels that favor this particular peak above all others. These pixels together form a category-agnostic instance segmentation mask. Finally, we merge the instance and semantic segmentation masks using a simple greedy strategy, yielding a complete panoptic segmentation output.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Backbone and Feature Extraction</head><p>Our work develops a meta architecture to model and segment instances. To this end, PCV reduces the training of instance recognition to pixel labelling, which can be tackled by various implementations of Fully Convolutional Networks <ref type="bibr" target="#b39">[40]</ref>. We follow the design of UPSNet <ref type="bibr" target="#b55">[56]</ref>, which repurposes a Feature Pyramid Network (FPN) <ref type="bibr" target="#b33">[34]</ref> with a ResNet backbone <ref type="bibr" target="#b20">[21]</ref> for semantic segmentation. Features  from each stage of FPN, respectively at 1/32, 1/16, 1/8 and 1/4 of input resolution, first go through a shared deformable convolution module before being upsampled to a uniform size of 1/4 of the input scale. Channel dimensions of the feature maps are reduced from 256 to 128 with 1 × 1 conv before channel-wise concatenation. On top of this, we apply a 1 × 1 conv, softmax and 4× nearest neighbor upsampling to generate per-pixel labels. Note that we apply softmax first, before upsampling, since it is faster to produce instance masks at a lower resolution. The semantic segmentation branch predicts the labels for all categories, and is different from PFPN <ref type="bibr" target="#b22">[23]</ref>, which lumps all "thing" classes into a single category.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Region Discretization</head><p>Consider an instance mask consisting of a set of pixels</p><formula xml:id="formula_0">{p i | p i ∈ R 2 } N i=1</formula><p>, and the instance center of mass c = 1 N p i . Predicting the relative offset δ i = c − p i from a pixel is typically treated as offset regression <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b43">44]</ref>. But a direct regression limits the ability of the system to represent uncertainty, and suffers from the typical problem of "regressing to the mean". A pixel unsure about its instance centroid location might hedge by pointing between multiple candidates, creating spurious peaks and false positives. Moreover, it is impossible to attribute such pixels to object hypotheses during backprojection. We instead frame voting as classification among possible spatial cells where the centroid may reside. The probability histogram produces an explicit distribution for downstream reasoning.</p><p>Voting Filter Unlike YOLO <ref type="bibr" target="#b46">[47]</ref>, which divides up the entire image into a grid of regularly tiled patches, we consider a discretization of the region centered around each pixel. See <ref type="figure">Fig. 1 (left)</ref> for a visual illustration. For a particular pixel p i , we map each of the M × M pixels centered <ref type="bibr">12 12 12 13 13 13 14 14 14</ref> Ground Truth Assignment 10 10 10 9 9 9 16 16 16 10 10 10 9 9 9 16 16 16 10 10 10 9 9 9 16 16 16 <ref type="table" target="#tab_5">11 11 11 2 1 8 15 15 15   11 11 11 3 0 7 15 15 15   11 11 11 4 5 6 15 15 15   12 12 12 13 13 13 14 14 14   12 12 12 13 13 13 14 14 14   12 12 12 13 13 13 14 14 14</ref> 10 10 10 9 9 9 16 16 16 10 10 10 9 9 9 16 16 16 10 10 10 9 9 9 16 16 16 11 <ref type="bibr" target="#b10">11</ref>   around p i to K discrete indices. This mapping can be naturally recorded with a translation invariant lookup table of size M × M . By overlaying the lookup table on top of p i , the ground truth index for classification can be directly read off from the spatial cell into which the instance centroid falls. We refer to this lookup table as the Voting Filter. <ref type="figure" target="#fig_2">Fig. 3</ref> shows a toy example. For stuff pixels that do not belong to any instances, we create an "abstention" label as an extra class, and hence there are in total K + 1 classes for the instance voting branch. If the instance centroid falls outside the extent of the Voting Filter, i.e. the pixel is too far away from the centroid, we ignore it during training.</p><p>Scale vs. Accuracy Discretization implies a loss of spatial accuracy, but we argue that knowing the exact location of the centroid is not necessary for accurate instance segmentations. What matters is the consensus among pixels that enables backprojection. Large instances can naturally tolerate coarser predictions than small objects, as seen in <ref type="figure">Fig. 5</ref>. We construct the Voting Filter so that the farther the distance from the instance centroid, the larger the spatial cell. A naive evenly spaced grid would have to either be too fine, introducing too many classes for the network to learn and converge, or too coarse to allow accurate predictions for smaller objects. Based on these considerations, we propose a grid of square cells whose size expands radially outward, as shown in <ref type="figure">Fig. 4</ref>. It involves K = 233 cells over a region of M = 243 pixels applied to images at 1/4 input resolution, thus covering up to 972 × 972 at full resolution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Voting as Transposed Convolution</head><p>The instance voting branch yields a tensor of size [H, W, K + 1], where K + 1 is the number of distinct voting possibilities, including abstention by stuff pixels. We use dilated deconvolution and average pooling to aggregate the probabilistic votes to their intended spatial locations. cates a pixel whose votes we inspect. We only display cells which receive a vote stronger than 0.01 Left: pixels distant from the object center (like the front skier's foot) can afford more slack/spatial uncertainty, voting for larger cells near grid perimeter. Right: Pixels of small objects (the back skier's foot) need more spatial accuracy, and vote for small cells near the grid center.</p><p>Recall our toy example in <ref type="figure" target="#fig_2">Fig. 3</ref>. Say the blue pixel predicts a probability of 0.9 for its instance centroid to fall into cell 16, which consists of 9 pixels. Voting involves two steps: 1) transfer the probability 0.9 to cell 16, and 2) share the vote evenly among the 9 constituent pixels, with each pixel receiving 0.1. We implement step 1 with dilated deconvolution (deconv), and step 2 with average pooling.</p><p>Transposed convolution, or deconvolution by convention, spreads a point signal over multiple spatial locations, whereas a conv kernel aggregates spatial information to a single point. It is most often used during the backpropagation of a convnet, as well as feature upsampling. The parameters of a deconv kernel can be learned. For the purpose of vote aggregation, however, we fix the deconv kernel parameters to 1-hot across each channel that marks the target location. Dilation in this case enables a pixel to cast its vote to faraway points. Note that for every deconv kernel, there exists an equivalent conv kernel, and vice versa. The distinction is superfluous, but thinking of and implementing voting as deconv is more natural.</p><p>Our toy Voting Filter in <ref type="figure" target="#fig_2">Fig. 3</ref> discretizes the 9 × 9 region into inner 3×3 cells of side length 1, encircled by outer 3 × 3 cells of side length 3, hence K = 9 + 8 = 17 voting classes. At step 1, after discarding abstention votes, we split the [H, W, 17] tensor along channels into two components of size [H, <ref type="bibr">W, 9]</ref> and [H, W, 8], and apply two deconv kernels of size [C in =9, C out =1, H =3, W =3] with dilation 1 and [C in =8, C out =1, H=3, W=3] with dilation 3 to produce 10 10 10 9 9 9 16 16 16 11 11 <ref type="table" target="#tab_5">11 2 1 8 15 15 15  11 11 11 3 0 7 15 15 15  11 11 11 4 5 6 15 15 15  12 12 12 13 13 13 14 14 14  12 12 12 13 13 13 14 14 14  12 12 12 13 13 13 14 14 14   12 11 10 9 24  20 19 18 17 16  20 19 18 17 16  13 2 1 8 23  21 6 5 4 15  21 6 5 4 15  14 3 0 7 22  22 7 0 3 14  22 7 0 3 14  15 4 5 6 21  23 8 1 2 13  23 8 1 2 13  16 17 18 19 20  24 9 10 11 12  24 9 10 11 12</ref> -1 -1 18 -1 -1 9 10 -1 23 8 21 6 5 4 15 -1 -1 -1 24 9 -1 -1 0 -1 22 6 -1 -1 -1 -1 24 8 -1 2 23 7 0 3 14 -1 24 9 -1 11 12 -1 1 -  <ref type="table" target="#tab_5">12 12 12 13 13 13 14 14 14  12 12 12 13 13 13 14 14 14  12 12 12 13 13 13 14 14 14   12 11 10 9 24  20 19 18 17 16  20 19 18 17 16  13 2 1 8 23  21 6 5 4 15  21 6 5 4 15  14 3 0 7 22  22 7 0 3 14  22 7 0 3 14  15 4 5 6 21  23 8 1 2 13  23 8 1 2 13  16 17 18 19 20  24 9 10 11 12  24 9 10 11 12</ref> -1 -1 18 -1 -1 9 10 -1 23 8 21 6 5 4 15 -1 -1 -1 24 9 -1 -1 0 -1 22 6 -1 -1 -1 -1 24 8 -1 2 23 7 0 3 14 -1 24 9 -1 11 12 -1 1 -  <ref type="table" target="#tab_5">12 12 12 13 13 13 14 14 14  12 12 12 13 13 13 14 14 14   12 12 12 13 13 13 14 14 14   12 11 10 9 24  20 19 18 17 16  20 19 18 17 16  13 2 1 8 23  21 6 5 4 15  21 6 5 4 15  14 3 0 7 22  22 7 0 3 14  22 7 0 3 14   15 4 5 6 21  23 8 1 2 13  23 8 1 2 13  16 17 18 19 20  24 9 10 11 12  24 9 10 11</ref>   The Query Filter is convolved within each peak region to produce instance masks. For simplicity a peak region here is a single red point, but is in general a connected component of pixels, and hence the need for convolving the Query Filter. −1 denotes pixels whose argmax voting decision is abstention i.e. "stuff" pixels. Where the Query Filter disagrees with the argmax voting indices, the pixels are not included in the instance masks.</p><p>two heatmaps H dilate1 , H dilate3 , both of size [H, W, 1].</p><p>After step 1, all the votes have been sent to the center of each spatial cell. At step 2, we smooth out the votes evenly within each cell. Smoothing in this particular case is exactly equivalent to average pooling. We apply 3 × 3 average pooling on H dilate3 , and 1 × 1 average pooling on H dilate1 (an identity operation). The two heatmaps are then summed together to complete the final voting heatmap. The voting process for other instantiations of Voting Filter can be done analogously. Voting with our default grid design takes on average 1.3 ms over COCO images, show in <ref type="table" target="#tab_8">Table  5</ref>.</p><p>Peaks in the voting heatmap correspond to consensus detections, and we use a simple strategy of thresholding followed by connected components to locate the peaks. We define a peak region, which identifies a hypothesized instance, as a connected component of pixels that survive after thresholding the voting heatmap. We set the threshold value to 4.0 for both COCO and Cityscapes. See <ref type="figure" target="#fig_6">Fig. 7</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Backprojection as Filtering</head><p>Backprojection aims to determine for every peak region the pixels that favor this particular maximum above all others. To do this we make use of the Query Filter. Recall that the Voting Filter records the class label a pixel at the center of the filter should predict given possible centroid lo-cations around. The Query Filter is the spatial inversion of the Voting Filter. It records the class labels the surrounding pixels should predict for the instance centroid at the center of the filter. This dual relationship is shown in the top row of <ref type="figure" target="#fig_5">Fig. 6</ref>.</p><p>During backprojection, we first obtain the argmax voting index at each pixel. This is a tensor of size [H, W, 1]. Then, within a peak region, we convolve the Query Filter and perform equality comparison against the argmax voting indices to pick up all the pixels whose strongest vote falls within this peak region. <ref type="figure" target="#fig_5">See Fig. 6</ref>, bottom row. This operation is parallelizable and can be implemented to run on a GPU. In practice, we extend the equality comparison to top 3 votes rather than just the argmax vote, so that a pixel whose argmax decision is wrong is not completely abandoned. If a single pixel is contested by multiple peaks, the pixel is assigned to the peak region whose total vote count is the highest. In the edge case where multiple peaks are within the same spatial cell with respect to the pixel, the pixel goes to the spatially nearest peak (this distance is measured from the center of the enclosing bounding box of the peak region to the pixel).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Segment Loss Normalization</head><p>Training a network to solve pixel labeling problems such as ours usually involves averaging the per-pixel cross entropy loss over an image <ref type="bibr" target="#b39">[40]</ref>. Each pixel contributes equally to the training and the notion of instance is absent. This is often the case for semantic segmentation, since the annotations specify only the categories. For Panoptic Segmentation, however, each instance segment is given equal weighting during evaluation and training with the default pixel-averaged loss would put emphasis primarily on large instances, neglecting small objects that are numerous and critical. Therefore, we need to design an objective function that balances the loss across instances. Let a i denotes the area of the mask segment to which a pixel p i belongs. The training losses for both semantic and voting branches are normalized to be</p><formula xml:id="formula_1">L = 1 i w i i w i log p(y i |p i )<label>(1)</label></formula><p>where y i is the ground truth semantic/voting label, and</p><formula xml:id="formula_2">w i = 1 a λ i</formula><p>. λ controls the strength of normalization. When λ = 0, w i = 1, we get back the default pixel-averaged loss. When λ = 1, we divide the summed loss from each segment by the segment area, so that all segments would contribute equally to the training. λ = 0.5 could be interpreted as a length based normalization that strikes a middle ground between pixel-averaged loss and full segment normalized loss. Note that stuff and thing segments are treated identically. The final loss is the sum of semantic segmentation loss and voting loss L total = L sem + L vote . In Sec. 4, we demonstrate through ablation experiments that segment loss normalization significantly improves performance on both COCO and Cityscapes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.">Determining Object Categories</head><p>Once an instance mask is obtained from backprojection, we predict its category by taking the majority decision made by the semantic segmentation branch in the masked region. This strategy is similar to the one used by <ref type="bibr" target="#b56">[57]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>We report results on COCO <ref type="bibr" target="#b35">[36]</ref> and Cityscapes <ref type="bibr" target="#b8">[9]</ref> Panoptic Segmentation. Since PCV formulates centroid prediction as region classification rather than offset regression, it trades off the upper bound on prediction accuracy for a richer representation. We first conduct oracle experiments to understand the potential of our system. Then we compare our model performance on COCO and Cityscapes validation sets against prior and concurrent works. Ablations focus on the use of different discretization schemes and segment loss normalizations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Setup</head><p>COCO Panoptic Segmentation consists of 80 thing and 53 stuff categories. We use the 2017 split with 118k training images and report results on val and test-dev splits. Cityscapes includes images of urban street scenes. We use standard train/val split, including 2975 and 500 images respectively. There are 19 categories, 11 stuff and 8 things. We measure performance by Panoptic Quality (PQ) <ref type="bibr" target="#b23">[24]</ref>. PQ can be interpreted as a generalized F1-score that reflects both recognition quality RQ and segmentation quality SQ. In addition to the overall PQ, we include PQ th and PQ st and focus in particular on thing category performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Oracles</head><p>There are no learnable parameters in the vote aggregation and backprojection steps of PCV, and so once the pixel- wise classification decisions are made by the backbone network, the subsequent inference is deterministic. Therefore we perform oracle experiments by feeding into the inference pipeline ground truth classification labels for both the voting and semantic branches. As seen in <ref type="table">Table 1</ref>, given our default discretization scheme, PCV oracle achieves performance close to the upper bound on both COCO and Cityscapes validation sets. The remaining gaps in PQ are mostly due to small instances of extremely high occlusion and instances with colliding centroids. We also show 2 more oracle results: a simple radially expanding grid with 41 voting classes performs worse than the default grid with 233 voting classes. A uniform grid with evenly-spaced bins of size 15 and total Voting Filter side length 225 does the worst. Even though it has roughly the same number of voting classes as our default grid, the even spacing severely degrades performance on small instances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Main Results and Ablations</head><p>For Cityscapes training we use batch size 16 over 8 GPUs and crop input images to a uniform size of 1536 × 1024. We apply random horizontal flipping and randomly scale the size of the crops from 0.5 to 2. The model is trained for 65 epochs (12k iterations) with learning rate set initially at 0.01, dropped by 10x at 9000 iterations. We use SGD with momentum 0.9 and weight decay at 1e-4.</p><p>For COCO, we use standard Mask R-CNN 1× training schedule and hyperparameters. Input images are resized to have length 800 on the shorter side and length not exceeding 1333 on the longer. Resizing is consistent for both training and testing. Left-right flipping is the only data augmentation used. We use SGD with momentum 0.9 and set the initial learning rate at 0.0025, weight decay at 0.0001. The model is trained on 8 GPUs with batch size of 16 for a total of around 13 epochs (90k iterations). Learning rate decays by a factor of 10 at 60k and 80k iterations. BatchNorm <ref type="bibr" target="#b21">[22]</ref> layers in ResNet are frozen in our current setup.</p><p>Following <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b55">56]</ref>, for stuff predictions we filter out small predicted segments to reduce false positives. The thresholds are set at areas of 4096 pixels for COCO and 2048 pixels for Cityscapes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Main Results</head><p>We compare the performance of PCV against representative methods using different approaches. On both COCO and Cityscapes, PCV still lags behind leading methods that leverage Mask RCNN for instance segmentation. On the challenging COCO benchmark, PCV outperforms all other proposal free methods as well as <ref type="bibr" target="#b54">[55]</ref> which uses RetinaNet for object detection. Results on Cityscapes are shown in <ref type="table" target="#tab_7">Table 4</ref>. Qualitative results are displayed in <ref type="figure" target="#fig_7">Fig 8 and 9</ref>.      Ablation: discretization We explore the influence of discretization by comparing a model using a simple 41-cell grid against the default model using a 233-cell grid. The results on COCO val2017 are presented in <ref type="table" target="#tab_5">Table 2b</ref>. The full grid outperforms the simplistic grid and this agrees with our observation made earlier for the oracle experiments. The simple grid might make the learning easier but sacrifices the prediction accuracy due to coarse discretization.</p><p>Ablation: segment loss normalization We hypothesize that the contribution from each pixel to the final training loss should be normalized by a function of the segment area so that large instances would not eclipse the attention paid to small objects. We train PCV on COCO with λ set at 0, 0.5, 1. As expected, pixel-averaged loss with λ = 0 dilutes the focus on small objects and drags down PQ things, while a full area based segment normalization with λ = 1 causes severe degradation on stuff PQ. Length-based normalization with λ set at 0.5 achieves the best performance on both things and stuff.</p><p>Timing <ref type="table" target="#tab_8">Table 5</ref> examines PCV runtime breakdown, benchmarked on a GTX 1080 Ti and averaged over  Cityscapes and COCO val. Backprojection relies on an unoptimized indexing implementation. PCV runs at 5fps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>We propose a novel approach to panoptic segmentation that is entirely pixel-driven. Different from proposal-based object detection approaches, Pixel Consensus Voting elevates pixels to a first-class role; each pixel provides evidence for presence and location of object(s) it may belong to. It affords efficient inference, thanks to our convolutional mechanism for voting and backprojection. It is significantly simpler than current, highly engineered state-ofthe-art panoptic segmentation models.</p><p>Our results demonstrate that the Generalized Hough transform, a historical competitor to the sliding window detection paradigm, is again viable once combined with deep neural networks. This should be a call for future research exploring new ways of interconnecting traditional computer vision techniques with deep learning. For PCV specifically, there is clear potential to explore improved voting and inference protocols. This includes voting in higher dimensions (e.g., scale-space) and alternative models of interaction between instance detection and category assignments.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Network architecture for PCV. FPN serves as a shared feature extractor for the semantic segmentation branch and instance voting branch. Each branch predicts output at every pixel, and is trained with a per-pixel cross entropy loss.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Voting Filter and ground truth assignment. Left: a toy Voting Filter mapping a M × M, M = 9 region around a pixel to K = 17 indices. The discretization is coarser on the periphery with 3 × 3 cells. Middle: an instance mask where the red pixel is the mask centroid. We need to discretize the offset from the blue pixel to the centroid. Right: overlaying the Voting Filter on top of the blue pixel, one sees that the ground truth voting index for the blue pixel is 16.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :Figure 5 :</head><label>45</label><figDesc>The grid structure of our voting and query filters. It covers an area of 243× 243 and consists of 233 bins ranging in size of 1, 3, 9, 27 from center to the periphery.Pixels of a large object need only a rough estimatePixels of a small object need to be more precise Illustration of voting behavior. The green cross indi-</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Query Filter and backprojection. Top: The Query Filter is a spatial inversion of the Voting Filter, and the indices of the two filters are symmetric about the center (highlighted here for a few corresponding pairs of cells in the two filters). The Voting Filter captures the spatial relationship between a pixel and the surrounding centroid, whereas the Query Filter represents the dual relationship between a centroid and surrounding pixels; Bottom:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>Illustration of instance mask inference in PCV. Left to right: input image, voting heatmap, detected peak regions (random colors assigned to each peak); six masks resulting from backprojection from color-matching regions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 8 :</head><label>8</label><figDesc>Results of PCV on Cityscapes val and COCO test-dev.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 9 :</head><label>9</label><figDesc>Results of PCV on images from COCO val2017.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>PQ SQ RQ PQ th SQ th RQ th PQ st</figDesc><table><row><cell></cell><cell>1/4 gt</cell><cell>92.5 93.2 99.2 90.6 91.6 98.8 95.3</cell></row><row><cell></cell><cell>default grid</cell><cell>90.1 93.0 96.8 86.6 91.3 94.8 95.3</cell></row><row><cell>COCO</cell><cell>simple grid</cell><cell>79.2 92.6 85.1 68.6 90.7 75.4 95.3</cell></row><row><cell></cell><cell>uniform grid</cell><cell>67.1 95.8 70.1 49.4 96.0 51.5 93.8</cell></row><row><cell></cell><cell>1/4 gt</cell><cell>89.4 89.8 99.6 87.1 87.7 99.4 91.0</cell></row><row><cell></cell><cell>default grid</cell><cell>88.6 89.7 98.8 85.4 87.4 97.6 91.0</cell></row><row><cell>Cityscapes</cell><cell>simple grid</cell><cell>83.0 89.3 92.8 72.1 86.6 83.4 91.0</cell></row><row><cell></cell><cell>uniform grid</cell><cell>66.1 92.6 71.8 31.8 94.3 33.4 91.0</cell></row><row><cell cols="3">Table 1: Oracle inference on COCO and Cityscapes val</cell></row><row><cell cols="3">using ground truth voting and semantic classification label.</cell></row><row><cell cols="3">'1/4 gt' is the performance upper bound when the output is</cell></row><row><cell cols="3">at 1/4 of input resolution, and the default discretization is</cell></row><row><cell cols="2">behind by a small gap.</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>PQSQ RQ PQ th SQ th RQ th PQ st Segment Loss Normalization: results on COCO val with various λ that controls the normalization strength. λ = 0.5 improves PQ th by 7 points over the commonly used pixel-averaged loss.PQ SQ RQ PQ th SQ th RQ th PQ st Impact of Discretization: consistent with oracle results inTable 1, the simple grid is too coarse for accurate localizations and the default grid leads on PQ th by 7.17 points on COCO val.</figDesc><table><row><cell>λ=0 λ=0.5 37.5 77.7 47.2 32.9 77.2 40.5 λ=1.0 31.8 74.7 41.3 (a) default grid 37.5 77.7 47.2 33.0 78.0 40.3 32.6 40.0 78.4 50.0 33.7 33.9 75.1 44.0 28.6 simple grid 33.3 77.2 41.8 (b)</cell><cell>40.0 78.4 50.0 32.8 77.4 40.9</cell><cell>33.7 34.1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 2 :</head><label>2</label><figDesc>Ablations on segment loss normalization and impact of discretization.</figDesc><table><row><cell></cell><cell>Methods</cell><cell>Backbone</cell><cell>Split</cell><cell>PQ</cell><cell>SQ</cell><cell>RQ</cell><cell>PQ th</cell><cell>SQ th</cell><cell>RQ th</cell><cell>PQ st</cell><cell>SQ st</cell><cell>RQ st</cell></row><row><cell></cell><cell>PFPN [23] (1x)</cell><cell>ResNet 50</cell><cell>val</cell><cell>39.4</cell><cell>77.8</cell><cell>48.3</cell><cell>45.9</cell><cell>80.9</cell><cell>55.4</cell><cell>29.6</cell><cell>73.3</cell><cell>37.7</cell></row><row><cell>Mask R-CNN</cell><cell>PFPN [23] (3x)</cell><cell>ResNet 50</cell><cell>val</cell><cell>41.5</cell><cell>79.1</cell><cell>50.5</cell><cell>48.3</cell><cell>82.2</cell><cell>57.9</cell><cell>31.2</cell><cell>74.4</cell><cell>39.4</cell></row><row><cell></cell><cell>UPSNet [56] (1x)</cell><cell>ResNet 50</cell><cell>val</cell><cell>42.5</cell><cell>78.0</cell><cell>52.5</cell><cell>48.6</cell><cell>79.4</cell><cell>59.6</cell><cell>33.4</cell><cell>75.9</cell><cell>41.7</cell></row><row><cell></cell><cell>SSPS [55]</cell><cell>ResNet 50</cell><cell>val</cell><cell>32.4</cell><cell>-</cell><cell>-</cell><cell>34.8</cell><cell>-</cell><cell>-</cell><cell>28.6</cell><cell>-</cell><cell>-</cell></row><row><cell>Single Stage Detection</cell><cell>SSPS [55]</cell><cell>ResNet 50</cell><cell>test-dev</cell><cell>32.6</cell><cell>74.3</cell><cell>42.0</cell><cell>35.0</cell><cell>74.8</cell><cell>44.8</cell><cell>29.0</cell><cell>73.6</cell><cell>37.7</cell></row><row><cell></cell><cell>AdaptIS [51]</cell><cell>ResNet 50</cell><cell>val</cell><cell>35.9</cell><cell>-</cell><cell>-</cell><cell>40.3</cell><cell>-</cell><cell>-</cell><cell>29.3</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell>DeeperLab [57]</cell><cell>Xception 71</cell><cell>val</cell><cell>33.8</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell>DeeperLab [57]</cell><cell cols="2">Xception 71 test-dev</cell><cell>34.3</cell><cell>77.1</cell><cell>43.1</cell><cell>37.5</cell><cell>77.5</cell><cell>46.8</cell><cell>29.6</cell><cell>76.4</cell><cell>37.4</cell></row><row><cell>Proposal-Free</cell><cell>SSAP [16]</cell><cell>ResNet 101</cell><cell>val</cell><cell>36.5</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell>SSAP [16]</cell><cell cols="2">ResNet 101 test-dev</cell><cell>36.9</cell><cell>80.7</cell><cell>44.8</cell><cell>40.1</cell><cell>81.6</cell><cell>48.5</cell><cell>32.0</cell><cell>79.4</cell><cell>39.3</cell></row><row><cell></cell><cell>Ours (1x)</cell><cell>ResNet 50</cell><cell>val</cell><cell>37.5</cell><cell>77.7</cell><cell>47.2</cell><cell>40.0</cell><cell>78.4</cell><cell>50.0</cell><cell>33.7</cell><cell>76.5</cell><cell>42.9</cell></row><row><cell></cell><cell>Ours (1x)</cell><cell>ResNet 50</cell><cell>test-dev</cell><cell>37.7</cell><cell>77.8</cell><cell>47.3</cell><cell>40.7</cell><cell>78.7</cell><cell>50.7</cell><cell>33.1</cell><cell>76.3</cell><cell>42.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3 :</head><label>3</label><figDesc>Comparisons on COCO. PCV outperforms proposal-free and single-state detection methods.</figDesc><table><row><cell></cell><cell>PQ</cell><cell>PQ th</cell><cell>PQ st</cell><cell>mIoU</cell></row><row><cell>DIN [1]</cell><cell>53.8</cell><cell>42.5</cell><cell>62.1</cell><cell>80.1</cell></row><row><cell>UPSNet [56]</cell><cell>59.3</cell><cell>54.6</cell><cell>62.7</cell><cell>75.2</cell></row><row><cell>PFPN [23]</cell><cell>58.1</cell><cell>52.0</cell><cell>62.5</cell><cell>75.7</cell></row><row><cell>AdaptIS [51]</cell><cell>59.0</cell><cell>55.8</cell><cell>61.3</cell><cell>75.3</cell></row><row><cell>SSAP [16]</cell><cell>58.4</cell><cell>50.6</cell><cell>-</cell><cell>-</cell></row><row><cell>Ours</cell><cell>54.2</cell><cell>47.8</cell><cell>58.9</cell><cell>74.1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 4 :</head><label>4</label><figDesc>Results on Cityscapes val using ResNet 50</figDesc><table><row><cell></cell><cell>Input Size</cell><cell cols="4">Backbone Voting Backproj. Total</cell></row><row><cell>COCO</cell><cell>800 × 1333</cell><cell>93.4</cell><cell>1.3</cell><cell>81.8</cell><cell>176.5</cell></row><row><cell cols="2">Cityscapes 1024×2048</cell><cell>115.6</cell><cell>2.8</cell><cell>64.4</cell><cell>182.8</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 5 :</head><label>5</label><figDesc>runtime benchmark using GTX 1080 Ti (unit: ms)</figDesc><table /><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Acknowledgements</head><p>We would like to thank Deva Ramanan for discussions and feedback. The work was in part supported by the DARPA L2M award FA8750-18-2-0126, the DARPA GARD award HR00112020003, and AFOSR award FF9950-18-1-0166 (MADlab).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Pixelwise instance segmentation with a dynamically instantiated network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anurag</forename><surname>Arnab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="441" to="450" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Deep watershed transform for instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5221" to="5229" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Generalizing the hough transform to detect arbitrary shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Dana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ballard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern recognition</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="111" to="122" />
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Poselets: Body part detectors trained using 3d human pose annotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lubomir</forename><surname>Bourdev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 12th International Conference on Computer Vision</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1365" to="1372" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Cocostuff: Thing and stuff classes in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Caesar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jasper</forename><surname>Uijlings</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vittorio</forename><surname>Ferrari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1209" to="1218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iasonas</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="834" to="848" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Tensormask: A foundation for dense object segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinlei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Dollár</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.12174</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxwell</forename><forename type="middle">D</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The cityscapes dataset for semantic urban scene understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>Cordts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Omran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Ramos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Rehfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Enzweiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>Benenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uwe</forename><surname>Franke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3213" to="3223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Semantic instance segmentation with a discriminative loss function</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Davy</forename><surname>Bert De Brabandere</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Neven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Gool</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.02551</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geus</forename><surname>Daan De</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.03892</idno>
		<title level="m">Panagiotis Meletis, and Gijs Dubbelman. Fast panoptic segmentation network</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Use of the hough transformation to detect lines and curves in pictures. Technical report, Sri International Menlo Park Ca Artificial Intelligence Center</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Richard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><forename type="middle">E</forename><surname>Duda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hart</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The pascal visual object classes (voc) challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Everingham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">I</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="303" to="338" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Object detection with discriminatively trained part-based models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pedro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><forename type="middle">B</forename><surname>Felzenszwalb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Mcallester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ramanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="1627" to="1645" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Hough forests for object detection, tracking, and action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juergen</forename><surname>Gall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nima</forename><surname>Razavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="2188" to="2202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Ssap: Single-shot instance segmentation with affinity pyramid</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naiyu</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanhu</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yupei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiqi</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="642" to="651" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Rich feature hierarchies for accurate object detection and semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="580" to="587" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Efficient regression of general-activity human poses from depth images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Shotton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pushmeet</forename><surname>Kohli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Criminisi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Fitzgibbon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2011 International Conference on Computer Vision</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="415" to="422" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Simultaneous detection and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pablo</forename><surname>Bharath Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Arbeláez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="297" to="312" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Piotr Dollár, and Ross Girshick. Mask r-cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgia</forename><surname>Gkioxari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2961" to="2969" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.03167</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Kaiming He, and Piotr Dollár. Panoptic feature pyramid networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kirillov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6399" to="6408" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Panoptic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kirillov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carsten</forename><surname>Rother</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Dollár</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9404" to="9413" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Instancecut: from edges to instances with multicut</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kirillov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeny</forename><surname>Levinkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bjoern</forename><surname>Andres</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bogdan</forename><surname>Savchynskyy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carsten</forename><surname>Rother</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5008" to="5017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Recurrent pixel embedding for instance grouping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Charless</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fowlkes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="9018" to="9028" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Cornernet: Detecting objects as paired keypoints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hei</forename><surname>Law</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="734" to="750" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Combined object categorization and segmentation with an implicit shape model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ales</forename><surname>Bastian Leibe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Leonardis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on statistical learning in computer vision, ECCV</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Robust object detection with interleaved categorization and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleš</forename><surname>Bastian Leibe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Leonardis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="259" to="289" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Allan</forename><surname>Raventos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arjun</forename><surname>Bhargava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takaaki</forename><surname>Tagawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrien</forename><surname>Gaidon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.01192</idno>
		<title level="m">Learning to fuse things and stuff</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Attention-guided unified network for panoptic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinze</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingxi</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dalong</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="7026" to="7035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Proposal-free network for instance-level object segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodan</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunchao</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohui</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianchao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuicheng</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="2978" to="2991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Human pose estimation using deep consensus voting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ita</forename><surname>Lifshitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ethan</forename><surname>Fetaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shimon</forename><surname>Ullman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="246" to="260" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Feature pyramid networks for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bharath</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2117" to="2125" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Kaiming He, and Piotr Dollár. Focal loss for dense object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2980" to="2988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Microsoft coco: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="740" to="755" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">An end-to-end network for panoptic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huanyu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changqian</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingbo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6172" to="6181" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Ssd: Single shot multibox detector</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng-Yang</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander C</forename><surname>Berg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="21" to="37" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Affinity derivation and graph merge for instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiding</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siyu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wengang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jizheng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Houqiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="686" to="703" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Fully convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3431" to="3440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Object detection using a max-margin hough transform</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhransu</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1038" to="1045" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Instance segmentation by jointly optimizing spatial embeddings and clustering bandwidth</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Davy</forename><surname>Neven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bert</forename><forename type="middle">De</forename><surname>Brabandere</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Proesmans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8837" to="8845" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Associative embedding: End-to-end learning for joint detection and grouping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alejandro</forename><surname>Newell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2277" to="2287" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Semi-convolutional operators for instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Novotny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Albanie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diane</forename><surname>Larlus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Vedaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="86" to="102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Personlab: Person pose estimation and instance segmentation with a bottom-up, part-based, geometric embedding model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tyler</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spyros</forename><surname>Gidaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Tompson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="269" to="286" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Deep hough voting for 3d object detection in point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Or</forename><surname>Charles R Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>Litany</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guibas</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.09664</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Yolo9000: better, faster, stronger</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Redmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="7263" to="7271" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">End-to-end instance segmentation with recurrent attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengye</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Richard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6656" to="6664" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Faster r-cnn: Towards real-time object detection with region proposal networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>Shaoqing Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="91" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Recurrent instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernardino</forename><surname>Romera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-</forename><surname>Paredes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip Hilaire Sean</forename><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="312" to="329" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Adaptis: Adaptive instance selection network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantin</forename><surname>Sofiiuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Barinova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anton</forename><surname>Konushin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="7355" to="7363" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Fcos: Fully convolutional one-stage object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9627" to="9636" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Original approach for the localisation of objects in images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Régis</forename><surname>Vaillant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christophe</forename><surname>Monrocq</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Le Cun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEE Proceedings-Vision, Image and Signal Processing</title>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="volume">141</biblScope>
			<biblScope unit="page" from="245" to="250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Rapid object detection using a boosted cascade of simple features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Viola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Jones</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Single-shot panoptic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Luiten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bastian</forename><surname>Leibe</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.00764</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Upsnet: A unified panoptic segmentation network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuwen</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renjie</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ersin</forename><surname>Yumer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8818" to="8826" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tien-Ju</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Maxwell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jyh-Jing</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vivienne</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Sze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.05093</idno>
		<title level="m">Deeperlab: Single-shot image parser</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Multi-scale context aggregation by dilated convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fisher</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Koltun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.07122</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Pyramid scene parsing network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojuan</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2881" to="2890" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Tracking objects as points</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingyi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Koltun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Krähenbühl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingyi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dequan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Krähenbühl</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.07850</idno>
		<title level="m">Objects as points</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
