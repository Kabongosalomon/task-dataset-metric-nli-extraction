<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Deep Sparse Representation-based Classification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Student Member, IEEE</roleName><forename type="first">Abavisani</forename><surname>Mahdi</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Senior Member, IEEE</roleName><forename type="first">Vishal</forename><forename type="middle">M Patel</forename></persName>
						</author>
						<title level="a" type="main">Deep Sparse Representation-based Classification</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>1</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T16:29+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present a transductive deep learning-based formulation for the sparse representation-based classification (SRC) method. The proposed network consists of a convolutional autoencoder along with a fully-connected layer. The role of the autoencoder network is to learn robust deep features for classification. On the other hand, the fully-connected layer, which is placed in between the encoder and the decoder networks, is responsible for finding the sparse representation. The estimated sparse codes are then used for classification. Various experiments on three different datasets show that the proposed network leads to sparse representations that give better classification results than state-of-the-art SRC methods. The source code is available at: github.com/mahdiabavisani/DSRC. Index Terms-Deep learning, sparse representation-based classification, deep sparse representation-based classification.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Sparse coding has become widely recognized as a powerful tool in signal processing and machine learning with various applications in computer vision and pattern recognition <ref type="bibr" target="#b0">[1]</ref>- <ref type="bibr" target="#b2">[3]</ref>. Sparse representation-based classification (SRC) as an application of sparse coding was first proposed in <ref type="bibr" target="#b0">[1]</ref>, and was shown to provide robust performance on various face recognition datasets. Since then, SRC has been used in numerous applications <ref type="bibr" target="#b3">[4]</ref>- <ref type="bibr" target="#b8">[9]</ref>. In SRC, an unlabeled sample is represented as a sparse linear combination of the labeled training samples. This representation is obtained by solving a sparsitypromoting optimization problem. Once the representation is found, the label is assigned to the test sample based on the minimum reconstruction error rule <ref type="bibr" target="#b0">[1]</ref>.</p><p>The SRC method is based on finding a linear representation of the data. However, linear representations are almost always inadequate for representing non-linear structures of the data which arise in many practical applications. To deal with this issue, some works have exploited the kernel trick to develop non-linear extensions of the SRC-based methods <ref type="bibr" target="#b9">[10]</ref>- <ref type="bibr" target="#b19">[20]</ref>. Kernel SRC methods require the use of a pre-determined kernel function such as polynomial or Gaussian. Selection of the kernel function and its parameters is an important issue in training when kernel SRC methods are used for classification.</p><p>In this paper, we propose a deep neural network-based framework that finds an explicit nonlinear mapping of data, while simultaneously obtaining sparse codes that can be used for classification. Learning nonlinear mappings with neural networks has been shown to produce remarkable improvements in subspace clustering tasks <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b21">[22]</ref>. We introduce M. Abavisani is with the department of Electrical and Computer Engineering at Rutgers University, Piscataway, NJ USA. email: mahdi.abavisani@rutgers.edu. Vishal M. Patel is with the department of Electrical and Computer Engineering at Johns Hopkins University, Baltimore, MD USA. email: vpatel36@jhu.edu. This work was partially supported by the NSF grant 1618677 and by US Office of Naval Research (ONR) Grant YIP N00014-16-1-3134.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Encoder Decoder</head><p>Input Output</p><formula xml:id="formula_0">Z m ⇥ e Z m ⇥ e ⇥ s Z ⇥ e Z ⇥ e C X X ⇥ {G(x 1 ), G(x 2 ), · · · , G(x N X )} G(·) {y 1 , y 2 , · · · , y N Y } {F (y 1 ), F (y 2 ), · · · , F (y N Y )} F (·) 1 Z m ⇥ e Z m ⇥ e ⇥ s Z ⇥ e Z ⇥ e C X X ⇥ {G(x 1 ), G(x 2 ) G(·) {y 1 , y 2 , · · · , y N {F (y 1 ), F (y 2 ) F (·) One Zero Trainable … … … … XˆX ⇥ { G( x 1 ) , G( x 2 ) , · · ·, G( x N X ) } G( · ) { y 1 , y 2 , · · ·, y N Y } { F( y 1 ) , F( y 2 ) , · · ·, F( y N Y ) } F( · ) Z ⇥ e C XˆX ⇥ {G(x 1 ),G(x 2 ),···,G(x N X )} G(· ) {y 1 ,y 2 ,···,y N Y } {F(y 1 ),F(y 2 ),···,F(y N Y )} F(· ) Z ⇥ e C X ˆ X ⇥ { G ( x 1 ) , G ( x 2 ) , · · · , G ( x N X ) } G ( · ) { y 1 , y 2 , · · · , y N Y } { F ( y 1 ) , F ( y 2 ) , · · · , F ( y N Y ) } F ( · ) X ˆ X ⇥ { G ( x 1 ) , G ( x 2 ) , · · · , G ( x N X ) } G ( · ) { y 1 , y 2 , · · · , y N Y } { F ( y 1 ) , F ( y 2 ) , · · · , F ( y N Y ) } F ( · )</formula><p>Let G be our encoder, F be our decoder, M be our mean distribution network be a large discriminator. X 2 R d⇥N is fed to G, and a latent representation g(x i ) comes out of the enc directly fed to decoder for reconstruction loss. However, we also feed g(x</p><formula xml:id="formula_1">i ) t have D(g(x i ))</formula><p>with is a N dimensional vector specifying that basically reco</p><formula xml:id="formula_2">(the index of x i ). The N dimensional D(g(x i )) is fed to M returning a k dime vector of membership. Z test Z trainẐtestẐtrain Y 1 = Y 1 C 1 + E 1 + N 1 Y 2 = Y 2 C 2 + E 2 + N 2 Y 3 = Y 3 C 3 + E 3 + N 3 Y 4 = Y 4 C 4 + E 4 + N 4 Y 5 = Y 5 C 5 + E 5 + N 5 C 1 ⇡ C 2 ⇡ C 3 ⇡ C 4 ⇡ C 5 Z m ⇥ m e Z m ⇥ m e ⇥ s Z ⇥e Z ⇥e C X X ⇥ {G(x 1 ), G(x 2 ), · · · , G(x NX )} G(·)</formula><p>{y , y , · · · , y } Let G be our encoder, F be our decoder, M be our mean distribution be a large discriminator. X 2 R d⇥N is fed to G, and a latent representation g(x i ) comes out o directly fed to decoder for reconstruction loss. However, we also feed have D(g(x i )) with is a N dimensional vector specifying that basica</p><formula xml:id="formula_3">(the index of x i ). The N dimensional D(g(x i )) is fed to M returning vector of membership. Z test Z trainẐtestẐtrain Y 1 = Y 1 C 1 + E 1 + N 1 Y 2 = Y 2 C 2 + E 2 + N 2 Y 3 = Y 3 C 3 + E 3 + N 3 Y 4 = Y 4 C 4 + E 4 + N 4 Y 5 = Y 5 C 5 + E 5 + N 5 C 1 ⇡ C 2 ⇡ C 3 ⇡ C 4 ⇡ C 5 Z m ⇥ m e Z m ⇥ m e ⇥ s Z ⇥e Z ⇥e C X X ⇥ {G(x 1 ), G(x 2 ), · · · , G(x NX )} G(·) {y 1 , y 2 , · · · , y NY }</formula><p>Let G be our encoder, F be our decoder, M be our mean distribution network, and D be a large discriminator. X 2 R d⇥N is fed to G, and a latent representation g(x i ) comes out of the encoder. It directly fed to decoder for reconstruction loss. However, we also feed g(x i ) to D and have D(g(x i )) with is a N dimensional vector specifying that basically recognizes i</p><formula xml:id="formula_4">(the index of x i ). The N dimensional D(g(x i )) is fed to M returning a k dimensional vector of membership. Z test Z trainẐtestẐtrain Y 1 = Y 1 C 1 + E 1 + N 1 Y 2 = Y 2 C 2 + E 2 + N 2 Y 3 = Y 3 C 3 + E 3 + N 3 Y 4 = Y 4 C 4 + E 4 + N 4 Y 5 = Y 5 C 5 + E 5 + N 5 C 1 ⇡ C 2 ⇡ C 3 ⇡ C 4 ⇡ C 5 Z m ⇥ m e Z m ⇥ m e ⇥ s Z ⇥e Z ⇥e C X X ⇥ Let G be our encoder, F</formula><p>be our decoder, M be our mean distribution network, and be a large discriminator. X 2 R d⇥N is fed to G, and a latent representation g(x i ) comes out of the encoder. directly fed to decoder for reconstruction loss. However, we also feed g(x i ) to D a have D(g(x i )) with is a N dimensional vector specifying that basically recognize</p><formula xml:id="formula_5">(the index of x i ). The N dimensional D(g(x i )) is fed to M returning a k dimension vector of membership. Z test Z trainẐtestẐtrain Y 1 = Y 1 C 1 + E 1 + N 1 Y 2 = Y 2 C 2 + E 2 + N 2 Y 3 = Y 3 C 3 + E 3 + N 3 Y 4 = Y 4 C 4 + E 4 + N 4 Y 5 = Y 5 C 5 + E 5 + N 5 C 1 ⇡ C 2 ⇡ C 3 ⇡ C 4 ⇡ C 5 Z m ⇥ m e Z m ⇥ m e ⇥ s Z ⇥e Z ⇥e C X X ⇥</formula><p>Let G be our encoder, F be our decoder, M be our mean distribution ne be a large discriminator. X 2 R d⇥N is fed to G, and a latent representation g(x i ) comes out of th directly fed to decoder for reconstruction loss. However, we also feed g( have D(g(x i )) with is a N dimensional vector specifying that basically (the index of</p><formula xml:id="formula_6">x i ). The N dimensional D(g(x i )) is fed to M returning a k vector of membership. Z test Z trainẐtestẐtrain Y 1 = Y 1 C 1 + E 1 + N 1 Y 2 = Y 2 C 2 + E 2 + N 2 Y 3 = Y 3 C 3 + E 3 + N 3 Y 4 = Y 4 C 4 + E 4 + N 4 Y 5 = Y 5 C 5 + E 5 + N 5 C 1 ⇡ C 2 ⇡ C 3 ⇡ C 4 ⇡ C 5 Z m ⇥ m e Z m ⇥ m e ⇥ s Z ⇥e Z ⇥e C X X ⇥ {G(x 1 ), G(x 2 ), · · · , G(x NX )} G(·) {y 1 , y 2 , · · · , y NY } {F (y 1 ), F (y 2 ), · · · , F (y NY )} F (·) 1</formula><p>Let G be our encoder, F be our decoder, M be our mean distribution network be a large discriminator. X 2 R d⇥N is fed to G, and a latent representation g(x i ) comes out of the enc directly fed to decoder for reconstruction loss. However, we also feed g(x i ) t have D(g(x i )) with is a N dimensional vector specifying that basically reco (the index of a transductive model, which accepts a set of training and test samples, learns a mapping that is suitable for sparse representation, and recovers the corresponding sparse codes. Our model consists of an encoder that is responsible for learning the mapping, a sparse coding layer which mimics the task of constructing the mapped test samples by a combination of the mapped training samples, and a decoder that is used for training the networks.</p><formula xml:id="formula_7">x i ). The N dimensional D(g(x i )) is fed to M returning a k dim vector of membership. Z test Z trainẐtestẐtrain Y 1 = Y 1 C 1 + E 1 + N 1 Y 2 = Y 2 C 2 + E 2 + N 2 Y 3 = Y 3 C 3 + E 3 + N 3 Y 4 = Y 4 C 4 + E 4 + N 4 Y 5 = Y 5 C 5 + E 5 + N 5 C 1 ⇡ C 2 ⇡ C 3 ⇡ C 4 ⇡ C 5 Z m ⇥ m e Z m ⇥ m e ⇥ s Z ⇥e Z ⇥e C X X ⇥ {G(x 1 ), G(x 2 ), · · · , G(x NX )} G(·) {y 1 , y 2 , · · · , y NY } {F (y 1 ), F (y 2 ), · · · , F (y NY )} F (·)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Sparse representation-based classification</head><p>In SRC, given a set of labeled training samples, the goal is to classify an unseen set of test samples. Suppose that we collect all the vectorized training samples with the label i in the matrix X i train ∈ R d0×ni , where d 0 is the dimension of each sample and n i is the number of samples in class i, then the training matrix can be constructed as</p><formula xml:id="formula_8">X train = [X 1 train , X 2 train , · · · , X K train ] ∈ R d0×n<label>(1)</label></formula><p>where n 1 + n 2 + · · · + n K = n and we have a total of K classes.</p><p>In SRC, it is assumed that an observed sample x test ∈ R d0 can be well approximated by a linear combination of the samples in X i train if x test is from class i. Thus, it is possible to predict the class of a given unlabeled data by finding a set of samples in the training set that can better approximate x test . Mathematically, these samples can be found by solving the following optimization problem</p><formula xml:id="formula_9">min α α 0 s.t. x test = X train α,<label>(2)</label></formula><p>where α 0 counts the number of non-zero elements in α.</p><p>The minimization problem (2) finds a sparse solution for the linear system. However, since the optimization problem <ref type="formula" target="#formula_9">(2)</ref> is an NP-hard problem, in practice, a sparsity constraint is enforced by the 1 -norm of α which is a convex relaxation of the above problem <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b23">[24]</ref>. Thus, in practice the following minimization problem is solved to obtain the sparse codes where λ 0 is a positive regularization parameter. Once α is found, one can estimate the class label of x test as follows</p><formula xml:id="formula_10">min α x test − X train α 2 2 + λ 0 α 1 ,<label>(3)</label></formula><formula xml:id="formula_11">class(x test ) = arg min k x test − X train δ k (α) 2 2 ,<label>(4)</label></formula><p>where δ k (·) is the characteristic function that selects the coefficients associated with the class i.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. DEEP SPARSE REPRESENTATION-BASED</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CLASSIFICATION NETWORK</head><p>We develop a transductive classification model based on sparse representations. In a transductive model, as opposed to inductive models, both training and test sets are observed, and the learning process pursues reasoning from the specific training samples to a specific set of test cases <ref type="bibr" target="#b24">[25]</ref>. We build our method based on convolutional autoencoders. In particular, our network contains an encoder, a sparse coding layer, and a decoder. The encoder receives both the training and test sets as raw data inputs and extracts abstract features from them. The sparse coding layer recovers the test cases by a sparse linear combination of the training samples, and concatenates them along with the training features which are then fed to the decoder. The decoder maps both the training embeddings and the recovered test embeddings back to the original representation of the data. <ref type="figure">Figure 1</ref> gives an overview of the proposed deep SRC (DSRC) framework.</p><p>Sparse representation: Let X train ∈ R d0×n and, X test ∈ R d0×m be the given vectorized training and testing data, respectively. We feed X = [X train , X test ] to the encoder, where it develops the corresponding embedding features Z = [Z train , Z test ] ∈ R dz×(m+n) . The minimization problem (3) for a single test observation can be re-written for a matrix of testing embedding features as</p><formula xml:id="formula_12">min A Z test − Z train A 2 F + λ 0 A 1 ,<label>(5)</label></formula><p>where A ∈ R n×m is the coefficient matrix that contains the sparse codes in its columns, and λ 0 is a positive regularization parameter. Note that the first penalty term in equation <ref type="formula" target="#formula_12">(5)</ref> is equivalent to the penalty term used for a fully-connected neural network layer with the input of Z train , the output of Z test and trainable parameters of A. As a result, considering the sparsity constraint, one can model the optimization problem (5) in a neural network framework with a fully-connected layer with sparse parameters which have no non-linearity activation or bias nodes. We use such a model inside our sparse coding layer to find the sparse codes for the observed test set. The sparse coding layer is located between the encoder and decoder networks. Its task for Z train is to pass them to the decoder, and for the test features Z test it will pass their reconstructions that are found from (5), as Z train A, to the decoder. Thus, assuming thatẐ train andẐ test are the outputs of the sparse coding layer for training and testing features, we haveẐ</p><formula xml:id="formula_13">train = Z train I n ,Ẑ test = Z train A,<label>(6)</label></formula><p>Algorithm 1 Deep sparse representation-based classification 1: procedure DSRC(X train , X test , λ 0 , λ 1 ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2:</head><p>Construct X = [X train , X test ].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3:</head><p>Find A via Θ by solving the optimization problem (8).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4:</head><p>Classify the test samples using (9) . 5: end procedure where I n ∈ R n×n is the identity matrix. Therefore, if the decoder's input isẐ = [Ẑ train ,Ẑ test ], from (6) we can calculateẐ asẐ = ZΘ sc , where</p><formula xml:id="formula_14">Θ sc = I n A 0 n×m 0 m .<label>(7)</label></formula><p>In equation <ref type="formula" target="#formula_14">(7)</ref>, 0 n×m ∈ R n×m and 0 m ∈ R m×m are zero matrices. One can write an end-to-end training objective that includes sparse coding and training of the encoder-decoder as follows</p><formula xml:id="formula_15">min Θ Z − ZΘ sc 2 F + λ 0 Θ sc 1 + λ 1 X −X 2 F , (8)</formula><p>where Θ is the union of all the trainable parameters including encoder and decoder's parameters and A. Here, X = [X train ,X test ] is the output of the decoder (i.e. reconstructions), and λ 0 and λ 1 are positive regularization parameters. Note that the optimization problem (8) simultaneously finds sparse codes A and a set of desirable embedding features Z that are especially suitable for providing efficient sparse codes.</p><p>Classification: Once the sparse coefficient matrix A is found, it can be used for associating the class labels to the test samples. For each test sample x i test in X test , its embedding features z i test , and the corresponding sparse code column α i in A are used to estimate the class labels as follows</p><formula xml:id="formula_16">class(x i test ) = arg min k z i test − Z train δ k (α i ) 2 2 .<label>(9)</label></formula><p>The proposed DSRC method is summarized in Algorithm 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. EXPERIMENTAL RESULTS</head><p>In this section, we evaluate our method against state-of-theart SRC methods. The USPS handwritten digits dataset <ref type="bibr" target="#b25">[26]</ref>, the street view house numbers (SVHN) dataset <ref type="bibr" target="#b26">[27]</ref>, and the UMDAA-01 face recognition dataset <ref type="bibr" target="#b27">[28]</ref> are used in our experiments. <ref type="figure">Figure 2 (a)</ref>, (b), and (c) show sample images from these datasets. Since the number of parameters in the sparse coding layer scales with the multiplication of training and testing sizes, we randomly select a smaller subset of the used datasets and perform all the experiments on the selected subset. In all the experiments, the input images are resized to 32 × 32.</p><p>We compare our method with the standard SRC method <ref type="bibr" target="#b0">[1]</ref>, Kernel SRC (KSRC) <ref type="bibr" target="#b13">[14]</ref>, SRC on features extracted from an autoencoder with similar architecture to our network (AE-SRC), and SRC on features extracted from the state-of-theart pre-trained networks. In our experiment with the pretrained networks, the networks are pre-trained on the Imagenet dataset <ref type="bibr" target="#b28">[29]</ref>. For this purpose, we use the following (a) USPS <ref type="bibr" target="#b25">[26]</ref> (b) SVHN <ref type="bibr" target="#b26">[27]</ref> (c) UMDAA-01 <ref type="bibr" target="#b27">[28]</ref> Fig. 2. Sample images from (a) USPS <ref type="bibr" target="#b25">[26]</ref>, (b) SVHN <ref type="bibr" target="#b26">[27]</ref>, and (c) UMDAA-01 <ref type="bibr" target="#b27">[28]</ref>. four popular network architectures: VGG-19 <ref type="bibr" target="#b29">[30]</ref>, Inception-V3 <ref type="bibr" target="#b30">[31]</ref>, Resnet-50 <ref type="bibr" target="#b31">[32]</ref> and Densenet-169 <ref type="bibr" target="#b32">[33]</ref>. We feed these networks with our datasets, extract the features corresponding to the last layer before classification, and pass them to the classical SRC algorithm. Note these networks accept 224×224 inputs. Thus, as a preprocessing step, we resample the input images to 224 × 224 images before feeding them to the pretrained networks.</p><p>We compare different methods in terms of their five-fold averaged classification accuracy. In all the experiments, unless otherwise stated, we randomly split the datasets into sets of training and testing samples, where 20% of the samples are used for testing, and 80% of the samples are used as the training set. Network structure: The encoder network of our model consists of stacked four convolutional layers, and the decoder has three fractionally-strided convolution layers (also known as deconvolution layers). Each plugged in convolution or fractionally-strided convolution is coupled with a ReLu nonlinearity as well, but does not have a batch-norm layer. <ref type="table" target="#tab_1">Table I</ref> gives the details of the network, including the kernel sizes and the number of filters. Training details: We implemented our method with Tensorflow-1.4 <ref type="bibr" target="#b33">[34]</ref>. We use the adaptive momentum-based gradient descent method (ADAM) <ref type="bibr" target="#b34">[35]</ref> to minimize the loss function, and apply a learning rate of 10 −3 . Before we start training on our objective function, in each experiment, we pre-train our encoder and decoder on the dataset without the sparse coding layer. In particular, we pre-train the encoderdecoder for 20k epochs with the objective of minΘ X−X 2 F , whereΘ indicates the union of parameters in the encoder and decoder networks. We use a batch size of 100 for this stage. However, in the actual stage of training, we feed all the samples including the training and testing samples as a single large batch. We set the regularization parameters as λ 0 = 1 and λ 1 = 8 in all the experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. USPS digits</head><p>The first set of experiments is conducted on the USPS handwritten digits dataset <ref type="bibr" target="#b25">[26]</ref>. This dataset contains 7291 training and 2007 test grayscale images of ten digits (0-9). <ref type="figure">Figure 2</ref> (a), shows example images from this dataset. We perform the experiments on a subset with a total size of 2000 samples. In particular, we randomly select 160 and 40 samples per digit from the training and testing sets, respectively. The first row of <ref type="table" target="#tab_1">Table II</ref> shows the performance of various SRC methods. As can be observed from this table, the proposed method performs significantly better than the other methods including the classical and deep learning-based methods. <ref type="figure" target="#fig_1">Figure 3</ref> shows the coefficient matrix A, extracted from Θ sc , the matrix of the network trained for this experiment. For better visualization, we show the absolute value of the transposed A (i.e. |A T |). Thus, each row of the matrix in <ref type="figure" target="#fig_1">Figure 3</ref> corresponds to the sparse codes for one of the test samples. Similarly, columns in this figure are coefficients related to the training samples. This matrix is sparse and shows a block diagram pattern, where most of the non-zero coefficients for each test sample are those that correspond to the training samples with the same class as the observed test sample. Analysis of the network: To understand the effects of some of our model choices, we compare the performance of our DSRC method with variations of it by changing the regularization norm on Θ sc in the loss function <ref type="bibr" target="#b7">(8)</ref>. We replace the term Θ sc 1 in (8) by Θ sc p , where p = 0.5, 1.5 and 2, and report their performances by DSRC 0.5 , DSRC 1.5 and DSRC 2 , respectively.</p><p>In addition, if we do not follow the specific structure described in equation <ref type="bibr" target="#b6">(7)</ref>, and instead have a fully connected layer with (m + n) 2 parameters which receives Z and recon-structsẐ, the architecture of the network will be similar to the deep subspace clustering networks (DSC) proposed in <ref type="bibr" target="#b20">[21]</ref> for the task of subspace clustering. As an ablation study, we use this method to extract sparse codes and then apply the same classification rule as in <ref type="bibr" target="#b8">(9)</ref> to estimate class labels for the test set. We call this method DSC-SRC.</p><p>Table III reveals that while the regularization norm on the coefficient matrix is selected between 1 and 2 , it does not have much effect on the performance of the classification task. However, in our experiments, we observed that for norms smaller than 1, the problem is not stable and often does not converges. In addition, DSC-SRC cannot provide a desirable performance. Note that the fully-connected layer in this method (counterpart to our sparse coding layer) does not limit the testing features to be reconstructed with only the training features. As a result, it is possible that testing features shape an isolated group that does not have a strong connection to the training features. This makes it more difficult to estimate a label for the test samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Street view house numbers</head><p>The SVHN dataset <ref type="bibr" target="#b26">[27]</ref> contains 630,420 color images of real-world house numbers collected from Google Street View images. This dataset has three splits as the training set with 73,257 images, the testing set with 26,032 images and an extra set containing 531,131 additional samples. In this experiment, similar to our experiments on MNIST, we randomly select 160 images per digit from the training split and 40 per digit from the test split. This dataset is much more challenging than MNIST. This is in part due to the large variations of data. Furthermore, many samples in this dataset contain multiple digits in an image. The task is to classify the center digit.</p><p>The second row in <ref type="table" target="#tab_1">Table II</ref> compares the performance of different SRC methods. This table demonstrates the advantage of our method. While the classification task is much more challenging on SVHN than MNIST, the gap between the performance of our method and the second best performance is even more. The next best performing method is VGG19-SRC which performs 14.86% behind the accuracy of our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. UMD mobile faces</head><p>The UMD mobile face dataset (UMDAA-01) <ref type="bibr" target="#b27">[28]</ref> contains 750 front-facing camera videos of 50 users captured while using a smartphone. This dataset has been collected over three different sessions. This dataset was originally collected for the active authentication task, but since its frames include challenging facial image instances with various illumination and pose conditions it has also been used for other tasks <ref type="bibr" target="#b35">[36]</ref>, <ref type="bibr" target="#b36">[37]</ref>. In this experiment, we randomly select 50 facial images per subjects from the data in Session 1. <ref type="figure">Figure 2</ref> shows some sample images from this dataset.</p><p>The performance of various SRC methods on the UMDAA-01 dataset are tabulated in the third row of <ref type="table" target="#tab_1">Table II</ref>  challenging datasets are better represented by our method. This is because our method not only efficiently finds the sparse codes, but also it seeks for a representation of data (the output of the encoder) that is especially suitable for sparse representation.</p><p>Comparison to state-of-the-art classification networks: While deep neural networks perform very well when they are trained on large datasets, in the case of limited number of labeled training samples, they often tend to overfit to the training samples. The objective of this experiment is to analyze the performance of our approach in such circumstances. We compare our method to the following classification networks: VGG-19 <ref type="bibr" target="#b29">[30]</ref>, Inception-V3 <ref type="bibr" target="#b30">[31]</ref>, Resnet-50 <ref type="bibr" target="#b31">[32]</ref> and Densenet-169 <ref type="bibr" target="#b32">[33]</ref>. We first pre-train the networks on the Imagenet dataset <ref type="bibr" target="#b28">[29]</ref>, and then fine-tune them on the available training samples in UMDAA-01. <ref type="figure" target="#fig_2">Figure 4</ref> shows the performance of the classification networks on four different versions of UMDAA-01 dataset with varying number of training samples. The four versions are created by randomly splitting the dataset into sets of training and testing samples that respectively contain 20%, 40%, 60% and 80% of the total number of samples as training samples and use the rest of samples as the testing set. As the figure suggests, accuracy improves by increasing the number of training samples in all the cases. However, the results show better performances for DSRC even when less training data is available.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. CONCLUSION</head><p>We presented an autoencoder-based sparse coding network for SRC. In particular, we introduced a sparse coding layer that is located between the conventional encoder and decoder networks. This layer recovers sparse codes of embedding features that are received from the encoder. The spare codes are later used to estimate the class labels of testing samples. We discussed a framework that allows an end-to-end training. Various experiments on three different image classification datasets showed that the proposed network leads to sparse representations that give better classification results than stateof-the-art SRC methods. <ref type="bibr" target="#b5">6</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX: CONVERGENCE</head><p>To empirically show the convergence of our proposed method, in <ref type="figure" target="#fig_3">Figure 5</ref>, we plot the values of the objective function of DSRC in the experiment with the UMDAA-01 dataset and its classification accuracy in different iterations. The reported loss values in <ref type="figure" target="#fig_3">Figure 5</ref> are scaled to have a maximum value of one. As can be seen from the figure, our algorithm converges in a few iterations. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>1 Fig. 1 .</head><label>11</label><figDesc>An overview of the proposed deep SRC network. The trainable parameters of sparse coding layer are depicted with solid blue lines. Note that Z train =Ẑ train , and Ztest ≈Ẑtest = Z train A.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Visualization of the sparse coding matrix (A) in the experiment with the USPS dataset. Note that for better visualization the absolute value of the transposed A (i.e. |A T |) is shown.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .</head><label>4</label><figDesc>Effect of the number of training samples on the performance of different classification networks. The figure shows five-fold averaged classification accuracies of the methods trained on varying number of training samples in the UMDAA-01 dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 .</head><label>5</label><figDesc>Values of the DSRC's loss function in the experiment on the UMDAA-01 dataset vs iterations. The loss values are scaled to have the maximum value of one.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE I DETAILS</head><label>I</label><figDesc>OF OUR NETWORKS. NOTE THAT THE NUMBER OF PARAMETERS IN THE SPARSE CODING LAYER RELY ON THE SIZE OF DATASET INCLUDING THE n TRAINING AND m TEST SAMPLES.</figDesc><table><row><cell>Encoder</cell><cell>Layer Conv 1 Conv 2 Conv 3 Conv 4</cell><cell>Input X Conv 1 Conv 2 Conv 3</cell><cell>Output Conv 1 Conv 2 Conv 3 Z</cell><cell>Kernel 1 × 5 × 5 × 10 1 × 3 × 3 × 20 1 × 3 × 3 × 30 1 × 3 × 3 × 30</cell><cell>(stride, pad) (2,1) (2,1) (1,0) (1,0)</cell></row><row><cell>Sparse coding layer</cell><cell>Θsc</cell><cell cols="2">ZẐ</cell><cell>m × n Parameters</cell><cell>-</cell></row><row><cell>Decoder</cell><cell cols="2">deconv 1Ẑ deconv 2 deconv 1</cell><cell>deconv 1 deconv 2</cell><cell>1 × 3 × 3 × 30 1 × 3 × 3 × 20</cell><cell>(1,0) (2,1)</cell></row><row><cell></cell><cell cols="3">deconv 3 deconv 2X</cell><cell>1 × 5 × 5 × 10</cell><cell>(2,1)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>. As can be seen, our proposed DSRC method similar to the experiments with SVHN provides remarkable improvements as compared to the other SRC methods. This clearly shows that more</figDesc><table><row><cell></cell><cell>1</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Accuracy</cell><cell>0.6 0.8</cell><cell></cell><cell></cell><cell></cell><cell>VGG19 InceptionV3</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>ResNet50</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>DenseNet</cell></row><row><cell></cell><cell>0.4</cell><cell></cell><cell></cell><cell></cell><cell>DSRC</cell></row><row><cell></cell><cell>20%</cell><cell>40%</cell><cell># training samples total # samples</cell><cell>× 100</cell><cell>60%</cell><cell>80%</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Robust face recognition via sparse representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ganesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="210" to="227" />
			<date type="published" when="2009-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">K-svd: An algorithm for designing overcomplete dictionaries for sparse representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Aharon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alfred</forename><surname>Bruckstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on signal processing</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">4311</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Sparse subspace clustering: Algorithm, theory, and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Elhamifar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2765" to="2781" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Robust visual tracking and vehicle classification via sparse representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xue</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haibin</forename><surname>Ling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="2259" to="2272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Joint sparse representation for robust multimodal biometrics recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Shekhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Vishal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Patel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nasser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rama</forename><surname>Nasrabadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="113" to="126" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A robust sparse representation based face recognition system for smartphones</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mahdi</forename><surname>Abavisani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohsen</forename><surname>Joneidi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shideh</forename><surname>Rezaeifar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shahriar Baradaran</forename><surname>Shokouhi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE Signal Processing in Medicine and Biology Symposium (SPMB)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Lfm signal detection and estimation based on sparse representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohsen</forename><surname>Joneidi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alireza</forename><surname>Zaeemzadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shideh</forename><surname>Rezaeifar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mahdi</forename><surname>Abavisani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nazanin</forename><surname>Rahnavard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 49th Annual Conference on Information Sciences and Systems (CISS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Face-based multiple user active authentication on mobile devices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pramuditha</forename><surname>Perera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Vishal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Patel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Forensics and Security</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1240" to="1250" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Learning mixtures of separable dictionaries for tensor data: Analysis and algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohsen</forename><surname>Ghassemi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zahra</forename><surname>Shakeri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Waheed U</forename><surname>Sarwate</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bajwa</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.09284</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Multiple kernel learning for sparse representation-based classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shrivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">M</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="3013" to="3024" />
			<date type="published" when="2014-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Design of non-linear kernel dictionaries for object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Van Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">M</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">M</forename><surname>Nasrabadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="5123" to="5135" />
			<date type="published" when="2013-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Kernel sparse subspace clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">M</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2014 IEEE International Conference on Image Processing (ICIP)</title>
		<imprint>
			<date type="published" when="2014-10" />
			<biblScope unit="page" from="2849" to="2853" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Latent space sparse subspace clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">M</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">V</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2013 IEEE International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2013-12" />
			<biblScope unit="page" from="225" to="232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Kernel sparse representation-based classifier</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><forename type="middle">Da</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pei</forename><forename type="middle">Chann</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fan</forename><forename type="middle">Zhang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1684" to="1695" />
			<date type="published" when="2012-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Kernel sparse representation for image classification and face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">W</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">T</forename><surname>Chia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">6314</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Visual classification with multi-task joint sparse representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><forename type="middle">T</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Using the kernel trick in compressive sensing: Accurate signal recovery from fewer measurements</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanchao</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shannon</forename><surname>Hughes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="3940" to="3943" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Kernel dictionary learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hien Van Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Vishal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Patel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nasser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rama</forename><surname>Nasrabadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="2021" to="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Kernel sparse representation based classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhonghua</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhong</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wankou</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="120" to="128" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Latent space sparse and lowrank subspace clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">M</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">V</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of Selected Topics in Signal Processing</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="691" to="701" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Deep subspace clustering networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pan</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongdong</forename><surname>Lia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathieu</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Reid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Deep multimodal subspace clustering networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Abavisani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">M</forename><surname>Patel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of Selected Topics in Signal Processing</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1601" to="1614" />
			<date type="published" when="2018-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Decoding by linear programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Emmanuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terence</forename><surname>Candes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on information theory</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="4203" to="4215" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">For most large underdetermined systems of linear equations the minimal ??1-norm solution is also the sparsest solution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Donoho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications on Pure and Applied Mathematics: A Journal Issued by the Courant Institute of Mathematical Sciences</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="797" to="829" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Learning by transduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Gammerman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Volodya</forename><surname>Vovk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourteenth conference on Uncertainty in artificial intelligence</title>
		<meeting>the Fourteenth conference on Uncertainty in artificial intelligence</meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="1998" />
			<biblScope unit="page" from="148" to="155" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A database for handwritten text recognition research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><forename type="middle">J</forename><surname>Hull</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="550" to="554" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Reading digits in natural images with unsupervised feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuval</forename><surname>Netzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Bissacco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS workshop on deep learning and unsupervised feature learning</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">2011</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Domain adaptive sparse representation-based classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Vishal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rama</forename><surname>Shekhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">11th IEEE International Conference and Workshops on</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
	<note>Automatic Face and Gesture Recognition (FG)</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.1556</idno>
		<title level="m">Very deep convolutional networks for large-scale image recognition</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Rethinking the inception architecture for computer vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zbigniew</forename><surname>Wojna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2818" to="2826" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Densely connected convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4700" to="4708" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Tensorflow: a system for large-scale machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martín</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjay</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Isard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Operating Systems Design and Implementation</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="265" to="283" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Domain adaptive subspace clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mahdi</forename><surname>Abavisani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vishal</forename><surname>Patel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">British Machine Vision Conference</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Adversarial domain adaptive subspace clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mahdi</forename><surname>Abavisani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Vishal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Patel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Identity, Security, and Behavior Analysis</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
