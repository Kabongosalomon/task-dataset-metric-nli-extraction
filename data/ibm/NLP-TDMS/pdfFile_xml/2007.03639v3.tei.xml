<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Human Trajectory Forecasting in Crowds: A Deep Learning Perspective</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Parth</forename><surname>Kothari</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sven</forename><surname>Kreiss</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Alahi</surname></persName>
						</author>
						<title level="a" type="main">Human Trajectory Forecasting in Crowds: A Deep Learning Perspective</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>1</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T19:49+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-Pedestrians</term>
					<term>trajectory forecasting</term>
					<term>deep learn- ing</term>
					<term>social interactions</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Presence of social interactions: the trajectory of a person is affected by the motion of the other people in his/her surroundings. Modelling how the observation of one sequence</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Abstract-Since the past few decades, human trajectory forecasting has been a field of active research owing to its numerous real-world applications: evacuation situation analysis, deployment of intelligent transport systems, traffic operations, to name a few. Early works handcrafted this representation based on domain knowledge. However, social interactions in crowded environments are not only diverse but often subtle. Recently, deep learning methods have outperformed their handcrafted counterparts, as they learned about human-human interactions in a more generic data-driven fashion. In this work, we present an in-depth analysis of existing deep learning-based methods for modelling social interactions. We propose two knowledgebased data-driven methods to effectively capture these social interactions. To objectively compare the performance of these interaction-based forecasting models, we develop a large scale interaction-centric benchmark TrajNet++, a significant yet missing component in the field of human trajectory forecasting. We propose novel performance metrics that evaluate the ability of a model to output socially acceptable trajectories. Experiments on TrajNet++ validate the need for our proposed metrics, and our method outperforms competitive baselines on both real-world and synthetic datasets.</p><p>Index Terms-Pedestrians, trajectory forecasting, deep learning, social interactions I. INTRODUCTION Humans possess the natural ability to navigate in social environments. In other words, we have understood the social etiquettes of human motion like respecting personal space, yielding right-of-way, avoid walking through people belonging to the same group. Our social interactions lead to various complex pattern-formation phenomena in crowds, for instance, the emergence of lanes of pedestrians with uniform walking direction, oscillations of the pedestrian flow at bottlenecks. The ability to model social interactions and thereby forecast crowd dynamics in real-world environments is extremely valuable for a wide range of applications: infrastructure design <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>, traffic operations <ref type="bibr" target="#b3">[4]</ref>, crowd abnormality detection systems <ref type="bibr" target="#b4">[5]</ref>, evacuation situation analysis <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>, deployment of intelligent transport systems <ref type="bibr">[11]</ref>, <ref type="bibr">[12]</ref>, <ref type="bibr" target="#b10">[13]</ref>, <ref type="bibr" target="#b11">[14]</ref> and recently helping in the broad quest of building a digital twin of our built environment. However, modelling social interactions is an extremely challenging task as there exists no fixed set of rules which govern human motion. A task closely related to learning human social interactions is forecasting the movement of the surrounding people, which conform to common social norms. We refer to this task of forecasting the human motion as human trajectory forecasting.</p><p>Before formally defining human trajectory forecasting, we introduce the notion of Trajectory and Scene. We define a This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>X1</head><p>X5 X3 X2 X4 <ref type="figure">Fig. 1</ref>: Human trajectory forecasting is the task of forecasting the future trajectories (dashed) of all humans which conform to the social norms, given the past observed scene (solid). The presence of social interactions distinguish human trajectory forecasting from other sequence modelling tasks: the primary pedestrian (X1) deviates from his direction of motion to avoid a collision, by forecasting the trajectory of the child (X2).</p><p>Trajectory as the time-profile of pedestrian motion states. Generally, these states are the position and velocity of a human. However, we can consider more complex states like body pose, to glean more information about a person's movement. We define a Scene as a collection of trajectories of multiple humans interacting in a social setting. A scene may also comprise physical objects and non-navigable areas that affect the human trajectories, e.g., walls, doors, and elevators. Also, when required, we refer to a particular pedestrian of interest in the scene as the Primary pedestrian. We define human trajectory forecasting as follows:</p><p>Given the past trajectories of all humans in a scene, forecast the future trajectories which conform to the social norms.</p><p>Human trajectory forecasting is primarily a sequence modelling task. The typical challenges for a sequence modelling task are (1) encoding observation sequence: we need to learn to model the long-term dependency in the past trajectory effectively, (2) multimodality: given the history of a scene, multiple futures (predictions) are plausible. In addition to this, for human trajectory forecasting, there exist two crucial challenges that differentiate it from other sequence prediction tasks such as language modelling, weather forecasting, and stock market forecasting (see <ref type="figure">Fig 1)</ref>: affects the forecast of another sequence is an essential requirement for a good human trajectory forecasting model. • Physically acceptable outputs: a good human trajectory forecasting model should provide physically acceptable outputs, for instance, the model prediction should not undergo collisions. Quantifying the physical feasibility of a model prediction is crucial for safety-critical applications.</p><p>Our objective is to encode the observed scene into a representation that captures all information necessary to forecast human motion. To focus on learning the social interactions that affect social motion, we assume that there do not exist any physical constraints in our scenes. The future trajectory can also be affected by the long-term goal of the human, which cannot always be observed or inferred. We therefore focus on short-term human trajectory forecasting (next 5 secs).</p><p>Following the success of Social LSTM <ref type="bibr" target="#b12">[15]</ref>, a variety of neural networks (NN) based modules that model social interactions have been proposed in literature. In this work, we explicitly focus on the design of these interaction modules and not the entire forecasting model. The challenge in designing these interaction modules lies in handling a variable number of neighbours and modelling how they collectively influence one's future trajectory. We present a high-level pipeline encompassing most of the existing designs of interaction modules. Based on our taxonomy, we propose two novel modules which incorporate domain knowledge into the NNbased pipeline. As a consequence, these modules are better equipped to learn social etiquettes like collision avoidance and leader-follower. A long-standing question in NN-based trajectory forecasting models is to explore techniques that help to explain the model decisions. In this work, we propose to utilize Layer-wise Relevance Propagation (LRP) <ref type="bibr" target="#b13">[16]</ref> to explain the decisions of our trajectory forecasting models. To the best of our knowledge, this is the first work that applies LRP in a regression setting, to infer inter-sequence (neighbours) effects on the model output.</p><p>To demonstrate the efficacy of a trajectory forecasting model, one needs to have the means to objectively compare with other forecasting baselines on good quality datasets. However, current methods have been evaluated on different subsets of available data without a proper sampling of scenes in which social interactions occur. As our final contribution, we introduce TrajNet++, a large scale interaction-centric trajectory forecasting benchmark comprising explicit agentagent scenarios. Our benchmark provides proper indexing of trajectories by defining a hierarchy of trajectory categorization. In addition, we provide an extensive evaluation system to test the gathered methods for a fair comparison. In our evaluation, we go beyond the standard distance-based metrics and introduce novel metrics that measure the capability of a model to emulate pedestrian behavior in crowds. We demonstrate the efficacy of our proposed domain-knowledge based baselines on TrajNet++, in comparison to various interaction encoder designs. Furthermore, we illustrate how the decisions of our proposed model architecture can be explained using LRP in real-world scenarios.</p><p>To summarize, our main contributions are as follows:</p><p>1) We provide an in-depth analysis of existing designs of NN-based interaction encoders along with their source code. We explain the decision-making of trajectory forecasting models by extending layer-wise relevance propagation to the regression setting of trajectory forecasting. 2) We propose two simple yet novel methods driven by domain knowledge for capturing social interactions. 3) We present TrajNet++, a large scale interaction-centric trajectory forecasting benchmark with novel evaluation metrics that quantify the physical feasibility of a model.</p><p>II. RELATED WORK Finding the ideal representation to encode human social interactions in crowded environments is an extremely challenging task. Social interactions are not only diverse but often subtle. In this work, we consider microscopic models of pedestrian crowds, where collective phenomena emerge from the complex interactions between many individuals (self-organizing effects). Current human trajectory forecasting works can be categorized into learning human-human (social) interactions or human-space (physical) interactions or both. Our work is focused on deep learning based models that capture social interactions. In this section, we review the work done for modelling the human-human interactions to obtain the social representation.</p><p>With a specific focus on pedestrian path forecasting problem, Helbing and Molnar <ref type="bibr" target="#b14">[17]</ref> presented a force-based motion model with attractive forces (towards the goal of a person and towards his/her group) and repulsive forces (away from people not belonging to a person's group and physical obstacles), called Social Force model, which captures the social and physical interactions. Their seminal work displays competitive results even on modern pedestrian datasets and has been extended for improved trajectory forecasting <ref type="bibr" target="#b15">[18]</ref>, <ref type="bibr" target="#b16">[19]</ref>, <ref type="bibr" target="#b17">[20]</ref>, <ref type="bibr" target="#b18">[21]</ref>, tracking <ref type="bibr" target="#b19">[22]</ref>, <ref type="bibr" target="#b20">[23]</ref>, <ref type="bibr" target="#b21">[24]</ref> and activity forecasting <ref type="bibr" target="#b22">[25]</ref>, <ref type="bibr" target="#b23">[26]</ref>. Burstedde et al. <ref type="bibr" target="#b24">[27]</ref> utilize the cellular automaton model, another type of microscopic model, for predicted pedestrian motion. In their model, the environment is divided into uniformly distributed grids and each pedestrian has a matrix of preference to determine the transition to neighbouring cells. The matrix of preference is determined by the pedestrian's own intent along with the locations of surrounding agents. Similar to social force, the cellular automaton model has been extended over the years for improved trajectory forecasting <ref type="bibr" target="#b25">[28]</ref>. Another prominent model for simulating human motion is Reciprocal Velocity Obstacles (RVO) <ref type="bibr" target="#b26">[29]</ref>, which guarantees safe and oscillation-free motion, assuming that each agent follows identical collision avoidance reasoning. Social interaction modelling has been approached from different perspectives such as Discrete Choice framework <ref type="bibr" target="#b27">[30]</ref>, continuum dynamics <ref type="bibr" target="#b28">[31]</ref> and Gaussian processes <ref type="bibr" target="#b29">[32]</ref>, <ref type="bibr" target="#b30">[33]</ref>, <ref type="bibr" target="#b31">[34]</ref>. Robicquet et al. <ref type="bibr" target="#b32">[35]</ref> defined social sensitivity to characterize human motion into different navigation styles. Alahi et al. <ref type="bibr" target="#b33">[36]</ref> defined Social Affinity Maps to link broken or unobserved trajectories to forecast pedestrian destinations. Yi et al. <ref type="bibr" target="#b34">[37]</ref> exploited crowd grouping as a cue to better forecast trajectories. However, all these methods use handcrafted functions based on relative distances and specific rules to model interactions. These functions impose not only strong priors but also have limited capacity when modelling complex interactions. In recent times, methods based on neural networks (NNs) that infer interactions in a data-driven fashion have been shown to outperform the works mentioned above.</p><p>Inspired by the application of recurrent neural networks (RNNs) in diverse sequence prediction tasks <ref type="bibr" target="#b35">[38]</ref>, <ref type="bibr" target="#b36">[39]</ref>, <ref type="bibr" target="#b37">[40]</ref>, <ref type="bibr" target="#b38">[41]</ref>, Alahi et al. <ref type="bibr" target="#b12">[15]</ref> proposed Social LSTM, the first NNbased model for human trajectory forecasting. Social LSTM is an LSTM <ref type="bibr" target="#b39">[42]</ref> network with a novel social pooling layer to capture social interactions of nearby pedestrians. RNNs incorporating social interactions allow anticipating interactions that can occur in a more distant future. The social pooling module has been extended to incorporate physical space context <ref type="bibr" target="#b40">[43]</ref>, <ref type="bibr" target="#b41">[44]</ref>, <ref type="bibr" target="#b42">[45]</ref>, <ref type="bibr" target="#b43">[46]</ref>, <ref type="bibr" target="#b44">[47]</ref>, <ref type="bibr" target="#b45">[48]</ref> and various other designs of NN-based interaction module have been proposed <ref type="bibr" target="#b46">[49]</ref>, <ref type="bibr" target="#b47">[50]</ref>, <ref type="bibr" target="#b48">[51]</ref>, <ref type="bibr" target="#b49">[52]</ref>, <ref type="bibr" target="#b50">[53]</ref>, <ref type="bibr" target="#b51">[54]</ref>, <ref type="bibr" target="#b52">[55]</ref>, <ref type="bibr" target="#b53">[56]</ref>, <ref type="bibr" target="#b54">[57]</ref>, <ref type="bibr" target="#b55">[58]</ref>, <ref type="bibr" target="#b56">[59]</ref>, <ref type="bibr" target="#b57">[60]</ref>, <ref type="bibr" target="#b58">[61]</ref>. Pfieffer et al. <ref type="bibr" target="#b46">[49]</ref> proposed an angular pooling grid for efficient computation. Shi et al. <ref type="bibr" target="#b47">[50]</ref> proposed an elliptical pooling grid placed along the direction of movement of the pedestrian with more focus on the pedestrians in the front. Bisagno et al. <ref type="bibr" target="#b48">[51]</ref> proposed to consider only pedestrians not belonging to the same group during social pooling. While modelling social interactions, Hasan et al. <ref type="bibr" target="#b56">[59]</ref>, <ref type="bibr" target="#b57">[60]</ref> based on domain knowledge, only consider the pedestrians in the visual frustum of attention <ref type="bibr" target="#b59">[62]</ref>. Gupta et al. <ref type="bibr" target="#b49">[52]</ref> propose to encode neighbourhood information through the use of a permutationinvariant (symmetric) max-pooling function. Zhang et al. <ref type="bibr" target="#b50">[53]</ref> proposed to refine the state of the LSTM cell using message passing algorithms. Zhu et al. <ref type="bibr" target="#b51">[54]</ref> proposed a novel star topology to model interactions. The center hub maintains information of the entire scene which each pedestrian can query. Ivanovic et al. <ref type="bibr" target="#b52">[55]</ref> and Salzmann et al. <ref type="bibr" target="#b58">[61]</ref> proposed to sum-pool the neighbour states and pass it through an LSTMbased encoder to obtain the interaction vector. Liang et al. <ref type="bibr" target="#b53">[56]</ref> proposed to utilize geometric relations obtained from the spatial distance between pedestrians, to derive the interaction representation. <ref type="bibr" target="#b54">[57]</ref>, <ref type="bibr" target="#b55">[58]</ref> propose to input the relative position and relative velocity of nearest neighbours directly to an MLP to obtain the interaction vector. Many works <ref type="bibr" target="#b60">[63]</ref>, <ref type="bibr" target="#b61">[64]</ref>, <ref type="bibr" target="#b62">[65]</ref>, <ref type="bibr" target="#b63">[66]</ref>, <ref type="bibr" target="#b64">[67]</ref>, <ref type="bibr" target="#b65">[68]</ref>, <ref type="bibr" target="#b66">[69]</ref>, <ref type="bibr" target="#b67">[70]</ref>, <ref type="bibr" target="#b68">[71]</ref>, <ref type="bibr" target="#b69">[72]</ref>, <ref type="bibr" target="#b70">[73]</ref>, <ref type="bibr" target="#b71">[74]</ref>, <ref type="bibr" target="#b72">[75]</ref>, <ref type="bibr" target="#b73">[76]</ref>, <ref type="bibr" target="#b74">[77]</ref> propose interaction module designs based on attention mechanisms <ref type="bibr" target="#b75">[78]</ref>, <ref type="bibr" target="#b76">[79]</ref> to identify the neighbours which affect the trajectory of the person of interest. The attention weights are either learned or handcrafted based on domain knowledge (e.g., euclidean distance). For an extensive survey of all human forecasting methods capturing both social and physical interactions, one can refer to Rudenko et al. <ref type="bibr" target="#b77">[80]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. PROBLEM STATEMENT</head><p>Our objective is to forecast the future trajectories of all the pedestrians present in a scene. The network takes as input the trajectories of all the people in a scene denoted by X = { 1 , 2 , . . . , } and our task is to forecast the corresponding future trajectories Y = { 1 , 2 , . . . , }. The position and velocity of pedestrian at time-step is denoted by x = ( , ) and v respectively. We receive the positions of all pedestrians at time-steps = 1, . . . , and want to forecast the future positions from time-steps = +1 to . We denote our predictions usingŶ. At time-step , we denote the state of pedestrian by s . The state can refer to different attributes of the person, e.g., the position concatenated with velocity (s = [x , v ]). The problem statement can be extended to take as input more attributes at each time-step, e.g., the body pose, as well as predicting most-likely future trajectories. We focus on the design choices for the interaction module.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. METHOD</head><p>A global data-driven pipeline for forecasting human motion is illustrated in <ref type="figure" target="#fig_0">Fig 2.</ref> It comprises of the motion encoding module, the interaction module and the decoder module. On a high level, the motion encoding module is responsible for encoding the past motion of pedestrians. The interaction module learns to capture the social interactions between pedestrians. The motion encoding module and the interaction module are not necessarily mutually exclusive. The output of the interaction module is the social representation of the scene. The social representation is passed to the decoder module to predict a single trajectory or a trajectory distribution depending on the decoder architecture. Since our benchmark TrajNet++ focuses on interaction-centric scenes, in this work, we focus on investigating the design choices for the interaction module.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Interaction Module</head><p>Humans have the capability to navigate with ease in complex, crowded environments by following unspoken social rules, which result in social interactions. In recent years, these social interactions are captured effectively by designing novel interaction modules. In this section, we broadly categorize the different data-driven interaction encoders studied in literature, based on their underlying components. We show how most of these designs fall within our categorization. Following this, in the experimental section we empirically analyze the effectiveness of each of these components and provide recommendations for designing improved interaction modules. The existing designs can be broadly categorized into (1) Grid based and (2) Non-Grid based. We now discuss in detail the different components of these interaction encoders.</p><p>1) Grid Based Interaction Models: In grid-based models, the interaction module takes as input a local grid constructed around the pedestrian of interest. Each cell within the grid represents a particular spatial position relative to the pedestrian of interest. The design of grid-based models largely differ based on neighbour input state representation. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Neighbour input state: Consider an</head><p>× grid around the primary pedestrian, where each cell contains information about neighbours located in that corresponding position. Existing designs provides the information of the neighbours in two main forms: (a) Occupancy Pooling <ref type="bibr" target="#b12">[15]</ref>, <ref type="bibr" target="#b42">[45]</ref> where each cell in the grid indicates the presence of a neighbour (see <ref type="figure" target="#fig_1">Fig 3a)</ref> (b) Social Pooling <ref type="bibr" target="#b12">[15]</ref>, <ref type="bibr" target="#b42">[45]</ref>, <ref type="bibr" target="#b44">[47]</ref>, <ref type="bibr" target="#b48">[51]</ref>, <ref type="bibr" target="#b40">[43]</ref>, <ref type="bibr" target="#b45">[48]</ref>, <ref type="bibr" target="#b41">[44]</ref> where each cell contains the entire past history of the neighbour, represented by, e.g., the LSTM hidden state of the neighbours (see <ref type="figure" target="#fig_1">Fig 3c)</ref>. The obtained grid is embedded using an MLP to get the interaction vector .</p><p>Directional Pooling In this work, based on our domain knowledge, we propose to take as input the relative velocity of each neighbour in the corresponding grid cell. When humans navigate in crowded environments, in addition to relative positions of the neighbours, they naturally tend to focus on the neighbours' velocities. For the same positional configuration, the relative velocities of neighbours lead to the concepts of leaderfollower and collision avoidance i.e., one exhibits leaderfollower and accelerates when the neighbour is in front and walking along the same direction, while the same positional configuration leads to deceleration when the neighbour moves in the opposite direction. Having access to relative velocities can therefore significantly improve model performance in preventing collisions.</p><p>Furthermore, due to the complex nature of real-world movements combined with the possibility of noisy measurements, the current design of social pooling can sometimes fail to learn the important notion of preventing collisions. One reason lies in the fact that the models are trained to minimize the displacement errors <ref type="bibr" target="#b12">[15]</ref>, <ref type="bibr" target="#b64">[67]</ref> and not collisions. The models are expected to learn the notion of collision avoidance implicitly. By focusing explicitly on relative velocity configurations, we can obtain more domain-knowledge driven control over the design of the interaction encoder. When the model explicitly focuses only on relative velocity configuration (rather than abstract hidden-state configurations), which is sufficient to learn concepts of leader-follower and collision avoidance, the resulting simple design has the potential to output safer predictions. Furthermore, directional pooling design are computationally faster to deploy in real-time scenarios due to the reduced size of input ( × ×2 in comparison to × × where is the dimension of the hidden-state). One might additionally argue to only consider the neighbours in front of the primary pedestrian as proposed in <ref type="bibr" target="#b59">[62]</ref>. We will demonstrate in the experimental section that the directional pooling implicitly learns this notion of only focusing on the neighbours in the field-of-view of the primary pedestrian.</p><p>2) Non-Grid Based Interaction Models: Non-grid based modules, as the name suggests, capture the social interactions in a grid-free manner. The challenge in designing non-grid based models lies in (1) handling a variable number of neighbours and (2) aggregating the state information of multiple neighbours to obtain the interaction vector . As illustrated in <ref type="figure">Fig 4</ref>, the design choices of these modules can be categorized based on four factors: (a) neighbour input state, (b) input state embedding, (c) neighbour information aggregation strategy, and (d) aggregated vector embedding.</p><p>Neighbour input state: Non-grid based methods do not contain an implicit notion of the spatial position of neighbours with respect to the primary pedestrian, unlike the gridbased counterparts. Hence, almost all the existing designs in literature take as input the relative spatial position of the neighbours. Another popular input choice is the hidden-state of the neighbouring pedestrian <ref type="bibr" target="#b64">[67]</ref>, <ref type="bibr" target="#b49">[52]</ref> as the hidden-state has the ability to encode information regarding the motion history of the corresponding pedestrian. Amirian et al. <ref type="bibr" target="#b65">[68]</ref> models the neighbour states using interaction-centric geometric features like bearing angle between agents and distance of closest approach <ref type="bibr" target="#b78">[81]</ref>. Ivanovic et al. <ref type="bibr" target="#b52">[55]</ref> takes as input the velocity of neighbours. In this work, we argue that inputting relative velocity of neighbours is an important factor for reducing collisions in model predictions.</p><p>Input state embedding: The input states of the neighbours <ref type="figure">Fig. 4</ref>: Illustration of the non-grid based encoding modules to obtain the interaction vector. The challenge lies in handling a variable number of neighbours and aggregating their state information to construct the interaction vector (a) Neighbour information is aggregated via attention mechanism (b) Neighbour information is aggregated utilizing a symmetric function (c) Neighbour information is aggregated via concatenation.</p><formula xml:id="formula_0">X1 X5 X3 X2 X4 MLP / LSTM X5 X3 X2 X4 (a) ATTENTION (b) MAXPOOL (c) CONCAT NEIGHBOUR STATE EMBEDDING NEIGHBOUR STATE AGGREGATION 1. MLP 2. LSTM</formula><p>are usually embedded using an MLP. However, recent works <ref type="bibr" target="#b79">[82]</ref>, <ref type="bibr" target="#b67">[70]</ref> based on graph neural network <ref type="bibr" target="#b80">[83]</ref> designs, embed the relative input states using an LSTM. Each connection of a primary pedestrian to his neighbour is modelled using a different LSTM. The LSTM helps to capture the evolution of the relative neighbour states, unlike the first-order MLP.</p><p>Aggregation strategy: One of the most important challenges of non-grid based models is to find the ideal strategy to aggregate the information of all the neighbours. Gupta et al. <ref type="bibr" target="#b49">[52]</ref> proposed to aggregate the interaction information by applying a symmetric max-pool function on the LSTM hiddenstates of the neighbouring pedestrians. Ivanovic et al. <ref type="bibr" target="#b52">[55]</ref> and Hasan et al. <ref type="bibr" target="#b56">[59]</ref> utilized the symmetric sum-pooling function.</p><p>A large body of works utilize the attention mechanism <ref type="bibr" target="#b75">[78]</ref>, <ref type="bibr" target="#b76">[79]</ref> to determine the weights of different neighbours in predicting the future trajectory. These weights can be either hand-crafted <ref type="bibr" target="#b61">[64]</ref> or learnt in a data-driven manner <ref type="bibr" target="#b64">[67]</ref>, <ref type="bibr" target="#b63">[66]</ref>, <ref type="bibr" target="#b65">[68]</ref>. The attention mechanism can be applied multiple times to model higher-order spatial interactions. The commonly used data-driven attention mechanism is the design proposed for the Transformer architecture <ref type="bibr" target="#b75">[78]</ref>.</p><p>A simple baseline for aggregating neighbour information is to concatenate the neighbour embeddings. To tackle the issue of handling variable number of neighbours, we investigate the performance of the concatenation scheme by selecting the topneighbours based on a defined criterion, (e.g., euclidean distance). Despite the simplicity, we demonstrate that the concatenation strategy performs at par with its sophisticated counterparts.</p><p>Aggregated vector embedding: The aggregated neighbour vector is usually passed through an MLP, with the exception of Ivanovic et al. <ref type="bibr" target="#b52">[55]</ref> passes the sum-pooled neighbour information through an LSTM, to obtain the interaction vector . We argue that encoding the aggregated vector using LSTMs offers the advantage of modelling higher-order interactions in the temporal domain. In other words, the interaction module learns how the interaction representations evolve over time.</p><p>For brevity, the interaction modules are denoted using acronyms based on their designs. The acronyms are of the form P-Q-R-S where P denotes the input to the module, Q denotes the state embedding module, R denotes the information aggregation mechanism and S denotes aggregated vector embedding module. The choices for each of these components is provided in <ref type="table" target="#tab_2">Table I</ref>. The table also illustrates how our categorization encompasses the popular designs on NN-based interaction modules in literature.</p><p>DirectConcat Equivalent to our proposed D-Grid, we now describe its nongrid counterpart DirectConcat. Grid-based models, based on their design, implicitly consider only those neighbours that are within the grid constructed around the primary pedestrian. We argue that modelling interactions of all pedestrians (even those far away) can lead to the model learning spurious correlations. Thus, we propose to consider only the top-neighbours closest to the primary pedestrian. We will demonstrate in the experimental section that if is set to a large value, i.e. if the model considers all pedestrians in the scene, the model deteriorates in its ability to learn collision avoidance.</p><p>Similar to aggregating the obtained directional grid by flattening the obtained grid, in DirectConcat we propose to concatenate the relative-velocity and relative-position embeddings of top-neighbours. This preserves the unique identity of the neighbours as compared to mixing the different embeddings like in max-pooling <ref type="bibr" target="#b49">[52]</ref> or sum-pooling <ref type="bibr" target="#b52">[55]</ref>. Finally, we pass the aggregated vector through an LSTM as compared to an MLP. This design choice helps to model higher-order spatiotemporal interactions better and is more robust to noise in the real-world measurements as LSTM controls the evolution of the interaction vector. We demonstrate in the experimental section that indeed the LSTM embedding further helps to improve the collision metric. By design, DirectConcat falls under the D-MLP-ConC-LSTM architecture of our categorization. We <ref type="bibr" target="#b12">[15]</ref>, <ref type="bibr" target="#b42">[45]</ref>, <ref type="bibr" target="#b46">[49]</ref> </p><formula xml:id="formula_1">Acronym (P-Q-R-S) Input (P) Embed-I (Q) Aggreg. (R) Embed-II (S) References O-Grid Position None Grid MLP O-LSTM</formula><formula xml:id="formula_2">S-Grid H-State None Grid MLP S-LSTM [15]</formula><p>, <ref type="bibr" target="#b42">[45]</ref>, <ref type="bibr" target="#b44">[47]</ref>, <ref type="bibr" target="#b48">[51]</ref>, <ref type="bibr" target="#b40">[43]</ref>, <ref type="bibr" target="#b45">[48]</ref>, <ref type="bibr" target="#b41">[44]</ref>, <ref type="bibr">[</ref>  <ref type="bibr" target="#b65">[68]</ref>, <ref type="bibr" target="#b61">[64]</ref>, <ref type="bibr" target="#b63">[66]</ref>, <ref type="bibr" target="#b50">[53]</ref>, <ref type="bibr" target="#b60">[63]</ref>, <ref type="bibr" target="#b62">[65]</ref>, <ref type="bibr" target="#b68">[71]</ref>, <ref type="bibr">[</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Forecasting Model</head><p>We now describe the rest of the components of the forecasting model. To claim that a particular design of the interaction module is superior, it is essential to keep the rest of the forecasting model components constant. Only then we can be sure that it was the interaction module design that boosted performance, and not one of the extra added components. We choose the time-sequence encoder to be an LSTM due to its capability to handle varying input length and capture longterm dependencies. Moreover, most works have LSTMs as their base motion-encoding architecture.</p><p>The rest of the architecture we describe now is identical for all the methods described in the previous section. The state of person at time-step , s , is embedded using a single layer MLP to get the state embedding . We represent each person's state using his/her velocity, as switching the input representation from absolute coordinates to velocities increases the generalization power of sequence encoder. We obtain the interaction vector of person from the interaction encoder. We concatenate the interaction vector with the velocity embedding and provide the resultant vector as input to the sequenceencoding module. Mathematically, we obtain the following recurrence:</p><formula xml:id="formula_3">= (v ; ),<label>(1)</label></formula><formula xml:id="formula_4">ℎ = (ℎ −1 , [ ; ]; ),<label>(2)</label></formula><p>where is the embedding function, , are the weights to be learned. The weights are shared between all persons in the scene.</p><p>The hidden-state of the LSTM at time-step of pedestrian is then used to predict the distribution of the velocity at timestep + 1. Similar to Graves <ref type="bibr" target="#b81">[84]</ref>, we output a bivariate Gaussian distribution parametrized by the mean +1 = ( , ) +1 , standard deviation +1 = ( , ) +1 and correlation coefficient +1 :</p><formula xml:id="formula_5">[ , , ] = (ℎ −1 , ),<label>(3)</label></formula><p>where is modelled using an MLP and is learned.</p><p>Training: All the parameters of the forecasting model are learned by minimizing the negative log-likelihood (NLL) loss:</p><formula xml:id="formula_6">L ( ) = − ∑︁ = +1 log(P(v | , , )).<label>(4)</label></formula><p>Contrary to the general practice of training the model by minimizing the NLL loss for all the trajectories in the training dataset, we minimize the loss for only the primary pedestrian (defined in the next section) in each scene of the training dataset. We will demonstrate how this training procedure helps the model to better capture social interactions in the experimental section.</p><p>Testing: During test time, till time-step , we provide the ground truth position of all the pedestrians as input to the forecasting model. From time +1 to , we use the predicted position (derived from the predicted velocity) of each pedestrian as input to the forecasting model and predict the future trajectories of all the pedestrians. is modelled using a sequence encoder, the neighbour edges correspond to our input embeddings which are aggregated via attention mechanism. The resulting interaction vector is provided as input to the sequence encoder (vertex ).</p><p>1) Equivalence to Graph Neural Networks: Recently, graph neural networks (GNNs) have become popular for forecasting human motion. In the GNN setup, each pedestrian is represented as a node/vertex and two interacting pedestrians are connected via an edge . models the sequence representation of the associated pedestrian and edge updates according to the interactions between the associated pedestrians. We show an equivalence between dynamic-interaction-based graph neural networks and our proposed LSTM-based pipeline with S-X-Attn-MLP (where X ∈ {MLP, LSTM}) interaction encoding scheme, visually illustrated in <ref type="figure" target="#fig_2">Figure 5</ref>. Without loss of generality, let pedestrian be the primary pedestrian. Vertex is modelled using an LSTM sequence encoder. Edge takes as input the state of the neighbours and updates over time using an MLP or LSTM (input state embedding). At each time-step, the information of all connected edges is aggregated using attention mechanism (aggregation strategy), popularly referred to as GAT-pooling <ref type="bibr" target="#b82">[85]</ref> in GNN literature. Finally the aggregated vector is optionally passed through an MLP to obtain the interaction vector which is the input to the LSTM sequence encoder for . Social-BiGAT <ref type="bibr" target="#b64">[67]</ref> utilizes the S-MLP-Attn-MLP design, Social Attention <ref type="bibr" target="#b79">[82]</ref> utilizes the O-LSTM-Attn-MLP design while recently, STAR <ref type="bibr" target="#b72">[75]</ref> utilizes the S-MLP-Attn-MLP design with the sequence encoder for vertex being a Transformer <ref type="bibr" target="#b75">[78]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Explaining trajectory forecasting models</head><p>Trajectory forecasting models are deployed in many safetycritical applications like autonomous systems. In such scenarios, it becomes really important to gain insight into the decision-making of so-called 'blackbox' neural networks. Several works in literature attempt to explain the rationale behind the NN decisions <ref type="bibr" target="#b83">[86]</ref>, <ref type="bibr" target="#b13">[16]</ref>, <ref type="bibr" target="#b84">[87]</ref>, <ref type="bibr" target="#b85">[88]</ref>, <ref type="bibr" target="#b86">[89]</ref>. Out of these techniques, Layer-wise Relevance Propagation (LRP) is one of the most prominent methods in explainable machine learning.</p><p>LRP re-distributes the model output score to each of the input variables indicating the extent to which they contribute to the output. LRP works by reverse-propagating the prediction through the network by means of heuristic propagation rules that apply to each layer of a neural network <ref type="bibr" target="#b13">[16]</ref>. These propagation rules are based on a local conservation principle: the net quantity or relevance, received by any higher layer neuron is redistributed in the same amount to neurons of the layer below. Mathematically, if and are indices for neurons in two consecutive layers, and denoting by the relevance flowing between two neurons, we have the equations:</p><formula xml:id="formula_7">Σ = (5) = Σ<label>(6)</label></formula><p>On applying the local conservation principle across all the layers, we obtain global conservation of the output score when reverse propagated back to the inputs. Recently, Arras et al. <ref type="bibr" target="#b88">[90]</ref> have shown that the principle of LRP can also be applied to LSTMs. LRP has largely been explored in the domain of model classification i.e. the outputs are classification scores. In this work, we utilize LRP to determine on which neighbours (via the input pooling map) and past velocities (via the input velocity embedding) of the primary pedestrian our model focuses on, when regressing to the next predicted velocity. We achieve this by reverse-propagating both the x-component as well as y-component of predicted velocity (v pred = ( , )) and adding the obtained input relevance scores. To the best of our knowledge, we are the first work to empirically demonstrate that LRP provides reasonable explanations when extended to the regression task of trajectory forecasting. Moreover, the LRP technique is generic and can be applied on top of any trajectory forecasting network to analyze its predictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. TRAJNET++: A TRAJECTORY FORECASTING BENCHMARK</head><p>In this section, we present TrajNet++, our interactioncentric human trajectory forecasting benchmark. To demonstrate the efficacy of a trajectory forecasting model, the standard practice is to evaluate these models against baselines on a standard benchmark. However, current methods have been evaluated on different subsets of available data without proper sampling of scenes in which social interactions occur. In other words, a data-driven method cannot learn to model agentagent interactions if the benchmark comprises primarily of scenes where the agents are static or move linearly. Therefore, our benchmark comprises largely of scenes where social interactions occur. To this extent, we propose the following trajectory categorization hierarchy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Trajectory Categorization</head><p>We provide a detailed trajectory categorization <ref type="figure">(Fig 8)</ref>. This detailed categorization helps us not only to better sample trajectories for TrajNet++ dataset but also glean insights into the model performance in diverse scenarios, i.e., to verify whether the model captures all the different kinds of interactions.</p><p>To aid our categorization, we introduce the notion of a primary pedestrian as a reference pedestrian with respect to which we categorize scenes. Each scene has a primary pedestrian whose motion we want to forecast. We refer to the other pedestrians in the scene as neighbouring pedestrians.</p><p>We explain in detail our proposed hierarchy for trajectory categorization <ref type="figure">(Fig 8)</ref>. We also provide example scenarios for the same in <ref type="figure">Fig 6:</ref> 1) Static (Type I): If the euclidean displacement of the primary pedestrian in the scene is less than a specific threshold. 2) Linear (Type II): If the trajectory of the primary pedestrian can be correctly forecasted with the help of an Extended Kalman Filter (EKF). A trajectory is said to be correctly forecasted by EKF if the FDE between the ground truth trajectory and forecasted trajectory is less than a specific threshold. The rest of the scenes are classified as 'Non-Linear'. We further divide non-linear scenes into Interacting (Type III) and Non-Interacting (Type IV).</p><p>3) Interacting (Type III): These correspond to scenes where the primary trajectory undergoes social interactions. For a detailed categorization coherent with commonly observed social interactions, we divide interacting Using our defined trajectory categorization, we construct the TrajNet++ benchmark by sampling trajectories corresponding largely to 'Type III: Interacting' category.</p><p>trajectories into the following sub-categories (shown in <ref type="figure">Fig 7)</ref>. Using our defined trajectory categorization, we construct the TrajNet++ benchmark by sampling trajectories corresponding mainly to the Type III category. Moreover, having many Type-I scenes in a dataset can hamper the training of the model and result in misleading evaluation. Therefore, we remove such samples in the construction of our benchmark. The details of the categorization thresholds as well as the datasets which comprise our TrajNet++ benchmark are provided in the supplementary material. A few examples of our categorization in the real world are displayed in <ref type="figure">Fig 9.</ref> In addition to comprising well-sampled trajectories, TrajNet++ provides an extensive evaluation system to understand model performance better.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Evaluation Metrics</head><p>Unimodal Evaluation: Unimodal evaluation refers to the evaluation of models that propose a single future mode for a given past observation. The most commonly used metrics of human trajectory forecasting in the unimodal setting are (a) Leader Follower (b) Collision Avoidance (c) Group (d) Others <ref type="figure">Fig. 9</ref>: Sample scenes from our benchmark. In each of the samples, we illustrate a different social interaction between the primary pedestrian (yellow) and the corresponding interacting neighbours (red) in real world datasets. <ref type="figure">Fig. 10</ref>: Visual illustration of our proposed collision metrics.</p><p>In the example, the model prediction exhibits ground-truth collision (Col-II = 1) but no prediction collision (Col-I = 0).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Average Displacement Error (ADE) and Final Displacement</head><p>Error (FDE) defined as follows: 1) Average Displacement Error (ADE): Average 2 distance between ground truth and model prediction overall predicted time steps. 2) Final Displacement Error (FDE): The distance between the predicted final destination and the ground truth final destination at the end of the prediction period . These metrics essentially define different distance measures between the forecasted trajectory and the ground truth trajectory. With respect to our task, one of the most important aspects of human behavior in crowded spaces is collision avoidance. To ensure that models forecast feasible collisionfree trajectories, we propose two new collision-based metrics in our framework (see <ref type="figure">Fig 10)</ref>:</p><p>3</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>) Collision I -Prediction collision (Col-I):</head><p>This metric calculates the percentage of collision between the primary pedestrian and the neighbors in the forecasted future scene. This metric indicates whether the predicted model trajectories collide, i.e., whether the model learns the notion of collision avoidance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4) Collision II -Groundtruth collision (Col-II):</head><p>This metric calculates the percentage of collision between the primary pedestrian's prediction and the neighbors in the groundtruth future scene. We want to stress further the importance of the collision metrics in the unimodal setup. As mentioned earlier, human motion is multimodal. A model may forecast a physicallyfeasible future, which is different from the actual ground truth. Such a physically-feasible prediction can result in a large ADE/FDE, which can be misleading. Our Col-I metric can help overcome this limitation of ADE/FDE metrics and provides a solution to measure 'physical feasibility' of a prediction (aversion to a collision in this case). Col-II metric indicates whether the model understood the intention of the neighbours and predicted the desired trajectory mode indicated by fewer collisions with neighbours in ground truth. We believe our proposed collision metrics are an important step towards capturing the understanding of the model of human social etiquette in crowds.</p><p>Multimodal Evaluation: For models performing multimodal forecasting, i.e., outputting a future trajectory distribution, we provide the following metrics to measure their performance: 5) Top-k ADE: Given output predictions for an observed scene, this metric calculate the ADE of the prediction closest to the groundtruth trajectory, similar in spirit to Variety Loss <ref type="bibr" target="#b49">[52]</ref>. 6) Top-k FDE: Given output predictions for an observed scene, this metric calculate the FDE of the prediction closest to the groundtruth trajectory, similar in spirit to Variety Loss <ref type="bibr" target="#b49">[52]</ref>. For the Top-k metrics, we propose be small (3 as opposed to 20) as a model outputting uniformly-spaced predictions, irrespective of the input observation, can result in a much lower Top-20 ADE/FDE. 7) Average NLL: This metric was proposed by Boris et. al. <ref type="bibr" target="#b52">[55]</ref>. At each prediction step, the authors utilize a Kernel Density Estimate (KDE) <ref type="bibr" target="#b89">[91]</ref>. From these estimates, the log-likelihood of ground truth trajectory is computed at each time step and is subsequently averaged over the prediction horizon. This metric provides a good indication of the probability of the ground truth trajectory in the model prediction distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. EXPERIMENTS</head><p>In this section, we perform extensive experimentation on both TrajNet++ synthetic and real-world datasets to understand  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Implementation Details</head><p>The velocity of each pedestrian is embedded into a 64dimensional vector. The dimension of the interaction vector is 256. The dimension of the goal direction vector is 64. For grid-based interaction encoding, we construct a grid of size 16 × 16 with a resolution of 0.6 meters. The dimension of the hidden state of both the encoder LSTM and decoder LSTM is 128. As mentioned earlier, each pedestrian has its own encoder and decoder. The batch size is fixed to 8. We train using ADAM optimizer <ref type="bibr" target="#b90">[92]</ref> with a learning rate of 1e-3. We perform interaction encoding at every timestep. For the concatenation based models, we consider top-4 nearest neighbours based on euclidean distance unless stated otherwise. For the attention aggregation strategy, we utilize the attention mechanism proposed in the Transformer architecture <ref type="bibr" target="#b75">[78]</ref>.</p><p>Data augmentation is another technique that can help increase accuracy, which can get wrongly attributed to the interaction encoder. We use rotation augmentation as the data augmentation technique to regularize all the models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Interaction Models: Synthetic Experiments</head><p>We utilize synthetic datasets to validate the efficacy of various interaction modules in a controlled setup. For the synthetic dataset, since ORCA has access to the goals of each pedestrian, we embed the goal-direction and concatenate it to the velocity embedding (see <ref type="bibr">Eq 1)</ref>. <ref type="table" target="#tab_2">Table II</ref> quantifies the performance of the different designs of interaction modules published in the literature on TrajNet++ synthetic dataset. It is very interesting to note how our proposed Col-I metric provides a more complete picture of model performance. Observing only the distancebased metrics, one might wrongly conclude that the methods are similar in performance, however, they do not indicate the ability of the model to learn social etiquette (collision avoidance in this case). In safety-critical scenarios, it is more important for a model to prevent collisions in comparison to minimizing ADE/FDE. 1) Grid-Based Models: our proposed D-Grid outperforms O-Grid, especially in terms of Col-I, i.e., D-Grid learns better to avoid collisions. It is interesting to note that even though the motion encoder (LSTM) has the potential to infer the relative velocity of neighbours over time, there is a significant difference in performance when we explicitly provide relative velocity of the neighbours as input. Further, since ORCA is a first-order trajectory simulator dependent only on relative configuration of neighbours, one can explain the performance of D-Grid being at par with S-Grid in the controlled setup.</p><p>2) Aggregation Strategy: We focus on the information aggregation strategies for non-grid based encoders. It is evident that the baseline D-MLP-Conc-MLP of concatenating the neighbourhood information performs better than the sophisticated attention-based D-MLP-Attn-MLP and max-poolingbased D-MLP-MaxP-MLP alternatives. This performance can be attributed to the simplicity of the concatenation scheme along with its property to preserve the identity of the surrounding neighbours. The MaxPooling strategy mixes up the different embeddings of the neighbours resulting in a high collision loss.</p><p>3) LSTM-based interaction model: Among the nongrid LSTM-based designs, the drop in performance of D-MLP-SumPool-LSTM module <ref type="bibr" target="#b52">[55]</ref> can be attributed to (1) sum pooling which loses the individual identity of the neighbours and (2) encoding of absolute neighbour coordinates instead of relative coordinates: relational coordinates of agents to the target agent are easier to train than exact coordinates of agents. We notice that encoding the interaction information using LSTM [O-LSTM-Att-MLP, D-MLP-Conc-LSTM], improves performance over its MLP-based counterparts. MLP encoders, due to their non-recurrent nature, have no information regarding the interaction representation at the previous step. We argue that LSTMs can capture the evolution of interaction and therefore provide a better neighbourhood representation as the scene evolves, especially in cases where the input measurements are noisy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Interaction Models: Real World Experiments</head><p>Now, we discuss the performances of forecasting models on TrajNet++ real-world data. With the help of our defined trajectory categorization, we construct the TrajNet++ real-world benchmark by sampling trajectories corresponding mainly to Type III Interacting category. Having gained insights on the performance of different modules on controlled synthetic data, we explore the question, 'Do these findings generalize to the real world datasets comprising much more diverse interactions?' .0 (0.5) Non-Grid based methods S-MLP-MaxP-MLP <ref type="bibr" target="#b49">[52]</ref> 0.57/1.24 12.6 (0.9) 14.6 (0.7) S-MLP-Att-MLP <ref type="bibr" target="#b64">[67]</ref> 0.56/1.  We emphasize that our goal is to reduce Col-I without compromising distance-based metrics. <ref type="table" target="#tab_2">Table III</ref> provides an extensive evaluation of existing baselines on the Type III interacting trajectories of the TrajNet++ real dataset. We observe that Col-I metric is the differentiating factor for various model designs when compared on identical grounds. We hope that in future, researchers will incorporate the collision metrics while reporting their model performances on trajectory forecasting datasets. Moreover, the performance of ADE/FDE is similar ( including submitted methods) indicating that there exists a lot of scope to improve the performance of current trajectory forecasting models on a well-sampled interaction-centric test set.</p><p>1) Classical Methods: We first compare with the classical trajectory forecasting models, namely, Extended Kalman Filter (EKF), Social Force <ref type="bibr" target="#b14">[17]</ref>, and ORCA <ref type="bibr" target="#b26">[29]</ref>. Both Social Force and ORCA models forecast the future trajectory based on the assumption that each pedestrian has an intended direction of motion and a preferred velocity. We interpolate the observed trajectory to identify the virtual goals for each agent. Social Force and ORCA are calibrated to fit the TrajNet++ training data by minimizing ADE/FDE metrics, along with the constraint that collisions should be avoided</p><p>The high error of EKF can be attributed to the fact that the filter does not model social interactions. The interactionbased NN models outperform the handcrafted models in terms of the distance-based metrics, as NN have the ability to learn the subtle and diverse social interactions.</p><p>2) Grid-based modules: Our proposed D-Grid performs superior to O-Grid in the real world as well. It is interesting to compare the performances of D-Grid and S-Grid.</p><p>The current design of S-Grid fails to learn the notion of prediction collision. This reaffirms the fact that while training to minimize ADE/FDE, the hidden-state of LSTM is unable to provide representations necessary to avoid collisions. In the D-Grid design, we force the model to focus explicitly on relative velocities based on our domain knowledge. The simplicity of our design slightly hampers the distance-based accuracy as we limit the expressibility of the model. However, it leads to safer predictions as the task of the model to learn social concepts is made easier thanks to our domain-knowledge based design. Further, as shown in <ref type="table" target="#tab_2">Table IV</ref>, the D-Grid provides significant computational speed-up in comparison to S-Grid rendering it useful for real-time deployment.  3) Aggregation Strategy: We evaluate the performance of various aggregation strategies [D-MLP-Attn-MLP, D-MLP-MaxP-MLP, D-MLP-ConC-MLP] on real-world data keeping all the other factors constant. We observe that the max-pooling strategy performs the worst due to its design to hard-merge the embeddings of various neighbours. The concatenation strategy, despite its simplicity, performs only slightly worse in comparison to its sophisticated attentionbased counterpart. One interesting point to note is that D-MLP-Attn-MLP performs superior to its social counterpart S-MLP-Attn-MLP further corroborating the strength of knowledge-based modules. We believe that the concatenation baseline is a simple yet powerful baseline to compare to when designing future information aggregating modules. 4) LSTM-based interaction models: Among the LSTMbased non-grid designs, D-MLP-SumPool-LSTM module <ref type="bibr" target="#b52">[55]</ref> demonstrates high Col-I metric due to (1) sum pooling strategy and (2) encoding of absolute neighbour coordinates. The Col-I metric for O-LSTM-Att-MLP <ref type="bibr" target="#b79">[82]</ref> is relatively higher compared to D-MLP-Concat-LSTM in the real-world due to the absence of relative velocity as input to the interaction model. One can notice the importance of having an LSTM-based embedding in our proposed DirectConcat model by comparing the performance between D-MLP-Concat-LSTM and D-MLP-Concat-MLP. This design choice helps to model higher-order spatiotemporal interactions better and is more robust to noise in the real-world measurements as LSTM controls the evolution of the interaction vector. The top-neighbours are chosen based on euclidean distance. We argue that imposing domain knowledge by considering nearest neighbours is one of the reasons for improvement in Col-I metric as compared to its attention-based and max-pooling-based counterparts. This is corroborated by observing that considering a large number of nearest neighbours ( = 8), in comparison to ( = 4), results in an increase in the model prediction collisions. 5) Comparison to Vanilla LSTM: The interaction-based models perform superior to Vanilla LSTM in terms of <ref type="figure">Fig. 11</ref>: Visualizing the decision-making of grid-based interaction modules using layer-wise relevance propagation. The darker the yellow circles, the more is the weight (also shown in the legend) provided by the primary pedestrian (blue) to the corresponding neighbour (yellow). Our proposed D-Grid, driven by domain knowledge, outputs more human-like trajectories with more intuitive focus on surrounding neighbours as compared to S-Grid.</p><formula xml:id="formula_8">SCENE 1 D-Grid S-Grid SCENE 2 D-Grid S-Grid</formula><p>distance-based metrics. However, an important point to discuss is the performance comparison between Vanilla LSTM and interaction-based models in terms of the Col-II metric.</p><p>We would like to remind that performance in Col-II metric represents the cases where the model predicts the correct mode for the primary pedestrian so that the collisions with the ground-truth trajectories of neighbours is minimal. Due to the multimodal nature of real-world data, it is quite possible that the interaction model predicts a different mode for one of the pedestrians (primary or neighbour) leading to the primary pedestrian not following the ground-truth mode. Indeed, two of the current interaction models [O-MLP-Att-LSTM, D-MLP-SumP-LSTM] struggle in accurately predicting the ground-truth mode compared to Vanilla LSTM. However, this observation does not undermine the importance of modelling social interactions. The usefulness of modelling social interactions is justified by the Col-I metric comparison, which indicates that given the chosen mode for the primary pedestrian, the interaction models predicts a collision-free future for the entire scene, as opposed to Vanilla LSTM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6) Modified Training Objective:</head><p>We employ a modified training objective where we penalize only the primary pedestrian in comparison to the standard practice of penalizing all pedestrians in the scene <ref type="bibr" target="#b49">[52]</ref>, <ref type="bibr" target="#b79">[82]</ref>, <ref type="bibr" target="#b52">[55]</ref>. In the real world dataset, we know that the primary trajectories are largely interacting thanks to our defined categorization; however, there exist significant portion of trajectories among the neighbours which are static and linear. Penalizing such neighbouring trajectories during training might bias to the network into learning linear and static behavior because of the resulting imbalanced distribution (caused by the neighbours).  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>7)</head><p>Understanding NN decision-making: Now, using the popular technique of LRP, we investigate how various input factors affect the decision-making of the NN at each time-step. This helps us in verifying whether the NN decision-making process follows human intuition. <ref type="figure" target="#fig_4">Fig 11 illustrates</ref> the score of each neighbour obtained on applying the LRP procedure on our proposed D-Grid module and baseline S-Grid in real-world scenarios.</p><p>In Scene 1, we demonstrate the application of LRP on a simple real-world example. In case of D-Grid, the primary pedestrian starts focusing on the potential collider 2 despite it being distant compared to 1 thereby preventing collision by staying closer to 1. On the other hand, S-Grid keeps focusing on the 1 which is not desirable. It is interesting to note that once 2 passes the primary pedestrian, both D-Grid and S-Grid shift the attention of the primary pedestrian back to 1.</p><p>In Scene 2, we demonstrate the effectiveness of our proposed D-Grid module in a complex real-world scenario. For D-Grid, initially the primary pedestrian focuses on 3 to prevent collision. On successfully avoiding collision with 3, D-Grid immediately shifts the focus to the pair 1 and 2 as they would potentially lead to another collision. On coming in close proximity to 1 and 2, the focus significantly shifts towards 1 as it is closer to the primary pedestrian. Finally, on passing 1 and 2, the primary pedestrian attends to the pedestrian 4 in front. On the other hand, S-Grid passes in between 1 and 2, such behavior is not expected in human crowds.</p><p>Thus, we can see that LRP is an effective investigative tool to understand the rationale behind the NN decisions. We can observe that, along with having a lower Col-I metric as compared to S-Grid in <ref type="table" target="#tab_2">Table III</ref>, the decision making of our domain-knowledge based D-Grid satisfies human intuition while navigating crowds. The LRP technique is generic and can be applied on top of any existing trained interaction module architecture.</p><p>To summarize, despite claims in literature that specific interaction modules better model interactions, we observe that under identical conditions, all modules perform similar in terms of the distance-based ADE and FDE metrics. The incorporation of Col-I metrics paints a more complete picture of model performance. Secondly, relative velocity plays a crucial role in learning collision avoidance in the real-world. Thirdly, a simple concatenation strategy performs at par with the sophisticated attention-based counterparts. We believe that the concatenation baseline should be a standard baseline to compare to when designing future information aggregating modules. Finally, the LRP technique is a useful investigative tool to gain insights regarding the decision-making process of NNs. We hope that such practices will help to accelerate the development of interaction modules in future research. There certainly exists room for improvement, and we hope that our benchmark provides the necessary resources to advance the field of trajectory forecasting. We open-source our code for reproducibility.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. CONCLUSIONS</head><p>In this work, we tackled the challenge of modelling social interactions between pedestrians in crowds. While modelling social interactions is a central issue in human trajectory forecasting, the literature lacks a definitive comparison between the many existing interaction model designs on identical grounds. We presented an in-depth analysis of the design of interaction modules proposed in the literature and proposed two domain-knowledge based interaction models.</p><p>A significant yet missing component in this field is an objective and informative evaluation of these interaction-based methods. To solve this issue, we propose TrajNet++: (1) TrajNet++ is interaction-centric as it largely comprises scenes where interactions take place thanks to our defined trajectory categorization, both in the real-world and synthetic settings, (2) TrajNet++ provides an extensive evaluation system that includes novel collision-based metrics that can help measure the physical feasibility of model predictions. The superior quality of TrajNet++ is highlighted by the improved performance of interaction-based models on real world datasets on all metrics (4 of the top 5 methods on TrajNet <ref type="bibr" target="#b93">[95]</ref>, an earlier benchmark, do not model social interactions). Further, we demonstrated how our collision-based metrics provide a more concrete picture regarding the model performance.</p><p>Our proposed models outperform competitive baselines on TrajNet++ synthetic dataset by benchmarking against several popular interaction module designs in the field. On the real dataset, there is no clear winner amongst all the designs in terms of distance-based metrics, when compared on equal grounds. Our proposed designs show significant gains in reducing model prediction collisions. There is room for improvement, and we hope that our benchmark facilitates researchers to objectively and easily compare their methods against existing works so that the quality of trajectory forecasting models can keep increasing, allowing us to tackle more challenging scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Human Trajectory Forecasting in Crowds:</head><p>A Deep Learning Perspective</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Material</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VIII. TRAJNET++ FRAMEWORK</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Categorization Rules</head><p>In this section, we provide the mathematical conditions to be satisfied to classify a scene into a particular category. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. TrajNet++ Datasets</head><p>We now describe the datasets used in the TrajNet++ benchmark. Since the focus of this work is to tackle agent-agent interactions in crowded settings, we explicitly select datasets where scene constraints do not play a significant role in determining the future trajectory. For each real world dataset, we utilize only the information regarding the pedestrian locations from the respective annotations files, i.e., spatial coordinates of each pedestrian at each time frame. Furthermore, we provide no information regarding the destination of each pedestrian or structure of the scene. Our goal is to forecast only the 2D spatial coordinates for each pedestrian.</p><p>1) TrajNet++ Real Dataset:</p><p>• ETH: ETH dataset provides for two locations: Univ and Hotel, where pedestrian trajectories are observed. This dataset contains a total of approximately 750 pedestrians exhibiting complex interactions <ref type="bibr">(Pellegrini et. al. [23]</ref>). The dataset is one of the widely used benchmarks for pedestrian trajectory forecasting. It captures diverse realworld social interactions like leader follower, collision avoidance, and group forming and dispersing.</p><p>• UCY: UCY dataset consists of three scenes: Zara01, Zara02 and Uni, with a total of approximately 780 pedestrians <ref type="bibr">(Lerner et. al. [2]</ref>). This dataset, in addition to the ETH dataset, is widely used as benchmarks for pedestrian trajectory forecasting, offering a wide range of non-linear trajectories arising out of social interactions. • WildTrack: This is a recently proposed benchmark <ref type="bibr" target="#b94">[96]</ref> for pedestrian detection and tracking captured in front of ETH Zurich. Since the dataset comprises of diverse crowd interactions in the wild, we utilize it for our task of trajectory forecasting. • L-CAS: This is a recently proposed benchmark for pedestrian trajectory forecasting <ref type="bibr">(Sun et. al. [97]</ref>). The dataset, comprising over 900 pedestrian tracks, comprises diverse social interactions that are captured within indoor environments. Some of the challenges scenarios in this dataset include people pushing trolleys and running children. • CFF: This is a large-scale dataset of 42 million trajectories extracted from real-world train stations <ref type="bibr" target="#b33">[36]</ref>. It is one of the biggest datasets that capture agent-agent interactions in crowded settings during peak travel times. Due to the high density of people, we observe higher instances of social interactions like leader-follower in this dataset. 2) TrajNet++ Synthetic Dataset: Interaction-centric synthetic datasets can provide the necessary controlled environment to compare the performances of different model components. We provide synthetic data in TrajNet++ to evaluate the performance of a model under controlled interaction scenarios.</p><p>Simulator Selection: It is a necessary condition that the interactions in the synthetic dataset are similar to those in the real world. Empirically, we find that in comparison to Social Force <ref type="bibr" target="#b14">[17]</ref>, ORCA <ref type="bibr" target="#b26">[29]</ref> provides a better similarity to real world human motion with respect to collision avoidance. We choose ORCA parameters, which demonstrate a reaction distance and reaction curvature similar to real data during collision avoidance <ref type="figure" target="#fig_0">(Fig 12)</ref>.</p><p>Dataset Generation: Given the ORCA parameters, we generated the synthetic dataset using the following procedure:</p><p>pedestrians were initialized at random on a circle of radius keeping a certain minimum distance _ between their initial positions. The goal of each pedestrian was defined to be the point diametrically opposite to the initial position on the circle. For the TrajNet++ synthetic dataset: We ran different simulations with chosen randomly from the range [4, 7) on a circle of radius = 10 meters and _ = 2 meters. Given the generated trajectories, we selected only those scenes which belonged to the Type III: 'Interacting' category. The ORCA simulator demonstrates sensitive dependence on initial conditions. This can be attributed to the fact that all the agents are expected to collide near the same point (at the origin), so slight perturbations can greatly affect the future trajectory of all agents. Sensitivity to initial conditions, also known as the Butterfly Effect, is a well-studied phenomenon of Chaos theory <ref type="bibr" target="#b96">[98]</ref>. To identify such sensitive initial conditions, the practice which is often followed is to perturb the initial conditions with arbitrary small noise and observe the effect. Along similar lines, we propose an additional step to filter out such 'sensitive' scenes: in each scene, we perturb all trajectories at the point of observation with a small uniform noise ( ∈ [− _ ℎ ℎ, _ ℎ ℎ]), and forecast the future trajectories using ORCA. We perform this procedure times. If any of the ORCA predictions have a significant ADE compared to the ground truth, we filter out such scenes. <ref type="figure" target="#fig_1">Fig 13 visualizes</ref> the sample outputs of our filtering process (with _ ℎ ℎ = 0.01, = 20, = 5). We passed the selected scenes through a final additional filter that identifies sharp unrealistic turns in trajectories.  <ref type="figure" target="#fig_1">Fig. 13</ref>: Illustration of our filtering procedure to generate Trajnet++ synthetic dataset. Given a ground-truth scene (in black) generated by ORCA, we perturb the positions of agents and forecast the future with ORCA, iteratively, to obtain a distribution (in blue). This procedure helps us identify the sensitive scenes and consequently remove them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3) TrajNet++ Dataset Split:</head><p>We now provide the training dataset and test dataset split of the TrajNet++ benchmark (see <ref type="table" target="#tab_2">Table VI</ref> and <ref type="table" target="#tab_2">Table VII</ref>). The trajectories are divided according to our defined categorization for TrajNet++. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 :</head><label>2</label><figDesc>A data-driven pipeline for human trajectory forecasting.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 :</head><label>3</label><figDesc>Illustration of the grid-based interaction encoding modules. (a) Occupancy pooling: each cell indicates the presence of a neighbour (b) Our proposed directional pooling: each cell contains the relative velocity of the neighbour with respect to the primary pedestrian. (c) Social pooling: each cell contains the LSTM hidden-state of the neighbour. The constructed grid tensors are passed through an MLP-based neural network to obtain the interaction vector.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 5 :</head><label>5</label><figDesc>Illustration of Graph neural networks (purple) as a special case of our data-driven pipeline (brown). Each vertex</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 6 :Fig. 7 :Fig. 8 :</head><label>678</label><figDesc>Visualization of our high-level defined trajectory categories (a) Leader Follower (b) Collision avoidance (c) Group (d) Others Visualization of our Type III interactions commonly occurring in real world crowds. Our proposed hierarchy for trajectory categorization.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>( a )</head><label>a</label><figDesc>Leader Follower [LF] (Type IIIa): Leader follower phenomenon refers to the tendency to follow pedestrians going in relatively the same direction. The follower tends to regulate his/her speed and direction according to the leader. If the primary pedestrian is a follower, we categorize the scene as Leader Follower. (b) Collision Avoidance [CA] (Type IIIb): Collision avoidance phenomenon refers to the tendency to avoid pedestrians coming from the opposite direction. We categorize the scene as Collision avoidance if the primary pedestrian to be involved in collision avoidance. (c) Group (Type IIIc): The primary pedestrian is said to be a part of a group if he/she maintains a close and roughly constant distance with at least one neighbour on his/her side during prediction. (d) Other Interactions (Type IIId): Trajectories where the primary pedestrian undergoes social interactions other than LF, CA and Group. We define social interaction as follows: We look at an angular region in front of the primary pedestrian. If any neighbouring pedestrian is present in the defined region at any time-instant during prediction, the scene is classified as having the presence of social interactions. 4) Non-Interacting (Type IV): If a trajectory of the primary pedestrian is non-linear and undergoes no social interactions during prediction.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>-ConC-LSTM (k=8) 0.56/1.22 8.5 (0.5) 14.0 (0.1) D-MLP-ConC-LSTM [Ours] 0.55/1.19 6.8 (0.4) 14.5 (0.5)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>•</head><label></label><figDesc>Static (Type I): The total distance traveled by the primary pedestrian is less than 1 meter. • Linear (Type II): A trajectory is categorized to be Linear if the final displacement error (FDE) of the extended kalman filter prediction is less than 0.5m. • Leader Follower (Type IIIa): The primary pedestrian follows a neighbour, moving in the same direction within an angular range of ±15 deg and having relative velocity in the range of ±15 deg, for more than 2 seconds. • Collision Avoidance (Type IIIb): The primary pedestrian is faced head-on by a neighbour, coming from the opposite direction within an angular range of ±15 deg and relative velocity of movement in the range [180±15 deg]) at any given point of time. • Group (Type IIIc): There exists a neighbour on the side of the primary pedestrian (angular range [90 ± 15 deg] or [−90 ± 15 deg]) for the entire duration of the sample with mean distance ≤ 1 and standard deviation ≤ 0.2 . • Other Interactions (Type IIId): If at any point of time, a neighbour exists in the front (angular range of ±15 deg) of the primary pedestrian within a distance of 5 m, we categorize this trajectory of undergoing social interactions. • Non-Interacting (Type IV): All the other trajectories that fail to satisfy any of the above conditions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 12 :</head><label>12</label><figDesc>Illustration of our calibrated ORCA parameters showing similar reaction curvature (in blue) as those shown by humans in real world datasets (in black). Solid line denotes the primary pedestrian. Dotted lines denote the neighbours.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>Fig 14 illustrates a few sample scenes in our TrajNet++ synthetic dataset. (a) Sensitive Scenes (b) Insensitive Scenes</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 14 :</head><label>14</label><figDesc>Illustration of our synthetically generated samples using the calibrated ORCA parameters.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE I :</head><label>I</label><figDesc>Model Acronyms: Acronyms for the various designs of interaction modules. We observe that most of the existing interaction encoder designs fall under our defined categorization.will use the terms DirectConcat and D-MLP-ConC-LSTM interchangeably.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE II</head><label>II</label><figDesc></figDesc><table><row><cell>: Unimodal Comparison of interaction encoder de-</cell></row><row><cell>signs when forecasting 12 future time-steps, given the previous</cell></row><row><cell>9 time-steps, on TrajNet++ synthetic dataset. Errors reported</cell></row><row><cell>are ADE / FDE in meters, Col I / Col II reported in %. We em-</cell></row><row><cell>phasize that our goal is to reduce Col-I without compromising</cell></row><row><cell>distance-based metrics.</cell></row><row><cell>the efficacy of various interaction module designs for human</cell></row><row><cell>trajectory forecasting. Moreover, we demonstrate how our</cell></row><row><cell>proposed metrics help to provide a complete picture of model</cell></row><row><cell>performance.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE III :</head><label>III</label><figDesc></figDesc><table /><note>Unimodal Comparison of interaction encoder de- signs when forecasting 12 future time-steps, given the previous 9 time-steps, on interacting trajectories of TrajNet++ real world dataset. Errors reported are ADE / FDE in meters, Col I / Col II in mean % (std. dev. %) across 5 independent runs.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>TABLE IV</head><label>IV</label><figDesc></figDesc><table><row><cell>: Speed (in seconds) comparison with S-Grid at test-</cell></row><row><cell>time. D-Grid provides 3.7x speedup as compared to S-Grid</cell></row><row><cell>rendering it more suitable for real-world deployment tasks.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>Table V illustrates the effectiveness of our modified training objective in helping the model to learn collision avoidance better. During test time, we do not provide the ground truth neighbour trajectories.</figDesc><table><row><cell>Training Objective</cell><cell>Dataset</cell><cell>ADE</cell><cell>FDE</cell><cell>Col-I</cell></row><row><cell>Standard [52], [82], [55]</cell><cell>Synth</cell><cell>0.25</cell><cell>0.50</cell><cell>11.9</cell></row><row><cell>Proposed [Ours]</cell><cell>Synth</cell><cell>0.24</cell><cell>0.49</cell><cell>2.2</cell></row><row><cell>Standard [52], [82], [55]</cell><cell>Real</cell><cell>0.59</cell><cell>1.27</cell><cell>7.4</cell></row><row><cell>Proposed [Ours]</cell><cell>Real</cell><cell>0.56</cell><cell>1.22</cell><cell>5.4</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>TABLE V :</head><label>V</label><figDesc>Our proposed training objective that penalizes only the primary prediction provides superior performance.</figDesc><table /><note></note></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Name</head><p>Total <ref type="table">I  II  III  LF  CA  Grp  Oth  IV  Synthetic  54513  0  0  54513  495  7183  0  46853  0  BIWI Hotel.  229  13  91  109  22  29  38  41</ref>    </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Simped: simulating pedestrian flows in a virtual urban environment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Jiang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Crowds by example</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lerner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chrysanthou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lischinski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Graph. Forum</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="655" to="664" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">An analysis of visitor circulation: Movement patterns and the general value principle</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bitgood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Curator: The Museum Journal</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="463" to="475" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">The multi-agent transport simulation matsim</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Horni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Nagel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">W</forename><surname>Axhausen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Abnormal crowd behavior detection using social force model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mehran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A H</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Simulation of pedestrian crowds in normal and evacuation situations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Helbing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">J</forename><surname>Farkas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Molnar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Vicsek</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Simulating dynamical features of escape panic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Helbing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">J</forename><surname>Farkas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Vicsek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">407</biblScope>
			<biblScope unit="page" from="487" to="490" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Modeling crowd evacuation of a building based on seven methodological approaches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">How simple rules determine pedestrian behavior and crowd disasters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Moussaïd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Helbing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Theraulaz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="page" from="6884" to="6888" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">State-of-the-art pedestrian and evacuation dynamics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<ptr target="https://uber.app.box.com/v/uberatgsafetyreport" />
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Intelligent Transportation Systems</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1849" to="1866" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Crowd-robot interaction: Crowd-aware robot navigation with attention-based deep reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kreiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Alahi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 International Conference on Robotics and Automation (ICRA)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6015" to="6022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Autonomous vehicles that interact with pedestrians: A survey of theory and practice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rasouli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">K</forename><surname>Tsotsos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Intelligent Transportation Systems</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="900" to="918" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Social lstm: Human trajectory prediction in crowded spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Alahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ramanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Robicquet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="961" to="971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Binder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Montavon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Klauschen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Samek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS ONE</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Social force model for pedestrian dynamics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Helbing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Molnar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review E</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<date type="published" when="1998-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Learning intentions for improved human motion prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Elfring</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Van De Molengraft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Steinbuch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Robotics and Autonomous Systems</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="591" to="602" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Human motion prediction under social grouping constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rudenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Palmieri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Lilienthal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">O</forename><surname>Arras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3358" to="3364" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Joint long-term prediction of human motion using a planning-based social force approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rudenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Palmieri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">O</forename><surname>Arras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE International Conference on Robotics and Automation (ICRA)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Improved opencl-based implementation of social field pedestrian model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Intelligent Transportation Systems</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="2828" to="2839" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">People tracking with human motion predictions from social forces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Luber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Stork</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">D</forename><surname>Tipaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">O</forename><surname>Arras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2010 IEEE International Conference on Robotics and Automation</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="464" to="469" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Improving data association by joint modeling of pedestrian trajectories and groupings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pellegrini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">V</forename><surname>Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Learning an image-based motion context for multiple people tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Leal-Taixé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fenzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kuznetsova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Rosenhahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2014 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3542" to="3549" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A unified framework for multi-target tracking and collective activity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Understanding collective activitiesof people from videos</title>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="1242" to="1257" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Simulation of pedestrian dynamics using a two-dimensional cellular automaton</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Burstedde</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Klauck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Schadschneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zittartz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">An agent-based pedestrian and group dynamics model applied to experimental and realworld scenarios</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Vizzari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Manenti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ohtsuka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Shimura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Intelligent Transportation Systems</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="32" to="45" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Reciprocal velocity obstacles for real-time multi-agent navigation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manocha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2008 IEEE International Conference on Robotics and Automation</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1928" to="1935" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Discrete choice models for pedestrian walking behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Antonini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bierlaire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Weber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transportation Research Part B: Methodological</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="667" to="687" />
			<date type="published" when="2006-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Continuum crowds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Treuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Popovi263</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH &apos;06</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Modelling smooth paths using gaussian processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">T M</forename><surname>Keat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Laugier</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<publisher>FSR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Gaussian process regression flow for analysis of motion trajectories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">A</forename><surname>Essa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2011 International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1164" to="1171" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Pedestrian path, pose, and intention prediction through gaussian process dynamical models and pedestrian activity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">Q</forename><surname>Mínguez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">P</forename><surname>Alonso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fernández-Llorca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">Á</forename><surname>Sotelo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Intelligent Transportation Systems</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="1803" to="1814" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Learning social etiquette: Human trajectory understanding in crowded scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Robicquet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Alahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Socially-aware large-scale crowd forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Alahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ramanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2014 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2211" to="2218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Understanding pedestrian behaviors from stationary crowd groups</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3488" to="3496" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Speech recognition with deep recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rahman Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2013 IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="6645" to="6649" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Meng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Show and tell: A neural image caption generator</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Toshev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3156" to="3164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Look and think twice: Capturing top-down visual attention with feedback convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2956" to="2964" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Human trajectory prediction using spatially aware deep attention models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Varshneya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Srinivasaraghavan</surname></persName>
		</author>
		<idno>abs/1705.09436</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Desire: Distant future prediction in dynamic scenes with interacting agents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vernaza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">B</forename><surname>Choy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H S</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">K</forename><surname>Chandraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2165" to="2174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Context-aware trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bartoli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lisanti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ballan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">D</forename><surname>Bimbo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">24th International Conference on Pattern Recognition (ICPR)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1941" to="1946" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Ss-lstm: A hierarchical lstm model for pedestrian trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">Q</forename><surname>Huynh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Reynolds</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE Winter Conference on Applications of Computer Vision (WACV)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1186" to="1194" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Multi-agent tensor fusion for contextual trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Monfort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">N</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Social and scene-aware trajectory prediction in crowded spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lisotto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Coscia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ballan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2567" to="2574" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">A data-driven model for interaction-aware pedestrian motion prediction in object cluttered environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pfeiffer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Paolo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Sommer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">I</forename><surname>Nieto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Siegwart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cadena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE International Conference on Robotics and Automation (ICRA)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Pedestrian trajectory prediction in extremely crowded scenarios</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Shibasaki</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>in Sensors</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Group lstm: Group trajectory prediction in crowded scenarios</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Bisagno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">O</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Conci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV Workshops</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Social gan: Socially acceptable trajectories with generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Alahi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2255" to="2264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Sr-lstm: State refinement for lstm towards pedestrian trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="1903" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Starnet: Pedestrian trajectory prediction using deep neural network in star topology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="1797" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">The trajectron: Probabilistic multi-agent trajectory modeling with dynamic spatiotemporal graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ivanovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pavone</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Peeking into the future: Predicting future person activities and locations in videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Niebles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Hauptmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5718" to="5727" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Prediction of pedestrian dynamics in complex architectures with artificial neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tordeux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chraibi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Seyfried</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Schadschneider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Intelligent Transportation Systems</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">An artificial intelligence-based approach for simulating pedestrian movement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">W M</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">K K</forename><surname>Yuen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Intelligent Transportation Systems</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="3159" to="3170" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Mx-lstm: Mixing tracklets and vislets to jointly forecast trajectories and head poses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Setti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tsesmelis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">D</forename><surname>Bue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Galasso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cristani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="6067" to="6076" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Forecasting people trajectories and head poses by jointly reasoning on tracklets and vislets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Setti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tsesmelis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Belagiannis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Amin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">D</forename><surname>Bue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cristani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Galasso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Trajectron++: Multi-agent generative trajectory forecasting with heterogeneous data for control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ivanovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chakravarty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pavone</surname></persName>
		</author>
		<idno>abs/2001.03093</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">seeing is believing&quot;: Pedestrian trajectory forecasting using visual frustum of attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Setti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tsesmelis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">D</forename><surname>Bue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cristani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Galasso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE Winter Conference on Applications of Computer Vision (WACV)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1178" to="1185" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Encoding crowd interaction with deep neural network for pedestrian trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Piao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5275" to="5284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Soft + hardwired attention: An lstm framework for human trajectory prediction and abnormal event detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Fernando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Denman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sridharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fookes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural networks : the official journal of the International Neural Network Society</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="page" from="466" to="478" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Social-wagdat: Interactionaware trajectory prediction via wasserstein graph double-attention network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tomizuka</surname></persName>
		</author>
		<idno>abs/2002.06241</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Sophie: An attentive gan for predicting paths compliant to social and physical constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Hirose</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
		<idno>abs/1806.01482</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Social-bigat: Multimodal trajectory forecasting using bicycle-gan and graph attention networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Martín-Martín</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">D</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">H</forename><surname>Rezatofighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="1907" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Social ways: Learning multimodal distributions of pedestrian trajectories with gans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Amirian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-B</forename><surname>Hayet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pettré</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="1904" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Gd-gan: Generative adversarial networks for trajectory prediction and group detection in crowds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Fernando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Denman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sridharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fookes</surname></persName>
		</author>
		<idno>abs/1812.07667</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Situation-aware pedestrian trajectory prediction with spatio-temporal attention model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Haddad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Lam</surname></persName>
		</author>
		<idno>abs/1902.05437</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Stgat: Modeling spatialtemporal interactions for human trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6271" to="6280" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Socialstgcnn: A social spatio-temporal graph convolutional neural network for human trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Elhoseiny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">G</forename><surname>Claudel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Evolvegraph: Heterogeneous multi-agent multi-modal trajectory prediction with evolving interaction graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tomizuka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Recursive social behavior graph for trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="657" to="666" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Spatio-temporal graph transformer networks for pedestrian trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mangalam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Girase</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Adeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gaidon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note>It is not the journey but the destination: Endpoint conditioned trajectory prediction,&quot; in ECCV</note>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Dynamic and static contextaware lstm for multi-agent motion prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Attention is all you need,&quot; in NIPS</note>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno>abs/1409.0473</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Human motion trajectory prediction: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rudenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Palmieri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Herman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Kitani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Gavrila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">O</forename><surname>Arras</surname></persName>
		</author>
		<idno>abs/1905.06113</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Context-based pedestrian path prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F P</forename><surname>Kooij</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Flohr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gavrila</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Social attention: Modeling attention in human crowds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vemula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Muelling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Oh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE International Conference on Robotics and Automation (ICRA)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Spectral networks and locally connected networks on graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<idno>abs/1312.6203</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Generating sequences with recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<idno>abs/1308.0850</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Graph attention networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Velickovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liò</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno>abs/1710.10903</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<idno>abs/1409.1556</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Striving for simplicity: The all convolutional net</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Springenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename></persName>
		</author>
		<idno>abs/1412.6806</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>Riedmiller</note>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Axiomatic attribution for deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sundararajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Taly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Alber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lapuschkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Seegerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hägele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">T</forename><surname>Schütt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Montavon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Samek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-R</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dähne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-J</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">innvestigate neural networks!</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kindermans</surname></persName>
		</author>
		<ptr target="http://jmlr.org/papers/v20/18-540.html" />
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">93</biblScope>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Explaining and interpreting lstms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Arras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Arjona-Medina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Widrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Montavon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gillhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Samek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="1909" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<monogr>
		<title level="m" type="main">On estimation of a probability density function and mode</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Parzen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1962" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno>abs/1412.6980</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<monogr>
		<title level="m" type="main">Amenet: Attentive maps encoder network for trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Rosenhahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sester</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Robust trajectory forecasting for multiple intelligent agents in dynamic scene</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<monogr>
		<title level="m" type="main">Trajnet: Towards a benchmark for human trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Alahi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Wildtrack: A multi-camera hd dataset for dense unscripted pedestrian detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chavdarova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Baqué</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bouquet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Maksai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Jose</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Bagautdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lettry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">V</forename><surname>Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Fleuret</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5030" to="5039" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">3dof pedestrian trajectory prediction learned from long-term autonomous mobile robot deployment data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Mellado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hanheide</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Duckett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE International Conference on Robotics and Automation (ICRA)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<monogr>
		<title level="m" type="main">Does the flap of a butterfly&apos;s wings in brazil set off a tornado in texas</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Edward</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1972" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
