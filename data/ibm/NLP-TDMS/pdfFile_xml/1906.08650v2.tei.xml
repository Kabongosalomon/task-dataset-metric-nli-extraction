<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">3D Instance Segmentation via Multi-Task Metric Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Lahoud</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernard</forename><surname>Ghanem</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Pollefeys</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eth</forename><surname>Zurich</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><forename type="middle">R</forename><surname>Oswald</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eth</forename><surname>Zurich</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">KAUST</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">KAUST</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">3D Instance Segmentation via Multi-Task Metric Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T10:26+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We propose a novel method for instance label segmentation of dense 3D voxel grids 1 . We target volumetric scene representations, which have been acquired with depth sensors or multi-view stereo methods and which have been processed with semantic 3D reconstruction or scene completion methods. The main task is to learn shape information about individual object instances in order to accurately separate them, including connected and incompletely scanned objects. We solve the 3D instance-labeling problem with a multi-task learning strategy. The first goal is to learn an abstract feature embedding, which groups voxels with the same instance label close to each other while separating clusters with different instance labels from each other. The second goal is to learn instance information by densely estimating directional information of the instance's center of mass for each voxel. This is particularly useful to find instance boundaries in the clustering post-processing step, as well as, for scoring the segmentation quality for the first goal. Both synthetic and real-world experiments demonstrate the viability and merits of our approach. In fact, it achieves state-of-the-art performance on the ScanNet 3D instance segmentation benchmark <ref type="bibr" target="#b4">[5]</ref>.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>A central goal of computer vision research is high-level scene understanding. Recent methodological progress for 2D images makes reliable results possible for a variety of computer vision problems, including image classification <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b47">48]</ref>, image segmentation <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b41">42]</ref>, object detection <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b40">41]</ref> and instance segmentation in 2D images <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b36">37]</ref>. Furthermore, it is now possible to recover highly-detailed 3D geometry with low-cost depth sensors <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b54">55]</ref> or with image-based 3D reconstruction algorithms <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b42">43]</ref>. Combining both these concepts, many algorithms have been developed for 3D scene and object classification <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b50">51]</ref>, 3D object detection <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b51">52]</ref>, and joint 3D reconstruction and semantic labeling <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b48">49]</ref>. <ref type="bibr" target="#b0">1</ref> https://sites.google.com/view/3d-instance-mtml</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Input Scene</head><p>Our Instance Labels</p><p>Ground truth Instance Labels Our Instance Labels <ref type="figure">Figure 1</ref>. Sample results of our method. Our proposed method takes as input a 3D point cloud, and outputs instance labels unique to each object within the scene. The labels are generated by learning a metric that groups parts of the same object instance and estimates the direction towards the instance's center of mass.</p><p>Advances in 2D instance segmentation were mainly fueled by the large number of datasets and challenges available in the 2D realm. When compared to the plethora of powerful methods for instance segmentation of 2D images, the 3D counterpart problem has been less explored in the literature. In addition to the lack of datasets, the majority of 2D methods are not applicable to the 3D setting or their extension is by no means straightforward.</p><p>With the emergence of labeled datasets and benchmarks for the task of 3D instance segmentation (e.g. ScanNet <ref type="bibr" target="#b4">[5]</ref>), numerous works have surfaced to tackle this task. In many cases, the work in 3D benefits from pioneering work in 2D, with modifications that allow processing of 3D input data. As such, this 3D processing tends to be similar to other 3D understanding techniques, mainly semantic segmentation.</p><p>In this paper, we address the problem of 3D instance segmentation. Given the 3D geometry of a scene, we want to label all the geometry that belongs to the same object with a unique label. Unlike previous methods that entangle instance labeling with semantic labeling, we propose a technique that mainly focuses on instance labeling through grouping/clustering of information pertaining to a single object. Our method still benefits from semantic information as a local cue, but adds to it information related to 3D dimensions and 3D connectivity, whose usefulness is unique to the 3D setting.</p><p>In particular, we propose a learning algorithm that processes a 3D voxel grid and learns two main characteristics: (1) a feature descriptor unique to every instance, and (2) a direction that would point towards the instance center. Our method aims to provide a grouping force that is independent of the size of the scene and the number of instances within.</p><p>Contributions. Our contributions are two fold. (i) We propose a multi-task neural network architecture for 3D instance segmentation of voxel-based scene representations. In addition to a metric learning task, we task our network to predict directional information to the object's center. We demonstrate that the multi-task learning improves the results for both tasks. Our approach is robust and scalable, therefore suitable for processing large amounts of 3D data.</p><p>(ii) Our experiments demonstrate state-of-the-art performance for 3D instance segmentation. At the time of submission, our method ranks first in terms of average AP50 score on the ScanNet 3D instance segmentation benchmark <ref type="bibr" target="#b4">[5]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>This section gives a brief overview of related 2D and 3D approaches. It is worthwhile to note that a large amount of related work exists for 2D deep learning-based semantic segmentation and instance label segmentation. Recent surveys can be found in <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b15">16]</ref>.</p><p>2D Instance Segmentation via Object Proposals or Detection. Girshick <ref type="bibr" target="#b13">[14]</ref> proposed a network architecture that creates region proposals as candidate object segments. In a series of followup work, this idea has been extended to be faster <ref type="bibr" target="#b40">[41]</ref> and to additionally output pixel-accurate masks for instance segmentation <ref type="bibr" target="#b17">[18]</ref>. The authors of YOLO <ref type="bibr" target="#b38">[39]</ref> and its follow-up work <ref type="bibr" target="#b39">[40]</ref> apply a grid-based approach, in which each grid cell generates an object proposal. Deep-Mask <ref type="bibr" target="#b36">[37]</ref> learns to jointly estimate an object proposal and an object score. Lin et al. <ref type="bibr" target="#b29">[30]</ref> propose a multi-resolution approach for object detection, which they call feature pyramid networks. In <ref type="bibr" target="#b16">[17]</ref>, the region proposals are refined with a network that predicts the distance to the boundary which is then transformed into a binary object mask. Khoreva et al. <ref type="bibr" target="#b20">[21]</ref> jointly perform instance and semantic segmentation. A similar path follows <ref type="bibr" target="#b26">[27]</ref>, which combines fully convolutional networks for semantic segmentation with instance mask proposals. Dai et al. <ref type="bibr" target="#b8">[9]</ref> use fully convolutional networks (FCNs) and split the problem into bounding box estimation, mask estimation, and object categorization and propose a multi-task cascaded network architecture. In a follow-up work <ref type="bibr" target="#b7">[8]</ref>, they combine FCNs with windowed instance-sensitive score maps.</p><p>While all these approaches have been very successful in the 2D domain, many of them require large amounts of resources and their extension to the 3D domain is non-trivial and challenging.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2D Instance Segmentation via Metric Learning.</head><p>Liang et al. <ref type="bibr" target="#b27">[28]</ref> propose a method without object proposals as they directly estimate bounding box coordinates and confidences in combination with clustering as a postprocessing step. Fathi et al. <ref type="bibr" target="#b9">[10]</ref> compute likelihoods of pixels to belong to the same object by grouping similar pixels together within an embedding space. Bai and Urtasun <ref type="bibr" target="#b1">[2]</ref> learn an energy map of the image in which object instances can be easily predicted. Novotny et al. <ref type="bibr" target="#b35">[36]</ref> learn a position sensitive metric (semi-convolution embedding) to better distinguish between identical copies of the same object. Kong and Fowlkes <ref type="bibr" target="#b22">[23]</ref> train a network that assigns all pixels to a spherical embedding, in which points of the same object instance are within a close vicinity and noninstance related points are placed apart from each other. The instances are then extracted via a variant of mean-shift clustering <ref type="bibr" target="#b10">[11]</ref> that is implemented as a recurrent network. The approach by DeBrabandere et al. <ref type="bibr" target="#b2">[3]</ref> follows the same idea, but the authors do not impose constraints on the shape of the embedding space. Likewise, they compute the final segmentation via mean-shift clustering in the feature space.</p><p>None of these approaches has been applied to a 3D setting. Our approach builds upon the work of DeBrabandere et al. <ref type="bibr" target="#b2">[3]</ref>. We extend this method with a multi-task approach for 3D instance segmentation on dense voxel grids.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3D Instance Segmentation.</head><p>Wang et al. <ref type="bibr" target="#b49">[50]</ref> propose SGPN, an instance segmentation for 3D point clouds. In the first step, they extract features with PointNet <ref type="bibr" target="#b37">[38]</ref> and subsequently build a similarity matrix, in which each element classifies whether two points belong to the same object instance. The approach is not very scalable and limited to small point cloud sizes, since the size of the similarity matrix is squared the number of points in the point cloud. Moreover, there is a number of recent concurrent or unpublished works that address 3D instance segmentation. The GSPN method <ref type="bibr" target="#b53">[54]</ref> proposes a generative shape proposal network, which relies on object proposals to identify instances in 3D point clouds. The 3D-SIS approach <ref type="bibr" target="#b18">[19]</ref> combines 2D and 3D features aggregated from multiple RGB-D input views. MASC <ref type="bibr" target="#b30">[31]</ref> relies on the superior performance of the SparseConvNet <ref type="bibr" target="#b14">[15]</ref> architecture and combines it with an instance affinity score that is estimated across multiple scales. PanopticFusion <ref type="bibr" target="#b33">[34]</ref> predicts pixel-wise labels for RGB frames and carries them over into a 3D grid, where a fully connected CRF is used for final inference.</p><p>Apart from these recent concurrent works, there has generally been sparse research on 3D instance segmentation.  <ref type="figure">Figure 2</ref>. Overview of our network architecture. We cast 3D instance segmentation as a multi-task learning problem. The input to our method is a voxel grid and the output are two latent spaces: 1) a feature vector embedding that groups voxels with similar instance label close in the latent space; 2) a 3D latent space that encodes directional predictions for each voxel. The inputs and outputs of our network are visualized and explained in <ref type="figure">Fig. 3</ref>. The parameters in the figure correspond to (number of filters, kernel size, stride, dilation).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Method Overview</head><p>In this work, we aim at segmenting 3D instances within a given 3D scene. To fully locate a 3D instance, one would require both a semantic label and an instance label. Rather than solving the complex task of scene completion, semantic labeling and instance segmentation at once, we model our 3D instance segmentation process as a post-processing step for semantic segmentation labeling. We focus on the grouping and splitting of semantic labels, relying on interinstance and intra-instance relations. We benefit from the real distances in 3D scenes, where sizes and distances between objects are key to the final instance segmentation.</p><p>We split our task into a label segmentation then instance segmentation problem, as we believe that features learned in each step possess task-specific information. Semantic segmentation on one hand can rely on local information to predict the class label. Learning to semantically label a volumetric representation inherently encodes features from neighboring volumes but does not require knowledge of the whole environment. On the other hand, instance segmentation requires a holistic understanding of the scene in order to join or separate semantically labeled volumes.</p><p>Problem Setting. Our method's input is a voxelized 3D space with each voxel encoding either a semantic label or a local feature vector learned through semantic labeling. In this paper, we use the semantic labeling network in <ref type="bibr" target="#b14">[15]</ref>. We fix the voxel size to preserve 3D distances among all voxels within a scene. In problem settings where point clouds or meshes are available, one could generate a 3D voxelization by grouping information from points within every voxel. Our method then processes the voxelized 3D space and outputs instance label masks, each corresponding to a single object in the scene, along with its semantic label. The output mask can also be reprojected back into a point cloud by assigning the voxel label to all points within it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Network Architecture</head><p>In order to process the 3D input, we utilize a 3D convolution network, which is based on the SSCNet architecture <ref type="bibr" target="#b45">[46]</ref>. We apply some changes to the original SSCNet network to better suit our task. As shown in <ref type="figure">Figure 2</ref>, the network input and output are equally sized. Since the pooling layer scales down the scene size, we use a transpose of convolution (also referred to as deconvolution <ref type="bibr" target="#b55">[56]</ref>) to upsample back into the original size. We also use larger dilations for diluted 3D convolution layers to increase the receptive field. We make the receptive field large enough to access all the voxels of usual indoor rooms. With a voxel size of 10cm, our receptive field is as large as 14.2m. With larger scenes, our 3D convolution network would still be applicable to the whole scene, while preserving the filter and voxel sizes, and thus preserving the real distances. Objects lying at distances larger than the receptive field are separated by default.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Multi-task Loss Function</head><p>In order to group voxels of the same instance, we aim to learn two types of feature embedding. The first type maps every voxel into a feature space, where voxels of the same instance are closer to each other than voxels belonging to different instances. This is similar to the work of DeBrabandere et al. <ref type="bibr" target="#b2">[3]</ref>, but applied in a 3D setting. The second type of feature embedding assigns a 3D vector to every voxel, where the vector would point towards the physical center of the object it belongs to. This enables the learning of shape containment and removes ambiguities among similar shapes.</p><p>In order to learn both feature embeddings, we introduce a multi-task loss function that is minimized during training. The first part of the loss encourages discrimination in the feature space among multiple instances, while the second part penalizes angular deviations of vectors from the desired direction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Network</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Our</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>World Space</head><p>Feature Embedding Space Direction Embedding Space <ref type="figure">Figure 3</ref>. Embedding space visualization. Voxels with similar instance labels in the world space (left) are mapped: <ref type="bibr" target="#b0">(1)</ref> to similar locations in the feature embedding space such that the instances form clusters (middle) and <ref type="formula">(2)</ref> to directional vectors pointing to the object center (right). The red arrows depict inter-class push forces among cluster centers, while the grey arrows indicate intra-class pull forces of between points and cluster centers. The other colors differentiate voxels or features of different object instances.</p><p>Feature Embedding Loss. We follow the work of DeBrabandere et al. <ref type="bibr" target="#b2">[3]</ref>, which learns a feature embedding that can be subsequently clustered. Thus, we define the feature embedding loss as a weighted sum of three terms: (1) an intra-cluster variance term L var that pulls features that should belong to the same instance towards the mean feature, (2) an inter-cluster distance term L dist that encourages clusters with different instance labels to be pushed apart, and (3) a regularization term L reg that pulls all features towards the origin in order to bound the activations.</p><formula xml:id="formula_0">L FE = γ var L var + γ dist L dist + γ reg L reg<label>(1)</label></formula><p>The individual loss functions are weighted by γ var = γ dist = 1, γ reg = 0.001 and are defined similar to <ref type="bibr" target="#b2">[3]</ref> as follows:</p><formula xml:id="formula_1">L var = 1 C C c=1 1 N c Nc i=1 [ µ c − x i − δ var ] 2 + (2) L dist = 1 C(C − 1) C c A =1 C c B =1 c B =c A 2δ dist − µ c A − µ c B 2 + (3) L reg = 1 C C c=1 µ c<label>(4)</label></formula><p>Here C is the number of ground truth clusters, N c denotes the number of elements in cluster c, µ c is the cluster center, i.e. the mean of the elements in cluster c, and x i is a feature vector. Further, the norm · denotes the 2 -norm and [x] + = max(0, x) the hinge. The parameter δ var describes the maximum allowed distance between a feature vector x i and the cluster center µ c in order to belong to cluster c. Likewise, 2δ dist is the minimum distance that different cluster centers should have in order to avoid overlap. A visualization of the forces and the embedding spaces can be found in <ref type="figure">Figure 3</ref>. Feature embeddings of different clusters exert forces on each other, i.e. each feature embedding is affected by the number and location of other cluster centers. This connection might be disadvantageous in some cases, especially when a large number of instances exist in a single scene. Therefore, we propose next an additional loss that provides local information essential for instance separation without being affected by other instances.</p><p>Directional Loss. We here aim to generate a vector feature that would locally describe the intra-cluster relationship without being affected by other clusters. We choose the vector to be the one pointing towards the ground truth center of the object. To learn this vector feature, we attend to the following directional loss:</p><formula xml:id="formula_2">L dir = − 1 C C c=1 1 N c Nc i=1 v i v GT i with v GT i = z i − z c z i − z c<label>(5)</label></formula><p>Here, v i denotes the normalized directional vector feature, v GT i is the desired direction which points towards the object center, z i is the voxel center location, and z c is the object center location.</p><p>Joint Loss. We jointly minimize both the feature embedding loss and the directional loss during training. Our final joint loss reads as:</p><formula xml:id="formula_3">L joint = α FE L FE + α dir L dir<label>(6)</label></formula><p>We use α FE = 0.5 and α dir = 1.</p><p>Post-processing. We apply mean-shift clustering <ref type="bibr" target="#b10">[11]</ref> on the feature embedding. Similar to object detection algorithms, instance segmentation does not restrict the labeling to one coherent set, and thus allows overlap between multiple objects. We use the mean-shift clustering output with multiple thresholds as proposals that are scored according to their direction feature consistency. We also use connected components for suggested splitting that would further be scored by the coherency of its feature embeddings. The coherency of the feature embedding is described by the number of feature embeddings that lie within a given threshold from the feature cluster center. The directional feature coherency score is simply L dir , which is the average cosine similarity between the normalized vector pointing from the voxel to the center of the object and the predicted normalized direction feature. We then sort all object proposals and perform non-maximum suppression (NMS) to remove objects that overlap by more than a threshold. The final score is obtained by appending both feature embedding scores with a score that encourages objects of regular sizes over extremely large or small objects. As for the semantic label, it is chosen to be the most occurring label among all points within the clustered voxels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Network Training</head><p>Training Data. During training, we append flips of voxelized scenes as well as multiple orientations around the vertical axis to our training data. We pretrain our network using ground truth segmentation labels as input, with labels one-hot encoded to maintain the same sized input as training using the semantic segmentation output.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Results and Evaluation</head><p>Setup. Our network was implemented in Tensorflow and run with an Nvidia GTX1080Ti GPU. For the network training, we use the ADAM optimizer and a learning rate of 5e−4 and batch size of 2. The training converged after about 100 epochs and took about 2 days. The inference time for our network is about 1s for scene sizes of 1.6M voxels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Datasets.</head><p>For experimental evaluation, we trained and tested our method on the following datasets that include real and synthetic data.</p><p>• Synthetic Toy Dataset: In order to validate our approach, we create a synthetic dataset with objects of different sizes and aspect ratios placed on a planar surface. We introduce 5 object shapes, where each shape is analogous to an object class in the real data. The shapes of the objects considered are shown in <ref type="figure" target="#fig_0">Figure 4</ref>. We then randomly orient and position objects on the surface plane, and randomly choose whether an object is in contact with another object. We generate 1000 scene, and split our dataset into 900 training scenes, and 100 testing scenes.</p><p>• ScanNet <ref type="bibr" target="#b4">[5]</ref>: We conduct experiments on the ScanNet v2 dataset, which contains 1513 scans with 3D instance annotations. The training set contains 1201 scans, and the remaining 312 scans are used for validation. An additional 100 unlabeled scans form an evaluation test set. Evaluation metrics. Following the evaluation procedure adopted in most instance segmentation methods as well as the ScanNet evaluation benchmark, we use the average precision metric (AP) score to evaluate our proposed algorithm. We use the AP25 and AP50 metrics, which denote the AP score with a minimum intersection-over-union (IoU) threshold of 25% and 50%, respectively. The AP score averages scores obtained with IoU thresholds ranging from 50% to 95% with a step of 5%.</p><p>Baselines. To assess the performance of our method, we consider the following baseline methods:</p><p>• Input Segmentation: In this case, we assume that the segmentation label, which is input to our method, to be the desired instance segmentation label. If every scene contains a single instance of every semantic label, this baseline would be ideal. In reality, these scenes barely occur, but such a metric would still serve as an inception to whether splitting and/or grouping voxels is reasonable.</p><p>• Connected Components: Given the ground truth segmentation labels, a connected components algorithm tends to correctly label all instances that are not touching. Since this happens seldom in a 3D setting, this is usually a high-scoring and challenging baseline.</p><p>• We further compare against submissions to the Scan-Net benchmark, specifically MaskRCNN proj <ref type="bibr" target="#b17">[18]</ref>, SGPN <ref type="bibr" target="#b37">[38]</ref>, GSPN <ref type="bibr" target="#b53">[54]</ref>, 3D-SIS <ref type="bibr" target="#b18">[19]</ref>, Occipital-SCS, MASC <ref type="bibr" target="#b30">[31]</ref>, PanopticFusion <ref type="bibr" target="#b33">[34]</ref>, and 3D-BoNet <ref type="bibr" target="#b52">[53]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Evaluation on Synthetic 3D Data</head><p>We evaluate our method on the simple toy dataset, and report AP50 score for all objects in <ref type="table">Table 1</ref>. In this part, we allow only one coherent labeling. Note that the directional loss alone is not discriminative enough for subsequent clustering and is thus not considered in the ablation study. Generating object proposals from directional information only is tedious, since it is noisy and the clustering problem is much more difficult and less efficient. Therefore, we do not evaluate the directional prediction alone, but instead, we resort to using object proposals from mean shift clustering and using the directional information for scoring them.  <ref type="table">Table 1</ref>. AP50 results on synthetic toy dataset. On this dataset with 5 objects, our approach with multi-task learning as well as the baseline with only feature embedding (FE) outperform the connected components baseline, even though it uses the ground truth semantic labels. The difference between FE only and Multi-task is small in a noise-free setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Input Scenes with Semantic Labels</head><p>Output Scenes with Instance Labels <ref type="figure">Figure 5</ref>. Experiment on synthetic toy dataset. Two examples of random scenes for which our network generated instance labels.</p><p>The goal of the simple toy problem in <ref type="figure">Figure 5</ref> is to study whether the network can abstract and differentiate various object sizes although their shapes are rather similar. Furthermore, it is interesting to see how our method performs when object instances are spatially touching, especially when they belong to the same semantic class. Although the input features are very similar (due to the same object class and the spatial proximity), our network is able to successfully place the corresponding feature vectors in different locations in the feature space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Evaluation on Real 3D Data</head><p>Feature Space Study.</p><p>Minimizing the feature loss in Eq. (1) works toward two tasks: pulling points belonging to the same instance together and pushing clusters of different instances apart. Since real data contains noise, outliers, and missing data, the mapping of individual points in the feature space might be less discriminative and clusters might be overlapping. In <ref type="figure">Figure 6</ref>, we visualize the 3D feature space in order to study these effects and observe that feature points of the same instance do indeed spread towards neighboring clusters. But for this example, the feature clustering results are not influenced and still achieve high accuracy. Note that we exclude ground and wall labels since their instance segmentation and splitting is less meaningful and is also ignored in the benchmark.</p><p>Evaluation on ScanNet Output. In <ref type="figure">Figure 7</ref>, we present qualitative results on the ScanNet dataset <ref type="bibr" target="#b4">[5]</ref>. The results of our method on the voxel grid are simply projected onto the mesh which is then used for evaluation on the benchmark. As can be seen in the rightmost column, our method sometimes splits objects like 'desk' or the labels of 'furniture' bleed into neighboring geometry. Due to our mostly geometric approach, our method needs structural changes to recognize object boundaries and to potentially relabel a new instance. Nonetheless, our proposed method was able to group single object instances together in most cases.</p><p>In <ref type="table">Table 2</ref>, we provide an ablation study and include comparisons against simple baselines. The first baseline uses the input segmentation labels (SparseConvNet <ref type="bibr" target="#b14">[15]</ref>) as instance labels. Furthermore, we evaluate a simple connected component labeling method on the segmentation labeling, because in the 3D setting in general, and considering the given datasets, very few object instances are touching each other. Hence, this connected component baseline is already a challenging one especially for a rather noise free geometry and labeling. It is clear that this method tends to substantially improve the instance labeling results. With increasing amounts of noise connected component labeling rapidly performs worse. In rare cases, the results of this method get worse, which is due to the fact that the scenes are not completely scanned and a single object instance might be disconnected due to missing scene parts.</p><p>Ablation Study: Single-task vs. Multi-task. We compare our network with single-task learning to that of multitask learning. The six rightmost columns in <ref type="table">Table 2</ref> show the results of single-task learning and multi-task learning. With very few exceptions, the network trained with a multitask loss consistently outperforms the single-task one. This is in line with the results on the synthetic dataset and supports our hypothesis that the directional loss adds more discriminative features, which are helpful to group the features according to object instances in the feature space. For objects that rarely have multiple instances within a scene, such as the 'counter' class, the segmentation as instance outperforms our method. Since this occurrence is uncommon, its effect on the overall average evaluation is negligible. <ref type="table">Table 3</ref> provides an overview of our benchmark results on the ScanNet test dataset (with held out ground truth). One can see that our method outperforms the others in AP50 score. Other methods include those that process all RGB-D Input (RGB) Feature Label GT Feature Label Ours GT Label Clustering Label <ref type="figure">Figure 6</ref>. Visualization of the feature embedding and labeling. This figure shows (from left to right) the colored 3D scene input, its generated 3D feature embeddings, along with the ground truth (GT) labels and our instance labeling result after mean-shift clustering (colors of the instances in the final results are chosen randomly and do not correspond to GT label colors).</p><p>Segment. <ref type="bibr" target="#b14">[15]</ref>   <ref type="table">Table 2</ref>. Ablation study on the ScanNet dataset <ref type="bibr" target="#b4">[5]</ref> validation set. We show the instance labeling performance of the segmentation method in <ref type="bibr" target="#b14">[15]</ref>, connected components labeling on the <ref type="bibr" target="#b14">[15]</ref> segmentation, our method with feature embedding (FE) only and our method with multi-task learning.  <ref type="bibr" target="#b28">[29]</ref> 0  <ref type="table">Table 3</ref>. State-of-the-art comparison on the ScanNet 3D instance segmentation dataset <ref type="bibr" target="#b4">[5]</ref>. The table shows the AP50 score of individual semantic categories and the average score (sorted by avg AP50 score in descending order). We achieve the best average score.</p><p>images that were used to reconstruct the scenes of ScanNet. Instance labels of single RGB-D frames in these methods are propagated throughout the whole scene and concatenated based on the location estimation. On the other hand, our method directly operates in the 3D setting, without the need to use the 2D information. This leads to much faster processing on the 3D scenes, and requires substantially less information to extract the 3D object instance segmentations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Input (RGB)</head><p>Semantic GT SPC <ref type="bibr" target="#b14">[15]</ref> CC SGPN <ref type="bibr" target="#b49">[50]</ref> Instance GT Ours <ref type="figure">Figure 7</ref>. Qualitative results of our method on the ScanNet validation dataset <ref type="bibr" target="#b4">[5]</ref>. This figure shows the original input scene as a textured mesh, the semantic labeling results of SparseConvNet (SPC) <ref type="bibr" target="#b14">[15]</ref> which we use as input and our instance labeling results as well as the semantic groundtruth (GT). We further show multiple 3D instance segmentation baselines: connected component (CC) labeling on the SPC semantic labeling, SPGN <ref type="bibr" target="#b49">[50]</ref>, and the groundtruth instance labels next to our labeling results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>We proposed a method for 3D instance segmentation of voxel-based scenes. Our approach is based on metric learning and the first part assigns all voxels belonging to the same object instance feature vectors that are in close vicinity. Conversely, voxels belonging to different object instances are assigned features that are further apart from each other in the feature space. The second part estimates directional information of object centers, which is used to score the segmentation results generated by the first part.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 4 .</head><label>4</label><figDesc>Overview of the synthetic toy dataset. Left: We consider 5 different object classes represented by cubes with various edge lengths. Middle: Example scene with object colors showing the class labels. Right: Corresponding ground truth instance labeling (randomly chosen color per instance).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>00 0.00 0.05 0.00 0.00 0.02 0.00 0.05 0.02 0.24 0.07 0.00 0.01 0.11 0.02 0.11 0.01</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Method Obj1 Obj2 Obj3 Obj4 Obj5 Connected comp. 92.5 85.1 86.9 93.5 79.9 Ours (FE only) 97.3 92.7 95.0 96.4 95.2 Ours (Multi-task) 98.0 93.5 96.1 96.6 95.3</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>.16 0.26 0.59 0.14 0.48 0.22 0.42 0.41 0.13 0.32 0.71 0.41 0.54 0.59 0.87 0.30 MASC [31] 0.45 0.53 0.56 0.38 0.38 0.63 0.00 0.51 0.26 0.36 0.43 0.33 0.45 0.57 0.37 0.64 0.39 0.98 0.28 3D-SIS [19] 0.38 1.00 0.43 0.25 0.19 0.58 0.01 0.26 0.03 0.32 0.24 0.08 0.42 0.86 0.12 0.70 0.27 0.88 0.24 Unet-backbone</figDesc><table><row><cell>Method</cell><cell>Avg AP</cell><cell>bathtub</cell><cell>bed</cell><cell>bookshelf</cell><cell>cabinet</cell><cell>chair</cell><cell>counter</cell><cell>curtain</cell><cell>desk</cell><cell>door</cell><cell>otherfurniture</cell><cell>picture</cell><cell>refrigerator</cell><cell>shower curtain</cell><cell>sink</cell><cell>sofa</cell><cell>table</cell><cell>toilet</cell><cell>window</cell></row><row><cell>MTML (Ours)</cell><cell>0.55</cell><cell cols="18">1.00 0.81 0.59 0.33 0.65 0.00 0.82 0.18 0.42 0.36 0.18 0.45 1.00 0.44 0.69 0.57 1.00 0.40</cell></row><row><cell>Occipital-SCS</cell><cell>0.51</cell><cell cols="18">1.00 0.72 0.51 0.51 0.61 0.09 0.60 0.18 0.35 0.38 0.17 0.44 0.85 0.39 0.62 0.54 0.89 0.39</cell></row><row><cell>3D-BoNet</cell><cell>0.49</cell><cell cols="18">1.00 0.67 0.59 0.30 0.48 0.10 0.62 0.31 0.34 0.26 0.13 0.43 0.80 0.40 0.50 0.51 0.91 0.44</cell></row><row><cell>PanopticFusion [34]</cell><cell>0.48</cell><cell cols="18">0.67 0.71 0.60 0.26 0.55 0.00 0.61 0.18 0.25 0.43 0.44 0.41 0.86 0.49 0.59 0.27 0.94 0.36</cell></row><row><cell>ResNet-backbone [29]</cell><cell>0.46</cell><cell cols="2">1.00 0.74 0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgments. This research was supported by competitive funding from King Abdullah University of Science and Technology (KAUST). Further support was received by the Intelligence Advanced Research Projects Activity (IARPA) via Department of Interior/ Interior Business Center (DOI/IBC) contract number D17PC00280. The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright annotation thereon. Disclaimer: The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of IARPA, DOI/IBC, or the U.S. Government.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Segnet: A deep convolutional encoder-decoder architecture for image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Badrinarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Kendall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Cipolla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2481" to="2495" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Deep watershed transform for instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Computer Vision and Pattern Recognition (CVPR</title>
		<meeting>International Conference on Computer Vision and Pattern Recognition (CVPR</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Semantic instance segmentation with a discriminative loss function</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Davy</forename><surname>Bert De Brabandere</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Neven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Gool</surname></persName>
		</author>
		<idno>abs/1708.02551</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Learning priors for semantic 3d reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Cherabier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><forename type="middle">L</forename><surname>Schönberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><forename type="middle">R</forename><surname>Oswald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Pollefeys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Geiger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European Conference on Computer Vision (ECCV)</title>
		<meeting>European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Scannet: Richly-annotated 3d reconstructions of indoor scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angel</forename><forename type="middle">X</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manolis</forename><surname>Savva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maciej</forename><surname>Halber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Funkhouser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Nießner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>International Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Joint 3d-multiview prediction for 3d semantic scene segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Nießner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European Conference on Computer Vision (ECCV)</title>
		<meeting>European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="458" to="474" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Scancomplete: Large-scale scene completion and semantic segmentation for 3d scans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Ritchie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Bokeloh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jrgen</forename><surname>Sturm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Niener</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>International Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2018-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Instance-sensitive fully convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jifeng</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European Conference on Computer Vision (ECCV)</title>
		<editor>Bastian Leibe, Jiri Matas, Nicu Sebe, and Max Welling</editor>
		<meeting>European Conference on Computer Vision (ECCV)<address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="534" to="549" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Instance-aware semantic segmentation via multi-task network cascades</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jifeng</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>International Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3150" to="3158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Semantic instance segmentation via deep metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alireza</forename><surname>Fathi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zbigniew</forename><surname>Wojna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vivek</forename><surname>Rathod</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyun</forename><forename type="middle">Oh</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergio</forename><surname>Guadarrama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><forename type="middle">P</forename><surname>Murphy</surname></persName>
		</author>
		<idno>abs/1703.10277</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The estimation of the gradient of a density function, with applications in pattern recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Fukunaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Hostetler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="32" to="40" />
			<date type="published" when="1975-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Accurate, dense, and robust multiview stereopsis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yasutaka</forename><surname>Furukawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Ponce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1362" to="1376" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Garcia-Garcia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergio</forename><surname>Orts-Escolano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergiu</forename><surname>Oprea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Villena-Martinez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jose</forename><surname>Garcia-Rodriguez</surname></persName>
		</author>
		<title level="m">A Review on Deep Learning Techniques Applied to Semantic Segmentation</title>
		<imprint>
			<date type="published" when="2017-04" />
		</imprint>
	</monogr>
	<note>ArXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Fast R-CNN</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Computer Vision (ICCV)</title>
		<meeting>International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1440" to="1448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">and Laurens van der Maaten. 3d semantic segmentation with submanifold sparse convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Engelcke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>International Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A review of semantic segmentation using deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanming</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theodoros</forename><surname>Georgiou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">S</forename><surname>Lew</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Multimedia Information Retrieval</title>
		<imprint>
			<date type="published" when="2017-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Boundary-aware instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeeshan</forename><surname>Hayder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathieu</forename><surname>Salzmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>International Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Mask R-CNN</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgia</forename><surname>Gkioxari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Computer Vision (ICCV)</title>
		<meeting>International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2980" to="2988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">3d-sis: 3d semantic instance segmentation of rgb-d scans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Nießner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>International Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Kinectfusion: real-time dynamic 3d surface reconstruction and interaction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shahram</forename><surname>Izadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">A</forename><surname>Newcombe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Otmar</forename><surname>Hilliges</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Molyneaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Hodges</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pushmeet</forename><surname>Kohli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Shotton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">J</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">W</forename><surname>Fitzgibbon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Graphics and Interactive Techniques</title>
		<meeting><address><addrLine>Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-08-07" />
			<biblScope unit="page">23</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Simple does it: Weakly supervised instance and semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Khoreva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>Benenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><forename type="middle">Hendrik</forename><surname>Hosang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Hein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>International Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1665" to="1674" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Continuous global optimization in multiview 3d reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kalin</forename><surname>Kolev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Klodt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Cremers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="80" to="96" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Recurrent pixel embedding for instance grouping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charless</forename><forename type="middle">C</forename><surname>Fowlkes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>International Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="9018" to="9028" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 25: 26th Annual Conference on Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1106" to="1114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Joint semantic segmentation and 3d reconstruction from monocular video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhijit</forename><surname>Kundu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Dellaert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fuxin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">M</forename><surname>Rehg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European Conference on Computer Vision (ECCV)</title>
		<meeting>European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="703" to="718" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">2d-driven 3d object detection in rgb-d images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Lahoud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernard</forename><surname>Ghanem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Computer Vision (ICCV)</title>
		<meeting>International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4622" to="4630" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Fully convolutional instance-aware semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haozhi</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jifeng</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyang</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>International Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4438" to="4446" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Proposal-free network for instance-level semantic object segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodan</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunchao</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohui</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianchao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuicheng</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="issue">99</biblScope>
			<biblScope unit="page" from="1" to="1" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>PP</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">3d graph embedding learning with a structure-aware loss function for point cloud semantic instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhidong</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunxiang</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.05247</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Feature pyramid networks for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bharath</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><forename type="middle">J</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>International Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Masc: Multi-scale affinity with sparse convolution for 3d instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yasutaka</forename><surname>Furukawa</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.04478</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Fully convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>International Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Voxnet: A 3d convolutional neural network for real-time object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Maturana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Scherer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/RSJ International Conference on Intelligent Robots and Systems</title>
		<meeting><address><addrLine>Pittsburgh, PA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Panopticfusion: Online volumetric semantic mapping at the level of stuff and things</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaku</forename><surname>Narita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takashi</forename><surname>Seno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomoya</forename><surname>Ishikawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yohsuke</forename><surname>Kaji</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.01177</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Real-time 3d reconstruction at scale using voxel hashing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Nießner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Zollhöfer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shahram</forename><surname>Izadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Stamminger</surname></persName>
		</author>
		<idno>169:1-169:11</idno>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Semi-convolutional operators for instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Novotný</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Albanie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diane</forename><surname>Larlus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Vedaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European Conference on Computer Vision (ECCV)</title>
		<meeting>European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="89" to="105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Learning to segment object candidates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">O</forename><surname>Pedro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Pinheiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dollár</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 28: Annual Conference on Neural Information Processing Systems</title>
		<meeting><address><addrLine>Montreal, Quebec, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-12-07" />
			<biblScope unit="page" from="1990" to="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Pointnet: Deep learning on point sets for 3d classification and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Charles Ruizhongtai Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaichun</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>International Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="77" to="85" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">You only look once: Unified, real-time object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Redmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Santosh</forename><surname>Kumar Divvala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>International Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="779" to="788" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">YOLO9000: better, faster, stronger</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Redmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>International Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6517" to="6525" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Faster R-CNN: towards real-time object detection with region proposal networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>Shaoqing Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><forename type="middle">B</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 28: Annual Conference on Neural Information Processing Systems</title>
		<meeting><address><addrLine>Montreal, Quebec, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-12-07" />
			<biblScope unit="page" from="91" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">U-net: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olaf</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Medical Image Computing and Computer-Assisted Intervention -MICCAI 2015 -18th International Conference Munich</title>
		<meeting><address><addrLine>Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
	<note>Proceedings, Part III</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Pixelwise view selection for unstructured multi-view stereo</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Lutz Schönberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enliang</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Pollefeys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan-Michael</forename><surname>Frahm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European Conference on Computer Vision (ECCV)</title>
		<meeting>European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Convolutionalrecursive deep learning for 3d object classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brody</forename><surname>Huval</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Putta</forename><surname>Bharath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Bath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 25: 26th Annual Conference on Neural Information Processing Systems 2012</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="665" to="673" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Semantic scene completion from a single depth image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuran</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fisher</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angel</forename><forename type="middle">X</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manolis</forename><surname>Savva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">A</forename><surname>Funkhouser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>International Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Large-scale multi-resolution surface reconstruction from RGB-D sequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Steinbrücker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Kerl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Cremers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Computer Vision (ICCV)</title>
		<meeting>International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3264" to="3271" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Going deeper with convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><forename type="middle">E</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>International Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">CNN-SLAM: real-time dense monocular SLAM with learned depth prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keisuke</forename><surname>Tateno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federico</forename><surname>Tombari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iro</forename><surname>Laina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nassir</forename><surname>Navab</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>International Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6565" to="6574" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Sgpn: Similarity group proposal network for 3d point cloud instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiyue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronald</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiangui</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulrich</forename><surname>Neumann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>International Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2018-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">3d shapenets: A deep representation for volumetric shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhirong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuran</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fisher</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linguang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxiong</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>International Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1912" to="1920" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Pixor: Realtime 3d object detection from point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjie</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>International Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2018-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Learning object bounding boxes for 3d instance segmentation on point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronald</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingyong</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Markham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Trigoni</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.01140</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Gspn: Generative shape proposal network for 3d instance segmentation in point cloud</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">He</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minhyuk</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>International Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">A globally optimal algorithm for robust tv-l1 range image integration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Zach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Pock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Horst</forename><surname>Bischof</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Computer Vision (ICCV)</title>
		<meeting>International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Deconvolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilip</forename><surname>Matthew D Zeiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>International Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
