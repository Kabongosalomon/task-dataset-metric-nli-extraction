<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">DPW-SDNet: Dual Pixel-Wavelet Domain Deep CNNs for Soft Decoding of JPEG-Compressed Images</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honggang</forename><surname>Chen</surname></persName>
							<email>honggangchen@yeah.net</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linbo</forename><surname>Qing</surname></persName>
							<email>qinglb@scu.edu.cn</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuhua</forename><surname>Xiong</surname></persName>
							<email>xiongsh@scu.edu.cn</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Truong</forename><forename type="middle">Q</forename><surname>Nguyen</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Sichuan University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Xiaohai He</orgName>
								<orgName type="institution">Sichuan University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Sichuan University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">Sichuan University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<address>
									<settlement>San Diego</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">DPW-SDNet: Dual Pixel-Wavelet Domain Deep CNNs for Soft Decoding of JPEG-Compressed Images</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T18:31+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>JPEG is one of the widely used lossy compression methods. JPEG-compressed images usually suffer from compression artifacts including blocking and blurring, especially at low bit-rates. Soft decoding is an effective solution to improve the quality of compressed images without changing codec or introducing extra coding bits. Inspired by the excellent performance of the deep convolutional neural networks (CNNs) on both low-level and high-level computer vision problems, we develop a dual pixel-wavelet domain deep CNNs-based soft decoding network for JPEGcompressed images, namely DPW-SDNet. The pixel domain deep network takes the four downsampled versions of the compressed image to form a 4-channel input and outputs a pixel domain prediction, while the wavelet domain deep network uses the 1-level discrete wavelet transformation (DWT) coefficients to form a 4-channel input to produce a DWT domain prediction. The pixel domain and wavelet domain estimates are combined to generate the final soft decoded result. Experimental results demonstrate the superiority of the proposed DPW-SDNet over several state-ofthe-art compression artifacts reduction algorithms.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The number of devices with high-resolution camera increases significantly over the last few years, with the introduction of smart phones and IoT (Internet of Things) devices. Limited by the transmission bandwidth and storage capacity, these images and videos are compressed. As shown in <ref type="figure" target="#fig_0">Fig. 1</ref>, compressed images usually suffer from compression artifacts due to the information loss in the lossy compression process, especially at low bit-rates. In addition to poor perceptual quality, compression artifacts also reduce the accuracy of other processing steps such as object detection and classification. Therefore, it is necessary to improve the quality of compressed images. This paper focuses on the soft decoding of JPEG images due to the fact that the JPEG is one of the commonly used compression standards for still images. In recent years, many works investigate the restoration of JPEG images, aiming to remove compression artifacts and enhance the perceptual quality and objective assessment scores. In literature, the restoration procedure is usually referred to as soft decoding <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b21">22]</ref>, deblocking <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b32">33]</ref>, or compression artifacts reduction <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b9">10]</ref>. In this paper, we use these terms interchangeably. Inspired by the excellent performance of the deep convolutional neural networks (CNNs) on various computer vision problems, we propose a dual pixel-wavelet domain deep CNNs-based soft decoding network for JPEG-compressed images, namely DPW-SDNet. From <ref type="figure" target="#fig_0">Fig. 1</ref> that illustrates a restored image by the proposed DPW-SDNet, we can observe that most of the compression artifacts are removed and some missing textures are recovered. Overall, the main contribution of this work is a dual-branch deep CNN that can reduce compression artifacts in both the pixel domain and wavelet domain. More specifically, our contributions are two folds:</p><p>• We develop an effective and efficient soft decoding method for JPEG-compressed images using dual pixelwavelet domain deep CNNs. The combination of the pixel domain and wavelet domain predictions leads to better soft decoding performance.</p><p>• We reshape the compressed image and its 1-level discrete wavelet transformation (DWT) coefficients into two tensors with smaller size, which are used as the inputs to the pixel and wavelet sub-networks, respectively. By performing soft decoding on two smaller tensors, the DPW-SDNet achieves state-of-the-art performance while maintaining efficiency.</p><p>The rest of this paper is organized as follows. We describe the related work in the next section. The proposed soft decoding algorithm is presented in Section 3. Experiments are shown in Section 4. Finally, Section 5 concludes this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Let X and Y be the original uncompressed image and the corresponding JPEG-compressed version, respectively. Given the compressed image Y, the goal of soft decoding is to produce an estimate that is as close as possible to the original image X. Existing methods for soft decoding of JPEG-compressed images can be roughly split into three categories: enhancement-based, restoration-based, and learning-based methods.</p><p>The enhancement-based methods usually remove compression artifacts via performing pixel domain or transform domain filtering. For instance, Foi et al. <ref type="bibr" target="#b6">[7]</ref> proposed a shape-adaptive discrete cosine transformation (DCT)-based image filtering, yielding excellent performance on deblocking and deringing of compressed images. Zhai et al. <ref type="bibr" target="#b30">[31]</ref> proposed to reduce blocking artifacts via postfiltering in shifted windows of image blocks. In <ref type="bibr" target="#b29">[30]</ref>, the authors developed an efficient artifacts reduction algorithm through joint DCT domain and spatial domain processing. Yoo et al. <ref type="bibr" target="#b28">[29]</ref> proposed an inter-block correlation-based blocking artifacts reduction framework, in which the artifacts in flat regions and edge regions were removed using different strategies.</p><p>Compression artifacts reduction is formulated as an illposed inverse problem for the restoration-based soft decoding methods, where the prior knowledge about high-quality images, compression algorithms, and compression parameters is used to assist the restoration process <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b37">38]</ref>. For instance, in <ref type="bibr" target="#b24">[25]</ref>, the original image and compression distortion were modeled as a high-order Markov random field and spatially correlated Gaussian noise, respectively. Non-local self-similarity property was widely used in deblocking algorithms. In general, the low-rank <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b35">36]</ref> and group sparse representation <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b37">38]</ref> were applied to model this property. In <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b37">38]</ref>, sparsity was utilized as an image prior to regularize the restored image. The graph model was used in the deblocking methods proposed in <ref type="bibr" target="#b12">[13]</ref> and <ref type="bibr" target="#b20">[21]</ref>. In some works <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b37">38]</ref>, the quantization constraint on DCT coefficients was applied to restrain the resultant image. In particular, Dar et al. <ref type="bibr" target="#b3">[4]</ref> designed a sequential denoising-based soft decoding algorithm, where the existing state-of-the-art denoising method was used to construct a regularization. On the whole, most of the restorationbased soft decoding methods are time-consuming to some extent due to the complex optimization process.</p><p>Recently, excellent results were obtained by deep learning-based approaches <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b33">34]</ref>. Dong et al. <ref type="bibr" target="#b4">[5]</ref> developed a shallow CNN for compression artifacts reduction on the basis of the network for superresolution <ref type="bibr" target="#b5">[6]</ref>. The authors of <ref type="bibr" target="#b4">[5]</ref> found that it is hard to train a network beyond four layers in low-level vision tasks. To address this issue, Kim et al. <ref type="bibr" target="#b16">[17]</ref> introduced the residual learning technique and designed a very deep network of twenty layers for single image super-resolution. In <ref type="bibr" target="#b33">[34]</ref>, Zhang et al. presented a very deep network via incorporating the residual learning and batch normalization for a series of general image denoising problems, including denoising, super-resolution, and deblocking. Li et al. <ref type="bibr" target="#b18">[19]</ref> combined the skip connection and residual learning to ease the network training process. Cavigelli et al. <ref type="bibr" target="#b0">[1]</ref> developed a deep compression artifacts reduction network with a multi-scale loss function. In <ref type="bibr" target="#b2">[3]</ref>, Chen and Pock proposed a trainable nonlinear reaction diffusion model for efficient image restoration. Inspired by the success of the dual DCTpixel domain sparse coding <ref type="bibr" target="#b21">[22]</ref>, the authors of <ref type="bibr" target="#b8">[9]</ref> and <ref type="bibr" target="#b26">[27]</ref> designed dual-domain networks for the deblocking of JPEG images. More recently, some works aim to improve the perceptual quality of compressed images <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b9">10]</ref>. Overall, deep learning-based approaches show obvious superiority over conventional soft decoding methods in terms of both the restoration performance and running time 1 .</p><p>Inspired by the success of the wavelet domain networks for super-resolution <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b13">14]</ref>, we present a dual pixel-wavelet domain deep CNN for the soft decoding of JPEG-compressed images in this paper. The proposed  DPW-SDNet is different from previous deep learning-based soft decoding algorithms in the following aspects: 1) The DPW-SDNet consists of two parallel branches that perform restoration in the pixel domain and wavelet domain, respectively.</p><p>2) The DPW-SDNet takes two tensors as the network inputs rather than the original compressed image and DWT coefficients. Experiments show that the DPW-SDNet achieves competitive restoration performance and execution speed on JPEG-compressed images. Moreover, the extensions of the proposed DPW-SDNet to other compression standards are straightforward.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Proposed DPW-SDNet</head><p>As outlined in <ref type="figure" target="#fig_1">Fig. 2</ref>, the proposed DPW-SDNet composes of two parallel branches: the pixel domain soft decoding branch and the wavelet domain soft decoding branch. The network in the pixel domain branch (namely P-SDNet) removes compression artifacts in pixel domain directly, while the network in the wavelet domain branch (namely W-SDNet) performs restoration in wavelet domain. The pixel domain and wavelet domain estimates are combined to generate the final soft decoded result. Note that we do not directly use the original compressed image and its DWT sub-bands as the inputs of the two sub-networks. In the following sections, more details about the DPW-SDNet are presented. For convenience, we assume that the input Y is a gray-scaled image of size m × n where m, n are both even.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">The Pixel Domain Branch</head><p>In the pixel domain branch (shown in the bottom half of <ref type="figure" target="#fig_1">Fig. 2</ref>), first the compressed image Y is downsampled to generate four downsampled sub-images of size m 2 × n 2 . Since we have to recover an image that has the same size with the input, a reversible downsampling strategy is used in this process as <ref type="bibr" target="#b34">[35]</ref>. <ref type="figure" target="#fig_2">Fig. 3</ref> illustrates the reversible downsampling process. Given Y, the pixels located at (2i + 1, 2j+1), (2i+1, 2j+2), (2i+2, 2j+1), and (2i+2, 2j+2) (i = 0, 1, 2, · · · , m 2 − 1, j = 0, 1, 2, · · · , n 2 − 1) are respectively sampled to form four different sub-images, which are concatenated to constitute a tensor of size m 2 × n 2 × 4. Then, the tensor is fed into the pixel domain deep CNN. At least two benefits can be achieved by using a smaller tensor as the input of a deep CNN. First, a smaller input means lower computational complexity. In addition, working on the downsampled images can enlarge the receptive field, which is beneficial to restoration process.</p><p>For convenience, we name the pixel domain deep CNN P-SDNet. The input and output of the P-SDNet are tensors. The D-layer P-SDNet consists of two kinds of blocks. The first (D − 1) blocks are "CONV+BN+ReLU", and the last block only includes a convolutional layer. Note that the abbreviation "CONV" represents a convolutional layer, "BN" denotes the batch normalization <ref type="bibr" target="#b14">[15]</ref>, and "ReLU" represents the rectified linear unit <ref type="bibr" target="#b17">[18]</ref>. The kernel number of each convolutional layer is set to 64 except the last layer that outputs a 4-channel residual image. The kernel size of each convolutional layers is set to 3 × 3. In each layer, the zero padding strategy is adopted to keep all feature maps having the same size. Since the input and output of the P-SDNet are very similar, we adopt the residual learning <ref type="bibr" target="#b11">[12]</ref> for stable and fast training. Hence, the training loss function of the P-SDNet is defined as</p><formula xml:id="formula_0">L P (Θ P ) = 1 2N N i=1 (f p (y pt i ; Θ P ) + y pt i ) − x pt i 2<label>(1)</label></formula><p>where the Θ P represents all parameters in P-SDNet, f p (y pt i ; Θ P ) is the predicted residual component, and</p><formula xml:id="formula_1">{(y pt i , x pt i )} N i=1</formula><p>denotes N compressed-clean tensor pairs in the pixel domain.</p><p>Finally, the four feature maps in the output of P-SDNet are assembled according to the inverse process of the downsampling procedure to form the pixel domain estimate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">The Wavelet Domain Branch</head><p>The framework of the wavelet domain branch is similar to the pixel domain branch. Given a compressed image Y, we first conduct the 1-level 2-dimensional discrete wavelet transformation (2D-DWT) and obtain its four wavelet subbands coefficients. The size of each sub-band is m 2 × n 2 . Similarly, the four wavelet sub-bands are concatenated to constitute a tensor of size m 2 × n 2 × 4, which is used as the input of the wavelet domain deep CNN, namely W-SDNet. By concatenating four wavelet sub-bands, the information in different sub-bands can be fused while keeping the consistency among them. Moreover, the computational cost can be reduced.</p><p>The architecture of the W-SDNet is set to be the same as the P-SDNet, including the network depth, number of kernels, and kernel size. Therefore, we do not introduce the W-SDNet in details to avoid redundancy. The main difference between the two sub-networks is that the W-SDNet predicts wavelet coefficients residual while the P-SDNet predicts pixel intensity residual. Correspondingly, the training loss function of the W-SDNet is defined as</p><formula xml:id="formula_2">L W (Θ W ) = 1 2N N i=1 (f w (y wt i ; Θ W ) + y wt i ) − x wt i 2 (2) where the Θ W represents all parameters in W-SDNet, f w (y wt i ; Θ W ) is the predicted residual component, and {(y wt i , x wt i )} N i=1</formula><p>denotes N compressed-clean tensor pairs in the wavelet domain.</p><p>The four feature maps in the output of W-SDNet are the wavelet sub-bands of the soft decoded image. Therefore, the 2-dimensional inverse discrete wavelet transformation (2D-IDWT) is performed on these coefficients to produce the wavelet domain estimate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">The Combination of the Dual-Branch</head><p>As mentioned above, the pixel domain and wavelet domain branches both produce a soft decoded version of the input image. Since the two predictions are generated in different spaces, they have their respective characteristics. Hence, combining them should improve the restoration performance further. There are many ways to fuse the two intermediate results. For example, we can design a network with a 2-channel input and a 1-channel output to combine them. Considering the computational complexity, the two estimates derived from the dual-domain are simply equally weighted to generate the final output in this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>In this section, we first introduce some implementation details, followed by experimental results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Implementation Details</head><p>Training Data: The publicly available imageset BSDS500 2 is used to train the DPW-SDNet. We adopt the data augmentation (rotation and downsampling) to generate more training images. For the P-SDNet, we extract training sample pairs from original images and the corresponding compressed images. Correspondingly, the 2D-DWT coefficients of the original images and compressed images are used to generate training sample pairs for the W-SDNet. We generate N = 523, 968 training sample pairs for each subnetwork, and the size of each sample is set to 31 × 31 × 4.</p><p>Training Parameters: We use the Caffe package <ref type="bibr" target="#b15">[16]</ref> to implement the proposed network, and the depths of P-SDNet and W-SDNet are set to 20 (D = 20). The stochastic gradient descent algorithm is adopted to optimize our networks. The batch size, weight decay, momentum are set to 64, 0.0001, and 0.9, respectively. The initial learning rate is set to 0.1, and it decreases by a factor of 10 every 10 epochs. The maximum number of iterations is set to 300, 000 for both the pixel domain and wavelet domain sub-networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Soft Decoding Performance Evaluation</head><p>The DPW-SDNet is compared with five state-of-theart soft decoding algorithms for JPEG-compressed images, including two restoration-based approaches (i.e., CON-COLOR <ref type="bibr" target="#b32">[33]</ref> and D2SD <ref type="bibr" target="#b21">[22]</ref>) and three deep learningbased algorithms (i.e., ARCNN <ref type="bibr" target="#b4">[5]</ref>, TNRD <ref type="bibr" target="#b2">[3]</ref>, and DnCNN-3 <ref type="bibr" target="#b33">[34]</ref>). Referring to <ref type="bibr" target="#b33">[34]</ref>, two benchmark imagesets Classic5 and LIVE1 are used as test datasets. For the color images in the LIVE1 dataset, only the luminance components are processed. The MATLAB JPEG encoder is used to generate JPEG-compressed images at different quality factors (QFs). We compare the performance of these (e) ARCNN <ref type="bibr" target="#b4">[5]</ref> (f) TNRD <ref type="bibr" target="#b2">[3]</ref> (g) DnCNN-3 <ref type="bibr" target="#b33">[34]</ref> (h) Proposed DPW-SDNet (e) ARCNN <ref type="bibr" target="#b4">[5]</ref> (f) TNRD <ref type="bibr" target="#b2">[3]</ref> (g) DnCNN-3 <ref type="bibr" target="#b33">[34]</ref> (h) Proposed DPW-SDNet algorithms in the cases of QF = 10, 20, 30, and 40. For the DPW-SDNet, a dedicated model is trained for each QF. For the five competitors, we use the original codes and models provided by the authors. <ref type="table" target="#tab_0">Table 1</ref> reports the objective assessment scores achieved by all tested algorithms, including the PSNR, SSIM <ref type="bibr" target="#b25">[26]</ref>, and PSNR-B <ref type="bibr" target="#b27">[28]</ref> 3 . Note that the PSNR-B is a specifically developed assessment metric for blocky and deblocked images. It can be observed from <ref type="table" target="#tab_0">Table 1</ref> that the DPW-SDNet consistently outperforms the five competitors with considerable improvements. The only exception is the PSNR-B value on Classic5 in the case of QF = 40, where the CON-COLOR <ref type="bibr" target="#b32">[33]</ref> is superior to the DPW-SDNet. Overall, the DnCNN-3 <ref type="bibr" target="#b33">[34]</ref> and TNRD <ref type="bibr" target="#b2">[3]</ref> generate the second-best and the third-best results, respectively. The CONCOLOR <ref type="bibr" target="#b32">[33]</ref>, D2SD <ref type="bibr" target="#b21">[22]</ref>, and ARCNN <ref type="bibr" target="#b4">[5]</ref> achieve comparable performance overall. On average, the proposed DPW-SDNet achieves about (0.30 ∼ 0.34) dB PSNR gains, (0.0030 ∼ 0.0098) SSIM gains, and (0.04 ∼ 0.24) dB PSNR-B gains over the second-best approach DnCNN-3 <ref type="bibr" target="#b33">[34]</ref>. The gains over the two restoration-based soft decoding algorithms and ARCNN <ref type="bibr" target="#b4">[5]</ref> are more significant. The improvements over state-of-the-art deblocking approaches demonstrate the effectiveness of the proposed DPW-SDNet.</p><p>One important aim of soft decoding algorithms is to recover images with high visual quality as JPEG-compressed images at high compression ratios usually suffer from severe artifacts. Therefore, some soft decoded images produced by different methods at QF = 10 are shown in <ref type="figure" target="#fig_3">Fig. 4</ref>, <ref type="figure" target="#fig_4">Fig. 5</ref>, and <ref type="figure" target="#fig_6">Fig. 6</ref> in order to compare visual quality. It can be observed that most of the compression artifacts in JPEG images are removed by performing soft decoding on them. However, some soft decoded images are over-smoothed to some extent, or still suffer from visible artifacts. By contrast, the DPW-SDNet shows superiority in reducing artifacts and restoring details. The restored images using DPW-SDNet are more perceptually appealing, which can be seen from the highlighted regions. The results in this section verify that the DPW-SDNet not only achieves higher objective evaluation scores, but also produces better visual quality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Discussion on Dual-Domain Soft Decoding</head><p>In DPW-SDNet, two parallel branches are used to restore the compressed image in the pixel domain and wavelet domain, respectively. It is meaningful to study the ability of the two branches and discuss the effectiveness of the dual- (c) CONCOLOR <ref type="bibr" target="#b32">[33]</ref> (d) D2SD <ref type="bibr" target="#b21">[22]</ref> (e) ARCNN <ref type="bibr" target="#b4">[5]</ref> (f) TNRD <ref type="bibr" target="#b2">[3]</ref> (g) DnCNN-3 <ref type="bibr" target="#b33">[34]</ref> (h) Proposed DPW-SDNet   <ref type="table" target="#tab_1">Table 2</ref> presents the objective assessment scores of the DPW-SDNet and its two variants, i.e., the P-SDNet and W-SDNet. Here the P-SDNet represents that only the pixel domain branch is used to restore the compressed image, while the W-SDNet represents that only the wavelet domain branch is used.</p><p>It can be observed from <ref type="table" target="#tab_1">Table 2</ref> that both the P-SDNet and W-SDNet generate excellent restoration performance, which proves the ability of the presented network. Moreover, the gains of the DPW-SDNet over the P-SDNet and W-SDNet verify the effectiveness of the dual-domain soft decoding. Furthermore, it is believed that the fusion of the two branches could be more effective with a more complex combination method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Discussion on Blind Soft Decoding</head><p>In above experiments, we use a dedicated model for each compression QF. To test the capacity of the DPW-SDNet further, we train a universal model for compressed images at different QFs. We refer to the universal model as the blind DPW-SDNet (B-DPW-SDNet), which is trained using the samples compressed at different QFs 4 . In Section 4.2, DPW-SDNet and DnCNN-3 <ref type="bibr" target="#b33">[34]</ref> perform the best and the second-best on the whole, respectively. Therefore, we compare the B-DPW-SDNet with them in <ref type="table" target="#tab_2">Table 3</ref>.</p><p>As expected, the B-DPW-SDNet is slightly inferior to DPW-SDNet. However, in most cases, it still outper-   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Empirical Study on Training Convergence and Running Time</head><p>In <ref type="figure" target="#fig_7">Fig. 7</ref>, we show the PSNR values of DPW-SDNet with different training iterations. The trends are similar for different QFs, so only the curves at QF = 40 are presented. It can be seen that the training converges after about 200,000 iterations. In our experiments, the maximum number of iterations is set to 300,000. The training of a single model takes about 9 hours on a GeForce GTX 1080 Ti GPU.</p><p>Running time is an important factor for a soft decoding algorithm. We run different deblocking methods on the same desktop computer with an Inter Core i7 CPU 4.2 GHz, 32GB RAM, and Matlab environment. <ref type="figure" target="#fig_8">Fig. 8</ref> presents the execution time of different approaches on three representative image sizes in Classic5 and LIVE1 5 . It can be seen that the proposed P-SDNet and W-SDNet are the most efficient approaches. The DPW-SDNet costs about 2× time compared with the P-SDNet and W-SDNet, but it is still less time-consuming than other compared algorithms. Moreover, the execution speed of the DPW-SDNet can be greatly accelerated with a GPU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion and Future Work</head><p>A dual pixel-wavelet domain deep network-based soft decoding framework is developed for JPEG-compressed images, namely DPW-SDNet. In DPW-SDNet, the compressed image is restored in both pixel and wavelet spaces using deep CNNs. In addition, we use 4-channel tensors as the inputs of our networks rather than the 2-dimensional images, which makes the DPW-SDNet efficient and effective. Experimental results on benchmark datasets demonstrate the effectiveness and efficiency of our soft decoding algorithm. Future work includes the extensions of the proposed DPW-SDNet to other image compression standards as well as other image restoration problems. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Acknowledgment</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Illustrations of compression artifacts and soft decoding. (a) JPEG-compressed image in the case of QF = 10 (PSNR = 25.79 dB, SSIM = 0.7621, PSNR-B = 23.48 dB); (b) Soft decoded result of (a) using the developed DPW-SDNet (PSNR = 28.22 dB, SSIM = 0.8376, PSNR-B = 27.84 dB).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Flowchart of the proposed DPW-SDNet. The DPW-SDNet reduces compression artifacts in dual pixel-wavelet domain. The depths of the P-SDNet and W-SDNet are set to 20. The number next to each convolutional layer represents the number of kernels, and all of the convolutional layers in DPW-SDNet have the same kernel size of 3 × 3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Illustration of the reversible downsampling process used in the pixel domain soft decoding branch. (a) The input image (size: m × n, here m = n = 16); (b)-(e) Different downsampled versions of (a) (size: m 2 × n 2 ); (f) The tensor composed of (b)-(e) (size: m 2 × n 2 × 4). Note that this downsampling process is reversible.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Visual quality comparison of different soft decoding methods on Barbara in the case of QF = 10. (a) Original image (PSNR (dB), SSIM, PSNR-B (dB)); (b) JPEG (25.79, 0.7621, 23.48); (c) CONCOLOR [33] (27.73, 0.8216, 27.63); (d) D2SD [22] (27.93, 0.8214, 27.64); (e) ARCNN [5] (26.92, 0.7967, 26.75); (f) TNRD [3] (27.24, 0.8099, 27.13); (g) DnCNN-3 [34] (27.58, 0.8161, 27.29); (h) Proposed DPW-SDNet (28.22, 0.8376, 27.84).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 .</head><label>5</label><figDesc>Visual quality comparison of different soft decoding methods on Bike in the case of QF = 10. (a) Original image (PSNR (dB), SSIM, PSNR-B (dB)); (b) JPEG (25.77, 0.7417, 23.02); (c) CONCOLOR [33] (27.00, 0.7801, 27.00); (d) D2SD [22] (27.11, 0.7859, 26.97); (e) ARCNN [5] (27.41, 0.7924, 27.11); (f) TNRD [3] (27.54, 0.7971, 27.22); (g) DnCNN-3 [34] (27.59, 0.7999, 27.28); (h) Proposed DPW-SDNet (28.04, 0.8133, 27.58).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 .</head><label>6</label><figDesc>Visual quality comparison of different soft decoding methods on Lighthouse3 in the case of QF = 10. (a) Original image (PSNR (dB), SSIM, PSNR-B (dB)); (b) JPEG (28.29, 0.7636, 25.98); (c) CONCOLOR [33] (29.77, 0.7976, 29.36); (d) D2SD [22] (29.77, 0.7977, 29.24); (e) ARCNN [5] (29.63,0.7973, 29.19); (f) TNRD [3] (29.75, 0.8013, 29.27); (g) DnCNN-3 [34] (29.81, 0.8007, 29.38); (h) Proposed DPW-SDNet (30.30, 0.8104, 29.76).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 .</head><label>7</label><figDesc>The PSNR (dB) values of DPW-SDNet on Classic5 and LIVE1 with different training iterations (QF = 40).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 8 .</head><label>8</label><figDesc>The running time (s) of different soft decoding algorithms on three representative image sizes in Classic5 and LIVE1.forms DnCNN-3<ref type="bibr" target="#b33">[34]</ref> with obvious gains. Compared with DPW-SDNet, B-DPW-SDNet is more flexible and practical. Given QF, DPW-SDNet can be used to obtain better restoration performance, while B-DPW-SDNet can produce competitive results when the QF is unknown. Hence, one can select a proper model according to the practical application.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>This work was supported in part by the National Natural Science Foundation of China under Grant 61471248, in part by the Fundamental Research Funds for the Central Universities under Grant 2012017yjsy159, and in part by the China Scholarship Council under Grant 201706240037. The authors thank Cheolhong An and Wenshu Zhan for helpful discussions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Average PSNR (dB)/SSIM/PSNR-B (dB) scores of different soft decoding algorithms on Classic5 and LIVE1. The best and the second-best scores are highlighted in red and blue, respectively. .7595/25.21 30.12/0.8344/27.50 31.48/0.8666/28.94 32.43/0.8849/29.92 CONCOLOR [33] 29.24/0.7963/29.14 31.38/0.8541/31.18 32.70/0.8809/32.50 33.60/0.8961/33.36 D2SD [22] 29.21/0.7960/28.87 31.47/0.8551/31.15 32.79/0.8813/32.40 33.66/0.8962/33.20</figDesc><table><row><cell></cell><cell>QF</cell><cell>10</cell><cell>20</cell><cell>30</cell><cell>40</cell></row><row><cell>Classic5</cell><cell cols="5">JPEG 27.82/0ARCNN [5] 29.05/0.7929/28.78 31.16/0.8517/30.60 32.52/0.8806/32.00 33.33/0.8953/32.81</cell></row><row><cell></cell><cell>TNRD [3]</cell><cell cols="3">29.28/0.7992/29.04 31.47/0.8576/31.05 32.78/0.8837/32.24</cell><cell>-</cell></row><row><cell></cell><cell>DnCNN-3 [34]</cell><cell cols="4">29.40/0.8026/29.13 31.63/0.8610/31.19 32.90/0.8860/32.36 33.77/0.9003/33.20</cell></row><row><cell></cell><cell>DPW-SDNet</cell><cell cols="4">29.74/0.8124/29.37 31.95/0.8663/31.42 33.22/0.8903/32.51 34.07/0.9039/33.24</cell></row><row><cell></cell><cell>JPEG</cell><cell cols="4">27.77/0.7730/25.34 30.08/0.8512/27.57 31.41/0.8852/28.93 32.36/0.9041/29.96</cell></row><row><cell></cell><cell cols="5">CONCOLOR [33] 28.87/0.8018/28.76 31.08/0.8681/30.90 32.42/0.8985/32.16 33.39/0.9157/33.07</cell></row><row><cell></cell><cell>D2SD [22]</cell><cell cols="4">28.83/0.8023/28.54 31.08/0.8690/30.80 32.41/0.8987/32.10 33.37/0.9156/33.06</cell></row><row><cell>LIVE1</cell><cell>ARCNN [5]</cell><cell cols="4">29.04/0.8076/28.77 31.31/0.8733/30.79 32.73/0.9043/32.22 33.63/0.9198/33.14</cell></row><row><cell></cell><cell>TNRD [3]</cell><cell cols="3">29.14/0.8111/28.88 31.46/0.8769/31.04 32.84/0.9059/32.28</cell><cell>-</cell></row><row><cell></cell><cell>DnCNN-3 [34]</cell><cell cols="4">29.19/0.8123/28.91 31.59/0.8802/31.08 32.99/0.9090/32.35 33.96/0.9247/33.29</cell></row><row><cell></cell><cell>DPW-SDNet</cell><cell cols="4">29.53/0.8210/29.13 31.90/0.8854/31.27 33.31/0.9130/32.52 34.30/0.9282/33.44</cell></row><row><cell cols="2">(a) Original image</cell><cell>(b) JPEG</cell><cell>(c) CONCOLOR [33]</cell><cell></cell><cell>(d) D2SD [22]</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Average PSNR (dB)/SSIM/PSNR-B (dB) scores of different variants of the DPW-SDNet on Classic5 and LIVE1. The best scores are highlighted in red.</figDesc><table><row><cell></cell><cell>QF</cell><cell>10</cell><cell>20</cell><cell>30</cell><cell>40</cell></row><row><cell></cell><cell>P-SDNet</cell><cell cols="4">29.69/0.8116/29.33 31.89/0.8657/31.39 33.18/0.8899/32.49 34.04/0.9036/33.22</cell></row><row><cell>Classic5</cell><cell>W-SDNet</cell><cell cols="4">29.70/0.8117/29.33 31.91/0.8660/31.37 33.18/0.8900/32.48 34.03/0.9036/33.21</cell></row><row><cell></cell><cell>DPW-SDNet</cell><cell cols="4">29.74/0.8124/29.37 31.95/0.8663/31.42 33.22/0.8903/32.51 34.07/0.9039/33.24</cell></row><row><cell></cell><cell>P-SDNet</cell><cell cols="4">29.49/0.8203/29.10 31.86/0.8849/31.25 33.27/0.9126/32.49 34.26/0.9278/33.41</cell></row><row><cell>LIVE1</cell><cell>W-SDNet</cell><cell cols="4">29.51/0.8205/29.11 31.87/0.8850/31.25 33.28/0.9127/32.50 34.26/0.9279/33.42</cell></row><row><cell></cell><cell>DPW-SDNet</cell><cell cols="4">29.53/0.8210/29.13 31.90/0.8854/31.27 33.31/0.9130/32.52 34.30/0.9282/33.44</cell></row><row><cell cols="2">domain combination.</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>Comparisons of PSNR (dB)/SSIM/PSNR-B (dB) scores of the DnCNN-3 [34], DPW-SDNet, and B-DPW-SDNet on Classic5 and LIVE1. The best and the second-best scores are highlighted in red and blue, respectively. .8026/29.13 31.63/0.8610/31.19 32.90/0.8860/32.36 33.77/0.9003/33.20 DPW-SDNet 29.74/0.8124/29.37 31.95/0.8663/31.42 33.22/0.8903/32.51 34.07/0.9039/33.24 B-DPW-SDNet 29.69/0.8104/29.34 31.92/0.8660/31.39 33.18/0.8900/32.44 34.01/0.9035/33.19</figDesc><table><row><cell>QF</cell><cell>10</cell><cell>20</cell><cell>30</cell><cell>40</cell></row><row><cell cols="5">Classic5 29.40/0LIVE1 DnCNN-3 [34] DnCNN-3 [34] 29.19/0.8123/28.91 31.59/0.8802/31.08 32.99/0.9090/32.35 33.96/0.9247/33.29 DPW-SDNet 29.53/0.8210/29.13 31.90/0.8854/31.27 33.31/0.9130/32.52 34.30/0.9282/33.44</cell></row><row><cell>B-DPW-SDNet</cell><cell cols="4">29.48/0.8193/29.10 31.87/0.8849/31.26 33.27/0.9127/32.46 34.24/0.9278/33.38</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">In general, the deep learning-based image restoration approaches are time-consuming in model training phase but efficient in testing phase. In this paper, the running time refers to the time cost in testing phase only.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Available: https://www2.eecs.berkeley.edu/Research/Projects/CS/ vision/grouping/resources.html</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">For the TNRD<ref type="bibr" target="#b2">[3]</ref>, the results at QF = 40 are not presented as the corresponding model is not available.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">Note that the same training dataset and the same number of training samples are used to train the universal model and the dedicated model.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">In this experiment, the running time of the TNRD<ref type="bibr" target="#b2">[3]</ref> is evaluated with the multi-threaded computation implementation.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">CAS-CNN: A deep convolutional neural network for image compression artifact suppression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Cavigelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hager</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Benini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Joint Conference on Neural Networks (IJCNN)</title>
		<meeting>the International Joint Conference on Neural Networks (IJCNN)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="752" to="759" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Reducing artifacts in jpeg decompression via a learned dictionary</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">K</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Process</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="718" to="728" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Trainable nonlinear reaction diffusion: A flexible framework for fast and effective image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1256" to="1272" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Postprocessing of compressed images via sequential denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Dar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Bruckstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Giryes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="3044" to="3058" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Compression artifacts reduction by a deep convolutional network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Computer Vision (ICCV)</title>
		<meeting>the International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="576" to="584" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Learning a deep convolutional network for image super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="184" to="199" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Pointwise shapeadaptive dct for high-quality denoising and deblocking of grayscale and color images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Foi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Katkovnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Egiazarian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1395" to="1411" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Deep generative adversarial compression artifact removal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Galteri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Seidenari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bertini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Del</forename><surname>Bimbo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Computer Vision (ICCV)</title>
		<meeting>the International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4826" to="4835" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Building dual-domain representations for compression artifacts reduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="628" to="644" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">One-to-many network for visually pleasing compression artifacts reduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4867" to="4876" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Deep wavelet prediction for image super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Mousavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">H</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Monga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1100" to="1109" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Graph-based dequantization of block-compressed piecewise smooth images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kazui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Process. Lett</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="242" to="246" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Wavelet-SRNet: A wavelet-based cnn for multi-scale face super resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1689" to="1697" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning (ICML)</title>
		<meeting>the International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="448" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Caffe: Convolutional architecture for fast feature embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Karayev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Guadarrama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM international conference on Multimedia</title>
		<meeting>the 22nd ACM international conference on Multimedia</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="675" to="678" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Accurate image superresolution using very deep convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Kwon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K. Mu</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1646" to="1654" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Neural Information Processing Systems Conference (NIPS)</title>
		<meeting>the Neural Information Processing Systems Conference (NIPS)</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">An efficient deep convolutional neural networks model for compressed image deblocking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Multimedia and Expo (ICME)</title>
		<meeting>the IEEE International Conference on Multimedia and Expo (ICME)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1320" to="1325" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">An iterative framework of cascaded deblocking and super-resolution for compressed images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Qing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Teng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Multimedia</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1305" to="1320" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Random walk graph laplacian-based smoothness prior for soft decoding of jpeg images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="509" to="524" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Data-driven soft decoding of compressed images in dual transform-pixel domain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1649" to="1659" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Adaptive multi-dimension sparsity based coefficient estimation for compression artifact reduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Multimedia and Expo (ICME)</title>
		<meeting>the IEEE International Conference on Multimedia and Expo (ICME)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Image blocking artifacts reduction via patch clustering and low-rank minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Data Compression Conference (DCC)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="516" to="516" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Postprocessing of low bit-rate block dct coded images based on a fields of experts prior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">K</forename><surname>Cham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2743" to="2751" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Image quality assessment: from error visibility to structural similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Bovik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">R</forename><surname>Sheikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">P</forename><surname>Simoncelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="600" to="612" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">D 3 : Deep dual-domain based fast restoration of jpegcompressed images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2764" to="2772" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Quality assessment of deblocked images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Bovik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="88" to="98" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Post-processing for blocking artifact reduction based on inter-block correlation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">B</forename><surname>Yoo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Ra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Multimedia</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1536" to="1548" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Efficient deblocking with coefficient regularization, shape-adaptive filtering, and quantization constraint</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Multimedia</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="735" to="745" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Efficient image deblocking based on postfiltering in shifted windows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Circuits Syst. Video Technol</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="122" to="126" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Image deblocking using group-based sparse representation and quantization constraint prior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Image Processing (ICIP)</title>
		<meeting>the IEEE International Conference on Image Processing (ICIP)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="306" to="310" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">CONCOLOR: Constrained non-convex low-rank model for image deblocking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1246" to="1259" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Beyond a gaussian denoiser: Residual learning of deep cnn for image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="3142" to="3155" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">FFDNet: Toward a fast and flexible solution for cnn based image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.04026</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Low-rank decomposition based restoration of compressed images via adaptive noise estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="4158" to="4171" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Compression artifact reduction by overlapped-block transform coefficient estimation with block similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="4613" to="4626" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Reducing image compression artifacts by structural sparse representation and quantization constraint prior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Circuits Syst. Video Technol</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2057" to="2071" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
