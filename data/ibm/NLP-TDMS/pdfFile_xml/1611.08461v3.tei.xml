<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Discriminative Correlation Filter Tracker with Channel and Spatial Reliability</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Lukežič</surname></persName>
							<email>alan.lukezic@fri.uni-lj.si</email>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Computer and Information Science</orgName>
								<orgName type="institution">University of Ljubljana</orgName>
								<address>
									<country key="SI">Slovenia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomáš</forename><surname>Vojíř</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Faculty of Electrical Engineering</orgName>
								<orgName type="institution">Czech Technical University</orgName>
								<address>
									<settlement>Prague</settlement>
									<country key="CZ">Czech Republic</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukačehovin</forename><surname>Zajc</surname></persName>
							<email>luka.cehovin@fri.uni-lj.si</email>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Computer and Information Science</orgName>
								<orgName type="institution">University of Ljubljana</orgName>
								<address>
									<country key="SI">Slovenia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiří</forename><surname>Matas</surname></persName>
							<email>matas@cmp.felk.cvut.cz</email>
							<affiliation key="aff1">
								<orgName type="department">Faculty of Electrical Engineering</orgName>
								<orgName type="institution">Czech Technical University</orgName>
								<address>
									<settlement>Prague</settlement>
									<country key="CZ">Czech Republic</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matej</forename><surname>Kristan</surname></persName>
							<email>matej.kristan@fri.uni-lj.si</email>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Computer and Information Science</orgName>
								<orgName type="institution">University of Ljubljana</orgName>
								<address>
									<country key="SI">Slovenia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Discriminative Correlation Filter Tracker with Channel and Spatial Reliability</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T16:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Visual tracking</term>
					<term>Correlation filters</term>
					<term>Channel reliability</term>
					<term>Constrained optimization</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Short-term tracking is an open and challenging problem for which discriminative correlation filters (DCF) have shown excellent performance. We introduce the channel and spatial reliability concepts to DCF tracking and provide a learning algorithm for its efficient and seamless integration in the filter update and the tracking process. The spatial reliability map adjusts the filter support to the part of the object suitable for tracking. This both allows to enlarge the search region and improves tracking of non-rectangular objects. Reliability scores reflect channel-wise quality of the learned filters and are used as feature weighting coefficients in localization. Experimentally, with only two simple standard feature sets, HoGs and Colornames, the novel CSR-DCF method -DCF with Channel and Spatial Reliability -achieves state-of-theart results on VOT 2016, VOT 2015 and OTB100. The CSR-DCF runs close to real-time on a CPU.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Short-term, model-free visual object tracking is the problem of continuously localizing a target in a videosequence given a single example of its appearance. It has received significant attention of the computer vision community which is reflected in the number of papers published on the topic and the existence of multiple performance evaluation benchmarks <ref type="bibr" target="#b49">(Wu et al, 2013;</ref><ref type="bibr" target="#b25">Kristan et al, 2013</ref><ref type="bibr" target="#b26">Kristan et al, , 2014</ref><ref type="bibr" target="#b27">Kristan et al, , 2015</ref><ref type="bibr" target="#b30">Kristan et al, , 2016c</ref><ref type="bibr" target="#b33">Liang et al, 2015;</ref><ref type="bibr" target="#b42">Smeulders et al, 2014;</ref><ref type="bibr" target="#b39">Mueller et al, 2016)</ref>. Diverse factorsocclusion, illumination change, fast object or camera motion, appearance changes due to rigid or non-rigid deformations and similarity to the background -make shortterm tracking challenging.</p><p>Recent short-term tracking evaluations <ref type="bibr" target="#b49">(Wu et al, 2013;</ref><ref type="bibr" target="#b25">Kristan et al, 2013</ref><ref type="bibr" target="#b26">Kristan et al, , 2014</ref><ref type="bibr" target="#b27">Kristan et al, , 2015</ref> consistently confirm the advantages of semi-supervised discriminative tracking approaches <ref type="bibr" target="#b17">(Grabner et al, 2006;</ref><ref type="bibr" target="#b0">Babenko et al, 2011;</ref><ref type="bibr" target="#b18">Hare et al, 2011;</ref><ref type="bibr" target="#b3">Bolme et al, 2010)</ref>. In particular, trackers based on the discriminative correlation filter (DCF) method <ref type="bibr" target="#b3">(Bolme et al, 2010;</ref><ref type="bibr" target="#b7">Danelljan et al, 2014a;</ref><ref type="bibr" target="#b20">Henriques et al, 2015;</ref><ref type="bibr" target="#b31">Li and Zhu, 2014a;</ref><ref type="bibr" target="#b9">Danelljan et al, 2015a)</ref> have shown state-of-the-art performance in all standard benchmarks. Discriminative correlation methods learn a filter with a pre-defined response on the training image. The latter is obtained by slightly extending the region around the target to include background samples.</p><p>The standard formulation of DCF uses circular correlation which allows to implement learning efficiently by Fast Fourier transform (FFT). However, the FFT requires the filter and the search region size to be equal which limits the detection range. Due to the circularity, the filter is trained on many examples that contain unrealistic, wrapped-around circularly-shifted versions of the target. A naive approach to the reduction of the windowing problems is to learn the filter from a larger region. However, due to the large area of the background in the region, the tracking performance of the DCF drops significantly as shown in <ref type="figure">Figure 2</ref>.</p><p>The windowing problems were recently addressed by  <ref type="figure">Figure 1</ref>: Overview of the CSR-DCF approach. An automatically estimated spatial reliability map restricts the correlation filter to the parts suitable for tracking (top) improving localization within a larger search region and performance for irregularly shaped objects. Channel reliability weights calculated in the constrained optimization step of the correlation filter learning reduce the noise of the weight-averaged filter response (bottom).</p><p>Kiani <ref type="bibr" target="#b24">Galoogahi et al (2015)</ref> who propose zero-padding the filter during learning and by <ref type="bibr" target="#b9">Danelljan et al (2015a)</ref> who introduce spatial regularization to penalize filter values outside the target boundaries. Both approaches train from image regions much larger than the target and thus increase the detection range.</p><p>Another limitation of the published DCF methods is the assumption that the target shape is well approximated by an axis-aligned rectangle. For irregularly shaped objects or those with a hollow center, the filter eventually learns the background, which may lead to drift and failure. The same problem appears for approximately rectangular objects in the case of occlusion. The Kiani <ref type="bibr" target="#b24">Galoogahi et al (2015)</ref> and <ref type="bibr" target="#b9">Danelljan et al (2015a)</ref> methods both suffer from this problem.</p><p>In this paper we introduce the CSR-DCF, the Discriminative Correlation Filter with Channel and Spatial Reliability. The spatial reliability map adapts the filter support to the part of the object suitable for tracking which overcomes both the problems of circular shift enabling an arbitrary search (and training) region size and the limitations related to the rectangular shape assumption. An important benefit of a large training region is that background samples from a wider area around the target are obtained to improve the filter discriminative power. The spatial reliability map is estimated using the output of a graph labeling problem solved efficiently in each frame. An efficient optimization procedure is applied for learning a correlation filter with the support constrained by the spatial reliability map since the standard closed-form solution cannot be generalized to this case. <ref type="figure">Figure 2</ref> shows that tracking performance of our spatially constrained correlation filter (denoted as S-DCF) does not degrade with increasing training and search region size as is the case with the standard DCF. In contrast, the performance of S-DCF improves from better treatment of training samples and increased search region size. Experiments show that the novel filter optimization procedure outperforms related approaches for constrained learning in DCFs.</p><p>Channel reliability is the second novelty the CSR-DCF tracker introduces. The reliability is estimated from the properties of the constrained least-squares solution to filter design. The channel reliability scores are used for weighting the per-channel filter responses in localization <ref type="figure">(Figure 1)</ref>.</p><p>The CSR-DCF shows state-of-the-art performance on standard benchmarks -OTB100 <ref type="bibr" target="#b50">(Wu et al, 2015)</ref>, VOT2015 <ref type="bibr" target="#b27">(Kristan et al, 2015)</ref> and VOT2016 <ref type="bibr" target="#b27">(Kristan et al, 2015)</ref> while running close to real-time on a single CPU. The spatial and channel reliability formulation is general and can be used in most modern correlation filters, e.g. those using deep features.</p><p>The remainder of the paper is structured as follows. In Section 2 we review most closely related work, our approach is described in Section 3, experimental results are presented in Section 4 and conclusions are drawn in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>The discriminative correlation filters for object detection date back to the 80's with seminal work of <ref type="bibr" target="#b21">Hester and Casasent (1980</ref>  <ref type="bibr" target="#b49">(Wu et al, 2013</ref>) at a remarkable processing speed. Significant improvements have been made since and in 2014 the top-performing trackers on a recent benchmark <ref type="bibr" target="#b26">(Kristan et al, 2014)</ref> were all from this class of trackers. DCF improvements fall into two categories, introduction of new features and conceptual improvements in filter learning. In the first group, <ref type="bibr" target="#b20">Henriques et al (2015)</ref> replaced the grayscale templates by HoG <ref type="bibr" target="#b6">(Dalal and Triggs, 2005)</ref>, <ref type="bibr" target="#b8">Danelljan et al (2014b)</ref> proposed multi-dimensional color attributes and <ref type="bibr" target="#b32">Li and Zhu (2014b)</ref> applied feature combination. Recently, convolutional network features learned for object detection have been applied <ref type="bibr" target="#b38">(Ma et al, 2015;</ref><ref type="bibr" target="#b10">Danelljan et al, 2015b</ref><ref type="bibr" target="#b11">Danelljan et al, , 2016</ref>, leading to a performance boost, but at a cost of significant speed reduction.</p><p>Conceptually, the first successful theoretical extension of the standard DCF was the kernelized formulation by <ref type="bibr" target="#b20">Henriques et al (2015)</ref> which achieved remarkable tracking performance, but still preserved high speed. Later, a correlation filter based scale adaptation was proposed by <ref type="bibr" target="#b7">Danelljan et al (2014a)</ref> introduced a scale-space pyramid learned within a correlation filter framework. <ref type="bibr" target="#b52">Zhang et al (2014)</ref> introduced spatio-temporal context learning in the DCFs. To improve localization with correlation filters, <ref type="bibr" target="#b1">Bertinetto et al (2016a)</ref> proposed a tracking method that combines the output of the correlation filter with the tar-get segmentation probability map. <ref type="bibr" target="#b11">Danelljan et al (2016)</ref> addressed a multiple-resolution feature map issue in correlation filters by formulating filter learning in continuous space, while <ref type="bibr" target="#b41">Qi et al (2016)</ref> proposed a mechanism to combine correlation responses from multiple convolutional layers. A correlation filter tracker which is able to handle drifts in longer sequences was proposed by <ref type="bibr" target="#b46">Wang et al (2016)</ref>. It clusters similar target appearances together and uses the clusters for target localization instead of a single online learned filter.</p><p>Since most of the correlation filter trackers represent the target with a single filter, it can easily get corrupted when occlusion or a target deformation happen. In general, part-based trackers are better in addressing these issues. Therefore several part-based correlation filter methods were proposed. <ref type="bibr" target="#b36">Liu et al (2015)</ref> use an efficient method to combine correlation outputs of multiple parts and <ref type="bibr" target="#b35">Liu et al (2016)</ref> proposed a tracking method for modeling the target structure with multiple parts using multiple correlation filters. <ref type="bibr" target="#b37">Lukežič et al (2017)</ref> treat the parts correlation filter responses and their constellation constraints jointly as an equivalent spring system. They derive a highly efficient optimization to infer the most probable target deformation.</p><p>Recently, Kiani <ref type="bibr" target="#b24">Galoogahi et al (2015)</ref> addressed the problem that occurs due to learning with circular correlation from small training regions. They proposed a learning framework that artificially increases the filter size by implicitly zero padding the filter. This reduces the boundary artifacts by increasing the number of training examples in constrained filter learning. <ref type="bibr" target="#b9">Danelljan et al (2015a)</ref> reformulate the learning cost function to penalize nonzero filter values outside the object bounding box. Performance better than <ref type="bibr" target="#b24">(Kiani Galoogahi et al, 2015)</ref> is reported, but the learned filter is still a trade-off between the correlation response and regularization, and it does not guarantee that filter values are zero outside of object bounding box.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Spatially constrained correlation filters</head><p>The use of multiple channels in correlation filters <ref type="bibr" target="#b20">(Henriques et al, 2015;</ref><ref type="bibr" target="#b12">Danelljan et al, 2017;</ref><ref type="bibr" target="#b16">Galoogahi et al, 2013)</ref> has become very popular in visual tracking. In the following we present the main ideas behind learning these filters. Given a set of N c channel features f = {f d } d=1:Nc and corresponding target templates (filters) h = {h d } d=1:Nc , the object position is estimated as the location of the maximum of correlation responsẽ g(h),g</p><formula xml:id="formula_0">(h) = Nc d=1 f d h d .<label>(1)</label></formula><p>The symbol represents circular correlation between f d ∈ R cw×c h and h d ∈ R cw×c h , where c w and c h are the training/search region width and height, respectively. The optimal correlation filter h is estimated by minimizing</p><formula xml:id="formula_1">ε(h) = g(h) − g 2 + λ h 2 ,<label>(2)</label></formula><p>where g is the desired output g ∈ R cw×c h , which is typically a 2-D Gaussian function centered at the target location. Efficient tracking performance is achieved by expressing the cost (2) into the Fourier domain</p><formula xml:id="formula_2">ε(h) = Nc d=1 diag(f d )ĥ d −ĝ 2 + λ Nc d=1 ĥ 2 ,<label>(3)</label></formula><p>where the operatorâ = vec(F[a]) is a Fourier transform of a reshaped into a column vector, i.e.,â ∈ R D×1 , with D = c w · c h , diag(â) being a D × D diagonal matrix formed fromâ and (·) is the complex-conjugate operator. The closed-form solution for d-th filter channelĥ d which minimizes the cost function (3) is equal tô</p><formula xml:id="formula_3">h d = diag(f d )ĝ −1 Nc d=1 diag(f d )f d + λ ,<label>(4)</label></formula><p>where −1 is element-wise division. The solution (4) considers all feature channels jointly and is used in most of the recent correlation filter trackers. Note that the final response is obtained as summation over correlation responses of all channels (1) and the location of the maximum in the final response represents the new position of the target. Note that a filter for the d-th channel is computed in (4) by dividing d-th feature with the sum over all feature channels. This means that the feature scale crucially impacts the level by which a channel contributes to the final response, irrespective of its discriminative power. Since features (e.g., HoG, colornames and grayscale template) vary in scale, some channels might suppress the others by an order of magnitude. This is demonstrated in <ref type="figure" target="#fig_1">Figure 3</ref> where each HoG channel on its own contributes to the final response very little.</p><p>To avoid the issue with different scales we consider each channel independently. This means that each filter channel is optimized to fit the desired output separately. The cost function is thus defined as</p><formula xml:id="formula_4">ε(h) = Nc d=1 f d h d − g 2 + λ h d 2 .<label>(5)</label></formula><p>Additionally, we introduce channel weights w = {w d } d=1:Nc which can be considered as scaling factors based on the discriminative power of each feature channel. These weights are called channel reliability weights in the rest of the paper and they are applied when correlation response is calculated in the target localization stage:</p><formula xml:id="formula_5">g = Nc d=1 f d h d ·w d .<label>(6)</label></formula><p>We present our method for constrained correlation filter learning in Section 3.1. The most reliable parts of the filter are identified by introducing the spatial reliability map (Section 3.2). The method for channel reliability w d estimation is presented in Section 3.3, the proposed tracker is described in Section 3.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Constrained correlation filter learning</head><p>Since filter learning is independent across the channels in our formulation (5), we assume only a single channel in the following derivation (i.e., N c = 1) and drop the channel index for clarity.</p><p>Let m ∈ {0, 1} be a spatial reliability map with elements either zero or one, that identifies pixels which should be set to zero in the learned filter. The constraint can be formalized as h ≡ m h, where represents the Hadamard (element-wise) product. Such constraint does not lead to a closed-form solution, but an iterative approach akin to <ref type="bibr" target="#b24">Kiani Galoogahi et al (2015)</ref> can be derived for efficiently solving the optimization problem. In the following we summarize the main steps of our approach and report the full derivation in Appendix 6.</p><p>We start by introducing a dual variable h c and the constraint h c − m h ≡ 0,</p><p>which leads to the following augmented Lagrangian <ref type="bibr" target="#b4">(Boyd et al, 2011</ref>)</p><formula xml:id="formula_7">L(ĥ c , h,l|m) = diag(f )ĥ c −ĝ 2 + λ 2 h m 2 + (8) [l H (ĥ c −ĥ m ) +l H (ĥ c −ĥ m )] + µ ĥ c −ĥ m 2 ,</formula><p>wherel is a complex Lagrange multiplier, µ &gt; 0, and we use the definition h m = (m h) for compact notation. The augmented Lagrangian (8) can be iteratively minimized by the alternating direction method of multipliers, e.g. <ref type="bibr" target="#b4">Boyd et al (2011)</ref>, which sequentially solves the following sub-problems at each iteration:</p><formula xml:id="formula_8">h i+1 c = arg min hc L(ĥ c , h i ,l i |m),<label>(9)</label></formula><formula xml:id="formula_9">h i+1 = arg min h L(ĥ i+1 c , h,l i |m),<label>(10)</label></formula><p>and the Lagrange multiplier is updated aŝ</p><formula xml:id="formula_10">l i+1 =l i + µ(ĥ i+1 c −ĥ i+1 ).<label>(11)</label></formula><p>Minimizations in (9,10) have at each iteration a closedform solution, i.e.,</p><formula xml:id="formula_11">h i+1 c = f ĝ + (µĥ i m −l i ) −1 f f + µ i , (12) h i+1 = m F −1 l i + µ iĥi+1 c / λ 2D + µ i .<label>(13)</label></formula><p>A standard scheme for updating the constraint penalty µ values <ref type="bibr" target="#b4">(Boyd et al, 2011)</ref> is applied, i.e., µ i+1 = βµ i . Computations of (12,11) are fully carried out in the frequency domain, the solution for (13) requires a single inverse FFT and another FFT to compute theĥ i+1 . A single optimization iteration thus requires only two calls of the Fourier transform, resulting in a very fast optimization. The computational complexity is that of the Fourier transform, i.e., O(D log D). Filter learning is implemented in less than five lines of Matlab code and is summarized in the Algorithm 1.</p><p>Algorithm 1 : Constrained filter optimization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Require:</head><p>Features extracted from training region f , ideal correlation response g, binary mask m.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ensure:</head><p>Optimized filter h. Procedure:</p><p>1: Initialize filter h 0 by h t−1 . 2: Initialize Lagrangian coefficients: l 0 ← zeros. 3: while stop condition do 4:</p><p>Calculateĥ i+1 c fromĥ i andl i using (12).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5:</head><p>Calculate h i+1 fromĥ i+1 c andl i using (13).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6:</head><p>Update the Lagrangianl i+1 fromĥ i+1 c and h i+1 (11). 7: end while</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Constructing spatial reliability map</head><p>Once the target is localized, a training region is extracted and used to update the filter. Our constrained filter learning (13) requires estimation of spatial reliability map m (i.e., segmentation) that identifies pixels in the training region which likely belong to the target (see <ref type="figure" target="#fig_3">Figure 4</ref>). In the following we briefly outline the segmentation model which is used to estimate m.</p><p>During tracking, the object foreground/background color models are maintained as color histograms  probability of observing y i is defined as</p><formula xml:id="formula_12">c = {c f , c b }. Let y i = [y c i , y x i ] be</formula><formula xml:id="formula_13">p(y i ) = 1 j=0 p(y i |m i = j)p(m i = j) = (14) = 1 j=0 p(y c i |m i = j)p(y x i |m i = j)p(m i = j),</formula><p>where p(y c i |m i = j), p(y x i |m i = j) and p(m i = j) are the appearance likelihood, the spatial likelihood and the foreground/background prior probability. The appearance likelihood term p(y c i |m i = j) is computed by Bayes rule from the object foreground/background color models c f and c b . The prior probability p(m i = j) is defined by the ratio between the region sizes for foreground/background histogram extraction.</p><p>The central pixels in axis-aligned approximations of an elongated rotating, articulated or deformable object are likely to contain the object regardless of the specific deformation. On the other hand, in the absence of measurements, pixels away from the center belong to the object or background equally likely. This deformation invariance of central elements reliability is enforced in our approach by defining a weak spatial prior</p><formula xml:id="formula_14">p(y x i |m i = j) = k(x; σ),<label>(15)</label></formula><p>where k(x; σ) is a modified Epanechnikov kernel, k(r; σ) = 1 − (r/σ) 2 , with size parameter σ equal to the minor bounding box axis and clipped to interval [0.5, 0.9] such that the object prior probability at center is 0.9 and changes to a uniform prior away from the center <ref type="figure" target="#fig_3">(Figure 4)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Inference</head><p>In practice the likelihood p(y i |m i ) is noisy and requires regularization for our filter learning. We thus apply a MRF from <ref type="bibr" target="#b14">(Diplaros et al, 2007;</ref><ref type="bibr" target="#b28">Kristan et al, 2016a)</ref>, which treats the prior and posterior label distributions over pixels as random variables and applies a MRF constraint over these. This formulation affords an efficient inference which avoids hard label assignment during optimization and can be implemented as a series of convolutions.</p><p>The prior over the i-th pixel is defined compactly as π i = [π i0 , π i1 ] with π ij = p(m i = j) and a standard approximation is made <ref type="bibr" target="#b14">(Diplaros et al, 2007)</ref> that decomposes the joint pdf over priors π = [π 1 , ..., π M ] into a product of local conditional distributions p(π) = M i=1 p(π i |π Ni ), where M is number of pixels, π Ni is a mixture distribution over the priors of i-th pixel's neighbors, i.e., π Ni = j∈Ni,j =i λ ij π j and λ ij are fixed weights satisfying j λ ij = 1. In <ref type="bibr" target="#b14">Diplaros et al (2007)</ref> the weights are fixed to a normalized Gaussian and are shared across all pixel locations. The potentials in the MRF are defined as</p><formula xml:id="formula_15">p(π i |π Ni ) ∝ exp − 1 2 E(π i , π Ni ) ,with exponent defined as E(π i , π Ni ) = D(π i ||π Ni ) + H(π i ).The term D(π i ||π Ni )</formula><p>is the Kullback-Leibler divergence which penalizes the difference between prior distributions over the neighboring pixels (π i and π Ni ), while the term H(π i ) is the entropy defined as H(π i ) = − 1 j=0 π ij log π ij ,which penalizes uninformative priors π i .</p><p>For smooth solutions <ref type="bibr" target="#b14">Diplaros et al (2007)</ref> propose us-ing a similar constraint over the posteriors p i = [p i0 , p i1 ] with p ij being the posterior probability of class j at i-th pixel, leading to the following energy function</p><formula xml:id="formula_16">F = M i=1 log p(y i ) − 1 2 E(π i , π Ni ) + E(p i , p Ni ) .</formula><p>(16) Minimization of the energy (16) w.r.t. π and p is efficiently solved by the solver from <ref type="bibr" target="#b14">Diplaros et al (2007)</ref>. The final mask m for learning the filter in Section 3.1 is obtained by thresholding the posterior at 0.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Channel reliability estimation</head><p>Channel reliabilityw d in (6) reflects the importance of each channel at the target localization stage. In our approach it consists of two types of reliability measures: (i) channel learning reliabilityw</p><formula xml:id="formula_17">(lrn) d</formula><p>, which is calculated in the filter learning stage, and (ii) channel detection reliabilityw</p><formula xml:id="formula_18">(det) d</formula><p>which is calculated in the target localization stage. The joint channel reliabilityw d in (6) at target localization stage is computed as the product of both reliability measures, i.e.,</p><formula xml:id="formula_19">w d =w (lrn) d ·w (det) d<label>(17)</label></formula><p>and normalized s.t. dw d = 1. The reliability measures are described in following paragraphs.</p><p>Channel learning reliability. Constrained minimization of (8) solves a least squares problem averaged over all circular displacements of the filter on a feature channel. A discriminative feature channel f d produces a filter h d whose output f d * h d nearly exactly fits the ideal response g. On the other hand, since the response is highly noisy on channels with low discriminative power, a global error reduction in the least squares significantly reduces the maximal response. This effect is demonstrated in <ref type="figure">Figure 5</ref>, which shows correlation responses for a highly discriminative and non-discriminative channels. Thus a straightforward measure of channel learning reliabilityw (lrn) d is the maximum response value of a learned channel filter, which is computed as  <ref type="figure">Figure 5</ref>: A filter is learned on feature channels from a training region using the constrained optimization with a binary segmentation mask m. Correlation responses between the learned filter and the training region for two feature channels are shown on the right. On a discriminative feature channel the filter response is much stronger and less noisy than on a non-discriminative channel.</p><formula xml:id="formula_20">w (lrn) d = max(f d * h d ).<label>(18)</label></formula><p>Channel detection reliability. The second part of the channel reliability reflects how uniquely each channel votes for a single target location. Note that <ref type="bibr" target="#b3">Bolme et al (2010)</ref> proposed a similar approach to detect loss of target. Our measure is based on the ratio between the second and first highest non-adjacent peaks in the channel response map, i.e., 1 − ρ max2</p><formula xml:id="formula_21">d /ρ max1 d .</formula><p>The two largest peaks in the response map are obtained as two largest values after a 3×3 non-maximum suppression. Note that this ratio penalizes situations in which multiple similar objects appear in the target vicinity (i.e., response map contains many well expressed modes), even if the major mode accurately depicts the target position. To mitigate such penalizations, the final values are note allowed to fall below 0.5. The detection reliability of d-th channel is estimated asw</p><formula xml:id="formula_22">(det) d = max(1 − ρ max2 d /ρ max1 d , 0.5).<label>(19)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Tracking with channel and spatial reliability</head><p>A single tracking iteration of the proposed channel and spatial reliability correlation filter tracker (CSR-DCF) is summarized in Algorithm 2 and visualized in <ref type="figure">Figure 6</ref>. The localization and update steps proceed as follows. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Update step</head><p>New target location <ref type="figure">Figure 6</ref>: The CSR-DCF tracking iteration: localization step is shown on the left and update step on the right side of the image.</p><p>Localization step. Features are extracted from a search region centered at the target estimated position in the previous time-step and correlated with the learned filter h t−1 . The object is localized by summing the correlation responses weighted by the estimated channel reliability scores w t−1 . The scale is estimated by a single scale-space correlation filter as in <ref type="bibr" target="#b7">Danelljan et al (2014a)</ref>. Per-channel filter responses are used to compute the corresponding detection reliability valuesw <ref type="bibr">(det)</ref> </p><formula xml:id="formula_23">= [w (det) 1 , . . . ,w (det)</formula><p>Nc ] T according to <ref type="bibr">(19)</ref>. Update step. The training region is centered at the target location estimated at localization step. The foreground and background histogramsc are extracted and updated by exponential moving average with learning rate η c (step 5 in Algorithm 2). The foreground histogram is extracted by an Epanechnikov kernel within the estimated object bounding box and the background is extracted from the neighborhood twice the object size. The spatial reliability map m (Sect. 3.2) is constructed and the optimal filtersh are computed by optimizing (8). The per-channel learning reliability weightsw <ref type="bibr">(lrn)</ref> </p><formula xml:id="formula_24">= [w (lrn) 1 , . . . ,w (lrn)</formula><p>Nc ] T are estimated from the correlation responses (18). Current frame reliability weightsw are computed from detection and learning reliability <ref type="formula" target="#formula_0">(17)</ref>. The filters and channel reliability weights are updated by exponential moving average (current and from previous frame) with learning rate η (steps 10 and 11 in the Algorithm 2). Note that we compute the spatial reliability map in each frame independently to capture large target appearance changes, e.g. caused by rotation or deformation. <ref type="bibr" target="#b24">Kiani Galoogahi et al (2015)</ref> and <ref type="bibr" target="#b9">Danelljan et al (2015a)</ref> have previously considered constrained filter learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Comparison with prior work</head><p>Here we highlight the differences of our approach.</p><p>The LBCF tracker <ref type="bibr" target="#b24">(Kiani Galoogahi et al, 2015)</ref> addresses the circular boundary effect of the Fourier transform and implicitly increases the filter search region size. In contrast, the CSR-DCF primarily reduces the impact of the background in the filter. The solution of Kiani <ref type="bibr" target="#b24">Galoogahi et al (2015)</ref> is similar to our filter optimization, but it is derived for a rectangular mask only. Since rotating and deformable targets are poorly approximated by an axis-aligned bounding box their filter is contaminated by background leading to a reduced performance. The LBCF updates the auto-spectral and cross-spectral ener-Algorithm 2 : The CSR-DCF tracking algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Require:</head><p>Image I t , object position on previous frame p t−1 , scale s t−1 , filter h t−1 , color histograms c t−1 , channel reliability w t−1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ensure:</head><p>Position p t , scale s t and updated models. Localization and scale estimation:</p><p>1: New target location p t : position of the maximum in correlation between h t−1 and image patch features f extracted on position p t−1 and weighted by the channel reliability scores w (Sect.  gies (f f andf ĝ in <ref type="formula" target="#formula_0">(12)</ref>) separately, which approximates computation of a single filter from a weighted sum of errors over past training samples. This adaptation is reasonable since it is derived for a rectangular mask that remains constant throughout tracking. The CSR-DCF estimates the mask separately for each training sample and learns a corresponding filter. For articulated objects in particular the mask varies significantly with time, therefore it is beneficial to compute the exact filter for each frame. Robustness is increased by moderately averaging the filters temporally.</p><formula xml:id="formula_25">c f t = (1 − η c )c f t−1 + η cc f , c b t = (1 − η c )c b t−1 + η cc b<label>.</label></formula><p>Similarly to our approach, the SRDCF (Danelljan et al, 2015a) uses a spatial map in filter learning. In contrast to our approach, their map does not adapt to the target and is required to be highly smooth for their optimization to converge. In CSR-DCF the map serves as a hard constraint resulting in a filter with values off the target set to zero. In contrast, the SRDCF <ref type="bibr" target="#b9">(Danelljan et al, 2015a)</ref> filter is a compromise between target position regression and a penalty term that prefers potentially non-zero values in the filter center and close-to-zero values away from the center, but does not guarantee zero values outside the mask.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental analysis</head><p>This section presents a comprehensive experimental evaluation of the CSR-DCF tracker. Implementation details are discussed in Section 4.1, convergence of the filter optimization method is presented in Section 4.2, Section 4.3 reports comparison of the proposed constrained learning to the related state-of-the-art and the ablation study is provided in Section 4.4. Tracking performance on three recent benchmarks: OTB-100 <ref type="bibr" target="#b50">(Wu et al, 2015)</ref>, VOT2015 <ref type="bibr" target="#b27">(Kristan et al, 2015)</ref> and VOT2016 <ref type="bibr">(Kristan et al, 2016b)</ref> is reported in Sections 4.6, 4.7 and 4.8, respectively. The detailed analysis of the tracker, including per-attribute tracking performance is presented in Section 4.9 and tracking speed analysis in Section 4.10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Implementation details and parameters</head><p>A popular implementation <ref type="bibr" target="#b15">Felzenszwalb et al (2010)</ref> of the standard HoG <ref type="bibr" target="#b6">(Dalal and Triggs, 2005)</ref> and Colornames <ref type="bibr" target="#b48">(van de Weijer et al, 2009)</ref> features are used in the correlation filter and HSV foreground/background color histograms with 16 bins per color channel are used in reliability map estimation with parameter α min = 0.05. All the parameters are set to values commonly used in literature <ref type="bibr" target="#b9">(Danelljan et al, 2015a;</ref><ref type="bibr" target="#b24">Kiani Galoogahi et al, 2015)</ref>. Histogram adaptation rate is set to η c = 0.04, correlation filter adaptation rate is set to η = 0.02, and the regularization parameter is set to λ = 0.01. The augmented Lagrangian optimization parameters are set to µ 0 = 5 and β = 3. All parameters have a straight-forward interpretation, do not require fine-tuning, and were kept constant throughout all experiments. Our Matlab implementation 1 runs at 13 frames per second on an Intel Core i7 3.4GHz standard desktop.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Convergence of constrained learning</head><p>The constrained filter learning described in Section 3.1 is an iterative optimization method that minimizes the cost function <ref type="formula" target="#formula_39">(8)</ref>. This experiment demonstrates how the cost changes with the number of iterations during filter optimization. <ref type="figure" target="#fig_4">Figure 7</ref> shows the average squared difference between the result of the correlation of the filter constrained by the spatially constrained function and the ideal output. This graph was obtained by averaging 60 examples of initializing a filter on a target (one per VOT2015 sequence) and scaling each to an interval between zero and one. It is clear that the error drops by 80% within the first few iterations. Already after four iterations, the performance improvements become negligible, therefore we set number of iterations to N = 4. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Impact of the boundary constraint formulation</head><p>This section compares our proposed boundary constraints formulation (Sect. 3) with recent state-of-the-art approaches <ref type="bibr" target="#b9">(Danelljan et al, 2015a;</ref><ref type="bibr" target="#b24">Kiani Galoogahi et al, 2015)</ref>. In the first experiment, three variants of the standard single-scale HoG-based correlation filter were im-plemented to emphasize the difference in boundary constraints: the first uses our spatial reliability boundary constraint formulation from Section 3 (T SC ) the second applies the spatial regularization constraint <ref type="bibr" target="#b9">(Danelljan et al, 2015a</ref>) (T SR ) and the third applies the limited boundaries constraint (Kiani Galoogahi et al, 2015) (T LB ). The three variants were compared on the challenging VOT2015 dataset <ref type="bibr" target="#b27">(Kristan et al, 2015)</ref> by applying a standard no-reset one-pass evaluation from OTB <ref type="bibr" target="#b49">(Wu et al, 2013)</ref> and computing the AUC on the success plot. The tracker with our constraint formulation T SC achieved 0.32 AUC, while the alternatives achieved 0.28 (T SR ) and 0.16 (T LB ). The only difference between these tackers is in the constraint formulation, which indicates superiority of the proposed spatial-reliability-based constraints formulation over the recent alternatives (Kiani <ref type="bibr" target="#b24">Galoogahi et al, 2015;</ref><ref type="bibr" target="#b9">Danelljan et al, 2015a)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Robustness to non-axis-aligned target initialization</head><p>The CSR-DCF tracker from Section 3 was compared to the original recent state-of-the-art trackers SRDCF <ref type="bibr" target="#b9">(Danelljan et al, 2015a)</ref> and LBCF (Kiani <ref type="bibr" target="#b24">Galoogahi et al, 2015)</ref> that apply alternative boundary constraints. For fair comparison, the source code of SRDCF and LBCF was obtained from the authors, all three trackers used only HoG features and tracked on the same single scale. An experiment was designed to evaluate initialization and tracking of non axis-aligned targets, which is the case for most realistic deforming and non-circular objects. Trackers were initialized on frames with non-axis aligned targets and left to track until the sequence end, resulting in a large number of tracking trajectories. The VOT2015 dataset <ref type="bibr" target="#b27">(Kristan et al, 2015)</ref> contains non-axis-aligned annotations, which allows automatic identification of tracker initialization frames, i.e., frames in which the ground truth bounding box significantly deviates from an axis-aligned approximation. Frames with overlap (intersection over union of predicted and groundtruth bounding boxes) of the ground truth and the axisaligned approximation lower than 0.5 were identified and filtered to obtain a set of initialization frames at least hundred frames apart. This constraint fits half the typical short-term sequence length <ref type="bibr" target="#b27">(Kristan et al, 2015)</ref> and reduces the potential correlation across the initializations  <ref type="table">Table 1</ref>: Comparison of three most related trackers on non-axis-aligned initialization experiment: weighted average tracking length in frames Γ frm and proportions Γ prp , and weighted average overlaps using the original and axis-aligned ground truth, Φ rot and Φ aa , respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Tracker</head><p>Γ prp Γ frm Φ aa Φ rot CSR-DCF 1 0.58 1 221 1 0.31 1 0.24 SRDCF (ICCV2015) 2 0.31 2 95 2 0.16 2 0.12 LBCF (CVPR2015) 3 0.12 3 37 3 0.06 3 0.04 (see <ref type="figure" target="#fig_5">Figure 8</ref> (bottom) for examples). Initialization robustness is estimated by counting the number of trajectories in which the tracker was still tracking (overlap with ground truth greater than 0) Θ frm frames after initialization. The graph in <ref type="figure" target="#fig_5">Figure 8</ref> (top-left) shows these values with increasing the threshold Θ frm . The CSR-DCF graph is consistently above the SRDCF and LBCF for all thresholds. The performance is summarized by the average tracking length (number of frames before the overlap drops to zero) weighted by trajectory lengths. The weighted average tracking lengths in frames, Γ frm , and proportions of full trajectory lengths, Γ prp , are shown in <ref type="table">Table 1</ref>. The CSR-DCF by far outperforms SRDCF and LBCF in all measures indicating significant robustness in the initialization of challenging targets that deviate from axis-aligned templates. This improvement is further confirmed by the graph in <ref type="figure" target="#fig_5">Figure 8</ref> (top-right) which shows the OTB success plots <ref type="bibr" target="#b49">(Wu et al, 2013</ref>) calculated on these trajectories and summarized by the AUC values, which are equal to the average overlaps <ref type="bibr">(Čehovin et al, 2016)</ref>. <ref type="table">Table 1</ref> shows the average overlaps computed on the original ground truth on VOT2015 (Φ rot ) and on ground truth approximated by the axis-aligned bounding box (Φ aa ). Again, the CSR-DCF by far outperforms the competing alternatives SRDCF and LBCF. Tracking examples for the three trackers are shown in <ref type="figure" target="#fig_6">Figure 9</ref>.</p><p>In summary, the results show that the quality of spatial constraints significantly affects the relative tracking performance when a large portion of the training region in the target vicinity is occupied by background. The relative performance of LBCF <ref type="bibr" target="#b24">(Kiani Galoogahi et al, 2015)</ref> is lowest among the three trackers since this tracker treats all pixels within axis-aligned bounding box equally as target. The SRDCF <ref type="bibr" target="#b9">(Danelljan et al, 2015a)</ref> mostly focuses on the central pixels of the training region and suppresses the filter values at the borders, thus outperforming the LBCF (Kiani <ref type="bibr" target="#b24">Galoogahi et al, 2015)</ref>. The spatial reliability map in CSR-DCF most successfully reduces the in-fluence of background in filter learning resulting in considerable robustness to poor initializations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Spatial and channel reliability ablation study</head><p>An ablation study on VOT2016 was conducted to evaluate the contribution of spatial and channel reliability in CSR-DCF. Results of the VOT primary measure expected average overlap (EAO) and two supplementary measures accuracy and robustness (A,R) are summarized in <ref type="table" target="#tab_5">Table 2</ref>. For the details of performance measures and evaluation protocol we refer the reader to the Section 4.7. Performance of the various modifications of CSR-DCF is discussed in the following. Channel reliability weights. Setting the channel reliability weights to uniform values (CSR-DCF c − ) is equivalent to treating all channels as independent and equally important. The performance drop in EAO compared to CSR-DCF is 12%. Spatial reliability map. Replacing the spatial reliability map in CSR-CDF by a constant map with uniform values within the bounding box and zeros elsewhere (CSR-DCF s u ), results in a 21% drop in EAO. The other parts of the tracker remained unchanged in this experiment, including the channel reliability. This clearly shows the importance of our segmentation-based spatial reliability map estimation from Section 3.2. Channel and spatial reliability. Making both replacements in the original tracker means that this version (CSR-DCF c − s u ) does not use channel reliability weights and it uses uniform spatial reliability map (uniform values within the bounding box and zeros elsewhere). The performance drops by 24% compared to CSR-DCF. Removal of the uniform spatial reliability map from CSR-DCF c − s u results in the CSR-DCF c − s − . This version reduces our tracker to a standard DCF with a large receptive field. Since the learned filter captures a significant amount of background, the performance drops by over 50%. ADMM Filter optimization method. To demonstrate the importance of the constrained optimization method we modify the proposed tracker as follows. The filter h is calculated with a naive approach, i.e., a closed-form solution followed by masking with the spatial reliability map m: h = F(F −1 (ĥ) m). For a fair comparison the tracker, </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Spatial reliability map quality analysis</head><p>In this section we evaluate the quality of our spatial reliability map estimation (Section 3.2) from a visual tracking perspective. We compare the CSR-DCF tracker with the version of CSR-DCF that uses ideal spatial reliability map (the tracker is denoted as CSR*-DCF). In the VOT2016 challenge <ref type="bibr">(Kristan et al, 2016b)</ref>, the ground truth bounding boxes were automatically computed by optimizing coverage over manually segmented targets in each frame. The VOT2016 has recently made their perframe segmentations freely available <ref type="bibr" target="#b43">(Vojir and Matas, 2017)</ref>. We use these per-frame segmentation masks in CSR*-DCF as spatial reliability map m. Results of evaluation on VOT2016 <ref type="bibr">(Kristan et al, 2016b)</ref> are reported in <ref type="table" target="#tab_6">Table 3</ref>. The performances of the CSR-DCF and CSR*-DCF are very similar. The trackers achieve an equal expected average overlap (EAO) and average accuracy (A av ). But the CSR*-DCF has a single failure less than CSR-DCF on 60 sequences which is 0.02 on average. In <ref type="table" target="#tab_6">Table 3</ref> the average number of failures is denoted as robustness (R av ). These results show that our approach for spatial reliability estimation (Section 3.2) generates near ideal maps from a tracking perspective. <ref type="figure">Figure 10</ref> qualitatively compares the spatial reliabil-  <ref type="figure">Figure 10</ref>: Qualitative comparison of the spatial reliability maps during tracking. The dashed bounding box represents area from which correlation filter is obtained. This is also the area where spatial reliability map is calculated. In addition, the ground-truth segmentation masks are visualized on the right side under each frame.</p><p>ity maps to the ground-truth segmentation masks on VOT2016 <ref type="bibr">(Kristan et al, 2016b)</ref>. Note that at pixel level, the maps are different. But from the perspective of tracking they are nearly equivalent since the tracking performance remains unchanged. For example, in the case of a basketball player, the legs are not well segmented by our approach. But since the legs constantly move, they are in fact non-informative for object localization from the perspective of the correlation filter template matching and do not contribute to improved tracking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.6</head><p>The OTB100 benchmark <ref type="bibr" target="#b50">(Wu et al, 2015)</ref> The OTB100 <ref type="bibr" target="#b50">(Wu et al, 2015)</ref> benchmark contains results of 29 trackers evaluated on 100 sequences by a noreset evaluation protocol. Tracking quality is measured by precision and success plots. The success plot shows the fraction of frames with the overlap between th epredicted and ground truth bounding box greater than a threshold with respect to all threshold values. The precision plot shows similar statistics on the center error. The results are summarized by areas under these plots. To reduce clutter, we show here only the results for top-performing recent baselines, i.e., Struck <ref type="bibr" target="#b18">(Hare et al, 2011)</ref>, TLD <ref type="bibr" target="#b23">(Kalal et al, 2012)</ref>, CXT <ref type="bibr" target="#b13">(Dinh et al, 2011)</ref>, ASLA (Xu Jia, 2012), SCM (Wei Zhong, 2012), LSK <ref type="bibr" target="#b34">(Liu et al, 2011)</ref>, CSK <ref type="bibr" target="#b19">(Henriques et al, 2012)</ref> and results for recent topperforming state-of-the-art trackers SRDCF <ref type="bibr" target="#b9">(Danelljan et al, 2015a)</ref> and MUSTER <ref type="bibr" target="#b22">(Hong et al, 2015)</ref>. The CSR-DCF is ranked top on the benchmark <ref type="figure">(Fig. 11)</ref>. It significantly outperforms the best performers reported in <ref type="bibr" target="#b50">(Wu et al, 2015)</ref> and outperforms the current state-of-the-art SRDCF <ref type="bibr" target="#b9">(Danelljan et al, 2015a)</ref> and MUSTER <ref type="bibr" target="#b22">(Hong et al, 2015)</ref>. The average CSR-DCF performance on success plot is slightly lower than SRDCF <ref type="bibr" target="#b9">(Danelljan et al, 2015a)</ref> due to poorer scale estimation, but yields better performance in the average precision (center error). Both, precision and success plot, show that the CSR-DCF tracks on average longer than competing methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.7</head><p>The VOT2015 benchmark <ref type="bibr" target="#b27">(Kristan et al, 2015)</ref> The VOT2015 <ref type="bibr" target="#b27">(Kristan et al, 2015)</ref> benchmark contains results of 63 state-of-the-art trackers evaluated on 60 chal-  <ref type="figure">Figure 11</ref>: Evaluation on OTB100 <ref type="bibr" target="#b50">(Wu et al, 2015)</ref> benchmark.</p><p>lenging sequences. In contrast to related benchmarks, the VOT2015 dataset was constructed from over 300 sequences by an advanced sequence selection methodology that favors objects difficult to track and maximizes a visual attribute diversity cost function <ref type="bibr" target="#b27">(Kristan et al, 2015)</ref>. This makes it arguably the most challenging sequence set available. The VOT methodology <ref type="bibr" target="#b30">(Kristan et al, 2016c)</ref> resets a tracker upon failure to fully use the dataset. The basic VOT measures are the number of failures during tracking (robustness) and average overlap during the periods of successful tracking (accuracy), while the primary VOT2015 measure is the expected average overlap (EAO) on short-term sequences. The latter can be thought of as the expected no-reset average overlap (AUC in OTB methodology), but with reduced bias and the variance as explained in <ref type="bibr" target="#b27">(Kristan et al, 2015)</ref>. <ref type="figure" target="#fig_7">Figure 12</ref> shows the VOT EAO plots with the CSR-DCF and the VOT2015 state-of-the-art approaches considering the VOT2016 rules that do not consider trackers learned on video sequences related to VOT to prevent over-fitting. The CSR-DCF outperforms all trackers and achieves the top rank. The CSR-DCF significantly outperforms the related correlation filter trackers like SRDCF <ref type="bibr" target="#b9">(Danelljan et al, 2015a)</ref> as well as trackers that apply computationally-intesive state-of-the-art deep features e.g., deepSRDCF <ref type="bibr" target="#b10">(Danelljan et al, 2015b</ref>) and SO-DLT <ref type="bibr" target="#b45">(Wang et al, 2015b)</ref>. For completeness, detailed results for the ten top-performing trackers are shown in <ref type="table" target="#tab_8">Table 4</ref>.  Finally, we assess our tracker on the most recent visual tracking benchmark, VOT2016 <ref type="bibr">(Kristan et al, 2016b)</ref>. The dataset contains 60 sequences from VOT2015 (Kris-   <ref type="bibr">(Kristan et al, 2016b;</ref><ref type="bibr" target="#b40">Nam and Han, 2016)</ref>, MLDF <ref type="bibr">(Kristan et al, 2016b;</ref><ref type="bibr" target="#b44">Wang et al, 2015a)</ref>, FastSiamnet <ref type="bibr" target="#b2">(Bertinetto et al, 2016b)</ref> and different detection-based approaches: EBT <ref type="bibr" target="#b53">(Zhu et al, 2016)</ref> and SRBT <ref type="bibr">(Kristan et al, 2016b)</ref>. <ref type="figure" target="#fig_1">Figure 13</ref> shows the EAO performance on the VOT2016. The CSR-DCF outperforms all 70 trackers with the EAO score equal to 0.338. The CSR-DCF significantly outperforms correlation filter approaches that do not apply deep ConvNets. Even though the CSR-DCF applies only simple features, it outperforms all trackers that apply computationally intensive deep features. Detailed performance scores for the ten top-performing trackers are shown in <ref type="table" target="#tab_9">Table 5</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.9">Per-attribute analysis</head><p>The VOT2016 <ref type="bibr">(Kristan et al, 2016b)</ref> dataset is per-frame annotated with visual attributes and allows detailed analysis of per-attribute tracking performance. <ref type="figure" target="#fig_3">Figure 14</ref> shows per-attribute plot for ten top-performing trackers on VOT2016 in EAO. The CSR-DCF is consistently ranked among top three trackers on five out of six attributes. In four attributes (size change, occlusion, camera motion, unassigned) the tracker is ranked top. The only attribute on which our CSR-DCF is outperformed by four of the compared trackers (MLDF, CCOT, SSAT and TCNN) is illumination change. All of these trackers use deep CNN features which are much more complex than the features in CSR-DCF and better handle illumination change.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.10">Tracking speed analysis</head><p>Tracking speed is an important factor of many real-world tracking problems. <ref type="table" target="#tab_11">Table 6</ref> thus compares several related and well-known trackers (including the best-performing tracker on the VOT2016 challenge) in terms of speed and VOT performance measures. Speed measurements on a single CPU are computed on Intel Core i7 3.4GHz standard desktop.</p><p>The CSR-DCF performs on par with the VOT2016 best-performing CCOT <ref type="bibr" target="#b11">(Danelljan et al, 2016)</ref>, which   The average speed of our tracker measured on the VOT 2016 dataset is approximately 13 frames-per-second 2 or 77 milliseconds per-frame. <ref type="figure" target="#fig_10">Figure 15</ref> shows the processing time required by each step of the CSR-DCF. A tracking iteration is divided into two steps: (i) target localization and (ii) the visual model update. Target localization takes in average 35 milliseconds at each frame and is composed of two sub-steps: estimation of object translation (23ms) and scale change estimation (12ms). The visual model update step takes on average 42 milliseconds. It consists of three sub-steps: spatial reliability map estimation (16ms), filter update (12ms) and scale model update (14ms). Filter optimization, which is part of the filter update step, takes on average 7 milliseconds. <ref type="figure" target="#fig_14">Figure 16</ref> shows four examples of tracking with the CSR-DCF. In the following we describe tracking performance on each sequence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.11">Qualitative evaluation</head><p>The first example shows tracking of an octopus along with channel reliability weights. The first eighteen weights correspond to HoG channels, the 19th weight is reliability of a grayscale template and the last ten weights correspond to colornames. Note that the colors in boxes are not the actual colors of the colornames, because these features are subspace of original colornames, designed to improve correlation filter tracking (see <ref type="bibr" target="#b8">(Danelljan et al, 2014b)</ref>). Observe that when the octopus changes shape significantly, some channels become more discriminative than the others -this is particularly evident in the first eighteen channels that represent the HoG features. Tracking a gymnast is shown in the second example. The target is deforming and rotating over the sequence significantly, while our tracker is able to successfully track it. Additionally, the correlation response from the localization step is shown for each frame. The peak in the response is well expressed, which means that the filter accurately represents the target and that the discriminative channels overrule the less discriminative ones by our channel reliability estimation approach.</p><p>The third example shows tracking a sprinter. The spatial reliability map is visualized next to each frame. In the bottom-right corner of each frame the tracking patch is overlaid with the spatial reliability map. The reliability maps fit the target well and prevent the filter from learning the background.</p><p>The last example shows tracking under occlusion, i.e., a motorcyclist driving on the road while being repeatedly occluded by the trees. This example demonstrates that our tracker is robust to short-term full occlusions and that it is able to recover and localize the target despite the full occlusion. This is possible due to the robust learning with channel and spatial reliability map and the large capture range that our learning scheme provides.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>The Discriminative Correlation Filter with Channel and Spatial Reliability (CSR-DCF) was introduced. The spatial reliability map adapts the filter support to the part of the object suitable for tracking which overcomes both the problems of circular shift enabling an arbitrary search region size and the limitations related to the rectangular shape assumption. A novel efficient spatial reliability map estimation method was proposed and an efficient optimization procedure was used for learning a correlation filter with the support constrained by the estimated map. The second novelty of CSR-DCF is the channel reliability. The reliability is estimated from the properties of the constrained least-squares solution. The channel reliability scores were used for weighting the per-channel filter responses in localization.</p><p>Experimental comparison with recent related state-ofthe-art boundary-constraints formulations showed significant benefits of using our formulation. The CSR-DCF achieves state-of-the-art performance on standard benchmarks: OTB100 <ref type="bibr" target="#b50">(Wu et al, 2015)</ref>, VOT2015 <ref type="bibr" target="#b27">(Kristan et al, 2015)</ref> and VOT2016 <ref type="bibr">(Kristan et al, 2016b)</ref> while running close to the real-time on a single CPU. Despite using simple features like HoG and Colornames, the CSR-DCF performs on par with trackers that apply computationally complex deep ConvNet, but is significantly faster.</p><p>To the best of our knowledge, the proposed approach is the first of its kind to introduce constrained filter learning with arbitrary spatial reliability map and the use of channel reliabilities. The spatial and channel reliability formulation is general and can be used in most modern correlation filters, e.g. those using deep features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Appendix 1: Derivation of the augmented Lagrangian minimizer</head><p>This section provides a complete derivation of the relations (12, 13) in the Section 3.1. The augmented La-grangian from Equation <ref type="formula" target="#formula_39">(8)</ref> is</p><formula xml:id="formula_26">L(ĥ c , h,l) = diag(f )ĥ c −ĝ 2 + λ 2 h m 2 + (20) [l H (ĥ c −ĥ m ) +l H (ĥ c −ĥ m )] + µ ĥ c −ĥ m 2 ,</formula><p>with h m = (m h). For the purposes of derivation we will rewrite (20) into a fully vectorized form</p><formula xml:id="formula_27">L(ĥ c , h,l) = diag(f )ĥ c −ĝ 2 + λ 2 h m 2 + (21) l H (ĥ c − √ DFMh) +l H (ĥ c − √ DFMh) + µ ĥ c − √ DFMh 2 ,</formula><p>where F denotes D × D orthonormal matrix of Fourier coefficients, such that the Fourier transform is defined aŝ x = F(x) = √ DFx and M = diag(m). For clearer representation we denote the four terms in the summation (21) as</p><formula xml:id="formula_28">L(ĥ c , h,l) = L 1 + L 2 + L 3 + L 4 ,<label>(22)</label></formula><p>where</p><formula xml:id="formula_29">L 1 = diag(f )ĥ c −ĝ T diag(f )ĥ c −ĝ ,<label>(23)</label></formula><formula xml:id="formula_30">L 2 = λ 2 h m 2 ,<label>(24)</label></formula><formula xml:id="formula_31">L 3 =l H (ĥ c − √ DFMh) +l H (ĥ c − √ DFMh),<label>(25)</label></formula><formula xml:id="formula_32">L 4 = µ ĥ c − √ DFMh 2 .<label>(26)</label></formula><p>Minimization of Equation <ref type="formula" target="#formula_39">(8)</ref>  </p><p>The partial complex gradients are: (36)</p><formula xml:id="formula_34">∇ĥ c L 1 = (31) = ∂ ∂ĥ c diag(f )ĥ c −ĝ T diag(f )ĥ c −ĝ = = ∂ ∂ĥ c ĥ T c diag(f ) H diag(f )ĥ c −ĥ T c diag(f ) Hĝ − g H diag(f )ĥ c +ĝ Hĝ = = diag(f ) H diag(f )ĥ c − diag(f )ĝ, ∇ĥ c L 2 = 0,<label>(32)</label></formula><p>Next we derive the closed-form solution of (28). The optimal h is obtained when the complex gradient w.r.t. h vanishes, i.e.,</p><formula xml:id="formula_35">∇ h L ≡ 0 (37) ∇ h L 1 + ∇ h L 2 + ∇ h L 3 + ∇ h L 4 ≡ 0.<label>(38)</label></formula><p>The partial gradients are</p><formula xml:id="formula_36">∇ h L 1 = 0,<label>(39)</label></formula><formula xml:id="formula_37">∇ h L 2 = (40) = ∂ ∂h λ 2 (Mh) T (Mh) = ∂ ∂h λ 2 h H MMh .</formula><p>Since we defined mask m as a binary mask, the product MM can be simplified into M and the result for ∇ h L 2 is</p><formula xml:id="formula_38">∇ h L 2 = λ 2 Mh.<label>(41)</label></formula><p>The remaining gradients are as follows: </p><formula xml:id="formula_39">∇ h L 3 =<label>(</label></formula><p>The values in m are either zero or one. Elements in h that correspond to the zeros in m can in principle not be recovered from <ref type="formula" target="#formula_3">(45)</ref>  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Correlation responses of different feature channels (27 HoG, 10 colornames and one grayscale channel) are summed to obtain the final (single channel) correlation response (middle). Note that maximum values of channel responses may vary by orders of magnitude (right).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>the observation, i.e., the color y c i and position y x i at i-th pixel in the training region and let m i ∈ {0, 1} be a random variable denoting the unknown foreground/background label. The joint</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Spatial reliability map construction from the training region. From left to right: a training region with the target bounding box, t the foreground-background color models, the posterior object probability after Markov random field regularization, and the training region masked with the final binary reliability map. The probabilities are color-coded in a blue (0.0) -green (0.5) -yellow (1.0) colormap.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 7 :</head><label>7</label><figDesc>Convergence speed of constrained filter learning from Section 3.1 shown as a relative drop of the initial cost.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 8 :</head><label>8</label><figDesc>The number of trajectories with tracking successful up to frame Θ frm (upper left), the success plots (upper right) and initialization examples of non-axisaligned targets (bottom).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 9 :</head><label>9</label><figDesc>Qualitative results for trackers CSR-DCF (red) tracker, SRDCF (blue) and LBCF (green).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 12 :</head><label>12</label><figDesc>Expected average overlap (EAO) plot for CSR-DSF (#1) and all trackers participating in the VOT 2015<ref type="bibr" target="#b27">(Kristan et al, 2015)</ref> benchmark listed below the plot in alphabetical order with their numerical codes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 13 :</head><label>13</label><figDesc>Expected average overlap (EAO) plot for CSR-DSF (#1) and all trackers participating in the VOT 2016 (Kristan et al, 2016b) benchmark listed below the plot in alphabetical order with their numerical codes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 15</head><label>15</label><figDesc>: A single iteration processing time decomposed across the main steps of the CSR-DCF.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>in Section 3.1 is an iterative process at which the following minimizations are rer.t. toĥ c is derived by findingĥ c at which the complex gradient of the augmented Lagrangian vanishes, i.e.,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>√</head><label></label><figDesc>DFMh =ĥ m according to our original definition ofĥ m . Plugging (31-34) into (30) yieldsdiag(f ) H diag(f )ĥ c − diag(f )ĝ +l + µĥ c − µĥ m = 0,(35)h c = diag(f )ĝ + µĥ m −l diag(f ) H diag(f ) + µ ,which can be rewritten intôh c =f ĝ + µĥ m −l f f + µ .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>√DF</head><label></label><figDesc>of the inverse Fourier transform, i.e., F −1 (x) = 1 Hx , (44) can be rewritten intom h = m F −1 (l + µĥ c ) λ 2D + µ .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 16 :</head><label>16</label><figDesc>since this would result in division by zero. But our initial definition of the problem was to seek solutions for the filter that satisfies the following relation h ≡ h m. This means the values corresponding to zeros in m should be zero in h. Thus the proximal solution to (45) is h = m F −1 (l + µĥ c ) Qualitative results of tracking with the CSR-DCF on four video sequences.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>Calculate channel reliabilityw =w (lrn) w (det) 10: Update filter h t = (1 − η)h t−1 + ηh.</figDesc><table /><note>6: Estimate reliability map m (Sect. 3.2).7: Estimate a new filterh using m (Algorithm 1).8: Estimate learning channel reliabilityw (lrn) from h (Sect. 3.3).9:11: Update channel reliability w t = (1 − η)w t−1 + ηw.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 2 :</head><label>2</label><figDesc>Ablation study of CSR-DCF. The use of channel reliability is indicated in the Chan. column, the the type of spatial reliability map in the Spat. column. The Opt.</figDesc><table><row><cell cols="5">column indicates whether the constrained optimization is</cell></row><row><cell>used.</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Tracker</cell><cell cols="4">Chan. Spat. Opt. EAO</cell><cell>R av</cell><cell>A av</cell></row><row><cell>CSR-DCF</cell><cell cols="4">x segm. x 1 0.338 1 0.85 1 0.51</cell></row><row><cell>CSR-DCF c −</cell><cell cols="4">-segm. x 2 0.297 2 1.08 2 0.51</cell></row><row><cell>CSR-DCF s u</cell><cell cols="4">x unif. x 3 0.264 3 1.18 3 0.49</cell></row><row><cell cols="4">CSR-DCF c − s u -unif. x</cell><cell>0.256 1.33 2 0.51</cell></row><row><cell cols="4">CSR-DCF c − o − -segm. -</cell><cell>0.251 1.47 2 0.51</cell></row><row><cell cols="2">CSR-DCF c − s − -</cell><cell>-</cell><cell>-</cell><cell>0.152 2.85 0.47</cell></row><row><cell cols="2">denoted as CSR-DCF c</cell><cell></cell><cell></cell></row></table><note>− o − , does not use channel reliabil- ity weights. The performance drop in EAO compared to CSR-DCF c − is 15%.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3 :</head><label>3</label><figDesc>Tracking performance comparison of the two versions of CSR-DCF on VOT2016. The proposed method is denoted as CSR-DCF while the version using ground-truth segmentation masks instead of color-based spatial reliability map is denoted as CSR*-DCF.</figDesc><table><row><cell>Tracker</cell><cell>EAO</cell><cell>A av</cell><cell>R av</cell></row><row><cell>CSR-DCF</cell><cell>0.338</cell><cell>0.51</cell><cell>0.85</cell></row><row><cell>CSR*-DCF</cell><cell>0.338</cell><cell>0.51</cell><cell>0.83</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 4 :</head><label>4</label><figDesc>The ten top-performing trackers on the VOT2015 benchmark.</figDesc><table><row><cell>Tracker</cell><cell>EAO</cell><cell>A av</cell><cell>R av</cell></row><row><cell>CSR-DCF</cell><cell>1 0.320</cell><cell>3 0.55</cell><cell>2 0.93</cell></row><row><cell>DeepSRDCF</cell><cell>2 0.318</cell><cell>2 0.56</cell><cell>3 1.00</cell></row><row><cell>EBT</cell><cell>3 0.313</cell><cell>0.45</cell><cell>1 0.81</cell></row><row><cell>srdcf</cell><cell>0.288</cell><cell>3 0.55</cell><cell>1.18</cell></row><row><cell>LDP</cell><cell>0.278</cell><cell>0.49</cell><cell>1.30</cell></row><row><cell>sPST</cell><cell>0.277</cell><cell>0.54</cell><cell>1.42</cell></row><row><cell>scebt</cell><cell>0.255</cell><cell>0.54</cell><cell>1.72</cell></row><row><cell>nsamf</cell><cell>0.254</cell><cell>0.53</cell><cell>1.45</cell></row><row><cell>struck</cell><cell>0.246</cell><cell>0.46</cell><cell>1.50</cell></row><row><cell>rajssc</cell><cell>0.242</cell><cell>1 0.57</cell><cell>1.75</cell></row><row><cell cols="4">4.8 The VOT2016 benchmark (Kristan</cell></row><row><cell>et al, 2016b)</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 5 :</head><label>5</label><figDesc>The ten top-performing trackers on the VOT2016 benchmark.</figDesc><table><row><cell>Tracker</cell><cell>EAO</cell><cell>A av</cell><cell>R av</cell></row><row><cell>CSR-DCF</cell><cell>1 0.338</cell><cell>0.51</cell><cell>2 0.85</cell></row><row><cell>CCOT</cell><cell>2 0.331</cell><cell>0.52</cell><cell>2 0.85</cell></row><row><cell>TCNN</cell><cell>3 0.325</cell><cell>3 0.54</cell><cell>0.96</cell></row><row><cell>SSAT</cell><cell>0.321</cell><cell>1 0.57</cell><cell>1.04</cell></row><row><cell>MLDF</cell><cell>0.311</cell><cell>0.48</cell><cell>1 0.83</cell></row><row><cell>Staple</cell><cell>0.295</cell><cell>3 0.54</cell><cell>1.35</cell></row><row><cell>DDC</cell><cell>0.293</cell><cell>0.53</cell><cell>1.23</cell></row><row><cell>EBT</cell><cell>0.291</cell><cell>0.44</cell><cell>3 0.90</cell></row><row><cell>SRBT</cell><cell>0.290</cell><cell>0.50</cell><cell>1.25</cell></row><row><cell>STAPLEp</cell><cell>0.286</cell><cell>2 0.55</cell><cell>1.32</cell></row><row><cell cols="4">tan et al, 2015) with improved annotations. The bench-</cell></row><row><cell cols="4">mark evaluated a set of 70 trackers which includes</cell></row><row><cell cols="4">the recently published and yet unpublished state-of-</cell></row><row><cell cols="4">the-art trackers. The set is indeed diverse, the top-</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 6 :</head><label>6</label><figDesc>Speed in frames per second (fps) of correlation trackers and Struck -a baseline. The EAO, average accuracy (A av ) and average failures (R av ) are shown for reference.</figDesc><table><row><cell cols="2">Tracker</cell><cell>EAO</cell><cell>A av</cell><cell>R av</cell><cell>fps</cell></row><row><cell cols="2">CSR-DCF</cell><cell cols="4">1 0.338 2 0.51 1 0.85 3 13.0</cell></row><row><cell cols="5">CCOT ECCV2016 2 0.331 1 0.52 1 0.85</cell><cell>0.6</cell></row><row><cell cols="5">CCOT* ECCV2016 3 0.274 1 0.52 2 1.18</cell><cell>1.0</cell></row><row><cell cols="2">SRDCF ICCV2015</cell><cell cols="3">0.247 1 0.52 3 1.50</cell><cell>7.3</cell></row><row><cell>KCF</cell><cell>PAMI2015</cell><cell cols="2">0.192 3 0.48</cell><cell cols="2">2.03 1 115.7</cell></row><row><cell>DSST</cell><cell>PAMI2016</cell><cell cols="2">0.181 3 0.48</cell><cell cols="2">2.52 2 18.6</cell></row><row><cell cols="2">Struck ICCV2011</cell><cell>0.142</cell><cell>0.42</cell><cell>3.37</cell><cell>8.5</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">The CSR-DCF Matlab source is publicly available on: https://github.com/alanlukezic/csr-dcf</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">With some basic code optimization and refactoring we speed-up our algorithm to 19 FPS without significant performance drop (only one additional failure on VOT2016 dataset).</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknownledgements</head><p>This work was supported in part by the following research programs and projects: Slovenian research agency research programs and projects P2-0214, L2-6765 and J2-8175. Jiři Matas and Tomáš Vojír were supported by The Czech Science Foundation Project GACR P103/12/G084 and Toyota Motor Europe. We would also like to thank dr. RokŽitko for discussion on complex differentiation.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Robust object tracking with online multiple instance learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Babenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Pattern Anal Mach Intell</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1619" to="1632" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Staple: Complementary learners for real-time tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bertinetto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Valmadre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Golodetz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Miksik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phs</forename><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Comp. Vis. Patt. Recognition</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1401" to="1409" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bertinetto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Valmadre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Henriques</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Torr</surname></persName>
		</author>
		<idno>arXiv:160609549</idno>
		<title level="m">Fully-convolutional siamese networks for object tracking</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Visual object tracking using adaptive correlation filters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Bolme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Beveridge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">A</forename><surname>Draper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">M</forename><surname>Lui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Comp. Vis. Patt. Recognition, IEEE</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="2544" to="2550" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Distributed optimization and statistical learning via the alternating direction method of multipliers. Foundations and Trends in</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Peleato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Eckstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="122" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Visual object tracking performance measures revisited</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Cehovin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Leonardis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kristan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Image Proc</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1261" to="1274" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Histograms of oriented gradients for human detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Dalal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Triggs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comp. Vis. Patt. Recognition</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="886" to="893" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Accurate scale estimation for robust visual tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Danelljan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Häger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">S</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Felsberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. British Machine Vision Conference</title>
		<meeting>British Machine Vision Conference</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Adaptive color attributes for real-time visual tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Danelljan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">S</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Felsberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Van De Weijer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2014 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting><address><addrLine>Columbus, OH, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-06-23" />
			<biblScope unit="page" from="1090" to="1097" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Learning spatially regularized correlation filters for visual tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Danelljan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hager</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shahbaz</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Felsberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. Computer Vision</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="4310" to="4318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Convolutional features for correlation filter based visual tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Danelljan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Häger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">S</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Felsberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision Workshop (ICCVW)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="621" to="629" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Beyond correlation filters: learning continuous convolution operators for visual tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Danelljan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">S</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Felsberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European Conf. Computer Vision</title>
		<meeting>European Conf. Computer Vision</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="472" to="488" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Discriminative scale space tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Danelljan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Häger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">S</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Felsberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Pattern Anal Mach Intell</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1561" to="1575" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Context tracker: Exploring supporters and distracters in unconstrained environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">B</forename><surname>Dinh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Vo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Medioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Comp. Vis. Patt. Recognition</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1177" to="1184" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A spatially constrained generative model and an em algorithm for image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Diplaros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Vlassis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Gevers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Neural Networks</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="798" to="808" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Object detection with discriminatively trained part-based models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Felzenszwalb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mcallester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Pattern Anal Mach Intell</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1627" to="1645" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Multi-channel correlation filters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">K</forename><surname>Galoogahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Sim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lucey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. Computer Vision</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3072" to="3079" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Real-time tracking via on-line boosting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Grabner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Grabner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bischof</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. British Machine Vision Conference</title>
		<meeting>British Machine Vision Conference</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="47" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Struck: Structured output tracking with kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Saffari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phs</forename><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. Computer Vision</title>
		<meeting><address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="263" to="270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Exploiting the circulant structure of tracking-by-detection with kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Henriques</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Caseiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Batista</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European Conf. Computer Vision</title>
		<editor>Fitzgibbon A, Lazebnik S, Perona P, Sato Y, Schmid C</editor>
		<meeting>European Conf. Computer Vision<address><addrLine>Berlin Heidelberg, Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="702" to="715" />
		</imprint>
	</monogr>
	<note>Heidelberg</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Highspeed tracking with kernelized correlation filters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Henriques</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Caseiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Batista</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Pattern Anal Mach Intell</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="583" to="596" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Multivariant technique for multiclass pattern recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">F</forename><surname>Hester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Casasent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Optics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1758" to="1761" />
			<date type="published" when="1980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Multi-store tracker (muster): A cognitive psychology inspired approach to object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Prokhorov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Comp. Vis. Patt. Recognition</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="749" to="758" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Trackinglearning-detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Kalal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mikolajczyk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Matas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Pattern Anal Mach Intell</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1409" to="1422" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Correlation filters with limited boundaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kiani</forename><surname>Galoogahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Sim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lucey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Comp. Vis. Patt. Recognition</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="4630" to="4638" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The visual object tracking vot2013 challenge results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kristan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pflugfelder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Leonardis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Matas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Porikli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Cehovin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Nebehay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Fernandez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vojir</forename><surname>Tea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Vis. Obj. Track. Challenge VOT2013</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="98" to="111" />
		</imprint>
	</monogr>
	<note>conjunction with ICCV2013</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">The visual object tracking vot2014 challenge results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kristan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pflugfelder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Leonardis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Matas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Čehovin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Nebehay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Vojir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European Conf. Computer Vision</title>
		<meeting>European Conf. Computer Vision</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="191" to="217" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kristan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Matas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Leonardis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Felsberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Čehovin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Fernandez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Vojir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Häger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Nebehay</surname></persName>
		</author>
		<title level="m">The visual object tracking vot2015 challenge results. In: Int. Conf. Computer Vision</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Fast image-based obstacle detection from unmanned surface vehicles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kristan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">S</forename><surname>Kenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kovačič</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Perš</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Cybernetics</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="641" to="654" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Fernandez G (2016b) The visual object tracking vot2016 challenge results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kristan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Leonardis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Matas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Felsberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pflugfelder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Čehovin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Vojir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Häger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lukežič</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European Conf. Computer Vision</title>
		<meeting>European Conf. Computer Vision</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A novel performance evaluation methodology for single-target trackers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kristan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Matas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Leonardis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Vojir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pflugfelder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Fernandez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Nebehay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Porikli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Cehovin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Pattern Anal Mach Intell</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A scale adaptive kernel correlation filter tracker with feature integration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European Conf. Computer Vision</title>
		<meeting>European Conf. Computer Vision</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="254" to="265" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A scale adaptive kernel correlation filter tracker with feature integration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European Conf. Computer Vision</title>
		<meeting>European Conf. Computer Vision</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="254" to="265" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Encoding color information for visual tracking: Algorithms and benchmark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Blasch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Image Proc</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="5630" to="5644" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Robust tracking using local sparse appearance model and kselection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kulikowsk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Comp. Vis. Patt. Recognition</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1313" to="1320" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Structural correlation filter for robust visual tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Comp. Vis. Patt. Recognition</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4312" to="4320" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Real-time part-based visual tracking via adaptive correlation filters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Comp. Vis. Patt. Recognition</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="4902" to="4912" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Deformable parts correlation filters for robust visual tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lukežič</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zajc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristan</forename><forename type="middle">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Cybernetics PP</title>
		<imprint>
			<biblScope unit="issue">99</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Hierarchical convolutional features for visual tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. Computer Vision</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3074" to="3082" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A benchmark and simulator for uav tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ghanem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European Conf. Computer Vision</title>
		<meeting>European Conf. Computer Vision</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Learning multi-domain convolutional neural networks for visual tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Nam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Comp. Vis. Patt. Recognition</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4293" to="4302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Hedged deep tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">H</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CVPR</publisher>
			<biblScope unit="page" from="4303" to="4311" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Visual tracking: An experimental survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Smeulders</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cucchiara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Calderara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dehghan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Pattern Anal Mach Intell</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1442" to="1468" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Pixel-wise object segmentations for the VOT 2016 dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Vojir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Matas</surname></persName>
		</author>
		<idno>CTU-CMP-2017-01</idno>
		<imprint>
			<date type="published" when="2017" />
			<pubPlace>Prague, Czech Republic</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Center for Machine Perception, K13133 FEE Czech Technical University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Research Report</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Visual tracking with fully convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. Computer Vision</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3119" to="3127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Transferring rich feature hierarchies for robust visual tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yeung</surname></persName>
		</author>
		<idno>abs/1501.04587</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Visual tracking with reliable memories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">N</forename><surname>Metaxas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence</title>
		<meeting>the Twenty-Fifth International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3491" to="3497" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Robust object tracking via sparsity-based collaborative model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mhy Huchuan</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Comp. Vis. Patt. Recognition</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1838" to="1845" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Learning color names for real-world applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Van De Weijer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Verbeek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Larlus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Image Proc</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1512" to="1523" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Online object tracking: A benchmark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Comp. Vis. Patt. Recognition</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2411" to="2418" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Object tracking benchmark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Pattern Anal Mach Intell</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1834" to="1848" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Visual tracking via adaptive structural local sparse appearance model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mhy Huchuan</forename><surname>Xu Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Comp. Vis. Patt. Recognition</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1822" to="1829" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Fast visual tracking via dense spatio-temporal context learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European Conf. Computer Vision</title>
		<meeting>European Conf. Computer Vision</meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="127" to="141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Beyond local search: Tracking objects everywhere with instance-specific proposals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Porikli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="943" to="951" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
