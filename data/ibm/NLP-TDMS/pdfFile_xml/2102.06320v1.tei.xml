<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">On Automatic Parsing of Log Records</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jared</forename><surname>Rand</surname></persName>
							<email>jrand@ryerson.ca</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Ryerson University</orgName>
								<address>
									<settlement>Toronto</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andriy</forename><surname>Miranskyy</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Ryerson University</orgName>
								<address>
									<settlement>Toronto</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">On Automatic Parsing of Log Records</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T16:16+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Software log analysis helps to maintain the health of software solutions and ensure compliance and security. Existing software systems consist of heterogeneous components emitting logs in various formats. A typical solution is to unify the logs using manually built parsers, which is laborious.</p><p>Instead, we explore the possibility of automating the parsing task by employing machine translation (MT). We create a tool that generates synthetic Apache log records which we used to train recurrent-neural-network-based MT models. Models' evaluation on real-world logs shows that the models can learn Apache log format and parse individual log records. The median relative edit distance between an actual real-world log record and the MT prediction is less than or equal to 28%. Thus, we show that log parsing using an MT approach is promising.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Modern software solutions consist of a stack of hardware and software components <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>. A failure of a component may lead to an outage, affecting the solution's customers. It is crucial to quickly detect such a failure and identify the potential root cause of the problem to create a fix. Detection of the root cause is a daunting task, taking up to 40% of the time needed to fix the problem <ref type="bibr" target="#b2">[3]</ref>. Finding the root causes is done by examining the logs emitted by the solution's components <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b5">6]</ref>. Additionally, these logs may be used in the detection of cyberattacks <ref type="bibr" target="#b0">[1]</ref> or auditing compliance with policies <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b6">7]</ref>.</p><p>There exist tools that do automatic log examinations and speed up diagnostics <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b5">6]</ref>. Unfortunately, components have individual log formats, while analysis tools prefer the logs in a unified format <ref type="bibr" target="#b1">[2]</ref>. Thus, maintainers need to manually create individual converters for every log format <ref type="bibr" target="#b7">[8]</ref>. Given that a solution may have thousands of components, this becomes laborious <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b8">9]</ref>. If one can create a tool that parses logs automatically, this tool will speed up defect detection and repair, allowing developers to focus on creating new functionality and reducing maintenance efforts.</p><p>There exists a significant body of literature on recognizing formats. Researchers worked on detecting field type 1 in a structured record set <ref type="bibr" target="#b9">[10]</ref>, developing parsers rapidly and incrementally <ref type="bibr" target="#b10">[11]</ref>, extracting specific information from a log string <ref type="bibr" target="#b12">[12,</ref><ref type="bibr" target="#b13">13,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b6">7]</ref>, and detecting log formats by comparing multiple similar log strings <ref type="bibr" target="#b14">[14,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b15">15]</ref>. But can we individually parse a complete raw log string (so that we can convert it to a universal format) without comparing it to other log records emitted by the same component?</p><p>This leads us to the following research question (RQ): How can we automatically parse an individual raw log string? To answer our RQ, we reduce parsing to a machine translation (MT) task. That is, we need to create an Oracle that, given a raw log string as input, will produce a string of tokens, showing which particular field a character in the input string belongs to. A toy example of the input and output is given in <ref type="figure" target="#fig_0">Figure 1</ref>.</p><p>How should an Oracle look? In the field of MT for natural languages, the best models are currently based on deep neural networks (DNNs) following an encoder-decoder architecture that implements sequence-to-sequence learning. We will discuss the details of the models in Section 2.</p><p>DNNs require large volumes of data for training. Thus, we create a tool to generate synthetic logs mimicking real ones. We will further discuss synthetic data generation and real logs (used for validation of the models) in Section 3. We will then discuss the setup of our experiments in Section 4, followed by a comparison of the performance of our models in Section 5 and a summary of our findings in Section 6. Finally, we will provide details for accessing the tool and the logs in Section 7. 2020-09-20 jane ERROR file not found tttttttttt uuuu lllll iiiiiiiiiiiiii <ref type="figure" target="#fig_0">Figure 1</ref>: A toy example of log translation. The top line represents an input string of the raw log. The characters in the bottom line represent the field type that a given input character is mapped to. For example, all the characters in the substring 2020-09-20 belong to a time field, denoted by t; substring jane represents a user field denoted by u; substring ERROR is a log record type field denoted by l, and substring file not found is log message details denoted by i. Finally, denotes a separator between the fields.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Models</head><p>We chose DNN architectures, popular for machine translation of natural language. First, we compared recurrent neural networks using gated recurrent units (GRU) <ref type="bibr" target="#b17">[16]</ref> against those using long short-term memory (LSTM) <ref type="bibr" target="#b18">[17]</ref> cells. Our preliminary experiments showed that LSTM-based translators outperformed the GRU-based ones (hinting that extra memory-related gates present in the LSTM cell but absent in the GRU cell may be necessary for our task). Thus, we focused on LSTM-based translators and converged on three architectures.</p><p>The first one, deemed M C , is based on the classic neural MT architecture akin to <ref type="bibr" target="#b19">[18]</ref> with LSTM-based encoder and decoder layers. The second one, deemed M L , is similar to M C but added the attention layer as per Bahdanau et al. <ref type="bibr" target="#b20">[19]</ref>. The third one, deemed M S , is based on the seq2seq architecture <ref type="bibr" target="#b21">[20]</ref> with the LSTM layers and Luong et al. attention mechanism <ref type="bibr" target="#b22">[21]</ref>. During our initial tests we evaluated M S with and without beam search decoding <ref type="bibr" target="#b23">[22]</ref>. We ended up using M S with regular inference as initial tests found beam search evaluation to be inferior for our datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Logs under study</head><p>In this work, we focus on log formats of the Apache HTTP server <ref type="bibr" target="#b24">[23]</ref>. The ubiquitousness of this product makes it a good candidate for our tests.</p><p>We will discuss our generator tool, designed to create synthetic Apache log records in Section 3.1. Then we will discuss the real-world datasets in Section 3.2, followed by the description of the synthetic datasets used for training the Oracle in Section 3.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Synthetic logs' generator</head><p>As discussed above, to train DNNs, we need large volumes of data. There exist tools for generating synthetic logs, e.g., <ref type="bibr" target="#b25">[24,</ref><ref type="bibr" target="#b26">25]</ref>. However, for the training of the DNNs, we need not only the raw log strings, which will serve as input to a DNN, but also the information about the log strings' format that will be used as output from the model.</p><p>Most of the generators use the Apache Common Log Format (hereby referred to as CLF) or Combined Log Format (an extended version of CLF hereby referred to as ELF). Explanations of what these formats look like can be found in <ref type="table">Table 1</ref> (for details, see Apache manual <ref type="bibr" target="#b27">[26]</ref>).</p><p>While CLF and ELF are the most common forms of Apache logs, we did not feel confident that a DNN trained solely on CLF and ELF could accomplish our goal of recognizing the fields of any Apache log. Additionally, the existing fake log generators did not vary much in their generated data, often using the current date of generation as the date for each log record and using a small subset of fake websites and sub-pages for which it would create requests. Furthermore, in order to train the DNNs, we needed 'ground truth' output strings, which would be easier to generate alongside the log strings rather than after the fact.</p><p>Thus, we created our own Python-based generator, which extends and combines the Faker <ref type="bibr" target="#b25">[24]</ref> and fake-useragent <ref type="bibr" target="#b28">[27]</ref> libraries. These libraries were used to realistically generate specifically-formatted fields, such as the user agent field and IPv6 addresses.</p><p>Our generator creates synthetic log records based on 15 fields 2 and one separator field listed in <ref type="table">Table 2</ref>. The user should specify the total number of the log records to produce and the type of format (random or fixed). The tool then generates raw log records (input) and the associated translations (outputs). An example of the generated data is shown in <ref type="figure">Figure 2</ref>. <ref type="table">Table 1</ref>: Apache log formats, see <ref type="table">Table 2</ref> for fields' description. Name Fields (acronyms)</p><p>Common Log Format (CLF) h l u t "r" s b Combined Log Format (ELF) h l u t "r" s b "R" "i" <ref type="table">Table 2</ref>: A list of fields that our synthetic log generator can produce. For details about the fields, see <ref type="bibr" target="#b24">[23]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Field</head><p>Field acronym description h IP address of the client host. Can be IPv4 or IPv6. l</p><p>The remote logname. We were unable to find a good example of what kinds of values are returned by Apache servers, thus for this paper we only supplied the commonly-given value '-'. This field could not be omitted as it is present in both the ELF and CLF formats. u</p><p>The remote username. Can be empty ('-') t</p><p>The datetime of the request, presented in the default [day/month/year:hour:minute:second zone] format. r</p><p>The request line from the client. Made up of the method, path and querystring, and protocol. s</p><p>The status of the request. b</p><p>The number of bytes sent. m</p><p>The request method. U</p><p>The requested URI path. H</p><p>The request protocol. q</p><p>The request querystring. v</p><p>The canonical servername of the server servicing the request. V</p><p>The servername according to UseCanonical. In our generator, this field is identical to the v field. i</p><p>The user agent of the request 3 . R</p><p>The referrer of the request 3 . Represents a separator between log fields.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Real logs</head><p>To validate the generalizability of the DNNs trained on synthetic log records produced by the generator discussed in Section 3.1, we take three publicly available log files and deem the validation datasets V A [28], V B [29], and V C <ref type="bibr" target="#b29">[30]</ref>. The first two logs capture execution results of two web vulnerability scanners, namely, Netsparker and Acunetix <ref type="bibr" target="#b30">[31]</ref>. The third one is a sample Apache web server log file that can be processed by Elastic software. The summary statistics of the log files is shown in <ref type="table" target="#tab_0">Table 3</ref>. The log format of the validation logs is (or is extremely similar to) ELF 4 . We have parsed the log records from these three files using custom scripts to produce the correct character-to-field mapping strings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Synthetic datasets</head><p>Using our log generator (covered in Section 3.1), we create synthetic logs for training and testing, while varying the number of log records and their formats. We create five synthetic datasets that may help us uncover various challenges of the "log translation" task. The datasets summary statistics are given in <ref type="table" target="#tab_0">Table 3</ref>; their details are as follows.</p><p>The first dataset, deemed T T , contains trivial -to-learn data. The triviality of this dataset refers to the ability of models trained on this set to learn the fields and correctly interpret the validation datasets. T T consists of 100K ELF mock logs. The models trained on this dataset should be able to recognize the ELF-based log records from our validation datasets very well. However, the generalizability to other formats would be mediocre.</p><p>The second dataset, deemed T E , has easy-to-learn data. It contains 20K lines using a mix of the formats: ELF, CLF, and randomly generated records, which are generated based on all the fields in <ref type="table">Table 2</ref>. The random and CLF records are added to assess the generalizability of the model. Hypothetically, models trained on T E and validated on V (·) datasets will have worse performance than those trained on T T , because it has fewer log records and the model has to learn of multiple formats.  <ref type="figure">Figure 2</ref>: An example of a record for translation generated by our log generator. Lines 1, 3, and 5 are examples of logs in CLF, ELF, and random format, respectively. The characters in lines 2, 4, and 6 represent mapping to their equivalent field type (described in <ref type="table">Table 2</ref>). The third dataset, deemed T M , contains moderately-difficult-to-learn data. T M contains a mix of formats: ≈ 50% of 100K records are in the CLF format and ≈ 50% have randomly generated formats. Based on <ref type="table">Table 1</ref>, CLF is similar to ELF, but two of the fields (R and i) are missing. Thus, it will be harder for the model to recognize ELF records in V (·) .</p><p>The fourth dataset, deemed T M , is a shorter version of T M containing only 20K records. The more observations a dataset has, the more information a machine learning model will obtain for training. However, this comes at a cost of increased training time. Thus, we want to see how the change in observations affects models' performance. T M will help us assess how much data are needed for training.</p><p>The fifth dataset, deemed T H , carries hard -to-learn data. This dataset contains 100K randomly generated records, and none of them look like CLF or ELF. Thus, models trained on this dataset must learn the nature of the fields well in order to properly parse log records in V (·) .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Setup</head><p>We want to assess the generalizability of our approach. To do this, we create three groups of experiments where a model is trained on Training Datasets T (·) (described in Section 3.3). We train the neural networks for up to 300 epochs with a mini-batch size of 64 log records. Optimization is done using the Adam algorithm 5 <ref type="bibr" target="#b31">[32]</ref>. Each dataset is randomly split into 90% training data and 10% validation data during training. The best model, preserved for further evaluation, is the one with the lowest cross-entropy loss for M C and M L and sparse categorical cross-entropy loss for M S . Translation is done at the character-level, i.e., we do not do any log record prepossessing.</p><p>We have tuned the models' hyper-parameters. For M C and M L , we have experimented with different number of cells in these layers, namely {256, 512, 1024}. This was done to assess the degree of 'freedom' required to recognize different log formats. We also varied the dropout rates in the encoder and decoders layer, setting them to {0.0, 0.2, 0.4, 0.6, 0.8}. This was done to regularize the model and reduce overtraining. We evaluate the performance of the models on three real-world log files (discussed in Section 3.2). The performance is measured using the Levenshtein (a.k.a. the edit) distance <ref type="bibr" target="#b32">[33]</ref>, which computes the number of changes needed to transform a string returned by the Oracle into an expected (ground truth) string. We report the absolute and relative Levenshtein distances, deemed D A and D R , respectively. For a given log record, D R is computed by dividing D A by the log record length. D A and D R lie within [0, ∞) range: the closer to 0 -the better.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Comparison approach</head><p>It is easy to measure D A and D R for individual strings. However, how to aggregate the measurements for a particular V (·) dataset? Let us look at the distributions of the D A and D R values. For the sake of brevity, we show the distributions only for the models trained on T M in <ref type="figure" target="#fig_1">Figure 3</ref>. As we can see, the distributions have a long right tail: although the median values of D A are between 51 and 61, the max values go up to 4283. This is due to the presence in V B and V C of a small number of long log records (as shown in <ref type="table" target="#tab_0">Table 3</ref>). Namely, less than 0.2% of log records are longer than 1000 characters, while the median length of the log records is between 231 and 238 characters for all three V (·) . Once we normalize the results using the D R , we can see that the amount of changes is proportional to the string's length, with the median D R between ≈ 21 and 25%.</p><p>To preserve space and allow quantitative comparison, we present the summary statistics for the remaining evaluations by computing min, max, mean, and various quantiles of the distributions. The results for the top models, based on the lowest values of D A and D R for a given quantile, are shown in <ref type="table">Table 4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Discussion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">Architecture comparison</head><p>The models with the attention mechanisms (M L and M S ) underperformed and are not shown in <ref type="table">Table 4</ref>; the M Cbased models are the winners. The poor performance may suggest that the attention mechanisms, which work well for natural language translation, are less suited for our problem. <ref type="table">Table 4</ref>: Summary statistics for the distributions of D A and D R for the best performing models. All the models have 512 cells in the LSTM layers; d denotes the dropout rate and is either 0.2 or 0.4. q p denotes the sample quantile function, where p is the probability value; e.g., when p = 0.50, the q .50 returns the median of a distribution. For example, for a model trained on dataset T H , when validated on V C , the maximum value of D R is 0.91 (as shown in the bottom-right corner).   <ref type="table">Table 4</ref> shows that the models with 512 cells prevailed, which may imply that we do need some degree of freedom to learn the patterns but not too much to overwhelm the optimizer.</p><formula xml:id="formula_0">Trained V A V B V C on</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2">Hyperparameters</head><p>The dropout rate d = 0.2 is the best in all cases, except for models trained on T E . In this particular case, a dropout of 0.2 and 0.4 provide similar results. We expected the dropout to be positive as our goal is to generalize the learning process, and these expectations were met.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.3">Dataset size</head><p>Comparison of results for T M and T M in <ref type="table">Table 4</ref> suggests that the larger number of observations improves performances of the model. However, we can observe the diminishing returns: increasing the dataset size by a factor of five (as in the case of T M and T M ) leads to incremental improvements in the D A and D R values.</p><p>Moreover, compare the results for models trained on T E and T M : the model trained on 20K of simpler observations from T E performs better than the model trained on 100K harder records from T M . This implies that the quality of the input matters more than the quantity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.4">Training time</head><p>We used Nvidia Tesla P100 and Titan X Pascal GPUs for the training. The training time per epoch (for datasets with 100K log records) ranged between one and three hours, depending on the models and inputs. Thus, training the model for hundreds of epochs is time-consuming. We observed that the validation loss would often reach the lowest (best) values between 60 and 150 epochs during models' training, which enabled us to perform early stopping and save time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.5">Training datasets vs. models' performance</head><p>As expected, the resulting models' performance degrades as the difficulty of the training dataset increases. The T Tbased model came up first (with the exception of a few high quantiles): it had to learn only the fields' beginning and end while the fields' order stayed the same. The T H -based model came last: not only did the model have to understand the beginning and ends of the fields, but also it had to learn the field's order while never been able to see a single example of the ELF record. To our pleasant surprise, the T H -based model did not fall behind their competitors significantly and was quite close to the T M -based model, with the median D R between 0.25 and 0.28, and the 90-th quantile of D R between 0.26 and 0.43. This implies that the T H -based model was able to learn the concept of fields relatively well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Summary</head><p>Our RQ was: How can we automatically parse an individual raw log string? To answer the RQ, we reformulated parsing as an MT task and explored three MT architectures. We showed that the models based on the classic LSTM MT architecture are the most promising. Moreover, the model trained on randomly generated log records was able to partially parse the log records in a format that it did not see in training: 50% of log records per evaluation dataset were parsed with the D R ≤ 28% and 90% of records with the D R ≤ 43%. This implies that parsing of the individual strings using MT is possible.</p><p>This work is of interest to researchers as it provides novel insights into the log parsing field. The quality of our models' translation is not adequate for the practitioner at this stage, but we hope that this work will inspire others to explore various MT approaches and improve upon our results.</p><p>To aid these researchers, we created a tool for generating synthetic logs in Apache format used for creating training data for the models. We also found and parsed three real-world validation logs for models' evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Data Availability</head><p>The tool source code repository is <ref type="bibr" target="#b33">[34]</ref>. The version of the tool used in this paper is stored at <ref type="bibr" target="#b34">[35]</ref>. The training and validation datasets, T (·) and V (·) , are available at <ref type="bibr" target="#b35">[36]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>1 :</head><label>1</label><figDesc>41.193.93.229 --10/Jul/7983:05:08:49 +0100 "GET explore/category/home.html HTTP/2" 302 65953 2: hhhhhhhhhhhhh l u tttttttttttttttttttttttttt rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr sss bbbbb 3: 192.168.4.25 --[22/Dec/2016:16:11:41 +0300] "POST /DVWA/login.php HTTP/1.1" 200 1532 "-" "Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 6.1; Trident/4.0; w3af.sf.net" 4: hhhhhhhhhhhh l u [tttttttttttttttttttttttttt] "rrrrrrrrrrrrrrrrrrrrrrrrrrrrr" sss bbbb "R" "iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii" 5: PUT ycgmvjc.com HTTP/2 -102186 -d8idf~gyck.html 6: mmm VVVVVVVVVVV HHHHHH l bbbbbb F UUUUUUUUUUUUUUU</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Distribution of D A and D R values (left and right pane, respectively) for the best model trained on the T M dataset and validated on V A , V B , and V C datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>T</head><label></label><figDesc>T , d = 0.2 0.03 0.11 0.06 0.08 0.33 0.36 0.50 0.59 0.03 0.06 0.06 0.06 0.06 0.11 0.34 2.18 0.01 0.12 0.04 0.09 0.27 0.50 1.75 2.02 T E , d = 0.2 0.05 0.15 0.08 0.10 0.39 0.46 0.61 0.71 0.05 0.10 0.10 0.10 0.10 0.17 0.43 0.82 0.03 0.10 0.08 0.09 0.15 0.35 0.47 0.77 T E , d = 0.4 0.05 0.12 0.08 0.09 0.20 0.40 0.69 0.82 0.04 0.09 0.08 0.08 0.10 0.15 0.46 0.94 0.03 0.11 0.05 0.10 0.20 0.51 0.63 0.75 T M , d = 0.2 0.09 0.23 0.23 0.26 0.33 0.39 0.70 0.80 0.09 0.22 0.24 0.24 0.29 0.29 0.61 0.97 0.09 0.30 0.29 0.36 0.43 0.59 0.69 0.94 T M , d = 0.2 0.07 0.20 0.23 0.28 0.30 0.33 0.42 0.58 0.06 0.18 0.21 0.22 0.25 0.26 0.37 0.97 0.04 0.24 0.25 0.31 0.36 0.42 0.48 0.84 T H , d = 0.2 0.07 0.25 0.28 0.31 0.40 0.45 0.63 0.79 0.06 0.21 0.25 0.25 0.26 0.35 0.61 0.97 0.06 0.28 0.27 0.32 0.43 0.63 0.64 0.91</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 3 :</head><label>3</label><figDesc>Datasets' description.</figDesc><table><row><cell cols="2">Dataset Log records</cell><cell cols="3">Log records length</cell><cell>Log records' format description</cell></row><row><cell></cell><cell cols="4">count min median max</cell></row><row><cell>T T</cell><cell cols="2">100,000 136</cell><cell cols="2">272 1173 100% ELF</cell></row><row><cell>T E</cell><cell>20,000</cell><cell>4</cell><cell cols="2">250 1173 ≈ 40% of the ELF format, ≈ 24% of the CLF format, and ≈</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>36% of randomly drawn and reshuffled fields shown in Table 2.</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>The random strings have 2 to 14 records in them.</cell></row><row><cell cols="5">T M 161 1294 T M 100,000 4 20,000 4 162 1527 Identical to the one of T M .</cell></row><row><cell>T H</cell><cell>100,000</cell><cell>4</cell><cell cols="2">291 1528 100% of the randomly generated records using the same ap-</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>proach as in the T E case. The random strings have 2 to 15</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>fields in them.</cell></row><row><cell>V A</cell><cell cols="2">7,314 194</cell><cell>238</cell><cell>602 100% ELF</cell></row><row><cell>V B</cell><cell>6,539</cell><cell>79</cell><cell cols="2">238 4398 100% ELF</cell></row><row><cell>V C</cell><cell>10,000</cell><cell>81</cell><cell cols="2">231 1363 100% ELF</cell></row></table><note>≈ 50% of the CLF format and ≈ 50% of the randomly gener- ated records using the same approach as in the T E case. The random strings have 2 to 14 fields in them.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>min avg q .50 q .75 q .90 q .95 q .99 max min avg q .50 q .75 q .90 q .95 q .99 max min avg q .50 q .75 q .90 q .95 q .99 max</figDesc><table><row><cell></cell><cell>T T , d = 0.2</cell><cell>7 33 13 21 101 119 224 298</cell><cell>7 22 14 14 17 33 105 4150</cell><cell>2 22</cell><cell>9 17 78 83 169 419</cell></row><row><cell></cell><cell>T E , d = 0.2</cell><cell cols="2">13 43 22 32 121 151 277 426 11 30 23 23 25 51 140 3566</cell><cell cols="2">7 23 18 24 33 59 77 1050</cell></row><row><cell>D A</cell><cell cols="5">T E , d = 0.4 T M , d = 0.2 21 63 56 78 100 122 305 477 22 61 58 58 65 78 204 4242 17 70 70 91 113 116 184 1281 10 35 20 25 59 122 305 491 10 29 19 20 22 45 136 4145 6 22 13 21 37 102 174 853</cell></row><row><cell></cell><cell cols="5">T M , d = 0.2 17 55 59 71 86 92 203 240 16 51 51 53 57 59 124 4283 15 56 61 80 88 93 108 1146</cell></row><row><cell></cell><cell cols="5">T H , d = 0.2 15 69 68 88 113 135 233 476 16 60 59 61 67 97 201 4285 15 66 66 85 105 110 202 1241</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Note that it is relatively easy to detect some patterns, e.g., dates, using basic RegEx. But a basic RegEx may have challenges understanding if a date belongs to the log record's timestamp field or if the date is part of a log message itself, which implies that developers will have to code up additional rules.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">There are ≈ 3.6 × 10 12 permutations of log formats that can be generated from these 15 fields. For efficiency, we only implemented these 15 fields out of 43 total possible Apache fields<ref type="bibr" target="#b24">[23]</ref>. The generator can be easily extended with additional fields, if required.<ref type="bibr" target="#b2">3</ref> In a real Apache HTTP server deployment, this field is extracted from the %i log parameter, see<ref type="bibr" target="#b24">[23]</ref> for details.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">The log records of V A and V B were wrapped in quotes ("), which makes them a slightly different format from ELF. While this is likely a product of processing and these quotes could be removed, we opted to keep them for training completeness.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">We used learning rate of 0.001, β 1 = 0.9, β 2 = 0.999, and = 10 −7 .</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Beehive: large-scale log analysis for detecting suspicious activity in enterprise networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Yen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oprea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Onarlioglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Leetham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">K</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Juels</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kirda</surname></persName>
		</author>
		<idno type="DOI">10.1145/2523649.2523670</idno>
		<ptr target="https://doi.org/10.1145/2523649.2523670" />
	</analytic>
	<monogr>
		<title level="m">Annual Computer Security Applications Conference, ACSAC &apos;13</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="199" to="208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Operational-log analysis for big data systems: Challenges and solutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">V</forename><surname>Miranskyy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hamou-Lhadj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Cialini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Larsson</surname></persName>
		</author>
		<idno type="DOI">10.1109/MS.2016.33</idno>
		<ptr target="https://doi.org/10.1109/MS.2016.33" />
	</analytic>
	<monogr>
		<title level="j">IEEE Software</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="52" to="59" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">An empirical study on the use of mutant traces for diagnosis of faults in deployed systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Murtaza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hamou-Lhadj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">H</forename><surname>Madhavji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gittens</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jss.2013.11.1094</idno>
		<ptr target="https://doi.org/10.1016/j.jss.2013.11.1094" />
	</analytic>
	<monogr>
		<title level="j">Journal of Systems and Software</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="page" from="29" to="44" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">An iterative, multi-level, and scalable approach to comparing execution traces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">V</forename><surname>Miranskyy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">H</forename><surname>Madhavji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gittens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wilding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Godwin</surname></persName>
		</author>
		<idno type="DOI">10.1145/1287624.1287704</idno>
		<ptr target="https://doi.org/10.1145/1287624.1287704" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th joint meeting of the European Software Engineering Conference and the ACM SIGSOFT International Symposium on Foundations of Software Engineering</title>
		<meeting>the 6th joint meeting of the European Software Engineering Conference and the ACM SIGSOFT International Symposium on Foundations of Software Engineering</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="537" to="540" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Inferring models of concurrent systems from logs of their behavior with csight</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Beschastnikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Brun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Ernst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<idno type="DOI">10.1145/2568225.2568246</idno>
		<ptr target="https://doi.org/10.1145/2568225.2568246" />
	</analytic>
	<monogr>
		<title level="m">36th International Conference on Software Engineering, ICSE &apos;14</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="468" to="479" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Gk-tail+ an efficient approach to learn software models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mariani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pezzè</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Santoro</surname></persName>
		</author>
		<idno type="DOI">10.1109/TSE.2016.2623623</idno>
		<ptr target="https://doi.org/10.1109/TSE.2016.2623623" />
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="715" to="738" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Semantic mediation for A posteriori log analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Dernaika</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Cuppens-Boulahia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Cuppens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Raynaud</surname></persName>
		</author>
		<idno type="DOI">10.1145/3339252.3340104</idno>
		<idno>ARES 2019</idno>
		<ptr target="https://doi.org/10.1145/3339252.3340104" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th International Conference on Availability, Reliability and Security</title>
		<meeting>the 14th International Conference on Availability, Reliability and Security</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="page" from="1" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Drain: An online log parsing approach with fixed depth tree</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Lyu</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICWS.2017.13</idno>
		<ptr target="https://doi.org/10.1109/ICWS.2017.13" />
	</analytic>
	<monogr>
		<title level="m">2017 IEEE International Conference on Web Services</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="33" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A search-based approach for accurate identification of log message formats</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Messaoudi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Panichella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bianculli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">C</forename><surname>Briand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sasnauskas</surname></persName>
		</author>
		<idno type="DOI">10.1145/3196321.3196340</idno>
		<ptr target="https://doi.org/10.1145/3196321.3196340" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th Conference on Program Comprehension, ICPC 2018</title>
		<meeting>the 26th Conference on Program Comprehension, ICPC 2018</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="167" to="177" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Sherlock: A deep learning approach to semantic data type detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hulsebos</surname></persName>
		</author>
		<idno type="DOI">10.1145/3292500.3330993</idno>
		<ptr target="https://doi.org/10.1145/3292500.3330993" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining, KDD 2019</title>
		<meeting>the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining, KDD 2019</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1500" to="1508" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Example-driven reconstruction of software models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Nierstrasz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kobel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Gîrba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lanza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bunke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">11th European Conference on Software Maintenance and Reengineering, Software Evolution in Complex Software Intensive Systems</title>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="275" to="286" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title/>
		<idno type="DOI">10.1109/CSMR.2007.23</idno>
		<ptr target="https://doi.org/10.1109/CSMR.2007.23" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Execution anomaly detection in distributed systems through unstructured log analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICDM.2009.60</idno>
		<ptr target="https://doi.org/10.1109/ICDM.2009.60" />
	</analytic>
	<monogr>
		<title level="m">ICDM 2009, The Ninth IEEE International Conference on Data Mining</title>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="149" to="158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A lightweight algorithm for message type extraction in system application logs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Makanju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Zincir-Heywood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">E</forename><surname>Milios</surname></persName>
		</author>
		<idno type="DOI">10.1109/TKDE.2011.138</idno>
		<ptr target="https://doi.org/10.1109/TKDE.2011.138" />
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1921" to="1936" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Spell: Streaming parsing of system event logs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICDM.2016.0103</idno>
		<ptr target="https://doi.org/10.1109/ICDM.2016.0103" />
	</analytic>
	<monogr>
		<title level="m">IEEE 16th International Conference on Data Mining, ICDM 2016</title>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="859" to="864" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A systematic literature review on automated log abstraction techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>El-Masri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Petrillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Guéhéneuc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hamou-Lhadj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bouziane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information and Software Technology</title>
		<imprint>
			<biblScope unit="volume">122</biblScope>
			<biblScope unit="page">106276</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.infsof.2020.106276</idno>
		<ptr target="https://doi.org/10.1016/j.infsof.2020.106276" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning phrase representations using RNN encoder-decoder for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Van Merrienboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ç</forename><surname>Gülçehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/d14-1179</idno>
		<ptr target="https://doi.org/10.3115/v1/d14-1179" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1724" to="1734" />
		</imprint>
	</monogr>
	<note>A meeting of SIGDAT, a Special Interest Group of the ACL. ACL</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<idno type="DOI">10.1162/neco.1997.9.8.1735</idno>
		<ptr target="https://doi.org/10.1162/neco.1997.9.8.1735" />
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<ptr target="http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 27: Annual Conference on Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1409.0473" />
	</analytic>
	<monogr>
		<title level="m">3rd International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Massive exploration of neural machine translation architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Britz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Goldie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<idno>abs/1703.03906</idno>
		<ptr target="http://arxiv.org/abs/1703.03906" />
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Effective approaches to attention-based neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/d15-1166</idno>
		<ptr target="https://doi.org/10.18653/v1/d15-1166" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, EMNLP 2015. The Association for Computational Linguistics</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing, EMNLP 2015. The Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1412" to="1421" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Google&apos;s neural machine translation system: Bridging the gap between human and machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<idno>abs/1609.08144</idno>
		<ptr target="http://arxiv.org/abs/1609.08144" />
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Apache module mod log config</title>
		<ptr target="https://httpd.apache.org/docs/current/mod/modlogconfig.html" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Faker package documentation</title>
		<ptr target="https://faker.readthedocs.io/en/master/#" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Generate a boatload of fake apache log files very quickly</title>
		<idno>kiritbasu/fake-apache-log-generator:</idno>
		<ptr target="https://github.com/kiritbasu/Fake-Apache-Log-Generator" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Log files</title>
		<ptr target="https://httpd.apache.org/docs/1.3/logs.html#combined" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">fake-useragent package documentation</title>
		<ptr target="https://fake-useragent.readthedocs.io/en/stable/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">examples/apache logs at master · elastic/examples</title>
		<ptr target="https://github.com/elastic/examples/blob/master/Common%20Data%20Formats/apachelogs/apachelogs" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Detection of attack-targeted scans from the apache http server access logs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">B</forename><surname>Seyyar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Gül</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.aci.2017.04.002</idno>
		<ptr target="https://doi.org/10.1016/j.aci.2017.04.002" />
	</analytic>
	<monogr>
		<title level="j">Applied Computing and Informatics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="28" to="36" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1412.6980" />
	</analytic>
	<monogr>
		<title level="m">3rd International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Binary codes capable of correcting deletions, insertions, and reversals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">I</forename><surname>Levenshtein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Soviet physics doklady</title>
		<imprint>
			<date type="published" when="1966" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="707" to="710" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Log generating tool</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Miranskyy</surname></persName>
		</author>
		<ptr target="https://github.com/WulffHunter/loggenerator" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Log parsing: generators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">--</forename></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.4536575</idno>
		<ptr target="https://doi.org/10.5281/zenodo.4536575" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Log parsing: datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">--</forename></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.4536514</idno>
		<ptr target="https://doi.org/10.5281/zenodo.4536514" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
