<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Learning Instance Occlusion for Panoptic Segmentation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Lazarow</surname></persName>
							<email>jlazarow@ucsd.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of California San Diego</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kwonjoon</forename><surname>Lee</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of California San Diego</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kunyu</forename><surname>Shi</surname></persName>
							<email>kshi@ucsd.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of California San Diego</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuowen</forename><surname>Tu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of California San Diego</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Learning Instance Occlusion for Panoptic Segmentation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T12:48+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Panoptic segmentation requires segments of both "things" (countable object instances) and "stuff" (uncountable and amorphous regions) within a single output. A common approach involves the fusion of instance segmentation (for "things") and semantic segmentation (for "stuff") into a non-overlapping placement of segments, and resolves overlaps. However, instance ordering with detection confidence do not correlate well with natural occlusion relationship. To resolve this issue, we propose a branch that is tasked with modeling how two instance masks should overlap one another as a binary relation. Our method, named OCFusion, is lightweight but particularly effective in the instance fusion process. OCFusion is trained with the ground truth relation derived automatically from the existing dataset annotations. We obtain state-of-the-art results on COCO and show competitive results on the Cityscapes panoptic segmentation benchmark.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Image understanding has been a long standing problem in both human perception <ref type="bibr" target="#b0">[1]</ref> and computer vision <ref type="bibr" target="#b24">[25]</ref>. The image parsing framework <ref type="bibr" target="#b34">[35]</ref> is concerned with the task of decomposing and segmenting an input image into constituents such as objects (text and faces) and generic regions through the integration of image segmentation, object detection, and object recognition. Scene parsing is similar in spirit and consists of both non-parametric <ref type="bibr" target="#b32">[33]</ref> and parametric <ref type="bibr" target="#b39">[40]</ref> approaches.</p><p>After the initial development, the problem of image understanding was studied separately as object detection (or extended to instance segmentation) and semantic segmentation. Instance segmentation <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b14">15]</ref> requires the detection and segmentation of each thing (countable object instance) within an image, while semantic segmentation <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b39">40]</ref> provides a dense perpixel classification without distinction between instances within the same thing category. Kirillov et al. <ref type="bibr" target="#b16">[17]</ref> proposed the panoptic segmentation task that combines the strength * indicates equal contribution. <ref type="figure">Figure 1</ref>: An illustration of fusion using masks sorted by detection confidence alone <ref type="bibr" target="#b16">[17]</ref> vs. with the ability to query for occlusions (OCFusion; ours). Occlude(A, B) = 0 in occlusion head means mask B should be placed on top of mask A. Mask R-CNN proposes three instance masks listed with decreasing confidence. The heuristic of <ref type="bibr" target="#b16">[17]</ref> occludes all subsequent instances after the "person", while our method retains them in the final output by querying the occlusion head.</p><p>of semantic segmentation and instance segmentation. In this task, each pixel in an image is assigned either to a background class (stuff ) or to a specific foreground object (an instance of things).</p><p>A common approach for panoptic segmentation has emerged in a number of works <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b37">38]</ref> that relies on combining the strong baseline architectures used in semantic segmentation and instance segmentation into either a separate or shared architecture and then fusing the results from the semantic segmentation and instance segmentation branches into a single panoptic output. Since there is no expectation of consistency in proposals between semantic and instance segmentation branches, conflicts must be resolved. Furthermore, one must resolve conflicts within the instance segmentation branch as it proposes segmentations indepen-  <ref type="figure">Figure 2</ref>: Illustration of the overall architecture. The FPN is used as a shared backbone for both thing and stuff branches. In thing branch, Mask R-CNN will generate instance mask proposals, and the occlusion head will output binary values Occlude(M i , M j ) (Equation 1) for each pair of mask proposals M i and M j with appreciable overlap (larger than a threshold) to indicate occlusion relation between them. Occlusion head architecture is described in Section 2.4. Fusion process is described in 2.3. dent of each other. While a pixel in the panoptic output can only be assigned to a single class and instance, instance segmentation proposals are often overlapping.</p><p>To handle these issues, Kirillov et al. <ref type="bibr" target="#b16">[17]</ref> proposed a fusion process similar to non-maximum suppression (NMS) that favors instance proposals over semantic proposals. However, we observe that occlusion relationships between different objects do not correlate well with object detection confidences used in this NMS-like fusion procedure <ref type="bibr" target="#b16">[17]</ref>, which therefore generally leads to poor performance when an instance that overlaps another (e.g., a tie on a shirt in Figure 3a) has lower detection confidence than the instance it should occlude. This can cause a large number of instances that Mask R-CNN successfully proposes fail to exist in the panoptic prediction (shown in <ref type="figure">Figure 1</ref>). Therefore, in this work, we focus on enriching the fusion process established by <ref type="bibr" target="#b16">[17]</ref> with a binary relationship between instances to determine occlusion ordering. We propose adding an additional branch (occlusion head) to the instance segmentation pipeline tasked with determining which of two instance masks should lie on top of (or below) the other to resolve occlusions in the fusion process. The proposed occlusion head can be fine-tuned easily on top of an existing Panoptic Feature Pyramid Networks (FPNs) <ref type="bibr" target="#b15">[16]</ref> architecture with minimal difficulty. We call our approach fusion with occlusion head (OCFusion). OC-Fusion brings significant performance gains on the COCO and Cityscapes panoptic segmentation benchmarks with low computational cost.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Learning Instance Occlusion for Panoptic Fusion</head><p>We adopt the coupled approach of <ref type="bibr" target="#b15">[16]</ref> that uses a shared Feature Pyramid Network (FPN) <ref type="bibr" target="#b20">[21]</ref> backbone with a topdown process for semantic segmentation branch and Mask R-CNN <ref type="bibr" target="#b9">[10]</ref> for instance segmentation branch.</p><p>In this section, we first discuss the instance occlusion problem arising within the fusion heuristic introduced in <ref type="bibr" target="#b16">[17]</ref> and then introduce OCFusion method to address the problem. The overall approach is shown in <ref type="figure">Figure 2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Fusion by confidence</head><p>The fusion protocol in <ref type="bibr" target="#b16">[17]</ref> adopts a greedy strategy during inference in an iterative manner. Instance proposals are first sorted in order of decreasing detection confidence. In each iteration, the proposal is skipped if its intersection with the mask of all already assigned pixels is above a certain ratio of τ . Otherwise, pixels in this mask that have yet to be assigned are assigned to the instance in the output. After all instance proposals of some minimum detection threshold are considered, the semantic segmentation is merged into the output by considering its pixels corresponding to each "stuff" class. If the number of pixels exceeds some threshold after removing already assigned pixels, then these pixels are assigned to the corresponding "stuff" category. Pixels that are unassigned after this entire process are considered void predictions and have special treatment in the panoptic scoring process. We denote this type of fusion as fusion by confidence.</p><p>Softening the greed. The main weakness of the greedy fusion process is the complete reliance on detection confidences (e.g. for Mask R-CNN, those from the box classification score) for a tangential task. Detection scores not only have little to do with mask quality (e.g., <ref type="bibr" target="#b12">[13]</ref>), but they also do not incorporate any knowledge of layout. If they are used in such a way, higher detection scores would imply a more foreground ordering. Often this is detrimental since Mask R-CNN exhibits behavior that can assign nearmaximum confidence to very large objects (e.g. see dining table images in <ref type="figure">Figure 3b</ref>) that are both of poor mask quality and not truly foreground. It is common to see images with a significant number of true instances suppressed in the panoptic output by a single instance with large area that was assigned the largest confidence.  <ref type="figure">Figure 3</ref>: Images and ground truth masks from the COCO dataset. (a) is an example where even predicting the ground truth mask creates ambiguity when attempting to assign pixels to instances in a greedy manner. The baseline fusion process <ref type="bibr" target="#b16">[17]</ref> is unable to properly assign these as shown in the 2nd and 4th images of the rightmost column whereas our method is able to handle the occlusion relationship present as shown in the 1st and 3rd images of the rightmost column. (b) is an example where Mask R-CNN baseline produces an instance prediction that occludes the entire image and creates the same ambiguity in (a) despite an unambiguous ground truth annotation.</p><p>Our approach softens this greedy fusion process with an occlusion head that is dedicated to predicting the binary relation between instances with appreciable overlap so that instance occlusions can be properly handled.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Occlusion head formulation</head><p>Consider two masks M i and M j proposed by an instance segmentation model, and denote their intersection as I ij = M i ∩ M j . We are interested in the case where one of the masks is heavily occluded by the other. Therefore, we consider their respective intersection ratios</p><formula xml:id="formula_0">R i = Area(I ij )/Area(M i ) and R j = Area(I ij )/Area(M j )</formula><p>where Area(M ) denotes the number of "on" pixels in mask M . As noted in Section 2.1, the fusion process considers the intersection of the current instance proposal with the mask consisting of all already claimed pixels. Here, we are looking at the intersection between two masks and denote the threshold as ρ. If either R i ≥ ρ or R j ≥ ρ, we define these two masks as having appreciable overlap. In this case, we must then decide which instance the pixels in I ij should belong to. We attempt to answer this by learning a binary relation Occlude(M i , M j ) such that whenever M i and M j have appreciable intersection:</p><formula xml:id="formula_1">Occlude(M i , M j ) = 1 if Mi should be placed on top of Mj 0 if Mj should be placed on top of Mi.</formula><p>(1)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Fusion with occlusion head</head><p>We now describe our modifications to the inference-time fusion heuristic of <ref type="bibr" target="#b16">[17]</ref> that incorporates Occlude(M i , M j ) in Algorithm 1.</p><p>After the instance fusion component has completed, the semantic segmentation is then incorporated as usual, only considering pixels assigned to stuff classes and determining whether the number of unassigned pixels corresponding to the class in the current panoptic output exceeds some threshold, e.g., 4096. The instance fusion process is illustrated in <ref type="figure">Figure 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Occlusion head architecture</head><p>We implement Occlude(M i , M j ) as an additional "head" within Mask R-CNN <ref type="bibr" target="#b9">[10]</ref>. Mask R-CNN already contains two heads: a box head that is tasked with taking region proposal network (RPN) proposals and refining the bounding box as well as assigning classification scores, while the mask head predicts a fixed size binary mask (usually 28 × 28) for all classes independently from the output of the box head. Each head derives its own set of features from the underlying FPN. We name our additional head, the "occlusion head" and implement it as a binary classifier that takes two (soft) masks M i and M j along with their respective FPN features (determined by their respective boxes) as input. The classifier output is interpreted as the value of Occlude(M i , M j ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Fusion with Occlusion Head.</head><p>P is H × W matrix, initially empty. ρ is a hyperparameter, the minimum intersection ratio for occlusion. τ is a hyperparameter.</p><p>for each proposed instance mask Mi do Ci = Mi − P pixels in Mi that are not assigned in P for j &lt; i do each already merged segment Iij is the intersection between mask Mi and Mj. Ri = Area(Iij)/Area(Mi).</p><formula xml:id="formula_2">Rj = Area(Iij)/Area(Mj). if Ri ≥ ρ or Rj ≥ ρ then significant intersection if Occlude(Mi, Mj) = 1 then Ci = Ci (Cj Iij). Cj = Cj − Iij. end if end if end for if Area(Ci)/Area(Mi) ≤ τ then continue else</formula><p>assign the pixels in Ci to the panoptic mask P . end if end for</p><p>The architecture of occlusion head is inspired by <ref type="bibr" target="#b12">[13]</ref> as shown in <ref type="figure">Figure 2</ref>. For two mask representations M i and M j , we apply max pooling to produce a 14 × 14 representation and concatenate each with the corresponding RoI features to produce the input to the head. Three layers of 3 × 3 convolutions with 512 feature maps and stride 1 are applied before a final one with stride 2. The features are then flattened before a 1024 dimensional fully connected layer and finally projected to a single logit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.">Ground truth occlusion</head><p>We use ground truth panoptic mask along with ground truth instance masks to derive ground truth occlusion relation. We pre-compute the intersection between all pairs of masks with appreciable overlap. We then find the pixels corresponding to the intersection of the masks in the panoptic ground truth. We determine the instance occlusion based on which instance owns the majority of pixels in the intersection. We store the resulting "occlusion matrix" for each image in an N i × N i matrix where N i is the number of instances in the image and the value at position (i, j) is either −1, indicating no occlusion, or encodes the value of Occlude(i, j).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6.">Occlusion head training</head><p>During training, the occlusion head is designed to first find pairs of predicted masks that match to different ground truth instances. Then, the intersection between these pairs of masks is computed, and the ratio of the intersection to mask area taken. A pair of masks is added for consideration when one of these ratios is at least as large as the pre-determined threshold ρ. We then subsample the set of all pairs meeting this criterion to decrease computational cost. It is desirable for the occlusion head to reflect the consistency of Occlude, therefore we also invert all pairs so that Occlude(M i , M j ) = 0 ⇐⇒ Occlude(M j , M i ) = 1 whenever the pair (M i , M j ) meets the intersection criteria. This also mitigates class imbalance. Since this is a binary classification problem, the overall loss L o from the occlusion head is given by the binary cross-entropy over all subsampled pairs of masks that meet the intersection criteria.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Related work</head><p>Next, we discuss in detail the difference between OCFusion and the existing approaches for panoptic segmentation, occlusion ordering, and non-maximum suppression. Panoptic segmentation. The task of panoptic segmentation is introduced in <ref type="bibr" target="#b16">[17]</ref> along with a baseline where predictions from instance segmentation (Mask R-CNN <ref type="bibr" target="#b9">[10]</ref>) and semantic segmentation (PSPNet <ref type="bibr" target="#b39">[40]</ref>) are combined via a heuristics-based fusion strategy. A stronger baseline based on a single Feature Pyramid Network (FPN) <ref type="bibr" target="#b20">[21]</ref> backbone followed by multi-task heads consisting of semantic and instance segmentation branches is concurrently proposed by <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b37">38]</ref>. On top of this baseline, attention layers are added in <ref type="bibr" target="#b18">[19]</ref> to the instance segmentation branch, which are guided by the semantic segmentation branch; a loss term enforcing consistency between things and stuff predictions is then introduced in [18]; a parameter-free panoptic head which computes the final panoptic mask by pasting instance mask logits onto semantic segmentation logits is presetned in <ref type="bibr" target="#b37">[38]</ref>. These works have been making steady progress in panoptic segmentation, but their focus is not to address the problem for explicit reasoning of instance occlusion. Occlusion ordering and layout learning. Occlusion handling is a long-studied computer vision task <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b10">11]</ref>. In the context of semantic segmentation, occlusion ordering has been adopted in <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b41">42]</ref>. A repulsion loss is added to a pedestrian detection algorithm <ref type="bibr" target="#b36">[37]</ref> to deal with the crowd occlusion problem, but it focuses on detection only, without instance segmentation. In contrast, we study the occlusion ordering problem for instance maps in panoptic segmentation. Closest to our method is the recent work of <ref type="bibr" target="#b22">[23]</ref>, which proposes a panoptic head to resolve this issue in a similar manner to <ref type="bibr" target="#b37">[38]</ref> but instead with a learnable convolution layer. Since our occlusion head can deal with two arbitrary masks, it offers more flexibility over these approaches which attempt to "rerank" the masks in a linear fashion <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b22">23]</ref>. Furthermore, the approach of <ref type="bibr" target="#b22">[23]</ref> is based off how a class should be placed on top of another class (akin to semantic segmentation) while we explicitly model the occlusion relation between arbitrary instances. This allows us to leverage the intra-class occlusion relations such as "which of these two persons should occlude the other?", and we show this leads to a gain in <ref type="figure" target="#fig_4">Figure 7</ref> and <ref type="table">Table 9</ref>. In a nutshell, we tackle the occlusion problem in a scope that is more general than <ref type="bibr" target="#b22">[23]</ref> with noticeable performance advantage, as shown in <ref type="table" target="#tab_2">Table 2</ref> and <ref type="table" target="#tab_3">Table 3</ref>. Learnable NMS. One can relate resolving occlusions to non-maximum suppression (NMS) that is applied to boxes, while our method tries to suppress intersections between masks. Our method acts as a learnable version of NMS for instance masks with similar computations to the analogous ideas for boxes such as <ref type="bibr" target="#b11">[12]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Implementation details</head><p>We extend the Mask R-CNN benchmark framework <ref type="bibr" target="#b25">[26]</ref>, built on top of PyTorch, to implement our architecture. Batch normalization <ref type="bibr" target="#b13">[14]</ref> layers are frozen and not fine-tuned for simplicity. We perform experiments on the COCO dataset <ref type="bibr" target="#b21">[22]</ref> [17] as well as the Cityscapes dataset <ref type="bibr" target="#b3">[4]</ref> with panoptic annotations.</p><p>We find the most stable and efficient way to train the occlusion head is by fine-tuning with all other parameters frozen. We add a single additional loss only at fine-tuning time so that the total loss during panoptic training is L = λ i (L c + L b + L m ) + λ s L s where L c , L b , and L m are the box head classification loss, bounding-box regression loss, and mask loss while L s is the semantic segmentation crossentropy loss. At fine-tuning time, we only minimize L o , the classification loss from the occlusion head. We subsample 128 mask occlusions per image.</p><p>During fusion, we only consider instance masks with detection confidence of at least 0.5 or 0.6 and reject segments during fusion when their overlap ratio with the existing panoptic mask (after occlusions are resolved) exceeds τ = 0.5 on COCO and τ = 0.6 on Cityscapes. Lastly, when considering the segments of stuff generated from the semantic segmentation, we only consider those which have at least 4096 pixels remaining after discarding those already assigned on COCO and 2048 on Cityscapes. Semantic head. On COCO, repeat the combination of 3 × 3 convolution and 2× bilinear upsampling until 1/4 scale is reached, following the design of <ref type="bibr" target="#b15">[16]</ref>. For the model with ResNeXt-101 backbone, we replace each convolution with deformable convolution <ref type="bibr" target="#b5">[6]</ref>. For ResNet-50 backbone, we additionally add one experiment that adopts the design from <ref type="bibr" target="#b37">[38]</ref> which uses 2 layers of deformable convolution followed by a bilinear upsampling to the 1/4 scale. On Cityscapes, we adopt the design from <ref type="bibr" target="#b37">[38]</ref>. COCO. The COCO 2018 panoptic segmentation task con-sists of 80 thing and 53 stuff classes. We use 2017 dataset which has a split of 118k/5k/20k for training, validation and testing respectively. Cityscapes. Cityscapes consists of 8 thing classes and 11 stuff classes. We use only fine dataset with a split of 2975/500/1525 for training, validation and testing respectively. COCO training. We train the FPN-based architecture described in <ref type="bibr" target="#b15">[16]</ref> for 90K iterations on 8 GPUs with 1 image per GPU. The base learning rate of 0.02 is reduced by 10 at both 60k and 80k iterations. We then proceed to fine-tune with the occlusion head for 2500 more iterations. We choose λ i = 1.0 and λ s = 0.5 while for the occlusion head we choose the intersection ratio ρ as 0.2. For models with ResNet-50 and ResNet-101 backbone, we use random horizontal flipping as data augmentation. For model with ResNeXt-101 backbone, we additionally use scale jitter (with scale of shorter image edge equals to {640, 680, 720, 760, 800}). Cityscapes training. We randomly rescale each image by 0.5 to 2× (scale factor sampled from a uniform distribution) and construct each batch of 16 (4 images per GPU) by randomly cropping images of size 512 × 1024. We train for 65k iterations with a base learning rate of 0.01 with decay at 40k and 55k iterations. We fine-tune the occlusion head for 5000 more iterations. We choose λ i = λ s = 1.0 with intersection ratio ρ as 0.1. We do not pretrain on COCO. Panoptic segmentation metrics. We adopt the panoptic quality (PQ) metric from <ref type="bibr" target="#b16">[17]</ref> to measure panoptic segmentation performance. This single metric captures both segmentation and recognition quality. PQ can be further broken down into scores specific to things and stuff, denoted PQ Th and PQ St , respectively. Multi-scale testing. We adopt the same scales as <ref type="bibr" target="#b37">[38]</ref> for both COCO and Cityscapes multi-scale testing. For the stuff branch, we average the multi-scale semantic logits of semantic head. For the thing branch, we average the multiscale masks and choose not to do bounding box augmentation for simplicity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Backbone   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">COCO panoptic benchmark</head><p>We obtain state-of-the-art results on COCO Panoptic Segmentation validation set with and without multi-scale testing as is shown in 2. We also obtain single model stateof-the-art results on the COCO test-dev set, as shown in Table <ref type="bibr" target="#b2">3</ref>. In order to show the effectiveness of our method, we compare to our baseline model in <ref type="table" target="#tab_1">Table 1</ref>, and the results show that our method consistently provides significant gain on PQ Th as well as PQ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Cityscapes panoptic benchmark</head><p>We obtain competitive results on the Cityscapes validation set and the best results among models with a ResNet-50 backbone, shown in <ref type="table" target="#tab_6">Table 5</ref>. <ref type="table" target="#tab_5">Table 4</ref> shows our strong relative improvement over the baseline on PQ Th as well as PQ.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Occlusion head performance</head><p>In order to better gauge the performance of the occlusion head, we determine its classification accuracy on both COCO and Cityscapes validation dataset at ρ = 0.20 with ResNet-50 backbone. We measure the accuracy of the occlusion head in predicting the true ordering given ground truth boxes and masks. The occlusion head classification accuracy on COCO and Cityscapes is 91.58% and 93.60%, respectively, which validates the effectiveness of OCFusion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Inference time analysis</head><p>We analyze the computational cost of our method and empirically show the inference time overhead of our method compared to the baseline model. While our method incurs an O(n 2 ) cost in order to compute pairwise intersections, where n is the number of instances, this computation is only needed for the subset of masks whose detection confidence is larger than a threshold (0.5 or 0.6 usually) as dictated by the Panoptic FPN <ref type="bibr" target="#b15">[16]</ref> baseline. This filtering greatly limits    <ref type="bibr" target="#b37">[38]</ref>.</p><p>the practical magnitude of n. Furthermore, only the subset of remaining mask pairs that have appreciable overlap (larger than ρ) requires evaluation by the occlusion head. We measure this inference time overhead in <ref type="table" target="#tab_7">Table 6</ref>. OC-Fusion incurs a modest 2.0% increase in computational time on COCO and 4.7% increase on Cityscapes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method COCO Cityscapes</head><p>Baseline 153 378 OCFusion 156 396 Change in runtime (ms) +3 +18 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.">Visual comparisons</head><p>Since panoptic segmentation is a relatively new task, the most recent papers offer only comparisons against the baseline presented in <ref type="bibr" target="#b16">[17]</ref>. We additionally compare with a few other recent methods <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b37">38]</ref>.</p><p>We first compare our method against <ref type="bibr" target="#b15">[16]</ref> in <ref type="figure" target="#fig_1">Figure 4</ref> as well as two recent works: UPSNet <ref type="bibr" target="#b37">[38]</ref> in <ref type="figure" target="#fig_3">Figure 6</ref> and the Spatial Ranking Module of <ref type="bibr" target="#b22">[23]</ref> in <ref type="figure" target="#fig_2">Figure 5</ref>. The latter two have similar underlying architectures alongside modifications to their fusion process. We note that except for comparisons between <ref type="bibr" target="#b15">[16]</ref>, the comparison images shown are those included in the respective papers and not of our own choosing. Overall, we see that our method is able to preserve a significant number of instance occlusions lost by other methods while maintaining more realistic fusions, e.g., the arm is entirely above the man versus sinking behind partly as in "fusion by confidence". </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7.">Ablation experiments</head><p>We study the sensitivity of our method to the hyperparameters τ and ρ in <ref type="table" target="#tab_9">Table 7</ref> for COCO and <ref type="table" target="#tab_10">Table 8</ref> for Cityscapes. We also include the number of examples of occlusions we are able to collect at the given ρ denoted as N. Naturally, a larger ρ leads to less spurious occlusions but <ref type="bibr">(</ref>   decreases the overall number of examples that the occlusion head is able to learn from. Intra-class instance occlusion in Cityscapes is a challenging problem, also noted in <ref type="bibr" target="#b9">[10]</ref>. Since we can enable inter-class or intra-class occlusion query ability independently, we show ablation results in <ref type="table">Table 9</ref> that highlight the importance of being able to handle intra-class occlusion on. We believe this sets our method apart from others, e.g., <ref type="bibr" target="#b22">[23]</ref> which simplifies the problem by handling inter-class occlusion only. Additionally, <ref type="figure" target="#fig_4">Figure 7</ref> shows a visual comparison between resulting panoptic segmentations when intraclass occlusion handling is toggled on Cityscapes. Only the model with intra-class handling enabled can handle the occluded cars better during the fusion process.  <ref type="table">Table 9</ref>: Ablation study on different types of occlusion on the Cityscapes val dataset. means capability enabled.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Inter-class</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>We have introduced an explicit notion of instance occlusion to Mask R-CNN so that instances may be effectively fused when producing a panoptic segmentation. We assemble a dataset of occlusions already present in the COCO and Cityscapes datasets and then learn an additional head for Mask R-CNN tasked with predicting occlusion between two masks. Adding occlusion head on top of Panoptic FPN incurs minimal overhead, and we show that it is effective even when trained for few thousand iterations. In the future, we hope to explore how further understanding of occlusion, including relationships of stuff, could be helpful.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 :</head><label>4</label><figDesc>Comparison against Kirillov et al.<ref type="bibr" target="#b15">[16]</ref> which uses fusion by confidence.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5 :</head><label>5</label><figDesc>Comparison against Spatial Ranking Module [23].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 6 :</head><label>6</label><figDesc>Comparison against UPSNet</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 7 :</head><label>7</label><figDesc>Comparison for w/o (left) or w/ (right) intraclass capability enabled. Best viewed in color.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>+0.5) 53.0 (+1.3) 63.6 (+0.0) 59.3 (+0.7) 53.5 (+1.7) 63.6 (+0.0)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>1 Instance i class box Instance j Occlusion matrix Occlude ( , ) Input Convolution and Upsample Mask head Stuff branch Thing branch Fusion module Instance masks Stuff map Output Occlusion head</head><label></label><figDesc></figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>PQ PQ Th PQ St Comparison to our implementation of Panoptic FPN<ref type="bibr" target="#b15">[16]</ref> baseline model on the MS-COCO val dataset.</figDesc><table><row><cell>Baseline</cell><cell>ResNet-50 39.5 46.5 29.0</cell></row><row><cell>OCFusion</cell><cell>ResNet-50 41.3 49.4 29.0</cell></row><row><cell>relative improvement</cell><cell>+1.8 +3.0 +0.0</cell></row><row><cell>Baseline</cell><cell>ResNet-101 41.0 47.9 30.7</cell></row><row><cell>OCFusion</cell><cell>ResNet-101 43.0 51.1 30.7</cell></row><row><cell>relative improvement</cell><cell>+2.0 +3.2 +0.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Comparison to prior work on the MS-COCO val dataset. m.s. stands for multi-scale testing.</figDesc><table><row><cell>Method</cell><cell cols="2">Backbone m.s. test PQ PQ Th PQ St</cell></row><row><cell>JSIS-Net [7]</cell><cell>ResNet-50</cell><cell>27.2 29.6 23.4</cell></row><row><cell cols="2">Panoptic FPN [16] ResNet-101</cell><cell>40.9 48.3 29.7</cell></row><row><cell>OANet [23]</cell><cell>ResNet-101</cell><cell>41.3 50.4 27.7</cell></row><row><cell>AUNet [19]</cell><cell>ResNeXt-152</cell><cell>46.5 55.9 32.5</cell></row><row><cell>UPSNet  *  [38]</cell><cell>ResNet-101</cell><cell>46.6 53.2 36.7</cell></row><row><cell>AdaptIS [31]</cell><cell>ResNeXt-101</cell><cell>42.8 50.1 31.8</cell></row><row><cell>OCFusion  *</cell><cell>ResNeXt-101</cell><cell>46.7 54.0 35.7</cell></row></table><note>* Used de- formable convolution.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Comparison to prior work on the MS-COCO test-dev dataset. m.s. stands for multi-scale testing.</figDesc><table /><note>* Used deformable convolution.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Comparison to our implementation of Panoptic FPN [16] baseline model on the Cityscapes val dataset.</figDesc><table><row><cell cols="3">All results are based on a ResNet-50 backbone.</cell></row><row><cell>Method</cell><cell>m.s. test</cell><cell>PQ PQ Th PQ St</cell></row><row><cell>Panoptic FPN [16]</cell><cell></cell><cell>57.7 51.6 62.2</cell></row><row><cell>AUNet [19]</cell><cell></cell><cell>56.4 52.7 59.0</cell></row><row><cell>UPSNet  *  [38]</cell><cell></cell><cell>59.3 54.6 62.7</cell></row><row><cell>UPSNet  *  [38]</cell><cell></cell><cell>60.1 55.0 63.7</cell></row><row><cell>AdaptIS [31]</cell><cell></cell><cell>59.0 55.8 61.3</cell></row><row><cell>OCFusion  *</cell><cell></cell><cell>59.3 53.5 63.6</cell></row><row><cell>OCFusion  *</cell><cell></cell><cell>60.2 54.0 64.7</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 :</head><label>5</label><figDesc>Comparison to prior work on the Cityscapes val dataset. All results are based on a ResNet-50 backbone. m.s. stands for multi-scale testing.</figDesc><table /><note>* Used deformable con- volution.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 6 :</head><label>6</label><figDesc>Runtime (ms) overhead per image.</figDesc><table><row><cell>Runtime re-</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>τ , ρ) 0.05 0.10 0.20 0.4 41.27 (Th: 49.43, St: 28.97) 41.22 (Th: 49.33, St: 28.97) 41.20 (Th: 49.30, St: 28.97) 0.5 41.20 (Th: 49.32, St: 28.95) 41.15 (Th: 49.23, St: 28.95) 41.24 (Th: 49.29, St: 29.10) 0.6 41.09 (Th: 49.15, St: 28.93) 41.03 (Th: 49.03, St: 28.93) 41.02 (Th: 49.02, St: 28.93)</figDesc><table><row><cell>N</cell><cell>192,519</cell><cell>157,784</cell><cell>132,165</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 7 :</head><label>7</label><figDesc>COCO Hyperparameter Ablation: PQ Th: 52.10, St: 63.62) 59.15 (Th: 53.00, St: 63.62) 59.07 (Th: 52.80, St: 63.63) 0.5 59.18 (Th: 53.09, St: 63.61) 59.26 (Th: 53.28, St: 63.61) 59.22 (Th: 53.19, St: 63.61) 0.6 59.21 (Th: 53.17, St: 63.61) 59.33 (Th: 53.46, St: 63.60) 58.70 (Th: 51.96, St: 61.</figDesc><table><row><cell cols="2">(τ , ρ) 0.05</cell><cell>0.10</cell><cell>0.20</cell></row><row><cell cols="4">0.4 58.76 (60)</cell></row><row><cell>N</cell><cell>33,391</cell><cell>29,560</cell><cell>6,617</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 8 :</head><label>8</label><figDesc>Cityscapes Hyperparameter Ablation: PQ</figDesc><table /><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgements. This work is supported by NSF IIS-1618477 and IIS-1717431. We thank Yifan Xu, Weijian Xu, Sainan Liu, Yu Shen, and Subarna Tripathi for valuable discussions. Also, we appreciate the anonymous reviewers for their helpful and constructive comments and suggestions.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Recognition-by-components: a theory of human image understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irving</forename><surname>Biederman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">115</biblScope>
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iasonas</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="834" to="848" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Multiinstance object segmentation with occlusion handling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaokai</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The cityscapes dataset for semantic urban scene understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>Cordts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Omran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Ramos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Rehfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Enzweiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>Benenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uwe</forename><surname>Franke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Instance-aware semantic segmentation via multi-task network cascades</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jifeng</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Deformable convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jifeng</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haozhi</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuwen</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Panoptic segmentation with a joint semantic and instance segmentation network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Panagiotis</forename><surname>Daan De Geus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gijs</forename><surname>Meletis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dubbelman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.02110</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Multi-cue pedestrian classification with partial occlusion handling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Enzweiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Eigenstetter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dariu M</forename><surname>Gavrila</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The pascal visual object classes (voc) challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Everingham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">I</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Piotr Dollár, and Ross Girshick. Mask r-cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgia</forename><surname>Gkioxari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Recovering occlusion boundaries from a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Derek</forename><surname>Hoiem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martial</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning non-maximum suppression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Hosang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>Benenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Mask scoring r-cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaojin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lichao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongchao</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinggang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Object detection free instance segmentation with labeling transformations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeyu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuowen</forename><surname>Tu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.08991</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Panoptic feature pyramid networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kirillov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note>Kaiming He, and Piotr Dollár</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Panoptic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kirillov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carsten</forename><surname>Rother</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Dollár</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Allan</forename><surname>Raventos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arjun</forename><surname>Bhargava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takaaki</forename><surname>Tagawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrien</forename><surname>Gaidon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.01192</idno>
		<title level="m">Learning to fuse things and stuff</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Attention-guided unified network for panoptic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinze</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingxi</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dalong</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Proposal-free network for instance-level object segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodan</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunchao</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohui</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianchao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuicheng</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="2978" to="2991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Feature pyramid networks for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bharath</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><forename type="middle">J</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Microsoft coco: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">An end-to-end network for panoptic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huanyu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changqian</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingbo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Fully convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Vision: A computational investigation into the human representation and processing of visual information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Marr</surname></persName>
		</author>
		<idno>1982. 1</idno>
		<imprint>
			<publisher>henry holt and co. Inc</publisher>
			<pubPlace>New York, NY</pubPlace>
		</imprint>
	</monogr>
	<note>2(4.2</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">maskrcnn-benchmark: Fast, modular reference implementation of Instance Segmentation and Object Detection algorithms in PyTorch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<ptr target="https://github.com/facebookresearch/maskrcnn-benchmark" />
		<imprint>
			<date type="published" when="2018-01-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Learning to segment object candidates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Pedro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Pinheiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dollar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Learning to refine object segments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pedro</forename><forename type="middle">O</forename><surname>Pinheiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Dollr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Hough regions for joining instance localization and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hayko</forename><surname>Riemenschneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sabine</forename><surname>Sternig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Donoser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Horst</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bischof</surname></persName>
		</author>
		<idno>ECCV. 2012. 1</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Textonboost: Joint appearance, shape and context modeling for multi-class object recognition and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Shotton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carsten</forename><surname>Rother</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Criminisi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Adaptis: Adaptive instance selection network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantin</forename><surname>Sofiiuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Barinova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anton</forename><surname>Konushin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Symmetric stereo matching for occlusion handling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Sing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heung-Yeung</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Scene parsing with object instances and occlusion ordering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Tighe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Niethammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Svetlana</forename><surname>Lazebnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Auto-context and its application to high-level vision tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuowen</forename><surname>Tu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Image parsing: Unifying segmentation, detection, and recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuowen</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangrong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song-Chun</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="113" to="140" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">An hog-lbp human detector with partial occlusion handling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tony</forename><forename type="middle">X</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuicheng</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Repulsion loss: Detecting pedestrians in a crowd</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinlong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tete</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuning</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuai</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In CVPR</title>
		<imprint>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Upsnet: A unified panoptic segmentation network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuwen</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renjie</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ersin</forename><surname>Yumer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Instancelevel segmentation for autonomous driving with deep densely connected mrfs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanja</forename><surname>Fidler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Pyramid scene parsing network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojuan</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuai</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadeep</forename><surname>Jayasumana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernardino</forename><surname>Romera-Paredes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vibhav</forename><surname>Vineet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhizhong</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dalong</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip Hs</forename><surname>Torr</surname></persName>
		</author>
		<title level="m">Conditional random fields as recurrent neural networks. In ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Semantic amodal segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuandong</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><surname>Metaxas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Dollár</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
