<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">HOList: An Environment for Machine Learning of Higher-Order Theorem Proving</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kshitij</forename><surname>Bansal</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
								<address>
									<addrLine>Mountain View</addrLine>
									<region>California</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarah</forename><forename type="middle">M</forename><surname>Loos</surname></persName>
							<email>smloos@google.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
								<address>
									<addrLine>Mountain View</addrLine>
									<region>California</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><forename type="middle">N</forename><surname>Rabe</surname></persName>
							<email>mrabe@google.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
								<address>
									<addrLine>Mountain View</addrLine>
									<region>California</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
							<email>szegedy@google.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
								<address>
									<addrLine>Mountain View</addrLine>
									<region>California</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stewart</forename><surname>Wilcox</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Google Research</orgName>
								<address>
									<addrLine>Mountain View</addrLine>
									<region>California</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">HOList: An Environment for Machine Learning of Higher-Order Theorem Proving</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>Preprint, compiled November 5, 2019</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T22:19+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present an environment, benchmark, and deep learning driven automated theorem prover for higher-order logic. Higher-order interactive theorem provers enable the formalization of arbitrary mathematical theories and thereby present an interesting, open-ended challenge for deep learning. We provide an open-source framework based on the HOL Light theorem prover that can be used as a reinforcement learning environment. HOL Light comes with a broad coverage of basic mathematical theorems on calculus and the formal proof of the Kepler conjecture, from which we derive a challenging benchmark for automated reasoning. We also present a deep reinforcement learning driven automated theorem prover, DeepHOL, with strong initial results on this benchmark.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Formalization of mathematics and the automated creation of new mathematical content is at the frontier of current AI techniques. Given the fundamental nature of mathematics and its importance for most scientific disciplines, the capability for high level formal mathematical reasoning is both an important practical task as well as one of the most challenging case studies in AI. However, traditional formal computer mathematics has been a fragmented domain, exploring various approaches for different logical foundations. This has led to a large number of incompatible theorem proving systems, which added extra challenges for AI researchers trying to push the limits of formal reasoning using machine learning.</p><p>Well-defined, large-scale benchmarks were instrumental for unifying disparate efforts in machine learning research: Lib-riSpeech <ref type="bibr" target="#b0">[1]</ref> for speech recognition, the Netflix prize <ref type="bibr" target="#b1">[2]</ref> for recommendation, ImageNet <ref type="bibr" target="#b2">[3]</ref> for object recognition, MSCOCO <ref type="bibr" target="#b4">[4]</ref> for object detection and segmentation, WMT <ref type="bibr" target="#b5">[5]</ref> for machine translation, and SQuAD <ref type="bibr" target="#b6">[6]</ref> for question answering -just to name a couple of examples. Benchmarks have fostered collaboration and competition and provide a means to measure progress, contributing significantly to accelerated progress and reproducible science.</p><p>This paper provides a benchmark and reinforcement learning environment for theorem proving. The long-term goal is to enable the automatic formalization of large theories, and hence we want to start with a theorem proving system that has a track-record of large-scale formalization efforts and includes a large corpus of foundational mathematics for benchmarking and learning. Our choice fell on HOL Light, the interactive theorem prover (ITP) in which the proof of the Kepler conjecture <ref type="bibr" target="#b7">[7]</ref> has been formalized. The formalization of the proof of the Kepler conjecture has been a huge effort, taking over 20 person-years to complete, and required formalizing a significant part of arithmetic, linear algebra, and multivariate analysis. The resulting benchmark consists of 2199 definitions and 29462 theorems and lemmata, which capture a variety of interesting mathematics and should be a practical seed for new (auto-)formalization efforts.</p><p>To demonstrate the feasibility of the proposed learning task, we present an automated theorem prover powered by deep learning, called DeepHOL. Based on a simple solver architecture, DeepHOL learns to prove theorems based on imitating human proofs and improves itself using reinforcement learning. Given a proof goal (represented as a string) DeepHOL learns to predict the tactic (and its arguments) that leads to a successful proof. Thereby, DeepHOL achieves theorem proving capabilities that are comparable to much more complicated state-of-the-art automated theorem proving systems. In our open-source release, available at http://deephol.org, we expose the APIs of our modular theorem prover. This simplifies the development of new provers significantly and allows researchers to focus on the machine learning aspects.</p><p>The contributions of our work are the following:</p><p>• An instrumented, pre-packaged version of HOL Light that can be used as a reinforcement learning environment for theorem proving using our well-defined, stable Python API. Our solution comes with optimized startup capabilities for proof search, while allowing replay and strict verification of the produced proofs. • Proof export and import capabilities that allow for managing large theories programmatically from the Python interface. • A full-fledged, competitive automated neural theorem proving system that can automatize theorem proving in higher-order logic at tactic level directly. • A large scale reinforcement learning system that was used for training our prover. • Comparison of neural model architectures for theorem proving purposes. • Well-defined benchmarks on our HOL Light based environment to enable research and measuring progress of AI driven theorem proving in large theories.</p><p>This paper is organized as follows. We discuss related work in Section 2 before we describe our theorem proving environment in Section 3. In Section 4 we present the organization of the benchmark. The DeepHOL automated theorem prover is described in Section 5 and we discuss first experimental results for it in Section 6. Then we conclude in Section 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>The earliest work of applying machine learning on reasoning in large theories is <ref type="bibr" target="#b9">[8]</ref>. The most most similar works to ours are TacticToe <ref type="bibr" target="#b10">[9]</ref> and GamePad <ref type="bibr" target="#b11">[10]</ref>. TacticToe is the first published result on machine learning tackling higher-order theorem proving at a relatively large scale at tactic level <ref type="bibr" target="#b10">[9]</ref>. Although TacticToe is a great success that came with significant improvements over previous automated theorem proving systems, they do not propose an easy to use benchmark or environment for machine learning researchers. TacticToe does not employ deep learning nor reinforcement learning. They rely on the HOL4 <ref type="bibr" target="#b12">[11]</ref> system that has a significantly less theorems with more complex human proof scripts with a larger number of more elementary tactics.</p><p>GamePad has very similar objectives to ours <ref type="bibr" target="#b11">[10]</ref>. They also provide an easy-to-use Python API for an interactive theorem prover, and they present test and training sets. They chose to base their system on Coq <ref type="bibr" target="#b13">[12]</ref>, an interactive theorem prover based on the calculus of inductive constructions. While enabling automatic code extraction, it comes with a much smaller coverage of fundamental mathematics. Even including the formalization of the Feit-Thompson theorem, their benchmark comprises only 1602 theorems and lemmas, while ours features 29462 theorems and lemmas. Besides presenting a much larger data set, we also demonstrate the feasibility of achieving state-of-the-art prover performance based on our data and environment by presenting a deep learning based theorem prover. We also report the results as theorem proving performance instead of proxy metrics.</p><p>Other interactive theorem provers we could have based a learning environment on include Mizar <ref type="bibr" target="#b14">[13]</ref>, Isabelle <ref type="bibr" target="#b15">[14]</ref>, HOL4 <ref type="bibr" target="#b12">[11]</ref>, and Lean <ref type="bibr" target="#b16">[15]</ref>. The Mizar mathematical library is probably the most comprehensive formalization effort, but its declarative style makes it hard to employ proof search, and its source code is not freely available. Like Coq and HOL Light, also Isabelle <ref type="bibr" target="#b15">[14]</ref> was used for major formalization efforts, such as the formalization of the seL4 microkernel <ref type="bibr" target="#b17">[16]</ref>. We are not aware of a comprehensive coverage of fundamental mathematics in Isabelle, HOL4, or Lean.</p><p>In closely related work, Kaliszyk and Urban <ref type="bibr" target="#b18">[17]</ref> translate from HOL Light and Flyspeck to automated theorem provers and SMT solvers, for which they learn a premise selector. In contrast to our work, they use neither deep learning nor reinforcement learning. Similar methods for premise selection on the HOL Light corpora were proposed in <ref type="bibr" target="#b19">[18]</ref>.</p><p>The first use of deep neural networks for large scale theorem proving was proposed in <ref type="bibr" target="#b20">[19]</ref>. They have used convolutional networks for premise selection in large theories, particularly on Mizar mathematical library <ref type="bibr" target="#b14">[13]</ref>. Those methods were used as a pre-selection for applying the first order logic automated theorem prover E <ref type="bibr" target="#b21">[20]</ref>. We have reused several ideas from that paper, including some aspects of our neural network architecture and the hard negative mining methodology.</p><p>Whalen <ref type="bibr" target="#b22">[21]</ref> proposed a purely deep reinforcement learning based solution for theorem proving for the Metamath prover <ref type="bibr" target="#b23">[22]</ref>. This work was moderately successful, finding mostly proofs for very simple theorems, especially in propositional logic. On the other hand, Metamath is not considered to be a serious contender for large scale mathematical formalization work.</p><p>Loos et al. <ref type="bibr" target="#b24">[23]</ref> proposed deep neural networks to augment theorem prover E <ref type="bibr" target="#b21">[20]</ref> to rank given clauses during proof search.</p><p>Here, we propose a neural prover written from scratch, relying solely on a small set of preexisting tactics and neural networks for all high level decisions.</p><p>Kaliszyk et al. <ref type="bibr" target="#b25">[24]</ref> proposed a machine learning benchmark for higher-order logic reasoning based on the HOL Light corpus. It features a few static datasets and it remains unclear how performance of machine learning models on this dataset relates to real world prover performance. <ref type="bibr" target="#b26">[25]</ref> demonstrated the viability of reinforcement learning with XGBoost and LIBLINEAR <ref type="bibr" target="#b27">[26]</ref> on hand engineered features in first order logic context using leanCoP <ref type="bibr" target="#b28">[27]</ref> on Mizar mathematical library <ref type="bibr" target="#b14">[13]</ref>.</p><p>Earlier works on employing (non-deep) machine learning for theorem proving in general and for reasoning in large theories include <ref type="bibr" target="#b29">[28,</ref><ref type="bibr" target="#b30">29,</ref><ref type="bibr" target="#b31">30,</ref><ref type="bibr" target="#b32">31,</ref><ref type="bibr" target="#b33">32,</ref><ref type="bibr" target="#b34">33,</ref><ref type="bibr" target="#b35">34,</ref><ref type="bibr" target="#b36">35,</ref><ref type="bibr" target="#b37">36,</ref><ref type="bibr" target="#b39">37,</ref><ref type="bibr" target="#b40">38,</ref><ref type="bibr" target="#b41">39,</ref><ref type="bibr" target="#b42">40,</ref><ref type="bibr" target="#b43">41,</ref><ref type="bibr" target="#b44">42,</ref><ref type="bibr" target="#b45">43,</ref><ref type="bibr" target="#b46">44]</ref>. Recently, Wang et al. <ref type="bibr" target="#b47">[45]</ref> proposed a premise selection method utilizing deep graph embeddings.</p><p>3 Architecture of the Environment Here we describe the architecture of the evaluation and training environment. The goal of the environment is to enable artificial agents to interact with the HOL Light interactive theorem prover (ITP) in a replicable manner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">ITP Terminology</head><p>In order to describe our changes to HOL Light, it is helpful to establish some common terminology. To prove a theorem in an ITP, the human user starts with entering the theorem's statement as the goal of a new proof. The ITP provides a small number of tactics to manipulate the goal. Tactics may have tactic arguments, which can be a previously proven theorem or a list of previously proven theorems. (There are also tactics that take terms as arguments, but we do not support them currently.) Applying a tactic to a goal can lead to a failure, when not all conditions are met, or is successful and produces a list of subgoals. The goal is only proven successfully, if all its subgoals are proven. In particular, if the goal is proven if the tactic application produces an empty list of subgoals. We refer to tactic applications sometimes also as proof steps.</p><p>We can think of proofs as trees, where goals are nodes and tactic applications are (hyper-)edges to other goals. In a successful proof, all leaves are goals with a tactic application that produced an empty list of subgoals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Instrumentation to HOL Light</head><p>In order to create a stable, well-defined environment, we fix a particular version of HOL Light with a pre-selected subset of tactics and a fixed library of basic theorems, which are proved in one well-defined order. This is the ITP part of the environment Preprint -HOList: An Environment for Machine Learning of Higher-Order Theorem Proving 3 which is written in OCaml with a few additional C++ functions.</p><p>Since it is non-trivial to find and build the exact correct set of libraries for this environment, we provide a prepackaged docker image. It can be used as a reliable black box for proof search and as reinforcement learning environment, communicated with using a simple API. We have also open sourced all the changes to the HOL Light system so that new modifications and forks are possible by third parties.</p><p>The prepackaged version we provide has the following additional instrumentation, which we describe below in detail:</p><p>• Logging of human-written proofs shipped with HOL Light.</p><p>• A new API to interact with HOL Light for proof search.</p><p>• Fast startup for distributed proof search.</p><p>• A proof checker to remove the need to trust search algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Proof Logging for Human Proofs</head><p>We want to utilize the existing human proofs for both training and evaluation. To that effect, we have instrumented the prove method in HOL Light with extra logging code. If HOL Light is executed in proof-dump mode, each invocation of the prove function dumps the proven theorems and their proofs into files. These proof logs can then be converted to training examples (see Section 4.1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Proof Assistant API</head><p>The API provides two functions: (1) to apply tactics to goals and (2) to register theorems for future use in tactic applications. Tactic applications are completely stateless and contain the goal, the tactic to be applied, and the tactic arguments. The poof assistant (i.e. HOL Light in our implementation) returns the outcome of the tactic application, including the list of subgoals for successful applications. The stateless tactic application interface frees us from the strict order on subgoals that HOL Light enforces in the human interface, and allows us to easily implement more advanced proof search strategies.</p><p>The tactic arguments can consist of a list of theorems. Implemented naively, this list could make the tactic application request very large and could slow down the prover. In the argument list of tactics we therefore allow theorems to be referenced by a fingerprint number. The second API function allows us to register theorems such that HOL Light can resolve the fingerprints to theorems. The registration of theorems is hence stateful, in contrast to tactic applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Fast Startup</head><p>Starting HOL Light and loading all the potentially needed libraries can take a long time -we measured it at up to 20 minutes. This would be inhibitively long for proof search, especially in a distributed setting with thousands of workers and the startup time has to be paid for every worker. The Proof Assistant API allows us to load only a minimal core of HOL Light and register the remaining theorems from the libraries using the API. This brings the startup time of our HOL Light to mere seconds. <ref type="table" target="#tab_2">Proof states  core  239  2320  23512  complex 398  16623  509621  flyspeck 1563  10519  538540  all  2200  29462  1071673   Table 1</ref>: The three corpora of the benchmark.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definitions Theorems</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Proof Checking</head><p>Any bug in the implementation of a theorem prover could make its reasoning unsound, rendering the whole formalization effort futile. For that reason, HOL Light is designed around a small trusted core of about 400 lines of OCaml code that builds proofs from few very basic rules. OCaml's type system guarantees that a theorem object can only be constructed by this trusted core, and the rest of the HOL Light system can be seen as mere convenience features.</p><p>Our API allows researchers to implement proof search algorithms outside of OCaml. The correctness of any proof found through the API thus relies on the correctness of our API implementation and the proof search itself. We thus implemented a proof checker that avoids the need for trusting the proof search and even the API. The proof checker compiles proofs into OCaml code that can be loaded in HOL Light, where they have to pass through the trusted core.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Benchmark</head><p>We present three different corpora: "core", "complex", and "flyspeck." The core corpus contains the basic theorems that needed to define the tactics and the complex corpus consists of theorems of complex calculus. While proofs of core theorems are useful for training, we omit them in validation, since some tactics assume those theorems. Flyspeck contains most of the lemmas and theorems of the Kepler conjecture. Together these three corpora encompass almost 30k theorems and proofs (see <ref type="table">Table 1</ref>).</p><p>We propose two tasks that can be measured on these benchmarks:</p><p>• Predict the tactic and tactic arguments that were employed in the human proof. • Prove each of the theorems in the corpora while utilizing only those theorems as tactic arguments that also humans had available. For that purpose, we provide all theorems in the three corpora in one unified list, in the order they were proven by humans.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Training Examples</head><p>Our training examples consist of a goal, a tactic, an arglist, and a negarglist. The goal is a provable statement, i.e. it is either a theorem from one of the corpora or a subgoal of a successful proof. The tactic is the ID of one of a preselected small set of tactics (currently consisting of 41 tactics) that led to a successful proof. The arglist is the list of theorems that were passed to a tactic application as arguments. Additionally, there is a special argument signifying that the argument list was empty.</p><p>Preprint -HOList: An Environment for Machine Learning of Higher-Order Theorem Proving 4</p><p>The negarglist is an optional list of non-arguments that is not actually necessary for any proof. negarglist consists of highscoring theorems that were not actually needed as arguments.</p><p>They are collected during proof search in our reinforcement learning pipeline, and the list is empty for all the examples generated from the human proof logs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Splits</head><p>Before training and evaluation, we have split the top level theorems into three subsets: training, validation and test set in a 60:20:20 ratio. Since the goals occurring in the proof of a theorem are likely correlated with the theorem itself, we assign them the same split as the theorem. The validation set can be used for continuous monitoring for proxy metrics of the model during training. The validation set is also occasionally used to measure the end-to-end prover performance of the models during training. The test set, on the other hand, must only be used extremely rarely for final assessment of a few models before publishing a paper alongside their validation set performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Representation of Expressions</head><p>All expressions are presented as S-expressions that have only few types of non-leaf nodes: function applications, abstractions (i.e. lambda functions), variables, constants, and function types. All other information, such as variable names, constant names, and type names, is given as leaf-nodes. For example, the expression f (x) for a function f : R → R looks as follows: (a (v (fun (real) real) f) (v real x)). These S-expressions have a unique correspondence to terms in HOL Light and are easy to parse into a tree. However, our current models only observe the string version of these expressions. Expressions are quite long in this representation: The average number of tokens in the goals is around 500, and the median is around 300.</p><p>For many operations, HOL Light automatically invents new generic types (e.g. ?345882) and generic variables (e.g. GEN%PVAR%9675) on the fly. This leads to thousands of types and variables that often occur in only one (or a few) expressions, and hence would hardly get meaningful embeddings in typical deep learning approaches. Further, tokens that are shared only between few expressions bear the risk of unintentionally giving away information about the relations between these statements. We therefore decided to normalize the data sets by mapping generic types and generic variables to a much smaller set of names while maintaining the semantics of all expressions. After normalization, the number of distinct tokens is 1254.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">DeepHOL Prover architecture</head><p>In this section, we describe the high-level architecture of our reference neural prover. The intelligence is fully learned without any hand-crafted features, and with very simple data preprocessing. In particular, we have not implemented any tweaks for the particular logic or interactive theorem prover (ITP). All the engineering went into the neural network architecture, which is very generic, and into maintaining the proof search graph without any special regard for the particular ITP system. In other words, DeepHOL currently uses HOL Light and its logic (HOL), but is not specialized to it. We believe that our solution would also work with other goal-tactic based prover like Coq <ref type="bibr" target="#b13">[12]</ref>, HOL4 <ref type="bibr" target="#b12">[11]</ref>, or Lean <ref type="bibr" target="#b16">[15]</ref>. Here we describe the details of our reference prover solution in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Action Generator</head><p>The most crucial part of our prover is the action generator that produces a list of tactic applications for a given goal. We have split this into two subtasks:</p><p>• To rank the tactics, and</p><p>• to create an argument list for each of the tactics (comprised of a list of theorems).</p><p>As noted earlier, DeepHOL is currently not using tactics that take arbitrary terms (formulas) as parameters.</p><p>For both subtasks, the action generator employs a neural network, which we describe in Section 5.4. The ranking of tactic applications it produces is used in the proof search (Section 5.3) to expand the proof search graph (Section 5.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Proof Search Graph</head><p>The proof search graph is our data structure that captures the state of the proof search, and allows us to detect when a proof for the original goal is available. The nodes of the proof search graph are the goals that we have seen in the proof search, including the original goal statement that we want to prove. Each goal can have multiple alternative tactic applications, each of which might result in multiple subgoals. That is, tactic applications are labelled hyperedges in the proof search graph.</p><p>The proof search graph provides some features that allow us to prune some subtrees of the search early: First, whenever a tactic application closes a subgoal, this information is traced back to the parent subgoals and each alternate tactic application (and its whole sub-branch) is marked as closed is discarded from the queue to be processed. If during this recursive process the root node is reached, then the proof is closed and the proof process stops. Second, when all tactic applications for a goal fail we mark that goal as unsuccessful. Similar to tracing closed goals, the proof search graph automatically traces the siblings of unsuccessful subgoals that become superflous, and mark them unsuccessful as well. Third, when tactic applications produce identical subgoals, we let them point to the same node in the proof search graph. We refer to this as subgoal sharing, and once a subgoal is newly shared, previously stored information about subgoals being closed or ignored is be propagated through the search graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Proof Search</head><p>Our proof search is a simple breadth first search. In each iteration, its expands all leaf nodes (i.e. goals that have not been expanded yet). To exand a goal, it calls the action generator to generate a list of tactic applications, and applies them in order. It stops applying tactics to a goal, when it reaches a maximum number of unsuccessful tactic applications or a minimum number of successful tactic applications. Whenever a complete proof is found for the top level goal, the proof search is stopped and the whole proof search graph is serialized and stored as the result. Also, the proof search finishes if the search graph reaches a prescribed limit on the number of subgoals or the proof search times out.</p><p>Note that subgoal sharing, as explained in Section 5.2, is crucial for our proof search: Without subgoal sharing the search process could end up oscillating between two formulas by rewriting the same subterm back and forth using the same equation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Neural Architectures</head><p>For the generation and ranking of actions in the action generator, we use a deep, two-tower neural network depicted in <ref type="figure">Figure 1</ref>.</p><p>The predictions of the neural network are based on a single goal, represented as an S-expression of the HOL Light term (i.e. a string). (In HOL Light, each goal consists of a list of hypotheses and a conclusion, and we currently drop the hypotheses before we feed a goal to the neural network.)</p><p>The neural network has two separate prediction heads S and R. The goal tower G computes an embedding G(g) of the current goal g and infers a scoring vector S (G(g)) for the fixed set of tactics where the tactic classifier S is a linear layer producing logits of a softmax classifier. The premise tower P computes a fixed size embedding P(t i ) of all possible tactic arguments t i in the scope of the goal to be proved. The ranking of the premises is performed by a combiner network C that takes the concatenation of the goal embedding, the premise embedding and possibly that of the tactic T j to be applied: r(t i ) = C(G(g), P(t i ), T j ), where r(t i ) is the score of theorem t i for its being a useful tactic argument for transforming the current goal g towards a closed proof. We have also tried the unconditioned setup, in which the ranking of the tactic arguments is independent of that of the tactic to be applied, that is r(t i ) = C(G(g), P(t i )). In essence, we propose a hybrid architecture that both predicts the correct tactic to be applied, as well as rank the premise parameters required for meaningful application of the tactics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Supervised Learning</head><p>We started training DeepHOL in a supervised learning setup, for which we use the human proof logs. We have split our data into test, train, and validation set on the theorem level, as described in Section 4. We always report both validation and test set performance for the final result to verify that we did not over-fit on the validation set. Continuous measurements and ablation analyses are reported only on the validation or training set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Reinforcement Learning Loop</head><p>In the reinforcement learning loop, we have both a trainer and multiple provers running continuously. The training is (optionally) seeded with training examples from existing (human/generated) proof logs. Then, we run the neural prover in rounds, each round trying to prove a random sample of theorems Note that although we can make use of human and inherited proof traces, the system can learn without any supervision or initial seed data. However, preliminary experiments have shown that, in its current form, it learns inferior models compared to those that were seeded with human proofs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6.1">Proof Pruning</head><p>The argument lists of tactic applications in the reinforcement learning loop are quite long, and they contain superfluous elements. In order to obtain high quality training data for tactic argument prediction, we prune the parameter list before using them for training. For all tactics that take a list of theorems as an argument, our current implementation generates a list of fixed length. For successful tactic applications, we then iterate over the arguments in reverse score order and greedily omit those arguments that do not change the outcome of the tactic application. While a non-greedy approach might yield even shorter argument lists, it would also take longer to compute. In practice, our approach produces short argument lists with minimal effort. Removed parameters are stored as "hard negatives" and utilized during training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results and Comparisons</head><p>In this section, we first present several baseline results based on imitation (i.e. fully supervised) learning. Then we come  to our reinforcement learning results using a WaveNet <ref type="bibr" target="#b48">[46]</ref> based encoder architecture, but with three different training methodologies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Model Training Hyperparameters</head><p>All models were trained with the Adam optimizer <ref type="bibr" target="#b49">[47]</ref> and exponentially decreasing learning rate starting at 0.0001 with decay rate 0.98 at every 100000 steps. For evaluation, we use moving exponential parameter averaging at a rate of 0.9999 per step <ref type="bibr" target="#b50">[48,</ref><ref type="bibr" target="#b51">49]</ref>. First, we established trivial baselines by running the built-in first-order theorem prover ASM_MESON_TAC on each theorem on the dataset with empty argument list and with an argument list predicted with our baseline WaveNet model. Next, we compare the performance of various WaveNet style architectures. Finally, we report our reinforcement learning experiments on the complex analysis corpus. Our final prover performance numbers are summarized in <ref type="table" target="#tab_2">Table 2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Comparison of Model Architectures</head><p>We trained and evaluated a large number of networks and present a sample of our findings. During our experiments, we looked at the following proxy metrics:</p><p>1. Accuracy of tactic prediction out of the 41 possible tactics.</p><p>(Ranging between 38% and 42% for most models.) 2. Success rate of selecting a positive tactic argument over a randomly selected negative argument. (Around 1% error rate).</p><p>For the encoders, we have tried WaveNet <ref type="bibr" target="#b48">[46]</ref> style networks with different hyper-parameters. The various results on the complex analysis corpus are based on imitation learning and the combination of imitation learning and reinforcement learning. In the base model we used two WaveNet blocks of four layers each. The number of filters in each block was either 128 or 256. As one can see in <ref type="table" target="#tab_2">Table 2</ref>, the network with less filters did better. Then we tried a deeper variant with four blocks of five layers each, in this case with depth 128. Here the deeper Maximum number of top tactics explored <ref type="bibr" target="#b6">[6,</ref><ref type="bibr" target="#b17">16]</ref> Maximum successful tactic applications <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b6">6]</ref> Number of selected tactic arguments <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b33">32]</ref>  network with more blocks, which has 47 million parameters, turned out to be superior. Both architectures incorporate fully connected combiner layers with additional dropout layers before each of them. The ratio of dropped out neurons during training was 0.3. Note that the reinforcement learning experiments was performed earlier and was ran with the narrow architecture (with 128 filters in each layer) and with two wavenet blocks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Reinforcement Learning</head><p>In our reinforcement learning set up, the model training runs on a single GPU, while theorem proving is performed in a distributed manner: we attempt to prove 2000 randomly selected theorems from the training set of the union of the complex and core corpora in every round. At the start of each round, we fetch the latest trained model checkpoint and precompute the theorem argument embedding for each theorem in the complex and core libraries. This precomputation greatly accelerates the ranking of the tactic arguments. The proof search is distributed over 1000 cores and we set a computation limit of 100 explored proof states and a total timeout of 300 seconds. Each individual tactic application has a timeout of 5 seconds. Additionally, for each example, we pick prover options uniformly in the ranges described by <ref type="table" target="#tab_3">Table 3</ref>, to increase the diversity of the generated proofs. This also increases the chance of finding a proof at all for harder statements.</p><p>Given the high computational cost of running the reinforcement learning loop, we have only tried a couple of variants. Each of our these experiments use the same version of WaveNet <ref type="bibr" target="#b48">[46]</ref> architecture (with 128 filters in each layer). In our first loop experiment, "Loop", we trained a loop with tactic independent argument selection. That is, the tactic argument ranking was independent of the tactic chosen, and we pick only top level theorems to be proved by proof search in the reinforcement   learning scenario. Alongside our first loop, we trained a separate model "Trained on loop output" that was not used in the loop for proof search guidance, but did benefit from a curriculum-style learning, since it trained in parallel to the loop. In our second loop experiment, "Loop tactic dependent", we have trained a model in which the arguments ranking depends on the selected tactic. In our third loop experiment, "Loop on subgoals", the proof search can pick from any of the internal proof states from the training set of the joined core+complex corpus. This was motivated partially by the success of <ref type="bibr" target="#b52">[50]</ref>, we tried to run a reinforcement learning loop in which we train for solving each subgoal separately, hoping that it will help for learning longer proofs. This means, that we expected a bigger variety of theorems to be generated during proof search. However, our naive implementation did not seem to end up with improved results. Performance of each loop's final checkpoint on the validation set is presented in <ref type="table" target="#tab_2">Table 2</ref>. We also ran the final checkpoint of the "Loop" on a sample of 2000 proofs from the flyspeck dataset; we closed 752 (37.0%) of these proofs automatically.</p><p>While it was too computationally expensive to track the validation performance on every round of the loop, we did record the performance on the training set. In <ref type="figure" target="#fig_2">Fig. 2</ref>, we show the cumulative number of proofs closed by the tactic dependent loop at each round. Recall that in each round we sample theorems from the training set and use the most recent checkpoint to guide the proof search. In <ref type="figure" target="#fig_3">Fig. 3</ref>, we show the percentage of the sampled theorems that are proved in each round.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>We presented a machine learning oriented open source environment for higher-order theorem proving as well as a neural network based automated prover, trained on a large-scale reinforcement learning system. We also suggest a benchmark for machine reasoning in higher-order logic on a relatively large and practically relevant corpus of theorems with varying complexity. Our benchmark includes purely neural network based baselines, which demonstrate strong automated reasoning capabilities, including premise selection from a large number of theorems. We hope that our initial effort fosters collaboration and paves the way for strong and practical AI systems that can learn to reason efficiently in large formal theories.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>5 PremiseFigure 1 :</head><label>51</label><figDesc>Preprint -HOList: An Environment for Machine Learning of Higher-Order Theorem Proving Two-tower neural architecture for ranking actions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>in the training set. Training examples extracted from successful proof logs of each round of our neural prover are mixed in continuously. Training examples of more recent rounds (fresh examples) can be weighed differently from older rounds (historical examples) during the training process. To summarize, our loop works with the following four kinds of training example pools: 1. (optional) Human training examples as seed. 2. (optional) Inherited computer generated examples as seed: in addition to using human training examples as seed, examples generated during any previous experiments with our prover can also be used as seed. In our current experiments, we used examples that were generated by a prover that was run on the whole training set utilizing a model that was trained in purely supervised manner. 3. Fresh generated loop examples (examples that were produced in the last k rounds, where k is a user-settable parameter). 4. Historical training loop examples (examples that were produced in all but the last k rounds). During training, batches are filled with examples from each pool according to a prescribed split ratio. This means that the ratio of different kinds of examples the model is trained on does not shift as more examples are generated by the loop. Most importantly, it also ensures that examples from freshly constructed new proofs show up quickly and deterministically during the training process.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>This figure presents the cumulative number of proofs closed by the tactic dependent loop. The total number of theorems in the training set is 10199.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Percentage of theorems proved in each round of the loop. Each round samples 2000 theorems from the training set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell>: Percentage of theorems closed using various models on</cell></row><row><cell>the validation set of the complex corpus comprising of 3225 the-</cell></row><row><cell>orems. First two lines are trivial baselines that call HOL Light's</cell></row><row><cell>built-in first order theorem prover with and without utilizing our</cell></row><row><cell>argument selection model. The middle section shows results of</cell></row><row><cell>models trained in a supervised scenario on human proofs. The</cell></row><row><cell>last four lines report results using our reinforcement learning</cell></row><row><cell>loops.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Randomized proof search parameters and their ranges.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>Preprint -HOList: An Environment for Machine Learning of Higher-Order Theorem Proving</figDesc><table><row><cell></cell><cell>7</cell></row><row><cell></cell><cell>Theorems proved</cell></row><row><cell>Name</cell><cell>(% of training set)</cell></row><row><cell>Loop</cell><cell>5679 (55.7%)</cell></row><row><cell>Loop tactic dependent</cell><cell>5518 (54.1%)</cell></row><row><cell>Loop on subgoals</cell><cell>1988 (19.5%)</cell></row><row><cell>Union</cell><cell>5919 (58.0%)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Total count of proofs found by each loop.</figDesc><table /><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We would like to thank Alex Alemi, Geoffrey Irving, Cezary Kaliszyk, Thibault Gauthier, Ramana Kumar, Viktor Toman, and Josef Urban for their insightful comments and contributions to early versions of this work.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Librispeech: an asr corpus based on public domain audio books</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vassil</forename><surname>Panayotov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoguo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Povey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Khudanpur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Acoustics, Speech and Signal Processing (ICASSP), 2015 IEEE International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="5206" to="5210" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The netflix prize</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stan</forename><surname>Lanning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of KDD cup and workshop</title>
		<meeting>KDD cup and workshop<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page">35</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
	<note>CVPR 2009. IEEE Conference on</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ieee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Microsoft coco: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="740" to="755" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Findings of the 2014 workshop on statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondrej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Buck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Federmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Leveling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christof</forename><surname>Monz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Pecina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herve</forename><surname>Saint-Amand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ninth workshop on statistical machine translation</title>
		<meeting>the ninth workshop on statistical machine translation</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="12" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Squad: 100,000+ questions for machine comprehension of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantin</forename><surname>Lopyrev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.05250</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A formal proof of the kepler conjecture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Hales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gertrud</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tat Dat</forename><surname>Dang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Harrison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cezary</forename><surname>Hoang Le Truong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Kaliszyk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Magron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tat</forename><surname>Mclaughlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Thang Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Forum of Mathematics</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">An Environment for Machine Learning of Higher-Order Theorem Proving 8</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Preprint -Holist</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Malarea sg1-machine learner for automated reasoning with semantic guidance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Urban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoff</forename><surname>Sutcliffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petr</forename><surname>Pudlák</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiří</forename><surname>Vyskočil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Automated Reasoning</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="441" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Tactictoe: Learning to reason with hol4 tactics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thibault</forename><surname>Gauthier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cezary</forename><surname>Kaliszyk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Urban</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LPAR-21. 21st International Conference on Logic for Programming, Artificial Intelligence and Reasoning</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="125" to="143" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Gamepad: A learning environment for theorem proving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawn</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.00608</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A brief overview of hol4</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konrad</forename><surname>Slind</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Norrish</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Theorem Proving in Higher Order Logics</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="28" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Interactive theorem proving and program development: Coq&apos;Art: the calculus of inductive constructions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yves</forename><surname>Bertot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Castéran</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">The Mizar Mathematical Library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mizar</surname></persName>
		</author>
		<idno>/01/18</idno>
		<ptr target="http://mizar.org.Accessed" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The isabelle framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Makarius</forename><surname>Wenzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><forename type="middle">C</forename><surname>Paulson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Nipkow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Theorem Proving in Higher Order Logics, 21st International Conference</title>
		<editor>Otmane Aït Mohamed, César A. Muñoz, and Sofiène Tahar</editor>
		<meeting><address><addrLine>TPHOLs; Montreal, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008-08-18" />
			<biblScope unit="volume">5170</biblScope>
			<biblScope unit="page" from="33" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Floris Van Doorn, and Jakob von Raumer. The lean theorem prover (system description</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonardo</forename><surname>De Moura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soonho</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeremy</forename><surname>Avigad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Automated Deduction</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="378" to="388" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">sel4: Formal verification of an os kernel</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerwin</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Elphinstone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gernot</forename><surname>Heiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">June</forename><surname>Andronick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Cock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Derrin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhammika</forename><surname>Elkaduwe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Engelhardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rafal</forename><surname>Kolanski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Norrish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Sewell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harvey</forename><surname>Tuch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Winwood</surname></persName>
		</author>
		<idno type="DOI">http:/doi.acm.org/10.1145/1629575.1629596</idno>
		<ptr target="http://doi.acm.org/10.1145/1629575.1629596" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGOPS 22Nd Symposium on Operating Systems Principles, SOSP &apos;09</title>
		<meeting>the ACM SIGOPS 22Nd Symposium on Operating Systems Principles, SOSP &apos;09<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="207" to="220" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Learning-assisted automated reasoning with flyspeck</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cezary</forename><surname>Kaliszyk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Urban</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Automated Reasoning</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="173" to="213" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Initial experiments with external provers and premise selection on hol light corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cezary</forename><surname>Kaliszyk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Urban</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Deepmath-deep sequence models for premise selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">François</forename><surname>Alexander A Alemi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Chollet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niklas</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Eén</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Urban</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2235" to="2243" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">E -A Brainiac Theorem Prover</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Schulz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI Commun</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="111" to="126" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Holophrasm: a neural automated theorem prover for higher-order logic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Whalen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1608.02644</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Metamath: A computer language for pure mathematics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Norman</forename><surname>Megill</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Deep network guided proof search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarah</forename><surname>Loos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cezary</forename><surname>Kaliszyk</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.06972</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Holstep: A machine learning dataset for higher-order logic theorem proving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cezary</forename><surname>Kaliszyk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">François</forename><surname>Chollet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.00426</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Reinforcement learning of theorem proving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cezary</forename><surname>Kaliszyk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Urban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henryk</forename><surname>Michalewski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirek</forename><surname>Olšák</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.07563</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Liblinear: A library for large linear classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai-Wei</forename><surname>Rong-En Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cho-Jui</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang-Rui</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chih-Jen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1871" to="1874" />
			<date type="published" when="2008-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">leanCoP: lean connectionbased theorem proving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Otten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Bibel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Symb. Comput</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="139" to="161" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Learning search control knowledge for equational deduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Schulz</surname></persName>
		</author>
		<idno>978-3- 89838-230-4</idno>
	</analytic>
	<monogr>
		<title level="j">DISKI. Infix Akademische Verlagsgesellschaft</title>
		<imprint>
			<biblScope unit="volume">230</biblScope>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">The use of data-mining for the automatic formation of tactics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hazel</forename><surname>Duncan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bundy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Levine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Storkey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pollet</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Malecop machine learning connection prover</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Urban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiří</forename><surname>Vyskočil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petr</forename><surname>Štěpánek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Automated Reasoning with Analytic Tableaux and Related Methods</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="263" to="277" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Overview and evaluation of premise selection techniques for large theory mathematics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Kühlwein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeni</forename><surname>Twan Van Laarhoven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Tsivtsivadze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Urban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Heskes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Automated Reasoning</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="378" to="392" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Stronger automation for flyspeck by feature weighting and strategy evolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cezary</forename><surname>Kaliszyk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Urban</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Mash: machine learning for sledgehammer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Kühlwein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jasmin</forename><forename type="middle">Christian</forename><surname>Blanchette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cezary</forename><surname>Kaliszyk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Urban</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Interactive Theorem Proving</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="35" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Premise selection for mathematics by corpus analysis and kernel methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><surname>Alama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Heskes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Kühlwein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeni</forename><surname>Tsivtsivadze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Urban</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Automated Reasoning</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="191" to="213" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Machine learning for first-order theorem proving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">P</forename><surname>Bridge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><forename type="middle">B</forename><surname>Holden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><forename type="middle">C</forename><surname>Paulson</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10817-014-9301-5</idno>
		<idno>0168-7433. doi: 10. 1007/s10817-014-9301-5</idno>
		<ptr target="http://dx.doi.org/10.1007/s10817-014-9301-5" />
	</analytic>
	<monogr>
		<title level="j">J. Autom. Reasoning</title>
		<imprint>
			<biblScope unit="page" from="1" to="32" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Machine learner for automated reasoning 0</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cezary</forename><surname>Kaliszyk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Urban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiří</forename><surname>Vyskočil</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1402.2359</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">4 and 0.5. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">An Environment for Machine Learning of Higher-Order Theorem Proving 9</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Preprint -Holist</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Machine learning of coq proof guidance: First experiments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cezary</forename><surname>Kaliszyk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lionel</forename><surname>Mamane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Urban</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1410.5467</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Random forests for premise selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Färber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cezary</forename><surname>Kaliszyk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Frontiers of Combining Systems</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="325" to="340" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Mizar 40 for mizar 40</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cezary</forename><surname>Kaliszyk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Urban</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Automated Reasoning</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="245" to="256" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Efficient semantic features for automated reasoning over large theories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cezary</forename><surname>Kaliszyk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Urban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jirí</forename><surname>Vyskocil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Femalecop: Fairly efficient machine learning connection prover</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cezary</forename><surname>Kaliszyk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Urban</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Logic for Programming</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="88" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Learning-assisted theorem proving with millions of lemmas</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cezary</forename><surname>Kaliszyk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Urban</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of symbolic computation</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="page" from="109" to="128" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Premise selection and external provers for hol4</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thibault</forename><surname>Gauthier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cezary</forename><surname>Kaliszyk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Certified Programs and Proofs</title>
		<meeting>the 2015 Conference on Certified Programs and Proofs</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="49" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">A learningbased fact selector for isabelle/hol</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jasmin</forename><forename type="middle">Christian</forename><surname>Blanchette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Greenaway</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cezary</forename><surname>Kaliszyk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Kühlwein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Urban</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Automated Reasoning</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="219" to="244" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Premise selection for theorem proving by deep graph embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingzhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yihe</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2786" to="2796" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Wavenet: A generative model for raw audio</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aäron</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sander</forename><surname>Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heiga</forename><surname>Dieleman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Zen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nal</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Senior</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kavukcuoglu</surname></persName>
		</author>
		<idno>abs/1609.03499</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">A new method of stochastic approximation type</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boris</forename><surname>Teodorovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Polyak</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Avtomatika i telemekhanika</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="98" to="107" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Acceleration of stochastic approximation by averaging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Boris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anatoli B Juditsky</forename><surname>Polyak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Control and Optimization</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="838" to="855" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Curriculum learning and theorem proving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zsolt</forename><surname>Zombori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrián</forename><surname>Csiszárik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henryk</forename><surname>Michalewski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cezary</forename><surname>Kaliszyk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Urban</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AITP</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
