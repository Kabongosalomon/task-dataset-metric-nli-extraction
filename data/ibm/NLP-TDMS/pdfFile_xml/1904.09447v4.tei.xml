<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">An Unsupervised Joint System for Text Generation from Knowledge Graphs and Semantic Parsing</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Schmitt</surname></persName>
							<email>martin@cis.lmu.de</email>
							<affiliation key="aff0">
								<orgName type="department">Center for Information and Language Processing (CIS)</orgName>
								<orgName type="institution">LMU Munich</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sahand</forename><surname>Sharifzadeh</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Informatics</orgName>
								<orgName type="institution">LMU Munich</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Volker</forename><surname>Tresp</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Informatics</orgName>
								<orgName type="institution">LMU Munich</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Siemens AG Munich</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Information and Language Processing (CIS)</orgName>
								<orgName type="institution">LMU Munich</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">An Unsupervised Joint System for Text Generation from Knowledge Graphs and Semantic Parsing</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T16:20+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Knowledge graphs (KGs) can vary greatly from one domain to another. Therefore supervised approaches to both graph-to-text generation and text-to-graph knowledge extraction (semantic parsing) will always suffer from a shortage of domain-specific parallel graphtext data; at the same time, adapting a model trained on a different domain is often impossible due to little or no overlap in entities and relations. This situation calls for an approach that (1) does not need large amounts of annotated data and thus (2) does not need to rely on domain adaptation techniques to work well in different domains. To this end, we present the first approach to unsupervised text generation from KGs and show simultaneously how it can be used for unsupervised semantic parsing. We evaluate our approach on WebNLG v2.1 and a new benchmark leveraging scene graphs from Visual Genome. Our system outperforms strong baselines for both text↔graph conversion tasks without any manual adaptation from one dataset to the other. In additional experiments, we investigate the impact of using different unsupervised objectives. 1</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Knowledge graphs (KGs) are a general-purpose approach for storing information in a structured, machine-accessible way <ref type="bibr" target="#b57">(Van Harmelen et al., 2008)</ref>. They are used in various fields and domains to model knowledge about topics as different as lexical semantics <ref type="bibr">(Fellbaum, 2005;</ref><ref type="bibr" target="#b0">van Assem et al., 2006)</ref>, common sense <ref type="bibr" target="#b52">(Speer et al., 2017;</ref><ref type="bibr" target="#b48">Sap et al., 2019)</ref>, biomedical research <ref type="bibr" target="#b61">(Wishart et al., 2018)</ref> and visual relations in images .</p><p>This ubiquity of KGs necessitates interpretability because diverse users -both experts and nonexperts -work with them. Even though, in prin-1 https://github.com/mnschmit/ unsupervised-graph-text-conversion ciple, a KG is human-interpretable, non-experts may have difficulty making sense of it. Thus, there is a need for methods, such as automatic natural language generation ("graph→text"), that support them.</p><p>Semantic parsing, i.e., the conversion of a text to a formal meaning representation, such as a KG, ("text→graph") is equally important because it makes information that only exists in text form accessible to machines, thus assisting knowledge base engineers in KG creation and completion.</p><p>As KGs are so flexible in expressing various kinds of knowledge, separately created KGs vary a lot. This unavoidably leads to a shortage of training data for both graph↔text tasks. We therefore propose an unsupervised model that (1) easily adapts to new KG domains and (2) only requires unlabeled (i.e., non-parallel) texts and graphs from the target domain, together with a few fact extraction heuristics, but no manual annotation.</p><p>To show the effectiveness of our approach, we conduct experiments on the latest release (v2.1) of the WebNLG corpus <ref type="bibr" target="#b50">(Shimorina and Gardent, 2018)</ref> and on a new benchmark we derive from Visual Genome <ref type="bibr" target="#b24">(Krishna et al., 2017)</ref>. While both of these datasets contain enough annotations to train supervised models, we evaluate our unsupervised approach by ignoring these annotations. The datasets are particularly well-suited for our evaluation as both graphs and texts are completely humangenerated. Thus for both our tasks, models are evaluated with natural, i.e., human-generated targets.</p><p>Concretely, we make the following contributions: (1) We present the first unsupervised non-template approach to text generation from KGs (graph→text). (2) We jointly develop a new unsupervised approach to semantic parsing that automatically adjusts to a target KG schema (text→graph).</p><p>(3) In contrast to prior unsupervised graph→text and text→graph work, our model does not re-quire manual adaptation to new domains or graph schemas. (4) We provide a thorough analysis of the impact of different unsupervised objectives, especially the ones we newly introduce for text↔graph conversion. (5) We create a new large-scale dataset for text↔graph transformation tasks in the visual domain.</p><p>2 Related Work graph → text. Our work is the first attempt at fully unsupervised text generation from KGs. In this respect it is only comparable to traditional rule-or template-based approaches <ref type="bibr" target="#b25">(Kukich, 1983;</ref><ref type="bibr" target="#b34">McRoy et al., 2000)</ref>. However, in contrast to these approaches, which need to be manually adapted to new domains and KG schemas, our method is generally applicable to all kinds of data without modification.</p><p>There is a large body of literature about supervised text generation from structured data, notably about the creation of sports game summaries from statistical records <ref type="bibr" target="#b47">(Robin, 1995;</ref><ref type="bibr" target="#b55">Tanaka-Ishii et al., 1998)</ref>. Recent efforts make use of neural encoderdecoder mechanisms <ref type="bibr" target="#b60">(Wiseman et al., 2017;</ref><ref type="bibr" target="#b43">Puduppully et al., 2019)</ref>. Although text creation from relational databases is related and our unsupervised method is, in principle, also applicable to this domain, in our work we specifically address text creation from graph-like structures such as KGs.</p><p>One recent work on supervised text creation from KGs is <ref type="bibr" target="#b4">(Bhowmik and de Melo, 2018)</ref>. They generate a short description of an entity, i.e., a single KG node, based on a set of facts about the entity. We, however, generate a description of the whole KG, which involves multiple entities and their relations. <ref type="bibr" target="#b23">Koncel-Kedziorski et al. (2019)</ref> generate texts from whole KGs. They, however, do not evaluate on human-generated KGs but automatically generated ones from the scientific information extraction tool SciIE <ref type="bibr" target="#b31">(Luan et al., 2018)</ref>. Their supervised model is based on message passing through the topology of the incidence graph of the KG input. Such graph neural networks <ref type="bibr" target="#b22">(Kipf and Welling, 2017;</ref><ref type="bibr" target="#b58">Veličković et al., 2018)</ref> have been widely adopted in supervised graph-to-text tasks <ref type="bibr" target="#b3">(Beck et al., 2018;</ref><ref type="bibr" target="#b8">Damonte and Cohen, 2019;</ref><ref type="bibr" target="#b44">Ribeiro et al., 2019</ref><ref type="bibr">Ribeiro et al., , 2020</ref>.</p><p>Even though <ref type="bibr" target="#b32">Marcheggiani and Perez-Beltrachini (2018)</ref> report that graph neural networks can make better use of graph input than RNNs for supervised learning, for our unsuper-vised approach we follow the line of research that uses RNN-based sequence-to-sequence models <ref type="bibr" target="#b53">Sutskever et al., 2014)</ref> operating on serialized triple sets <ref type="bibr" target="#b13">(Gardent et al., 2017b;</ref><ref type="bibr" target="#b56">Trisedya et al., 2018;</ref><ref type="bibr" target="#b15">Gehrmann et al., 2018;</ref><ref type="bibr" target="#b6">Castro Ferreira et al., 2019;</ref><ref type="bibr" target="#b9">Fan et al., 2019)</ref>. We make this choice because learning a common semantic space for both texts and graphs by means of a shared encoder and decoder is a central component of our model. It is a nontrivial, separate research question whether and how encoder-decoder parameters can effectively be shared for models working on both sequential and non-sequential data. We thus leave the adaptation of our approach to graph neural networks for future work.</p><p>text → graph. Converting a text into a KG representation, our method is an alternative to prior work on open information extraction <ref type="bibr" target="#b35">(Niklaus et al., 2018)</ref> with the advantage that the extractions, though trained without labeled data, automatically adjust to the KGs used for training. It is therefore also related to relation extraction in the unsupervised <ref type="bibr" target="#b62">(Yao et al., 2011;</ref><ref type="bibr" target="#b33">Marcheggiani and Titov, 2016;</ref><ref type="bibr" target="#b51">Simon et al., 2019)</ref> and distantly supervised setting <ref type="bibr" target="#b46">(Riedel et al., 2010;</ref><ref type="bibr" target="#b37">Parikh et al., 2015)</ref>. However, these systems merely predict a single relation between two given entities in a single sentence, while we translate a whole text into a KG with potentially multiple facts.</p><p>Our text→graph task is therefore most closely related to semantic parsing <ref type="bibr" target="#b20">(Kamath and Das, 2019</ref>), but we convert statements into KG facts whereas semantic parsing typically converts a question into a KG or database query. <ref type="bibr" target="#b39">Poon and Domingos (2009)</ref> proposed the first unsupervised approach. They, however, still need an additional KG alignment step, i.e., are not able to directly adjust to the target KG. Other approaches overcome this limitation but only in exchange for the inflexibility of manually created domain-specific lexicons <ref type="bibr" target="#b40">(Popescu et al., 2004;</ref><ref type="bibr" target="#b16">Goldwasser et al., 2011)</ref>. Poon (2013)'s approach is more flexible but still relies on preprocessing by a dependency parser, which generally means that language-specific annotations to train such a parser are needed. Our approach is endto-end, i.e., does not need any language-specific preprocessing during inference and only depends on a POS tagger used in the rule-based text→graph system to bootstrap training.</p><p>Unsupervised sequence generation. Our unsu-pervised training regime for both text↔graph tasks is inspired by <ref type="bibr" target="#b27">(Lample et al., 2018b)</ref>. They used self-supervised pretraining and backtranslation for unsupervised translation from one language to another. We adapt these principles and their noise model to our tasks, and introduce two new noise functions specific to text↔graph conversion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Preliminaries</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data structure</head><p>We formalize a KG as a labeled directed multigraph (V, E, s, t, l) where entities are nodes V and edges E represent relations between entities. The lookup functions s, t : E → V assign to each edge its source and target node. The labeling function l assigns labels to nodes and edges where node labels are entity names and edge labels come from a predefined set R of relation types.</p><p>An equivalent representation of a KG is the set of its facts. A fact is a triple consisting of an edge's source node (the subject), the edge itself (the predicate), and its target node (the object). So the set of facts F of a KG can be obtained from its edges:</p><formula xml:id="formula_0">F := { (s(e), e, t(e)) | e ∈ E } .</formula><p>Applying l to all triple elements and writing out F in an arbitrary order generates a serialization that makes the KG accessible to sequence models otherwise used only for text. This has the advantage that we can train a sequence encoder to embed text and KGs in the same semantic space. Specifically, we serialize a KG by writing out its facts separated with end-of-fact symbols (EOF) and elements of each fact with special SEP symbols. We thus define our task as a sequence-to-sequence (seq2seq) task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Scene Graphs</head><p>The Visual Genome (VG) repository is a large collection of images with associated manually annotated scene graphs; see <ref type="figure">Fig. 1</ref>. A scene graph formally describes image objects with their attributes, e.g., <ref type="bibr">(hydrant, attr, yellow)</ref>, and their relations to other image objects, e.g., <ref type="bibr">(woman, in, shorts)</ref>. Each scene graph is organized into smaller subgraphs, known as region graphs, representing a subpart of a more complex larger picture that is interesting on its own. Each region graph is associated with an English text, the region description. Texts and graphs were not automatically produced from each other, but were collected from crowdworkers who <ref type="figure">Figure 1</ref>: Region graphs and textual region descriptions in Visual Genome (VG). Image regions serve as common reference for text and graph creation but are disregarded in our work. We solely focus on the pairs of corresponding texts and graphs. Illustration adapted from <ref type="bibr" target="#b24">(Krishna et al., 2017)</ref>. were presented an image region and then generated text and graph. So although the graphs were not specifically designed to closely resemble the texts, they describe the same image region. This semantic correspondence makes scene graph↔text conversion an interesting and challenging problem because text and graph are not simple translations of each other. Scene graphs are formalized in the same way as other KGs: V here contains image objects and their attributes, and R contains all types of visual relationships and the special label attr for edges between attribute and non-attribute nodes. <ref type="figure" target="#fig_0">Fig. 2</ref> shows an example. VG scene graphs have been used before for traditional KG tasks, such as KG completion <ref type="bibr" target="#b59">(Wan et al., 2018)</ref>, but we are the first to use them for a text↔graph conversion dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Approaches</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Rule-based systems</head><p>We propose a rule-based system as unsupervised baseline for each of the text↔graph tasks. Note that they both assume that the texts are in English. R graph→text . From a KG serialization, we remove noise function behavior swap applies a random permutation σ of words or facts with ∀i ∈ {1, . . . , n} , |σ(i) − i| ≤ k; k = 3 for text, k = +∞ for knowledge graphs.</p><p>drop removes each fact/word with a probability of pdrop.</p><p>blank replaces each fact/word with a probability of pblank by a special symbol blanked.</p><p>repeat inserts repetitions with a probability of prepeat in a sequence of facts/words.</p><p>rule generates a noisy translation by applying R graph→text to a graph or R text→graph to a text.  <ref type="figure">Figure 3</ref>: Example noisy training instance for the graph→text task in the composed noise setting. The fact highlighted in red is removed by drop, the one in blue is replaced with blanked by blank, the one in orange is repeated by repeat.</p><p>SEP symbols and replace EOF symbols by the word and. The special label attr is mapped to is. This corresponds to a template-based enumeration of all KG facts. See <ref type="table">Table 5</ref> for an example. R text→graph . After preprocessing a text with NLTK's default POS tagger <ref type="bibr" target="#b29">(Loper and Bird, 2004</ref>) and removing stop words, we apply two simple heuristics to extract facts: (1) Each verb becomes a predicate; is creates facts with predicate attr. The content words directly before and after such a predicate word become subject and object.</p><p>(2) Adjectives a form attributes, i.e., build facts of the form (X, attr, a) where X is filled with the first noun after a. These heuristics are similar in nature to a rudimentary parser. See <ref type="table" target="#tab_11">Table 8</ref> for an example.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Neural seq2seq systems</head><p>Our main system is a neural seq2seq architecture. We equip the standard encoder-decoder model with attention  and copy mechanism <ref type="bibr" target="#b17">(Gu et al., 2016)</ref>. Allowing the model to directly copy from the source to the target side is beneficial in data to text generation <ref type="bibr" target="#b60">(Wiseman et al., 2017;</ref><ref type="bibr" target="#b43">Puduppully et al., 2019)</ref>. The encoder (resp. decoder) is a bidirectional (resp. unidirectional) LSTM <ref type="bibr" target="#b19">(Hochreiter and Schmidhuber, 1997)</ref>. Dropout <ref type="bibr" target="#b18">(Hinton et al., 2012)</ref> is applied at the input of both encoder and decoder <ref type="bibr" target="#b5">(Britz et al., 2017)</ref>. We combine this model with the following concepts: Multi-task model. In unsupervised machine translation, systems are trained for both translation directions <ref type="bibr" target="#b27">(Lample et al., 2018b)</ref>. In the same way, we train our system for both conversion tasks text↔graph, sharing encoder and decoder. To tell the decoder which type of output should be produced (text or graph), we initialize the cell state of the decoder with an embedding of the desired output type. The hidden state of the decoder is initialized with the last state of the encoder as usual. Noisy source samples. <ref type="bibr" target="#b26">Lample et al. (2018a)</ref> introduced denoising auto-encoding as pretraining and auxiliary task to train the decoder to produce well-formed output and make the encoder robust to noisy input. The training examples for this task consist of a noisy version of a sentence as source and the original sentence as target. We adapt this idea and propose the following noise functions for the domains of graphs and texts: swap, drop, blank, repeat, rule. <ref type="table" target="#tab_0">Table 1</ref> describes their behavior. swap, drop and blank are adapted from <ref type="bibr" target="#b26">(Lample et al., 2018a)</ref> with facts in graphs taking the role of words in text. As order should be irrelevant in a set of facts, we drop the locality constraint in the swap permutation for graphs by setting k = +∞. Denoising samples generated by repeat requires the model to learn to remove redundant information in a set of facts. In the case of text, repeat mimics a behavior often observed with insufficiently trained neural models, i.e., repeating words considered important.</p><p>Unlike the other noise functions, rule does not "perturb" its input, but rather noisily backtranslates it. We will see in Section 7 that bootstrapping with these noisy translations is essential.</p><p>We consider two fundamentally different noise injection regimes: <ref type="formula">(1)</ref>   <ref type="figure">Figure 3</ref> shows an example. (2) In the sampled noise setting, we do not use all noise functions at once but sample a single one per data instance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Training regimes</head><p>We denote the sets of graphs and corresponding texts by G and T . The set of available supervised examples (x, y) ∈ G × T is called S ⊂ G × T . P g and P t are probabilistic models that generate, conditioned on any input, a graph (g) or a text (t). Unsupervised training. We first obtain a language model for both graphs and text by training one epoch with the denoising auto-encoder objective:</p><formula xml:id="formula_1">L denoise = E x∼G [− log P g (x|C(x))] + E y∼T [− log P t (y|C(y))]</formula><p>where C ∈ C comp for composed noise and C ∈ {swap, blank, drop, repeat, rule} for sampled noise. In this pretraining epoch only, we use all possible noise functions individually on all available data. As sampled noise incorporates five different noise functions and composed noise only one, this results in five times more pretraining samples for sampled noise than for composed noise.</p><p>In subsequent epochs, we additionally consider L back as training signal:</p><formula xml:id="formula_2">L back = E x∼G [− log P g (x|z * (x))] + E y∼T [− log P t (y|w * (y))] z * (x) = arg max z P t (z|x) w * (y) = arg max w P g (w|y)</formula><p>This means that, in each iteration, we apply the current model to backtranslate a text (graph) to obtain a potentially imperfect graph (text) that we can use as noisy source with the clean original input being the target. This gives us a pseudo-parallel training instance for the next iteration -recall that  we address unsupervised generation, i.e., without access to parallel data. The total loss in these epochs is L back + L denoise , where now L denoise only samples one possible type of noise independently for each data instance. Supervised training. Our intended application is an unsupervised scenario. For our two datasets, however, we have labeled data (i.e., a "parallel corpus") and so can also compare our model to its supervised variant. Although supervised performance is generally better, it serves as a reference point and gives us an idea of the impact of supervision as opposed to factors like model architecture and hyperparameters. The supervised loss is simply defined as follows:</p><formula xml:id="formula_3">L sup = E (x,y)∼S [− log P t (y|x) − log P g (x|y)]</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Data</head><p>For our experiments, we randomly split the VG images 80/10/10 into train/val/test. We then remove all graphs from train that also occur in one of the images in val or test. Finally, we unify graph serialization duplicates with different texts to single instances with multiple references for graph→text and proceed analogously with text duplicates for text→graph. For WebNLG v2.1, we use the data splits as provided. Following <ref type="bibr" target="#b12">(Gardent et al., 2017a)</ref>, we resolve the camel case of relation names and remove underscores from entity names in a preprocessing step. For both datasets, the order of facts in graph serializations corresponds to the order of triples in the original dataset. Because of VG's enormous size and limited computation power, we additionally create a closed-domain ball   <ref type="bibr" target="#b28">(Lin et al., 2018)</ref>; the CHRF++ script is from <ref type="bibr" target="#b42">(Popović, 2017b)</ref>.</p><p>sports subset of VG, called VG ball , which we can use to quickly conduct additional experiments (see Section 7). We identify all images where at least one region graph contains at least one fact that mentions an object ending with ball and take all regions from them (keeping data splits the same). In contrast to alternatives like random subsampling, we consider this domain-focused construction more realistic. <ref type="table" target="#tab_2">Table 2</ref> shows relevant statistics for all datasets. While VG and WebNLG have similar statistics, VG is around 70 times larger than WebNLG, which makes it an interesting benchmark for future research, both supervised and unsupervised. Apart from size, there are two important differences:</p><p>(1) The VG graph schema has been freely defined by crowd workers and thus features a large variety of different relations. (2) The percentage of graph tokens occurring in the text, a measure important for the text→graph task, is lower for VG than for WebNLG. Thus, VG graphs contain more details than their corresponding texts, which is a characteristic feature of the domain of image captions: they mainly describe the salient image parts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Training details</head><p>We train all models with the Adam optimizer (Kingma and Ba, 2015) for maximally 30 epochs. We stop supervised models early when L sup does not decrease on val for 10 epochs. Unsupervised models are stopped after 5 iterations on VG because of its big size and limited computational resources. All hyperparameters and more details are described in Appendices A and B. Our implementation is based on AllenNLP <ref type="bibr" target="#b14">(Gardner et al., 2017)</ref>.</p><p>In unsupervised training, input graphs and texts are the same as in supervised training -only the gold target sides are ignored. While it is an artificial setup to split paired data and treat them as  <ref type="table">Table 4</ref>: BLEU scores on VG for our unsupervised models evaluated for graph→text at different iterations. U is calculated on all unlabeled data used for training. V 100 is a 100-size random sample from val. All results are computed with scripts from <ref type="bibr" target="#b28">(Lin et al., 2018).</ref> unpaired, this not only makes the supervised and unsupervised settings more directly comparable, but also ensures that the text data resemble the evaluation texts in style and domain. For the purpose of experiments on a benchmark, this seems appropriate to us. For a concrete use case, it would be an important first step to find adequate texts that showcase the desired language style and that are about a similar topic as the KGs that are to be textualized. As KGs are rarely the only means of storing information, e.g., in an industrial context, such texts should not be hard to come by in practice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results and Discussion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Text generation from graphs</head><p>Model selection. <ref type="table">Table 4</ref> shows how performance of our unsupervised model changes at every backtranslation iteration, measured in BLEU <ref type="bibr" target="#b36">(Papineni et al., 2002)</ref>, a common metric for natural language generation. For model selection, we adopt the two methods proposed by <ref type="bibr" target="#b27">Lample et al. (2018b)</ref>, i.e., a small validation set (we take a 100-size random subset of val, called V 100 ) and a fully unsupervised criterion (U) where BLEU compares an unlabeled sample with its back-and-forth translation. We confirm their finding that U is not reliable for neural <ref type="bibr">(a)</ref>   <ref type="table">Table 5</ref>: Texts generated from graph in <ref type="figure" target="#fig_0">Fig. 2.</ref> text generation models whereas V 100 correlates better with performance on the larger test sets. We use V 100 for model selection in the rest of this paper.</p><p>Quantitative evaluation. <ref type="table" target="#tab_4">Table 3</ref> shows BLEU, METEOR <ref type="bibr" target="#b2">(Banerjee and Lavie, 2005)</ref> and CHRF++ <ref type="bibr" target="#b41">(Popović, 2017a)</ref> for our unsupervised models and the rule baseline R graph→text , which is in many cases, i.e., if parallel graph-text data are scarce, the only alternative. First, we observe that R graph→text performs much better on WebNLG than VG, indicating that our new benchmark poses a tougher challenge. Second, our unsupervised models consistently outperform this baseline on all metrics and on both datasets, showing that our method produces textual descriptions much closer to human-generated ones. Third, noise composition, the general default in unsupervised machine translation, does not always perform better than noise sampling. Thus, it is worthwhile to try different noise settings for new tasks or datasets.</p><p>Surprisingly, supervised and unsupervised models perform nearly on par. Real supervision does not seem to give much better guidance in training than our unsupervised regime, as measured by our three metrics on two different datasets. Some metric-dataset combinations even favor one of the unsupervised models. Our qualitative observations provide a possible explanation for that. Qualitative observations. Taking a look at example generations <ref type="table">(Table 5)</ref>, we also see qualitatively how much easier it is to grasp the content of our natural language summarization than reading through a simple enumeration of KG facts. We find that the unsupervised model (c) seems to output the KG information in a more complete manner than its supervised counterpart (d). The supervision probably introduces a bias present in the training data that image captions focus on salient image parts and therefore the supervised model is encouraged to omit information. As it never sees a corresponding   text-graph pair together, the unsupervised model cannot draw such a conclusion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Graph extraction from texts</head><p>We evaluate semantic parsing (text→graph) performance by computing the micro-averaged F1 score of extracted facts. If there are multiple reference graphs (cf. Section 5.1), an extracted fact is considered correct if it occurs in at least one reference graph. For the ground truth number of facts to be extracted from a given text, we take the maximum number of facts of all its reference graphs.</p><p>Model selection. <ref type="table" target="#tab_8">Table 6</ref> shows that (compared to text generation quality) U is more reliable for text→graph performance. For sampled noise, it correctly identifies the best iteration, whereas for composed noise it chooses second best. In both noise settings, V 100 perfectly chooses the best model. Quantitative observations. <ref type="table" target="#tab_9">Table 7</ref> shows a comparison of our unsupervised models with two rule-based systems, our R text→graph and the highly domain-specific Stanford Scene Graph Parser (SSGP) by <ref type="bibr" target="#b49">Schuster et al. (2015)</ref>. We choose these two baselines to adequately represent the state of the art in the unsupervised setting. Recall from Section 2 that the only previous unsupervised works either cannot adapt to a target graph schema (open information extraction), which means their precision and recall of retrieved facts is always 0, or have been created for SQL query  generation from natural language questions <ref type="bibr" target="#b38">(Poon, 2013)</ref>, a related task that is yet so different that an adaptation to triple set generation from natural language statements is nontrivial. While rule-based systems do not automatically adapt to new graph schemas either, R text→graph and SSGP were at least designed with the scene graph domain in mind.</p><p>Although SSGP was not optimized to match the scene graphs from VG, its rules were still engineered to cover typical idiosyncrasies of textual image descriptions and corresponding scene graphs. Besides, we evaluate it with lemmatized reference graphs because it only predicts lemmata as predicates. All this gives it a major advantage over the other presented systems but it is nonetheless outperformed by our best unsupervised model -even on VG. This shows that our automatic method can beat even hand-crafted domain-specific rules.</p><p>Both R text→graph and SSGP fail to predict any fact from WebNLG. The DBpedia facts from WebNLG often contain multi-token entities while R text→graph only picks single tokens from the text. Likewise, SSGP models multi-token entities as two nodes VG  with an attr relation. This illustrates the importance of automatic adaptation to the target KG. Although our system uses R text→graph during unsupervised training and is similarly not adapted to the WebNLG dataset, it performs significantly better. Supervision helps more on WebNLG than on VG. The poor performance of R text→graph on WebNLG is probably a handicap for unsupervised learning.</p><p>Qualitative observations. <ref type="table" target="#tab_11">Table 8</ref> shows example facts extracted by different systems. R text→graph and SSGP are both fooled by the proximity of the noun pants and the verb play whereas our model correctly identifies man as the subject. It, however, fails to identify shirt as an entity and associates the two attributes colorful and white to pants. Only the supervised model produces perfect output.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Noise and translation completeness</head><p>Sampled noise only creates training pairs that either are complete rule-based translations or reconstruction pairs from a noisy graph to a complete graph or a noisy text to a complete text. In contrast, composed noise can introduce translations from a noisy text to a complete graph or vice versa and thus encourage a system to omit input information (cf. <ref type="figure">Fig. 3)</ref>. This difference is mirrored nicely in the results of our unsupervised systems for both tasks: composed noise performs better on VG where omit-ted information in an image caption is common and sampled noise works better on WebNLG where the texts describe their graphs completely.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Noise Ablation Study</head><p>Our unsupervised objectives are defined by different types of noise models. Hence, we examine their impact in a noise ablation study. <ref type="table" target="#tab_13">Table 9</ref> shows results for text→graph and graph→text on the validation splits of VG ball and WebNLG.</p><p>For both datasets and tasks, introducing variation via noise functions is crucial for the success of unsupervised learning. The model without noise (i.e., C(x) = x) fails completely as do all models lacking rule as type of noise, the only exception being the only-drop system on WebNLG. Even though drop seems to work equally well in this one case, the simple translations delivered by our rulebased systems clearly provide the most useful information for the unsupervised models -notably in combination with the other noise functions: removing rule and keeping all other types of noise (cf. "sample all but rule" and "comp. all but rule") performs much worse than leaving out drop.</p><p>We hypothesize that our two rule systems provide two important pieces of information:</p><p>(1) R graph→text helps distinguish data format tokens from text tokens and (2) R text→graph helps find probable candidate words in a text that form facts for the data output. As opposed to machine translation, where usually every word in a sentence is translated into a fluent sentence in the target language, identifying words that probably form a fact is more important in data-to/from-text generation.</p><p>We moreover observe that our unsupervised models always improve on the rule-based systems even when rule is the only type of noise: graph→text BLEU increases from 6.2/18.3 to 19.5/37.4 on VG ball /WebNLG and text→graph F1 from 14.4/0.0 to 18.5/31.0.</p><p>Finally, our ablation study makes clear that there is no best noise model for all datasets and tasks. We therefore recommend experimenting with both different sets of noise functions and noise injection regimes (sampled vs. composed) for new data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>We presented the first fully unsupervised approach to text generation from KGs and a novel approach to unsupervised semantic parsing that automatically adapts to a target KG. We showed the effectiveness of our approach on two datasets, WebNLG v2.1 and a new text↔graph benchmark in the visual domain, derived from Visual Genome. We quantitatively and qualitatively analyzed our method on text↔graph conversion. We explored the impact of different unsupervised objectives in an ablation study and found that our newly introduced unsupervised objective using rule-based translations is essential for the success of unsupervised learning.</p><p>We use the following settings for all our experiments: learning rate of 10 −4 , word embeddings of size 300, an LSTM hidden size of 250, a dropout rate of 0.2 and a batch size of 10. Following <ref type="bibr" target="#b27">Lample et al. (2018b)</ref>, we set p blank = p repeat = 0.2, p drop = 0.1. For inference, we decode greedily with a maximum number of 40 decoding steps. To speed up unsupervised learning, we increase the batch size to 64 when creating backtranslations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Model details</head><p>We train with homogeneous batches of one target output type (text or graph) at a time. We use a single GeForce GTX 1080 GPU for training and inference. In this environment, pure training takes approximately 9 ms per instance and inference, which also means backtranslation, takes approximately 21 ms per instance. This means that unsupervised learning approximately needs 30 ms per instance. WebNLG models use 10.6 million parameters, VG models have 60.7 million parameters. The difference is due to a larger vocabulary size of 70,800 for VG compared to 8,171 for WebNLG.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Results of all iterations on WebNLG</head><p>See  <ref type="table" target="#tab_0">Table 10</ref>: BLEU scores on WebNLG for our unsupervised models evaluated for graph→text at different iterations. U is calculated on all unlabeled data used for training. V 100 is a 100-size random sample from val. All results are computed with scripts from <ref type="bibr" target="#b28">(Lin et al., 2018)</ref>. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Example graph in our new VG benchmark.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>The composed noise setting is an adaptation of Lample et al. (2018a)'s noise model (blank•drop•swap) where our newly introduced noise functions rule and repeat are added to the start and end of the pipeline, i.e., all data samples are treated equally with the same noise function C comp := repeat•blank•drop•swap•rule.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Noise functions and their behavior on graphs and texts.</figDesc><table /><note>Man wearing a colorful shirt and white pants Man SEP wearing SEP colorful EOF shirt SEP attr SEP colorful EOF pants SEP attr SEP white EOF pants SEP playing SEP tennis pants SEP attr SEP white EOF shirt SEP attr SEP colorful EOF blanked pants SEP attr SEP white EOF shirt SEP attr SEP colorful EOF shirt SEP attr SEP colorful EOF blanked rule blank • drop • swap repeat L lm</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Statistics of WebNLG v2.1 and our newly created benchmark VG; VG ball is a subset of VG representing images from ball sports events. Data split sizes are given as number of graph-text pairs.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>Ours w/ composed noise 23.2 23.2 33.0 32.9 53.7 53.6 30.8 30.5 30.2 30.0 53.1 52.8</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">Visual Genome</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">WebNLG</cell><cell></cell></row><row><cell>graph → text</cell><cell cols="2">BLEU</cell><cell cols="2">METEOR</cell><cell cols="2">CHRF++</cell><cell cols="2">BLEU</cell><cell cols="2">METEOR</cell><cell cols="2">CHRF++</cell></row><row><cell></cell><cell>val</cell><cell>test</cell><cell>val</cell><cell>test</cell><cell>val</cell><cell>test</cell><cell>val</cell><cell>test</cell><cell>val</cell><cell>test</cell><cell>val</cell><cell>test</cell></row><row><cell>R graph→text</cell><cell>5.9</cell><cell cols="11">5.9 28.2 28.1 43.4 43.3 18.3 18.3 33.5 33.6 55.0 55.2</cell></row><row><cell>Ours w/ sampled noise</cell><cell cols="12">19.8 19.5 31.4 31.2 50.9 50.7 39.1 37.7 35.4 35.5 61.9 62.1</cell></row><row><cell>Ours supervised</cell><cell cols="12">26.5 26.4 32.3 32.2 53.7 53.6 35.1 34.4 39.6 39.5 64.1 64.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Results for unsupervised and supervised text generation. Note that training a supervised model on millions of labeled samples is usually not an option. Best unsupervised models are identified by best BLEU on V 100 . BLEU and METEOR are computed with scripts from</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>71.0 21.7 19.1 18.8 49.3 22.1 22.1 21.7 3 58.2 19.3 18.6 18.3 45.9 18.7 19.7 19.4 4 62.3 18.3 19.1 18.8 54.4 19.9 20.8 20.5 5 63.7 19.8 19.0 18.7 49.0 18.8 19.0 18.8</figDesc><table><row><cell></cell><cell>sampled noise</cell><cell></cell><cell>composed noise</cell></row><row><cell>#</cell><cell cols="2">U V100 val test</cell><cell>U V100 val test</cell></row><row><cell cols="2">1 19.1 1.0 1.2</cell><cell cols="2">1.2 17.0 2.0 2.2</cell><cell>2.2</cell></row><row><cell>2</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 6 :</head><label>6</label><figDesc>F1 scores on VG for our models fromTable 4evaluated on text→graph at different iterations.</figDesc><table><row><cell>text → graph</cell><cell>VG val</cell><cell>test</cell><cell cols="2">WebNLG val test</cell></row><row><cell>R text→graph</cell><cell cols="2">13.4 13.1</cell><cell>0.0</cell><cell>0.0</cell></row><row><cell>Stanford SG Parser</cell><cell cols="2">19.5 19.3</cell><cell>0.0</cell><cell>0.0</cell></row><row><cell>Ours w/ sampled noise</cell><cell cols="4">19.1 18.8 38.5 39.1</cell></row><row><cell>Ours w/ composed noise</cell><cell cols="4">22.1 21.7 32.5 33.1</cell></row><row><cell>Ours supervised</cell><cell cols="4">23.5 23.0 52.8 52.8</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 7</head><label>7</label><figDesc></figDesc><table><row><cell>: F1 scores of facts extracted by our unsuper-</cell></row><row><cell>vised semantic parsing (text→graph) systems and our</cell></row><row><cell>model trained with supervision.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 8</head><label>8</label><figDesc></figDesc><table><row><cell>: Example fact extractions and evaluation wrt</cell></row><row><cell>reference graph (RG). Green: correct (∈ RG). Yellow:</cell></row><row><cell>acceptable fact, but / ∈ RG. Red: incorrect ( / ∈ RG).</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 9 :</head><label>9</label><figDesc>Ablation study of our models on val of VG ball and WebNLG v2.1. Models selected based on V 100 . Bold: best performance per column and block. Underlined: worse than corresponding rule-based system.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 10</head><label>10</label><figDesc>for all intermediate graph→text results of unsupervised training on WebNLG andTable 11for text→graph. We find similar trends as for VG(Tables 4 and 6) except for U being a less reliable performance indicator for text→graph in the sampled noise setting.</figDesc><table><row><cell></cell><cell cols="2">sampled noise</cell><cell cols="2">composed noise</cell></row><row><cell>#</cell><cell>U V100</cell><cell>val</cell><cell>U V100</cell><cell>val</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 11 :</head><label>11</label><figDesc>F1 scores on WebNLG for our unsupervised models evaluated for text→graph at different iterations. U is calculated on all unlabeled data used for training. V 100 is a 100-size random sample from val.</figDesc><table /><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank the anonymous reviewers for their helpful comments and gratefully acknowledge a Ph.D. scholarship awarded to the first author by the German Academic Scholarship Foundation (Studienstiftung des deutschen Volkes). This work was supported by by the BMBF as part of the project MLWin (01IS18050).</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Conversion of wordnet to a standard rdf/owl representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aldo</forename><surname>Mark Van Assem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guus</forename><surname>Gangemi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schreiber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth Edition of the International Conference on Language Resources and Evaluation</title>
		<meeting>the Fifth Edition of the International Conference on Language Resources and Evaluation</meeting>
		<imprint>
			<publisher>LREC</publisher>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.0473</idno>
	</analytic>
	<monogr>
		<title level="j">Computing Research Repository</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">METEOR: An automatic metric for MT evaluation with improved correlation with human judgments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satanjeev</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Lavie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization</title>
		<meeting>the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization<address><addrLine>Ann Arbor, Michigan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="65" to="72" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Graph-to-sequence learning using gated graph neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gholamreza</forename><surname>Haffari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P18-1026</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="273" to="283" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Generating fine-grained open vocabulary entity type descriptions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajarshi</forename><surname>Bhowmik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melo</forename></persName>
		</author>
		<idno type="DOI">10.18653/v1/P18-1081</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="877" to="888" />
		</imprint>
	</monogr>
	<note>Long Papers). Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Massive exploration of neural machine translation architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denny</forename><surname>Britz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Goldie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D17-1151</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Neural data-to-text generation: A comparison between pipeline and end-to-end architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Thiago Castro Ferreira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Der Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emiel</forename><surname>Emiel Van Miltenburg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Krahmer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1052</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="552" to="562" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Learning phrase representations using RNN encoder-decoder for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Merriënboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fethi</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/D14-1179</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1724" to="1734" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Structural neural encoders for AMR-to-text generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Damonte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shay</forename><forename type="middle">B</forename><surname>Cohen</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1366</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Long and Short Papers</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3649" to="3658" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Using local knowledge graph construction to scale Seq2Seq models to multidocument inputs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Gardent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chloé</forename><surname>Braud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1428</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4184" to="4194" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<title level="m">Christiane Fellbaum. 2005. Wordnet and wordnets</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<title level="m">Encyclopedia of Language and Linguistics</title>
		<editor>Keith Brown et al.</editor>
		<meeting><address><addrLine>Oxford</addrLine></address></meeting>
		<imprint>
			<publisher>Elsevier</publisher>
			<biblScope unit="page" from="665" to="670" />
		</imprint>
	</monogr>
	<note>second edition</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Creating training corpora for NLG micro-planners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Gardent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anastasia</forename><surname>Shimorina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shashi</forename><surname>Narayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Perez-Beltrachini</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P17-1017</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="179" to="188" />
		</imprint>
	</monogr>
	<note>Long Papers). Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The WebNLG challenge: Generating text from RDF data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Gardent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anastasia</forename><surname>Shimorina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shashi</forename><surname>Narayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Perez-Beltrachini</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W17-3518</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Conference on Natural Language Generation</title>
		<meeting>the 10th International Conference on Natural Language Generation<address><addrLine>Santiago de Compostela, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="124" to="133" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Allennlp: A deep semantic natural language processing platform</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Grus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oyvind</forename><surname>Tafjord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pradeep</forename><surname>Dasigi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nelson</forename><forename type="middle">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Schmitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><forename type="middle">S</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.07640</idno>
	</analytic>
	<monogr>
		<title level="m">Computing Research Repository</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">End-to-end content and plan selection for data-to-text generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Gehrmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Falcon</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henry</forename><surname>Elder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Rush</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W18-6505</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Conference on Natural Language Generation</title>
		<meeting>the 11th International Conference on Natural Language Generation</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="46" to="56" />
		</imprint>
	</monogr>
	<note>Tilburg University, The Netherlands. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Confidence driven unsupervised semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Goldwasser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roi</forename><surname>Reichart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Portland, Oregon, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1486" to="1495" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Incorporating copying mechanism in sequence-to-sequence learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiatao</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">K</forename><surname>Victor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P16-1154</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1631" to="1640" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Improving neural networks by preventing co-adaptation of feature detectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1207.0580</idno>
	</analytic>
	<monogr>
		<title level="j">Computing Research Repository</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A survey on semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aishwarya</forename><surname>Kamath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajarshi</forename><surname>Das</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Automated Knowledge Base Construction (AKBC)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3rd International Conference on Learning Representations</title>
		<meeting><address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-05-07" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Semisupervised classification with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Text Generation from Knowledge Graphs with Graph Transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rik</forename><surname>Koncel-Kedziorski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhanush</forename><surname>Bekal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1238</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Visual genome: Connecting language and vision using crowdsourced dense image annotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ranjay</forename><surname>Krishna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuke</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oliver</forename><surname>Groth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenji</forename><surname>Hata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><surname>Kravitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephanie</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yannis</forename><surname>Kalantidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">A</forename><surname>Shamma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">S</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei-Fei</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11263-016-0981-7</idno>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">123</biblScope>
			<biblScope unit="page" from="32" to="73" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Design of a knowledge-based report generator</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Kukich</surname></persName>
		</author>
		<idno type="DOI">10.3115/981311.981340</idno>
	</analytic>
	<monogr>
		<title level="m">21st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting><address><addrLine>Cambridge, Massachusetts, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="1983" />
			<biblScope unit="page" from="145" to="150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Unsupervised machine translation using monolingual corpora only</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexis</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ludovic</forename><surname>Denoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc&amp;apos;aurelio</forename><surname>Ranzato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Phrase-based &amp; neural unsupervised machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexis</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ludovic</forename><surname>Denoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc&amp;apos;aurelio</forename><surname>Ranzato</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1549</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">GitHub repository: tylin/coco-caption (Microsoft COCO caption evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinlei</forename><surname>Chen</surname></persName>
		</author>
		<ptr target="https://github.com/tylin/coco-caption" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>Hao Fang, and Ramakrishna Vedantam</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Nltk: The natural language toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Loper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bird</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL Interactive Poster and Demonstration Sessions</title>
		<meeting>the ACL Interactive Poster and Demonstration Sessions<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="214" to="217" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Visual relationship detection with language priors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cewu</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ranjay</forename><surname>Krishna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Multi-task identification of entities, relations, and coreference for scientific knowledge graph construction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mari</forename><surname>Ostendorf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1360</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3219" to="3232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Deep graph convolutional encoders for structured data to text generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diego</forename><surname>Marcheggiani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Perez-Beltrachini</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W18-6501</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Conference on Natural Language Generation</title>
		<meeting>the 11th International Conference on Natural Language Generation<address><addrLine>Tilburg University, The Netherlands</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Discretestate variational autoencoders for joint discovery and factorization of relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diego</forename><surname>Marcheggiani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Titov</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00095</idno>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="231" to="244" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">YAG: A template-based generator for real-time systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Susan</forename><forename type="middle">W</forename><surname>Mcroy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Songsak</forename><surname>Channarukul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Syed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ali</surname></persName>
		</author>
		<idno type="DOI">10.3115/1118253.1118293</idno>
	</analytic>
	<monogr>
		<title level="m">INLG&apos;2000 Proceedings of the First International Conference on Natural Language Generation</title>
		<meeting><address><addrLine>Mitzpe Ramon, Israel</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2000" />
			<biblScope unit="page" from="264" to="267" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A survey on open information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christina</forename><surname>Niklaus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Cetto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">André</forename><surname>Freitas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siegfried</forename><surname>Handschuh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Computational Linguistics</title>
		<meeting>the 27th International Conference on Computational Linguistics<address><addrLine>Santa Fe, New Mexico, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Bleu: a method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Jing</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="DOI">10.3115/1073083.1073135</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 40th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Philadelphia, Pennsylvania, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Grounded semantic parsing for complex knowledge extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ankur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hoifung</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Poon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/N15-1077</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Denver, Colorado</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="756" to="766" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Grounded unsupervised semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hoifung</forename><surname>Poon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="933" to="943" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Unsupervised semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hoifung</forename><surname>Poon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pedro</forename><surname>Domingos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2009 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Modern natural language interfaces to databases: Composing statistical parsing with semantic tractability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ana-Maria</forename><surname>Popescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Armanasu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Ko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Yates</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COL-ING 2004: Proceedings of the 20th International Conference on Computational Linguistics</title>
		<meeting><address><addrLine>Geneva, Switzerland. COLING</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="141" to="147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">chrF++: words helping character n-grams</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maja</forename><surname>Popović</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W17-4770</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second Conference on Machine Translation</title>
		<meeting>the Second Conference on Machine Translation<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="612" to="618" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">GitHub repository: mpopovic/chrf (chrF)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maja</forename><surname>Popović</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Data-to-Text Generation with Content Selection and Planning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ratish</forename><surname>Puduppully</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd Conference on Artificial Intelligence</title>
		<meeting>the 33rd Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Enhancing AMR-to-text generation with dual graph representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">R</forename><surname>Leonardo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Ribeiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gardent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gurevych</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1314</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3181" to="3192" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Claire Gardent, and Iryna Gurevych. 2020. Modeling global and local node contexts for text generation from knowledge graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">R</forename><surname>Leonardo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Ribeiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.11003</idno>
	</analytic>
	<monogr>
		<title level="j">Computing Research Repository</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Modeling relations and their mentions without labeled text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Limin</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning and Knowledge Discovery in Databases</title>
		<meeting><address><addrLine>Berlin, Heidelberg; Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="148" to="163" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Revision-based Generation of Natural Language Summaries Providing Historical Background: Corpus-based Analysis, Design, Implementation and Evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacques</forename><surname>Pierre Robin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Columbia University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
	<note>UMI Order No. GAX95-33653</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">ATOMIC: an atlas of machine commonsense for if-then reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maarten</forename><surname>Sap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><surname>Ronan Le Bras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chandra</forename><surname>Allaway</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Bhagavatula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannah</forename><surname>Lourie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brendan</forename><surname>Rashkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Roof</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Thirty-Third AAAI Conference on Artificial Intelligence, AAAI 2019, The Thirty-First Innovative Applications of Artificial Intelligence Conference, IAAI 2019, The Ninth AAAI Symposium on Educational Advances in Artificial Intelligence, EAAI 2019</title>
		<meeting><address><addrLine>Honolulu, Hawaii, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-01-27" />
			<biblScope unit="page" from="3027" to="3035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Generating semantically precise scene graphs from textual descriptions for improved image retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ranjay</forename><surname>Krishna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angel</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W15-2812</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth Workshop on Vision and Language</title>
		<meeting>the Fourth Workshop on Vision and Language<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="70" to="80" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Handling rare items in data-to-text generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anastasia</forename><surname>Shimorina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Gardent</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W18-6543</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Conference on Natural Language Generation</title>
		<meeting>the 11th International Conference on Natural Language Generation<address><addrLine>Tilburg University, The Netherlands</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="360" to="370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Unsupervised information extraction: Regularizing discriminative approaches with relation distribution losses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Etienne</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Guigue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Piwowarski</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1133</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1378" to="1387" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Conceptnet 5.5: An open multilingual graph of general knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robyn</forename><surname>Speer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><surname>Chin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Catherine</forename><surname>Havasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence, AAAI&apos;17</title>
		<meeting>the Thirty-First AAAI Conference on Artificial Intelligence, AAAI&apos;17</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4444" to="4451" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
		<editor>Z. Ghahramani, M. Welling, C. Cortes, N. D</editor>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weinberger</surname></persName>
		</author>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Reactive content selection in the generation of real-time soccer commentary</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kumiko</forename><surname>Tanaka-Ishii</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koiti</forename><surname>Hasida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Itsuki</forename><surname>Noda</surname></persName>
		</author>
		<idno type="DOI">10.3115/980691.980778</idno>
	</analytic>
	<monogr>
		<title level="m">36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics</title>
		<meeting><address><addrLine>Montreal, Quebec, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1282" to="1288" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">GTR-LSTM: A triple encoder for sentence generation from RDF data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianzhong</forename><surname>Bayu Distiawan Trisedya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P18-1151</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Melbourne, Australia. As</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1627" to="1637" />
		</imprint>
	</monogr>
	<note>sociation for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Handbook of knowledge representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Van Harmelen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Lifschitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bruce</forename><surname>Porter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>Elsevier</publisher>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Graph Attention Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petar</forename><surname>Veličković</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillem</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arantxa</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adriana</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Liò</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Representation learning for scene graph completion via jointly structural and visual embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonghao</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Shi</forename><surname>Zheng</surname></persName>
		</author>
		<idno type="DOI">10.24963/ijcai.2018/132</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence, IJCAI-18</title>
		<meeting>the Twenty-Seventh International Joint Conference on Artificial Intelligence, IJCAI-18</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="949" to="956" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Challenges in data-to-document generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Wiseman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stuart</forename><surname>Shieber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Rush</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D17-1239</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2253" to="2263" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Drug-Bank 5.0: a major update to the DrugBank database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>David S Wishart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yannick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">An</forename><forename type="middle">C</forename><surname>Feunang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elvis</forename><forename type="middle">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ana</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><forename type="middle">R</forename><surname>Marcu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tanvir</forename><surname>Grant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Sajed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carin</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zinat</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nazanin</forename><surname>Sayeeda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ithayavani</forename><surname>Assempour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifeng</forename><surname>Iynkkaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Maciejewski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Research</title>
		<editor>Le, Allison Pon, Craig Knox, and Michael Wilson</editor>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">D1</biblScope>
			<biblScope unit="page" from="1074" to="1082" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Structured relation discovery using generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Limin</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aria</forename><surname>Haghighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2011 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Edinburgh, Scotland, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1456" to="1466" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
