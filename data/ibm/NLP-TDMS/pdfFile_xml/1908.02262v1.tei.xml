<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Predicting Prosodic Prominence from Text with Pre-trained Contextualized Word Representations</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aarne</forename><surname>Talman</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Digital Humanities</orgName>
								<orgName type="institution">University of Helsinki</orgName>
								<address>
									<country key="FI">Finland</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Basement AI</orgName>
								<address>
									<country key="FI">Finland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antti</forename><surname>Suni</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Digital Humanities</orgName>
								<orgName type="institution">University of Helsinki</orgName>
								<address>
									<country key="FI">Finland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hande</forename><surname>Celikkanat</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Digital Humanities</orgName>
								<orgName type="institution">University of Helsinki</orgName>
								<address>
									<country key="FI">Finland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sofoklis</forename><surname>Kakouros</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Digital Humanities</orgName>
								<orgName type="institution">University of Helsinki</orgName>
								<address>
									<country key="FI">Finland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">JÃ¶rg</forename><surname>Tiedemann</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Digital Humanities</orgName>
								<orgName type="institution">University of Helsinki</orgName>
								<address>
									<country key="FI">Finland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martti</forename><surname>Vainio</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Digital Humanities</orgName>
								<orgName type="institution">University of Helsinki</orgName>
								<address>
									<country key="FI">Finland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Predicting Prosodic Prominence from Text with Pre-trained Contextualized Word Representations</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T11:22+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we introduce a new natural language processing dataset and benchmark for predicting prosodic prominence from written text. To our knowledge this will be the largest publicly available dataset with prosodic labels. We describe the dataset construction and the resulting benchmark dataset in detail and train a number of different models ranging from feature-based classifiers to neural network systems for the prediction of discretized prosodic prominence. We show that pre-trained contextualized word representations from BERT outperform the other models even with less than 10% of the training data. Finally we discuss the dataset in light of the results and point to future research and plans for further improving both the dataset and methods of predicting prosodic prominence from text. The dataset and the code for the models are publicly available.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Prosodic prominence, i.e., the amount of emphasis that a speaker gives to a word, has been widely studied in phonetics and speech processing. However, the research on text-based natural language processing (NLP) methods for predicting prosodic prominence is somewhat limited. Even in the text-to-speech synthesis domain, with many recent methodological advances, work on symbolic prosody prediction has lagged behind. We believe that this is mainly due to the lack of suitable datasets. Existing, publicly available annotated speech corpora, are very small by current standards.</p><p>In this paper we introduce a new NLP dataset and benchmark for predicting prosodic prominence from text which is based on the recently published LibriTTS corpus <ref type="bibr" target="#b33">(Zen et al., 2019)</ref>, containing automatically generated prosodic prominence labels for over 260 hours or 2.8 million words of English audio books, read by 1230 different speakers. To our knowledge this will be the largest publicly available dataset with prosodic annotations. We first give some background about prosodic prominence and related research in Section 2. We then describe the dataset construction and annotation method in Section 3.</p><p>Prosody prediction can be turned into a sequence labeling task by giving each word in a text a discrete prominence value based on the amount of emphasis the speaker gives to the word when reading the text. In Section 4 we explain the experiments and the experimental results using a number of different sequence labeling approaches and show that pre-trained contextualized word representations from BERT <ref type="bibr" target="#b3">(Devlin et al., 2019)</ref> outperform our other baselines even with less than 10% of the training data. Although BERT has been previously applied in various sequence labeling tasks, like named entity recognition <ref type="bibr" target="#b3">(Devlin et al., 2019)</ref>, to the best of our knowledge, this is the first application of BERT in the task of predicting prosodic prominence. We analyse the results in Section 5, comparing BERT to a bidirectional long shortterm memory (BiLSTM) model and looking at the types of errors made by these selected models. We find that BERT outperforms the BiLSTM model across all the labels.</p><p>Finally in Section 6 we discuss the methods in light of the experimental results and highlight areas that are known to negatively impact the results. We also discuss the relevance of pre-training for the task of predicting prosodic prominence. We conclude by pointing to future research both in developing better methods for predicting prosodic prominence but also to further improve the quality of the dataset. The dataset and the PyTorch code for the models are available on GitHub: https://github.com/ Helsinki-NLP/prosody.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Prosodic Prominence</head><p>Every word and utterance in speech encompasses phonetic and phonological properties that are not resulting from the choice of the underlying lexical items and that encode meaning in addition to that of the individual lexemes. These properties are referred to as prosody and they depend on a variety of factors such as the semantic and syntactic relations between these items, and their rhythmic grouping <ref type="bibr" target="#b28">(Wagner and Watson, 2010)</ref>. Prosodic variation in speech contributes to a large extend to the perception of natural sounding speech. Prosodic prominence represents one type of prosodic phenomenon that manifests through the subjective impression of emphasis in speech where certain words are interpreted as more salient within their lexical surrounding context <ref type="bibr" target="#b28">(Wagner and Watson, 2010;</ref><ref type="bibr" target="#b27">Terken and Hermes, 2000)</ref>.</p><p>Due to the inherent difficulty in determining prominence -even for human subjects, see, e.g., <ref type="bibr" target="#b31">(Yoon et al., 2004</ref>) -the development of automatic tools for the annotation of prominent units has been a difficult task. This is exemplified from the large degree of discrepancy observed between human annotators when labeling prominence where the inter-transcriber agreement can vary substantially based on a multitude of factors such as the choice of annotators or annotation method <ref type="bibr" target="#b16">(Mo et al., 2008;</ref><ref type="bibr" target="#b31">Yoon et al., 2004;</ref>. Similarly, in prominence production, certain degree of freedom in prominence placement and large variability between styles and speakers <ref type="bibr" target="#b32">(Yuan et al., 2005)</ref>, renders the task of prominence prediction from text very difficult compared to most NLP tasks involving text only.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Generating Prominence Annotations</head><p>Throughout the literature a number of methods have been proposed for the labeling of prosodic prominence. These methods can be roughly categorized on the basis of the need for training data (manual prosodic annotations) into supervised and unsupervised, but crucially, on the basis of the information they utilize from speech and language to generate their predictions (prominence labels).</p><p>As prominence perception has been found to correlate with acoustic-phonetic features <ref type="bibr" target="#b12">(Lieberman, 1960)</ref>, with the constituent syntactic structure of an utterance <ref type="bibr" target="#b4">(Gregory and Altun, 2004;</ref><ref type="bibr" target="#b28">Wagner and Watson, 2010;</ref><ref type="bibr" target="#b1">Bresnan, 1973)</ref>, with the frequency of occurrence of individual lexical items <ref type="bibr" target="#b18">(Nenkova et al., 2007;</ref><ref type="bibr" target="#b8">Jurafsky et al., 2001)</ref>, and with the probabilities of contiguous lexical sequences <ref type="bibr" target="#b7">(Jurafsky, 1996)</ref>, automatic methods have been developed utilizing these features either in combination or independently <ref type="bibr" target="#b18">(Nenkova et al., 2007;</ref><ref type="bibr" target="#b19">Ostendorf et al., 1995;</ref><ref type="bibr" target="#b11">Levow, 2008)</ref>.</p><p>Overall, these features can be largely divided into two categories: (i) acoustic (derived from the sound pressure waveform of the speech signal) and (ii) language (extracted by studying the form of the language; for instance, semantic or syntactic factors in the language). Both acoustic and language-based features have been shown to provide good overall performance in detecting prominence (in both supervised and unsupervised cases), where, however, the methods utilizing acoustic features seem to provide better performance for the unsupervised detection of prominences in speech <ref type="bibr" target="#b26">(Suni et al., 2017;</ref><ref type="bibr" target="#b29">Wang and Narayanan, 2007;</ref>, with state-of-the-art results reaching high level of accuracy, close to that of the inter-annotator agreement for the data. While the top-down linguistic information is known to correlate with perceptual prominence, in this paper we want to make a clear distinction between data labelling and textbased prediction. Thus, in this work, we utilize purely acoustic prominence annotations of the speech data using the method developed by <ref type="bibr" target="#b26">Suni et al. (2017)</ref> as the prosodic reference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Predicting Prosodic Prominence from Text</head><p>To what extent prosodic prominence can be predicted from textual input only has been a topic of inquiry in linguistics for a long time. In traditional generative phonology <ref type="bibr" target="#b2">(Chomsky and Halle, 1968)</ref>, accent placement was considered to be fully determined by linguistic structure, whereas a seminal work by <ref type="bibr" target="#b0">Bolinger (1972)</ref> emphasized the importance and relevance of the lexical semantic context as well as the speakers' intention, positing that, in general, a mind reading ability may be necessary to determine prominent words in a sentence.  As longstanding inquiries hold, the goal of reliably predicting the placement of prominent entities from information automatically derived from textual resources is still ongoing. Several efforts have been made towards this direction, especially in text-to-speech (TTS) synthesis research, where generation of appropriate prosody would increase both intelligibility and quality of synthetic speech. Before the deep learning paradigm shift in NLP, several linguistic features were examined for prominence prediction, including function-content word distinction, part-of-speech class, and information status <ref type="bibr" target="#b5">(Hirschberg, 1993)</ref>. Statistical features like unigrams, bigrams, and TF-IDF have also been frequently used <ref type="bibr" target="#b13">(Marsi et al., 2003)</ref>. Later, the accent ratio, or simply the average accent status of a word type in the given corpus, was found to be a stronger predictor than linguistic features in the accent prediction task <ref type="bibr" target="#b18">(Nenkova et al., 2007)</ref>, suggesting that lexical information may be more relevant than linguistic structure for the prominence prediction task.</p><p>Recently, continuous representations of words have become commonplace in prosody predic-tion for TTS, though the symbolic level is often omitted and pitch and duration are predicted directly using lexical embeddings <ref type="bibr" target="#b30">(Watts, 2012</ref>). Yet, closely related to the proposed method, <ref type="bibr" target="#b22">(Rendel et al., 2016)</ref> experimented with various lexical embeddings as an input to a Bi-directional LSTM model, predicting binary prominence labels. Training on a proprietary, manually annotated single speaker corpus of 3730 sentences, they achieved an F-score of 0.71 with Word2Vec <ref type="bibr" target="#b15">(Mikolov et al., 2013</ref>) embeddings, with a clear improvement over traditional linguistic features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Dataset</head><p>We introduce, automatically generated, high quality prosodic annotations for the recently published LibriTTS corpus <ref type="bibr" target="#b33">(Zen et al., 2019)</ref>. The LibriTTS corpus is a cleaned subset of LibriSpeech corpus <ref type="bibr" target="#b20">(Panayotov et al., 2015)</ref>, derived from English audiobooks of the LibriVox project. <ref type="bibr">1</ref> We selected the 'clean' subsets of LibriTTS for annotation, comprising of 262.5 hours of read speech from 1230 speakers. The transcribed sentences were aligned 1 https://librivox.org  <ref type="table">Table 2</ref>: Example sentence with the annotation from the dataset. Discrete prominence values were used in the experiments of this paper. The real-valued labels are used for generation of the discrete labels, however, they could also be used directly for prominence prediction.</p><p>with the Montreal forced aligner <ref type="bibr" target="#b14">(McAuliffe et al., 2017)</ref>, using a pronunciation lexicon and acoustic models trained on the LibriSpeech dataset. The aligned sentences were then prosodically annotated with word-level acoustic prominence labels. For the annotation, we used the Wavelet Prosody Analyzer toolkit 2 , which implements the method described in <ref type="bibr" target="#b26">(Suni et al., 2017)</ref>. Briefly, the method consists of 1) the extraction of pitch and energy signals from the speech data and duration from the word level alignments, 2) filling the unvoiced gaps in extracted signals by interpolation followed by smoothing and normalizing, 3) combining the normalized signals by summing or multiplication, and 4) performing a continuous wavelet transform (CWT) on the composite signal and extracting continuous prominence values as lines of maximum amplitude across wavelet scales (see <ref type="figure" target="#fig_0">Figure 1</ref>). Essentially, the method assumes that the louder, the longer, and the higher, the more prominent. On top of this, the wavelet transform provides multi-resolution contextual information; the more the word stands out from its environment in various time scales, the more prominent the word is perceived.</p><p>For the current study, continuous prominence values were discretized to two (non-prominent, prominent) or three (non prominent, somewhat prominent, very prominent) classes. The binary case is closely related to the pitch accent detection task, aiming for results comparable with the majority of the literature on the topic. The weights in constructing the composite signal and discretization thresholds were adjusted based on The Boston University radio news corpus <ref type="bibr" target="#b19">(Ostendorf et al., 1995)</ref>, containing manually annotated pitch accent labels. This corpus is often used in the evaluation of pitch accent annotation and prediction quality, with the current annotation method yielding state-of-the-art accuracy in word level acoustic-based accent detection, 85.3%, us-2 https://github.com/asuni/wavelet_ prosody_toolkit ing weights 1.0, 0.5 and 1.0 for F0, energy and duration respectively, and using multiplication of these features in signal composition. For threeway discretization, the non-prominent / prominent cut-off was maintained and the prominent class was split to two classes of roughly equal size. Statistics of the resulting dataset are described in table 1. The full dataset is available for download here: https://github.com/ Helsinki-NLP/prosody. Although not discussed in this paper, the described acoustic annotation and text-based prediction methods can be applied to prosodic boundaries too, and the boundary labels will be included in the dataset at a later stage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>In this section we describe the experimental setup and the results from our experiments in predicting discrete prosodic prominence labels from text using the corpus described above.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Setup</head><p>We performed experiments with the following models:</p><p>â¢ BERT-base uncased <ref type="bibr" target="#b3">(Devlin et al., 2019)</ref> â¢ 3-layer 600D Bidirectional Long Short-Term Memory (BiLSTM) (Hochreiter and Schmidhuber, 1997) â¢ Minitagger (SVM) <ref type="bibr" target="#b25">(Stratos and Collins, 2015)</ref> + GloVe <ref type="bibr" target="#b21">(Pennington et al., 2014)</ref> â¢ MarMoT (CRF) <ref type="bibr" target="#b17">(Mueller et al., 2013)</ref> â¢ Majority class per word The models were selected so that they cover a wide variety of different architectures from feature-based statistical approaches to neural networks and pre-trained language models. The models are described in more detail below.</p><p>We use the Huggingface PyTorch implementation of BERT available in the pytorch transformers library, 3 which we further fine-tune during training. We take the last hidden layer of BERT and train a single fully-connected classifier layer on top of it, mapping the representation of each word to the labels. For our experiments we use the smaller BERT-base model using the uncased alternative. We use a batch size of 32 and fine-tune the model for 2 epochs.</p><p>For BiLSTM we use pre-trained 300D GloVe 840B word embeddings <ref type="bibr" target="#b21">(Pennington et al., 2014)</ref>. The initial word embeddings are fine-tuned during training. As with BERT, we add one fullyconnected classifier layer on top of the BiLSTM, mapping the representation of each word to the labels. We use a dropout of 0.2 between the layers of the BiLSTM. We use a batch size of 64 and train the model for 5 epochs.</p><p>For the SVM we use Minitagger 4 implementation by <ref type="bibr" target="#b25">Stratos and Collins (2015)</ref> using each dimension of the pre-trained 300D GloVe 840B word embeddings as features, with context-size 1, i.e. including the previous and the next word in the context.</p><p>For the conditional random field (CRF) model we use MarMot 5 by <ref type="bibr" target="#b17">Mueller et al. (2013)</ref> with the default configuration. The model applies standard feature templates that are used for part-ofspeech tagging such as surrounding words as well as suffix and prefix features. We did not optimize the feature model nor any of the other hyperparameters.</p><p>All systems except the Minitagger and CRF are our implementations using PyTorch and are made available on GitHub: https://github.com/ Helsinki-NLP/prosody.</p><p>For the experiments we used the larger train-360 training set. We report both 2-way and 3-way classification results. In the 2-way classification task we take the three prominence labels and merge labels 1 and 2 into a single prominent class.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results</head><p>All models reach over 80% in the 2-way classification task while 3-way classification accuracy stays below 70% for all of them. The BERTbased model gets the highest accuracy of 83.2% and 68.6% in the 2-way and 3-way classification tasks, respectively, demonstrating the value of a pytorch-transformers 4 https://github.com/karlstratos/ minitagger 5 http://cistern.cis.lmu.de/marmot/ pre-trained language model in this task. The 3layer BiLSTM achieves 82.1% in the 2-way classification and 66.4% in the 3-way classification task. The traditional feature-based classifiers perform slightly below the neural network models, with the CRF obtaining 81.8% and 66.4% for the two classification tasks, respectively. The Minitagger SVM model's test accuracies are slightly lower than the CRF's with 80.8% and 65.4% test accuracies. Finally taking a simple majority class per word gives 80.2% for the 2-way classification task and 62.4% for the 3-way classification task. The results are listed in <ref type="table">Table 3</ref>. The fairly low results across the board highlight the difficulty of the task of predicting prosodic prominence from text.</p><p>To better understand how much training data is needed in the two classification tasks, we trained selected models with different size subsets of the train-360 training data. The selected subsets were: 1%, 5%, 10%, 50% and 100% of the training examples (token-label pairs). <ref type="figure">Figures 2 and 3</ref> contain the learning curves for the 2-way and 3-way classification tasks, for all the models except for the majority and random baselines.</p><p>For all models and for both of the classification tasks we notice that they achieve quite high test accuracy already with a very small number of training examples. For most of the models the biggest improvement in performance is achieved when moving from 1% of the training examples to 5%. All models have reached close to their full predictive capacity with only 10% of the training examples. For example, BERT achieves 2-way classification test accuracy of 82.6% with 10% of the training data, which is only -0.6% points lower than the accuracy with the full training set. In the 3-way classification task 10% of the training data gives 67.1% for BERT, which is -1.7% points below the accuracy with the full training set.</p><p>Interestingly, in the 2-way classification task the BiLSTM model shows a slightly different learning curve, having already quite a high performance with just 1% of the training data, but then making no improvement between 1% and 5%. However, between 5% and 100% the BiLSTM model improvement is almost linear.</p><p>As the proposed dataset has been automatically generated as described in Section 3, we also tested the best two models, BERT and BiLSTM, with a manually annotated test set from The Boston University radio news corpus <ref type="bibr" target="#b19">(Ostendorf et al., 1995)</ref>.  <ref type="table">Table 3</ref>: Experimental results (%) for the 2 and 3-way classification tasks.</p><p>For this experiment we trained the models using the train-360 training set (as above) replacing only the test set. The results of this experiment are shown in <ref type="table">Table 4</ref>. The good results 6 from this experiment provide further support for the quality of the new dataset. Notice also that the difference between BERT and BiLSTM is much bigger with this test set (+3.9% compared to +1.1%). This difference could be due to the genre difference between the two test sets, with the Boston University news corpus being more contemporary compared to the source for our proposed dataset <ref type="bibr">(pre-1923 books)</ref>. This point will be further discussed in Section 6.</p><p>Model vs expert vs acoustic BERT-base 82.9% 82.1% 3-layer BiLSTM 79.0% 79.3% <ref type="table">Table 4</ref>: Test accuracies (%) for the Boston University radio news corpus (2-way classification). expert = expert annotated perceptual prominence labels, acoustic = our acoustic prominence labels</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Analysis</head><p>The experimental results show that although predicting prosodic prominence is a fairly difficult task, pre-trained contextualized word representations clearly help, as can be seen from the results for BERT. The difference between BERT and the other models is clear if we compare the other models with BERT fine-tuned with a small fraction of the training data. In fact, BERT already outperforms the other models with just 5% of the training examples in the 2-way classification case and with 10% of the training data in the 3-way classification case. This can be seen as an indication that BERT has acquired implicit semantic or syntactic information during pre-training that is useful in the task of predicting prosodic prominence.</p><p>To gain a better understanding of the types of predictive errors BERT makes, we look at the confusion matrices for the two classification tasks and compare those with the confusion matrices for the BiLSTM.</p><p>The 3-way classification confusion matrices are more informative as they allow comparison of the two models with respect to the predicted label in cases of error. <ref type="figure" target="#fig_2">Figure 4</ref> contains the 3-way classification confusion matrix for BERT and <ref type="figure" target="#fig_3">Figure 5</ref> for the BiLSTM model.  In the 3-way classification task, when the gold label is 0 (non prominent) BERT makes more errors with prediction being 2 (very prominent) compared to the BiLSTM model. However, when the gold label is 2 (very prominent) BiLSTM makes more predictions with 0 (non prominent) compared to BERT. In general for 0 labels BERT seems to have higher precision and BiLSTM better recall, whereas for label 2 BERT has clearly higher recall and precision. Both models have low precision and recall for the less distinctive prominence (label 1). It seems that the clearest difference between the two models is in their ability to predict high prominence (label 2).</p><p>We also provide the confusion matrices for the 2-way classification task for the two models. <ref type="figure" target="#fig_4">Figure 6</ref> contains the 2-way classification confusion matrix for BERT and <ref type="figure" target="#fig_5">Figure 7</ref> for the BiLSTM model. Here BERT has slightly higher precision and recall across both of the labels.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion</head><p>We have shown above that prosodic prominence can reasonably well be predicted from text using different sequence-labelling approaches and models. However, the reported performance is still quite low, even for state-of-the-art systems based on large pre-trained language models such as BERT. We list a number of reasons for these shortcomings below and discuss their impact and potential mitigation.</p><p>Although the annotation method has been shown to be quite robust, errors in automatic alignment, signal processing, and quantization introduce noise to the labels. This noise might not be detrimental to the training due to dataset size, but the test results are affected. To measure the size of this effect, manual correction of a part of the test set could be beneficial.</p><p>It is well known that different speakers have different accents, varying reading proficiency, and reading tempo, which all impact the consistency of the labeling as the source speech data contains in total samples from over 1200 different speakers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>REF:</head><p>One way led to the left and the other to the right straight up the mountain . BERT: One way led to the left and the other to the right straight up the mountain .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>REF:</head><p>In the next moment he was concealed by the leaves . BERT: In the next moment he was concealed by the leaves .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>REF:</head><p>I had to read it over carefully , as the text must be absolutely correct . BERT: I had to read it over carefully , as the text must be absolutely correct .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>REF:</head><p>Where were you when you began to feel bad ? BERT: Where were you when you began to feel bad ?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>REF:</head><p>He is taller than the Indian , not so tall as Gilchrist . BERT: He is taller than the Indian , not so tall as Gilchrist . Given that inter-speaker agreement on pitch accent placement is somewhere between 80 and 90% <ref type="bibr" target="#b32">(Yuan et al., 2005)</ref>, we cannot expect large improvements without speaker-specific modelling.</p><p>The source speech data contains multitude of genres ranging from non-fiction to metric poems with fixed prominence patterns and children's stories with high proportion of words emphasized. The difference in genres could impact the test results. Moreover, the books included in the source speech data are all from pre-1923, whereas BERT and GloVe are pre-trained with contemporary texts. We expect that the difference between BERT and other models would be higher with a dataset drawn from a more contemporary source. As noted in Section 3, the difference between BERT and BiLSTM is much bigger with the The Boston University radio news corpus test set (+3.9% compared to +1.1% with our test set). This could be due to the genre, with The Boston University radio news corpus being derived from a more contemporary source.</p><p>Overall, our results for BERT highlight the importance of pre-training of the word representations. As we noticed, already with as little as 10% of the training data, BERT outperforms the other models when they are trained on the entire training set. This suggests that BERT has implicitly learned syntactic or semantic information relevant for the prosody prediction task. Our results are in line with the earlier results by <ref type="bibr" target="#b24">Stehwien et al. (2018)</ref> and <ref type="bibr" target="#b22">Rendel et al. (2016)</ref> who showed that pre-trained word embeddings improve model performance in the prominence prediction task. Table 5 lists five randomly selected examples from the test set and shows the prominence predictions by BERT compared to the reference annotation. These examples indicate that even if the overall accuracy of the model is not high, the predictions still look plausible in isolation.</p><p>Finally, the classifiers in this paper are trained on single sentences, losing any discourse-level information and relations to surrounding context. Increasing the context to contain, e.g., also previous sentences could improve the results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>In this paper we have introduced a new NLP dataset and benchmark for predicting prosodic prominence from text, which to our knowledge is the largest publicly available dataset with prosodic labels. We described the dataset creation and the resulting benchmark and showed that various sequence labeling methods can be applied to the task of predicting prosodic prominence using the dataset.</p><p>Our experimental results show that BERT outperforms the other models with just up to 10% of the training data, highlighting the effectiveness of pre-training for the task. It also highlights that the implicit syntactic or semantic features BERT has learned during pre-training are relevant for the specific task of predicting prosodic prominence.</p><p>We also discussed a number of limitations of the automatic annotation system, as well as our current models. Based on this discussion, and more broadly, on the findings of this paper, we want to focus our future research activities in two fronts. Firstly, we will further develop the dataset annotation pipeline, improving the quality of prominence annotation and adding prosodic boundary labels. Secondly, we will further de-velop methods and models for improved prediction of prosodic prominence. In particular, as our results have shown that pre-training helps in the task, fine-tuning BERT with data involving features that are known to impact prosodic prominence (like part-of-speech tagged data) before training on the prosody dataset could help to improve the model performance. Furthermore, we will look at speaker-aware models, genre adaptation, and models for increased context. And, finally, our ultimate goal is to incorporate these methods into the development of a state-of-the-art text-to-speech synthesizer.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Continuous Wavelet Transform Annotation method.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :Figure 3 :</head><label>23</label><figDesc>Test accuracy with different size subsets of the training data for the 2-way classification task. Test accuracy with different size subsets of the training data for the 3-way classification task.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>3-way classification task confusion matrix for BERT.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5</head><label>5</label><figDesc>: 3-way classification task confusion matrix for BiLSTM.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>2-way classification task confusion matrix for BERT.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 :</head><label>7</label><figDesc>2-way classification task confusion matrix for BiLSTM.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Real-valued label 1.473 0.333 0.003 0.167 NA 2.160 0.006 0.037 0.719 NA</figDesc><table><row><cell>Token</cell><cell>Tell</cell><cell>me</cell><cell cols="2">you rascal</cell><cell>,</cell><cell>where</cell><cell>is</cell><cell>the</cell><cell>pig</cell><cell>?</cell></row><row><cell>Discrete label</cell><cell>2</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>NA</cell><cell>2</cell><cell>0</cell><cell>0</cell><cell>1</cell><cell>NA</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 5 :</head><label>5</label><figDesc>Typical 3-way prominence predictions of BERT compared to reference labels.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">https://github.com/huggingface/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">Better results have been reported on Boston dataset using lexical features, but there are methodological concerns related to cross-validation training and speakers reading the same text, see discussion on<ref type="bibr" target="#b23">(Rosenberg, 2009</ref>).</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>Talman, Celikkanat and Tiedemann are supported by the FoTran project, funded by the European Research Council (ERC) under the European Unions Horizon 2020 research and innovation programme (grant agreement no. 771113). We also gratefully acknowledges the support of the Academy of Finland through projects no. 314062 from the ICT 2023 call on Computation, Machine Learning and Artificial Intelligence, no. 1293348 from the call on Digital Humanities, and an Academy Fellowship project no. 309575.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Accent is predictable (if you&apos;re a mind-reader). Language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dwight</forename><surname>Bolinger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1972" />
			<biblScope unit="page" from="633" to="644" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Sentence stress and syntactic transformations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Joan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bresnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Approaches to natural language</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1973" />
			<biblScope unit="page" from="3" to="47" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">The sound pattern of english</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Chomsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Morris</forename><surname>Halle</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1968" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Long and Short Papers</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Using conditional random fields to predict pitch accents in conversational speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Michelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yasemin</forename><surname>Gregory</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Altun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics (ACL-2004)</title>
		<meeting>the 42nd Annual Meeting on Association for Computational Linguistics (ACL-2004)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page">677</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Pitch accent in context predicting intonational prominence from text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julia</forename><surname>Hirschberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="305" to="340" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">JÃ¼rgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A probabilistic model of lexical and syntactic access and disambiguation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive science</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="137" to="194" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Probabilistic relations between words: Evidence from reduction in lexical production</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michelle</forename><surname>Gregory</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William D</forename><surname>Raymond</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Typological studies in language</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="229" to="254" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Analyzing the contribution of top-down lexical and bottom-up acoustic cues in the detection of sentence prominence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sofoklis</forename><surname>Kakouros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joris</forename><surname>Pelemans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lyan</forename><surname>Verwimp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Wambacq</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Okko</forename><surname>RÃ¤sÃ¤nen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INTERSPEECH</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1074" to="1078" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">3pro-an unsupervised method for the automatic detection of sentence prominence in speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sofoklis</forename><surname>Kakouros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Okko</forename><surname>RÃ¤sÃ¤nen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Speech Communication</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="page" from="67" to="84" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Automatic prosodic labeling with conditional random fields and rich acoustic features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gina-Anne</forename><surname>Levow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third International Joint Conference on Natural Language Processing</title>
		<meeting>the Third International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Some acoustic correlates of word stress in american english</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Lieberman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="451" to="454" />
			<date type="published" when="1960" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Learning to predict pitch accents and prosodic boundaries in dutch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erwin</forename><surname>Marsi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Reynaert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Walter</forename><surname>Bosch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veronique</forename><surname>Daelemans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hoste</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">41st Annual meeting of the Association for Computational Linguistics : proceedings of the conference</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page" from="489" to="496" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Montreal Forced Aligner: Trainable text-speech alignment using kaldi</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Mcauliffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michaela</forename><surname>Socolof</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarah</forename><surname>Mihuc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Morgan</forename><surname>Sonderegger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Interspeech</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="498" to="502" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">NaÃ¯ve listeners prominence and boundary perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoonsook</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><surname>Cole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eun-Kyung</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Speech Prosody</title>
		<meeting>Speech Prosody<address><addrLine>Campinas, Brazil</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="735" to="738" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Efficient higher-order CRFs for morphological tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helmut</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>SchÃ¼tze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="322" to="332" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">To memorize or to predict: Prominence labeling in conversational speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ani</forename><surname>Nenkova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Brenier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anubha</forename><surname>Kothari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sasha</forename><surname>Calhoun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Whitton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Beaver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Human Language Technology Conference of the North American chapter of the Association for Computational Linguistics (NAACL-HLT-2007)</title>
		<meeting>the Human Language Technology Conference of the North American chapter of the Association for Computational Linguistics (NAACL-HLT-2007)</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="9" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mari</forename><surname>Ostendorf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Patti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanie</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shattuck-Hufnagel</surname></persName>
		</author>
		<title level="m">The Boston University radio news corpus. Linguistic Data Consortium</title>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="page" from="1" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">LibriSpeech: an ASR corpus based on public domain audio books</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vassil</forename><surname>Panayotov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoguo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Povey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Khudanpur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="5206" to="5210" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">GloVe: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Using continuous lexical embeddings to improve symbolic-prosody prediction in a text-to-speech front-end</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asaf</forename><surname>Rendel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raul</forename><surname>Fernandez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ron</forename><surname>Hoory</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bhuvana</forename><surname>Ramabhadran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="5655" to="5659" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Automatic detection and classification of prosodic events. Columbia University</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Rosenberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Effects of word embeddings on neural network-based pitch accent detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sabrina</forename><surname>Stehwien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ngoc</forename><forename type="middle">Thang</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antje</forename><surname>Schweitzer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">9th International Conference on Speech Prosody</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="719" to="723" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Simple semisupervised POS tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Stratos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st Workshop on Vector Space Modeling for Natural Language Processing</title>
		<meeting>the 1st Workshop on Vector Space Modeling for Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Hierarchical representation and estimation of prosody using continuous wavelet transform</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antti</forename><surname>Suni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>JurajÅ¡imko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martti</forename><surname>Aalto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vainio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Speech &amp; Language</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="123" to="136" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">The perception of prosodic prominence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacques</forename><surname>Terken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dik</forename><surname>Hermes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Prosody: Theory and experiment</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2000" />
			<biblScope unit="page" from="89" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Experimental and theoretical advances in prosody: A review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duane</forename><forename type="middle">G</forename><surname>Watson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Language and cognitive processes</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">7-9</biblScope>
			<biblScope unit="page" from="905" to="945" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">An acoustic measure for word prominence in spontaneous speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dagen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shrikanth</forename><surname>Narayanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on audio, speech, and language processing</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="690" to="701" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Unsupervised Learning for Textto-Speech Synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oliver</forename><surname>Watts</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
		<respStmt>
			<orgName>University of Edinburgh</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Intertranscriber reliability of prosodic labeling on telephone conversation using tobi</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tae-Jin</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandra</forename><surname>Chavarria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><surname>Cole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Hasegawa-Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eighth International Conference on Spoken Language Processing</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Pitch accent prediction: Effects of genre and speaker</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiahong</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><forename type="middle">M</forename><surname>Brenier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Ninth European Conference on Speech Communication and Technology</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heiga</forename><surname>Zen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Viet</forename><surname>Dang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ron</forename><forename type="middle">J</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ye</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonghui</forename><surname>Wu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.02882</idno>
		<title level="m">LibriTTS: A corpus derived from LibriSpeech for text-to-speech</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
