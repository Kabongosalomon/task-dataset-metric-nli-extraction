<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Scattering Transform Based Image Clustering using Projection onto Orthogonal Complement</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2020-11-26">November 26, 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angel</forename><surname>Villar-Corrales</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Chair of Multimedia Communications and Signal Processing</orgName>
								<orgName type="institution">University of Erlangen-Nuremberg</orgName>
								<address>
									<postCode>91058</postCode>
									<settlement>Erlangen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veniamin</forename><forename type="middle">I</forename><surname>Morgenshtern</surname></persName>
							<email>veniamin.morgenshtern@fau.de</email>
							<affiliation key="aff0">
								<orgName type="department">Chair of Multimedia Communications and Signal Processing</orgName>
								<orgName type="institution">University of Erlangen-Nuremberg</orgName>
								<address>
									<postCode>91058</postCode>
									<settlement>Erlangen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Scattering Transform Based Image Clustering using Projection onto Orthogonal Complement</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2020-11-26">November 26, 2020</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T22:01+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In the last few years, large improvements in image clustering have been driven by the recent advances in deep learning. However, due to the architectural complexity of deep neural networks, there is no mathematical theory that explains the success of deep clustering techniques. In this work we introduce Projected-Scattering Spectral Clustering (PSSC), a state-of-the-art, stable, and fast algorithm for image clustering, which is also mathematically interpretable. PSSC includes a novel method to exploit the geometric structure of the scattering transform of small images. This method is inspired by the observation that, in the scattering transform domain, the subspaces formed by the eigenvectors corresponding to the few largest eigenvalues of the data matrices of individual classes are nearly shared among different classes. Therefore, projecting out those shared subspaces reduces the intra-class variability, substantially increasing the clustering performance. We call this method 'Projection onto Orthogonal Complement' (POC). Our experiments demonstrate that PSSC obtains the best results among all shallow clustering algorithms. Moreover, it achieves comparable clustering performance to that of recent state-of-the-art clustering techniques, while reducing the execution time by more than one order of magnitude. In the spirit of reproducible research, we publish a high quality code repository along with the paper 1 .</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Image clustering is a fundamental computer vision task that aims at grouping images into clusters according to certain similarity metric, so that similar images belong to the same cluster and the images in different clusters are dissimilar. Image clustering is used in several machine learning and computer vision applications including image retrieval <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>, data mining <ref type="bibr" target="#b2">[3]</ref> and image segmentation <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5]</ref>.</p><p>Due to large variance in shape, style and appearance, clustering real images is considered a challenging task. Traditional clustering methods, such as k-means <ref type="bibr" target="#b5">[6]</ref>, mean-shift <ref type="bibr" target="#b6">[7]</ref>, DBSCAN <ref type="bibr" target="#b7">[8]</ref>, hierarchical clustering <ref type="bibr" target="#b8">[9]</ref> or Gaussian mixture-models <ref type="bibr" target="#b9">[10]</ref>, rely on computing the distance between handcrafted features extracted from the dataset samples. These techniques fail at clustering complex high-dimensional images, since engineered features often cannot capture the complexity of real data.</p><p>Spectral clustering <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12]</ref> generalizes ideas from spectral graph theory to cluster samples using the eigenvectors of matrices derived from data. Despite often outperforming the aforementioned algorithms, <ref type="figure">Figure 1</ref>: PSSC framework. Clustering is performed by cascading three well understood mathematical operators. First, the scattering transform of the images is computed. Second, intra-class variabilities are reduced using POC projection step. Third, the final cluster assignments are obtained by applying spectral clustering to the processed scattering representations. spectral clustering also relies on engineered features and suffers from the same drawbacks as the traditional approaches. Traditional and spectral clustering methods are often denoted as shallow clustering algorithms.</p><p>The recent advances in deep neural networks (DNNs) <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b15">16]</ref> have significantly improved the state-of-the-art for image clustering, giving birth to a new family of clustering algorithms commonly known as deep clustering. These methods perform (separately or jointly) two different processes: image features are learned from data using DNNs, and then these are used to group the images into clusters. By minimizing a clustering loss function (e.g., k-means loss <ref type="bibr" target="#b16">[17]</ref> or cluster hardening loss <ref type="bibr" target="#b17">[18]</ref>), the model is able to learn feature representations optimized for clustering.</p><p>Several architectures have been employed for deep clustering, including CNNs <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b19">20]</ref>, autoencoders <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b16">17]</ref> or GANs <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b24">25]</ref>. Despite their impressive performance for image clustering, the architecture complexity of DNNs, a deep cascade of learned modules and nonlinear operators <ref type="bibr" target="#b12">[13]</ref>, makes them hard to analyze mathematically <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b27">28]</ref>. Furthermore, deep clustering techniques require several minutes to process mid-sized datasets, hence being highly computationally inefficient.</p><p>In this work, we propose Projected-Scattering Spectral Clustering (PSSC), an image clustering framework that obtains results comparable to those of state-of-the-art DNNs, while being efficient, robust and interpretable. Our clustering framework (depicted in <ref type="figure">Figure 1</ref>) is composed of three steps. First, we process the images using a scattering network (ScatNet) <ref type="bibr" target="#b28">[29]</ref>. This step generates image features that are invariant to small translations and linearizes intra-class variabilities. Second, we introduce a new processing technique, denoted Projection onto Orthogonal Complement (POC), motivated by the geometrical structure of scattering features. This method is inspired by the observation that, in the scattering transform domain, the subspaces formed by the eigenvectors corresponding to the few largest eigenvalues of the data matrices of individual classes are nearly shared among different classes. Therefore, projecting out those shared subspaces reduces the intra-class variability, substantially increasing the clustering performance. Finally, we cluster the processed feature vectors using an efficient and scalable spectral clustering algorithm inspired by <ref type="bibr" target="#b29">[30]</ref>.</p><p>In summary, the contributions of our work are as follows:</p><p>• We introduce PSSC, a three-step framework to efficiently compute image clusters from an unlabeled image dataset. Unlike deep clustering techniques, our proposed pipeline is provably stable and mathematically tractable.</p><p>• We propose POC, a simple, but effective, geometrically motivated algorithm for processing scattering representations. We empirically demonstrate that the POC step simplifies deformations and structural variabilities, hence improving the clustering performance.</p><p>• Our experimental results show that the proposed framework outperforms all shallow clustering algorithms and obtains results comparable to those of state-of-the-art deep clustering models for four different benchmark datasets, while reducing execution runtime by more than one order of magnitude.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Scattering Transform</head><p>ScatNet <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b28">29]</ref> is a multi-layer hierarchical network in which the convolutional kernels correspond to wavelet filters. Scattering transform is an invariant, stable, and informative signal representation obtained by cascading wavelet modulus decompositions followed by a lowpass filter. Below we review the basics of the scattering transform and we refer to <ref type="bibr" target="#b28">[29]</ref> for further details.</p><p>Similarly to the wavelet transform, the scattering transform starts with a mother wavelet ψ(u). In the case of images, the wavelet basis is obtained by scaling ψ(u) and rotating it using a rotation group G of R 2 . Therefore, for a certain scale j ∈ Z and rotation r ∈ G, the wavelet function is defined as:</p><formula xml:id="formula_0">ψ 2 j r (u) = 2 2j ψ(2 j r −1 u).</formula><p>(1)</p><p>To simplify notation, we define γ = 2 j r, with |γ| = 2 j . Each rotated and dilated wavelet extracts the energy of a signal located at a scale and orientation given by γ.</p><p>Translation invariance of a representation is a desirable property for computer vision tasks. However, due to the convolution operator, the wavelet transform is inherently translation covariant. A translation invariant representation can be built by applying a non-linear operator that computes an informative average value of the wavelet coefficients. Namely, scattering transform creates a locally translation invariant representation by computing the complex modulus non-linearity and averaging the results using a low-pass filter φ.</p><p>Given an image X(u), where u ∈ R 2 indexes pixel coordinates, the zero-order scattering coefficients S[0] are obtained by averaging the signal energy using the low-pass filter:</p><formula xml:id="formula_1">S[0]X(u) = (X φ)(u) = X(v) · φ(u − v)dv.<label>(2)</label></formula><p>Higher-order translation invariant scattering coefficients can be computed by cascading wavelet transforms with modulus operators. Let p = (γ 1 , γ 2 , ..., γ m ) denote an ordered sequence of wavelets, also referred as path. Then, the scattering coefficients for a path p are computed as follows:</p><formula xml:id="formula_2">S[p]X(u) = |||X ψ γ 1 | ψ γ 2 |...| ψ γm | φ(u).<label>(3)</label></formula><p>Since the architecture of the scattering transform is structured as the cascade of convolution and nonlinear operators, it shares many similarities with the architecture of a CNN. The difference is that the convolutional kernels are given by wavelets, which do not need to be learned.</p><p>Scattering features are locally translation invariant and stable to deformations <ref type="bibr" target="#b31">[32]</ref>, hence they are useful unsupervised features for several signal processing and machine learning tasks.</p><p>In their seminal work, Bruna and Mallat <ref type="bibr" target="#b28">[29]</ref> used scattering representations as input features for support vector machines and PCA-based classifiers to obtain state-of-the-art results for classification of handwritten digits and textures in a supervised learning setting.</p><p>In <ref type="bibr" target="#b32">[33]</ref>, Oyallon et al. showed how hybrid architectures, obtained by combining the scattering transform with CNNs, outperform end-to-end classifiers for datasets composed of small images such as CIFAR-10 or STL-10.</p><p>More recently, Zarka et al. <ref type="bibr" target="#b33">[34]</ref> introduced a classification pipeline constructed by cascading well understood mathematical operators. Namely, the pipeline is composed of a ScatNet followed by dimensionality reduction, dictionary learning and a multi-layer perceptron (MLP) classifier. Using only predefined scattering representations, the authors reached higher accuracy than AlexNet <ref type="bibr" target="#b13">[14]</ref> on the ImageNet image classification challenge.</p><p>Loosely inspired by the previous work, our method also profits from the reduced variability and invariances provided by the scattering transform. However, in contrast to those methods, we use the scattering representations to address an unsupervised learning problem and we apply a novel processing step to make the feature representation more suitable for the task of clustering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Spectral Clustering</head><p>Spectral clustering <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b35">36]</ref> refers to a family of clustering algorithms that use the top eigenvectors of a matrix computed from pairwise distances between samples. These algorithms have been widely used in practice due to their ability to deal with non-linearly separable datasets. For more details about the spectral clustering algorithms, we refer to <ref type="bibr" target="#b11">[12]</ref>.</p><p>Despite its desirable clustering properties, spectral clustering algorithms do not gently scale to large datasets due to a computational complexity of O(N 3 ), where N is the number of samples in the dataset. This complexity makes it unfeasible to apply spectral clustering to datasets containing over a few thousand samples. To address this issue, novel approximate clustering algorithms <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b37">38]</ref> have been developed in order to reduce the computational complexity of spectral clustering so as to scale to arbitrarily large datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Projected-Scattering Spectral Clustering</head><p>This section presents a novel clustering framework: PSSC. Let X = {X i } N i=1 denote a dataset with N images. PSSC aims at grouping these images into C disjoint clusters based on an intermediate image representation obtained through the scattering transform and a geometrically motivated projection step denoted POC. The resulting clustering pipeline is illustrated in <ref type="figure">Figure 1</ref>.</p><p>Section 3 is organized as follows. In Section 3.1, we investigate the spectral distribution of the scattering transform of small images, with special focus on correlation between features and eigenvalue distribution. In Section 3.2, we introduce the POC algorithm, which exploits the geometrical structure of scattering representations to reduce intra-class variability. Finally, in Section 3.3, we introduce the clustering algorithm, inspired by <ref type="bibr" target="#b29">[30]</ref>, which we use to compute the cluster assignments. and scattering domain (right). Eigenvalues have been normalized with respect to 1 norm. In the scattering transform domain, the four largest eigenvalues explain over 50% of the data variance, whereas close to 50 eigenvalues are needed in the image domain to obtain the same percentage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Geometry of Scattering Transforms</head><p>The scattering transform is the first step of our clustering framework, as depicted in <ref type="figure">Figure 1</ref>. This step aims at transforming the input images into a more suitable representation for the task of clustering: X → S J X .</p><p>Invariance to small translations and rotations, as well as robustness to deformations, provided by the scattering transform representation, are desirable properties for pattern recognition tasks. Nevertheless, methods that rely on engineered input features are often outperformed by learned representations such as those obtained using DNNs.</p><p>In order to further improve the data representation provided by the scattering transform for our particular task of image clustering, we exploit the geometrical structure of the transformed data. In particular, we aim at minimizing the high correlations between scattering transform coefficients.</p><p>As found out by Bruna and Mallat in <ref type="bibr" target="#b28">[29]</ref>, natural images have scattering coefficients that are strongly correlated across paths. <ref type="figure" target="#fig_0">Figure 2</ref> displays the eigenvalue distribution of the covariance matrix of the MNIST <ref type="bibr" target="#b38">[39]</ref> test-set in the image domain on the left and in the scattering domain on the right. The eigenvalues have been normalized with respect to the 1 norm, so that they sum up to one. In the scattering domain, the four largest eigenvalues explain more that 50% of the total variance. In fact, more that 95% of the eigenvalues have an almost-zero magnitude.</p><p>This quick variance decay in the scattering domain indicates a strong correlation and redundancy between features.</p><p>A more detailed analysis of these correlations can be obtained by computing the affinity between the subspaces spanned by each class of the MNIST dataset. For successful clustering, it is desired that different classes belong to dissimilar subspaces. The affinity between two D-dimensional subspaces can be measured by computing the principal angles</p><formula xml:id="formula_3">θ = [θ 1 , θ 2 , ..., θ D ] T ; θ i ∈ [0, π/2] for i ∈ {1, 2, .</formula><p>.., D}, which correspond to the minimized angles between two subspaces <ref type="bibr" target="#b39">[40]</ref>. Angles close to 0 imply that vectors defining Algorithm 1 Principal angles between two subspaces procedure PRINCIPAL ANGLES ALGORITHM Inputs:</p><formula xml:id="formula_4">U = [u 1 , ..., u N ] ← vectors forming subspace 1 V = [v 1 , ..., v N ]</formula><p>← vectors forming subspace 2 D ← number of principal angles to compute Returns:</p><p>θ ← principal angles between subspaces U and V Algorithm: he subspaces are nearly colinear, whereas values close to π/2 correspond to almost orthogonal basis and lead to smaller classification and clustering errors <ref type="bibr" target="#b40">[41]</ref>. Algorithm 1 illustrates the greedy iterative method used to compute the principal angles between two subspaces. To measure the correlations between scattering coefficients, we compute the principal angles between the eigenbasis of two MNIST classes. For illustrative purposes, we select the classes containing digits 0 and 2 respectively. Top five principal angles between those two classes are listed in <ref type="table" target="#tab_0">Table 1</ref>. Whereas in the image domain all angles have magnitudes larger that 60°, three principal angles have much smaller magnitude in the scattering domain, indicating a high correlation between the eigenbasis of two different classes. The highly correlated eigenvectors are precisely the ones corresponding to the largest eigenvalues.</p><formula xml:id="formula_5">U ⊥ ← [ ] V ⊥ ← [ ] for i in range [1, D] do θ i = min u∈U,v∈V arccos u, v ||u|| 2 ||v|| 2 s.t. u T u ⊥ = 0 for all u ⊥ ∈ U ⊥ v T v ⊥ = 0 for all v ⊥ ∈ V ⊥ U ⊥ ← [U ⊥ , u] V ⊥ ← [V ⊥ , v] return θ</formula><p>High correlations and small principal angles between different classes are undesirable properties for the task of clustering in particular, and for pattern recognition tasks in general <ref type="bibr" target="#b40">[41]</ref>. The correlations might mislead the clustering algorithm resulting in errors. In the following section, we introduce a simple, but effective, algorithm to remove the correlations introduced by the scattering transform.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Projection onto Orthogonal Complement</head><p>Motivated by the strong correlations between the subspaces corresponding to different image classes in the scattering domain, we propose the POC algorithm to improve the scattering representation for the task of clustering.</p><p>The POC algorithm applies a linear operator that removes the high correlations between the subspaces corresponding to different classes, while preserving the specificity of the scattering features. This is achieved through an orthogonal projection that removes the principal scattering directions of variance.</p><p>For our image clustering pipeline, the POC algorithm receives as input the scattering transform of an image dataset in matrix form S J X ∈ R D×N . Each column of this matrix corresponds to the D-dimensional scattering transform of one image from the dataset.</p><p>First, we compute the Karhunen-Loeve transform of the scattering matrix, thus yielding the eigenvalues</p><formula xml:id="formula_6">λ = [λ 1 , λ 2 , . . . , λ D ] and eigenvectors W = [w 1 , w 2 , . . . , w D ] ∈ R D×D .</formula><p>Second, we define an orthogonal projection matrix W = [w n+1 , w n+2 , . . . , w D ] ∈ R D×(D−n) by removing the eigenvectors corresponding to the n largest eigenvalues. As explained in Section 3.1, these eigenvectors are highly-correlated between different classes.</p><p>Finally, we use W to perform an orthogonal projection of the scattering matrix into a lower-dimensional space where scattering features with largest intra-class variations have been removed</p><formula xml:id="formula_7">P (S J X ) = (W ) T S J X .<label>(4)</label></formula><p>To simplify the notation, we refer to P (S J X ) as S. <ref type="figure" target="#fig_1">Figure 3</ref> illustrates the effect of the POC algorithm for the task of clustering. For illustrative purposes, we use a toy dataset composed of two elongated clusters, displayed on the left-hand side. The shape of the clusters imitates the geometric structure of the scattering transform of small images, in which few directions span most of the data variance. The figure in the center displays the cluster predictions obtained using k-means. Large intra-class variability leads the clustering algorithm to assign several samples to the wrong cluster.</p><p>The figure on the right hand side displays the projected samples and cluster assignments obtained applying POC followed by k-means. The POC projection step removes the direction that spans the largest variance, which is shared among the two classes and leads to errors when directly applying the clustering algorithm. The correct cluster assignments are obtained applying k-means to the projected data, once the intra-class variabilities are reduced.</p><p>Despite the simplicity of this method, applying POC substantially increases the image clustering performance of PSSC framework.</p><p>The POC algorithm shares similarities with the PCA dimensionality reduction algorithm. However, instead of dropping the eigenvectors corresponding to the smallest eigenvalues, the geometry of the scattering transform and the high correlations between scattering coefficients motivate us to remove the eigenvectors corresponding to the largest eigenvalues.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Clustering Approach</head><p>The final step in our image clustering pipeline, as depicted in <ref type="figure">Figure 1</ref>, is a spectral clustering algorithm, which groups the N processed feature vectors into C disjoint clusters. In particular, we use a modified version of ultra-scalable spectral clustering (U-SPEC) <ref type="bibr" target="#b29">[30]</ref>. This method allows to deal with non-linearly separable clusters, while scaling efficiently to large datasets.</p><p>U-SPEC scales gently with the size of the dataset through the use of two relaxations: a hybrid sampling approach to select a robust subset of p representative samples from the dataset, and an efficient approximate k-NN search to construct a sparse affinity sub-matrix between the N samples from the dataset and the selected p representatives.</p><p>First, instead of computing an affinity matrix using all samples from the dataset, a robust subset of p examples is sampled using a hybrid approach. Closely following <ref type="bibr" target="#b29">[30]</ref>, a set of p (p &lt; p N ) candidate data points is randomly sampled from the dataset. Then, we perform the k-means algorithm on the p candidates to obtain p clusters, and use the p cluster centers as the set of representatives.</p><p>Second, we compute a sparse affinity sub-matrix between the N samples from the dataset and the selected p representatives using an approximate k-nearest neighbor (k-ANN) algorithm. This affinity submatrix A ∈ R N ×p encodes pairwise relationships between the representatives P = [p 1 , p 2 , ..., p p ] and the samples from the dataset S = [s 1 , s 2 , ..., s N ]. More precisely, each row i = 1, ..., N will contain k non-zero entries corresponding to the k-NN of s i :</p><formula xml:id="formula_8">A i,j = exp − ||s i −p j || 2 2 2σ 2 , p j in k-neighborhood of s i 0, otherwise.<label>(5)</label></formula><p>The affinity sub-matrix entries contain only k · N non-zero entries out of the total p · N (k p), hence making it a memory-efficient representation.</p><p>Differently from <ref type="bibr" target="#b29">[30]</ref>, we use Hierarchical Navigable Small World (HNSW) graphs <ref type="bibr" target="#b41">[42]</ref> to perform an efficient and robust k-ANN search for the construction of the affinity sub-matrix. This method exploits hierarchical directed graphs to find approximate nearest neighbors. We follow this approach to compute the affinities since, to the best of our knowledge, it outperforms all other k-ANN methods for high dimensional datasets, such as the scattering transform of small images.</p><p>Finally, U-SPEC aims at obtaining cluster assignments by treating the Laplacian of the sparse affinity sub-matrix A as a graph and solving an eigenproblem <ref type="bibr" target="#b11">[12]</ref>. However, directly solving the eigenproblem is a computationally expensive step that takes O(N 3 ).</p><p>Li et al. <ref type="bibr" target="#b42">[43]</ref> show how this step can be solved more efficiently by exploiting the bipartite structure of A. Applying transfer cut <ref type="bibr" target="#b42">[43]</ref>, the clustering is reduced to solving the generalized eigenproblem (8) using the Laplacian L of a much smaller graphĀ, with a much lower complexity of O(p 3 ) (p N ):</p><formula xml:id="formula_9">A = A T D −1 X A (6) L = D −1/2 YĀ D −1/2 Y (7) Lw = λD Y w.<label>(8)</label></formula><p>Above, D X and D Y are the degree matrices of A. These are diagonal matrices in which each element (i, i) from the diagonal is equal to the sum of A's i th row or column respectively.</p><p>After having solved the eigenproblem (8), the eigenvectors associated to the C largest eigenvalues are stacked into a matrix C = [w 1 , ..., w C ] ∈ R N ×C .</p><p>Finally, the cluster assignments are obtained by treating each row of C as a feature vector and clustering them using k-means. An original sample s i will be assigned to cluster c if and only if the i th row of C was assigned to cluster c.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Setup</head><p>In this section, we describe the image datasets used for testing, implementation details, the different evaluation metrics for the task of image clustering and the baseline methods used for comparison.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets</head><p>We evaluate our image clustering pipeline and compare it with other popular clustering methods on four different benchmark datasets. The MNIST <ref type="bibr" target="#b38">[39]</ref> database consists of 70000 images of size 28 × 28 pixels each of handwritten digits from ten different categories (digits 0-9). Furthermore, we also consider the MNIST-test set, which contains a subset of 10000 images from MNIST. The USPS dataset <ref type="bibr" target="#b43">[44]</ref> consists of 9298 handwritten digit images of size 16 × 16 each. Fashion-MNIST <ref type="bibr" target="#b44">[45]</ref> consists of 70000 images of size 28 × 28 pixels each of fashion products divided into 10 categories. This dataset poses a significantly more challenging alternative to the MNIST dataset due to large variability of the images in each category. <ref type="table" target="#tab_1">Table 2</ref> displays an overview of the datasets used for evaluation of our image clustering pipeline. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Evaluation Metrics</head><p>To evaluate the performance of the image clustering methods, we use two metrics widely used in the unsupervised learning literature. Both metrics are in the range [0,1], with higher values indicating a better clustering performance. Let N denote the total number of samples, y denote to the ground truth labels and y denote the predicted cluster assignments.</p><p>• Clustering Accuracy (ACC) is the best match between predicted clustering assignments and ground truth:</p><formula xml:id="formula_10">ACC = max c N i=1 1(y i =ŷ c i ) N<label>(9)</label></formula><p>whereŷ c is the cth permutation ofŷ.</p><p>• Normalized Mutual Information <ref type="bibr" target="#b45">[46]</ref> (NMI) is a metric inspired by information theory, which corresponds to a normalization of the mutual information between the predicted cluster assignments and the ground truth labels. This metric is symmetric and invariant to label permutations. NMI is defined as:</p><formula xml:id="formula_11">N M I = 2 · I(y,ŷ) H(y) + H(ŷ)<label>(10)</label></formula><p>where I(·, ·) is the mutual information and H(·) the binary entropy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Implementation Details</head><p>Our methods are implemented using the Python programming language, using the packages Numpy <ref type="bibr" target="#b48">[49]</ref> and Scikit-Learn <ref type="bibr" target="#b49">[50]</ref>. The scattering transforms are computed using the Kymatio software package <ref type="bibr" target="#b50">[51]</ref>. The scattering transforms are computed on a MSI Nvidia GeForce GTX 1080 Ti GPU and all other computations are performed on an Intel ® Xeon ® Silver 4114 CPU.</p><p>For the scattering transform, we use complex Morlet filters as convolutional kernels. We set the spatial support of the wavelets to 2 J = 8 pixels and the number of angles to L = 8. We consider the ScatNets of two levels of depth as recommended in <ref type="bibr" target="#b28">[29]</ref>.</p><p>Input images are zero-padded to a 32 × 32 resolution (1024-dimensional representation). Applying the scattering transform with the aforementioned settings to these images yields D = 3472 scattering coefficients, roughly resulting in a 3.4 times dimensionality increase.</p><p>Prior to applying the POC algorithm, we apply PCA to reduce the dimensionality of the scattering feature vectors to D = 1000. As shown in <ref type="figure" target="#fig_0">Figure 2</ref>, a large number of eigenvalues explain close to zero variance. Therefore, removing the dimensions associated to these eigenvalues significantly reduces computations while having negligible effect on the clustering results. The number of directions removed by the POC algorithm is the same for all four evaluated datasets. Namely, the orthogonal projection matrix W = [w n+1 , ..., w D ] is constructed by removing the top two eigenvectors (n=2).</p><p>Regarding the hyper-parameters for the U-SPEC algorithm, we select the number of candidates and representatives as p = 9000 and p = 1000, respectively. We compute the affinity sub-matrix by retrieving the five-nearest neighbors (k = 5) and finally assign the samples into C groups, where C is the ground-truth number of clusters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Baseline Methods</head><p>We compare our proposed PSSC pipeline with several popular image clustering baselines, belonging to different algorithmic classes. From the shallow clustering methods, we select k-means <ref type="bibr" target="#b5">[6]</ref>, spectral clustering (SC) <ref type="bibr" target="#b10">[11]</ref> and DBSCAN <ref type="bibr" target="#b7">[8]</ref>. From the deep clustering methods, we compare against DEC <ref type="bibr" target="#b17">[18]</ref>, IDEC <ref type="bibr" target="#b46">[47]</ref>, JULE <ref type="bibr" target="#b19">[20]</ref>, DEPICT <ref type="bibr" target="#b47">[48]</ref>, DCN <ref type="bibr" target="#b16">[17]</ref>, DDC <ref type="bibr" target="#b22">[23]</ref>, ADEC <ref type="bibr" target="#b24">[25]</ref> and N2D <ref type="bibr" target="#b20">[21]</ref> The evaluation results reported in the following section were extracted from the literature, or are the average results of five independent trials using the released code repository.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Clustering Results</head><p>We evaluate our proposed method (PSSC) and compare it to the baseline methods introduced in Section 4.4. <ref type="table" target="#tab_2">Table 3</ref> reports the image clustering results measured by clustering accuracy (ACC) and normalized mutual information (NMI). Methods above the double-line correspond to shallow clustering algorithms that do not rely on deep learning for feature extraction, whereas the ones below the double-line correspond to deep clustering algorithms. For each column, the best method from each algorithmic category is highlighted in bold. From <ref type="table" target="#tab_2">Table 3</ref> we can extract the following observations. First, deep clustering methods outperform by a large margin all algorithms not based on deep learning, with the exception of PSSC. This is due to the fact that the embedding representations learned by the CNNs are able to capture more semantically meaningful features, which then allow to perform clustering successfully.</p><p>Second, our PSSC pipeline performs better than all shallow clustering methods on all datasets by a large margin. In fact, our proposed method performs comparably to state-of-the-art deep clustering methods, achieving top-3 performance for at least one evaluation metric in three out of four evaluated datasets (all except USPS). This fact shows that the post-processed scattering features obtained by PSSC are equivalent to those learned by CNNs for the task of clustering. The advantage of our method is that it does not need to undergo a learning procedure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Timing Results</head><p>In <ref type="table" target="#tab_3">Table 4</ref> we show the amount of time required to cluster the entire MNIST dataset using different clustering algorithms. Except for PSSC, we exclude all other shallow clustering algorithms from the comparison since they do not yield competitive results. From the results listed in <ref type="table" target="#tab_3">Table 4</ref>, we clearly see how PSSC is more efficient than all baseline methods. Whereas deep clustering algorithms need to undergo a training procedure to learn appropriate weights, all parameters from the PSSC pipeline are fixed, making it an efficient clustering method. Precisely, compared to clustering algorithms that achieve the same performance for the MNIST dataset as PSSC (e.g, JULE or DEPICT), our method reduces the execution time by more than one order of magnitude.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Ablation Study</head><p>Our PSSC clustering framework is composed of three well differentiated building blocks: ScatNet, POC and spectral clustering. In this section, we perform an ablation study to investigate the contribution of each of the aforementioned building blocks to the clustering accuracy. In particular, we evaluate different versions of our original PSSC pipeline on the MNIST dataset. These versions are constructed by either removing some of the original building blocks (i.e., ScatNet or POC processing) or by replacing the U-SPEC clustering algorithm by a simpler method: k-means. <ref type="table" target="#tab_4">Table 5</ref> displays the results of the ablation study from which we extract the following observations. First, clustering using scattering representations instead of images yields a large performance boost, improving the clustering accuracy from 75% (2) and (4) to 96.5% <ref type="bibr" target="#b0">(1)</ref>.</p><p>Second, experiments using our POC algorithm along with the scattering transform demonstrate a superior clustering performance. When removing the POC processing step from our original pipeline, the clustering accuracy drops from 96.5% (1) to 94.2% <ref type="bibr" target="#b2">(3)</ref>.</p><p>The effect of POC is more significant when we replace the U-SPEC clustering algorithm by k-means. The latter computes the cluster assignments based on the distance between the cluster center and the samples. Therefore, it is beneficial to have the samples closely scattered around the cluster center. As explained in Section 3.2, the POC algorithm removes the directions of largest variance of the scattering transform. This processing step significantly reduces redundant intra-class variabilities, thus bringing samples much closer to the cluster center, as shown in <ref type="figure" target="#fig_1">Figure 3</ref>. From <ref type="table" target="#tab_4">Table 5</ref>, we see that POC processing improves the accuracy when using k-means from 60.1% (6) to 83.8% <ref type="bibr" target="#b4">(5)</ref>. Finally, we see how using U-SPEC for the clustering step clearly outperforms k-means. This is an expected results since k-means is not able to deal with non-linearly separable clusters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper we propose a novel image clustering framework, PSSC, based on post-processed scattering features extracted from the input images. Our method achieves comparable results to those of state-of-theart deep learning-based methods, while being robust, mathematically interpretable and efficient.</p><p>Our PSSC framework obtains the cluster assignments cascading three steps. First, we process the images using a ScatNet, thus generating image features that are invariant to small translations and with linearized intra-class variabilities. Second, scattering features are processed by the POC algorithm, which exploits the distribution of scattering features to project the samples into a lower-dimensional manifold more suitable for clustering. Finally, the projected features are clustered using an efficient and scalable spectral clustering algorithm.</p><p>We compare PSSC with both traditional algorithms and deep clustering methods. Our experiments demonstrate that PSSC obtains the best performance among all shallow clustering algorithms for all evaluated benchmark datasets. Furthermore, we achieve comparable results to those of the latest deep clustering techniques, reaching top-3 performance in three out of four evaluated datasets while reducing the execution time by more than one order of magnitude.</p><p>A natural next step is to address the image clustering problem for more complex datasets, such as Imagenet. We think that the method developed in this paper may be used as a building block towards solving this challenging problem. Since Imagenet is very large and contains a lot of small image patches, it is critical to have fast and robust clustering algorithm. In this sense, the order of magnitude speedup, with only a modest performance loss, of our method compared to deep clustering algorithms is very significant.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Eigenvalue distribution of the covariance matrix of the MNIST test set in the image domain (left)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Illustration of the POC step for clustering. Left-hand side figure displays a toy dataset composed of two elongated clusters. The figure in the center displays the predictions obtained using k-means. Righthand side figure displays the projected samples and cluster assignments obtained applying POC followed by k-means. It is shown how the POC step reduces intra-class variabilities, simplifying the task of clustering.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Principal angles between subspaces spanned by MNIST classes containing digits 0 and 2 in the image and scattering domains. Subspaces in the scattering domain are much more similar.</figDesc><table><row><cell></cell><cell></cell><cell cols="3">Principal Angles (degrees)</cell><cell></cell></row><row><cell>Domain</cell><cell>θ 1</cell><cell>θ 2</cell><cell>θ 3</cell><cell>θ 4</cell><cell>θ 5</cell></row><row><cell>Image</cell><cell cols="2">63.0°63.8°65.5°68.7°69.5°S</cell><cell></cell><cell></cell><cell></cell></row><row><cell>cattering</cell><cell cols="5">36.2°36.9°44.2°60.9°66.5°t</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Image datasets used for evaluting the image clustering pipeline.</figDesc><table><row><cell>Dataset</cell><cell cols="3">Images Classes Image Size</cell></row><row><cell>MNIST [39]</cell><cell cols="2">70000 10</cell><cell>28 × 28</cell></row><row><cell>MNIST-test [39]</cell><cell cols="2">10000 10</cell><cell>28 × 28</cell></row><row><cell>USPS [44]</cell><cell>9298</cell><cell>10</cell><cell>16 × 16</cell></row><row><cell cols="3">Fashion-MNIST [45] 70000 10</cell><cell>28 × 28</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Results of the compared methods for the benchmark datasets. Methods above the double-line are shallow clustering methods, whereas the ones below are deep clustering methods. Best results from each category are highlighted in bold. Exact results were taken from the literature or computed by us. Results marked with '-' indicate out of memory error.</figDesc><table><row><cell></cell><cell cols="2">MNIST</cell><cell cols="2">MNIST-test</cell><cell cols="2">USPS</cell><cell cols="2">Fashion-MNIST</cell></row><row><cell>Method</cell><cell>ACC</cell><cell>NMI</cell><cell>ACC</cell><cell>NMI</cell><cell>ACC</cell><cell>NMI</cell><cell>ACC</cell><cell>NMI</cell></row><row><cell>k-means [6]</cell><cell>0.584</cell><cell>0.497</cell><cell>0.596</cell><cell>0.505</cell><cell>0.735</cell><cell>0.613</cell><cell>0.474</cell><cell>0.512</cell></row><row><cell>SC [11]</cell><cell>-</cell><cell>-</cell><cell>0.705</cell><cell>0.715</cell><cell>0.818</cell><cell>0.819</cell><cell>-</cell><cell>-</cell></row><row><cell>DBSCAN [8]</cell><cell>-</cell><cell>-</cell><cell>0.114</cell><cell>0.167</cell><cell>0.000</cell><cell>0.000</cell><cell>-</cell><cell>-</cell></row><row><cell>PSSC (ours)</cell><cell cols="2">0.965 0.913</cell><cell cols="2">0.967 0.919</cell><cell cols="2">0.957 0.898</cell><cell cols="2">0.628 0.644</cell></row><row><cell>DEC [18]</cell><cell>0.863</cell><cell>0.834</cell><cell>0.856</cell><cell>0.830</cell><cell>0.762</cell><cell>0.767</cell><cell>0.518</cell><cell>0.546</cell></row><row><cell>IDEC [47]</cell><cell>0.881</cell><cell>0.867</cell><cell>0.846</cell><cell>0.802</cell><cell>0.761</cell><cell>0.758</cell><cell>0.529</cell><cell>0.557</cell></row><row><cell>JULE [20]</cell><cell>0.964</cell><cell>0.913</cell><cell>0.961</cell><cell>0.915</cell><cell>0.950</cell><cell>0.913</cell><cell>0.563</cell><cell>0.608</cell></row><row><cell>DCN [17]</cell><cell>0.830</cell><cell>0.810</cell><cell>0.802</cell><cell>0.786</cell><cell>0.688</cell><cell>0.683</cell><cell>0.501</cell><cell>0.558</cell></row><row><cell>DEPICT [48]</cell><cell>0.965</cell><cell>0.917</cell><cell>0.963</cell><cell>0.915</cell><cell>0.964</cell><cell>0.927</cell><cell>0.392</cell><cell>0.392</cell></row><row><cell>DDC [23]</cell><cell>0.965</cell><cell>0.932</cell><cell>0.965</cell><cell>0.916</cell><cell>0.967</cell><cell>0.918</cell><cell>0.619</cell><cell>0.682</cell></row><row><cell>N2D [21]</cell><cell>0.979</cell><cell>0.942</cell><cell>0.948</cell><cell>0.882</cell><cell>0.958</cell><cell>0.901</cell><cell cols="2">0.672 0.684</cell></row><row><cell>ADEC [25]</cell><cell cols="2">0.986 0.961</cell><cell cols="2">0.985 0.957</cell><cell cols="2">0.981 0.948</cell><cell>0.586</cell><cell>0.662</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Time required to cluster the MNIST dataset for different clustering algorithms. Out method presents a much better running time than the competing algorithms.</figDesc><table><row><cell></cell><cell cols="4">PSSC DEC JULE DEPICT N2D</cell></row><row><cell>Time (s)</cell><cell>182</cell><cell>613 12500</cell><cell>9561</cell><cell>1080</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>Results of the ablation study on the PSSC clustering pipeline. We compare the original PSSC pipeline (1) with different simplified versions.</figDesc><table><row><cell>Results</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Content-based image retrieval by clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Krovetz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th ACM SIGMM international workshop on Multimedia information retrieval</title>
		<meeting>the 5th ACM SIGMM international workshop on Multimedia information retrieval</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="193" to="200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Content based image retrieval using hierarchical and k-means clustering techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Murthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Vamsidhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">S</forename><surname>Rao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Engineering Science and Technology</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="209" to="212" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A comparative study of various clustering algorithms in data mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Chack</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Diswar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Engineering Research and Applications (IJERA)</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1379" to="1384" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Fuzzy c-means clustering with spatial information for image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-S</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-L</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-J</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">computerized medical imaging and graphics</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="9" to="15" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Image segmentation using k-means clustering algorithm and subtractive clustering algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Dhanachandra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Manglem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">J</forename><surname>Chanu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Procedia Computer Science</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="764" to="771" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Some methods for classification and analysis of multivariate observations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Macqueen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fifth Berkeley symposium on mathematical statistics and probability</title>
		<meeting>the fifth Berkeley symposium on mathematical statistics and probability<address><addrLine>Oakland, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1967" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="281" to="297" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Mean shift: A robust approach toward feature space analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Comaniciu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Meer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="603" to="619" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A density-based algorithm for discovering clusters in large spatial databases with noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-P</forename><surname>Kriegel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Kdd</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="issue">34</biblScope>
			<biblScope unit="page" from="226" to="231" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Hierarchical clustering schemes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="241" to="254" />
			<date type="published" when="1967" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Gaussian mixture models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Reynolds</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Encyclopedia of biometrics</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">741</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">On spectral clustering: Analysis and an algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="849" to="856" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">A tutorial on spectral clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><forename type="middle">V</forename><surname>Luxburg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Convolutional networks and applications in vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Farabet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 2010 IEEE international symposium on circuits and systems</title>
		<meeting>2010 IEEE international symposium on circuits and systems</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="253" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.1556</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Towards k-means-friendly spaces: Simultaneous deep learning and clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Sidiropoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hong</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3861" to="3870" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Unsupervised deep embedding for clustering analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Farhadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="478" to="487" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Deep clustering for unsupervised learning of visual features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Douze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="132" to="149" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Joint unsupervised learning of deep representations and image clusters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Batra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="5147" to="5156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">N2d:(not too) deep clustering via clustering the local manifold of an autoencoded embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mcconville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Santos-Rodriguez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Piechocki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Craddock</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.05968</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Deep clustering with convolutional autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on neural information processing</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="373" to="382" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Deep density-based image clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page">105841</biblScope>
		</imprint>
	</monogr>
	<note>Knowledge-Based Systems</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Adversarial feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Krähenbühl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.09782</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Adversarial deep embedded clustering: on a better tradeoff between feature randomness and feature drift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Mrabah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bouguessa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ksantini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Intriguing properties of neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6199</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Understanding deep convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mallat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences</title>
		<imprint>
			<biblScope unit="volume">374</biblScope>
			<biblScope unit="page">20150203</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Understanding deep learning requires rethinking generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Recht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.03530</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Invariant scattering convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mallat</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Ultra-scalable spectral clustering and ensemble clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-H</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-K</forename><surname>Kwoh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1212" to="1226" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Group invariant scattering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mallat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications on Pure and Applied Mathematics</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1331" to="1398" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Deep scattering spectrum</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Andén</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mallat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">16</biblScope>
			<biblScope unit="page" from="4114" to="4128" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Scattering networks for hybrid representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Oyallon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zagoruyko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lacoste-Julien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Blaschko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Belilovsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="2208" to="2221" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Deep network classification by scattering and homotopy dictionary learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zarka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Thiry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Angles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mallat</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.03561</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Multiclass spectral clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><forename type="middle">Y</forename><surname>Stella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<publisher>IEEE</publisher>
			<biblScope unit="page">313</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Self-tuning spectral clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zelnik-Manor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="1601" to="1608" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Fast approximate spectral clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 15th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="907" to="916" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Fast large-scale spectral clustering via explicit feature mapping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on cybernetics</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1058" to="1071" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">The mnist database of handwritten digits</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Burges</surname></persName>
		</author>
		<ptr target="http://yann.lecun.com/exdb/mnist" />
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">34</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Numerical methods for computing angles between linear subspaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bjorck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">H</forename><surname>Golub</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematics of computation</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">123</biblScope>
			<biblScope unit="page" from="579" to="594" />
			<date type="published" when="1973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">The role of principal angles in subspace classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Calderbank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1933" to="1945" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Efficient and robust approximate nearest neighbor search using hierarchical navigable small world graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">A</forename><surname>Malkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Yashunin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Segmentation using superpixels: A bipartite graph partitioning approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X.-M</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-F</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2012 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="789" to="796" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">A database for handwritten text recognition research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Hull</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="550" to="554" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Rasul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vollgraf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.07747</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Information theoretic measures for clusterings comparison: Variants, properties, normalization and correction for chance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">X</forename><surname>Vinh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Epps</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bailey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="2837" to="2854" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Improved deep embedded clustering with local structure preservation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCAI</title>
		<imprint>
			<biblScope unit="page" from="1753" to="1759" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Deep clustering via joint convolutional autoencoder embedding and relative entropy minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Dizaji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Herandi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE inter</title>
		<meeting>the IEEE inter</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5736" to="5745" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Array programming with numpy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">J</forename><surname>Millman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Van Der Walt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gommers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Virtanen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cournapeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Wieser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">J</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">585</biblScope>
			<biblScope unit="issue">7825</biblScope>
			<biblScope unit="page" from="357" to="362" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Scikit-learn: Machine learning in python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">the Journal of machine Learning research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Kymatio: Scattering transforms in python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Andreux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Angles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Exarchakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Leonarduzzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Rochette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Thiry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zarka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mallat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Andén</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Belilovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lostanlen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Hirn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Oyallon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Eickenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<biblScope unit="volume">1812</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
