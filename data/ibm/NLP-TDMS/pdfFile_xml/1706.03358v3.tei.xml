<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Sliced Wasserstein Kernel for Persistence Diagrams</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathieu</forename><surname>Carrière</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Cuturi</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Oudot</surname></persName>
						</author>
						<title level="a" type="main">Sliced Wasserstein Kernel for Persistence Diagrams</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T22:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Persistence diagrams play a key role in topological data analysis (TDA), in which they are routinely used to describe topological properties of complicated shapes. persistence diagrams enjoy strong stability properties and have proven their utility in various learning contexts. They do not, however, live in a space naturally endowed with a Hilbert structure and are usually compared with non-Hilbertian distances, such as the bottleneck distance. To incorporate persistence diagrams in a convex learning pipeline, several kernels have been proposed with a strong emphasis on the stability of the resulting RKHS distance w.r.t. perturbations of the persistence diagrams. In this article, we use the Sliced Wasserstein approximation of the Wasserstein distance to define a new kernel for persistence diagrams, which is not only provably stable but also discriminative (with a bound depending on the number of points in the persistence diagrams) w.r.t. the first diagram distance between persistence diagrams. We also demonstrate its practicality, by developing an approximation technique to reduce kernel computation time, and show that our proposal compares favorably to existing kernels for persistence diagrams on several benchmarks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Topological Data Analysis (TDA) is an emerging trend in data science, grounded on topological methods to design descriptors for complex data-see e.g. <ref type="bibr" target="#b4">[5]</ref> for an introduction to the subject. The descriptors of TDA can be used in various contexts, in particular statistical learning and geometric inference, where they provide useful insight into the structure of data. Applications of TDA can be found in a number of scientific areas, including computer vision <ref type="bibr" target="#b25">[26]</ref>, materials science <ref type="bibr" target="#b19">[20]</ref>, and brain science <ref type="bibr" target="#b36">[37]</ref>, to name a few. The tools developed in TDA are built upon persistent homology theory <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b28">29]</ref>, and their main output is a descriptor called persistence diagram, which encodes the topology of a space at all scales in the form of a point cloud with multiplicities in the plane R 2 -see Section 2.1 for more details.</p><p>Persistence diagrams as features. The main strength of persistence diagrams is their stability with respect to perturbations of the data <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b10">11]</ref>. On the downside, their use in learning tasks is not straightforward. Indeed, a large class of learning methods, such as SVM or PCA, requires a Hilbert structure on the descriptors space, which is not the case for the space of persistence diagrams. Actually, many simple operators of R n , such as addition, average or scalar product, have no analogues in that space. Mapping persistence diagrams to vectors in R n or in some infinitedimensional Hilbert space is one possible approach to facilitate their use in discriminative settings.</p><p>Related work. A series of recent contributions have proposed kernels for persistence diagrams, falling into two classes. The first class of methods builds explicit feature maps: one can, for instance, compute and sample functions extracted from persistence diagrams <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b34">35]</ref>; sort the entries of the distance matrices of the persistence diagrams <ref type="bibr" target="#b5">[6]</ref>; treat the points of the persistence diagrams as roots of a complex polynomial, whose coefficients are concatenated <ref type="bibr" target="#b13">[14]</ref>. The second class of methods, which is more relevant to our work, defines implicitly feature maps by focusing instead on building kernels for persistence diagrams. For instance, <ref type="bibr" target="#b33">[34]</ref> use solutions of the heat differential equation in the plane and compare them with the usual L 2 (R 2 ) dot product. <ref type="bibr" target="#b22">[23]</ref> handle a persistence diagram as a discrete measure on the plane, and follow by using kernel mean embeddings with Gaussian kernels-see Section 4 for precise definitions. Both kernels are provably stable, in the sense that the metric they induce in their respective reproducing kernel Hilbert space (RKHS) is bounded above by the distance between persistence diagrams. Although these kernels are injective, there is no evidence that their induced RKHS distances are discriminative and therefore follow the geometry of the diagram distances, which are more widely accepted distances to compare persistence diagrams.</p><p>More generally, one of the reasons why the derivation of kernels for persistence diagrams is not straightforward is that the natural metrics between persistence diagrams, the diagram distances are not negative semi-definite. Indeed, these diagram distances are very similar to the Wasserstein distance <ref type="bibr">[41, §6]</ref> between probability measures, which is not negative semi-definite. However, a relaxation of this metric called the Sliced Wasserstein distance <ref type="bibr" target="#b30">[31]</ref> has recently been shown to be negative semi-definite and was used to derive kernels for probability distributions in <ref type="bibr" target="#b20">[21]</ref>.</p><p>Contributions. In this article, we use the Sliced Wasserstein distance of <ref type="bibr" target="#b30">[31]</ref> to define a new kernel for persistence diagrams, which we prove to be both stable and discriminative. Specifically, we provide distortion bounds on the Sliced Wasserstein distance that quantify its ability to mimic the diagram distances between persistence diagrams. This is in contrast to other kernels for persistence diagrams, which only focus on stability. We also propose a simple approximation algorithm to speed up the computation of that kernel, confirm experimentally its discriminative power and show that it outperforms experimentally both proposals of <ref type="bibr" target="#b22">[23]</ref> and <ref type="bibr" target="#b33">[34]</ref> in several supervised classification problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Persistent Homology</head><p>Persistent homology is a technique inherited from algebraic topology for computing stable descriptors on real-valued functions. Given f : X → R as input, persistent homology outputs a planar point set with multiplicities, called the persistence diagram of f and denoted by Dg(f ). Note that the coordinates of the points belong to the extended real line R ext = R ∪ {+∞}. See <ref type="figure" target="#fig_0">Figure 1</ref> for an example. To understand the meaning of each point in this diagram, it suffices to know that, to compute Dg(f ), persistent homology considers the family of sublevel sets of f , i.e. the sets of the form f −1 ((−∞, t]) for t ∈ R, and it records the topological events (e.g. creation or merge of a connected component, creation or filling of a loop, void, etc.) that occur in f −1 ((−∞, t]) as t ranges from −∞ to +∞. Then, each point p ∈ Dg(f ) represents the lifespan of a particular topological feature (connected component, loop, void, etc.), with its creation and destruction times as coordinates. See again <ref type="figure" target="#fig_0">Figure 1</ref> for an illustration.</p><p>For the interested reader, we point out that the mathematical tool used by persistent homology to track the topological events in the family of sublevel sets is homological algebra, which turns the parametrized family of sublevel sets into a parametrized family of vector spaces and linear maps. Computing persistent homology then boils down to computing a family of bases for the vector spaces, which are compatible with the linear maps. It will be no surprise to the reader familiar with matrix reduction techniques that the simplest way to implement the compatible basis computation is using Gaussian elimination.</p><formula xml:id="formula_0">R X p q s (a) R X p q s (b) -∞ +∞ +∞ f (p) f (s) (c)</formula><p>Distance between persistence diagrams. We now define the pth diagram distance between persistence diagrams. Let p ∈ N and Dg 1 , Dg 2 be two persistence diagrams. Let Γ : Dg 1 ⊇ A → B ⊆ Dg 2 be a partial bijection between Dg 1 and Dg 2 . Then, for any point x ∈ A, the p-cost of x is defined as c p (x) = x − Γ(x) p ∞ , and for any point y ∈ (Dg 1 Dg 2 ) \ (A B), the p-cost of y is defined as c p (y) = y −π ∆ (y) p ∞ , where π ∆ is the projection onto the diagonal ∆ = {(x, x) : x ∈ R}. The cost c p (Γ) is defined as: c p (Γ) = ( x c p (x) + y c p (y)) 1/p . We then define the pth diagram distance d p as the cost of the best partial bijection:</p><formula xml:id="formula_1">d p (Dg 1 , Dg 2 ) = inf Γ c p (Γ).</formula><p>In the particular case p = +∞, the cost of Γ is defined as c(Γ) = max{max x c 1 (x) + max y c 1 (y)}. The corresponding distance d ∞ is often called the bottleneck distance. One can show that d p → d ∞ when p → +∞. A fundamental property of persistence diagrams is their stability with respect to (small) perturbations of their originating functions. Indeed, the stability theorem <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b12">13]</ref> asserts that for any f, g : X → R, we have</p><formula xml:id="formula_2">d ∞ (Dg(f ), Dg(g)) ≤ f − g ∞ ,<label>(1)</label></formula><p>In practice, persistence diagrams can be used as descriptors for data via the choice of appropriate filtering functions f , e.g. distance to the data in the ambient space, eccentricity, curvature, etc. The main strengths of the obtained descriptors are: (a) to be provably stable as mentioned previously; (b) to be invariant under reparametrization of the data; and (c) to encode information about the topology of the data, which is complementary and of an essentially different nature compared to geometric or statistical quantities. These properties have made persistence diagrams useful in a variety of contexts, including the ones mentioned in the introduction of the paper. For further details on persistent homology and on applications of persistence diagrams, the interested reader can refer e.g. to <ref type="bibr" target="#b28">[29]</ref> and the references therein.</p><p>Notation. Let D be the space of persistence diagrams with at most countably many points, D b f be the space of finite and bounded persistence diagrams, and D b N be the space of bounded persistence diagrams with less than N points. Obviously, we have the following sequence of (strict) inclusions:</p><formula xml:id="formula_3">D b N ⊂ D b f ⊂ D.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Kernel Methods</head><p>Positive Definite Kernels. Given a set X, a function k : X × X → R is called a positive definite kernel if for all integers n, for all families x 1 , · · · , x n of points in X, the matrix [k(x i , x j )] i,j is itself positive semi-definite. For brevity we will refer to positive definite kernels as kernels in the rest of the paper. It is known that kernels generalize scalar products, in the sense that, given a kernel k, there exists a Reproducing Kernel Hilbert Space (RKHS) H k and a feature map φ :</p><formula xml:id="formula_4">X → H k such that k(x 1 , x 2 ) = φ(x 1 ), φ(x 2 ) H k .</formula><p>A kernel k also induces a distance d k on X that can be computed as the Hilbert norm of the difference between two embeddings:</p><formula xml:id="formula_5">d 2 k (x 1 , x 2 ) def. = k(x 1 , x 1 ) + k(x 2 , x 2 ) − 2 k(x 1 , x 2 ).</formula><p>We will be particularly interested in this distance, since one of the goals we will aim for will be that of designing a kernel k for persistence diagrams such that d k has low distortion with respect to the first diagram distance d 1 .</p><p>Negative Definite and RBF Kernels. A standard way to construct a kernel is to exponentiate the negative of a Euclidean distance. Indeed, the Gaussian kernel for vectors with parameter σ &gt; 0 does follow that template approach:</p><formula xml:id="formula_6">k σ (x, y) = exp − x−y 2 2σ 2</formula><p>. An important theorem of [3] (Theorem 3.2.2, p.74) states that such an approach to build kernels, namely setting</p><formula xml:id="formula_7">k σ (x, y) def. = exp − f (x, y) 2σ 2 ,</formula><p>for an arbitrary function f can only yield a valid positive definite kernel for all σ &gt; 0 if and only if f is a conditionally negative definite function, namely that, for all integers n, for all x 1 , · · · , x n ∈ X, and for all a 1 , · · · , a n ∈ R such that i a i = 0, one has i,j a i a j f (x i , x j ) ≤ 0. Unfortunately, as observed experimentally in Appendix A of <ref type="bibr" target="#b32">[33]</ref>, d 1 is not conditionally negative definite (in practice, it only suffices to sample a family of point clouds to observe experimentally that more often than not the inequality above will be violated for a particular weight vector a). Actually, as observed in <ref type="bibr" target="#b29">[30]</ref>, even the square of the diagram distances d p cannot be used to define Gaussian kernels. Indeed, it was noted in Theorem 6 of <ref type="bibr" target="#b15">[16]</ref> that, if the square of a distance d defined on a geodesic space X is conditionally negative definite, then the metric space X is flat, or CAT(0). However, since the metric space D, equipped with d p , p ∈ N ∪ {+∞}, is not CAT(k) for any k &gt; 0-which is due to the non-uniqueness of geodesics, see <ref type="bibr" target="#b39">[40]</ref>-it follows that d 2 p is not conditionally negative definite.</p><p>In this article, we use an approximation of d 1 with the Sliced Wasserstein distance, which is provably conditionally negative definite, and we use it to define a RBF kernel that can be easily tuned thanks to its bandwidth parameter σ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Wasserstein distance for unnormalized measures on R</head><p>The Wasserstein distance <ref type="bibr">[41, §6]</ref> is a distance between probability measures. For reasons that will become clear in the next section, we will focus on a variant of that distance: the 1-Wasserstein distance for nonnegative, not necessarily normalized, measures on the real line <ref type="bibr">[36, §2]</ref>. Let µ and ν be two nonnegative measures on the real line such that |µ| = µ(R) and |ν| = ν(R) are equal to the same number r. We define the three following objects:</p><formula xml:id="formula_8">W(µ, ν) = inf P ∈Π(µ,ν) R×R |x − y|P (dx, dy) (2) Q r (µ, ν) = r R |M −1 (x) − N −1 (x)|dx (3) L(µ, ν) = inf f ∈1−Lipschitz R f (x)[µ(dx) − ν(dx)]<label>(4)</label></formula><p>where Π(µ, ν) is the set of measures on R 2 with marginals µ and ν, and M −1 and N −1 the generalized quantile functions of the probability measures µ/r and ν/r respectively. Proposition 2.1. We have W = Q r = L. Additionally (i) Q r is conditionally negative definite on the space of measures of mass r; (ii) for any three positive measures µ, ν, γ such that |µ| = |ν|, we have L(µ + γ, ν + γ) = L(µ, ν).</p><p>Proof. The equality between <ref type="formula">(2)</ref> and <ref type="formula">(3)</ref> is known for probability measures on the real line-see Proposition 2.17 in <ref type="bibr" target="#b35">[36]</ref> for instance, and can be trivially generalized to unnormalized measures. The equality between <ref type="formula">(2)</ref> and <ref type="formula" target="#formula_8">(4)</ref> is due to the well known Kantorovich duality for a distance cost [41, Particular case 5.4] which can also be trivially generalized to unnormalized measures, which proves the main statement of the proposition.</p><p>The definition of Q r shows that the Wasserstein distance is the l 1 norm of rM −1 − rN −1 , and is therefore conditionally negative definite (as the l 1 distance between two direct representations of µ and ν as functions rM −1 and rN −1 ), proving point (i). The second statement is immediate.</p><formula xml:id="formula_9">Remark 2.2.</formula><p>For two unnormalized uniform empirical measures µ = n i=1 δ x i and ν = n i=1 δ y i of the same size, with ordered x 1 ≤ · · · ≤ x n and y 1 ≤ · · · ≤ y n , one has:</p><formula xml:id="formula_10">W(µ, ν) = n i=1 |x i −y i | = X − Y 1 , where X = (x 1 , · · · , x n ) ∈ R n and Y = (y 1 , · · · , y n ) ∈ R n .</formula><p>3 The Sliced Wasserstein Kernel</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">The Sliced Wasserstein Kernel</head><p>In this section we define a new kernel between persistence diagrams, called the Sliced Wasserstein kernel, based on the Sliced Wasserstein metric of <ref type="bibr" target="#b30">[31]</ref>. The idea underlying this metric is to slice the plane with lines passing through the origin, to project the measures onto these lines where W is computed, and to integrate those distances over all possible lines. Formally: Definition 3.1. Given θ ∈ R 2 with θ 2 = 1, let L(θ) denote the line {λ θ : λ ∈ R}, and let π θ : R 2 → L(θ) be the orthogonal projection onto L(θ). Let Dg 1 , Dg 2 be two persistence diagrams, and let µ θ 1 = p∈Dg 1 δ π θ (p) and µ θ 1∆ = p∈Dg 1 δ π θ •π ∆ (p) , and similarly for µ θ 2 , where π ∆ is the orthogonal projection onto the diagonal. Then, the Sliced Wasserstein distance is defined as:</p><formula xml:id="formula_11">SW(Dg 1 , Dg 2 ) def. = 1 2π S 1 W(µ θ 1 + µ θ 2∆ , µ θ 2 + µ θ 1∆ )dθ.</formula><p>Note that, by symmetry, one can restrict on the half-circle [− π 2 , π 2 ] and normalize by π instead of 2π. Since Q r is conditionally negative definite, we can deduce that SW itself is conditionally negative definite:</p><formula xml:id="formula_12">Lemma 3.2. SW is conditionally negative definite on D b f .</formula><p>Proof. Let n ∈ N * , a 1 , · · · , a n ∈ R such that i a i = 0 and Dg 1 ,</p><formula xml:id="formula_13">· · · , Dg n ∈ D b f . Given 1 ≤ i ≤ n, we letμ θ i = µ θ i + q∈Dg k ,k =i δ π θ •π ∆ (q) ,μ θ ij∆ = p∈Dg k ,k =i,j δ π θ •π ∆ (p) and d = i |Dg i |. Then: i,j a i a j W(µ θ i + µ θ j∆ , µ θ j + µ θ i∆ ) = i,j a i a j L(µ θ i + µ θ j∆ , µ θ j + µ θ i∆ ) = i,j a i a j L(µ θ i + µ θ j∆ + µ θ ij∆ , µ θ j + µ θ i∆ + µ θ ij∆ ) = i,j a i a j L(μ θ i ,μ θ j ) = i,j a i a j Q d (μ θ i ,μ θ j ) ≤ 0</formula><p>The result follows by linearity of integration.</p><p>Hence, the theorem of <ref type="bibr" target="#b2">[3]</ref> allows us to define a valid kernel with:</p><formula xml:id="formula_14">k SW (Dg 1 , Dg 2 ) def. = exp − SW(Dg 1 , Dg 2 ) 2σ 2 .<label>(5)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Metric Equivalence</head><p>We now give the main theoretical result of this article, which states that SW is strongly equivalent to d 1 . This has to be compared with <ref type="bibr" target="#b33">[34]</ref> and <ref type="bibr" target="#b22">[23]</ref>, which only prove stability and injectivity. Our equivalence result states that k SW , in addition to be stable and injective, preserves the metric between persistence diagrams, which should intuitively lead to an improvement of the classification power. This intuition is illustrated in Section 4 and <ref type="figure">Figure 6</ref>, where we show an improvement of classification accuracies on several benchmark applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Stability</head><formula xml:id="formula_15">Theorem 3.3. SW is stable with respect to d 1 on D b f . For any Dg 1 , Dg 2 ∈ D b f , one has: SW(Dg 1 , Dg 2 ) ≤ 2 √ 2d 1 (Dg 1 , Dg 2 ). Proof. Let θ ∈ R 2 be such that θ 2 = 1. Let Dg 1 , Dg 2 ∈ D b f , and let Dg θ 1 = {π θ (p) : p ∈ Dg 1 } ∪ {π θ • π ∆ (q) : q ∈ Dg 2 } and Dg θ 2 = {π θ (q) : q ∈ Dg 2 } ∪ {π θ • π ∆ (p) : p ∈ Dg 1 }. Let γ * be the one-to-one bijection between Dg θ 1 and Dg θ 2 induced by W(µ θ 1 + µ θ 2∆ , µ θ 2 + µ θ 1∆ )</formula><p>, and let γ be the one-to-one bijection between Dg 1 ∪ π ∆ (Dg 2 ) and Dg 2 ∪ π ∆ (Dg 1 ) induced by the partial bijection achieving d 1 (Dg 1 , Dg 2 ). Then γ naturally induces a one-to-one matching γ θ between Dg θ 1 and Dg θ 2 with:</p><formula xml:id="formula_16">γ θ = {(π θ (p), π θ (q)) : (p, q) ∈ γ} ∪ {(π θ • π ∆ (p), π θ • π ∆ (q)) : (p, q) ∈ γ, p, q ∈ im(π ∆ )}.</formula><p>Now, one has the following inequalities:</p><formula xml:id="formula_17">W(µ θ 1 + µ θ 2∆ , µ θ 2 + µ θ 1∆ ) = (x,y)∈γ * |x − y| ≤ (π θ (p),π θ (q))∈γ θ | p, θ − q, θ | since γ θ is not the optimal matching between Dg θ 1 and Dg θ 2 ≤ (π θ (p),π θ (q))∈γ θ p − q 2 by the Cauchy-Schwarz inequality since θ 2 = 1 ≤ √ 2 (π θ (p),π θ (q))∈γ θ p − q ∞ since · 2 ≤ √ 2 · ∞ ≤ 2 √ 2 (p,q)∈γ p − q ∞ since π ∆ (p) − π ∆ (q) ∞ ≤ p − q ∞ = 2 √ 2d 1 (Dg 1 , Dg 2 ) Hence, we have SW(Dg 1 , Dg 2 ) ≤ 2 √ 2d 1 (Dg 1 , Dg 2 ).</formula><p>We now prove the discriminativity of SW. For this, we need a stronger assumption on the persistence diagrams, namely their cardinalities have not only to be finite, but also bounded by some N ∈ N * .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Discriminativity</head><p>Theorem 3.4. SW is discriminative with respect to d 1 on D b N . For any Dg 1 , Dg 2 ∈ X, one has:</p><formula xml:id="formula_18">1 2M d 1 (Dg 1 , Dg 2 ) ≤ SW(Dg 1 , Dg 2 ), where M = 1 + 2N (2N − 1). Proof. Let Dg 1 , Dg 2 ∈ D b N . Let S + 1 ⊆ S 1</formula><p>be the subset of the circle delimited by the angles − π 2 , π 2 . Let us consider the following set:</p><formula xml:id="formula_19">Θ 1 = θ ∈ S + 1 : ∃p 1 , p 2 ∈ Dg 1 such that θ, p 2 − p 1 = 0 , and similarly: Θ 2 = θ ∈ S + 1 : ∃q 1 , q 2 ∈ Dg 2 such that θ, q 2 − q 1 = 0 . Now, we let Θ = Θ 1 ∪ Θ 2 ∪ − π 2 , π 2</formula><p>be the union of these sets, and sort Θ in decreasing order. One has |Θ| ≤ 2N (2N − 1) + 2 = M + 1 since a vector θ that is orthogonal to a line defined by a specific pair of points (p 1 , p 2 ) appears exactly once in S + 1 . <ref type="figure">Figure 2</ref>: The integral of |cos(·)| has a lower bound that depends on the length of the integral support. In particular, when θ k+1 − θ k ≤ π, this integral is more than</p><formula xml:id="formula_20">1 − π 2 π 2 0 y = |cos(x)| α p θ k+1 − θ k y = 1 − 2x π</formula><formula xml:id="formula_21">(θ k+1 −θ k ) 2 2π</formula><p>by the Cauchy-Schwarz inequality.</p><p>For any θ that is between two consecutive θ k , θ k+1 ∈ Θ, the order of the projections onto L(θ) of the points of both Dg 1 and Dg 2 remains the same. Given any point p ∈ Dg 1 ∪π ∆ (Dg 2 ), we let γ(p) ∈ Dg 2 ∪ π ∆ (Dg 1 ) be its matching point according to the matching given by</p><formula xml:id="formula_22">W(µ θ 1 + µ θ 2∆ , µ θ 2 + µ θ 1∆</formula><p>). Then, one has the following equalities:</p><formula xml:id="formula_23">θ k+1 θ k W(µ θ 1 + µ θ 2∆ , µ θ 2 + µ θ 1∆ ) dθ = θ k+1 θ k p∈Dg 1 ∪π ∆ (Dg 2 ) | p − γ(p), θ | dθ = p∈Dg 1 ∪π ∆ (Dg 2 ) p − γ(p) 2 θ k+1 −θ k 0 |cos (α p + β) | dβ where α p = ∠(p − γ(p), θ k )</formula><p>We need to lower bound θ k+1 −θ k 0 |cos (α p + β) |dβ. Since θ k+1 − θ k ≤ π, one can show that this integral cannot be less than</p><formula xml:id="formula_24">(θ k+1 −θ k ) 2 2π</formula><p>using cosine concavity-see <ref type="figure">Figure 2</ref>. Hence, we now have the following lower bound:</p><formula xml:id="formula_25">θ k+1 θ k W(µ θ 1 + µ θ 2∆ , µ θ 2 + µ θ 1∆ ) dθ ≥ (θ k+1 − θ k ) 2 2π p∈Dg 1 ∪π ∆ (Dg 2 ) p − γ(p) 2 ≥ (θ k+1 − θ k ) 2 2π p∈Dg 1 ∪π ∆ (Dg 2 ) p − γ(p) ∞ ≥ (θ k+1 − θ k ) 2 2π p / ∈π ∆ (Dg 2 ) or γ(p) / ∈π ∆ (Dg 1 ) p − γ(p) ∞ ≥ (θ k+1 − θ k ) 2 2π d 1 (Dg 1 , Dg 2 ). Let Θ = θ 1 = − π 2 , θ 2 , ..., θ |Θ| = π 2 .</formula><p>Then, one has:</p><formula xml:id="formula_26">SW(Dg 1 , Dg 2 ) = 1 π π 2 − π 2 W(µ θ 1 + µ θ 2∆ , µ θ 2 + µ θ 1∆ ) dθ = 1 π |Θ|−1 k=1 θ k+1 θ k W(µ θ 1 + µ θ 2∆ , µ θ 2 + µ θ 1∆ ) dθ ≥   |Θ|−1 k=1 (θ k+1 − θ k ) 2   d 1 (Dg 1 , Dg 2 ) 2π 2 ≥ π 2 |Θ| − 1 d 1 (Dg 1 , Dg 2 )</formula><p>2π 2 by the Cauchy-Schwarz inequality</p><formula xml:id="formula_27">≥ d 1 (Dg 1 , Dg 2 ) 2M</formula><p>Hence, SW is discriminative.</p><p>In particular, Theorems 3.3 and 3.4 allow us to show that d SW , the distance induced by k SW in its RKHS, is also equivalent to d 1 in a broader sense: there exist continuous, positive and monotone functions g, h such that g(0) = h(0) = 0 and h</p><formula xml:id="formula_28">• d 1 ≤ d SW ≤ g • d 1 .</formula><p>The condition on the cardinalities of persistence diagrams can be relaxed. Indeed, one can prove that the feature map φ SW induced by k SW is injective when the persistence diagrams are only assumed to be finite and bounded: Proof. Note that if the persistence diagrams have bounded cardinalities, Proposition 3.5 is an immediate consequence of Theorem 3.4. One has that φ SW is continous since d SW is stable (cf Theorem 3.3). Now, let Dg 1 , Dg 2 ∈ D b f . such that d SW (Dg 1 , Dg 2 ) = φ SW (Dg 1 ) − φ SW (Dg 2 ) = 0. We necessarily have SW(Dg 1 , Dg 2 ) = 0. Assume that d 1 (Dg 1 , Dg 2 ) &gt; 0. Then, there must be a point p in Dg 1 that is not in Dg 2 . The Sliced Wasserstein distance being 0, there must be, for every θ ∈ S 1 , a point q θ in Dg 2 that has the same projection onto L(θ) as p: π θ (q θ ) = π θ (p), i.e. q θ ∈ (π θ (p), p), the line defined by the pair π θ (p), p. All these lines (π θ (p), p) intersect at p = q θ . Thus, q θ 1 = q θ 2 for any θ 1 = θ 2 , hence Dg 2 must include an infinite number of points, which is impossible. Thus, d 1 (Dg 1 , Dg 2 ) = 0 and φ SW is injective.</p><p>In particular, k SW can be turned into a universal kernel by considering exp(k SW ) (cf Theorem 1 in <ref type="bibr" target="#b24">[25]</ref>). This can be useful in a variety of tasks, including tests on distributions of persistence diagrams.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Computation</head><p>Approximate computation. In practice, we propose to approximate k SW in O(N log(N )) time using Algorithm 1. This algorithm first samples M directions in the half-circle S + 1 ; it then computes, for each sample θ i and for each persistence diagram Dg, the scalar products between the points of Dg and θ i , to sort them next in a vector V θ i (Dg). Finally, the 1 -norm between the vectors is averaged over the sampled directions: SW M (Dg 1 ,</p><formula xml:id="formula_29">Dg 2 ) = 1 M M i=1 V θ i (Dg 1 ) − V θ i (Dg 2 ) 1 .</formula><p>Note that one can easily adapt the proof of Lemma 3.2 to show that SW M is negative semi-definite by using the linearity of the sum. Hence, this approximation remains a kernel. If the two persistence diagrams have cardinalities bounded by N , then the running time of this procedure is O(M N log(N )). This approximation of k SW is useful since, as shown in Section 4, we have observed empirically that just a few directions are sufficient to get good classification accuracies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1: Approximate computation of SW</head><p>Input: Dg 1 = {p 1 1 , · · · , p 1 N 1 }, Dg 2 = {p 2 1 , · · · , p 2 N 2 }, M . Add π ∆ (Dg 1 ) to Dg 2 and vice-versa. Let SW = 0; θ = −π/2; s = π/M ; for i = 1, · · · , M do Store the products p 1 k , θ in an array V 1 ; Store the products p 2 k , θ in an array V 2 ; Sort V 1 and V 2 in ascending order;</p><formula xml:id="formula_30">SW = SW + s V 1 − V 2 1 ; θ = θ + s; end for Output: (1/π)SW;</formula><p>Exact computation. A persistence diagram is said to be in general position if it has no triplet of aligned points. If the persistence diagrams have cardinalities bounded by N , then the exact kernel computation for persistence diagrams in general position can be done in O(N 2 log(N )) time with Algorithm 2. In practice, given Dg 1 and Dg 2 , we slightly modify them with infinitesimally small random perturbations. The resulting persistence diagramsDg 1 andDg 2 are in general position and we can approximate k SW (Dg 1 , Dg 2 ) with k SW (Dg 1 ,Dg 2 ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>In this section, we compare k SW to k PSS and k PWG on several benchmark applications for which persistence diagrams have been proven useful. We compare these kernels in terms of classification accuracies and compuational cost. We review first our experimental setting, and review these tasks one by one.</p><p>Experimental setting All kernels are handled with the LIBSVM <ref type="bibr" target="#b6">[7]</ref> implementation of C-SVM, and results are averaged over 10 runs on a 2.4GHz Intel Xeon E5530 Quad Core. The cost factor C is cross-validated in the following grid: {0.001, 0.01, 0.1, 1, 10, 100, 1000}. <ref type="table" target="#tab_1">Table 1</ref> summarizes the properties of the datasets we consider, namely number of labels, as well as training and test instances for each task. <ref type="figure" target="#fig_3">Figure 3</ref> and 4 illustrate how we use persistence diagrams to represent complex data. We first describe the two baselines we considered, along with their parameterization, followed by our proposal.</p><p>PSS. The Persistence Scale Space kernel k PSS <ref type="bibr" target="#b33">[34]</ref> is defined as the scalar product of the two solutions of the heat diffusion equation with initial Dirac sources located at the points of the Algorithm 2: Exact computation of SW Input:</p><formula xml:id="formula_31">Dg 1 = {p 1 1 , · · · , p 1 N 1 } with |Dg 1 | = N 1 , Dg 2 = {p 2 1 , · · · , p 2 N 2 } with |Dg 2 | = N 2 1 Let Θ 1 = [], Θ 2 = [], V 1 = [], V 2 = [], B 1 = [[] ... []], B 2 = [[] ... []], SW = 0; 2 for i = 1, · · · , N 1 do 3 Add p 2 N 2 +i = π ∆ (p 1 i ) to Dg 2 ; 4 for i = 1, · · · , N 2 do 5 Add p 1 N 1 +i = π ∆ (p 2 i ) to Dg 1 ; 6 for i = 1, 2 do 7 for j = 1, · · · , N 1 + N 2 − 1 do 8 for k = j + 1, · · · , N 1 + N 2 do 9 Add ∠ p i j − p i k ⊥ ∈ − π 2 , π 2 to Θ i ; 10</formula><p>Sort A i in ascending order;</p><formula xml:id="formula_32">11 for j = 1, · · · , N 1 + N 2 do 12 Add p i j , [0, −1] to V i ; 13 Sort V i in ascending order; 14 Let f i : p i j → position of p i j , − π Add p i k 1 , Θ i [j] to B i f i (p i k 1 ) ; Add p i k 2 , Θ i [j] to B i f i (p i k 2 ) ; 18</formula><p>Swap f i (p i k 1 ) and f i (p i k 2 ); <ref type="bibr" target="#b18">19</ref> for j = 1, · · · , N 1 + N 2 do 20 Add p i j , π 2 to B i f i (p i j ) ; 21 for i = 1, · · · , N 1 + N 2 do <ref type="bibr" target="#b21">22</ref> Let k 1 = 0, k 2 = 0; <ref type="bibr" target="#b22">23</ref> Let θ m = − π 2 and θ M = min{B <ref type="bibr" target="#b0">1</ref>    <ref type="table">Table 2</ref>: Classification accuracies (%) for the benchmark applications.</p><formula xml:id="formula_33">[i][k 1 ] 2 , B 2 [i][k 2 ] 2 }; 24 while θ m = π 2 do 25 SW = SW + B 1 [i][k 1 ] 1 − B 2 [i][k 2 ] 1 2 θ M −θm 0 cos(∠ (B 1 [i][k 1 ] 1 − B 2 [i][k 2 ] 1 , θ m ) + θ)dθ; 26 θ m = θ M ; 27 if θ M == B 1 [i][k 1 ] 2 then k 1 = k 1 + 1; else k 2 = k 2 + 1; 28 θ M = min{B 1 [i][k 1 ] 2 , B 2 [i][</formula><p>persistence diagram. It has the following closed form expression:</p><formula xml:id="formula_34">k PSS (Dg 1 , Dg 2 ) = 1 8πt p∈Dg 1 q∈Dg 2 exp − p − q 2 8t − exp − p −q 2 8t , whereq = (y, x)</formula><p>is the symmetric of q = (x, y) along the diagonal. Since there is no clear heuristic on how to tune t, this parameter is chosen in the applications by ten-fold cross-validation with random 50%-50% training-test splits and with the following set of N PSS = 13 values: 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500 and 1000.</p><p>PWG. Let K, p &gt; 0 and Dg 1 and Dg 2 be two persistence diagrams. Let k ρ be the Gaussian kernel with parameter ρ &gt; 0. Let H ρ be the RKHS associated to k ρ . Let µ 1 = x∈Dg 1 arctan(Kpers(x) p )k ρ (·, x) ∈ H ρ be the kernel mean embedding of Dg 1 weigthed by the diagonal distances. Let µ 2 be defined similarly. Let τ &gt; 0. The Persistence Weighted Gaussian kernel k PWG <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b23">24]</ref> is defined as the Gaussian kernel with parameter τ on H ρ :</p><formula xml:id="formula_35">k PWG (Dg 1 , Dg 2 ) = exp − µ 1 − µ 2 Hρ 2τ 2 .</formula><p>The authors in <ref type="bibr" target="#b22">[23]</ref> provide heuristics to compute K, ρ and τ and give a rule of thumb to tune p. Hence, in the applications we select p according to the rule of thumb, and we use ten-fold cross-   Training Test Label = ? <ref type="figure" target="#fig_3">Figure 3</ref>: Sketch of the orbit recognition task. Each parameter r in the 5 possible choices leads to a specific behavior of the orbit. The goal is to recover parameters from the persistent homology of orbits in the test set.</p><p>validation with random 50%-50% training-test splits to chose K, ρ and τ . The ranges of possible values is obtained by multiplying the values computed with the heuristics with the following range of 5 factors: 0.01, 0.1, 1, 10 and 100, leading to N PWG = 5×5×5 = 125 different sets of parameters.</p><p>Parameters for k SW . The kernel we propose has only one parameter, the bandwidth σ in Eq. 5, which we choose using ten-fold cross-validation with random 50%-50% training-test splits. The range of possible values is obtained by computing the squareroot of the median, the first and the last deciles of all SW(Dg i , Dg j ) in the training set, then by multiplying these values by the following range of 5 factors: 0.01, 0.1, 1, 10 and 100, leading to N SW = 5 × 3 = 15 possible values.</p><p>Parameter Tuning. The bandwidth of k SW is, in practice, easier to tune than the parameters of its two competitors when using grid search. Indeed, as is the case for all infinitely divisible kernels, the Gram matrix does not need to be recomputed for each choice of σ, since it only suffices to  <ref type="figure">Figure 4</ref>: Examples of persistence diagrams computed on texture images from the OUTEX00000 dataset and persistence diagrams computed from points on 3D shapes. One can see that corresponding points in different shapes have similar persistence diagrams.</p><p>compute all the Sliced Wasserstein distances between persistence diagrams in the training set once. On the contrary, neither k PSS nor k PWG share this property, and require recomputations for each hyperparameter choice. Note however that this improvement may no longer hold if one uses other methods to tune parameters. For instance, using k PWG without cross-validation is possible with the heuristics given by the authors in <ref type="bibr" target="#b22">[23]</ref>, and leads to smaller training times, but also to worse accuracies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">3D shape segmentation</head><p>Our first task, whose goal is to produce point classifiers for 3D shapes, follows that presented in <ref type="bibr" target="#b5">[6]</ref>.</p><p>Data. We use some categories of the mesh segmentation benchmark of Chen et al. <ref type="bibr" target="#b11">[12]</ref>, which contains 3D shapes classified in several categories ("airplane", "human", "ant"...). For each category, our goal is to design a classifier that can assign, to each point in the shape, a label that describes the relative location of that point in the shape. For instance, possible labels are, for the human category, "head", "torso", "arm"... To train classifiers, we compute a persistence diagram per point using the geodesic distance function to this point-see <ref type="bibr" target="#b5">[6]</ref> for details. We use 1-dimensional persistent homology (0-dimensional would not be informative since the shapes are connected, leading to solely one point with coordinates (0, +∞) per persistence diagram). For each category, the training set contains one hundredth of the points of the first five 3D shapes, and the test set contains one hundredth of the points of the remaining shapes in that category. Points in training and test sets are evenly sampled. See <ref type="figure">Figure 4</ref>. Here, we focus on comparison between persistence diagrams, and not on achieving state-of-the-art results. It has been proven that persistence diagrams bring complementary information to classical descriptors in this task-see <ref type="bibr" target="#b5">[6]</ref>, hence reinforcing their discriminative power with appropriate kernels is of great interest. Finally, since data points are in R 3 , we set the p parameter of k PWG to 5.</p><p>Results. Classification accuracies are given in <ref type="table">Table 2</ref>. For most categories, k SW outperforms competing kernels by a significant margin. The variance of the results over the run is also less than  <ref type="figure">Figure 5</ref>: The first column corresponds to the orbit recognition and the texture classification while the second column corresponds to 3D shape segmentation. On each column, the first row shows the dependence of the accuracy on the number of directions, the second row shows the dependence of a single Gram matrix computation time, and the third row shows the dependence of the ratio of the approximation of SW and the exact SW. Since the box plot of the ratio for orbit recognition is very similar to that of 3D shape segmentation, we only give the box plot of texture classification in the first column.</p><p>that of its competitors. However, training times are not better in general. Hence, we also provide the results for an approximation of k SW with 10 directions. As one can see from <ref type="table">Table 2</ref> and from <ref type="figure">Figure 5</ref>, this approximation leaves the accuracies almost unchanged, while the training times become comparable with the ones of the other competitors. Moreover, according to <ref type="figure">Figure 5</ref>, using even less directions would slightly decrease the accuracies, but still outperform the competitors performances, while decreasing even more the training times.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Orbit recognition</head><p>In our second experiment, we use synthetized data. The goal is to retrieve parameters of dynamical system orbits, following an experiment proposed in <ref type="bibr" target="#b0">[1]</ref>.</p><p>Data. We study the linked twist map, a discrete dynamical system modeling fluid flow. It was used in <ref type="bibr" target="#b18">[19]</ref> to model flows in DNA microarrays. Its orbits can be computed given a parameter r &gt; 0 and initial positions (x 0 , y 0 ) ∈ [0, 1] × [0, 1] as follows:</p><formula xml:id="formula_36">x n+1 = x n + ry n (1 − y n ) mod 1 y n+1 = y n + rx n+1 (1 − x n+1 ) mod 1</formula><p>Depending on the values of r, the orbits may exhibit very different behaviors. For instance, as one can see in <ref type="figure" target="#fig_3">Figure 3</ref>, when r is 3.5, there seems to be no interesting topological features in the orbit, while voids form for r parameters around 4.3. Following <ref type="bibr" target="#b0">[1]</ref>, we use 5 different parameters r = 2.5, 3.5, 4, 4.1, 4.3, that act as labels. For each parameter, we generate 100 orbits with 1000 points and random initial positions. We then compute the persistence diagrams of the distance functions to the point clouds with the GUDHI library <ref type="bibr" target="#b38">[39]</ref> and we use them (in all homological dimensions) to produce an orbit classifier that predicts the parameter values, by training over a 70%-30% training-test split of the data. Since data points are in R 2 , we set the p parameter of k PWG to 4.</p><p>Results. Since the persistence diagrams contain thousands of points, we use kernel approximations to speed up the computation of the Gram matrices. In order for the approximation error to be bounded by 10 −3 , we use an approximation of k SW with 6 directions (as one can see from Figure 5, this has a small impact on the accuracy), we approximate k PWG with 1000 random Fourier features <ref type="bibr" target="#b31">[32]</ref>, and we approximate k PSS using Fast Gauss Transform <ref type="bibr" target="#b26">[27]</ref> with a normalized error of 10 −10 . One can see from <ref type="table">Table 2</ref> that the accuracy is increased a lot with k SW . Concerning training times, there is also a large improvement since we tune the parameters with grid search. Indeed, each Gram matrix needs not be recomputed for each parameter when using k SW .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Texture classification</head><p>Our last experiment is inspired from <ref type="bibr" target="#b33">[34]</ref> and <ref type="bibr" target="#b25">[26]</ref>. We use the OUTEX00000 data base <ref type="bibr" target="#b27">[28]</ref> for texture classification.</p><p>Data. persistence diagrams are obtained for each texture image by computing first the sign component of CLBP descriptors <ref type="bibr" target="#b16">[17]</ref> with radius R = 1 and P = 8 neighbors for each image, and then compute the persistent homology of this descriptor using the GUDHI library <ref type="bibr" target="#b38">[39]</ref>. See  <ref type="figure">Figure 6</ref>: We show how the metric d 1 is distorted. Each point represents a pair of persistence diagrams and its abscissae is the first diagram distance between them. Depending on the point color, its ordinate is the logarithm of the distance between persistence diagrams in the RKHS induced by either k PSS (blue points), k PWG (green points), k SW (red points) and a Gaussian kernel on d 1 (black points). <ref type="figure">Figure 4</ref>. Note that, contrary to the experiment of <ref type="bibr" target="#b33">[34]</ref>, we do not downsample the images to 32 × 32 images, but keep the original 128 × 128 images. Following <ref type="bibr" target="#b33">[34]</ref>, we restrict the focus to 0-dimensional persistent homology. We also use the first 50%-50% training-test split given in the database to produce classifiers. Since data points are in R 2 , we set the p parameter of k PWG to 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>We use the same approximation procedure as in Section 4.2. According to <ref type="figure">Figure 5</ref>, even though the approximation of SW is rough, this has again a small impact on the accuracy, while reducing the training time by a significant margin. As one can see from <ref type="table">Table 2</ref>, using k PSS leads to almost state-of-the-art results <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b16">17]</ref>, closely followed by the accuracies of k SW and k PWG . The best timing is given by k SW , again because we use grid search. Hence, k SW almost achieves the best result, and its training time is better than the ones of its competitors, due to the grid search parameter tuning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Metric Distortion.</head><p>To illustrate the equivalence theorem, we also show in <ref type="figure">Figure 6</ref> a scatter plot where each point represents the comparison of two persistence diagrams taken from the Airplane segmentation data set. Similar plots can be obtained with the other datasets considered here. For all points, the x-axis quantifies the first diagram distance d 1 for that pair, while the y-axis is the logarithm of the RKHS distance induced by either k SW , k PSS , k PWG or a Gaussian kernel directly applied to d 1 , to obtain comparable quantities. We use the parameters given by the cross-validation procedure described above. One can see that the distances induced by k SW are less spread than the others, suggesting that the metric induced by k SW is more discriminative. Moreover the distances given by k SW and the Gaussian kernel on d 1 exhibit the same behavior, suggesting that k SW is the best natural equivalent of a Gaussian kernel for persistence diagrams.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this article, we introduce the Sliced Wasserstein kernel, a new kernel for persistence diagrams that is provably equivalent to the first diagram distance between persistence diagrams. We provide fast algorithms to approximate it, and show on several datasets substantial improvements in accuracy and training times (when tuning parameters is done with grid search) over competing kernels. A particularly appealing property of that kernel is that it is infinitely divisible, substantially facilitating the tuning of parameters through cross validation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Sketch of persistent homology: (a) the horizontal lines are the boundaries of sublevel sets f ((−∞, t]), which are colored in decreasing shades of grey. The vertical dotted lines are the boundaries of their different connected components. For instance, a new connected component is created in the sublevel set f −1 ((−∞, t]) when t = f (p), and it is merged (destroyed) when t = f (s); its lifespan is represented by a copy of the point with coordinates (f (p), f (s)) in the persistence diagram of f (Figure (c)); (b) a piecewise-linear approximation g (blue) of the function f (red) from sampled values; (c) superposition of Dg(f ) (red) and Dg(g) (blue), showing the partial matching of minimum cost (magenta) between the two persistence diagrams.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Proposition 3 . 5 .</head><label>35</label><figDesc>The feature map φ SW is continuous and injective with respect to d 1 on D b f .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Taskk</head><label></label><figDesc>PSS (10 −3 ) k PWG (1000) k SW (6) Orbit N (124 ± 8.4) N (144 ± 14) 415 ± 7.9 + N C Texture N (165 ± 27)N (101 ± 9.6) 482 ± 68 + N C Taskk PSS k PWG k SW k SW (10) Human N (29 ± 0.3) N (318 ± 22) 2270 ± 336 + N C 107 ± 14 + N C Airplane N (0.8 ± 0.03) N (5.6 ± 0.02) 44 ± 5.4 + N C 10 ± 1.6 + N C Ant N (1.7 ± 0.01) N (12 ± 0.5) 92 ± 2.8 + N C 16 ± 0.4 + N C Bird N (0.5 ± 0.01) N (3.6 ± 0.02) 27 ± 1.6 + N C 6.6 ± 0.8 + N C FourLeg N (10 ± 0.07) N (113 ± 13) 604 ± 25 + N C 52 ± 3.2 + N C Octopus N (1.4 ± 0.01) N (11 ± 0.8) 75 ± 1.4 + N C 14 ± 2.1 + N C FishN (1.2 ± 0.004) N (9.6 ± 0.03) 72 ± 4.8 + N C 12 ± 1.1 + N C</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>3 :</head><label>3</label><figDesc>Gram matrices computation time (s) for the benchmark applications. As explained in the text, N represents the size of the set of possible parameters, and we have N = 13 for k PSS , N = 5 × 5 × 5 = 125 for k PWG and N = 3 × 5 = 15 for k SW . C is a constant that depends only on the training size. In all our applications, it is less than 0.1s.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>approx / SW exact )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>k 2 ] 2 };</figDesc><table><row><cell>Task</cell><cell cols="3">Training Test Labels</cell></row><row><cell>Orbit</cell><cell>175</cell><cell>75</cell><cell>5</cell></row><row><cell>Texture</cell><cell>240</cell><cell>240</cell><cell>24</cell></row><row><cell>Human</cell><cell>415</cell><cell>1618</cell><cell>8</cell></row><row><cell>Airplane</cell><cell>300</cell><cell>980</cell><cell>4</cell></row><row><cell>Ant</cell><cell>364</cell><cell>1141</cell><cell>5</cell></row><row><cell>Bird</cell><cell>257</cell><cell>832</cell><cell>4</cell></row><row><cell>FourLeg</cell><cell>438</cell><cell>1097</cell><cell>6</cell></row><row><cell>Octopus</cell><cell>334</cell><cell>1447</cell><cell>2</cell></row><row><cell>Fish</cell><cell>304</cell><cell>905</cell><cell>3</cell></row><row><cell>29 return 1 π SW;</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Number of instances in the training set, the test set and number of labels.</figDesc><table><row><cell>Task</cell><cell cols="3">k PSS (10 −3 ) k PWG (1000) k SW (6)</cell></row><row><cell cols="2">Orbit Texture 98.8 ± 0.0 63.6 ± 1.2 Task k PSS</cell><cell>77.7 ± 1.2 95.8 ± 0.0 k PWG</cell><cell>83.7 ± 0.5 96.1 ± 0.4 k SW</cell></row><row><cell cols="2">Human Airplane 65.4 ± 2.4 68.5 ± 2.0 Ant 86.3 ± 1.0 Bird 67.7 ± 1.8 FourLeg 67.0 ± 2.5 Octopus 77.6 ± 1.0 Fish 76.1 ± 1.6</cell><cell>64.2 ± 1.2 61.3 ± 2.9 87.4 ± 0.5 72.0 ± 1.2 64.0 ± 0.6 78.6 ± 1.3 79.8 ± 0.5</cell><cell>74.0 ± 0.2 72.6 ± 0.2 92.3 ± 0.2 67.0 ± 0.5 73.0 ± 0.4 85.2 ± 0.5 75.0 ± 0.4</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table</head><label></label><figDesc></figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">in V i ; 15 for j = 1, · · · , (N 1 + N 2 )(N 1 + N 2 − 1)/2 do 16 Let k 1 , k 2 such that Θ i [j] = ∠ p i k 1 − p i k 2 ⊥ ;</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgements. SO was supported by ERC grant Gudhi and by ANR project TopData. MC was supported by a chaire de l'IDEX Paris Saclay.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Persistence Images: A Stable Vector Representation of Persistent Homology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henry</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tegan</forename><surname>Emerson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Kirby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rachel</forename><surname>Neville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Peterson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Shipman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sofya</forename><surname>Chepushtanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Hanson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francis</forename><surname>Motta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lori</forename><surname>Ziegelmeier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1" to="35" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Induced matchings and the algebraic stability of persistence barcodes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulrich</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Lesnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational Geometry</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="162" to="191" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Harmonic Analysis on Semigroups: Theory of Positive Definite and Related Functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Christensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Ressel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1984" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Statistical Topological Data Analysis using Persistence Landscapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Bubenik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="77" to="102" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Zigzag Persistent Homology and Realvalued Functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gunnar</forename><surname>Carlsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitriy</forename><surname>Vin De Silva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Morozov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th Symposium on Computational Geometry</title>
		<meeting>the 25th Symposium on Computational Geometry</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="247" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Stable Topological Signatures for Points on 3D Shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Mathieu Carrière</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maks</forename><surname>Oudot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ovsjanikov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">LIBSVM: A library for support vector machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lin</surname></persName>
		</author>
		<ptr target="http://www.csie.ntu.edu.tw/~cjlin/libsvm" />
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Intelligent Systems and Technology</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="27" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Proximity of Persistence Modules and their Diagrams</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frédéric</forename><surname>Chazal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Cohen-Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Glisse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><surname>Guibas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Oudot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th Symposium on Computational Geometry</title>
		<meeting>the 25th Symposium on Computational Geometry</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="237" to="246" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Gromov-Hausdorff Stable Signatures for Shapes using Persistence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frédéric</forename><surname>Chazal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Cohen-Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><surname>Guibas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Facundo</forename><surname>Mémoli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Oudot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="page" from="1393" to="1403" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">The Structure and Stability of Persistence Modules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frédéric</forename><surname>Chazal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Vin De Silva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Glisse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Oudot</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Persistence stability for geometric complexes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frédéric</forename><surname>Chazal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Vin De Silva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Oudot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Geometriae Dedicata</title>
		<imprint>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A Benchmark for 3D Mesh Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Golovinskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Funkhouser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Stability of Persistence Diagrams. Discrete and Computational Geometry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herbert</forename><surname>Edelsbrunner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Harer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="103" to="120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Comparing persistence diagrams through complex vectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Di</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimo</forename><surname>Ferri</surname></persName>
		</author>
		<idno>abs/1505.01335</idno>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Computational Topology: an introduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herbert</forename><surname>Edelsbrunner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Harer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>AMS Bookstore</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Geodesic exponential kernels: When curvature and linearity conflict</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aasa</forename><surname>Feragen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">François</forename><surname>Lauze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Søren</forename><surname>Hauberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3032" to="3042" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A completed modeling of local binary pattern operator for texture classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenhua</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transaction on Image Processing</title>
		<imprint>
			<biblScope unit="page" from="1657" to="1663" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Juha Heinonen. Lectures on Analysis on Metric Spaces</title>
		<imprint>
			<date type="published" when="2001" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">DNA microarrays: design principles for maximizing ergodic, chaotic mixing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan-Martin</forename><surname>Hertzsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Sturman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Wiggins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Small</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="202" to="218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Hierarchical structures of amorphous solids characterized by persistent homology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yasuaki</forename><surname>Hiraoka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takenobu</forename><surname>Nakamura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akihiko</forename><surname>Hirata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emerson</forename><surname>Escolar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaname</forename><surname>Matsue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yasumasa</forename><surname>Nishiura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the National Academy of Science</title>
		<meeting>the National Academy of Science</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">26</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Sliced Wasserstein Kernels for Probability Distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soheil</forename><surname>Kolouri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gustavo</forename><surname>Rohde</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="5258" to="5267" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Eigenvalue Distribution of Compact Operators. Operator Theory: Advances and Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>König</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986" />
			<publisher>Birkhäuser</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Persistence Weighted Gaussian Kernel for Topological Data Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Genki</forename><surname>Kusano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenji</forename><surname>Fukumizu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yasuaki</forename><surname>Hiraoka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd International Conference on Machine Learning</title>
		<meeting>the 33rd International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2004" to="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Kernel method for persistence diagrams via kernel embedding and weight factor</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Genki</forename><surname>Kusano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenji</forename><surname>Fukumizu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yasuaki</forename><surname>Hiraoka</surname></persName>
		</author>
		<idno>abs/1706.03472</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Statistical Topological Data Analysis -A Kernel Perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roland</forename><surname>Kwitt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Huber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Niethammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weili</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulrich</forename><surname>Bauer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="3070" to="3078" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Persistence-Based Structural Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maks</forename><surname>Ovsjanikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frédéric</forename><surname>Chazal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Automatic online tuning for fast Gaussian summation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vlad</forename><surname>Morariu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balaji</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vikas</forename><surname>Raykar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramani</forename><surname>Duraiswami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1113" to="1120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Outex -new framework for empirical evaluation of texture analysis algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Ojala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Topi</forename><surname>Mäenpää</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matti</forename><surname>Pietikäinen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaakko</forename><surname>Viertola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juha</forename><surname>Kyllönen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sami</forename><surname>Huovinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th International Conference on Pattern Recognition</title>
		<meeting>the 16th International Conference on Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="701" to="706" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Oudot</surname></persName>
		</author>
		<title level="m">Persistence Theory: From Quiver Representations to Data Analysis. Number 209 in Mathematical Surveys and Monographs</title>
		<imprint>
			<publisher>American Mathematical Society</publisher>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Supervised Learning with Indefinite Topological Kernels. CoRR</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tullia</forename><surname>Padellini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierpaolo</forename><surname>Brutti</surname></persName>
		</author>
		<idno>abs/1709.07100</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Wasserstein barycenter and its application to texture mixing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Rabin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Peyré</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julie</forename><surname>Delon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Bernot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Scale Space and Variational Methods in Computer Vision</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="435" to="446" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Random Features for Large-Scale Kernel Machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Rahimi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Recht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="1177" to="1184" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">A Stable Multi-Scale Kernel for Topological Machine Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Reininghaus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Huber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulrich</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roland</forename><surname>Kwitt</surname></persName>
		</author>
		<idno>abs/1412.6821</idno>
		<imprint>
			<date type="published" when="2014" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A Stable Multi-Scale Kernel for Topological Machine Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Reininghaus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Huber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulrich</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roland</forename><surname>Kwitt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Principal Component Analysis of Persistent Homology Rank Functions with case studies of Spatial Point Patterns, Sphere Packing and Colloids</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vanessa</forename><surname>Robins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katharine</forename><surname>Turner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physica D: Nonlinear Phenomena</title>
		<imprint>
			<biblScope unit="volume">334</biblScope>
			<biblScope unit="page" from="1" to="186" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Optimal transport for applied mathematicians</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filippo</forename><surname>Santambrogio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Topological analysis of population activity in visual cortex</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gurjeet</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Facundo</forename><surname>Mémoli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tigran</forename><surname>Ishkhanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillermo</forename><surname>Sapiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gunnar</forename><surname>Carlsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dario</forename><surname>Ringach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Mercer&apos;s theorem on general domains: on the interaction between measures, kernels, and RKHSs. Constructive Approximation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ingo</forename><surname>Steinwart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clint</forename><surname>Scovel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="363" to="417" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">The GUDHI Project. GUDHI User and Reference Manual. GUDHI Editorial Board</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Fréchet Means for Distributions of Persistence Diagrams. Discrete and Computational Geometry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katharine</forename><surname>Turner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuriy</forename><surname>Mileyko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sayan</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Harer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="44" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Optimal transport : old and new</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cédric</forename><surname>Villani</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
