<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Embedding Propagation: Smoother Manifold for Few-Shot Classification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pau</forename><surname>Rodríguez</surname></persName>
							<email>pau.rodriguez@elementai.com</email>
							<affiliation key="aff0">
								<orgName type="department">Element AI</orgName>
								<address>
									<settlement>Montreal</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Issam</forename><surname>Laradji</surname></persName>
							<email>issam.laradji@elementai.com</email>
							<affiliation key="aff0">
								<orgName type="department">Element AI</orgName>
								<address>
									<settlement>Montreal</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of British Columbia</orgName>
								<address>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Drouin</surname></persName>
							<email>adrouin@elementai.com</email>
							<affiliation key="aff0">
								<orgName type="department">Element AI</orgName>
								<address>
									<settlement>Montreal</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Lacoste</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Element AI</orgName>
								<address>
									<settlement>Montreal</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Embedding Propagation: Smoother Manifold for Few-Shot Classification</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T18:36+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>few-shot · classification · semi-supervised learning · met- alearning</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Few-shot classification is challenging because the data distribution of the training set can be widely different to the test set as their classes are disjoint. This distribution shift often results in poor generalization. Manifold smoothing has been shown to address the distribution shift problem by extending the decision boundaries and reducing the noise of the class representations. Moreover, manifold smoothness is a key factor for semi-supervised learning and transductive learning algorithms. In this work, we propose to use embedding propagation as an unsupervised non-parametric regularizer for manifold smoothing in few-shot classification. Embedding propagation leverages interpolations between the extracted features of a neural network based on a similarity graph. We empirically show that embedding propagation yields a smoother embedding manifold. We also show that applying embedding propagation to a transductive classifier achieves new stateof-the-art results in miniImagenet, tiered Imagenet, Imagenet-FS, and CUB. Furthermore, we show that embedding propagation consistently improves the accuracy of the models in multiple semi-supervised learning scenarios by up to 16% points. The proposed embedding propagation operation can be easily integrated as a non-parametric layer into a neural network. We provide the training code and usage examples at https://github.com/ElementAI/embedding-propagation.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Abstract. Few-shot classification is challenging because the data distribution of the training set can be widely different to the test set as their classes are disjoint. This distribution shift often results in poor generalization. Manifold smoothing has been shown to address the distribution shift problem by extending the decision boundaries and reducing the noise of the class representations. Moreover, manifold smoothness is a key factor for semi-supervised learning and transductive learning algorithms. In this work, we propose to use embedding propagation as an unsupervised non-parametric regularizer for manifold smoothing in few-shot classification. Embedding propagation leverages interpolations between the extracted features of a neural network based on a similarity graph. We empirically show that embedding propagation yields a smoother embedding manifold. We also show that applying embedding propagation to a transductive classifier achieves new stateof-the-art results in miniImagenet, tiered Imagenet, Imagenet-FS, and CUB. Furthermore, we show that embedding propagation consistently improves the accuracy of the models in multiple semi-supervised learning scenarios by up to 16% points. The proposed embedding propagation operation can be easily integrated as a non-parametric layer into a neural network. We provide the training code and usage examples at https://github.com/ElementAI/embedding-propagation.</p><p>Keywords: few-shot · classification · semi-supervised learning · metalearning Deep learning methods have achieved state-of-the-art performance in computer vision tasks such as classification <ref type="bibr" target="#b22">[22]</ref>, semantic segmentation <ref type="bibr" target="#b31">[31]</ref>, and object detection <ref type="bibr" target="#b39">[39]</ref>. However, these methods often need to be trained on a large amount of labeled data. Unfortunately, labeled data is scarce and its collection is expensive for most applications. This has led to the emergence of deep learning methods based on transfer learning <ref type="bibr" target="#b59">[59]</ref>, few-shot learning (FSL) <ref type="bibr" target="#b9">[9]</ref>, and semi-supervised learning <ref type="bibr" target="#b5">[5]</ref>, that address the challenges of learning with limited data.</p><p>Few-shot learning methods have the potential to significantly reduce the need for human annotation. This is because such methods learn new tasks with few labeled examples by transferring the knowledge gained across several tasks. Three recent approaches have been successful for few-shot classification (FSC): metric learning, meta learning, and transfer learning. Metric learning approaches <ref type="bibr" target="#b53">[53,</ref><ref type="bibr" target="#b45">45]</ref> learn an embedding space where a set of labeled examples (support set) is used to predict the classes for unlabeled examples (query set). Meta-learning approaches <ref type="bibr" target="#b10">[10,</ref><ref type="bibr" target="#b42">42]</ref> learn to infer a set of parameters that can be adapted to new tasks. Transfer learning <ref type="bibr" target="#b6">[6,</ref><ref type="bibr" target="#b32">32]</ref> methods aim to learn a general feature representation and then train a classifier for each new task. In this work, we use an approach between metric learning and transfer learning. During training, the model attempts to learn a general feature representation that is fine-tuned using a metric-based classifier.</p><p>A key challenge in few-shot classification is training models that generalize well to unseen classes. This requires feature representations that are robust to small changes in the data distribution. This issue has been addressed outside the few-shot learning literature with a number of regularization techniques such as dropout <ref type="bibr" target="#b46">[46]</ref>, batch normalization <ref type="bibr" target="#b19">[19]</ref>, and manifold mixup <ref type="bibr" target="#b52">[52]</ref>. However, regularization in few-shot learning remains unexplored. In this work, we show that re-framing label propagation to perform manifold smoothing improves the performance of few-shot classifiers, particularly in the transductive and semisupervised settings. Different from manifold mixup <ref type="bibr" target="#b52">[52]</ref>, the proposed method is unsupervised and captures higher order interactions between the embedding.</p><p>We propose an embedding propagation (EP) method that outputs a set of interpolations from the network output features using their similarity in a graph. This graph is constructed with pairwise similarities of the features using the radial basis function (RBF). EP is non-parametric and can be applied on top of any feature extractor. It can be used as part of a network in order to obtain a regularized manifold for both training and testing. We refer to such network as EPNet. For few-shot classification, we empirically show that the proposed regularization improves the performance for transductive and semi-supervised learning. The hypothesis behind this improvement is based on the fact that using interpolated embeddings result in smoother decision boundaries and increased robustness to noise. These properties have been shown to be important for generalization <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b27">27,</ref><ref type="bibr" target="#b52">52]</ref> and semi-supervised learning <ref type="bibr" target="#b5">[5]</ref>.</p><p>For semi-supervised learning (SSL), EPNet takes advantage of an unlabeled set of images at test time in order to make better predictions of the query set. We adapt the SSL approach proposed by Lee et al. <ref type="bibr" target="#b25">[25]</ref> to the few-shot classification setup. Thus, for each unlabeled image, EPNet selects the class that has the maximum predicted probability as the pseudo label. EPNet then uses these pseudo labels along with the support set to perform label propagation to predict the labels of the query set. This approach achieves significant improvement over previous state-of-the-art in the 1-shot SSL setting. We hypothesize that EPNet is effective in the SSL setting because of the properties of smoother manifolds <ref type="bibr" target="#b5">[5]</ref>.</p><p>Overall, EPNet achieves state-of-the-art results on mini Imagenet <ref type="bibr" target="#b53">[53]</ref>, tiered Imagenet <ref type="bibr" target="#b39">[39]</ref>, Imagenet-FS <ref type="bibr" target="#b15">[15]</ref> and CUB <ref type="bibr" target="#b55">[55]</ref> for few-shot classification, and semi-supervised learning scenarios. In our ablation experiments, we evaluate different variations of embedding propagation and their impact on the smoothness of the decision boundaries. We also show that, with EP, we also achieve a clear improvement on the SSL setup compared to the same model without EP.</p><p>Our main contributions can be summarized as follows. We show that embedding propagation:</p><p>-Regularizes the manifold in an unsupervised manner.</p><p>-Leverages embedding interpolations to capture higher order feature interactions. -Achieves state-of-the-art few-shot classification results for the transductive and semi-supervised learning setups.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Related Work</head><p>Our work focuses on few-shot classification, but also intersects with manifold regularization, transductive learning, and semi-supervised learning. We describe relevant work for each of these topics and point out their relevance to our method.</p><p>Few-shot classification. A common practice for training models for few-shot learning is to use episodic learning <ref type="bibr" target="#b37">[37,</ref><ref type="bibr" target="#b53">53,</ref><ref type="bibr" target="#b45">45]</ref>. This training methodology creates episodes that simulate the train and test scenarios of few-shot learning. Meta-learning approaches make use of this episodic framework. They learn a base network capable of producing parameters for a task-specific network after observing the support set. The task-specific network is then evaluated on the query set and its gradient is used to update the base network. By doing so, the base network learns to use the support set to generate parameters that are suitable for good generalization. This was first introduced in <ref type="bibr" target="#b37">[37]</ref>. Perhaps, the most popular meta-learning approach is MAML <ref type="bibr" target="#b10">[10]</ref> and other algorithms that derivate from it <ref type="bibr" target="#b33">[33,</ref><ref type="bibr" target="#b36">36]</ref>, which learn a set of initial weights that are adapted to a specific task in a small amount of gradient steps. However, this choice of architecture, while general, offers limited performance for few-shot image classification. This lead to variants of meta-learning methods more adapted to image classification <ref type="bibr" target="#b34">[34,</ref><ref type="bibr" target="#b42">42,</ref><ref type="bibr" target="#b13">13,</ref><ref type="bibr" target="#b35">35]</ref>.</p><p>Most metric learning approaches are trained using episodes <ref type="bibr" target="#b53">[53,</ref><ref type="bibr" target="#b45">45,</ref><ref type="bibr" target="#b30">30]</ref>, they can also be seen as meta-learning approaches. Concretely, metric learning approaches are characterized by a classifier learned over a feature space. They focus on learning high-quality and transferable features with a neural network common to all tasks. EPNet leverages the work of Liu et al. <ref type="bibr" target="#b30">[30]</ref> for learning to propagate labels, and thus falls into this category. Graph-based approaches can also be framed into this category <ref type="bibr" target="#b44">[44,</ref><ref type="bibr" target="#b18">18,</ref><ref type="bibr" target="#b57">57,</ref><ref type="bibr" target="#b23">23]</ref>. Gidaris et al. <ref type="bibr" target="#b14">[14]</ref> proposed to generate classification weights with a graph neural network (GNN) and apply a denoising autoencoder to regularize their representation. EP does also perform a regularization on a graph representation. Set-to-set functions have also been used for embedding adaptation <ref type="bibr" target="#b58">[58]</ref>. However, different from GNNs and set-to-set, our graph is unsupervised and non-parametric, its purpose is manifold smoothing, and we show it improves semi-supervised learning approaches.</p><p>While metric learning offers a convenient approach to learn transferable features, it has been shown that neural networks trained with conventional supervised learning already learn transferable features <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b6">6,</ref><ref type="bibr" target="#b32">32]</ref>. Hence, to learn a classifier on a new task, it suffices to fine-tune the feature extractor to that task. Also, this approach has shown to learn more discriminative features compared to the episodic scenario. To take advantage of this transfer learning procedure, we use it in our pre-training phase. Thus, EPNet combines a metric-based classifier with the pre-training of transferable features to achieve a more general representation.</p><p>Regularization for Generalization. Regularization is a principled approach for improving the generalization performance of deep networks. Commonly used techniques such as dropout <ref type="bibr" target="#b46">[46]</ref> and batch normalization <ref type="bibr" target="#b19">[19]</ref> attempt to achieve robustness towards input variations. Others are based on regularizing weights <ref type="bibr" target="#b40">[40,</ref><ref type="bibr" target="#b43">43]</ref>. Another line of work that is based on manifold regularization <ref type="bibr" target="#b62">[62,</ref><ref type="bibr" target="#b52">52,</ref><ref type="bibr" target="#b50">50,</ref><ref type="bibr" target="#b2">3]</ref>. These works propose methods that aim to smooth the decision boundaries and flatten the class representations, which are important factors for generalization <ref type="bibr" target="#b27">[27,</ref><ref type="bibr" target="#b0">1]</ref>. Similarly, we attempt to smooth the manifold by incorporating an embedding propagation operation on the extracted features during training. A concurrent work <ref type="bibr" target="#b32">[32]</ref> and our work were the first to apply manifold regularization on few-shot classification. However, the method presented in <ref type="bibr" target="#b32">[32]</ref> differs from ours in four ways. First, they perform smoothing in an additional training phase. Second, they train linear classifiers at inference time. Third, they use an exemplar self-supervised loss in their training procedure. Fourth, they do not show the efficacy of their method for semi-supervised learning. In the few-shot classification benchmarks, we achieve better classification accuracy on the Imagenet datasets and CUB dataset for the 1-shot, 5-shot, and 10-shot case.  There are different lines of research showing that perturbing image representations results in better generalization <ref type="bibr" target="#b46">[46,</ref><ref type="bibr" target="#b19">19]</ref>. The most closely related to our work are based on feature interpolation. For instance, Zhao and Cho <ref type="bibr" target="#b7">[7]</ref> proposed to make predictions based on the interpolation of nearest neighbors to improve adversarial robustness. In Manifold Mixup this idea was expanded to smooth the representations of the neural architecture and achieve better generalization <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b27">27]</ref>. Manifold Mixup has been applied to FSC architectures as a fine-tuning step to improve their performance <ref type="bibr" target="#b32">[32]</ref>. Differently, we propose a novel procedure to smooth the manifold end-to-end. The proposed method is applied only at the output layer and achieves higher classification accuracy than previous approaches. Moreover, and also different from <ref type="bibr" target="#b32">[32]</ref>, we leverage the properties of smoother manifolds for semi-supervised learning <ref type="bibr" target="#b3">[4]</ref>, further widening the improvement margin.</p><p>Transductive learning (TL). The idea of transduction is to perform predictions only on the test points. In contrast, the goal of inductive learning is to output a prediction function defined on an entire space <ref type="bibr" target="#b51">[51]</ref>. Given a small set of labeled examples, transductive learning has been shown to outperform inductive learning <ref type="bibr" target="#b30">[30,</ref><ref type="bibr" target="#b20">20,</ref><ref type="bibr" target="#b29">29]</ref>. This makes TL a desirable method for few-shot classification. Liu et al. <ref type="bibr" target="#b30">[30]</ref> presented one of the few work using TL for FSC. Similar to this work, we use label propagation <ref type="bibr" target="#b63">[63]</ref> to predict the labels of the query set. However, they do not incorporate a manifold smoothing method such as the embedding propagation method investigated in this work.</p><p>Semi-Supervised learning. While the literature on semi-supervised learning is vast, few works leverage the use of unlabeled data in few-shot image classification. In <ref type="bibr" target="#b38">[38]</ref>, they develop a soft version of k-means to meta-learn how to use unlabeled data. Liu et al. <ref type="bibr" target="#b30">[30,</ref><ref type="bibr" target="#b29">29]</ref> used label propagation to leverage a set of unlabeled data. Their approach works with both semi-supervised and transductive learning and improves results over soft k-means. In this work we use a similar label propagation approach and show that the semi-supervised results can be further improved by using pseudo-labels (labels obtained from the current model).</p><p>Recently, Sun et al. <ref type="bibr" target="#b28">[28]</ref> used a meta-learning approach to cherry-pick examples from the unlabeled set and label them with the current model to increase the label set. In contrast, our method does not require cherry-picking which needs an extra learning step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Proposed Method</head><p>We propose an embedding propagation network (EPNet) that has the following pipeline. Given an input image, EPNet first extracts image features using a feature extractor. Then, we apply a novel embedding propagation method (described in Sec. 2.1) to map the features to a set of interpolated features that we refer to as embeddings. These embeddings are then used by a classifier to label the images (Sec. 2.3). The goal of embedding propagation is to increase the smoothness of the embedding manifold, which was shown to improve generalization <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b27">27]</ref> and the effectiveness of semi-supervised learning methods <ref type="bibr" target="#b3">[4]</ref> (Sec. 2.5). In the following sections, we explain EPNet in more detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Embedding propagation</head><p>Embedding propagation takes a set of feature vectors z i ∈ R m , obtained from applying a feature extractor (CNN) to the samples of an episode. Then, it outputs a set of embeddings z i ∈ R m through the following two steps. First, for each pair of features (i, j), the model computes the distance as</p><formula xml:id="formula_0">d 2 ij = z i − z j 2 2</formula><p>and the adjacency as A ij = exp −d 2 ij /σ 2 , where σ 2 is a scaling factor and A ii = 0, ∀i, as done in TPN <ref type="bibr" target="#b30">[30]</ref>. We chose σ 2 = Var d 2 ij which we found to stabilize training.</p><p>Next we compute the Laplacian of the adjacency matrix,</p><formula xml:id="formula_1">L = D − 1 2 AD − 1 2 , D ii = j A ij .<label>(1)</label></formula><p>Finally, using the label propagation formula described in <ref type="bibr" target="#b63">[63]</ref>, we obtain the propagator matrix P as,</p><formula xml:id="formula_2">P = (I − αL) −1 ,<label>(2)</label></formula><p>where α ∈ R is a scaling factor, and I is the identity matrix. Then, the embeddings are obtained as follows,</p><formula xml:id="formula_3">z i = j P ij z j .<label>(3)</label></formula><p>Since the z i are now a weighted sum of their neighbors, embedding propagation has the effect of removing undesired noise from the feature vectors. Note that this operation is simple to implement and compatible with a wide range of feature extractors and classifiers. Further, note that the computational complexity of Eq. 2 is negligible for few-shot episodes <ref type="bibr" target="#b30">[30]</ref> since the size of the episode is small.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Few-shot classification setup</head><p>Following the common few-shot setups <ref type="bibr" target="#b53">[53,</ref><ref type="bibr" target="#b38">38]</ref>, we are given three datasets: a base dataset (D b ), a novel dataset (D n ), and a validation dataset (D v ). The base dataset is composed of a large amount of labeled images</p><formula xml:id="formula_4">D b = {(x i , y i )} N base i=1 , where each image x i is labeled with class y i ∈ Y base . The novel dataset D n = {(x j , y j )} N novel j=1</formula><p>, where x j comes from previously unseen classes y j ∈ Y novel , such that Y base ∩ Y novel = ∅, is used to evaluate the transfer learning capabilities of the model. The validation dataset D v contains classes not present in D b and D n and is used to conduct hyperparameter search.</p><p>Furthermore, we have access to episodes. Each episode consists of n classes sampled uniformly without replacement from the set of all classes, a support set S (k examples per class) and a query set Q (q examples per class). This is referred to as n-way k-shot learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Inference Phase</head><p>Given an episode, we perform inference by extracting features of an input image, applying embedding propagation on those features, then applying label propagation. More formally, this is performed as follows. Let Z ∈ R (k+q)×m be the matrix of propagated embeddings obtained by jointly applying Eq. 1-3 to the support and query sets. Let P Z be the corresponding propagator matrix. Further, let Y S ∈ R k×n be a one-hot encoding of the labels in the support set and 0 ∈ R q×n a matrix of zeros. We compute the logits for the query set (Ŷ Q ) by performing label propagation as described in <ref type="bibr" target="#b63">[63]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Training procedure</head><p>EPNet is trained in two phases as illustrated in <ref type="figure" target="#fig_2">Fig. 2</ref>. First, the model is trained on D b using the common pretraining procedure for few-shot classification <ref type="bibr" target="#b42">[42]</ref> in order to learn a general feature representation. Second, the model is finetuned using episodes in order to learn to generalize to novel classes. Episodes are drawn from the same dataset D b . In both phases, EPNet uses the same feature extractor f θ (x) parametrized by θ to obtain the features z extracted for a given input image x. However, each phase relies on a different objective.</p><p>Pre-training phase. As shown in <ref type="figure" target="#fig_2">Fig. 2a</ref>, we train f θ using two linear classifiers, which are linear layers with softmax activations parametrized by W l and W r , respectively. The first classifier is trained to predict the class labels of examples in D b . It is optimized by minimizing the cross-entropy loss,</p><formula xml:id="formula_5">L c (x i , y i ; W l , θ) = − ln p(y i | z i , W l ),<label>(4)</label></formula><p>where y i ∈ Y b and the probabilities are obtained by applying softmax to the logits provided by the neural network. For fair comparison with recent literature, we also add a self-supervision loss <ref type="bibr" target="#b32">[32,</ref><ref type="bibr" target="#b12">12]</ref> to obtain more robust feature representations. Hence, we use the second classifier to predict image rotations and use the following loss,</p><formula xml:id="formula_6">L r (x i , r j ; W r , θ) = − ln p(r j | z i , W r ),<label>(5)</label></formula><p>where r j ∈ {0 • , 90 • , 180 • , 270 • }, and p(r j | z i , W r ) is the probability of the input being rotated by r j as predicted by a softmax classifier with weights W r . Overall, we use stochastic gradient descent (SGD) with batches of size 128 and 4 rotations per image to optimize the following loss,</p><formula xml:id="formula_7">argmin θ,W l ,Wr 128 i=1 4 j=1 L c (x i , y i ; W l , θ) + L r (x i , r j ; W r , θ).<label>(6)</label></formula><p>Episodic Learning phase. As shown in <ref type="figure" target="#fig_2">Fig. 2b</ref>, after the pre-training phase, we use episodic training to learn to recognize new classes. In this phase, we also optimize EPNet using two classifiers. The first classifier is based on label propagation. It computes class probabilities by applying a softmax to the query set logitsŶ Q defined in Sec. 2.3, i.e.,</p><formula xml:id="formula_8">L p (x i , y i ; θ) = − ln p(y i | z i , Z, Y S ).<label>(7)</label></formula><p>The second classifier is identical to the W l -based classifier used in pretraining. It is included to preserve a discriminative feature representation. Hence, we minimize the following loss:</p><formula xml:id="formula_9">argmin θ,W l   1 |Q| (xi,yi)∈Q L p (x i , y i ; θ) + 1 |S∪Q| (xi,yi)∈S∪Q 1 2 L c (x i , y i ; W l , θ)   .<label>(8)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Semi-supervised learning</head><p>In the semi-supervised learning scenario, we also have access to an unlabeled set of images U . We use the unlabeled set as follows. First, we use the inference procedure described in Sec. 2.3 to predict the labelsĉ U for the unlabeled set as pseudo-labels. Then, we augment the support set with U using their pseudolabels as the true labels. Finally, we use the inference procedure in Sec. 2.3 on the new support set to predict the labels for the query set. We also consider the semi-supervised scenario proposed by Garcia and Bruna <ref type="bibr" target="#b11">[11]</ref>. In this scenario the model is trained to perform 5-shot 5-way classification but only 20% to 60% of the support set is labeled.</p><p>As shown by Lee et al. <ref type="bibr" target="#b25">[25]</ref>, this procedure is equivalent to entropy regularization, an effective method for semi-supervised learning. Entropy regularization is particularly effective in cases where the decision boundary lies in low-density regions. With embedding propagation we achieve a similar decision boundary by smoothing the manifold.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>In this section, we present the results on three standard FSC datasets, mini Imagenet <ref type="bibr" target="#b53">[53]</ref>, tiered Imagenet <ref type="bibr" target="#b38">[38]</ref>, CUB <ref type="bibr" target="#b55">[55]</ref>, and Imagenet-FS <ref type="bibr" target="#b15">[15]</ref>. We also provide ablation experiments to illustrate the properties of embedding propagation. As common procedure, we averaged accuracies on D n over 1000 episodes <ref type="bibr" target="#b53">[53]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Datasets</head><p>mini Imagenet <ref type="bibr" target="#b37">[37]</ref>. A subset of the Imagenet dataset <ref type="bibr" target="#b41">[41]</ref> consisting of 100 classes with 600 images per class. Classes are divided in three disjoint sets of 64 base classes, 16 for validation and 20 novel classes. tiered Imagenet <ref type="bibr" target="#b38">[38]</ref>. A more challenging subset of the Imagenet dataset <ref type="bibr" target="#b41">[41]</ref> where class subsets are chosen from supersets of the wordnet hierarchy. The top hierarchy has 34 super-classes, which are divided into 20 base (351 classes), 6 validation (97 classes) and 8 novel (160 classes) categories. Imagenet-FS <ref type="bibr" target="#b15">[15]</ref>. A large-scale version of ImageNet. It is split into 389 base classes and 611 novel classes. The training set consists of 193 of the base classes. Validation consists of 193 of the base classes plus 300 novel classes. The test set consists of the remaining 196 base classes and the remaining 311 novel classes. CUB <ref type="bibr" target="#b6">[6,</ref><ref type="bibr" target="#b16">16]</ref>. A fine-grained dataset based on CUB200 <ref type="bibr" target="#b55">[55]</ref> composed of 200 classes and 11,788 images split in 100 base, 50 validation, and 50 novel classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Implementation Details</head><p>For fair comparison with previous work, we used three common feature extractors: (i) a 4-layer convnet <ref type="bibr" target="#b53">[53,</ref><ref type="bibr" target="#b45">45]</ref> with 64 channels per layer, (ii) a 12-layer resnet <ref type="bibr" target="#b34">[34]</ref>, and (iii) a wide residual network (WRN-28-10) <ref type="bibr" target="#b42">[42,</ref><ref type="bibr" target="#b61">61]</ref>. For mini, tiered Imagenet, and CUB, images are resized to 84 × 84. For Imagenet-FS, as described in <ref type="bibr" target="#b12">[12,</ref><ref type="bibr" target="#b13">13]</ref> we use a resnet-18 and images are resized to 224 × 224. In the training stage, the models are optimized using SGD with learning rate of 0.1 for 100 epochs. The learning rate is reduced by a factor of 10 every time the model reached a plateau, in which case the validation loss had not improved for 10 epochs. α is cross-validated on the 4-layer convnet.</p><p>In the episodic fine-tuning stage we randomly sample 5 classes per episode, where in each class k instances are selected for the support set and 15 for the query set. Similar to the training stage, the model is optimized with SGD with learning rate 0.001 reduced by a factor of 10 on plateau. For training the wide residual networks (WRN), we apply the standard data augmentation methods mentioned by Szegedy et al. <ref type="bibr" target="#b49">[49,</ref><ref type="bibr" target="#b42">42]</ref>. For the other architectures, we do not apply data augmentation. For Imagenet-FS, we add EP right after the denoising autoencoder of wDAE-GNN <ref type="bibr" target="#b14">[14]</ref>. We use the original code provided by the authors. 3 . Different from the other datasets, in this one evaluation is performed on the 311 test classes at the same time (311-way), with the number of supports k ∈ {1, 2, 5, 10, 20}.</p><p>We evaluate 3 variations of our method: (i) EPNet as described in Sec. 2; (ii) --Net, which is identical to EPNet but without EP; and (iii) EPNet SSL (semi-supervised learning) as described in Sec. 2.5.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Experimental Results</head><p>In this section we compare EPNet with previous methods in the standard fewshot classification scenario, and semi-supervised learning scenarios.</p><p>Main Results. We first report the results for the methods that do not use an unlabeled set. As seen in <ref type="table" target="#tab_0">Tables 1 and 2</ref>, EPNet obtains state-of-the-art accuracies on mini Imagenet, tiered Imagenet, and CUB-200-2011 for the 1-shot and 5-shot benchmarks even when compared with models that use more parameters or higher resolution images. It can also be observed the effectiveness of EP in isolation when comparing EPNet with an identical model without EP (--Net). Higher-way and 10-shot results can be found in the supplementary material. Note that EGNN <ref type="bibr" target="#b21">[21]</ref> uses ×45 parameters. On the large-scale Imagenet-FS, EP improves all benchmarks by approximately 2% accuracy, see <ref type="table" target="#tab_2">Table 3</ref>. These results demonstrate the scalability of our method and the orthogonality with other embedding transformations such as denoising autoencoders <ref type="bibr" target="#b14">[14]</ref>.</p><p>Semi-supervised learning. We evaluate EPNet on the SSL setting where 100 additional unlabeled samples are available <ref type="bibr" target="#b38">[38,</ref><ref type="bibr" target="#b30">30]</ref> (EPNet SSL ). We observe in <ref type="table" target="#tab_3">Table 4</ref> that including unlabeled samples increases the accuracy of EPNet for all settings, surpassing the state of the art by a wide margin of up to 16% accuracy points for the 1-shot WRN-28-10. Similar to previous experiments, removing EP to EPNet (--Net) is detrimental for the model, supporting our hypotheses. Following the same setting described in <ref type="bibr" target="#b11">[11,</ref><ref type="bibr" target="#b21">21]</ref>, we trained our model in the 5-shot 5-way scenario where the support samples are partially labeled. In <ref type="table" target="#tab_4">Table  5</ref>, we report the test accuracy with conv-4 when labeling 20%, 40%, 60% and 100% of the support set. EPNet obtains up to 2.7% improvement over previous state-of-the-art when 40% of the support are labeled. Moreover, EPNet also outperforms EGNN <ref type="bibr" target="#b21">[21]</ref> in the 40% and 60% scenarios, although EPNet has 45× less parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Ablation Studies</head><p>In this section we investigate the different hyperparameters of our method and the properties derived from embedding propagation. Additional ablations are provided in the supplementary material.</p><p>Algorithm ablation. In <ref type="table" target="#tab_5">Table 6</ref>, we investigate the impact of the rotation loss (ROT), embedding fine-tuning (EFT), label propagation (LP), and embedding propagation (EP) on the 1-shot mini Imagenet accuracy. When label propagation is deactivated, we substitute it with a prototypical classifier. Interestingly, it can be seen that the improvement is larger when using LP in combination  with EP <ref type="table" target="#tab_5">(Table 6</ref>; columns 2-4, and <ref type="bibr" target="#b10">[10]</ref><ref type="bibr" target="#b11">[11]</ref><ref type="bibr" target="#b12">[12]</ref>. This finding is in accordance with the hypothesis that EP performs manifold smoothing, and this is beneficial for transductive and SSL algorithms. We included a rotation loss for fair comparison with other SotA <ref type="bibr" target="#b12">[12,</ref><ref type="bibr" target="#b32">32]</ref>, however, we see that the main improvement is due to the combination of EP with LP. We also find that episodic fine-tuning successfully adapts our model to the episodic scenario ( <ref type="table" target="#tab_5">Table 6</ref>; line 2).</p><p>Embedding propagation on manifold smoothness. We explore whether embedding propagation helps the classifier to attain smoother decision boundaries. We use EPNet to obtain image embeddings and select a set of random pairs z i , z j that belong to different classes y i , y j . We then interpolate between each pair as z = α·z i +(1−α)z j where α ∈ [0..1], and plot this value against p(y i | z) (Sec. 7) in <ref type="figure" target="#fig_3">Fig. 3</ref>. We also plot p(y i |ẑ) where embeddings were obtained using EPNet without embedding propagation (--Net). We observe that EPNet has significantly smoother probability transitions than --Net as the embedding z changes from z i to z j . In contrast, --Net yields sudden probability transitions. This suggests that embedding propagation encourages smoother decision boundaries.</p><p>In <ref type="figure" target="#fig_5">Figure 4</ref>, we show the effect of embedding propagation on a toy dataset. The dataset consists of embeddings that are arranged in two disjoint moons. The embeddings in the top moon belong to first class, and the other to the second class. <ref type="figure" target="#fig_5">Figure 4a</ref>) illustrates the effect of batch sampling during the pre-training phase. Gray points correspond to the extracted embeddings when no embedding  propagation was applied. Each unique color shows multiple projections of the same gray point. Each projection is performed using a different batch of the data. This suggests that the projections of the same embedding fill a wide space in the manifold. As a result, the density and smoothness at the inter-class boundary increases. <ref type="figure" target="#fig_5">Figure 4b)</ref> shows the result of applying embedding propagation on all the gray points in <ref type="figure" target="#fig_5">Figure 4a</ref>). The blue and red colors correspond to the two-moon classes. We observe that the propagated manifold is denser and more compact than the original one, possibly reducing the noise of the representations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>We have presented EPNet, an approach to address the problem of distribution shift few-shot learning. EPNet introduces a simple embedding propagation step to regularize the feature representations. Empirically, we have shown that embedding propagation smooths decision boundaries, which is an important factor for generalization. By leveraging the properties of smooth manifolds, we have shown significant improvements on the transductive, and semi-supervised learning setup compared to methods that do not use embedding propagation. As a result, EPNet achieves state-of-the-art results on mini Imagenet, tiered Imagenet, and CUB for the standard and semi-supervised scenarios. Further, we have shown that EP scales to the larger Imagenet-FS dataset, improving by more than 2% the accuracy of the state-of-the-art wDAE-GNN <ref type="bibr" target="#b14">[14]</ref> in all setups. We have compared EPNet with a non-smooth version of the same model (--Net), showing that smoothing alone accounts for 4.8% accuracy improvement on 1-shot mini Imagenet with Wide Residual Networks.</p><p>In the following sections, we provide results in the 10-shot scenario as well as more challenging settings, such as 10-way, 15-way, and 20-way classification. We also illustrate the effect of ablating different parts of the propagator matrix. Finally, we report the CO 2 emissions to produce this research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>10-shot test accuracy.</head><p>We report the results of EPNet and EPNet SSL in <ref type="table" target="#tab_6">Table 7</ref>. Our methods improve the accuracy over TADAM <ref type="bibr" target="#b34">[34]</ref> and Discriminative <ref type="bibr" target="#b1">[2]</ref> by 5% accuracy. Since not many methods have been evaluated on this benchmark, it is challenging to illustrate the impact of embedding propagation. Further, we see that EPNet SSL does not improve much over EPNet, suggesting that embedding propagation has larger impact with fewer labeled data. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Higher-way results</head><p>For higher way setups, we compare against previous state-of-the-art methods on mini Imagenet <ref type="table">(Table 8</ref>). For a fair comparison, we use a WRN-28-10 [61] as our feature extractor. Our results show that EPNet attains higher test accuracies than previous state-of-the-art in all settings. For instance, in the 1-shot 20-way scenario, EPNet improves results from 36.5% to 38.6% accuracy. This suggests that embedding propagation generalizes effectively to higher number of classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Additional ablation experiments</head><p>While in <ref type="table" target="#tab_5">Table 6</ref> we ablate all the components of the proposed model, in <ref type="table" target="#tab_8">Table  9</ref> we focus only on EP and whether it leverages information from neighboring embeddings (off-diagonal) or it just rescales them (diagonal). We show that <ref type="table">Table 8</ref>: mini Imagenet 1-shot and 5-shot test accuracies for the 10-way, 15-way and 20-way scenarios. We report the accuracy with 95% confidence intervals over 600 episodes. <ref type="bibr" target="#b10">10</ref>  neighbor information is important for the performance of EP. We train three versions of EPNet, (i) one with the full propagator matrix, (ii) one with only the off-diagonal of the matrix, and (iii) one with the diagonal matrix only. Hence, the second version only relies on information from neighboring embeddings to make predictions. The third version is equivalent to multiplying the original embeddings by a scalar. As seen in <ref type="table" target="#tab_8">Table 9</ref>, the best performance is obtained with the first version, confirming that information from neighboring nodes is used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CO2 Emission Related to Experiments</head><p>Experiments were conducted using a private infrastructure (located in Quebec, Canada) with a carbon emission factor of 0.02 kg/kWh. A cumulative of 24480 hours of computation was performed on hardware of type Tesla V100 (with a TDP of 250 W). Total emissions are estimated to be 146.88 kgCO 2 eq, and 1000 kgCO 2 eq (685%) were offsetted through Gold Standard. Estimations were obtained using the MachineLearning Impact calculator <ref type="bibr" target="#b24">[24]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 :</head><label>1</label><figDesc>Illustration of the embedding propagation (EP) method. (a) Original decision boundaries for three classes. The color of a region represents the predicted class, and the color of a node represents the node's actual class. (b) Decision boundaries after applying EP, which are smoother than in (a). (c) Predictions after propagating the labels across the graph, leveraging unlabeled points (light gray) to classify a query example (shown in dark gray). Best viewed in color.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Episodic fine-tuning and evaluation</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 :</head><label>2</label><figDesc>Overview of the EPNet training procedure. EPNet is trained in two phases: a pretraining phase and an episodic fine-tuning phase. (a) First, the model is trained to learn general feature representations using a standard classification loss L C and an auxiliar rotation loss L R . (b) Then, the model is fine-tuned using episodic learning to learn to generalize to novel classes by minimizing the standard classification loss L C and a label propagation loss L P . In both phases the features are encoded using a feature extractor followed by our proposed embedding propagation method (Sec. 2).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 :</head><label>3</label><figDesc>Interpolation of embedding pairs of different classes vs probability of belonging to the first of these two classes. The top row shows the class probability for resnet-12 embeddings extracted from EPNet, and the second(--Net) from the same network trained without embedding propagation. The scalar α controls the weight of the first embedding in the linear interpolation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 4 :</head><label>4</label><figDesc>Visualization of embedding propagation on the two moons dataset. The embeddings are shown on the same scale.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Comparison of test accuracy against state-of-the art methods for 1shot and 5-shot classification using mini Imagenet and tiered Imagenet. The second column shows the number of parameters of each model in thousands (K). Robust − 20 uses an 18-layer residual network.--Net is identical to EPNet but without EP. Gray colored results are obtained using 224 × 224 pixels instead of the standard 84 × 84 pixel images. ±0.92 51.67 ±1.81 70.30 ±0.08 ProtoNet [45] 112K 49.42 ±0.78 68.20 ±0.66 53.31 ±0.89 72.69 ±0.74 ReNet [48] 223K 50.44 ±0.82 65.32 ±0.70 54.48 ±0.92 71.32 ±0.78 ±0.83 72.57 ±0.66 57.60 ±0.93 73.30 ±0.74 EPNet (ours) 112K 59.32 ±0.88 72.95 ±0.64 59.97 ±0.95 73.91 ±0.75 ±0.45 74.28 ±0.20 58.47 ±0.64 78.41 ±0.41 TADAM [34] 7989K 58.50 ±0.30 76.70 ±0.30 --MetaOpt-SVM [26] 12415K 62.64 ±0.61 78.60 ±0.46 65.99 ±0.72 81.56 ±0.53 Robust-20++ [8] 11174K 58.11 ±0.64 75.24 ±0.49 70.44 ±0.32 85.43 ±0.21 ±0.55 80.64 ±0.35 73.21 ±0.58 84.93 ±0.38 --Net (ours) 7989K 65.66 ±0.85 81.28 ±0.62 72.60 ±0.91 85.69 ±0.65 EPNet (ours) 7989K 66.50 ±0.89 81.06 ±0.60 76.53 ±0.87 87.32 ±0.64 ±0.12 66.33 ±0.05 81.44 ±0.09 ±0.15 78.85 ±0.10 68.18 ±0.16 83.09 ±0.12 CC+rot [12] 37582K 62.93 ±0.45 79.87 ±0.33 70.53 ±0.51 84.98 ±0.36 Manifold mixup [32] 37582K 64.93 ±0.48 83.18 ±0.72 ----Net (ours) 37582K 65.98 ±0.85 82.22 ±0.66 74.04 ±0.93 86.03 ±0.63 EPNet (ours) 37582K 70.74 ±0.85 84.34 ±0.53 78.50 ±0.91 88.36 ±0.57</figDesc><table><row><cell></cell><cell></cell><cell cols="2">mini Imagenet</cell><cell cols="2">tiered Imagenet</cell></row><row><cell></cell><cell>Params</cell><cell>1-shot</cell><cell>5-shot</cell><cell>1-shot</cell><cell>5-shot</cell></row><row><cell></cell><cell></cell><cell cols="2">CONV-4</cell><cell></cell><cell></cell></row><row><cell>Matching [53]</cell><cell cols="2">112K 43.56 ±0.84</cell><cell>55.31 ±0.73</cell><cell>-</cell><cell>-</cell></row><row><cell cols="4">MAML [30] 63.11 GNN [11] 112K 48.70 ±1.84 1619K 50.33 ±0.36 66.41 ±0.63</cell><cell>-</cell><cell>-</cell></row><row><cell>TPN [30]</cell><cell cols="2">171K 53.75 ±0.86</cell><cell cols="3">69.43 ±0.67 57.53 ±0.96 72.85 ±0.74</cell></row><row><cell>CC+rot [12]</cell><cell cols="2">112K 54.83 ±0.43</cell><cell>71.86 ±0.33</cell><cell>-</cell><cell>-</cell></row><row><cell>EGNN [21]</cell><cell>5068K</cell><cell>-</cell><cell>76.37</cell><cell>-</cell><cell>80.15</cell></row><row><cell>--Net (ours)</cell><cell cols="3">112K 57.18 RESNET-12</cell><cell></cell><cell></cell></row><row><cell cols="3">ProtoNets++ [56] 7989K 56.52 TPN [30] 8284K 59.46</cell><cell>75.65</cell><cell>-</cell><cell>-</cell></row><row><cell>MTL [47]</cell><cell cols="2">8286K 61.20 ±1.80</cell><cell>75.50 ±0.80</cell><cell>-</cell><cell>-</cell></row><row><cell>CAN [17]</cell><cell cols="3">8026K 67.19 WRN-28-10</cell><cell></cell><cell></cell></row><row><cell cols="4">LEO [42] 77.59 Robust-20++ [8] 37582K 61.76 ±0.08 37582K 62.80 ±0.62 80.85 ±0.43</cell><cell>-</cell><cell>-</cell></row><row><cell>wDAE-GNN [14]</cell><cell cols="2">48855K 62.96</cell><cell></cell><cell></cell><cell></cell></row></table><note>**</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Comparison with the state of the art on CUB-200-2011. * Robust−20++ uses an 18-layer residual network, and Accuracies obtained with 224×224 images appear in gray. ±0.69 83.21 ±0.44 EPNet (ours) RESNET-12 82.85 ±0.81 91.32 ±0.41</figDesc><table><row><cell></cell><cell>backbone</cell><cell>1-shot</cell><cell>5-shot</cell></row><row><cell cols="4">*  Robust-20++ [8] RESNET-18 68.68 Manifold mixup [32] WRN-28-10 80.68 ±0.81 90.85 ±0.44</cell></row><row><cell>EPNet (ours)</cell><cell cols="3">WRN-28-10 87.75 ±0.70 94.03 ±0.33</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Top-5 test accuracy on Imagenet-FS. ±0.24 57.80 ±0.16 69.67 ±0.09 74.64 ±0.06 77.31 ±0.05 57.88 ±0.15 64.76 ±0.10 72.29 ±0.07 75.63 ±0.04 77.40 ±0.03 wDAE-GNN [14] 48.00 ±0.21 59.70 ±0.15 70.30 ±0.08 75.00 ±0.06 77.80 ±0.05 59.10 ±0.13 66.30 ±0.10 73.20 ±0.05 76.10 ±0.04 77.50 ±0.03 wDAE-GNN + EP (ours) 50.07 ±0.27 62.16 ±0.16 72.89 ±0.11 77.25 ±0.07 79.48 ±0.05 60.87 ±0.16 68.53 ±0.10 75.56 ±0.07 78.28 ±0.04 78.89 ±0.03</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>Novel Classes</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>All classes</cell><cell></cell><cell></cell></row><row><cell>Approach</cell><cell>K=1</cell><cell>2</cell><cell>5</cell><cell>10</cell><cell>20</cell><cell>K=1</cell><cell>2</cell><cell>5</cell><cell>10</cell><cell>20</cell></row><row><cell>Batch SGM [15]</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>49.3</cell><cell>60.5</cell><cell>71.4</cell><cell>75.8</cell><cell>78.5</cell></row><row><cell>PMN [54]</cell><cell>45.8</cell><cell>57.8</cell><cell>69.0</cell><cell>74.3</cell><cell>77.4</cell><cell>57.6</cell><cell>64.7</cell><cell>71.9</cell><cell>75.2</cell><cell>77.5</cell></row><row><cell>LwoF [13]</cell><cell>46.2</cell><cell>57.5</cell><cell>69.2</cell><cell>74.8</cell><cell>78.1</cell><cell>58.2</cell><cell>65.2</cell><cell>72.7</cell><cell>76.5</cell><cell>78.7</cell></row><row><cell>CC+ Rot [12]</cell><cell>46.43</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>SSL results with 100 unlabeled samples. --Net is identical to EPNet but without embedding propagation. *Re-implementation [60] ±0.97 75.42 ±0.64 66.63 ±1.04 75.70 ±0.74 ±1.01 84.07 ±0.60 81.79 ±0.97 88.45 ±0.61 10 79.22 ±0.92 88.05 ±0.51 83.69 ±0.99 89.34 ±0.59</figDesc><table><row><cell></cell><cell></cell><cell cols="2">mini Imagenet</cell><cell cols="2">tiered Imagenet</cell></row><row><cell></cell><cell>Backbone</cell><cell>1-shot</cell><cell>5-shot</cell><cell>1-shot</cell><cell>5-shot</cell></row><row><cell>TPNSSL [30]</cell><cell>CONV-4</cell><cell>52.78</cell><cell>66.42</cell><cell>55.74</cell><cell>71.01</cell></row><row><cell>k-Meansmasked,soft [38]</cell><cell>CONV-4</cell><cell>50.41 ±0.31</cell><cell>64.39 ±0.24</cell><cell>-</cell><cell>-</cell></row><row><cell>EPNet (ours)</cell><cell>CONV-4</cell><cell>59.32 ±0.88</cell><cell>72.95 ±0.64</cell><cell>59.97 ±0.95</cell><cell>73.91 ±0.75</cell></row><row><cell>--NetSSL (ours)</cell><cell>CONV-4</cell><cell>63.74 ±0.97</cell><cell>75.30 ±0.67</cell><cell>65.01 ±1.04</cell><cell>74.24 ±0.80</cell></row><row><cell cols="3">EPNetSSL (ours) 65.13 LST [28] CONV-4 RESNET-12 70.10 ±1.90</cell><cell>78.70 ±0.80</cell><cell>77.70 ±1.60</cell><cell>85.20 ±0.80</cell></row><row><cell>EPNet (ours)</cell><cell cols="2">RESNET-12 66.50 ±0.89</cell><cell>81.06 ±0.60</cell><cell>76.53 ±0.87</cell><cell>87.32 ±0.64</cell></row><row><cell>--NetSSL (ours)</cell><cell cols="2">RESNET-12 73.42 ±0.94</cell><cell>83.17 ±0.58</cell><cell>80.26 ±0.96</cell><cell>88.06 ±0.59</cell></row><row><cell cols="3">EPNetSSL (ours) RESNET-12 75.36 *k-Meansmasked,soft [38] WRN-28-10 52.78 ±0.27</cell><cell>66.42 ±0.21</cell><cell>-</cell><cell>-</cell></row><row><cell>TransMatch [60]</cell><cell cols="2">WRN-28-10 63.02 ±1.07</cell><cell>81.19 ±0.59</cell><cell>-</cell><cell>-</cell></row><row><cell>EPNet (ours)</cell><cell cols="2">WRN-28-10 70.74 ±0.85</cell><cell>84.34 ±0.53</cell><cell>78.50 ±0.91</cell><cell>88.36 ±0.57</cell></row><row><cell>--NetSSL (ours)</cell><cell cols="2">WRN-28-10 77.70 ±0.96</cell><cell>86.30 ±0.50</cell><cell>82.03 ±1.03</cell><cell>88.20 ±0.61</cell></row><row><cell>EPNetSSL (ours)</cell><cell>WRN-28-</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>SSL results for the 5-shot 5-way scenario with different amounts of unlabeled data. The percentages refer to the amount of supports that are labeled in a set of 5 images per class.NetSSL  (ours) 112K 58.52 ±0.97 64.46 ±0.79 67.81 ±0.74 57.18 ±0.83 EPNetSSL (ours) 112K 60.66 ±0.97 67.08 ±0.80 68.74 ±0.74 59.32 ±0.88</figDesc><table><row><cell></cell><cell>Params</cell><cell>20%</cell><cell>40%</cell><cell>60%</cell><cell>100%</cell></row><row><cell>GNN [11]</cell><cell>112K</cell><cell>52.45</cell><cell>58.76</cell><cell>-</cell><cell>66.41</cell></row><row><cell>EGNN [21]</cell><cell>5068K</cell><cell>63.62</cell><cell>64.32</cell><cell>66.37</cell><cell>76.37</cell></row><row><cell>--</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 :</head><label>6</label><figDesc>Algorithm ablation with conv-4 on 1-shot mini Imagenet. EFT: Episodic Fine-tuning, ROT: Rotation loss, LP: Label Propagation, EP: Embedding Propagation 52.83 53.40 55.75 50.83 53.63 53.38 55.55 54.29 56.38 56.93 58.35 54.92 56.46 57.35 58.85</figDesc><table><row><cell>EXP 1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>6</cell><cell>7</cell><cell>8</cell><cell>9</cell><cell>10</cell><cell>11</cell><cell>12</cell><cell>13</cell><cell>14</cell><cell>15</cell><cell>16</cell></row><row><cell>EFT</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>ROT</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>LP</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>EP</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>ACC 49.57</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 7 :</head><label>7</label><figDesc>10-shot test accuracy on mini Imagenet, tiered Imagenet, and CUB. 85.39 88.39 92.68 EPNetSSL (ours) 87.34 89.24 92.88 WRN-28-10 EPNet (ours) 87.03 89.46 93.99 EPNetSSL (ours) 89.02 89.56 94.11</figDesc><table><row><cell></cell><cell cols="3">mini tiered CUB</cell></row><row><cell cols="2">RESNET-12</cell><cell></cell><cell></cell></row><row><cell cols="2">Discriminative [2] 78.50</cell><cell>-</cell><cell>-</cell></row><row><cell>TADAM [34]</cell><cell>80.80</cell><cell>-</cell><cell>-</cell></row><row><cell>EPNet (ours)</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>± 0.59 72.17 ± 0.44 44.55 ± 0.28 64.44 ± 0.34 38.55 ± 0.19 59.01 ± 0.27</figDesc><table><row><cell></cell><cell></cell><cell>-way</cell><cell cols="2">15-way</cell><cell cols="2">20-way</cell></row><row><cell></cell><cell>1-shot</cell><cell>5-shot</cell><cell>1-shot</cell><cell>5-shot</cell><cell>1-shot</cell><cell>5-shot</cell></row><row><cell>Baseline++ [6]</cell><cell>40.43</cell><cell>56.89</cell><cell>31.96</cell><cell>48.20</cell><cell>26.92</cell><cell>42.80</cell></row><row><cell>LEO [42]</cell><cell>45.26</cell><cell>64.36</cell><cell>36.74</cell><cell>56.26</cell><cell>31.42</cell><cell>50.48</cell></row><row><cell>DCO [26]</cell><cell>44.83</cell><cell>64.49</cell><cell>36.88</cell><cell>57.04</cell><cell>31.50</cell><cell>51.25</cell></row><row><cell>Manifold mixup [32]</cell><cell>50.40</cell><cell>70.93</cell><cell>41.65</cell><cell>63.32</cell><cell>36.50</cell><cell>58.36</cell></row><row><cell>EPNet (ours)</cell><cell>53.70</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 9 :</head><label>9</label><figDesc>Propagator ablation with resnet-12 on 5-shot mini Imagenet. Pretraining accuracy with (1) the full propagator matrix, (2) removing the diagonal of the propagator matrix, (3) removing the off-diagonal of the propagator matrix. As shown, our method leverages information from the neighborhood to attain optimal performance</figDesc><table><row><cell cols="3">VER OFF-DIAG DIAG ACC</cell></row><row><cell>1</cell><cell></cell><cell>75.95 ±0.56</cell></row><row><cell>2</cell><cell></cell><cell>-74.66 ±0.38</cell></row><row><cell>3</cell><cell>-</cell><cell>73.80 ±0.29</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">github.com/gidariss/wDAE_GNN_FewShot</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Generalization performance of support vector machines and other pattern classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bartlett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shawe-Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Kernel methodssupport vector learning</title>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rojas-Carulla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Światkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Turner</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.00326</idno>
		<title level="m">Discriminative k-shot learning using probabilistic models</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Manifold regularization: A geometric framework for learning from labeled and unlabeled examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Belkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Niyogi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Sindhwani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="2399" to="2434" />
			<date type="published" when="2006-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Semi-supervised learning (chapelle, o</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Chapelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Scholkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zien</surname></persName>
		</author>
		<editor>. et al.</editor>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
	<note>book reviews</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Semi-supervised classification by low density separation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Chapelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zien</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In: AISTATS</title>
		<imprint>
			<biblScope unit="page" from="57" to="64" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">A closer look at few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Kira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">C F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Huang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Retrieval-augmented convolutional neural networks against adversarial examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="11563" to="11571" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Diversity with cooperation: Ensemble methods for few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Dvornik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mairal</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3723" to="3731" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">One-shot learning of object categories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="594" to="611" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Model-agnostic meta-learning for fast adaptation of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1126" to="1135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Few-shot learning with graph neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bruna</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Boosting few-shot visual learning with self-supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gidaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bursuc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Pérez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cord</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8059" to="8068" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Dynamic few-shot visual learning without forgetting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gidaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CVPR</publisher>
			<biblScope unit="page" from="4367" to="4375" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Generating classification weights with gnn denoising autoencoders for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gidaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="21" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Low-shot visual recognition by shrinking and hallucinating features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3018" to="3027" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Few-shot learning with metric-agnostic conditional embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Hilliard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Phillips</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Howland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Yankov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Corley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">O</forename><surname>Hodas</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.04376</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Cross attention network for few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bingpeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4005" to="4016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Exploiting unsupervised inputs for accurate fewshot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Gripon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pateux</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="448" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Label propagation for deep semisupervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Iscen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tolias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Avrithis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Chum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5070" to="5079" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Edge-labeling graph neural network for fewshot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Yoo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="11" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS. pp</title>
		<imprint>
			<biblScope unit="page" from="1097" to="1105" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Transductive few-shot learning with meta-learned confidence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Kye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Hwang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.12017</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Quantifying the carbon emissions of machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lacoste</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Luccioni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Dandres</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.09700</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on challenges in representation learning, ICML</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Meta-learning with differentiable convex optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ravichandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Soatto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="10657" to="10665" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Lower bounds on the vc dimension of smoothly parameterized function classes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">L</forename><surname>Bartlett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">C</forename><surname>Williamson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1040" to="1053" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Learning to self-train for semi-supervised few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Chua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS. pp</title>
		<imprint>
			<biblScope unit="page" from="10276" to="10286" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Deep metric transfer for label propagation with limited annotated data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision Workshops</title>
		<meeting>the IEEE International Conference on Computer Vision Workshops</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="0" to="0" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Learning to propagate labels: transductive propagation network for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Fully convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CVPR</publisher>
			<biblScope unit="page" from="3431" to="3440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mangla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kumari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">N</forename><surname>Balasubramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.12087</idno>
		<title level="m">Charting the right manifold: Manifold mixup for few-shot learning</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Nichol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schulman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.02999</idno>
		<title level="m">Reptile: a scalable metalearning algorithm</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Tadam: Task dependent adaptive metric for improved few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Oreshkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">R</forename><surname>López</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lacoste</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS. pp</title>
		<imprint>
			<biblScope unit="page" from="721" to="731" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Few-shot image recognition by predicting parameters from activations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7229" to="7238" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Meta-learning with implicit gradients</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rajeswaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Kakade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS. pp</title>
		<imprint>
			<biblScope unit="page" from="113" to="124" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Optimization as a model for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Meta-learning for semi-supervised few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Triantafillou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Faster r-cnn: Towards real-time object detection with region proposal networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS. pp</title>
		<imprint>
			<biblScope unit="page" from="91" to="99" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rodríguez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Gonfaus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Roca</surname></persName>
		</author>
		<title level="m">Regularizing cnns with locally constrained decorrelations. ICLR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<title level="m">ImageNet Large Scale Visual Recognition Challenge. IJCC</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Meta-learning with latent embedding optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sygnowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Weight normalization: A simple reparameterization to accelerate training of deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS. pp</title>
		<imprint>
			<biblScope unit="page" from="901" to="909" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Few-shot learning with graph neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">G</forename><surname>Satorras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Estrach</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Prototypical networks for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS. pp</title>
		<imprint>
			<biblScope unit="page" from="4077" to="4087" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Dropout: a simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Meta-transfer learning for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Chua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="403" to="412" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Learning to compare: Relation network for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1199" to="1208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Going deeper with convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR. pp</title>
		<imprint>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Between-class learning for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tokozume</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ushiku</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Harada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR. pp</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5486" to="5494" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">An overview of statistical learning theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">N</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on neural networks</title>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lamb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Beckham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Najafi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Mitliagkas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<title level="m">Manifold mixup: Better representations by interpolating hidden states</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6438" to="6447" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Matching networks for one shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS. pp</title>
		<imprint>
			<biblScope unit="page" from="3630" to="3638" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Low-shot learning from imaginary data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hebert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hariharan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7278" to="7286" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Caltech-UCSD Birds 200</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Welinder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<idno>CNS-TR-2010-001</idno>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
		<respStmt>
			<orgName>California Institute of Technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Adaptive cross-modal few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Rostamzadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Oreshkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">O</forename><surname>Pinheiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS. pp</title>
		<imprint>
			<biblScope unit="page" from="4848" to="4858" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Dpgn: Distribution propagation graph network for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="13390" to="13399" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Few-shot learning via embedding adaptation with set-to-set functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">J</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">C</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sha</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="8808" to="8817" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yosinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Clune</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lipson</surname></persName>
		</author>
		<title level="m">How transferable are features in deep neural networks? In: NeurIPS</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3320" to="3328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Transmatch: A transfer-learning scheme for semi-supervised few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="12856" to="12864" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Wide residual networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zagoruyko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
		<idno type="DOI">10.5244/C.30.87</idno>
		<idno>1-87.12</idno>
		<ptr target="https://doi.org/10.5244/C.30.87" />
	</analytic>
	<monogr>
		<title level="j">BMVC. pp</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<date type="published" when="2016-09" />
			<publisher>BMVA Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">mixup: Beyond empirical risk minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Learning with local and global consistency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Bousquet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">N</forename><surname>Lal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS. pp</title>
		<imprint>
			<biblScope unit="page" from="321" to="328" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
