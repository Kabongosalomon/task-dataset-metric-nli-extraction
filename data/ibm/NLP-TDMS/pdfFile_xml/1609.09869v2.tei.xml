<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Structured Inference Networks for Nonlinear State Space Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahul</forename><forename type="middle">G</forename><surname>Krishnan</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Courant Institute of Mathematical Sciences</orgName>
								<orgName type="institution" key="instit2">New York University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uri</forename><surname>Shalit</surname></persName>
							<email>shalit@cs.nyu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Courant Institute of Mathematical Sciences</orgName>
								<orgName type="institution" key="instit2">New York University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Sontag</surname></persName>
							<email>dsontag@cs.nyu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Courant Institute of Mathematical Sciences</orgName>
								<orgName type="institution" key="instit2">New York University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Structured Inference Networks for Nonlinear State Space Models</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T17:55+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Gaussian state space models have been used for decades as generative models of sequential data. They admit an intuitive probabilistic interpretation, have a simple functional form, and enjoy widespread adoption. We introduce a unified algorithm to efficiently learn a broad class of linear and non-linear state space models, including variants where the emission and transition distributions are modeled by deep neural networks. Our learning algorithm simultaneously learns a compiled inference network and the generative model, leveraging a structured variational approximation parameterized by recurrent neural networks to mimic the posterior distribution. We apply the learning algorithm to both synthetic and real-world datasets, demonstrating its scalability and versatility. We find that using the structured approximation to the posterior results in models with significantly higher held-out likelihood. arXiv:1609.09869v2 [stat.ML]  </p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Models of sequence data such as hidden Markov models (HMMs) and recurrent neural networks (RNNs) are widely used in machine translation, speech recognition, and computational biology. Linear and non-linear Gaussian state space models (GSSMs, <ref type="figure" target="#fig_0">Fig. 1</ref>) are used in applications including robotic planning and missile tracking. However, despite huge progress over the last decade, efficient learning of non-linear models from complex high dimensional time-series remains a major challenge. Our paper proposes a unified learning algorithm for a broad class of GSSMs, and we introduce an inference procedure that scales easily to high dimensional data, compiling approximate (and where feasible, exact) inference into the parameters of a neural network.</p><p>In engineering and control, the parametric form of the GSSM model is often known, with typically a few specific parameters that need to be fit to data. The most commonly used approaches for these types of learning and inference problems are often computationally demanding, e.g. dual extended Kalman filter <ref type="bibr" target="#b29">(Wan and Nelson 1996)</ref>, expectation maximization <ref type="bibr" target="#b2">(Briegel and Tresp 1999;</ref><ref type="bibr" target="#b10">Ghahramani and Roweis 1999)</ref> or particle filters <ref type="bibr" target="#b25">(Sch√∂n, Wills, and Ninness 2011)</ref>. Our compiled inference algorithm can easily deal with high-dimensions both in the observed Copyright c 2017, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. and the latent spaces, without compromising the quality of inference and learning.</p><p>When the parametric form of the model is unknown, we propose learning deep Markov models (DMM), a class of generative models where classic linear emission and transition distributions are replaced with complex multi-layer perceptrons (MLPs). These are GSSMs that retain the Markovian structure of HMMs, but leverage the representational power of deep neural networks to model complex high dimensional data. If one augments a DMM model such as the one presented in <ref type="figure" target="#fig_0">Fig. 1</ref> with edges from the observations x t to the latent states of the following time step z t+1 , then the DMM can be seen to be similar to, though more restrictive than, stochastic RNNs <ref type="bibr" target="#b1">(Bayer and Osendorfer 2014)</ref> and variational RNNs <ref type="bibr" target="#b4">(Chung et al. 2015)</ref>.</p><p>Our learning algorithm performs stochastic gradient ascent on a variational lower bound of the likelihood. Instead of introducing variational parameters for each data point, we compile the inference procedure at the same time as learning the generative model. This idea was originally used in the wake-sleep algorithm for unsupervised learning <ref type="bibr" target="#b13">(Hinton et al. 1995)</ref>, and has since led to state-of-the-art results for unsupervised learning of deep generative models <ref type="bibr" target="#b17">(Kingma and Welling 2014;</ref><ref type="bibr" target="#b19">Mnih and Gregor 2014;</ref><ref type="bibr" target="#b24">Rezende, Mohamed, and Wierstra 2014)</ref>.</p><p>Specifically, we introduce a new family of structured inference networks, parameterized by recurrent neural networks, and evaluate their effectiveness in three scenarios: (1) when the generative model is known and fixed, (2) in parameter estimation when the functional form of the model is known and (3) for learning deep Markov models. By looking at the structure of the true posterior, we show both theoretically and empirically that inference for a latent state should be performed using information from its future, as opposed to recent work which performed inference using only information from the past <ref type="bibr" target="#b4">(Chung et al. 2015;</ref><ref type="bibr" target="#b8">Gan et al. 2015;</ref><ref type="bibr" target="#b11">Gregor et al. 2015)</ref>, and that a structured variational approximation outperforms mean-field based approximations. Our approach may easily be adapted to learning more general generative models, for example models with edges from observations to latent states.</p><p>Finally, we learn a DMM on a polyphonic music dataset and on a dataset of electronic health records (a complex high dimensional setting with missing data). We use the model z 1 z 2 . . .</p><p>x 1 x 2 z 1 z 2 . . . learned on health records to ask queries such as "what would have happened to patients had they not received treatment", and show that our model correctly identifies the way certain medications affect a patient's health. Related Work: Learning GSSMs with MLPs for the transition distribution was considered by <ref type="bibr" target="#b21">(Raiko and Tornio 2009)</ref>. They approximate the posterior with non-linear dynamic factor analysis <ref type="bibr" target="#b28">(Valpola and Karhunen 2002)</ref>, which scales quadratically with the observed dimension and is impractical for large-scale learning.</p><p>Recent work has considered variational learning of timeseries data using structured inference or recognition networks. Archer et al. propose using a Gaussian approximation to the posterior distribution with a block-tridiagonal inverse covariance. Johnson et al. use a conditional random field as the inference network for time-series models. Concurrent to our own work, Fraccaro et al. also learn sequential generative models using structured inference networks parameterized by recurrent neural networks.</p><p>Bayer and Osendorfer and Fabius and van Amersfoort create a stochastic variant of RNNs by making the hidden state of the RNN at every time step be a function of independently sampled latent variables. Chung et al. apply a similar model to speech data, sharing parameters between the RNNs for the generative model and the inference network. Gan et al. learn a model with discrete random variables, using a structured inference network that only considers information from the past, similar to <ref type="bibr">Chung et al. and Gregor et al.'s models.</ref> In contrast to these works, we use information from the future within a structured inference network, which we show to be preferable both theoretically and practically. Additionally, we systematically evaluate the impact of the different variational approximations on learning.</p><p>Watter et al. construct a first-order Markov model using inference networks. However, their learning algorithm is based on data tuples over consecutive time steps. This makes the strong assumption that the posterior distribution can be recovered based on observations at the current and next time-step. As we show, for generative models like the one in <ref type="figure" target="#fig_0">Fig. 1</ref>, the posterior distribution at any time step is a function of all future (and past) observations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>Gaussian State Space Models: We consider both inference and learning in a class of latent variable models given by: We denote by z t a vector valued latent variable and by x t a vector valued observation. A sequence of such latent variables and observations is denoted z, x respectively.</p><formula xml:id="formula_0">z t ‚àº N (G Œ± (z t‚àí1 , ‚àÜ t ), S Œ≤ (z t‚àí1 , ‚àÜ t )) (Transition) (1) x t ‚àº Œ†(F Œ∫ (z t )) (Emission)<label>(2)</label></formula><p>We assume that the distribution of the latent states is a multivariate Gaussian with a mean and covariance which are differentiable functions of the previous latent state and ‚àÜ t (the time elapsed of time between t ‚àí 1 and t). The multivariate observations x t are distributed according to a distribution Œ† (e.g., independent Bernoullis if the data is binary) whose parameters are a function of the corresponding latent state z t . Collectively, we denote by Œ∏ = {Œ±, Œ≤, Œ∫} the parameters of the generative model.</p><p>Eq. 1 subsumes a large family of linear and non-linear Gaussian state space models. For example, by setting</p><formula xml:id="formula_1">G Œ± (z t‚àí1 ) = G t z t‚àí1 , S Œ≤ = Œ£ t , F Œ∫ = F t z t ,</formula><p>where G t , Œ£ t and F t are matrices, we obtain linear state space models. The functional forms and initial parameters for G Œ± , S Œ≤ , F Œ∫ may be pre-specified.</p><p>Variational Learning: Using recent advances in variational inference we optimize a variational lower bound on the data log-likelihood. The key technical innovation is the introduction of an inference network or recognition network <ref type="bibr" target="#b13">(Hinton et al. 1995;</ref><ref type="bibr" target="#b17">Kingma and Welling 2014;</ref><ref type="bibr" target="#b19">Mnih and Gregor 2014;</ref><ref type="bibr" target="#b24">Rezende, Mohamed, and Wierstra 2014)</ref>, a neural network which approximates the intractable posterior. This is a parametric conditional distribution that is optimized to perform inference. Throughout this paper we will use Œ∏ to denote the parameters of the generative model, and œÜ to denote the parameters of the inference network.</p><p>For the remainder of this section, we consider learning in a Bayesian network whose joint distribution factorizes as: p(x, z) = p Œ∏ (z)p Œ∏ (x|z). The posterior distribution p Œ∏ (z|x) is typically intractable. Using the well-known variational principle, we posit an approximate posterior distribution q œÜ (z|x) to obtain the following lower bound on the marginal likelihood:</p><formula xml:id="formula_2">log p Œ∏ (x) ‚â• E q œÜ (z|x) [log p Œ∏ (x|z)] ‚àí KL( q œÜ (z|x)||p Œ∏ (z) ),<label>(3)</label></formula><p>where the inequality is by Jensen's inequality. Kingma and Welling; Rezende, Mohamed, and Wierstra use a neural net (with parameters œÜ) to parameterize q œÜ . The challenge in the resulting optimization problem is that the lower bound in Eq. 3 includes an expectation w.r.t. q œÜ , which implicitly depends on the network parameters œÜ. When using a Gaussian variational approximation q œÜ (z|x) ‚àº N (¬µ œÜ (x), Œ£ œÜ (x)), where ¬µ œÜ (x), Œ£ œÜ (x) are parametric functions of the observation x, this difficulty is overcome by using stochastic backpropagation: a simple transformation allows one to obtain unbiased Monte Carlo estimates of the gradients of Eq œÜ (z|x) [log p Œ∏ (x|z)] with respect to œÜ. The KL term in Eq.</p><p>3 can be estimated similarly since it is also an expectation. When the prior p Œ∏ (z) is Normally distributed, the KL and its gradients may be obtained analytically.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">A Factorized Variational Lower Bound</head><p>We leverage stochastic backpropagation to learn generative models given by Eq. 1, corresponding to the graphical model in <ref type="figure" target="#fig_0">Fig. 1</ref>. Our insight is that for the purpose of inference, we can use the Markov properties of the generative model to guide us in deriving a structured approximation to the posterior. Specifically, the posterior factorizes as:</p><formula xml:id="formula_3">p( z| x) = p(z 1 | x) T t=2 p(z t |z t‚àí1 , x t , . . . , x T ).<label>(4)</label></formula><p>To see this, use the independence statements implied by the graphical model in <ref type="figure" target="#fig_0">Fig. 1</ref> to note that p( z| x), the true posterior, factorizes as:</p><formula xml:id="formula_4">p( z| x) = p(z 1 | x) T t=2 p(z t |z t‚àí1 , x)</formula><p>Now, we notice that z t ‚ä• ‚ä• x 1 , . . . , x t‚àí1 |z t‚àí1 , yielding the desired result. The significance of Eq. 4 is that it yields insight into the structure of the exact posterior for the class of models laid out in <ref type="figure" target="#fig_0">Fig. 1</ref>. We directly mimic the structure of the posterior with the following factorization of the variational approximation:</p><formula xml:id="formula_5">q œÜ ( z| x) = q œÜ (z 1 |x 1 , . . . , x T ) T t=2 q œÜ (z t |z t‚àí1 , x t , . . . , x T ) (5) s.t. q œÜ (z t |z t‚àí1 , x t , . . . , x T ) ‚àº N (¬µ œÜ (z t‚àí1 , x t , . . . , x T ), Œ£ œÜ (z t‚àí1 , x t , . . . , x T ))</formula><p>where ¬µ œÜ and Œ£ œÜ are functions parameterized by neural nets.</p><p>Although q œÜ has the option to condition on all information across time, Eq. 4 suggests that in fact it suffices to condition on information from the future and the previous latent state.</p><p>The previous latent state serves as a summary statistic for information from the past. Exact Inference: We can match the factorization of the true posterior using the inference network but using a Gaussian variational approximation for the approximate posterior over each latent variable (as we do) limits the expressivity of the inferential model, except for the case of linear dynamical systems where the posterior distribution is Normally distributed. However, one could augment our proposed inference network with recent innovations that improve the variational approximation to allow for multi-modality <ref type="bibr" target="#b23">(Rezende and Mohamed 2015;</ref><ref type="bibr" target="#b27">Tran, Ranganath, and Blei 2016)</ref>. Such modifications could yield black-box methods for exact inference in timeseries models, which we leave for future work.</p><p>Deriving a Variational Lower Bound: For a generative model (with parameters Œ∏) and an inference network (with parameters œÜ), we are interested in max Œ∏ log p Œ∏ ( x). For ease of exposition, we instantiate the derivation of the variational bound for a single data point x though we learn Œ∏, œÜ from a corpus.</p><p>The lower bound in Eq. 3 has an analytic form of the KL term only for the simplest of transition models G Œ± , S Œ≤ between z t‚àí1 and z t (Eq. 1). One could estimate the gradient of the KL term by sampling from the variational model, but that results in high variance estimates and gradients. We use a different factorization of the KL term (obtained by using the prior distribution over latent variables), leading to the variational lower bound we use as our objective function:</p><formula xml:id="formula_6">L( x; (Œ∏, œÜ)) = T t=1 E q œÜ (zt| x) [log p Œ∏ (x t |z t )] (6) ‚àí KL(q œÜ (z 1 | x)||p Œ∏ (z 1 )) ‚àí T t=2 E q œÜ (zt‚àí1| x) [KL(q œÜ (z t |z t‚àí1 , x)||p Œ∏ (z t |z t‚àí1 ))] .</formula><p>The key point is the resulting objective function has more stable analytic gradients. Without the factorization of the KL divergence in Eq. 6, we would have to estimate KL(q( z| x)||p( z)) via Monte-Carlo sampling, since it has no analytic form. In contrast, in Eq. 6 the individual KL terms do have analytic forms. A detailed derivation of the bound and the factorization of the KL divergence is detailed in the supplemental material.</p><p>Learning with Gradient Descent: The objective in Eq. 6 is differentiable in the parameters of the model <ref type="bibr">(Œ∏, œÜ)</ref>. If the generative model Œ∏ is fixed, we perform gradient ascent of Eq. 6 in œÜ. Otherwise, we perform gradient ascent in both œÜ and Œ∏. We use stochastic backpropagation (Kingma and Welling 2014; Rezende, Mohamed, and Wierstra 2014) for estimating the gradient w.r.t. œÜ. Note that the expectations are only taken with respect to the variables z t‚àí1 , z t , which are the sufficient statistics of the Markov model. For the KL terms in Eq. 6, we use the fact that the prior p Œ∏ (z t |z t‚àí1 ) and the variational approximation to the posterior q œÜ (z t |z t‚àí1 , x) are both Normally distributed, and hence their KL divergence may be estimated analytically.</p><p>Algorithm 1 Learning a DMM with stochastic gradient descent: We use a single sample from the recognition network during learning to evaluate expectations in the bound. We aggregate gradients across mini-batches.</p><formula xml:id="formula_7">Inputs: Dataset D Inference Model: q œÜ ( z| x) Generative Model: p Œ∏ ( x| z), p Œ∏ ( z) while notConverged() do 1. Sample datapoint: x ‚àº D 2. Estimate posterior parameters (Evaluate ¬µ œÜ , Œ£ œÜ ) 3. SampleÀÜ z ‚àº q œÜ ( z| x) 4. Estimate conditional likelihood: p Œ∏ ( x|ÀÜ z) &amp; KL 5. Evaluate L( x; (Œ∏, œÜ)) 6. Estimate MC approx. to ‚àá Œ∏ L 7.</formula><p>Estimate MC approx. to ‚àá œÜ L (Use stochastic backpropagation to move gradients with respect to q œÜ inside expectation) 8. Update Œ∏, œÜ using ADAM (Kingma and Ba 2015) end while </p><formula xml:id="formula_8">MF-LR q(z t |x 1 , . . . x T ) BRNN MF-L q(z t |x 1 , . . . x t ) RNN ST-L q(z t |z t‚àí1 , x 1 , . . . x t ) RNN &amp; comb.fxn DKS q(z t |z t‚àí1 , x t , . . . x T ) RNN &amp; comb.fxn ST-LR q(z t |z t‚àí1 , x 1 , . . . x T ) BRNN &amp; comb.fxn</formula><p>Algorithm 1 depicts an overview of the learning algorithm. We outline the algorithm for a mini-batch of size one, but in practice gradients are averaged across stochastically sampled mini-batches of the training set. We take a gradient step in Œ∏ and œÜ, typically with an adaptive learning rate such as <ref type="bibr" target="#b16">(Kingma and Ba 2015)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Structured Inference Networks</head><p>We now detail how we construct the variational approximation q œÜ , and specifically how we model the mean and diagonal covariance functions ¬µ and Œ£ using recurrent neural networks (RNNs). Since our implementation only models the diagonal of the covariance matrix (the vector valued variances), we denote this as œÉ 2 rather than Œ£. This parameterization cannot in general be expected to be equal to p Œ∏ ( z| x), but in many cases is a reasonable approximation. We use RNNs due to their ability to scale well to large datasets. <ref type="table" target="#tab_0">Table 1</ref> details the different choices for inference networks that we evaluate. The Deep Kalman Smoother DKS corresponds exactly to the functional form suggested by Eq. 4, and is our proposed variational approximation. The DKS smoothes information from the past (z t ) and future (x t , . . . x T ) to form the approximate posterior distribution.</p><p>We also evaluate other possibilities for the variational models (inference networks) q œÜ : two are mean-field models (denoted MF) and two are structured models (denoted ST). They are distinguished by whether they use information from the past (denoted L, for left), the future (denoted R, for right), or both (denoted LR). See <ref type="figure" target="#fig_1">Fig. 2</ref> for an illustration of two of these methods. Each conditions on a different subset of the observations to summarize information in the input sequence x. DKS corresponds to ST-R.</p><p>The hidden states of the RNN parameterize the variational distribution, which go through what we call the "combiner function". We obtain the mean ¬µ t and diagonal covariance œÉ 2 t for the approximate posterior at each time-step in a manner akin to Gaussian belief propagation. Specifically, we interpret the hidden states of the forward and backward RNNs as parameterizing the mean and variance of two Gaussian-distributed "messages" summarizing the observations from the past and the future, respectively. We then multiply these two Gaussians, performing a variance-weighted average of the means. All operations should be understood to be performed element-wise on the corresponding vectors. h left t , h right t are the hidden states of the RNNs that run from the past and the future respectively (see <ref type="figure" target="#fig_1">Fig. 2</ref>).</p><p>Combiner Function for Mean Field Approximations: For the MF-LR inference network, the mean ¬µ t and diagonal variances œÉ 2 t of the variational distribution q œÜ (z t | x) are variational approximations for a sequence of length 3, using a bidirectional recurrent neural net (BRNN). The BRNN takes as input the sequence (x1, . . . x3), and through a series of non-linearities denoted by the blue arrows it forms a sequence of hidden states summarizing information from the left and right (h left t and h right t ) respectively. Then through a further sequence of non-linearities which we call the "combiner function" (marked (a) above), and denoted by the red arrows, it outputs two vectors ¬µ and Œ£, parameterizing the mean and diagonal covariance of q œÜ (zt|zt‚àí1, x) of Eq. 5. Sample≈ù zt are drawn from q œÜ (zt|zt‚àí1, x), as indicated by the black dashed arrows. For the structured variational models ST-LR, the samples·∫ët are fed into the computation of ¬µt+1 and Œ£t+1, as indicated by the red arrows with the label (a). The mean-field model does not have these arrows, and therefore computes q œÜ (zt| x). We use·∫ë0 = 0. The inference network for DKS (ST-R) is structured like that of ST-LR except without the RNN from the past. predicted using the output of the RNN (not conditioned on z t‚àí1 ) as follows, where softplus(x) = log(1 + exp(x)):</p><formula xml:id="formula_9">x 1 x 2 x 3 h left 1 h left 2 h left 3 Forward RNN h right 1 h right 2 h right 3 Backward RNN (¬µ 1 , Œ£ 1 ) (¬µ 2 , Œ£ 2 ) (¬µ 3 , Œ£ 3 ) Combiner function (a) (a) (a) z 1·∫ë2·∫ë3 0</formula><formula xml:id="formula_10">¬µ r = W right ¬µr h right t + b right ¬µr ; œÉ 2 r = softplus(W right œÉ 2 r h right t + b right œÉ 2 r ) ¬µ l = W left ¬µl h left t + b left ¬µl ; œÉ 2 l = softplus(W left œÉ 2 l h left t + b left œÉ 2 l ) ¬µ t = ¬µ r œÉ 2 l + ¬µ l œÉ 2 r œÉ 2 r + œÉ 2 l ; œÉ 2 t = œÉ 2 r œÉ 2 l œÉ 2 r + œÉ 2 l</formula><p>Combiner Function for Structured Approximations: The combiner functions for the structured approximations are implemented as:</p><formula xml:id="formula_11">(For ST-LR) h combined = 1 3 (tanh(W z t‚àí1 + b) + h left t + h right t ) (For DKS) h combined = 1 2 (tanh(W z t‚àí1 + b) + h right t ) (Posterior Means and Covariances) ¬µ t = W ¬µ h combined + b ¬µ œÉ 2 t = softplus(W œÉ 2 h combined + b œÉ 2 )</formula><p>The combiner function uses the tanh non-linearity from z t‚àí1 to approximate the transition function (alternatively, one could share parameters with the generative model), and here we use a simple weighting between the components. Relationship to Related Work: Archer et al.; <ref type="bibr">Gao et al. use</ref> </p><formula xml:id="formula_12">q( z| x) = t q(z t |z t‚àí1 , x) where q(z t |z t‚àí1 , x) = N (¬µ(x t ), Œ£(z t‚àí1 , x t , x t‚àí1 )).</formula><p>The key difference from our approach is that this parameterization (in particular, conditioning the posterior means only on x t ) does not account for the information from the future relevant to the approximate posterior distribution for z t .</p><p>Johnson et al. interleave predicting the local variational parameters of the graphical model (using an inference network) with steps of message passing inference. A key difference between our approach and theirs is that we rely on the structured inference network to predict the optimal local variational parameters directly. In contrast, in Johnson et al., any suboptimalities in the initial local variational parameters may be overcome by the subsequent steps of optimization albeit at additional computational cost.</p><p>Chung et al. propose the Variational RNN (VRNN) in which Gaussian noise is introduced at each time-step of a RNN. Chung et al. use an inference network that shares parameters with the generative model and only uses information from the past. If one views the noise variables and the hidden state of the RNN at time-step t together as z t , then a factorization similar to Eq. 6 can be shown to hold, although the KL term would no longer have an analytic form since p Œ∏ (z t |z t‚àí1 , x t‚àí1 ) would not be Normally distributed. Nonetheless, our same structured inference networks (i.e. using an RNN to summarize observations from the future) could be used to improve the tightness of the variational lower bound, and our empirical results suggest that it would result in better learned models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Deep Markov Models</head><p>Following <ref type="bibr" target="#b22">(Raiko et al. 2006)</ref>, we apply the ideas of deep learning to non-linear continuous state space models. When the transition and emission function have an unknown functional form, we parameterize G Œ± , S Œ≤ , F Œ∫ from Eq. 1 with deep neural networks. See <ref type="figure" target="#fig_0">Fig. 1 (right)</ref> for an illustration of the graphical model.</p><p>Emission Function: We parameterize the emission function F Œ∫ using a two-layer MLP (multi-layer perceptron), MLP(x, NL 1 , NL 2 ) = NL 2 (W 2 NL 1 (W 1 x + b 1 ) + b 2 )), where NL denotes non-linearities such as ReLU, sigmoid, or tanh units applied element-wise to the input vector. For modeling binary data, F Œ∫ (z t ) = sigmoid(W emission MLP(z t , ReLU, ReLU) + b emission ) parameterizes the mean probabilities of independent Bernoullis.</p><p>Gated Transition Function: We parameterize the transition function from z t to z t+1 using a gated transition function inspired by Gated Recurrent Units <ref type="bibr" target="#b3">(Chung et al. 2014)</ref>, instead of an MLP. Gated recurrent units (GRUs) are a neural architecture that parameterizes the recurrence equation in the RNN with gating units to control the flow of information from one hidden state to the next, conditioned on the observation. Unlike GRUs, in the DMM, the transition function is not conditional on any of the observations. All the information must be encoded in the completely stochastic latent state. To achieve this goal, we create a Gated Transition Function. We would like the model to have the flexibility to choose a linear transition for some dimensions while having a non-linear transitions for the others. We adopt the following parameterization, where I denotes the identity function and denotes element-wise multiplication:</p><formula xml:id="formula_13">g t = MLP(z t‚àí1 , ReLU, sigmoid) (Gating Unit) h t = MLP(z t‚àí1 , ReLU, I) (Proposed mean) (Transition Mean GŒ± and S Œ≤ ) ¬µ t (z t‚àí1 ) = (1 ‚àí g t ) (W ¬µp z t‚àí1 + b ¬µp ) + g t h t œÉ 2 t (z t‚àí1 ) = softplus(W œÉ 2 p ReLU(h t ) + b œÉ 2 p )</formula><p>Note that the mean and covariance functions both share the use of h t . In our experiments, we initialize W ¬µp to be the identity function and b ¬µp to 0. The parameters of the emission and transition function form the set Œ∏.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Evaluation</head><p>Our models and learning algorithm are implemented in Theano (Theano Development Team 2016). We use Adam <ref type="bibr" target="#b16">(Kingma and Ba 2015)</ref> with a learning rate of 0.0008 to train the DMM. Our code is available at github.com/clinicalml/structuredinference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Datasets:</head><p>We evaluate on three datasets. Synthetic: We consider simple linear and non-linear GSSMs. To train the inference networks we use N = 5000 datapoints of length T = 25. We consider both one and two dimensional systems for inference and parameter estimation. We compare our results using the training value of the variational bound L( x; (Œ∏, œÜ)) (Eq. 6) and the RMSE =</p><formula xml:id="formula_14">1 N 1 T N i=1 T t=1 [¬µ œÜ (x i,t ) ‚àí z * i,t ] 2 ,</formula><p>where z * correspond to the true underlying z's that generated the data.</p><p>Polyphonic Music: We train DMMs on polyphonic music data (Boulanger-lewandowski, Bengio, and Vincent 2012). An instance in the sequence comprises an 88-dimensional binary vector corresponding to the notes of a piano. We learn for 2000 epochs and report results based on early stopping using the validation set. We report held-out negative loglikelihood (NLL) in the format "a (b) {c}". a is an importance sampling based estimate of the NLL (details in supplementary material)</p><formula xml:id="formula_15">; b = 1 N i=1 Ti N i=1 ‚àíL( x; Œ∏, œÜ)</formula><p>where T i is the length of sequence i. This is an upper bound on the NLL, which facilitates comparison to RNNs; TSBN <ref type="bibr" target="#b8">(Gan et al. 2015)</ref> </p><formula xml:id="formula_16">(in their code) report c = 1 N N i=1</formula><p>1 Ti L( x; Œ∏, œÜ). We compute this to facilitate comparison with their work. As in (Kaae , we found annealing the KL divergence in the variational bound (L( x; (Œ∏, œÜ))) from 0 to 1 over 5000 parameter updates got better results.</p><p>Electronic Health Records (EHRs): The dataset comprises 5000 diabetic patients using data from a major health insurance provider. The observations of interest are: A1c level (hemoglobin A1c, a protein for which a high level indicates that the patient is diabetic) and glucose (blood sugar). We bin glucose into quantiles and A1c into clinically meaningful bins. The observations also include age, gender and ICD-9 diagnosis codes for co-morbidities of diabetes such as congestive heart failure, chronic kidney disease and obesity. There are 48 binary observations for a patient at every time-step. We group each patient's data (over 4 years) into three month intervals, yielding a sequence of length 18.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Synthetic Data</head><p>Compiling Exact Inference: We seek to understand whether inference networks can accurately compile exact posterior inference into the network parameters œÜ for linear GSSMs when exact inference is feasible. For this experiment we optimize Eq. 6 over œÜ, while Œ∏ is fixed to a synthetic distribution given by a one-dimensional GSSM. We compare results obtained by the various approximations we propose to those obtained by an implementation of Kalman smoothing <ref type="bibr" target="#b5">(Duckworth 2016</ref>) which performs exact inference. <ref type="figure">Fig.  3 (top and middle)</ref> depicts our results. The proposed DKS (i.e., ST-R) and ST-LR outperform the mean-field based variational method MF-L that only looks at information from the past. MF-LR, however, is often able to catch up when it comes to RMSE, highlighting the role that information from the future plays when performing posterior inference, as is evident in the posterior factorization in Eq. 4. Both DKS and ST-LR converge to the RMSE of the exact Smoothed KF, and moreover their lower bound on the likelihood becomes tight.</p><p>Approximate Inference and Parameter Estimation: Here, we experiment with applying the inference networks to synthetic non-linear generative models as well as using DKS for learning a subset of parameters within a fixed generative model. On synthetic non-linear datasets (see supplemental material) we find, similarly, that the structured variational approximations are capable of matching the performance of inference using a smoothed Unscented Kalman Filter (Wan, Van Der Merwe, and others 2000) on held-out data. Finally, <ref type="figure">Fig. 4</ref> illustrates a toy instance where we successfully perform parameter estimation in a synthetic, two-dimensional, non-linear GSSM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Polyphonic Music</head><p>Mean-Field vs Structured Inference Networks: <ref type="table" target="#tab_1">Table 2</ref> shows the results of learning a DMM on the polyphonic music dataset using MF-LR, ST-L, DKS and ST-LR. ST-L is a structured variational approximation that only considers information from the past and, up to implementation details, is comparable to the one used in <ref type="bibr" target="#b11">(Gregor et al. 2015)</ref>. Comparing the negative log-likelihoods of the learned models, we see that the looseness in the variational bound (which we first observed in the synthetic setting in <ref type="figure">Fig. 3 top right</ref>) significantly affects the ability to learn. ST-LR and DKS substantially outperform MF-LR and ST-L. This adds credence to the idea that by taking into consideration the factorization of the posterior, one can perform better inference and, consequently, learning, in real-world, high dimensional settings. Note that the DKS network has half the parameters of the ST-LR and MF-LR networks.</p><p>A Generalization of the DMM: To display the efficacy of our inference algorithm to model variants beyond firstorder Markov Models, we further augment the DMM with edges from x t‚àí1 to z t and from x t‚àí1 to x t . We refer to the resulting generative model as DMM-Augmented (Aug.). Augmenting the DMM with additional edges realizes a richer class of generative models.</p><p>We show that DKS can be used as is for inference on a more complex generative model than DMM, while making gains in held-out likelihood. All following experiments use DKS for posterior inference.</p><p>The baselines we compare to in <ref type="table" target="#tab_2">Table 3</ref> also have more complex generative models than the DMM. STORN has edges from x t‚àí1 to z t given by the recurrence update and TSBN has edges from x t‚àí1 to z t as well as from x t‚àí1 to x t .  HMSBN shares the same structural properties as the DMM, but is learned using a simpler inference network.</p><p>In <ref type="table" target="#tab_2">Table 3</ref>, as we increase the complexity of the generative model, we obtain better results across all datasets.</p><p>The DMM outperforms both RNNs and HMSBN everywhere, outperforms STORN on JSB, Nottingham and outperform TSBN on all datasets except Piano. Compared to LV-RNN (that optimizes the inclusive KL-divergence), DMM-Aug obtains better results on all datasets except JSB. This showcases our flexible, structured inference network's ability to learn powerful generative models that compare favourably to other state of the art models. We provide audio files for samples from the learned DMM models in the code repository.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">EHR Patient Data</head><p>Learning models from large observational health datasets is a promising approach to advancing precision medicine and could be used, for example, to understand which medications work best, for whom. In this section, we show how a DMM may be used for precisely such an application. Working with EHR data poses some technical challenges: EHR data are noisy, high dimensional and difficult to characterize easily. Patient data is rarely contiguous over large parts of the dataset and is often missing (not at random). We learn a DMM on the data showing how to handle the aforementioned technical challenges and use it for model based counterfactual prediction.</p><p>Graphical Model: <ref type="figure">Fig. 5</ref> represents the generative model we use when T = 4. The model captures the idea of an underlying time-evolving latent state for a patient (z t ) that is solely responsible for the diagnosis codes and lab values (x t ) we observe. In addition, the patient state is modulated by drugs (u t ) prescribed by the doctor. We may assume that the drugs prescribed at any point in time depend on the patient's entire medical history though in practice, the dotted edges in the Bayesian network never need to be modeled since x t and u t are always assumed to be observed. A natural line of follow up work would be to consider learning when u t is missing or latent.</p><p>We make use of time-varying (binary) drug prescription u t for each patient by augmenting the DMM with an additional edge every time step. Specifically, the DMM's transition function is now z t ‚àº N (G Œ± (z t‚àí1 , u t‚àí1 ), S Œ≤ (z t‚àí1 , u t‚àí1 )) (cf. Eq. 1). In our data, each u t is an indicator vector of eight anti-diabetic drugs including Metformin and Insulin, where Metformin is the most commonly prescribed first-line anti-diabetic drug.</p><formula xml:id="formula_17">z 1 u 1 x 1 z 2 u 2 x 2 z 3 u 3 x 3 z 4</formula><p>x 4 <ref type="figure">Figure 5</ref>: DMM for Medical Data: The DMM (from <ref type="figure" target="#fig_0">Fig. 1)</ref> is augmented with external actions ut representing medications presented to the patient. zt is the latent state of the patient. xt are the observations that we model. Since both ut and xt are always assumed observed, the conditional distribution p(ut|x1, . . . , xt‚àí1) may be ignored during learning.</p><p>Emission &amp; Transition Function:The choice of emission and transition function to use for such data is not well understood. In <ref type="figure" target="#fig_3">Fig. 6 (right)</ref>, we experiment with variants of DMMs and find that using MLPs (rather than linear functions) in the emission and transition function yield the best generative models in terms of held-out likelihood. In these experiments, the hidden dimension was set as 200 for the emission and transition functions. We used an RNN size of 400 and a latent dimension of size 50. We use the DKS as our inference network for learning.</p><p>Learning with Missing Data: In the EHR dataset, a subset of the observations (such as A1C and Glucose values which are commonly used to assess blood-sugar levels for diabetics) is frequently missing in the data. We marginalize them out during learning, which is straightforward within the probabilistic semantics of our Bayesian network. The subnetwork of the original graph we are concerned with is the emission function since missingness affects our ability to evaluate log p(x t |z t ) (the first term in Eq. 6). The missing random variables are leaves in the Bayesian sub-network (comprised of the emission function). Consider a simple example of two modeling two observations at time t, namely m t , o t . The log-likelihood of the data (m t , o t ) conditioned on the latent The x-axis denotes the number of 3-month intervals after prescription of Metformin. The y-axis denotes the proportion of patients (out of a test set size of 800) who, after their first prescription of Metformin, experienced a high level of A1C. In each tuple of bar plots at every time step, the left aligned bar plots (green) represent the population that received diabetes medication while the right aligned bar plots (red) represent the population that did not receive diabetes medication. (Rightmost Plot) Upper bound on negativelog likelihood for different DMMs trained on the medical data. (T) denotes "transition", (E) denotes "emission", (L) denotes "linear" and (NL) denotes "non-linear".</p><p>variable z t decomposes as log p(m t , o t |z t ) = log p(m t |z t ) + log p(o t |z t ) since the random variables are conditionally independent given their parent. If m is missing and marginalized out while o t is observed, then our log-likelihood is: log m p(m t , o t |z t ) = log( m p(m t |z t )p(o t |z t )) = log p(o t |z t ) (since m p(m t |z t ) = 1) i.e we effectively ignore the missing observations when estimating the loglikelihood of the data. The Effect of Anti-Diabetic Medications: Since our cohort comprises diabetic patients, we ask a counterfactual question: what would have happened to a patient had antidiabetic drugs not been prescribed? Specifically we are interested in the patient's blood-sugar level as measured by the widely-used A1C blood-test. We perform inference using held-out patient data leading up to the time k of first prescription of Metformin. From the posterior mean, we perform ancestral sampling tracking two latent trajectories: (1) the factual: where we sample new latent states conditioned on the medication u t the patient had actually received and (2) the counterfactual: where we sample conditioned on not receiving any drugs for all remaining timesteps (i.e u k set to the zero-vector). We reconstruct the patient observations x k , . . . , x T , threshold the predicted values of A1C levels into high and low and visualize the average number of high A1C levels we observe among the synthetic patients in both scenarios. This is an example of performing do-calculus <ref type="bibr" target="#b20">(Pearl 2009)</ref> in order to estimate model-based counterfactual effects.</p><p>The results are shown in <ref type="figure" target="#fig_3">Fig. 6</ref>. We see the model learns that, on average, patients who were prescribed anti-diabetic medication had more controlled levels of A1C than patients who did not receive any medication. Despite being an aggregate effect, this is interesting because it is a phenomenon that coincides with our intuition but was confirmed by the model in an entirely unsupervised manner. Note that in our dataset, most diabetic patients are indeed prescribed antidiabetic medications, making the counterfactual prediction harder. The ability of this model to answer such queries opens up possibilities into building personalized neural models of healthcare. Samples from the learned generative model and implementation details may be found in the supplement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Discussion</head><p>We introduce a general algorithm for scalable learning in a rich family of latent variable models for time-series data. The underlying methodological principle we propose is to build the inference network to mimic the posterior distribution (under the generative model). The space complexity of our learning algorithm depends neither on the sequence length T nor on the training set size N , offering massive savings compared to classical variational inference methods.</p><p>Here we propose and evaluate building variational inference networks to mimic the structure of the true posterior distribution. Other structured variational approximations are also possible. For example, one could instead use an RNN from the past, conditioned on a summary statistic of the future, during learning and inference.</p><p>Since we use RNNs only in the inference network, it should be possible to continue to increase their capacity and condition on different modalities that might be relevant to approximate posterior inference without worry of overfitting the data. Furthermore, this confers us the ability to easily model in the presence of missing data since the semantics of the DMM render it easy to marginalize out unobserved data. In contrast, in a (stochastic) RNN (bottom in <ref type="figure" target="#fig_0">Fig. 1)</ref> it is much more difficult to marginalize out unobserved data due to the dependence of the intermediate hidden states on the previous input. Indeed this allowed us to develop a principled application of the learning algorithm to modeling longitudinal patient data in EHR data and inferring treatment effect.</p><formula xml:id="formula_18">= z1 q(z 1 ) log p(z 1 ) q(z 1 ) + T t=2 zt‚àí1 zt q(z t ) log p(z t |z t‚àí1 ) q(z t |z t‚àí1 ) (Each expectation over zt is constant for t / ‚àà {t, t ‚àí 1}) = KL(q(z 1 )||p(z 1 )) + T t=2 E q(zt‚àí1) [KL(q(z t |z t‚àí1 )||p(z t |z t‚àí1 ))]<label>(8)</label></formula><p>For evaluating the marginal likelihood on the test set, we can use the following Monte-Carlo estimate:</p><formula xml:id="formula_19">p( x) 1 S S s=1 p( x| z (s) )p( z (s) ) q( z (s) | x) z (s) ‚àº q( z| x) (9)</formula><p>This may be derived in a manner akin to the one depicted in Appendix E <ref type="bibr" target="#b24">(Rezende, Mohamed, and Wierstra 2014)</ref> or Appendix D <ref type="bibr" target="#b17">(Kingma and Welling 2014)</ref>. The log likelihood on the test set is computed using:</p><formula xml:id="formula_20">log p( x) log 1 S S s=1 exp log p( x| z (s) )p( z (s) ) q( z (s) | x)<label>(10)</label></formula><p>Eq. 10 may be computed in a numerically stable manner using the log-sum-exp trick.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B KL divergence between Prior and Posterior</head><p>Maximum likelihood learning requires us to compute:</p><formula xml:id="formula_21">KL(q(z 1 , . . . , z T )||p(z 1 , . . . , z T )) = KL(q(z 1 )||p(z 1 )) + T ‚àí1 t=2 E q(zt‚àí1) [KL(q(z t |q t‚àí1 )||p(z t |z t‚àí1 ))]<label>(11)</label></formula><p>The KL divergence between two multivariate Gaussians q, p with respective means and covariances ¬µ q , Œ£ q , ¬µ p , Œ£ p can be written as:</p><formula xml:id="formula_22">KL(q||p) = 1 2 (log |Œ£ p | |Œ£ q | (a) ‚àíD+ (12) Tr(Œ£ ‚àí1 p Œ£ q ) (b) + (¬µ p ‚àí ¬µ q ) T Œ£ ‚àí1 p (¬µ p ‚àí ¬µ q ) (c) )</formula><p>The choice of q and p is suggestive. using Eq. 11 &amp; 12, we can derive a closed form for the KL divergence between q(z 1 . . . z T ) and p(z 1 . . . z T ). ¬µ q , Œ£ q are the outputs of the variational model. Our functional form for ¬µ p , Œ£ p is based on our generative and can be summarized as:</p><formula xml:id="formula_23">¬µ p1 = 0 Œ£ p1 = 1 ¬µ pt = G(z t‚àí1 , u t‚àí1 ) = G t‚àí1 Œ£ pt = ‚àÜ œÉ</formula><p>Here, Œ£ pt is assumed to be a learned diagonal matrix and ‚àÜ a scalar parameter.</p><p>Term (a) For t = 1, we have:</p><formula xml:id="formula_24">log |Œ£ p1 | |Œ£ q1 | = log|Œ£ p1 |‚àí log|Œ£ q1 |= ‚àí log|Œ£ q1 |<label>(13)</label></formula><p>For t &gt; 1, we have:</p><formula xml:id="formula_25">log |Œ£ pt | |Œ£ qt | = log|Œ£ pt |‚àí log|Œ£ qt |= D log(‚àÜ) + log| œÉ|‚àí log|Œ£ qt | (14)</formula><p>Term (b) For t = 1, we have:</p><formula xml:id="formula_26">Tr(Œ£ ‚àí1 p1 Œ£ q1 ) = Tr(Œ£ q1 )<label>(15)</label></formula><p>For t &gt; 1, we have:</p><formula xml:id="formula_27">Tr(Œ£ ‚àí1 pt Œ£ qt ) = 1 ‚àÜ Tr(diag( œÉ) ‚àí1 Œ£ qt )<label>(16)</label></formula><p>Term (c) For t = 1, we have:</p><formula xml:id="formula_28">(¬µ p1 ‚àí ¬µ q1 ) T Œ£ ‚àí1 p1 (¬µ p1 ‚àí ¬µ q1 ) = ||¬µ q1 || 2<label>(17)</label></formula><p>For t &gt; 1, we have:</p><formula xml:id="formula_29">(¬µ pt ‚àí ¬µ qt ) T Œ£ ‚àí1 pt (¬µ pt ‚àí ¬µ qt ) = (18) ‚àÜ(G t‚àí1 ‚àí ¬µ qt ) T diag( œÉ) ‚àí1 (G t‚àí1 ‚àí ¬µ qt )</formula><p>Rewriting <ref type="bibr">Eq. 11 using Eqns. 13,</ref><ref type="bibr">14,</ref><ref type="bibr">15,</ref><ref type="bibr">16,</ref><ref type="bibr">17,</ref><ref type="bibr">18</ref>, we get:</p><formula xml:id="formula_30">KL(q(z 1 , . . . , z T )||p(z 1 , . . . , z T )) = 1 2 ((T ‚àí 1)D log(‚àÜ) log| œÉ|‚àí T t=1 log|Œ£ qt | + Tr(Œ£ q1 ) + 1 ‚àÜ T t=2 Tr(diag( œÉ) ‚àí1 Œ£ qt ) + ||¬µ q1 || 2 + ‚àÜ T t=2 E zt‚àí1 (G t‚àí1 ‚àí ¬µ qt ) T diag( œÉ) ‚àí1 (G t‚àí1 ‚àí ¬µ qt ) )</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Polyphonic Music Generation</head><p>In the models we trained, the hidden dimension was set to be 100 for the emission distribution and 200 in the transition function. We typically used RNN sizes from one of {400, 600} and a latent dimension of size 100. Samples: <ref type="figure" target="#fig_4">Fig. 7</ref> depicts mean probabilities of samples from the DMM trained on JSB Chorales (Boulangerlewandowski, Bengio, and Vincent 2012). MP3 songs corresponding to two different samples from the best DMM model in the main paper learned on each of the four polyphonic data sets may be found in the code repository.</p><p>Experiments with NADE: We also experimented with Neural Autoregressive Density Estimators (NADE) <ref type="bibr" target="#b18">(Larochelle and Murray 2011)</ref> in the emission distribution for DMM-Aug and denote it DMM-Aug-NADE. In <ref type="table" target="#tab_3">Table 4</ref>, we see that DMM-Aug-NADE performs comparably to the state of the art RNN-NADE on JSB, Nottingham and Piano.  Linear SSMs : <ref type="figure" target="#fig_1">Fig. 8 (N=500, T=25)</ref> depicts the performance of inference networks using the same setup as in the main paper, only now using held out data to evaluate the RMSE and the upper bound. We find that the results echo those in the training set, and that on unseen data points, the inference networks, particularly the structured ones, are capable of generalizing compiled inference. Non-linear SSMs : <ref type="figure">Fig. 9</ref> considers learning inference networks on a synthetic non-linear dynamical system (N = 5000, T = 25). We find once again that inference networks that match the posterior realize faster convergence and better training (and validation) accuracy. x ST-R <ref type="figure" target="#fig_0">Figure 10</ref>: Inference on Non-linear Synthetic Data: Visualizing inference on training data. Generative Models: (a) Linear Emission and Non-linear Transition z * denotes the latent variable that generated the observation. x denotes the true data. We compare against the results obtained by a smoothed Unscented Kalman Filter (UKF) <ref type="bibr">(Wan, Van Der Merwe, and others 2000)</ref>. The column denoted "Observations" denotes the result of applying the emission function of the respective generative model on the posterior estimates shown in the column "Latent Space". The shaded areas surrounding each curve ¬µ denotes ¬µ ¬± œÉ for each plot.</p><p>Visualizing Inference: In <ref type="figure" target="#fig_0">Fig. 10</ref> we visualize the posterior estimates obtained by the inference network. We run posterior inference on the training set 10 times and take the empirical expectation of the posterior means and covariances of each method. We compare posterior estimates with those obtained by a smoothed Unscented Kalman Filter (UKF) <ref type="bibr">(Wan, Van Der Merwe, and others 2000)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Generative Models of Medical Data</head><p>In this section, we detail some implementation details and visualize samples from the generative model trained on patient data.</p><p>Marginalizing out Missing Data: We describe the method we use to implement the marginalization operation. The main paper notes that marginalizing out observations in the DMM corresponds to ignoring absent observations during learning. We track indicators denoting whether A1C values and Glucose values were observed in the data. These are used as markers of missingness. During batch learning, at every time-step t, we obtain a matrix B = log p(x t |z t ) of size batch-size √ó 48, where 48 is the dimensionality of the observations, comprising the log-likelihoods of every dimension for patients in the batch. We multiply this with a matrix of M . M has the same dimensions as B and has a 1 if the patient's A1C value was observed and a 0 otherwise. For dimensions that are never missing, M is always 1.</p><p>Sampling a Patient: We visualize samples from the DMM trained on medical data in <ref type="figure" target="#fig_0">Fig. 11</ref> The model captures correlations within timesteps as well as variations in A1C level and Glucose level across timesteps. It also captures rare occurrences of comorbidities found amongst diabetic patients.  <ref type="figure" target="#fig_0">Figure 11</ref>: Generated Samples Samples of a patient from the model, including the most important observations. The x-axis denotes time and the y-axis denotes the observations. The intensity of the color denotes its value between zero and one</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Generative Models of Sequential Data: (Top Left) Hidden Markov Model (HMM), (Top Right) Deep Markov Model (DMM) denotes the neural networks used in DMMs for the emission and transition functions. (Bottom) Recurrent Neural Network (RNN), ‚ô¶ denotes a deterministic intermediate representation. Code for learning DMMs and reproducing our results may be found at: github.com/clinicalml/structuredinference</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Structured Inference Networks: MF-LR and ST-LR</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :Figure 4 :</head><label>34</label><figDesc>Synthetic Evaluation: (Top &amp; Middle) Compiled inference for a fixed linear GSSM: zt ‚àº N (zt‚àí1 + 0.05, 10), xt ‚àº N (0.5zt, 20). The training set comprised N = 5000 onedimensional observations of sequence length T = 25. (Top left) RMSE with respect to true z * that generated the data. (Top right) Variational bound during training. The results on held-out data are very similar (see supplementary material). (Bottom) Visualizing inference in two sequences (denoted(1)and(2)); Left panels show the Latent Space of variables z, right panels show the Observations x. Observations are generated by the application of the emission function to the posterior shown in Latent Space. Shading denotes standard deviations. Parameter Estimation: Learning parameters Œ±, Œ≤ in a two-dimensional non-linear GSSM. N = 5000, T = 25 zt ‚àº N ([0.2z 0 t‚àí1 + tanh(Œ±z 1 t‚àí1 ); 0.2z 1 t‚àí1 + sin(Œ≤z 0 t‚àí1 )], 1.0) xt ‚àº N (0.5 zt, 0.1) where z denotes a vector, [] denotes concatenation and superscript denotes indexing.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 6 :</head><label>6</label><figDesc>(Left Two Plots) Estimating Counterfactuals with DMM:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 7 :</head><label>7</label><figDesc>Two samples from the DMM trained on JSB Chorales D Experimental Results on Synthetic Data Experimental Setup: We used an RNN size of 40 in the inference networks used for the synthetic experiments.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 8 :Figure 9 :</head><label>89</label><figDesc>Inference in a Linear SSM on Held-out Data: Performance of inference networks on held-out data using a generative model with Linear Emission and Linear Transition (same setup as main paper) z t ‚àº N (2 sin(z t‚àí1 ) + z t‚àí1 , 5)x t ‚àº N (0.5z t , 5) (b) Performance on held-out data Inference in a Non-linear SSM: Performance of inference networks trained with data from a Linear Emission and Non-linear Transition SSM</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>&lt; A1C &lt; 10.0 10.0 &lt; A1C &lt; 19.0 0 &lt; GLUC. &lt; 92.0 92.0 &lt; GLUC. &lt; 102.0 102.0 &lt; GLUC. &lt; 113.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Inference Networks: BRNN refers to a Bidirectional RNN and comb.fxn is shorthand for combiner function.</figDesc><table /><note>Inference Network Variational Approximation for z t Implemented With</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Comparing Inference Networks: Test negative loglikelihood on polyphonic music of different inference networks trained on a DMM with a fixed structure (lower is better). The numbers inside parentheses are the variational bound.</figDesc><table><row><cell>Inference Network</cell><cell>JSB</cell><cell>Nottingham</cell><cell>Piano</cell><cell>Musedata</cell></row><row><cell>DKS (i.e., ST-R)</cell><cell>6.605 (7.033)</cell><cell>3.136 (3.327)</cell><cell>8.471 (8.584)</cell><cell>7.280 (7.136)</cell></row><row><cell>ST-L</cell><cell>7.020 (7.519)</cell><cell>3.446 (3.657)</cell><cell>9.375 (9.498)</cell><cell>8.301 (8.495)</cell></row><row><cell>ST-LR</cell><cell>6.632 (7.078)</cell><cell>3.251 (3.449)</cell><cell>8.406 (8.529)</cell><cell>7.127 (7.268)</cell></row><row><cell>MF-LR</cell><cell>6.701 (7.101)</cell><cell>3.273 (3.441)</cell><cell>9.188 (9.297)</cell><cell>8.760 (8.877)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Evaluation against Baselines: Test negative loglikelihood (lower is better) on Polyphonic Music Generation dataset.</figDesc><table><row><cell cols="5">Table Legend: RNN (Boulanger-lewandowski, Bengio, and Vin-</cell></row><row><cell cols="5">cent 2012), LV-RNN (Gu, Ghahramani, and Turner 2015), STORN</cell></row><row><cell cols="5">(Bayer and Osendorfer 2014), TSBN, HMSBN (Gan et al. 2015).</cell></row><row><cell>Methods</cell><cell>JSB</cell><cell>Nottingham</cell><cell>Piano</cell><cell>Musedata</cell></row><row><cell></cell><cell>6.388</cell><cell>2.770</cell><cell>7.835</cell><cell>6.831</cell></row><row><cell>DMM</cell><cell>(6.926)</cell><cell>(2.964)</cell><cell>(7.980)</cell><cell>(6.989)</cell></row><row><cell></cell><cell>{6.856}</cell><cell>{2.954}</cell><cell>{8.246}</cell><cell>{6.203}</cell></row><row><cell></cell><cell>6.288</cell><cell>2.679</cell><cell>7.591</cell><cell>6.356</cell></row><row><cell>DMM-Aug.</cell><cell>(6.773)</cell><cell>(2.856)</cell><cell>(7.721)</cell><cell>(6.476)</cell></row><row><cell></cell><cell>{6.692}</cell><cell>{2.872}</cell><cell>{8.025}</cell><cell>{5.766}</cell></row><row><cell>HMSBN</cell><cell>(8.0473) {7.9970}</cell><cell>(5.2354) {5.1231}</cell><cell>(9.563) {9.786}</cell><cell>(9.741) {8.9012}</cell></row><row><cell>STORN</cell><cell>6.91</cell><cell>2.85</cell><cell>7.13</cell><cell>6.16</cell></row><row><cell>RNN</cell><cell>8.71</cell><cell>4.46</cell><cell>8.37</cell><cell>8.13</cell></row><row><cell>TSBN</cell><cell>{7.48}</cell><cell>{3.67}</cell><cell>{7.98}</cell><cell>{6.81}</cell></row><row><cell>LV-RNN</cell><cell>3.99</cell><cell>2.72</cell><cell>7.61</cell><cell>6.89</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Experiments with NADE Emission: Test negative loglikelihood (lower is better) on Polyphonic Music Generation dataset.</figDesc><table><row><cell cols="6">Table Legend: RNN-NADE (Boulanger-lewandowski, Bengio, and</cell></row><row><cell>Vincent 2012)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Methods</cell><cell>JSB</cell><cell cols="2">Nottingham</cell><cell>Piano</cell><cell>Musedata</cell></row><row><cell></cell><cell>5.118</cell><cell></cell><cell>2.305</cell><cell>7.048</cell><cell>6.049</cell></row><row><cell>DMM-Aug.-NADE</cell><cell>(5.335)</cell><cell></cell><cell>(2.347)</cell><cell>(7.099)</cell><cell>(6.115)</cell></row><row><cell></cell><cell>{5.264}</cell><cell></cell><cell>{2.364}</cell><cell>{7.361}</cell><cell>{5.247}</cell></row><row><cell>RNN-NADE</cell><cell>5.19</cell><cell></cell><cell>2.31</cell><cell>7.05</cell><cell>5.60</cell></row><row><cell cols="3">0 20 40 60 80 100 120 140 160 180 200 0 10 20 30 40 50 60 70 80 88</cell><cell cols="3">0 20 40 60 80 100 120 140 160 180 200 0 10 20 30 40 50 60 70 80 88</cell></row><row><cell>Time</cell><cell></cell><cell></cell><cell></cell><cell>Time</cell></row><row><cell cols="2">(a) Sample 1</cell><cell></cell><cell></cell><cell cols="2">(b) Sample 2</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>The Tesla K40s used for this research were donated by the NVIDIA Corporation. The authors gratefully acknowledge support by the DARPA Probabilistic Programming for Advancing Machine Learning (PPAML) Program under AFRL prime contract no. FA8750-14-C-0005, ONR #N00014-13-1-0646, a NSF CAREER award #1350965, and Independence Blue Cross. We thank David Albers, Kyunghyun Cho, Yacine Jernite, Eduardo Sontag and anonymous reviewers for their valuable feedback and comments.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Lower Bound on the Likelihood of data</head><p>We can derive the bound on the likelihood L( x; (Œ∏, œÜ)) as follows:</p><p>In the following we omit the dependence of q on x, and omit the subscript œÜ. We can show that the KL divergence between the approximation to the posterior and the prior simplifies as:</p><p>. . . z T q(z 1 ) . . . q(z T |z T ‚àí1 ) log p(z t |z t‚àí1 ) q(z t |z t‚àí1 )</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Black box variational inference for state space models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Archer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">M</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Buesing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cunningham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Paninski</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.07367</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Modeling temporal dependencies in high-dimensional sequences: Application to polyphonic music generation and transcription</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bayer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Osendorfer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Boulanger-Lewandowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1411.7610</idno>
	</analytic>
	<monogr>
		<title level="m">Learning stochastic recurrent networks</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>ICML</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Fisher scoring and a mixture of modes approach for approximate inference and learning in nonlinear state space models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Briegel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Tresp</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Empirical evaluation of gated recurrent neural networks on sequence modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.3555</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">A recurrent latent variable model for sequential data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kastner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Dinh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Kalman filter, kalman smoother, and em library for python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Duckworth</surname></persName>
		</author>
		<ptr target="https://pykalman.github.io/" />
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2016" to="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Fabius</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Van Amersfoort</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6581</idno>
		<title level="m">Variational recurrent auto-encoders</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Sequential neural models with stochastic layers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fraccaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>S√∏nderby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Paquet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Winther</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Deep temporal sigmoid belief networks for sequence modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Henao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">E</forename><surname>Carlson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carin</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Linear dynamical neural population models through nonlinear embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Archer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Paninski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Cunningham</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Learning nonlinear dynamical systems using an EM algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">T</forename><surname>Roweis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">DRAW: A recurrent neural network for image generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gregor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Danihelka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Neural adaptive sequential monte carlo</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Turner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The&quot; wake-sleep&quot; algorithm for unsupervised neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Frey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Neal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">268</biblScope>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Structured VAEs: Composing probabilistic graphical models and variational autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Duvenaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">B</forename><surname>Wiltschko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Datta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">P</forename><surname>Adams</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">How to Train Deep Variational Autoencoders and Probabilistic Ladder Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaae</forename><surname>S√∏nderby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Raiko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Maal√∏e</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Kaae S√∏nderby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Winther</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>ArXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Auto-encoding variational bayes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The neural autoregressive distribution estimator</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Murray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AISTATS</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Neural variational inference and learning in belief networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregor</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Causality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>Cambridge university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Variational bayesian learning of nonlinear hidden state-space models for model predictive control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Raiko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tornio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="issue">16</biblScope>
			<biblScope unit="page" from="3704" to="3712" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">State inference in variational bayesian nonlinear state-space models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Raiko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tornio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Honkela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Karhunen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on ICA and Signal Separation</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Variational inference with normalizing flows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Stochastic backpropagation and approximate inference in deep generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">System identification of nonlinear state-space models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">B</forename><surname>Sch√∂n</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wills</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ninness</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automatica</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="39" to="49" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Theano: A Python framework for fast computation of mathematical expressions</title>
		<idno>abs/1605.02688</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>Theano Development Team</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">The variational gaussian process</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ranganath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">An unsupervised ensemble learning method for nonlinear dynamic state-space models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Valpola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Karhunen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2647" to="2692" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Dual kalman filtering methods for nonlinear prediction, smoothing and estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">T</forename><surname>Nelson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Embed to control: A locally linear latent dynamics model for control from raw images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Van Der Merwe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AS-SPCC 2000. Watter</title>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
	<note>NIPS</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
