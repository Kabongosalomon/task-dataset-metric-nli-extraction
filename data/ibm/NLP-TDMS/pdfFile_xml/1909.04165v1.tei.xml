<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Learning Semantic Parsers from Denotations with Latent Structured Alignments and Abstract Programs</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bailin</forename><surname>Wang</surname></persName>
							<email>bailin.wang@ed.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">Institute for Language, Cognition and Computation School of Informatics</orgName>
								<orgName type="institution">University of Edinburgh</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Titov</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute for Language, Cognition and Computation School of Informatics</orgName>
								<orgName type="institution">University of Edinburgh</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute for Language, Cognition and Computation School of Informatics</orgName>
								<orgName type="institution">University of Edinburgh</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Learning Semantic Parsers from Denotations with Latent Structured Alignments and Abstract Programs</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T18:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Semantic parsing aims to map natural language utterances onto machine interpretable meaning representations, aka programs whose execution against a real-world environment produces a denotation. Weakly-supervised semantic parsers are trained on utterancedenotation pairs treating programs as latent. The task is challenging due to the large search space and spuriousness of programs which may execute to the correct answer but do not generalize to unseen examples. Our goal is to instill an inductive bias in the parser to help it distinguish between spurious and correct programs. We capitalize on the intuition that correct programs would likely respect certain structural constraints were they to be aligned to the question (e.g., program fragments are unlikely to align to overlapping text spans) and propose to model alignments as structured latent variables. In order to make the latent-alignment framework tractable, we decompose the parsing task into (1) predicting a partial "abstract program" and (2) refining it while modeling structured alignments with differential dynamic programming. We obtain state-of-the-art performance on the WIK-ITABLEQUESTIONS and WIKISQL datasets. When compared to a standard attention baseline, we observe that the proposed structuredalignment mechanism is highly beneficial. STRING select (ROW, COLUMN) COLUMN #column_slot ROW first (LIST[ROW]) LIST[ROW] #rows_slot Abstract Program: select (first (#rows_slot) #column_slot) Derivation Tree: <ref type="figure">Figure 2</ref>: An abstract program and its derivation tree.</p><p>Capitalized words indicate types of function arguments and their return value.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Semantic parsing is the task of translating natural language to machine interpretable meaning representations. Typically, it requires mapping a natural language utterance onto a program, which is executed against a knowledge base to obtain an answer or a denotation. Most previous work <ref type="bibr" target="#b52">(Zettlemoyer and Collins, 2005;</ref><ref type="bibr" target="#b46">Wong and Mooney, 2007;</ref><ref type="bibr" target="#b30">Lu et al., 2008;</ref><ref type="bibr" target="#b23">Jia and Liang, 2016)</ref> has focused on the supervised setting where a model is learned from question-program pairs. Weakly  <ref type="figure">Figure 1</ref>: After generating an abstract program for a question, our parser finds alignments between slots (with prefix #) and question spans. Based on the alignment, it instantiates each slot and a complete program is executed against a table to obtain a denotation. supervised semantic parsing <ref type="bibr" target="#b9">(Berant et al., 2013;</ref><ref type="bibr" target="#b29">Liang et al., 2011)</ref> reduces the burden of annotating programs by learning from questions paired with their answers (or denotations).</p><p>Two major challenges arise when learning from denotations: 1) training of the semantic parser requires exploring a large search space of possible programs to find those which are consistent, and execute to correct denotations; 2) the parser should be robust to spurious programs which accidentally execute to correct denotations, but do not reflect the semantics of the question. In this paper, we propose a weakly-supervised neural semantic parser that features structured latent alignments to bias learning towards correct programs which are consistent but not spurious.</p><p>Our intuition is that correct programs should re-arXiv:1909.04165v1 [cs.CL] 9 Sep 2019 spect certain constraints were they to be aligned to the question text, while spurious and inconsistent programs do not. For instance, in <ref type="figure">Figure 1</ref>, the answer to the question ("0") can be obtained by executing the correct program which selects the number of Turkey's silver medals. However, the same answer can be also obtained by the spurious programs shown in the figure. <ref type="bibr">1</ref> The spurious programs differ from the correct one in that they repeatedly use the column "silver". Whereas, in the question, the word "silver" only refers to the target column containing the answer; it also mistakenly triggers the appearance of the column "silver" in the row selection condition. This constraint, i.e., that a text span within a question cannot trigger two semantically distinct operations (e.g., selecting target rows and target columns) can provide a useful inductive bias. We propose to capture structural constraints by modeling the alignments between programs and questions explicitly as structured latent variables.</p><p>Considering the large search space of possible programs, an alignment model that takes into account the full range of correspondences between program operations and question spans would be very expensive. To make the process tractable, we introduce a two-stage approach that features abstract programs. Specifically, we decompose semantic parsing into two steps: 1) a natural language utterance is first mapped to an abstract program which is a composition of high-level operations; and 2) the abstract program is then instantiated with low-level operations that usually involve relations and entities specific to the knowledge base at hand. This decomposition is motivated by the observation that only a small number of sensible abstract programs can be instantiated into consistent programs. Similar ideas of using abstract meaning representations have been explored with fully-supervised semantic parsers <ref type="bibr">Catherine Finegan-Dollak and Radev, 2018)</ref> and in other related tasks <ref type="bibr" target="#b15">(Goldman et al., 2018;</ref><ref type="bibr" target="#b20">Herzig and Berant, 2018;</ref><ref type="bibr" target="#b34">Nye et al., 2019)</ref>.</p><p>For a knowledge base in tabular format, we abstract two basic operations of row selection and column selection from programs: these are handled in the second (instantiation) stage. As shown in <ref type="figure">Figure 1</ref>, the question is first mapped to the abstract program "select (#row slot, #column slot)" whose two slots are subsequently instantiated with filter conditions (row slot) and a column name (column slot). During the instantiation of abstract programs, each slot should refer to the question to obtain its specific semantics. In <ref type="figure">Figure 1</ref>, row slot should attend to "nation of Turkey" while column slot needs to attend to "silver medals". The structural constraint discussed above now corresponds to assuming that each span in a question can be aligned to a unique row or column slot. Under this assumption, the instantiation of spurious programs will be discouraged. The uniqueness constraint would be violated by both spurious programs in <ref type="figure">Figure 1</ref>, since "column:silver" appears in the program twice but can be only aligned to the span "silver medals" once.</p><p>The first stage (i.e., mapping a question onto an abstract program) is handled with a sequence-tosequence model. The second stage (i.e., program instantation) is approached with local classifiers: one per slot in the abstract program. The classifiers are conditionally independent given the abstract program and a latent alignment. Instead of marginalizing out alignments, which would be intractable, we use structured attention <ref type="bibr" target="#b24">(Kim et al., 2017)</ref>, i.e., we compute the marginal probabilities for individual span-slot alignment edges and use them to weight the input to the classifiers. As we discuss below, the marginals in our constrained model are computed with dynamic programming.</p><p>We perform experiments on two open-domain question answering datasets in the setting of learning from denotations. Our model achieves an execution accuracy of 44.5% in WIKITABLEQUES-TIONS and 79.3% in WIKISQL, which both surpass previous state-of-the-art methods in the same weakly-supervised setting. In WIKISQL, our parser is better than recent supervised parsers that are trained on question-program pairs. Our contributions can be summarized as follows:</p><p>• we introduce an alignment model as a means of differentiating between correct and spurious programs;</p><p>• we propose a neural semantic parser that performs tractable alignments by first mapping questions to abstract programs;</p><p>• we achieve state-of-the-art performance on two semantic parsing benchmarks. 2</p><p>Although we use structured alignments to mostly enforce the uniqueness constraint described above, other types of inductive biases can be useful and could be encoded in our two-stage framework. For example, we could replace the uniqueness constraint with modeling the number of slots aligned to a span, or favor sparse alignment distributions. Crucially, the two-stage framework makes it easier to inject prior knowledge about datasets and formalisms while maintaining efficiency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>Given knowledge base t, our task is to map a natural utterance x to program z, which is then executed against a knowledge base to obtain denotation [[z]] t = d. We train our parser only based on d without access to correct programs z * . Our experiments focus on two benchmarks, namely WIK-ITABLEQUESTIONS <ref type="bibr" target="#b35">(Pasupat and Liang, 2015)</ref> and WIKISQL <ref type="bibr" target="#b54">(Zhong et al., 2017)</ref> where each question is paired with a Wikipedia table and a denotation. <ref type="figure">Figure 1</ref> shows a simplified example taken from WIKITABLEQUESTIONS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Grammars</head><p>Executable programs z that can query tables are defined according to a language. Specifically, the search space of programs is constrained by grammar rules so that it can be explored efficiently. We adopt the variable-free language of <ref type="bibr" target="#b28">Liang et al. (2018)</ref> and define an abstract grammar and an instantiation grammar which decompose the generation of a program in two stages. <ref type="bibr">3</ref> The first stage involves the generation of an abstract version of a program which, in the second stage, gets instantiated. Abstract programs only consider compositions of high-level functions, such as superlatives and aggregation, while low-level functions and arguments, such as filter conditions and entities, are taken into account in the next step. In our table-based datasets, abstract programs do not include two basic operations of querying tables: row selection and column selection. These operations are handled at the instantiation stage. In <ref type="figure">Figure 1</ref> the abstract program has two slots for row and column selection, which are filled with the conditions "column:nation = Turkey" and "column:silver" at the instantiation stage. The two stages can be easily merged into one step when conducting symbolic combinatorial search. The motivation for the decomposition is to facilitate the learning of our neural semantic parser and the handling of structured alignments.</p><p>Abstract Grammar Our abstract grammar has five basic types: ROW, COLUMN, STRING, NUM-BER, and DATE; COLUMN is further sub-typed into STRING COLUMN, NUMBER COLUMN, and DATE COLUMN; other basic types are augmented with LIST to represent a list of elements like LIST <ref type="bibr">[ROW]</ref>. Arguments and return values of functions are typed using these basic types.</p><p>Function composition can be defined recursively based on a set of production rules, each corresponding to a function type. For instance, function ROW → first(LIST[ROW]) selects the first row from a list of rows and corresponds to production rule "ROW → first".</p><p>The abstract grammar has two additional types for slots (aka terminal rules) which correspond to row and column selection:</p><formula xml:id="formula_0">LIST[ROW] → #row slot COLUMN → #column slot</formula><p>An example of an abstract program and its derivation tree is shown in <ref type="figure">Figure 2</ref>. We linearize the derivation by traversing it in a left-toright depth-first manner. We represent the tree in <ref type="figure">Figure 2</ref> as a sequence of production rules:</p><formula xml:id="formula_1">"ROOT → STRING, STRING → select, ROW → first", LIST[ROW] → #row slot, COLUMN → #col- umn slot".</formula><p>The first action is always to select the return type for the root node.</p><p>Given a specific table t, the abstract grammar H t will depend on its column types. For example, if the table does not have number cells, "max/min" operations will not be executable.</p><p>Instantiation Grammar A column slot is directly instantiated by selecting a column; a row slot is filled with one or multiple conditions (COND) which are joined together with conjunction (OR) and disjunction (AND) operators:</p><formula xml:id="formula_2">COND → COLUMN OPERATOR VALUE #row slot → COND (AND COND)* #row slot → COND (OR COND)* where OPERATOR ∈ [&gt;, &lt;, =, ≥, ≤]</formula><p>and VALUE is a string, a number, or a date. A special condition #row slot → all rows is defined to signify that a program queries all rows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Search for Consistent Programs</head><p>A problematic aspect of learning from denotations is that, since annotated programs are not available (e.g., for WIKITABLEQUESTIONS), we have no means to directly evaluate a proposed grammar. As an evaluation proxy, we measure the coverage of our grammar in terms of consistent programs. Specifically, we exhaustively search for all consistent programs for each question in the training set. While the space of programs is exponential, we observed that abstract programs which are instantiated into correct programs are not very complex in terms of the number of production rules used to generate them. As a result, we impose restrictions on the number of production rules which can abstract programs, and in this way the search process becomes tractable. <ref type="bibr">4</ref> We find that 83.6% of questions in WIK-ITABLEQUESTIONS are covered by at least one consistent program. However, each question eventually has 200 consistent programs on average and most of them are spurious. Treating them as ground truth poses a great challenge for learning a semantic parser. The coverage for WIKISQL is 96.6% and each question generates 84 consistent programs.</p><p>Another important observation is that there is only a limited number of abstract programs that can be instantiated into consistent programs. The number of such abstract programs is 23 for WIK-ITABLEQUESTIONS and 6 for WIKISQL, suggesting that there are a few patterns underlying several utterances. This motivates us to design a semantic parser that first maps utterances to abstract programs. For the sake of generality, we do not restrict our parser to abstract programs in the training set. We elaborate on this below. <ref type="bibr">4</ref> Details are provided in the Appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Model</head><p>After obtaining consistent programs z for each question via offline search, we next show how to learn a parser that can generalize to unseen questions and tables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Training and Inference</head><p>Our learning objective J is to maximize the loglikelihood of the marginal probability of all consistent programs, which are generated by mapping an utterance x to an interim abstract program h:</p><formula xml:id="formula_3">J = log{ h∈Ht p(h|x, t) [[z]]=d p(z|x, t, h)}. (1)</formula><p>During training, our model only needs to focus on abstract programs that have successful instantiations of consistent programs and it does not have to explore the whole space of possible programs.</p><p>At test time, the parser chooses the programẑ with the highest probability:</p><formula xml:id="formula_4">h,ẑ = arg max h∈Ht, z p(h|x, t)p(z|x, t, h). (2)</formula><p>For efficiency, we only choose the top-k abstract programs to instantiate through beam search.ẑ is then executed to obtain its denotation as the final prediction.</p><p>Next, we will explain the basic components of our neural parser. Basically, our model first encodes a question and a table with an input encoder; it then generates abstract programs with a seq2seq model; and finally, these abstract programs are instantiated based on a structured alignment model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Input Encoder</head><p>Each word in an utterance is mapped to a distributed representation through an embedding layer. Following previous work <ref type="bibr" target="#b33">(Neelakantan et al., 2017;</ref><ref type="bibr" target="#b28">Liang et al., 2018)</ref>, we also add an indicator feature specifying whether the word appears in the table. This feature is mapped to a learnable vector. Additionally, in WIKITABLE-QUESTIONS, we use POS tags from the CoreNLP annotations released with the dataset and map them to vector representations. The final representation for a word is the concatenation of the vectors above. A bidirectional LSTM <ref type="bibr" target="#b21">(Hochreiter and Schmidhuber, 1997)</ref> is then used to obtain a contextual representation l i for the i th word.</p><p>A table is represented by a set of columns. Each column is encoded by averaging the embeddings of words under its column name. We also have a column type feature (i.e., number, date, or string) and an indicator feature signaling whether at least one entity in the column appears in the utterance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Generating Abstract Programs</head><p>Instead of extracting abstract programs as templates, similarly to <ref type="bibr" target="#b1">Xu et al. (2017)</ref> and Catherine Finegan-Dollak and Radev (2018), we generate them with a seq2seq model. Although templatebased approaches would be more efficient in practice, a seq2seq model is more general since it could generate unseen abstract programs which fixed templates could not otherwise handle.</p><p>Our goal here is to generate a sequence of production rules that lead to abstract programs. During decoding, the hidden state g j of the jth timestep is computed based on the previous production rule, which is mapped to an embedding a j−1 . We also incorporate an attention mechanism <ref type="bibr" target="#b31">(Luong et al., 2015)</ref> to compute a contextual vector b j . Finally, a score vector s j is computed by feeding the concatenation of the hidden state and context vector to a multilayer perceptron (MLP):</p><formula xml:id="formula_5">g j = LSTM(g j−1 , a j−1 ) b j = Attention(g j , l) s j = MLP 1 ([g j ; b j ]) p(a j |x, t, a &lt;j ) = softmax a j (s j )<label>(3)</label></formula><p>where the probability of production rule a j is computed by the softmax function. According to our abstract grammar, only a subset of production rules will be valid at the j-th time step. For instance, in <ref type="figure">Figure 2</ref>, production rule "STRING → select" will only expand to rules whose left-hand side is ROW, which is the type of the first argument of select. In this case, the next production rule is "ROW → first". We thus restrict the normalization of softmax to only focus on these valid production rules. The probability of generating an abstract program p(h|x, t) is simply the product of the probability of predicting each production rule j p(a j |x, t, a &lt;j ).</p><p>After an abstract program is generated, we need to instantiate slots in abstract programs. Our model first encodes the abstract program using a bi-directional LSTM. As a result, the representation of a slot is contextually aware of the entire abstract program .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Instantiating Abstract Programs</head><p>To instantiate an abstract program, each slot must obtain its specific semantics from the question. We model this process by an alignment model which learns the correspondence between slots and question spans. Formally, we use a binary alignment matrix A with size m × n × n, where m is the number of slots and n is the number of tokens. In <ref type="figure">Figure 1</ref>, the alignment matrix will only have A 0,6,8 = 1 and A 1,2,3 = 1 which indicates that the first slot is aligned with "nation of Turkey", and the second slot is aligned with "silver medals". The second and third dimension of the matrix represent the start and end position of a span.</p><p>We model alignments as discrete latent variables and condition the instantiation process on the alignments as follows:</p><formula xml:id="formula_6">[z]=d p(z|x, t, h) = A p(A|x, t, h) [z]=d p(z|x, t, h, A).<label>(4)</label></formula><p>We will first discuss the instantiation model p(z|x, t, h, A) and then elaborate on how to avoid marginalization in the next section. Each slot in an abstract program can be instantiated by a set of candidates following the instantiation grammar. For efficiency, we use local classifiers to model the instantiation of each slot independently:</p><formula xml:id="formula_7">p(z|x, t, h, A) = s∈S p(s → c|x, t, h, A), (5)</formula><p>where S is the set of slots and c is a candidate following our instantiation grammar. "s → c" represents the instantiation of slot s into candidate c.</p><p>Recall that there are two types of slots, one for rows and one for columns. All column names in the table are potential instantiations of column slots. We represent each column slot candidate by the average of the embeddings of words in the column name. Based on our instantiation grammar in Section 2.1, candidates for row slots are represented as follows: 1) each condition is represented with the concatenation of the representations of a column, an operator, and a value. For each slot, the probability of generating a candidate is computed with softmax normalization on a score function:</p><formula xml:id="formula_8">p(s → c|x, t, h, A) ∝ exp{MLP([s; c])}, (6)</formula><p>where s is the representation of the span that slot s is aligned with, and c is the representation of candidate c. The representations s and c are concatenated and fed to a MLP. We use the same MLP architecture but different parameters for column and row slots.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Structured Attention</head><p>We first formally define a few structural constraints over alignments and then explain how to incorporate them efficiently into our parser.</p><p>The intuition behind our alignment model is that row and column selection operations represent distinct semantics, and should therefore be expressed by distinct natural language expressions. Hence, we propose the following constraints:</p><p>Unique Span In most cases, the semantics of a row selection or a column selection is expressed uniquely with a single contiguous span:</p><formula xml:id="formula_9">∀k ∈ [1, |S|], i,j A k,i,j = 1,<label>(7)</label></formula><p>where |S| is the number of slots.</p><p>No Overlap Spans aligned to different slots should not overlap. Formally, at most one span that contains word i can be aligned to a slot:</p><formula xml:id="formula_10">∀i ∈ [1, n], k,j A k,i,j ≤ 1.<label>(8)</label></formula><p>As an example, the alignments in <ref type="figure">Figure 1</ref> follow the above constraints. Intuitively, the oneto-one mapping constraint aims to assign distinct and non-overlapping spans to slots of abstract programs. To further bias the alignments and improve efficiency, we impose additional restrictions: (1) a row slot must be aligned to a span that contains an entity since conditions that instantiate the slot would require entities for filtering; (2) a column slot must be aligned to a span with length 1 since most column names only have one word.</p><p>Marginalizing out all A in Equation (4) would be very expensive considering the exponential number of possible alignments. We approximate the marginalization by moving the outside expectation directly inside over A. As a result, we instead optimize the following objective: <ref type="bibr">(9)</ref> where E[A] are the marginals of A with respect to p <ref type="figure">(A|x, t, h)</ref>.</p><formula xml:id="formula_11">J ≈ log h∈H t p(h|x, t) [[z]]=d p(z|x, t, h, E[A]) ,</formula><p>The idea of using differentiable surrogates for discrete latent variables has been used in many other works like differentiable data structures <ref type="bibr" target="#b17">(Grefenstette et al., 2015;</ref><ref type="bibr" target="#b16">Graves et al., 2014)</ref> and attention-based networks <ref type="bibr" target="#b8">(Bahdanau et al., 2015;</ref><ref type="bibr" target="#b24">Kim et al., 2017)</ref>. Using marginals E[A] can be viewed as structured attention between slots and question spans.</p><p>The marginal probability of the alignment matrix A can be computed efficiently using dynamic programming (see <ref type="bibr">Täckström et al. 2015 for details)</ref>. An alignment is encoded into a path in a weighted lattice where each vertex has 2 |S| states to keep track of the set of covered slots. The marginal probability of edges in this lattice can be computed by the forward-backward algorithm <ref type="bibr" target="#b44">(Wainwright et al., 2008)</ref>. The lattice weights, represented by a scoring matrix M ∈ R m×n×n for all possible slot-span pairs, are computed using the following scoring function:</p><formula xml:id="formula_12">M k,i,j = MLP 2 ([r(k); span[i : j]]),<label>(10)</label></formula><p>where r(k) represents the k th slot and span[i : j] represents the span from word i to j. Recall that we obtain r(k) by encoding a generated abstract program. A span is represented by averaging the representations of the words therein. These two representations are concatenated and fed to a MLP to obtain a score. Since E[A] is not discrete anymore, the aligned representation of slot s in Equation (6) becomes the weighted average of representations of all spans in the set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We evaluated our model on two semantic parsing benchmarks, WIKITABLEQUESTIONS and WIK-ISQL. We compare against two common baselines to demonstrate the effectiveness of using abstract programs and alignment. We also conduct detailed analysis which shows that structured attention is highly beneficial, enabling our parser to differentiate between correct and spurious programs. Finally, we break down the errors of our parser so as to examine whether structured attention is better at instantiating abstract programs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Setup</head><p>Datasets WIKITABLEQUESTIONS contains 2,018 tables and 18,496 utterance-denotation pairs. The dataset is challenging as 1) the tables cover a wide range of domains and unseen tables appear at test time; and 2) the questions involve a variety of operations such as superlatives, comparisons, and aggregation <ref type="bibr" target="#b35">(Pasupat and Liang, 2015)</ref>. WIKISQL has 24,241 tables and 80,654 utterance-denotation pairs. The questions are logically simpler and only involve aggregation, column selection, and conditions. The original dataset is annotated with SQL queries, but we only use the execution result for training. In both datasets, tables are extracted from Wikipedia and cover a wide range of domains.</p><p>Entity extraction is important during parsing since entities are used as values in filter conditions during instantiation. String entities are extracted by string matching utterance spans and table cells. In WIKITABLEQUESTIONS, numbers and dates are extracted from the CoreNLP annotations released with the dataset. WIKISQL does not have entities for dates, and we use string-based normalization to deal with numbers.</p><p>Implementation We obtained word embeddings by a linear projection of GloVe pre-trained embeddings <ref type="bibr" target="#b37">(Pennington et al., 2014)</ref> which were fixed during training. Attention scores were computed based on the dot product between two vectors. Each MLP is a one-hidden-layer perceptron with ReLU as the activation function. Dropout <ref type="bibr" target="#b40">(Srivastava et al., 2014)</ref> was applied to prevent overfitting. All models were trained with Adam (Kingma and Ba, 2015). Implementations of abstract and instantiation grammars were based on AllenNLP . 5</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Baselines</head><p>Aside from comparing our model against previously published approaches, we also implemented the following baselines:</p><p>Typed Seq2Seq Programs were generated using a sequence-to-sequence model with attention <ref type="bibr" target="#b12">(Dong and Lapata, 2016)</ref>. Similarly to <ref type="bibr" target="#b26">Krishnamurthy et al. (2017)</ref>, we constrained the decod-Supervised by Denotations Dev. Test <ref type="bibr" target="#b35">Pasupat and Liang (2015)</ref> 37.0 37.1 <ref type="bibr" target="#b33">Neelakantan et al. (2017)</ref> 34. ing process so that only well-formed programs are predicted. This baseline can be viewed as merging the two stages of our model into one stage where generation of abstract programs and their instantiations are performed with a shared decoder.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Standard Attention</head><p>The aligned representation of slot s in Equation <ref type="formula">(6)</ref> is computed by a standard attention mechanism: s = Attention(r(s), l) where r(s) is the representation of slot s from abstract programs. Each slot is aligned independently with attention, and there are no global structural constraints on alignments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Main Results</head><p>For all experiments, we report the mean accuracy of 5 runs. Results on WIKITABLEQUESTIONS are shown in <ref type="table">Table 1</ref>. The structured-attention model achieves the best performance, compared against the two baselines and previous approaches. The standard attention baseline with abstract programs is superior to the typed Seq2Seq model, demonstrating the effectiveness of decomposing semantic parsing into two stages. Results on WIKISQL are shown in <ref type="table" target="#tab_2">Table 2</ref>. The structured-attention model is again superior to our two baseline models. Interestingly, its performance surpasses previously reported weakly-supervised models <ref type="bibr" target="#b28">(Liang et al., 2018;</ref><ref type="bibr">Agarwal et al., 2019)</ref> and is on par even with fully supervised ones .</p><p>The gap between the standard attention baseline and the typed Seq2Seq model is not very large on WIKISQL, compared to WIKITABLE-QUESTIONS. Recall from Section 2.2 that WIK-Supervised by Denotations Dev. Test <ref type="bibr" target="#b28">Liang et al. (2018)</ref> 72.  ISQL only has 6 abstract programs that can be successfully instantiated. For this reason, our decomposition alone may not be very beneficial if coupled with standard attention. In contrast, our structured-attention model consistently performs much better than both baselines. We report scores of ensemble systems in <ref type="table" target="#tab_4">Table 3</ref>. We use the best model which relies on abstract programs and structured attention as a base model in our ensemble. Our ensemble system achieves better performance than <ref type="bibr" target="#b28">Liang et al. (2018)</ref> and <ref type="bibr">Agarwal et al. (2019)</ref>, while using the same ensemble size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Analysis of Spuriousness</head><p>To understand how well structured attention can help a parser differentiate between correct and spurious programs, we analyzed the posterior distribution of consistent programs given a denota-</p><formula xml:id="formula_13">tion: p(z|x, t, d) where [[z]] = d.</formula><p>WIKISQL includes gold-standard SQL annotations, which we do not use in our experiments but exploit here for analysis. Specifically, we converted the annotations released with WIKISQL to programs licensed by our grammar. We then computed the log-probability of these programs according to the posterior distribution as a measure of how well a parser can identify them amongst all consistent programs log z * p(z * |x, t, d), where z * denotes correct programs. The average log-   probability assigned to correct programs by structured and standard attention is -0.37 and -0.85, respectively. This gap confirms that structured attention can bias our parser towards correct programs during learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Error Analysis</head><p>We further manually inspected the output of our structured-attention model and the standard attention baseline in WIKITABLEQUESTIONS. Specifically, we randomly sampled 130 error cases independently from both models and classified them into three categories.</p><p>Abstraction Errors If a parser fails to generate an abstract program, then it is impossible for it to instantiate a consistent complete program.</p><p>Instantiation Errors These errors arise when abstract programs are correctly generated, but are mistakenly instantiated either by incorrect column names or filter conditions.</p><p>Coverage Errors These errors arise from implicit assumptions made by our parser: a) there is a long tail of unsupported operations that are not covered by our abstract programs; b) if entities are not correctly identified and linked, abstract programs cannot be correctly instantiated. <ref type="table" target="#tab_5">Table 4</ref> shows the proportion of errors attested by the two attention models. We observe that structured attention suffers less from instantiation errors compared against the standard attention baseline, which points to the benefits of the structured alignment model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Neural Semantic Parsing</head><p>We follow the line of work that applies sequence-to-sequence models  to semantic parsing <ref type="bibr" target="#b23">(Jia and Liang, 2016;</ref><ref type="bibr" target="#b12">Dong and Lapata, 2016)</ref>. Our work also relates to models which enforce type constraints <ref type="bibr" target="#b48">(Yin and Neubig, 2017;</ref><ref type="bibr" target="#b38">Rabinovich et al., 2017;</ref><ref type="bibr" target="#b26">Krishnamurthy et al., 2017)</ref> so as to restrict the vast search space of potential programs. We use both methods as baselines to show that the structured bias introduced by our model can help our parser handle spurious programs in the setting of learning from denotations. Note that our alignment model can also be applied in the supervised case in order to help the parser rule out incorrect programs.</p><p>Earlier work has used lexicon mappings <ref type="bibr" target="#b51">(Zettlemoyer and Collins, 2007;</ref><ref type="bibr" target="#b46">Wong and Mooney, 2007;</ref><ref type="bibr" target="#b30">Lu et al., 2008;</ref><ref type="bibr" target="#b27">Kwiatkowski et al., 2010)</ref> to model correspondences between programs and natural language. However, these methods cannot generalize to unseen tables where new relations and entities appear. To address this issue, <ref type="bibr" target="#b35">Pasupat and Liang (2015)</ref> propose a floating parser which allows partial programs to be generated without being anchored to question tokens. In the same spirit, we use a sequence-to-sequence model to generate abstract programs while relying on explicit alignments to instantiate them. Besides semantic parsing, treating alignments as discrete latent variables has proved effective in other tasks like sequence transduction <ref type="bibr" target="#b49">(Yu et al., 2016)</ref> and AMR parsing <ref type="bibr" target="#b32">(Lyu and Titov, 2018)</ref>.</p><p>Learning from Denotations To improve the efficiency of searching for consistent programs, <ref type="bibr" target="#b53">Zhang et al. (2017)</ref> use a macro grammar induced from cached consistent programs. Unlike <ref type="bibr" target="#b53">Zhang et al. (2017)</ref> who abstract entities and relations from logical forms, we take a step further and abstract the computation of row and column selection. Our work also differs from <ref type="bibr" target="#b36">Pasupat and Liang (2016)</ref> who resort to manual annotations to alleviate spuriousness. Instead, we equip our parser with an inductive bias to rule out spurious programs during training. Recently, reinforcement learning based methods address the computational challenge by using a memory buffer <ref type="bibr" target="#b28">(Liang et al., 2018)</ref> which stores consistent programs and an auxiliary reward function <ref type="bibr">(Agarwal et al., 2019)</ref> which provides feedback to deal with spurious programs. <ref type="bibr" target="#b18">Guu et al. (2017)</ref> employ vari-ous strategies to encourage even distributions over consistent programs in cases where the parser has been misled by spurious programs. <ref type="bibr" target="#b11">Dasigi et al. (2019)</ref> use coverage of lexicon-like rules to guide the search of consistent programs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>In this paper, we proposed a neural semantic parser that learns from denotations using abstract programs and latent structured alignments. Our parser achieves state-of-the-art performance on two benchmarks, WIKITABLEQUESTIONS and WIKISQL. Empirical analysis shows that the inductive bias introduced by the alignment model helps our parser differentiate between correct and spurious programs. Alignments can exhibit different properties (e.g., monotonicity or bijectivity), depending on the meaning representation language (e.g., logical forms or SQL), the definition of abstract programs, and the domain at hand. We believe that these properties can be often captured within a probabilistic alignment model and hence provide a useful inductive bias to the parser.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>For instance, condition "string column:nation = Turkey" in Figure 1 is represented by vector representations of the column 'nation', the operator '=', and the entity 'Turkey'; 2) multiple conditions are encoded by averaging the representations of all conditions and adding a vector representation of AND /OR to indicate the relation between them.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Results on WIKISQL. f.w.: slots filled with.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Results of ensembled models on the test set; ensemble sizes are shown within parentheses.</figDesc><table><row><cell>Error Types</cell><cell cols="2">standard structured</cell></row><row><cell>Abstraction Error</cell><cell>19.2</cell><cell>20.0</cell></row><row><cell>Instantiation Error</cell><cell>41.5</cell><cell>36.2</cell></row><row><cell>Coverage Error</cell><cell>39.2</cell><cell>43.8</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Proportion of errors on the development set in WIKITABLEQUESTIONS.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">The first program can be paraphrased as: find the row with the largest number of silver medals and then select the number of silver medals from the previous row.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Our code is available at https://github.com/ berlino/weaksp_em19.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">We also extend their grammar to additionally support operations of conjunction and disjunction. More details are provided in the Appendix.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">Please refer to the Appendix for the full list of hyperparameters used in our experiments.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We would like to thank the anonymous reviewers for their valuable comments. We gratefully acknowledge the support of the European Research Council (Titov: ERC StG BroadSem 678254; Lapata: ERC CoG TransModal 681760) and the Dutch National Science Foundation (NWO VIDI 639.022.518).</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Grammars</head><p>We created our grammars following <ref type="bibr" target="#b53">Zhang et al. (2017)</ref> and <ref type="bibr" target="#b28">Liang et al. (2018)</ref>. Compared with <ref type="bibr" target="#b28">Liang et al. (2018)</ref>, we additionally support disjunction(OR) and conjunction <ref type="bibr">(AND)</ref>. Some functions are pruned based on their effect on coverage, which is the proportion of questions that obtain at least one consistent program. "same as" function <ref type="bibr" target="#b28">(Liang et al., 2018)</ref> is excluded since it introduces too many spurious programs while contributing little to the coverage. For the same reason, conjunction(AND) is not used in WIKITABLEQUES-TIONS and disjunction(OR) is not used in WIK-ISQL.</p><p>We also include non-terminals of function types in production rules <ref type="bibr" target="#b26">(Krishnamurthy et al., 2017)</ref>. For instance, function "ROW → first(LIST[ROW])" selects the first row from a list of rows and will lead to the production rule "ROW → first". In the paper, we eliminate the function type for simplicity. Practically, we use two production rules to represent the function: ROW → &lt;ROW: LIST[ROW] &gt; and &lt;ROW:LIST[ROW]&gt; → first , where &lt; ROW: LIST[ROW] &gt; is an abstract function type.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Search for Consistent Programs</head><p>We enumerate all possible programs in two stages using the abstract and instantiation grammars. To constrain the space and make the search process tractable, we restrict the maximal number of production rules for generating abstract programs during the first stage. It is based on the observation that the abstract programs which can be successfully instantiated into correct programs are usually not very complex. In other words, the consistent programs that are instantiated by long abstract programs are very likely to be spurious. For instance, programs like "select( previous( next( previous(argmax [all rows], column:silver) column:bronze)" are unlikely to have a corresponding question. Specifically, we set the maximal number of production rules for generating abstract programs to 6 and 9, which leads to search time of around 7 and 10 hours for WIKISQL and WIKITABLEQUES-TIONS respectively, using a single CPU. Note that this needs to be done only once.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Hyperparameters</head><p>Models used in WIKITABLEQUESTIONS and WIKISQL share similar hyperparameters which are listed in <ref type="table">Table 5</ref>. Our input embeddings are obtained by a linear projection from the fixed pre-trained embedding <ref type="bibr" target="#b37">(Pennington et al., 2014)</ref>. Word Indicator refers to the indicator feature of whether a word appears in the table; Column Indicator refers to the indicator feature of whether at least one entity in a column appears in the question. All MLPs mentioned in the paper have the  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Alignments</head><p>If a row slot is instantiated with the special condition 'all rows', then it is possible that the semantics of this slot is implicit. For instance, the question "which driver completed the least number of laps? " should first be mapped to the abstract program "select (argmin (#row slot, #column slot), #column slot )" which is then instantiated to the correct program "select (argmin (all rows, column:laps) column:driver)". The row slot in the abstract program is instantiated with 'all rows', but this is not explicitly expressed in the question.</p><p>To make it compatible with our constraints in Equation <ref type="formula">(6)</ref> and <ref type="formula">(7)</ref>, we add a special token "ALL ROW" at the end of each question. If a row slot is aligned with this token, then it is expected to be instantiated with the special condition 'all rows'. Specifically, this special token is mapped to a learnable vector during instantiations. Our alignment needs to learn to align this special token with a row slot if this row slot should be instantiated with the condition 'all rows'.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="67" to="68" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xu</surname></persName>
		</author>
		<idno>68.0</idno>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page">69</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Huang</surname></persName>
		</author>
		<idno>3 68.0</idno>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page">68</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename></persName>
		</author>
		<idno>74.5 73.5</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="75" to="76" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lapata</forename><surname>Dong</surname></persName>
		</author>
		<idno>79.0 78.5</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shi</surname></persName>
		</author>
		<idno>84.0 83.7</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Learning to generalize from sparse and underspecified rewards</title>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICML</title>
		<editor>References Rishabh Agarwal, Chen Liang, Dale Schuurmans, and Mohammad Norouzi</editor>
		<meeting>of ICML</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICLR</title>
		<meeting>of ICLR</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Semantic parsing on freebase from question-answer pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Frostig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Improving text-to-sql evaluation methodology</title>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<editor>Li Zhang Karthik Ramanathan Sesh Sadasivam Rui Zhang Catherine Finegan-Dollak, Jonathan K. Kummerfeld and Dragomir Radev</editor>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Iterative search for weakly supervised semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pradeep</forename><surname>Dasigi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shikhar</forename><surname>Murty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NAACL</title>
		<meeting>of NAACL</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Language to logical form with neural attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Coarse-to-fine decoding for neural semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Grus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oyvind</forename><surname>Tafjord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pradeep</forename><surname>Dasigi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nelson</forename><forename type="middle">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Schmitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><forename type="middle">S</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<title level="m">Allennlp: A deep semantic natural language processing platform</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Weakly supervised semantic parsing with abstract examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Goldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veronica</forename><surname>Latcinnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehud</forename><surname>Nave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Globerson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Wayne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivo</forename><surname>Danihelka</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1410.5401</idno>
		<title level="m">Neural turing machines</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning to transduce with unbounded memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><forename type="middle">Moritz</forename><surname>Hermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mustafa</forename><surname>Suleyman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NeurIPS</title>
		<meeting>of NeurIPS</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1828" to="1836" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">From language to programs: Bridging reinforcement learning and maximum marginal likelihood</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kelvin</forename><surname>Guu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Panupong</forename><surname>Pasupat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><forename type="middle">Zheran</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Neural multi-step reasoning for question answering on semi-structured tables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Till</forename><surname>Haug</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Octavian-Eugen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paulina</forename><surname>Ganea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Grnarova</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ECIR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Decoupling structure and lexicon for zero-shot semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Herzig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Natural language to structured query generation via meta-learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Po-Sen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenglong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rishabh</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Tau Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NAACL</title>
		<meeting>of NAACL</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Data recombination for neural semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robin</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Structured attention networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Denton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luong</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander M</forename><surname>Rush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICLR</title>
		<meeting>of ICLR</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICLR</title>
		<meeting>of ICLR</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Neural semantic parsing with type constraints for semi-structured tables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jayant</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pradeep</forename><surname>Dasigi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Inducing probabilistic ccg grammars from logical form with higherorder unification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
	<note>Sharon Goldwater, and Mark Steedman</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Memory augmented policy optimization for program synthesis and semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ni</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NeurIPS</title>
		<meeting>of NeurIPS</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Learning dependency-based compositional semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A generative model for parsing natural language to meaning representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wee</forename><surname>Hwee Tou Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><forename type="middle">S</forename><surname>Sun Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Effective approaches to attentionbased neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Amr parsing as graph prediction with latent alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunchuan</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Titov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Learning a natural language interface with neural programmer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arvind</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dario</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Amodei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICLR</title>
		<meeting>of ICLR</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Learning to infer program sketches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxwell</forename><surname>Nye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Hewitt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armando</forename><surname>Solar-Lezama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICML</title>
		<meeting>of ICML</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Compositional semantic parsing on semi-structured tables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Pasupat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Inferring logical forms from denotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Panupong</forename><surname>Pasupat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Abstract syntax networks for code generation and semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Rabinovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitchell</forename><surname>Stern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianze</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kedar</forename><surname>Tatwawadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaushik</forename><surname>Chakrabarti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleksandr</forename><surname>Polozov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weizhu</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.05054</idno>
		<title level="m">Incsql: Training incremental text-to-sql parsers with non-deterministic oracles</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Dropout: a simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Semantic parsing with syntaxand table-aware sql generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yibo</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duyu</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianshu</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guihong</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaocheng</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NeurIPS</title>
		<meeting>of NeurIPS</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Efficient inference and structured learning for semantic role labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oscar</forename><surname>Täckström</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuzman</forename><surname>Ganchev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Graphical models, exponential families, and variational inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations and Trends R in Machine Learning</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="1" to="305" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Pointing out SQL queries from text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenglong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Brockschmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rishabh</forename><surname>Singh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>MSR</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Learning synchronous grammars for semantic parsing with lambda calculus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuk</forename><forename type="middle">Wah</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawn</forename><surname>Song</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.04436</idno>
		<title level="m">Sqlnet: Generating structured queries from natural language without reinforcement learning</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">A syntactic neural model for general-purpose code generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengcheng</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Online segment to segment neural transduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Buys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Typesql: Knowledge-based type-aware neural text-to-sql generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zifan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zilin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Radev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NAACL</title>
		<meeting>of NAACL</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Online learning of relaxed ccg grammars for parsing to logical form</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP/CoNLL</title>
		<meeting>of EMNLP/CoNLL</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Learning to map sentences to logical form: structured classification with probabilistic categorial grammars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Luke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of UAI</title>
		<meeting>of UAI</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Macro grammars and holistic triggering for efficient semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuchen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Panupong</forename><surname>Pasupat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Seq2sql: Generating structured queries from natural language using reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<idno>abs/1709.00103</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
