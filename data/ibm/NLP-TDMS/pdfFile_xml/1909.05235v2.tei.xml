<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SoftTriple Loss: Deep Metric Learning Without Triplet Sampling</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Qian</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Alibaba Group</orgName>
								<address>
									<postCode>98004</postCode>
									<settlement>Bellevue</settlement>
									<region>WA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Shang</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Alibaba Group</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baigui</forename><surname>Sun</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Alibaba Group</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juhua</forename><surname>Hu</surname></persName>
							<email>juhuah@uw.edu</email>
							<affiliation key="aff2">
								<orgName type="department">School of Engineering and Technology</orgName>
								<orgName type="institution">University of Washington</orgName>
								<address>
									<postCode>98402</postCode>
									<settlement>Tacoma</settlement>
									<region>WA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Li</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Alibaba Group</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rong</forename><surname>Jin</surname></persName>
							<email>jinrong.jr@alibaba-inc.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Alibaba Group</orgName>
								<address>
									<postCode>98004</postCode>
									<settlement>Bellevue</settlement>
									<region>WA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">SoftTriple Loss: Deep Metric Learning Without Triplet Sampling</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T08:39+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Distance metric learning (DML) is to learn the embeddings where examples from the same class are closer than examples from different classes. It can be cast as an optimization problem with triplet constraints. Due to the vast number of triplet constraints, a sampling strategy is essential for DML. With the tremendous success of deep learning in classifications, it has been applied for DML. When learning embeddings with deep neural networks (DNNs), only a mini-batch of data is available at each iteration. The set of triplet constraints has to be sampled within the mini-batch. Since a mini-batch cannot capture the neighbors in the original set well, it makes the learned embeddings sub-optimal. On the contrary, optimizing SoftMax loss, which is a classification loss, with DNN shows a superior performance in certain DML tasks. It inspires us to investigate the formulation of SoftMax. Our analysis shows that SoftMax loss is equivalent to a smoothed triplet loss where each class has a single center. In real-world data, one class can contain several local clusters rather than a single one, e.g., birds of different poses. Therefore, we propose the SoftTriple loss to extend the SoftMax loss with multiple centers for each class. Compared with conventional deep metric learning algorithms, optimizing SoftTriple loss can learn the embeddings without the sampling phase by mildly increasing the size of the last fully connected layer. Experiments on the benchmark fine-grained data sets demonstrate the effectiveness of the proposed loss function. Code is available at</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Distance metric learning (DML) has been extensively studied in the past decades due to its broad range of applications, e.g., k-nearest neighbor classification <ref type="bibr" target="#b28">[29]</ref>, image retrieval <ref type="bibr" target="#b23">[24]</ref> and clustering <ref type="bibr" target="#b30">[31]</ref>. With an appropriate FC in SoftMax FC in SoftTriple <ref type="figure">Figure 1</ref>. Illustration of the proposed SoftTriple loss. In conventional SoftMax loss, each class has a representative center in the last fully connected layer. Examples in the same class will be collapsed to the same center. It may be inappropriate for the realworld data as illustrated. In contrast, SoftTriple loss keeps multiple centers (e.g., 2 centers per class in this example) in the fully connected layer and each image will be assigned to one of them. It is more flexible for modeling intra-class variance in real-world data sets.</p><p>distance metric, examples from the same class should be closer than examples from different classes. Many algorithms have been proposed to learn a good distance metric <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b28">29]</ref>. In most of conventional DML methods, examples are represented by hand-crafted features, and DML is to learn a feature mapping to project examples from the original feature space to a new space. The distance can be computed as the Mahalanobis distance <ref type="bibr" target="#b10">[11]</ref> </p><formula xml:id="formula_0">dist M (x i , x j ) = (x i − x j ) M (x i − x j )</formula><p>where M is the learned distance metric. With this formulation, the main challenge of DML is from the dimensionality of input space. As a metric, the learned matrix M has to be positive semi-definite (PSD) while the cost of keeping the matrix PSD can be up to O(d 3 ), where d is the dimensionality of original features. The early work directly applies PCA to shrink the original space <ref type="bibr" target="#b28">[29]</ref>. Later, various strategies are developed to reduce the computational cost <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17]</ref>.</p><p>Those approaches can obtain the good metric from the input features, but the hand-crafted features are task independent and may cause the loss of information, which limits the performance of DML. With the success of deep neural networks in classification <ref type="bibr" target="#b6">[7]</ref>, researchers consider to learn the embeddings directly from deep neural networks <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b20">21]</ref>. Without the explicit feature extraction, deep metric learning boosts the performance by a large margin <ref type="bibr" target="#b20">[21]</ref>. In deep metric learning, the dimensionality of input features is no longer a challenge since neural networks can learn low-dimensional features directly from raw materials, e.g., images, documents, etc. In contrast, generating appropriate constraints for optimization becomes challenging for deep metric learning.</p><p>It is because most of deep neural networks are trained with the stochastic gradient descent (SGD) algorithm and only a mini-batch of examples are available at each iteration. Since embeddings are optimized with the loss defined on an anchor example and its neighbors (e.g., the active set of pairwise <ref type="bibr" target="#b30">[31]</ref> or triplet <ref type="bibr" target="#b28">[29]</ref> constraints), the examples in a mini-batch may not be able to capture the overall neighborhood well, especially for relatively large data sets. Moreover, a mini-batch contains O(m 2 ) pairs and O(m 3 ) triplets, where m is the size of the mini-batch. An effective sampling strategy over the mini-batch is essential even for a small batch (e.g., 32) to learn the embeddings efficiently. Many efforts have been devoted to studying sampling an informative mini-batch <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b20">21]</ref> and sampling triplets within a mini-batch <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b23">24]</ref>. Some work also tried to reduce the total number of triplets with proxies <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b17">18]</ref>. The sampling phase for the mini-batch and constraints not only loses the information but also makes the optimization complicated. In this work, we consider to learn embeddings without constraints sampling.</p><p>Recently, researches have shown that embeddings obtained directly from optimizing SoftMax loss, which is proposed for classification, perform well on the simple distance based tasks <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b29">30]</ref> and face recognition <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b27">28]</ref>. It inspires us to investigate the formulation of SoftMax loss. Our Analysis demonstrates that SoftMax loss is equivalent to a smoothed triplet loss. By providing a single center for each class in the last fully connected layer, the triplet constraint derived by SoftMax loss can be defined on an original example, its corresponding center and a center from a different class. Therefore, embeddings obtained by optimizing SoftMax loss can work well as a distance metric. However, a class in real-world data can consist of multiple local clusters as illustrated in <ref type="figure">Fig. 1</ref> and a single center is insufficient to capture the inherent structure of the data. Consequently, embeddings learned from SoftMax loss can fail in the complex scenario <ref type="bibr" target="#b21">[22]</ref>.</p><p>In this work, we propose to improve SoftMax loss by introducing multiple centers for each class and the novel loss is denoted as SoftTriple loss. Compared with a single center, multiple ones can capture the hidden distribution of the data better due to the fact that they help to reduce the intra-class variance. This property is also crucial to reserve the triplet constraints over original examples while training with multiple centers. Compared with existing deep DML methods, the number of triplets in SoftTriple is linear in the number of original examples. Since the centers are encoded in the last fully connected layer, SoftTriple loss can be optimized without sampling triplets. <ref type="figure">Fig. 1</ref> illustrates the proposed SoftTriple loss. Apparently, SoftTriple loss has to determine the number of centers for each class. To alleviate this issue, we develop a strategy that sets a sufficiently large number of centers for each class at the beginning and then applies L 2,1 norm to obtain a compact set of centers. We demonstrate the proposed loss on the fine-grained visual categorization tasks, where capturing local clusters is essential for good performance <ref type="bibr" target="#b16">[17]</ref>.</p><p>The rest of this paper is organized as follows. Section 2 reviews the related work of conventional distance metric learning and deep metric learning. Section 3 analyzes the SoftMax loss and proposes the SoftTriple loss accordingly. Section 4 conducts comparisons on benchmark data sets. Finally, Section 5 concludes this work and discusses future directions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Distance metric learning Many DML methods have been developed when input features are provided <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b30">31]</ref>. The dimensionality of input features is a critical challenge for those methods due to the PSD projection, and many strategies have been proposed to alleviate it. The most straightforward way is to reduce the dimension of input space by PCA <ref type="bibr" target="#b28">[29]</ref>. However, PCA is task independent and may hurt the performance of learned embeddings. Some works try to reduce the number of valid parameters with the low-rank assumption <ref type="bibr" target="#b7">[8]</ref>. <ref type="bibr" target="#b15">[16]</ref> decreases the computational cost by reducing the number of PSD projections. <ref type="bibr" target="#b16">[17]</ref> proposes to learn the dual variables in the low-dimensional space introduced by random projections and then recover the metric in the original space. After addressing the challenge from the dimensionality, the hand-crafted features become the bottleneck of performance improvement.</p><p>The forms of constraints for metric learning are also developed in these methods. Early work focuses on optimizing pairwise constraints, which require the distances between examples from the same class small while those from different classes large <ref type="bibr" target="#b30">[31]</ref>. Later, <ref type="bibr" target="#b28">[29]</ref> develops the triplet constraints, where given an anchor example, the distance between the anchor point and a similar example should be smaller than that between the anchor point and a dissimilar example by a large margin. It is obvious that the number of pairwise constraints is O(n 2 ) while that of triplet constraints can be up to O(n 3 ), where n is the number of original examples. Compared with the pairwise constraints, triplet constraints optimize the geometry of local cluster and are more applicable for modeling intra-class variance. In this work, we will focus on the triplet constraints.</p><p>Deep metric learning Deep metric learning aims to learn the embeddings directly from the raw materials (e.g., images) by deep neural networks <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b20">21]</ref>. With the task dependent embeddings, the performance of metric learning has a dramatical improvement. However, most of deep models are trained with SGD that allows only a mini-batch of data at each iteration. Since the size of mini-batch is small, the information in it is limited compared to the original data. To alleviate this problem, algorithms have to develop an effective sampling strategy to generate the minibatch and then sample triplet constraints from it. A straightforward way is increasing the size of mini-batch <ref type="bibr" target="#b20">[21]</ref>. However, the large mini-batch will suffer from the GPU memory limitation and can also increase the challenge of sampling triplets. Later, <ref type="bibr" target="#b18">[19]</ref> proposes to generate the minibatch from neighbor classes. Besides, there are various sampling strategies for obtaining constraints <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b23">24]</ref>. <ref type="bibr" target="#b20">[21]</ref> proposes to sample the semi-hard negative examples. <ref type="bibr" target="#b23">[24]</ref> adopts all negative examples within the margin for each positive pair. <ref type="bibr" target="#b11">[12]</ref> develops distance weighted sampling that samples examples according to the distance from the anchor example. <ref type="bibr" target="#b2">[3]</ref> selects hard triplets with a dynamic violate margin from a hierarchical class-level tree. However, all of these strategies may fail to capture the distribution of the whole data set. Moreover, they make the optimization in deep DML complicated.</p><p>Learning with proxies Recently, some researchers consider to reduce the total number of triplets to alleviate the challenge from the large number of triplets. <ref type="bibr" target="#b13">[14]</ref> constructs the triplet loss with one original example and two proxies. Since the number of proxies is significantly less than the number of original examples, proxies can be kept in the memory that help to avoid the sampling over different batches. However, it only provides a single proxy for each class when label information is available, which is similar to SoftMax. <ref type="bibr" target="#b17">[18]</ref> proposes a conventional DML algorithm to construct the triplet loss only with latent examples, which assigns multiple centers for each class and further reduces the number of triplets. In this work, we propose to learn the embeddings by optimizing the proposed SoftTriple loss to eliminate the sampling phase and capture the local geometry of each class simultaneously.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">SoftTriple Loss</head><p>In this section, we first introduce the SoftMax loss and the triplet loss and then study the relationship between them to derive the SoftTriple loss.</p><p>Denote the embedding of the i-th example as x i and the corresponding label as y i , then the conditional probability output by a deep neural network can be estimated via the SoftMax operator</p><formula xml:id="formula_1">Pr(Y = y i |x i ) = exp(w yi x i ) C j exp(w j x i )</formula><p>where [w 1 , · · · , w C ] ∈ R d×C is the last fully connected layer. C denotes the number of classes and d is the dimension of embeddings. The corresponding SoftMax loss is</p><formula xml:id="formula_2">SoftMax (x i ) = − log exp(w yi x i ) j exp(w j x i )</formula><p>A deep model can be learned by minimizing losses over examples. This loss has been prevalently applied for classification task <ref type="bibr" target="#b6">[7]</ref>. Given a triplet (x i , x j , x k ), DML aims to learn good embeddings such that examples from the same class are closer than examples from different classes, i.e., ∀i, j, k,</p><formula xml:id="formula_3">x i − x k 2 2 − x i − x j 2 2 ≥ δ</formula><p>where x i and x j are from the same class and x k is from a different class. δ is a predefined margin. When each example has the unit length (i.e., x 2 = 1), the triplet constraint can be simplified as</p><formula xml:id="formula_4">∀i, j, k, x i x j − x i x k ≥ δ<label>(1)</label></formula><p>where we ignore the rescaling of δ. The corresponding triplet loss can be written as</p><formula xml:id="formula_5">triplet (x i , x j , x k ) = [δ + x i x k − x i x j ] +<label>(2)</label></formula><p>It is obvious from Eqn. 1 that the number of total triplets can be cubic in the number of examples, which makes sampling inevitable for most of triplet based DML algorithms.</p><p>With the unit length for both w and x, the normalized SoftMax loss can be written as</p><formula xml:id="formula_6">SoftMaxnorm (x i ) = − log exp(λw yi x i ) j exp(λw j x i )<label>(3)</label></formula><p>where λ is a scaling factor. Surprisingly, we find that minimizing the normalized SoftMax loss with the smooth term λ is equivalent to optimizing a smoothed triplet loss.</p><formula xml:id="formula_7">Proposition 1. SoftMaxnorm (x i ) = max p∈∆ λ j p j x i (w j − w yi ) + H(p) (4)</formula><p>where p ∈ R C is a distribution over classes and ∆ is the simplex as ∆ = {p| j p j = 1, ∀j, p j ≥ 0}. H(p) denotes the entropy of the distribution p.</p><p>Proof. According to the K.K.T. condition <ref type="bibr" target="#b0">[1]</ref>, the distribution p in Eqn. 4 has the closed-form solution</p><formula xml:id="formula_8">p j = exp(λx i (w j − w yi )) j exp(λx i (w j − w yi ))</formula><p>Therefore, we have</p><formula xml:id="formula_9">SoftMaxnorm (xi) = λ j pjx i (wj − wy i ) + H(p) = log( j exp(λx i (wj − wy i ))) = − log exp(λw y i xi) j exp(λw j xi)</formula><p>Remark 1 Proposition 1 indicates that the SoftMax loss optimizes the triplet constraints consisting of an original example and two centers, i.e., (x i , w yi , w j ). Compared with triplet constraints in Eqn. 1, the target of SoftMax loss is</p><formula xml:id="formula_10">∀i, j, x i w yi − x i w j ≥ 0</formula><p>Consequently, the embeddings learned by minimizing Soft-Max loss can be applicable for the distance-based tasks while it is designed for the classification task.</p><p>Remark 2 Without the entropy regularizer, the loss becomes max</p><formula xml:id="formula_11">p∈∆ λ j p j x i w j − λx i w yi which is equivalent to max j {x i w j } − x i w yi</formula><p>Explicitly, it punishes the triplet with the most violation and becomes zero when the nearest neighbor of x i is the corresponding center w yi . The entropy regularizer reduces the influence from outliers and makes the loss more robust. λ trades between the hardness of triplets and the regularizer. Moreover, minimizing the maximal entropy can make the distribution concentrated and further push the example away from irrelevant centers, which implies a large margin property.</p><p>Remark 3 Applying the similar analysis to the Prox-yNCA loss <ref type="bibr" target="#b13">[14]</ref>:</p><formula xml:id="formula_12">ProxyNCA (x i ) = − log exp(w y i xi) j =y i exp(w j xi) , we have ProxyNCA (x i ) = max p∈∆ λ j =yi p j x i (w j − w yi ) + H(p)</formula><p>where p ∈ R C−1 . Compared with the SoftMax loss, it eliminates the benchmark triplet containing only the corresponding class center, which makes the loss unbounded. Our analysis suggests that the loss can be bounded as in</p><formula xml:id="formula_13">Eqn. 2: hinge ProxyNCA (x i ) = [− log exp(w y i xi) j =y i exp(w j xi) ] + .</formula><p>Validating the bounded loss is out of the scope of this work.</p><p>Despite optimizing SoftMax loss can learn the meaningful feature embeddings, the drawback is straightforward. It assumes that there is only a single center for each class while a real-world class can contain multiple local clusters due to the large intra-class variance as in <ref type="figure">Fig. 1</ref>. The triplet constraints generated by conventional SoftMax loss is too brief to capture the complex geometry of the original data. Therefore, we introduce multiple centers for each class.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Multiple Centers</head><p>Now, we assume that each class has K centers. Then, the similarity between the example x i and the class c can be defined as</p><formula xml:id="formula_14">S i,c = max k x i w k c<label>(5)</label></formula><p>Note that other definitions of similarity can be applicable for this scenario (e.g., min z∈R K [w 1 c , · · · , w K c ]z − x i 2 ). We adopt a simple form to illustrate the influence of multiple centers.</p><p>With the definition of the similarity, the triplet constraint requires an example to be closer to its corresponding class than other classes ∀j, S i,yi − S i,j ≥ 0 As we mentioned above, minimizing the entropy term H(p) can help to pull the example to the corresponding center. To break the tie explicitly, we consider to introduce a small margin as in the conventional triplet loss in Eqn. 1 and define the constraints as</p><formula xml:id="formula_15">∀j j =yi , S i,yi − S i,j ≥ δ</formula><p>By replacing the similarity in Eqn. 4, we can obtain the</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>HardTriple loss as</head><formula xml:id="formula_16">HardTriple (x i ) = max p∈∆ λ j =yi p j (S i,j − (S i,yi − δ)) + p yi (S i,yi − δ − (S i,yi − δ)) + H(p) = − log exp(λ(S i,yi − δ)) exp(λ(S i,yi − δ)) + j =yi exp(λS i,j )<label>(6)</label></formula><p>HardTriple loss improves the SoftMax loss by providing multiple centers for each class. However, it requires the max operator to obtain the nearest center in each class while this operator is not smooth and the assignment can be sensitive between multiple centers. Inspired by the SoftMax loss, we can improve the robustness by smoothing the max operator.</p><p>Consider the problem</p><formula xml:id="formula_17">max k x i w k c which is equivalent to max q∈∆ k q k x i w k c<label>(7)</label></formula><p>we add the entropy regularizer to the distribution q as</p><formula xml:id="formula_18">max q∈∆ k q k x i w k c + γH(q)</formula><p>With a similar analysis as in Proposition 1, q has the closedform solution as</p><formula xml:id="formula_19">q k = exp( 1 γ x i w k c ) k exp( 1 γ x i w k c )</formula><p>Taking it back to the Eqn. 7, we define the relaxed similarity between the example x i and the class c as</p><formula xml:id="formula_20">S i,c = k exp( 1 γ x i w k c ) k exp( 1 γ x i w k c ) x i w k c</formula><p>By applying the smoothed similarity, we define the Soft-Triple loss as</p><formula xml:id="formula_21">SoftTriple (x i ) = − log exp(λ(S i,yi − δ)) exp(λ(S i,yi − δ)) + j =yi exp(λS i,j )<label>(8)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fig. 2 illustrates the differences between the SoftMax loss and the proposed losses.</head><p>Finally, we will show that the strategy of applying centers to construct triplet constraints can recover the constraints on original triplets.  <ref type="figure">Figure 2</ref>. Illustration of differences between SoftMax loss and proposed losses. Compared with the SoftMax loss, we first increase the dimension of the FC layer to include multiple centers for each class (e.g., 2 centers per class in this example). Then, we obtain the similarity for each class by different operators. Finally, the distribution over different classes is computed with the similarity obtained from each class.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theorem 1.</head><p>Given two examples x i and x j that are from the same class and have the same nearest center and x k is from a different class, if the triple constant containing centers is satisfied</p><formula xml:id="formula_22">x i w yi − x i w y k ≥ δ</formula><p>and we assume ∀i, x i − w yi 2 ≤ , then we have</p><formula xml:id="formula_23">x i x j − x i x k ≥ δ − 2</formula><p>Proof.</p><formula xml:id="formula_24">x i x j − x i x k = x i (x j − w yi ) + x i w yi − x i x k ≥ x i (x j − w yi ) + x i (w y k − x k ) + δ ≥ δ − x i 2 x j − w yi 2 − x i 2 w y k − x k 2 = δ − x j − w yi 2 − w y k − x k 2 ≥ δ − 2</formula><p>Theorem 1 demonstrates that optimizing the triplets consisting of centers with a margin δ can reserve the large margin property on the original triplet constraints. It also implies that more centers can be helpful to reduce the intraclass variance . In the extreme case that the number of centers is equal to the number of examples, becomes zero. However, adding more centers will increase the size of the last fully connected layer and make the optimization slow and computation expensive. Besides, it may incur the overfitting problem.</p><p>Therefore, we have to choose an appropriate number of centers for each class that can have a small approximation error while keeping a compact set of centers. We will demonstrate the strategy in the next subsection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Adaptive Number of Centers</head><p>Finding an appropriate number of centers for data is a challenging problem that also appears in unsupervised learning, e.g., clustering. The number of centers K trades between the efficiency and effectiveness. In conventional DML algorithms, K equals to the number of original examples. It makes the number of total triplet constraints up to cubic of the number of original examples. In SoftMax loss, K = 1 reduces the number of constraints to be linear in the number of original examples, which is efficient but can be ineffective. Without the prior knowledge about the distribution of each class, it is hard to set K precisely.</p><p>Different from the strategy of setting the appropriate K for each class, we propose to set a sufficiently large K and then encourage similar centers to merge with each other. It can keep the diversity in the generated centers while shrinking the number of unique centers.</p><p>For each center w t j , we can generate a matrix as</p><formula xml:id="formula_25">M t j = [w 1 j − w t j , · · · , w K j − w t j ]</formula><p>If w s j and w t j are similar, they can be collapsed to be the same one such that w s j − w t j 2 = 0, which is the L 2 norm of the s-th row in the matrix M t j . Therefore, we regularize the L 2 norm of rows in M t j to obtain a sparse set of centers, which can be written as the L 2,1 norm</p><formula xml:id="formula_26">M t j 2,1 = K s w s j − w t j 2</formula><p>By accumulating L 2,1 norm over multiple centers, we can have the regularizer for the j-th class as</p><formula xml:id="formula_27">R(w 1 j , · · · , w K j ) = K t M t j 2,1</formula><p>Since w has the unit length, the regularizer is simplified as</p><formula xml:id="formula_28">R(w 1 j , · · · , w K j ) = K t=1 K s=t+1 2 − 2w s j w t j (9)</formula><p>With the regularizer, our final objective becomes</p><formula xml:id="formula_29">min 1 N i SoftTriple (x i ) + τ C j R(w 1 j , · · · , w K j ) CK(K − 1)<label>(10)</label></formula><p>where N is the number of total examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>We conduct experiments on three benchmark finegrained visual categorization data sets: CUB-2011, Cars196 and SOP. We follow the settings in other works <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b13">14]</ref> for the fair comparison. Specifically, we adopt the Inception <ref type="bibr" target="#b24">[25]</ref> with the batch normalization <ref type="bibr" target="#b4">[5]</ref> as the backbone architecture. The parameters of the backbone are initialized with the model trained on the ImageNet ILSVRC 2012 data set <ref type="bibr" target="#b19">[20]</ref> and then fine-tuned on the target data sets. The images are cropped to 224 × 224 as the input of the network. During training, only random horizontal mirroring and random crop are used as the data augmentation. A single center crop is taken for test. The model is optimized by Adam with the batch size as 32 and the number of epochs as 50. The initial learning rates for the backbone and centers are set to be 1e-4 and 1e-2, respectively. Then, they are divided by 10 at {20, 40} epochs. Considering that images in CUB-2011 and Cars196 are similar to those in ImageNet, we freeze BN on these two data sets and keep BN training on the rest one. Embeddings of examples and centers have the unit length in the experiments.</p><p>We compare the proposed triplet loss to the normalized SoftMax loss. The SoftMax loss in Eqn. 3 is denoted as SoftMax norm . We refer the objective in Eqn. 10 as Soft-Triple. We set τ = 0.2 and γ = 0.1 for SoftTriple. Besides, we set a small margin as δ = 0.01 to break the tie explicitly. The number of centers is set to K = 10.</p><p>We evaluate the performance of the learned embeddings from different methods on the tasks of retrieval and clustering. For retrieval task, we use the Recall@k metric as in <ref type="bibr" target="#b23">[24]</ref>. The quality of clustering is measured by the Normalized Mutual Information (NMI) <ref type="bibr" target="#b12">[13]</ref>. Given the clustering assignment C = {c 1 , · · · , c n } and the ground-truth label Ω = {y 1 , · · · , y n }, NMI is computed as NMI = 2I(Ω;C) H(Ω)+H(C) , where I(·, ·) measures the mutual information and H(·) denotes the entropy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">CUB-2011</head><p>First, we compare the methods on a fine-grained birds data set CUB-2011 <ref type="bibr" target="#b25">[26]</ref>. It consists of 200 species of birds and 11, 788 images. Following the common practice, we split the data set as that the first 100 classes are used for training and the rest are used for test. We note that different works report the results with different dimension of embeddings while the size of embeddings has a significant impact on the performance. For fair comparison, we report the results for the dimension of 64, which is adopted by many existing methods and the results with 512 feature embeddings, which reports the state-of-the-art results on most of data sets. <ref type="table" target="#tab_1">Table 1</ref> summarizes the results with 64 embeddings. Note that Npairs * applies the multi-scale test while all other methods take a single crop test. For SemiHard <ref type="bibr" target="#b20">[21]</ref>, we report the result recorded in <ref type="bibr" target="#b22">[23]</ref>. First, it is surprising to observe that the performance of SoftMax norm surpasses that of the existing metric learning methods. It is potentially due to the fact that SoftMax loss optimizes the relations of examples as a smoothed triplet loss, which is analyzed in Proposition 1. Second, SoftTriple demonstrates the best performance among all benchmark methods. Compared to ProxyNCA, SoftTriple improves the state-of-the- art performance by 10% on R@1. Besides, it is 2% better than SoftMax norm . It verifies that SoftMax loss cannot capture the complex geometry of real-world data set with a single center for each class. When increasing the number of centers, SoftTriple can depict the inherent structure of data better. Finally, both of SoftMax and SoftTriple show the superior performance compared to existing methods. It demonstrates that meaningful embeddings can be learned without a sampling phase.  <ref type="table" target="#tab_2">Table 2</ref> compares SoftTriple with 512 embeddings to the methods with large embeddings. HDC <ref type="bibr" target="#b31">[32]</ref> applies the dimension as 384. Margin <ref type="bibr" target="#b11">[12]</ref> takes 128 dimension of embeddings and uses ResNet50 <ref type="bibr" target="#b3">[4]</ref> as the backbone. HTL <ref type="bibr" target="#b2">[3]</ref> sets the dimension of embeddings to 512 and reports the state-of-the-art result on the backbone of Inception. With the large number of embeddings, it is obvious that all methods outperform existing DML methods with 64 embeddings in <ref type="table" target="#tab_1">Table 1</ref>. It is as expected since the high dimensional space can separate examples better, which is consistent with the observation in other work <ref type="bibr" target="#b23">[24]</ref>. Compared with other methods, the R@1 of SoftTriple improves more than 8% over HTL that has the same backbone as SoftTriple. It also increases R@1 by about 2% over Margin, which applies a stronger backbone than Inception. It shows that SoftTriple loss is applicable with large embeddings.</p><p>To validate the effect of the proposed regularizer, we compare the number of unique centers for each class in <ref type="figure" target="#fig_0">Fig. 3</ref>. We set a larger number of centers as K = 20 to make the results explicit and then run SoftTriple with and without the regularizer in Eqn. 9. <ref type="figure" target="#fig_0">Fig. 3</ref> illustrates that the one without regularizer will hold a set of similar centers. In contrast, SoftTriple with the regularizer can shrink the size of centers significantly and make the optimization effective. Besides, we demonstrate the R@1 of SoftTriple with varying the number of centers in <ref type="figure" target="#fig_1">Fig. 4</ref>. Red line denotes SoftTriple loss equipped with the regularizer while blue dashed line has no regularizer. We find that when increasing the number of centers from 1 to 10, the performance of SoftTriple is improved significantly, which confirms that with leveraging multiple centers, the learned embeddings can capture the data distribution better. If adding more centers, the performance of SoftTriple almost remains the same and it shows that the regularizer can help to learn the compact set of centers and will not be influenced by the initial number of centers. On the contrary, without the regularizer, the blue dashed line illustrates that the performance will degrade due to overfitting when the number of centers are over-parameterized. Finally, we illustrate the examples of retrieved images in <ref type="figure">Fig. 5</ref>. The first column indicates the query image. The columns 2-4 show the most similar images retrieved according to the embeddings learned by SoftMax norm . The last four columns are the similar images returned by using the embeddings from SoftTriple. Evidently, embeddings from SoftMax norm can obtain the meaningful neighbors while the objective is for classification. Besides, SoftTriple improves the performance and can eliminate the images from different classes among the top of retrieved images, which are highlighted with red bounding boxes in SoftMax norm .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Query</head><p>SoftMax norm SoftTriple <ref type="figure">Figure 5</ref>. Examples of retrieved most similar images with the learned embeddings from SoftMaxnorm and SoftTriple. The images from the classes that are different from the query image are highlighted by red bounding boxes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Cars196</head><p>Then, we conduct the experiments on Cars196 data set <ref type="bibr" target="#b5">[6]</ref>, which contains 196 models of cars and 16, 185 images. We use the first 98 classes for training and the rest for test. <ref type="table" target="#tab_3">Table 3</ref> summaries the performance with 64 embeddings. The observation is similar as for CUB-2011. SoftMax norm shows the superior performance and is 3% better than ProxyNCA on R@1. Additionally, SoftTriple can further improve the performance by about 2%, which demonstrates the effectiveness of the proposed loss function. In <ref type="table" target="#tab_4">Table 4</ref>, we present the comparison with large dimension of embeddings. The number of embeddings for all methods in the comparison is the same as described in the experiments on CUB-2011. On this data set, HTL <ref type="bibr" target="#b2">[3]</ref> reports the state-of-the-art result while SoftTriple outperforms it and increases R@1 by 3%. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Stanford Online Products</head><p>Finally, we evaluate the performance of different methods on the Stanford Online Products (SOP) data set <ref type="bibr" target="#b23">[24]</ref>. It contains 120, 053 product images downloaded from eBay.com and includes 22, 634 classes. We adopt the standard splitting, where 11, 318 classes are used for training and the rest for test. Note that each class has about 5 images, so we set K = 2 for this data set and discard the regularizer. We also increase the initial learning rate for centers from 0.01 to 0.1.</p><p>We first report the results with 64 embeddings in <ref type="table">Table 5</ref>. In this comparison, SoftMax norm is 2% better than Prox-yNCA on R@1. By simply increasing the number of centers from 1 to 2, we observe that SoftTriple gains another 0.4% on R@1. It confirms that multiple centers can help to capture the data structure better. <ref type="table">Table 6</ref> states the performance with large embeddings. We can get a similar conclusion as in <ref type="table">Table 5</ref>. Both SoftMax norm and SoftTriple outperform the state-of-the-art methods. SoftTriple improves the state-of-the-art by more than 3% on R@1. It demonstrates the advantage of learning embeddings without sampling triplet constraints. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>Sampling triplets from a mini-batch of data can degrade the performance of deep metric learning due to its poor coverage over the whole data set. To address the problem, we propose the novel SoftTriple loss to learn the embeddings without sampling. By representing each class with multiple centers, the loss can be optimized with triplets defined with the similarities between the original examples and classes. Since centers are encoded in the last fully connected layer, we can learn embeddings with the standard SGD training pipeline for classification and eliminate the sampling phase. The consistent improvement from Soft-Triple over fine-grained benchmark data sets confirms the effectiveness of the proposed loss function. Since SoftMax loss is prevalently applied for classification, SoftTriple loss can also be applicable for that. Evaluating SoftTriple on the classification task can be our future work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 .</head><label>3</label><figDesc>Comparison of the number of unique centers in each class on CUB-2011. The initial number of centers is set to 20.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 .</head><label>4</label><figDesc>Illustration of SoftTriple with different number of centers and the influence of the regularizer. With the proposed regularizer as denoted by the red line, the performance is stable to the initial number of centers K when it is sufficiently large.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Embedding FC layer SoftMax Embedding FC layer SoftMax Max Operator Embedding FC layer SoftMax SoftMax Operator SoftMax Loss HardTriple Loss SoftTriple Loss</head><label></label><figDesc></figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>Comparison on CUB-2011. The dimension of the embeddings for all methods is 64.</figDesc><table><row><cell>Methods</cell><cell cols="5">R@1 R@2 R@4 R@8 NMI</cell></row><row><cell>SemiHard [21]</cell><cell>42.6</cell><cell>55.0</cell><cell>66.4</cell><cell>77.2</cell><cell>55.4</cell></row><row><cell>LiftedStruct [24]</cell><cell>43.6</cell><cell>56.6</cell><cell>68.6</cell><cell>79.6</cell><cell>56.5</cell></row><row><cell>Clustering [23]</cell><cell>48.2</cell><cell>61.4</cell><cell>71.8</cell><cell>81.9</cell><cell>59.2</cell></row><row><cell>Npairs  *  [22]</cell><cell>51.0</cell><cell>63.3</cell><cell>74.3</cell><cell>83.2</cell><cell>60.4</cell></row><row><cell>ProxyNCA [14]</cell><cell>49.2</cell><cell>61.9</cell><cell>67.9</cell><cell>72.4</cell><cell>59.5</cell></row><row><cell>SoftMaxnorm</cell><cell>57.8</cell><cell>70.0</cell><cell>80.1</cell><cell>87.9</cell><cell>65.3</cell></row><row><cell>SoftTriple</cell><cell>60.1</cell><cell>71.9</cell><cell>81.2</cell><cell>88.5</cell><cell>66.2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Comparison on CUB-2011 with large embeddings. "-" means the result is not available.</figDesc><table><row><cell>Methods</cell><cell cols="5">R@1 R@2 R@4 R@8 NMI</cell></row><row><cell>HDC [32]</cell><cell>53.6</cell><cell>65.7</cell><cell>77.0</cell><cell>85.6</cell><cell>-</cell></row><row><cell>Margin [12]</cell><cell>63.6</cell><cell>74.4</cell><cell>83.1</cell><cell>90.0</cell><cell>69.0</cell></row><row><cell>HTL [3]</cell><cell>57.1</cell><cell>68.8</cell><cell>78.7</cell><cell>86.5</cell><cell>-</cell></row><row><cell>SoftMaxnorm</cell><cell>64.2</cell><cell>75.6</cell><cell>84.3</cell><cell>90.2</cell><cell>68.3</cell></row><row><cell>SoftTriple</cell><cell>65.4</cell><cell>76.4</cell><cell>84.5</cell><cell>90.4</cell><cell>69.3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 .</head><label>3</label><figDesc>Comparison on Cars196. The dimension is 64.</figDesc><table><row><cell>Methods</cell><cell cols="5">R@1 R@2 R@4 R@8 NMI</cell></row><row><cell>SemiHard [21]</cell><cell>51.5</cell><cell>63.8</cell><cell>73.5</cell><cell>82.4</cell><cell>53.4</cell></row><row><cell>LiftedStruct [24]</cell><cell>53.0</cell><cell>65.7</cell><cell>76.0</cell><cell>84.3</cell><cell>56.9</cell></row><row><cell>Clustering [23]</cell><cell>58.1</cell><cell>70.6</cell><cell>80.3</cell><cell>87.8</cell><cell>59.0</cell></row><row><cell>Npairs  *  [22]</cell><cell>71.1</cell><cell>79.7</cell><cell>86.5</cell><cell>91.6</cell><cell>64.0</cell></row><row><cell>ProxyNCA [14]</cell><cell>73.2</cell><cell>82.4</cell><cell>86.4</cell><cell>88.7</cell><cell>64.9</cell></row><row><cell>SoftMaxnorm</cell><cell>76.8</cell><cell>85.6</cell><cell>91.3</cell><cell>95.2</cell><cell>66.7</cell></row><row><cell>SoftTriple</cell><cell>78.6</cell><cell>86.6</cell><cell>91.8</cell><cell>95.4</cell><cell>67.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 .</head><label>4</label><figDesc>Comparison on Cars196 with large embeddings.</figDesc><table><row><cell>Methods</cell><cell cols="5">R@1 R@2 R@4 R@8 NMI</cell></row><row><cell>HDC [32]</cell><cell>73.7</cell><cell>83.2</cell><cell>89.5</cell><cell>93.8</cell><cell>-</cell></row><row><cell>Margin [12]</cell><cell>79.6</cell><cell>86.5</cell><cell>91.9</cell><cell>95.1</cell><cell>69.1</cell></row><row><cell>HTL [3]</cell><cell>81.4</cell><cell>88.0</cell><cell>92.7</cell><cell>95.7</cell><cell>-</cell></row><row><cell>SoftMaxnorm</cell><cell>83.2</cell><cell>89.5</cell><cell>94.0</cell><cell>96.6</cell><cell>69.7</cell></row><row><cell>SoftTriple</cell><cell>84.5</cell><cell>90.7</cell><cell>94.5</cell><cell>96.9</cell><cell>70.1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 .Table 6 .</head><label>56</label><figDesc>Comparison on SOP. The dimension is 64. Comparison on SOP with large embeddings.</figDesc><table><row><cell>Methods</cell><cell cols="4">R@1 R@10 R@100 NMI</cell></row><row><cell>SemiHard [21]</cell><cell>66.7</cell><cell>82.4</cell><cell>91.9</cell><cell>89.5</cell></row><row><cell>LiftedStruct [24]</cell><cell>62.5</cell><cell>80.8</cell><cell>91.9</cell><cell>88.7</cell></row><row><cell>Clustering [23]</cell><cell>67.0</cell><cell>83.7</cell><cell>93.2</cell><cell>89.5</cell></row><row><cell>ProxyNCA [14]</cell><cell>73.7</cell><cell>-</cell><cell>-</cell><cell>90.6</cell></row><row><cell>SoftMaxnorm</cell><cell>75.9</cell><cell>88.8</cell><cell>95.2</cell><cell>91.5</cell></row><row><cell>SoftTriple</cell><cell>76.3</cell><cell>89.1</cell><cell>95.3</cell><cell>91.7</cell></row><row><cell>Methods</cell><cell cols="4">R@1 R@10 R@100 NMI</cell></row><row><cell>Npairs  *  [22]</cell><cell>67.7</cell><cell>83.8</cell><cell>93.0</cell><cell>88.1</cell></row><row><cell>HDC [32]</cell><cell>69.5</cell><cell>84.4</cell><cell>92.8</cell><cell>-</cell></row><row><cell>Margin [12]</cell><cell>72.7</cell><cell>86.2</cell><cell>93.8</cell><cell>90.7</cell></row><row><cell>HTL [3]</cell><cell>74.8</cell><cell>88.3</cell><cell>94.8</cell><cell>-</cell></row><row><cell>SoftMaxnorm</cell><cell>78.0</cell><cell>90.2</cell><cell>96.0</cell><cell>91.9</cell></row><row><cell>SoftTriple</cell><cell>78.3</cell><cell>90.3</cell><cell>95.9</cell><cell>92.0</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Convex optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lieven</forename><surname>Vandenberghe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>Cambridge university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Arcface: Additive angular margin loss for deep face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiankang</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanos</forename><surname>Zafeiriou</surname></persName>
		</author>
		<idno>abs/1801.07698</idno>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Deep metric learning with hierarchical triplet loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weifeng</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weilin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dengke</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">R</forename><surname>Scott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="272" to="288" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="448" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">3d object representations for fine-grained categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Stark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">4th International IEEE Workshop on 3D Representation and Recognition</title>
		<meeting><address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Robust structural metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daryl</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gert</forename><forename type="middle">R G</forename><surname>Lanckriet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Mcfee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="615" to="623" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Sphereface: Deep hypersphere embedding for face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiyang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yandong</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiding</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bhiksha</forename><surname>Raj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6738" to="6746" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Large-margin softmax loss for convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiyang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yandong</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiding</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="507" to="516" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">On the generalized distance in statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prasanta</forename><surname>Chandra Mahalanobis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1936" />
		</imprint>
		<respStmt>
			<orgName>National Institute of Science of India</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Sampling matters in deep embedding learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Manmatha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chao-Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Krähenbühl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="2859" to="2867" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Introduction to information retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prabhakar</forename><surname>Raghavan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="100" to="103" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">No fuss distance metric learning using proxies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yair</forename><surname>Movshovitz-Attias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Toshev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">K</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurabh</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="360" to="368" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Deep face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Omkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Parkhi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Efficient distance metric learning by adaptive sampling and mini-batch stochastic gradient descent (SGD)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rong</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinfeng</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lijun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shenghuo</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="page" from="353" to="372" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Finegrained visual categorization via multi-stage metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rong</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shenghuo</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanqing</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="3716" to="3724" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Large-scale distance metric learning with uncertainty</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiasheng</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shenghuo</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rong</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Metric learning with adaptive density discrimination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Rippel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manohar</forename><surname>Paluri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lubomir</forename><forename type="middle">D</forename><surname>Bourdev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICLR</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">ImageNet Large Scale Visual Recognition Challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision (IJCV)</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="252" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Facenet: A unified embedding for face recognition and clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Kalenichenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Philbin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="815" to="823" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Improved deep metric learning with multiclass n-pair loss objective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1849" to="1857" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Deep metric learning via facility location</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyun Oh</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanie</forename><surname>Jegelka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vivek</forename><surname>Rathod</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="2206" to="2214" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Deep metric learning via lifted structured feature embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyun Oh</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanie</forename><surname>Jegelka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="4004" to="4012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Going deeper with convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><forename type="middle">E</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">The Caltech-UCSD Birds-200-2011 Dataset. Technical report</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Welinder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Additive margin softmax for face verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiyang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haijun</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Process. Lett</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="926" to="930" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Cosface: Large margin cosine loss for deep face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yitong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dihong</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingchao</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5265" to="5274" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Distance metric learning for large margin nearest neighbor classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Kilian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><forename type="middle">K</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Saul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="207" to="244" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A discriminative feature learning approach for deep face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yandong</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaipeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Qiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="499" to="515" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Distance metric learning with application to clustering with side-information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stuart</forename><forename type="middle">J</forename><surname>Russell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="505" to="512" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Hard-aware deeply cascaded embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhui</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuiyuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="814" to="823" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
