<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Improving accuracy and speeding up Document Image Classification through parallel systems</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Ferrando</surname></persName>
							<email>javier.ferrando@bsc.es</email>
							<affiliation key="aff0">
								<orgName type="department">Barcelona Supercomputing Center -Centro Nacional de Supercomputacin</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juan</forename><surname>Luis Domnguez</surname></persName>
							<email>juan.dominguez@bsc.es</email>
							<affiliation key="aff0">
								<orgName type="department">Barcelona Supercomputing Center -Centro Nacional de Supercomputacin</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordi</forename><surname>Torres</surname></persName>
							<email>jordi.torres@bsc.es</email>
							<affiliation key="aff0">
								<orgName type="department">Barcelona Supercomputing Center -Centro Nacional de Supercomputacin</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Universitat</orgName>
								<address>
									<addrLine>Politcnica de Catalunya, UPC-BarcelonaTech 3 Serimag Media -TAAD</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ral</forename><surname>Garca</surname></persName>
							<email>raul.garcia@bsc.es</email>
							<affiliation key="aff0">
								<orgName type="department">Barcelona Supercomputing Center -Centro Nacional de Supercomputacin</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Garca</surname></persName>
							<email>david.garcia2@bsc.es</email>
							<affiliation key="aff0">
								<orgName type="department">Barcelona Supercomputing Center -Centro Nacional de Supercomputacin</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Garrido</surname></persName>
							<email>danielgarrido@serimagmedia.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordi</forename><surname>Cortada</surname></persName>
							<email>jorge.cortada@caixabank.com</email>
							<affiliation key="aff2">
								<orgName type="institution">CaixaBank</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mateo</forename><surname>Valero</surname></persName>
							<email>mateo.valero@bsc.es</email>
							<affiliation key="aff0">
								<orgName type="department">Barcelona Supercomputing Center -Centro Nacional de Supercomputacin</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Universitat</orgName>
								<address>
									<addrLine>Politcnica de Catalunya, UPC-BarcelonaTech 3 Serimag Media -TAAD</addrLine>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Improving accuracy and speeding up Document Image Classification through parallel systems</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T17:51+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Document Image Classification · Deep Learning · Parallel Systems · EfficientNet · BERT · Scalability · TensorFlow · PyTorch</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents a study showing the benefits of the Effi-cientNet models compared with heavier Convolutional Neural Networks (CNNs) in the Document Classification task, essential problem in the digitalization process of institutions. We show in the RVL-CDIP dataset that we can improve previous results with a much lighter model and present its transfer learning capabilities on a smaller in-domain dataset such as Tobacco3482. Moreover, we present an ensemble pipeline which is able to boost solely image input by combining image model predictions with the ones generated by BERT model on extracted text by OCR. We also show that the batch size can be effectively increased without hindering its accuracy so that the training process can be sped up by parallelizing throughout multiple GPUs, decreasing the computational time needed. Lastly, we expose the training performance differences between PyTorch and Tensorflow Deep Learning frameworks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Document digitization has become a common practice in a wide variety of industries that deal with vast amounts of archives. Document classification is a task to face when trying to automate their document processes, but high intra-class and low inter-class variability between documents have made this a challenging problem.</p><p>First attempts focused on structural similarity between documents <ref type="bibr" target="#b39">[40]</ref> and on feature extraction <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b29">30]</ref> to differentiate characteristics of each class. The combination of both approaches has also been tested <ref type="bibr" target="#b13">[14]</ref>.</p><p>Several classic machine learning techniques have been applied to these problem, i. e. K-Nearest Neighbor approach <ref type="bibr" target="#b6">[7]</ref>, Hidden Markov Model <ref type="bibr" target="#b18">[19]</ref> and Random Forest Classifier <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b23">24]</ref> while using SURF local descriptors before the Convolutional Neural Networks (CNNs) came into scene.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>arXiv:2006.09141v1 [cs.CV] 16 Jun 2020</head><p>With the rise of Deep Learning, researchers have tried deep neural networks to improve the accuracy of their classifiers. CNNs have been proposed in past works, initially in 2014 by Le Kang et al. <ref type="bibr" target="#b25">[26]</ref> who started with a simple 4layer CNN trained from scratch. Then, transfer learning was demonstrated to work effectively <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b0">1]</ref> by using a network pre-trained on ImageNet <ref type="bibr" target="#b16">[17]</ref>. And latest models have become increasingly heavier (greater number of parameters) <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b1">2]</ref> as shown in <ref type="table" target="#tab_0">Table 1</ref>, with the speed and computational resources drawback this entails.</p><p>Recently, textual information has been used by itself or as a combination together with visual features extracted by the previously mentioned models. Although Optical Character Recognition (OCR) is prone to errors, particularly when dealing with handwritten documents, the use of modern Natural Language Processing (NLP) techniques have demonstrated a boost in the classifiers performance <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b4">5]</ref>.</p><p>The contributions of this paper can be summarized in two main topics:</p><p>-Algorithmic performance: we propose a model and a training procedure to deal with images and text that outperforms the state-of-the-art in several settings and is lighter than any previous neural network used to classify the BigTobacco dataset, the most popular benchmark for Document Image Classification <ref type="table" target="#tab_0">(Table 1</ref>). -Training process speed up: we demonstrate the ability of these models to maintain their performance while saving a large amount of time by parallelizing over several GPUs. We also show the performance differences between the two most popular Deep Learning frameworks (TensorFlow and Pytorch), when using their own libraries dedicated to this task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Document Image Classification</head><p>Document Image Classification task tries to predict the class which a document belongs to by means of analyzing its image representation. This challenge can be tackled in two ways, as an image classification problem and as a text classification problem. The former tries to look for patterns in the pixels of the image to find elements such as shapes or textures that can be associated to a certain class. The latter tries to understand the language written in the document and relate this to the different classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Datasets</head><p>As mentioned earlier, in this work we make use of two publicly available datasets containing samples of images from scanned documents from USA Tobacco companies, published by Legacy Tobacco Industry Documents and created by the University of California San Francisco (UCSF). We find these datasets a good representation of what enterprises and institutions may face with, based on the quality and type of classes. Furthermore, they have been go-to datasets in this research field since 2014 with which we can compare results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RVL-CDIP (Ryerson Vision Lab Complex Document Information</head><p>Processing) is a 400.000 document sample (BigTobacco from now onwards) presented in <ref type="bibr" target="#b20">[21]</ref> for document classification tasks. This dataset contains the first page of each of the documents, which are labeled in 16 different classes with equal number of elements per class. A smaller sample containing 3482 images was proposed in <ref type="bibr" target="#b23">[24]</ref> as Tobacco3482 (SmallTobacco henceforth). This dataset is formed by documents belonging to 10 classes not uniformly distributed. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Deep Learning</head><p>The proposed methods in this work are based on supervised Deep Learning, where each document is associated to a class (label) so that the algorithms are trained by minimizing the error between the predictions and the truth. Deep Learning is a branch of machine learning that deals with deep neural networks, where each of the layers is trained to extract higher level representations of the previous ones. These models are trained by solving iteratively an unconstrained optimization problem. In each iteration, a random batch of the training data is fed into the model to compute the loss function value. Then, the gradient of the loss function with respect to the weights of the network is computed (backpropagation) and an update of the weights in the negative direction of the gradient is done. These networks are trained until they converge into a loss function minimum.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Computer Vision</head><p>The field where machines try to get an understanding of visual data is known as Computer Vision (CV). One of the most well-known tasks in CV is image classification. In 2010 The ImageNet Large Scale Visual Recognition Challenge (ILSVRC) was introduced, a competition that dealt with a 1.2 million images dataset belonging to 1000 classes. In 2012 the first CNN-based model significantly reduced the error rate, setting the beginning of the explosion of deep neural networks. From then onwards, deeper networks have become the norm. The most used architecture in Computer Vision have been CNN-based networks. Their main operation is the convolution one, which consists on a succession of dot products between the vector representations of both the input space (L q × B q × d q ) and the filters (F q × F q × d q ). We slide each filter around the input volume getting an activation map of dimension L q+1 = (L q −F q +1) and B q+1 = (B q − F q + 1). The output volume then has a dimension of L q+1 × B q+1 × d q+1 , where d q+1 refers to the number of filters used. We refer to <ref type="bibr" target="#b2">[3]</ref> (we used the same notation for simplicity) to a more detailed explanation. Usually, each convolution layer is associated to an activation layer, where an activation function is applied to the whole output volume. To reduce the number of parameters of the network, a pooling layer is typically located between convolution operations. The pooling layer takes a region P q × P q in each of the d q activation maps and performs an arithmetic operation. The most used pooling layer is the max-pool, which returns the maximum value of the aforementioned region.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Natural Language Processing</head><p>The features learned from the OCR output are achieved by means of Natural Language Processing techniques. NLP is the field that deals with the understanding of human language by computers, which captures underlying meanings and relationships between words.</p><p>The way machines deal with words is by means of a real values vector representation. Word2Vec <ref type="bibr" target="#b33">[34]</ref> showed that a vector could represent semantic and syntactic relationships between words. CoVe <ref type="bibr" target="#b31">[32]</ref> introduced the concept of contextbased embeddings, where the same word can have a different vector representation depending on the surrounding text. ELMo <ref type="bibr" target="#b35">[36]</ref> followed Cove but with a different training approach, by predicting the next word in a text sequence (Language Modelling), which made it possible to train on large available text corpus. Depending on the task (such as text classification, named entity recognition...) the output of the model can be treated in different ways. Moreover, custom layers can be added to the features extracted by these NLP models. For instance, ULM-Fit <ref type="bibr" target="#b22">[23]</ref> introduced a language model and a fine-tuning strategy to effectively adapt the model to various downstream tasks, which pushed transfer learning in the NLP field. Lately, the Transformer architecture <ref type="bibr" target="#b46">[47]</ref> has dominated the scene, being the bidirectional Transformer encoder (BERT) <ref type="bibr" target="#b17">[18]</ref> the one who established recently state-of-the-art results over several downstream tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Related Work</head><p>Several ways of measuring models have been shown in the past years regarding document classification on the Legacy Tobacco Industry Documents <ref type="bibr" target="#b30">[31]</ref>. Some authors have tested their models on a large-scale sample BigTobacco. Others tried on a smaller version named SmallTobacco, which could be seen as a more realistic scale of annotated data that users might be able to find. Lastly, transfer learning from in-domain datasets has been tested by using BigTobacco to pretrain the models to finally fine-tune on SmallTobacco. <ref type="table" target="#tab_1">Table 2</ref> summarizes the results of previous works in the different categories over time.</p><p>First results in the Deep Learning era have been mainly based on CNNs using transfer learning techniques. Multiple networks were trained on specific sections of the documents <ref type="bibr" target="#b20">[21]</ref> to learn region-based high dimensional features later compressed via Principal Component Analysis (PCA). The use of multiple Deep Learning models was also exploited by Arindam Das et al. by using an ensemble as a meta-classifier <ref type="bibr" target="#b15">[16]</ref>. A VGG-16 <ref type="bibr" target="#b40">[41]</ref> stack of networks using 5 different classifiers has been proposed, one of them trained on the full document and the others specifically over the header, footer, left body and right body. The Multi Layer Perceptron (MLP) was the ensemble that performed the better. A committee of models but with a SVM as the ensemble was also proposed <ref type="bibr" target="#b36">[37]</ref>. The addition of content-based information has been investigated on Small-Tobacco by extracting text through OCR and embedding the obtained features into the original document images as a previous phase to the training process <ref type="bibr" target="#b34">[35]</ref>. Lately, a MobilenetV2 architecture <ref type="bibr" target="#b37">[38]</ref> together with a CNN 2D <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b48">49]</ref> taking as input FastText embeddings <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b24">25]</ref> have achieved the best results in SmallTobacco <ref type="bibr" target="#b5">[6]</ref>.</p><p>A study of several CNNs was carried out <ref type="bibr" target="#b1">[2]</ref>, where VGG-16 architecture was found optimal. Afzal et al. also demonstrated that transfer learning from in-domain datataset like BigTobacco increases by a large margin the results in SmallTobacco. This was further investigated by adding content-based information with CNN 2D with ranking textual features (ACC2) to the OCR extracted.</p><p>As far as we are concerned, there is no study about the use of multiple GPUs in the training process for the task of Document Image Classification. However, parallelizing a computer vision task has been shown to work properly using ResNet-50, which is a widely used network that usually gives good results despite its low complexity architecture. Several training procedures are demonstrated to work effectively with this model <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b19">20]</ref>. A learning rate value proportional to the batch size, warmup learning rate behaviour, batch normalization, SGD to RMSProp optimizer transition are some of the techniques exposed in these works. A study of the distributed training methods using ResNet-50 architecture on a HPC cluster is shown in <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11]</ref>. To know more about the algorithms used in this field we refer to <ref type="bibr" target="#b7">[8]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Proposed Approach</head><p>In this section we present the models used and a brief explanation of them. We also show the training procedure used in both BigTobacco and SmallTobacco and the pipeline of our approach to the problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Image model</head><p>EfficientNets <ref type="bibr" target="#b44">[45]</ref> are a set of light CNNs designed to scale up in a structured manner. The network's width (w ), depth (d ) and resolution (r ) are defined as: w = α φ , d = β φ and r = γ φ , where φ is the scaling compound coefficient. The optimization problem is set by constraining α·β 2 ·γ 2 ≈ 2 and α ≥ 1, β ≥ 1, γ ≥ 1.</p><p>By means of a grid search of α, β, γ with AutoML MNAS framework <ref type="bibr" target="#b43">[44]</ref> and fixing φ = 1, a baseline model (B0) is generated optimizing FLOPs and accuracy. Then, the baseline network is scaled up uniformly fixing α, β, γ and increasing φ. We find that scaling the resolution parameter as proposed in <ref type="bibr" target="#b44">[45]</ref> does not improve the accuracy obtained. In our experiments in Section 5 we proceed with an input image size of 384 × 384, which corresponds to a resolution r = 1.71, as proposed by Tensmeyer et al. in <ref type="bibr" target="#b45">[46]</ref> with AlexNet architecture <ref type="bibr" target="#b27">[28]</ref>.</p><p>The main block of the EfficientNets is the mobile inverted bottleneck convolution <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b43">44]</ref>. This block is formed by two linear bottlenecks connected through both a shortcut connection and an intermediate expansion layer with a depthwise separable convolution (3 × 3) <ref type="bibr" target="#b12">[13]</ref>. Probabilities P (class|F C) are obtained by applying the softmax function on top of the fully connected layer FC of the EfficientNet model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pre-training on BigTobacco</head><p>We train EfficientNets (pre-trained previously on ImageNet) on BigTobacco using Stochastic Gradient Descent for 20 epochs with Learning Rate Warmup strategy <ref type="bibr" target="#b21">[22]</ref>, specifically we follow STLR (Slanted Triangular Learning Rate) <ref type="bibr" target="#b22">[23]</ref> which linearly increases the learning rate at the beginning of the training process and linearly decreases it after a certain number of iterations. We chose the reference learning rate η following the formula proposed in <ref type="bibr" target="#b19">[20]</ref> and used in <ref type="bibr" target="#b3">[4]</ref> and <ref type="bibr" target="#b21">[22]</ref>. Specifically, we set η = 0.2 · nk 256 , where k denotes the number of workers (GPUs) and n the number of samples per worker. <ref type="figure" target="#fig_0">Figure 1</ref> shows the multi-GPU training procedure to get EfficientNet BigTobacco , which represents EfficientNet model pre-trained on BigTobacco. EfficientNet is loaded with ImageNet weights (EfficientNet ImageNet ) and then located in different GPUs within the same node.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fine-tuning on SmallTobacco</head><p>We fine-tune on SmallTobacco the pre-trained models by freezing the entire network but the last softmax layer. Just 5 epochs are enough to get the peak of accuracy. STLR is used this time with η = 0.8· nk 256 . Since only the last layer is trained, we reduce the risk of catastrophic forgetting <ref type="bibr" target="#b32">[33]</ref>. Final fine-tuned model is represented as EfficientNet BigTobacco in <ref type="figure" target="#fig_0">Figure 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3D Pixels matrix</head><p>BigTobacco  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Text model</head><p>Predictions from OCR Tesseract <ref type="bibr" target="#b41">[42]</ref> are obtained by means of the BERT model <ref type="bibr" target="#b17">[18]</ref>. BERT is a multi-layer bidirectional Transformer encoder model pre-trained on a large corpus. In this work we use a modification of the original pre-trained BERT BASE version. In our case, we reduce to 6 the number of BERT layers since we find less variance in the final results and faster training/inference times. The output vector size is kept to 768. The maximum length of the input sequence is set to 512 tokens. The first token of the sequence is defined as [CLS], while [SEP ] is the token used at the end of each sequence. A fully connected layer is added to the final hidden state of the [CLS] token h <ref type="bibr">[CLS]</ref> of the BERT model, which is a representation of the whole sequence. Then, a softmax operation is performed giving P (class|h <ref type="bibr">[CLS]</ref> ) the probabilities of the output vector h <ref type="bibr">[CLS]</ref> , i.e the whole input sequence, pertaining to a certain class.</p><p>The training strategies used in this paper are similar to the ones proposed in <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b42">43]</ref>. We use a learning rate η B = 3e −5 for the embedding, pooling and encoder layers while a a custom learning rate η C = 1e −6 for the layers on top of the BERT model. A decay factor ξ = 1e −8 is used to reduce gradually the learning rate along the layers, η l = ξ · η l−1 . ADAM optimizer with β 1 = 0.9 and β 2 = 0.999 and L 2 -weight decay factor of 0.01 is used. The dropout probability is set at 0.2. Just 5 epochs are enough to find the peak of accuracy with a batch size of 6, the maximum we could use due to memory constraints.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Image and Text ensemble</head><p>In order to get the final enhanced prediction of the combination of both text and image model we use a simple ensemble as in <ref type="bibr" target="#b4">[5]</ref>.</p><formula xml:id="formula_0">P (class|out image , out text ) = w 1 · P (class|h [CLS] ) + w 2 · P (class|F C) P redicted Class = arg max class (P (class|out image , out text ))</formula><p>In this work w 1 , w 2 = 0.5 are found optimal. These parameters could be found by a grid search where N i=1 w i = 1, being N the number of models. This procedure shows to be an effective solution when both models have a similar accuracy and it allows us to avoid another training phase <ref type="bibr" target="#b5">[6]</ref>. In <ref type="figure">Figure 2</ref> this whole process is depicted. Predicted class <ref type="figure">Fig. 2</ref>: Pipeline of the proposed multimodal approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3D Pixels matrix</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>In this section we compare the performance of the different EfficientNets in SmallTobacco and BigTobacco as showed in <ref type="table" target="#tab_1">Table 2</ref> and demostrate the benefits of the multiple GPU training. Experiments have been carried out using GPUs clusters Power-CTE 7 of the Barcelona Supercomputing Center -Centro Nacional de Supercomputacin 8 , each one composed by: 2 IBM Power9 8335-GTGH at 2.40GHz (20 cores and 4 threads/core), 512GB of main memory distributed in 16 dimms × 32GB at 2666MHz and 4 GPU NVIDIA V100 (Volta) with 16GB HBM2.</p><p>The operating system is RedHat Linux 7.4. The models and their training are implemented with PyTorch 9 version 1.0 running on CUDA 10.1 and using cuDNN 7.6.4.</p><p>The only modification done to the images is a resize to 384 × 384 as explained in Section 4.1 and, in order to avoid overfitting, a shear transformation of an angle θ ∈ [−5 • , 5 • ] <ref type="bibr" target="#b45">[46]</ref> which is randomly applied in the training phase. No other modifications are used in our experiments. Source code is at https:// javiferran.github.io/document-classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Evaluation</head><p>In order to compare with previous results in SmallTobacco dataset, we divide the dataset following the procedure in <ref type="bibr" target="#b23">[24]</ref>. Documents are split in training, test and validation sets, containing 800, 2482 and 200 samples each one. 10 different splits of the dataset are created by randomly sampling from the 3482 documents, so that 100 samples per class are guaranteed between train and validation sets. In the <ref type="figure" target="#fig_2">Figure 4</ref> we give the accuracy on SmallTobacco as the median over the 10 dataset splits to compare with previous results. Accuracy on BigTobacco is shown as the one achieved on the test set. BigTobacco dataset used in Section 5.3 is slightly modified, where overlapping documents with SmallTobacco are extracted. Top performing model's accuracies are written down in <ref type="table" target="#tab_1">Table 2</ref>. We show in <ref type="figure" target="#fig_1">Figure 3</ref> the time it takes to train the different networks while using 1, 2, 3 or 4 GPUs in a single node. In order to take advantage of the multiple GPUs we use data parallelism, which consists of placing a copy of the model in each of them. Since every GPU share parameters, it is equivalent to having a single GPU with a larger batch size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Results on BigTobacco</head><p>The time reduction to complete the entire training process with B0 variant is ≈ 61.14% lower when compared with B4 (4 GPUs). Time reduction by using multiple GPUs is clearly showed in the left plot of <ref type="figure" target="#fig_1">Figure 3</ref>. For instance, EfficientNet-B0 benefits from a ≈ 75.4% time reduction after parallelizing over 4 GPUs. The total training time of the EfficientNets on the different number of GPUs is showed in the right side of <ref type="figure" target="#fig_1">Figure 3</ref>. The best performing model in BigTobacco dataset is EfficienNet-B4 with 92.31% accuracy in the test set.  Accuracies of the EfficientNets pre-trained on BigTobacco and finally finetuned on SmallTobacco are depicted in the left plot of <ref type="figure" target="#fig_2">Figure 4</ref>. Simpler models perform with less variability between the 10 random splits than the heavier ones. The best performing model is the EfficientNet-B1, achieving a new state-of-art accuracy of 94.04% median over 10 splits.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Results on SmallTobacco</head><p>In this work, we also wanted to test the potential of light EfficientNet models on a small dataset such as SmallTobacco without the use of transfer learning from in-domain dataset, and compared it with the previous state-of-the-art. Results given by our proposed method described in Section 4.3 are shown in the right plot of <ref type="figure" target="#fig_2">Figure 4</ref>. Although we perform the tests over 10 different random splits to give a wider view of how these models work, in order to compare with Audebert et al. <ref type="bibr" target="#b5">[6]</ref> we calculate the average over 3 random splits, which gives us a 89.47% accuracy.</p><p>Every ensemble model achieves better accuracy than previous results, and again, there is almost no difference between different EfficientNets results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Parallel platforms</head><p>Single GPU training requires a huge amount of time, especially when dealing with heavy architectures like in the case of the EfficientNet-B4, which takes almost two days to complete the whole training phase. For this reason, experimenting with several workers is crucial to minimize the amount of time spent on this tasks. We test the same model and training procedure with two of the main used frameworks to train Deep Learning models, PyTorch and Tensorflow <ref type="bibr" target="#b9">10</ref> . In both cases we use their own APIs for making a synchronous distributed training in several GPUs by means of data parallelism, where training on each GPU is done in its own process. We use PyTorch's DistributedDataParallel and Tensorflow's tf.distribute.Strategy (tf.distribute.MirroredStrategy). In both libraries data is loaded from the disk to page-locked memory in each host, and from there to each GPU in a parallel fashion by means of multiple workers. Each GPU is ensured to get a minibatch with non overlapping data. Every GPU has an identical copy of the model and each one does its own forward pass. Finally, NCCL is utilized as a backend to run the all-reduce algorithm to compute the gradients in parallel between GPUs, before updating the model parameters. Since we have not been able to apply the shear transformation efficiently in Tensorflow, we show the results of both frameworks without that preprocess. For this experiment we use the B0, B2 and B4 EfficientNets models. The time it takes to train each model is showed on the left side of <ref type="figure" target="#fig_3">Figure 5</ref>. PyTorch training is faster and the speedup more linear than in the case of TensorFlow. Some of this difference could be due to the data loading process, which we have not fully optimized in TensorFlow framework. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper we have presented the use of EfficientNets for the Document Image Classification task and their scaling capabilities through several GPUs. By means of two versions of the Legacy Tobacco Industry Documents, a huge and a small dataset, we demonstrated the training process to obtain high accuracy in both of them. We have compared the different versions of the EfficientNets and raised the state-of-the-art classification accuracy to 92.31% in BigTobacco and 94.04% when fine-tuned in SmallTobacco. We can consider the B0 the best choice when considering limited computational resources. We have also presented an ensemble method by adding the content extracted by OCR. A reduced version of the BERT model is trained and both models predictions are combined to achieve a new state-of-the-art accuracy of 89.47%. Finally, we have tested the same image models and training procedures in Tensorflow and PyTorch, where we have observed similar speedup values exploiting their libraries for distributed training. We have also tried distributed training in several GPU nodes by means Horovod framework <ref type="bibr" target="#b38">[39]</ref>, however the stack of software in our IBM Power 9 cluster is still in its early stages and we have not been able to obtain desired results. Nevertheless, future work may focus in testing this approach.</p><p>Future work may also evaluate the use of different OCR engines, as we suspect this could have a great impact on the quality of the text model predictions.</p><p>With this work we also want to provide to researchers a benchmark in the Document Image Classification task, which can serve as a reference point to effortlessly test parallel systems in both PyTorch and TensorFlow.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 :</head><label>1</label><figDesc>Pipeline of the different stages of the pre-training of EfficientNet over multiple GPUs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 :</head><label>3</label><figDesc>Left: speedup of the training process when parallelizing. Right: total time (hours) to train each model on different number of GPUs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 :</head><label>4</label><figDesc>Accuracy obtained in SmallTobacco by models pre-trainined on BigTobacco (Left) and without BigTobacco pre-training (Right). Previous state-ofthe-art (SOTA) results are shown with a horizontal dashed line.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 :</head><label>5</label><figDesc>Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Linear Left: the time to complete a whole training process. Right: speedup curves of TensorFlow and PyTorch.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Parameters of the CNNs architectures used in BigTobacco.</figDesc><table><row><cell>Model</cell><cell>#Params</cell></row><row><cell>AlexNet</cell><cell>60.97M</cell></row><row><cell>VGG-16</cell><cell>138.36M</cell></row><row><cell>ResNet-50</cell><cell>25.56M</cell></row><row><cell>Inception-V3</cell><cell>23.83M</cell></row><row><cell>EfficientNet-B2</cell><cell>9.2M</cell></row><row><cell>EfficientNet-B0</cell><cell>5.3M</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Previous results comparison (accuracy in %).</figDesc><table><row><cell></cell><cell>BigTobacco</cell><cell></cell><cell cols="2">SmallTobacco</cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="4">BigTobacco Pre-training No Pre-training</cell></row><row><cell>Author</cell><cell>Image</cell><cell cols="4">Image Image + Text Image Image + Text</cell></row><row><cell>Kumar et al. (2014)[24]</cell><cell></cell><cell></cell><cell></cell><cell>43.8</cell><cell></cell></row><row><cell>Kang et al. (2014)[26]</cell><cell></cell><cell></cell><cell></cell><cell>65.37</cell><cell></cell></row><row><cell>Afzal et al. (2015)[1]</cell><cell></cell><cell></cell><cell></cell><cell>77.6</cell><cell></cell></row><row><cell>Harley et al. (2015)[21]</cell><cell>89.8</cell><cell></cell><cell></cell><cell>79.9</cell><cell></cell></row><row><cell>Csurka et al. (2016)[15]</cell><cell>90.7</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Noce et al. (2016)[35]</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>79.8</cell></row><row><cell>Afzal et al. (2017)[2]</cell><cell>90.97</cell><cell>91.13</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Tensmeyer et al. (2018)[46]</cell><cell>90.8</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Das et al. (2018)[16]</cell><cell>92.21</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Audebert et al. (2019)[6]</cell><cell></cell><cell></cell><cell></cell><cell>84.5</cell><cell>87.8</cell></row><row><cell>Asim et al. (2019)[5]</cell><cell></cell><cell>93.2 5</cell><cell>95.8 6</cell><cell></cell><cell></cell></row><row><cell>Proposed work (2020)</cell><cell>92.31</cell><cell>94.04</cell><cell>94.9</cell><cell>85.99</cell><cell>89.47</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA SOTA</figDesc><table><row><cell></cell><cell>94</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>93</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Accuracy(%)</cell><cell>90 92</cell><cell></cell><cell></cell><cell></cell><cell>Accuracy(%)</cell><cell>89 90 91 92</cell><cell></cell><cell></cell><cell></cell><cell>model b0 b1 b2 b3 b4</cell></row><row><cell></cell><cell>88</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>88</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>87</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>b0</cell><cell>b1</cell><cell>b2</cell><cell>b3</cell><cell>b4</cell><cell>b0</cell><cell>b1</cell><cell>b2</cell><cell>b3</cell><cell>b4</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Model</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Model</cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">Accuracy obtained in 9 classes that overlap in BigTobacco 6 Evaluation method not specified</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7">https://www.bsc.es/support/POWER CTE-ug.pdf 8 https://www.bsc.es</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9">https://pytorch.org/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10">https://www.tensorflow.org/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Acknowledgements</head><p>This work was partially supported by the Spanish Ministry of Science and Innovation and the European Regional Development Fund under contract TIN2015-65316-P, by the BSC-CNS Severo Ochoa program SEV-2015-0493, and grant 2017-SGR-1414 by Generalitat de Catalunya and by the research agreement CaixaBank-BSC 2016-2021.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Deepdocclassifier: Document classification with deep convolutional neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">Z</forename><surname>Afzal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Capobianco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Marinai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Breuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dengel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liwicki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In: ICDAR. p</title>
		<imprint>
			<biblScope unit="page">12731278</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Cutting the error by half: Investigation of very deep cnn and advanced training strategies for document image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">Z</forename><surname>Afzal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Klsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A M</forename><surname>Liwicki</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>ICDAR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Aggarwal</surname></persName>
		</author>
		<title level="m">Neural Networks and Deep Learning: A Textbook</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Akiba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Suzuki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Fukuda</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.04325</idno>
		<title level="m">Extremely large minibatch sgd: Training resnet-50 on imagenet in 15 minutes</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Two stream deep network for document image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">N</forename><surname>Asim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">U G</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Razzaque</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dengel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ahmed</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ICDAR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Multimodal deep networks for text and image-based document classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Audebert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Herold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Slimani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Vidal</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>APIA</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Using tree-grammars for training set expansion in page classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Baldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Marinai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Soda</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<publisher>ICDAR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Demystifying parallel and distributed deep learning: An indepth concurrency analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ben-Nun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hoefler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys. vol</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Enriching word vectors with subword information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trans. Assoc. Comput. Linguist (TACL</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Scaling a convolutional neural network for classification of adjective noun pairs with tensorflow on gpu clusters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Campos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sastre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yagues</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Torres</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><forename type="middle">G</forename><surname>Nieto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="677" to="682" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Distributed training strategies for a computer vision deep learning training algorithm on a distributed gpu cluster</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Campos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sastre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yagues</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">B J</forename><surname>Torres</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><forename type="middle">G</forename><surname>Nieto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICCS. pp</title>
		<imprint>
			<biblScope unit="page" from="315" to="324" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Structured document classification by matching local salient features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Naoi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1558" to="1561" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Xception: Deep learning with depthwise separable convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Chollet</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A clustering-based algorithm for automatic document separation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Collins-Thompson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Nickolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR. p</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page">18</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Csurka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Larlus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gordo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Almazan</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1603.01076</idno>
		<title level="m">What is the right way to represent document images? arXiv preprint</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Document image classification with intra-domain transfer learning and stacked generalization of deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Parui</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ICDAR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Imagenet: a large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">F</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009-06" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>NAACL</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Hidden tree markov models for document image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Diligenti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Frasconi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gori</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Noordhuis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wesolowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kyrola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tulloch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<idno>abs/1706.02677</idno>
		<title level="m">Accurate, large minibatch sgd: Training imagenet in 1 hour. CoRR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Evaluation of deep convolutional nets for document image classification and retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">W</forename><surname>Harley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ufkes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">G</forename><surname>Derpanis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICDAR 2015. IEEE</title>
		<meeting>ICDAR 2015. IEEE</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page">991995</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">M S</forename><surname>Mu Accurate</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.01187</idno>
		<title level="m">Bag of tricks for image classification with convolutional neural networks</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Universal language model fine-tuning for text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ruder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">328339</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Structural similarity for document image classification and retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Jayant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>David</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="119" to="126" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Bag of tricks for efficient text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.01759</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Convolutional neural networks for document image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Doermann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page">31683172</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Convolutional neural networks for sentence classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>EMNLP</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Unsupervised classification of structurally similar document images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Doermann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1225" to="1229" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Learning document structure for retrieval and classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Doermann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="653" to="656" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Building a test collection for complex document information processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Agam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Argamon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Frieder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Grossman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="665" to="666" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Learned in translation: Contextualized word vectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mccann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS. pp</title>
		<imprint>
			<biblScope unit="page" from="6297" to="6308" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Catastrophic interference in connectionist networks: The sequential learning problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mccloskey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">J</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychology of learning and motivation</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="109" to="165" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR Workshop Papers</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Embedded textual content for document image classification with convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Noce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Gallo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zamberletti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Calefati</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 ACM Symposium on Document Engineering (DocEng &apos;16</title>
		<meeting>the 2016 ACM Symposium on Document Engineering (DocEng &apos;16</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Deep contextualized word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NAACL</title>
		<meeting>of NAACL</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Generalized stacking of layerwise-trained deep convolutional neural networks for document image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Bhattacharya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">23rd International Conference on Pattern Recognition (ICPR)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page">12731278</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Menglong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zhmoginov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">C</forename><surname>Chen</surname></persName>
		</author>
		<title level="m">Mobilenetv2: Inverted residuals and linear bottlenecks</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4510" to="4520" />
		</imprint>
	</monogr>
	<note>CVPR</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sergeev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Balso</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.05799</idno>
		<title level="m">Horovod: fast and easy distributed deep learning in TensorFlow</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Document image retrieval based on layout structural similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Doermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IPCV. pp</title>
		<imprint>
			<biblScope unit="page" from="606" to="612" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<idno>abs/1409.1556</idno>
		<imprint>
			<date type="published" when="2014" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">An overview of the tesseract ocr engine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Document Analysis and Recognition (ICDAR)</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">How to fine-tune bert for text classification?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.05583</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Mnasnet: Platform-aware neural architecture search for mobile</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Efficientnet: Rethinking model scaling for convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Analysis of convolutional neural networks for document image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tensmeyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Martinez</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>ICDAR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">U</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page">60006010</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ding</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.05338</idno>
		<title level="m">To tune or not to tune? how about the best of both worlds? arXiv preprint</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">A sensitivity analysis of (and practitioners guide to) convolutional neural networks for sentence classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>Wallace</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1510.03820</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
