<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">End-to-End Learning Local Multi-view Descriptors for 3D Point Clouds</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siyu</forename><surname>Zhu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongbo</forename><surname>Fu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">City University of Hong</orgName>
								<address>
									<settlement>Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Tan</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Simon Fraser University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chiew-Lan</forename><surname>Tai</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alibaba</forename><forename type="middle">A I</forename><surname>Labs</surname></persName>
						</author>
						<title level="a" type="main">End-to-End Learning Local Multi-view Descriptors for 3D Point Clouds</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T05:38+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this work, we propose an end-to-end framework to learn local multi-view descriptors for 3D point clouds. To adopt a similar multi-view representation, existing studies use hand-crafted viewpoints for rendering in a preprocessing stage, which is detached from the subsequent descriptor learning stage. In our framework, we integrate the multiview rendering into neural networks by using a differentiable renderer, which allows the viewpoints to be optimizable parameters for capturing more informative local context of interest points. To obtain discriminative descriptors, we also design a soft-view pooling module to attentively fuse convolutional features across views. Extensive experiments on existing 3D registration benchmarks show that our method outperforms existing local descriptors both quantitatively and qualitatively.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Local descriptors for 3D geometry are widely recognized as one of the cornerstones in many computer vision and graphics tasks, such as correspondence establishment, registration, segmentation, retrieval, etc. Particularly, with the prevalence of consumer-level RGB-D sensors, voluminous scanned data requires robust local descriptors for scene alignment and reconstruction <ref type="bibr" target="#b58">[59,</ref><ref type="bibr" target="#b3">4]</ref>. Such 3D data, however, is often noisy and incomplete, presenting challenges to the design of local descriptors.</p><p>Existing hand-engineered local descriptors <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b51">52,</ref><ref type="bibr" target="#b47">48]</ref>, proposed in the past few decades, are mostly built upon histograms of low-level 3D geometric properties. Recent trends with deep neural networks have motivated researchers to develop learning-based local descriptors in a data-driven manner <ref type="bibr" target="#b65">[66,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b11">12]</ref>. Several types of input representations for 3D local geometry have been explored, such as raw point cloud patches <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b5">6]</ref>, voxel grids <ref type="bibr" target="#b65">[66,</ref><ref type="bibr" target="#b11">12]</ref> and multi-view images <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b66">67]</ref>. Currently, on the geometric registration benchmark of 3DMatch <ref type="bibr" target="#b65">[66]</ref>, most learning-based methods are built upon either Point-Net <ref type="bibr" target="#b40">[41]</ref> with point cloud patches or 3D CNNs with voxel grids, and 3DSmoothNet <ref type="bibr" target="#b11">[12]</ref> achieves the state-of-the-art performance with smoothed density value voxelization. Despite the impressive progress made by the voxel representation, literature on 3D shape recognition and retrieval <ref type="bibr" target="#b49">[50,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b55">56]</ref> indicates superior performance of multi-view images than voxel grids, and some initial attempts <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b66">67]</ref> have been made to extend a similar idea to 3D local descriptors. Meanwhile, a line of recent studies has advanced 2D CNNs in learning local descriptors from a single image patch <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b62">63,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b31">32]</ref>. These motivate us to perform further investigation into a multi-view representation for 3D points and their local geometry.</p><p>The main challenges of adopting the multi-view representation in learning descriptors are as follows. First, to obtain multi-view images, a set of viewpoints (virtual cameras) are needed for 3D graphics rendering pipelines in a preprocessing stage <ref type="bibr" target="#b49">[50,</ref><ref type="bibr" target="#b18">19]</ref>. In existing studies <ref type="bibr" target="#b49">[50,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b16">17]</ref>, the viewpoints are either randomly sampled or heuristically hand-picked. However, how to determine the viewpoints in a data-driven manner to produce more informative renderings for neural networks still remains a question. Second, an effective fusion operation is required to integrate features from multiple views into a single compact descriptor. Max-view pooling is a dominant fusion approach <ref type="bibr" target="#b49">[50,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b55">56]</ref>, but this operation might overlook subtle details <ref type="bibr" target="#b66">[67,</ref><ref type="bibr" target="#b55">56]</ref>, leading to sub-optimal performance.</p><p>In this work, we propose a novel network architecture that learns local multi-view descriptors for 3D point clouds in an end-to-end manner, as illustrated in <ref type="figure" target="#fig_0">Fig. 1</ref>. Our network consists of three main stages: (1) multi-view rendering for a 3D point of interest of a point cloud; <ref type="bibr" target="#b1">(2)</ref> feature extraction in each rendered view; and (3) feature fusion across the views. Specifically, we first use an in-network differentiable renderer <ref type="bibr" target="#b29">[30]</ref> to project the 3D local geometry of a specific point as multi-view patches. Viewpoints used by the renderer are optimizable parameters during training. The renderer can back-propagate supervision signals from rendered pixels to the viewpoints, enabling joint optimization of the rendering stage with the other two stages. Next, to extract features in each rendered view, we leverage existing CNNs that are well matured in the task of learning single patch descriptors <ref type="bibr" target="#b50">[51,</ref><ref type="bibr" target="#b33">34]</ref>. Lastly, to fuse the features across all the views, we examine the gradient flow problem of max-view pooling <ref type="bibr" target="#b49">[50]</ref> and then design a novel soft-view pooling module. The former only considers the strongest response across views for each position in feature maps, while in contrast, our design adaptively aggregates all the responses with attentive weights estimated by a sub-network. In the backward pass, our design allows supervision signals to better flow into each input view for optimization. The experiments conducted on the 3DMatch benchmark <ref type="bibr" target="#b65">[66]</ref> shows that our method outperforms existing hand-crafted and learned descriptors, and is robust against rotation and point density as well.</p><p>Our contributions in this work are summarized as: (1) we propose a novel end-to-end framework for learning local multi-view descriptors of 3D point clouds, with the state-ofthe-art performance; (2) the viewpoints are optimizable via in-network differentiable rendering; (3) a soft-view pooling module fuses features across views attentively with a better gradient flow. We will make our code publicly available.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Hand-crafted 3D Local Descriptors. Over the past few decades, a large body of literature has investigated descriptors for encoding geometric information of local neighborhoods of 3D points. A full review is beyond the scope of this paper. Classic descriptors include, to name a few, Spin Image <ref type="bibr" target="#b19">[20]</ref>, 3D Shape Contexts <ref type="bibr" target="#b10">[11]</ref>, PFH <ref type="bibr" target="#b45">[46]</ref>, FPFH <ref type="bibr" target="#b44">[45]</ref>, SHOT <ref type="bibr" target="#b52">[53]</ref>, and Unique Shape Context <ref type="bibr" target="#b51">[52]</ref>. These handcrafted descriptors are mostly constructed from histograms of low-level geometric properties. Despite the progress made by these descriptors, they may fail to handle well the nuisances commonly observed in real scanned data, like noise, incompleteness, and low resolution <ref type="bibr" target="#b12">[13]</ref>.</p><p>Learned 3D Local Descriptors. With the recent success of deep neural networks <ref type="bibr" target="#b43">[44]</ref>, more attention has been shifted to developing learning-based 3D local descriptors <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b65">66,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b18">19]</ref>. In general, these methods fall into three categories according to input representations, including point cloud patches, voxel grids and multi-view images.</p><p>Point cloud patches are the most straightforward representation for local neighborhoods of points. PointNet, a seminal work done by Qi et al. <ref type="bibr" target="#b40">[41]</ref>, is specifically designed to handle the unstructured nature of point clouds. Studies like <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b60">61]</ref> build upon PointNet to learn descriptors for point cloud patches. There also exist PointNet-based works that learn local descriptors jointly with other tasks, such as keypoint detection <ref type="bibr" target="#b61">[62]</ref> and pose prediction <ref type="bibr" target="#b6">[7]</ref>.</p><p>Voxel grids, used in works like 3DMatch <ref type="bibr" target="#b65">[66]</ref> and 3DSmoothNet <ref type="bibr" target="#b11">[12]</ref>, are a common structured representation for 3D point clouds <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b41">42]</ref>. To reduce noise and boundary effects, Gojcic et al. <ref type="bibr" target="#b11">[12]</ref> proposed to use smoothed density value voxelization in 3DSmoothNet.</p><p>Their method achieves the state-of-the-art performance on the 3DMatch benchmark <ref type="bibr" target="#b65">[66]</ref>, substantially outperforming the aforementioned PointNet-based approaches <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b6">7]</ref>.</p><p>Multi-view images have demonstrated better performance than voxel grids in the task of 3D shape recognition and retrieval <ref type="bibr" target="#b49">[50,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b42">43]</ref>, owing to their ability of delivering rich information of 3D geometry. Motivated by the success in global shape analysis, researchers have extended the multi-view representation to 3D local descriptor learning <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b66">67]</ref>. Huang et al. <ref type="bibr" target="#b18">[19]</ref> re-purposed the CNN architecture from <ref type="bibr" target="#b49">[50,</ref><ref type="bibr" target="#b25">26]</ref> to extract local descriptors of 3D shapes (e.g., airplanes or chairs) from multi-view images, which are rendered offline with clustered viewpoints. There exist studies like <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b42">43]</ref> that use 2D filtering for innetwork image generation from point clouds. In contrast, our work considers the viewpoints as optimizable parameters and performs multi-view rendering with a differentiable renderer <ref type="bibr" target="#b29">[30]</ref> in neural networks.</p><p>To fuse view features into a single compact representation, max-view pooling is widely used owing to its computational efficiency and view-order invariance <ref type="bibr" target="#b49">[50,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b66">67]</ref>, but it tends to overlook subtle details as discussed in <ref type="bibr" target="#b55">[56,</ref><ref type="bibr" target="#b66">67,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b64">65,</ref><ref type="bibr" target="#b36">37]</ref>. Zhou et al. <ref type="bibr" target="#b66">[67]</ref> proposed Fuseption, a residual-learning module for feature fusion, but their module is not view-order invariant and its number of parameters grows with the number of input views. Alternative approaches, such as feature aggregation with NetVLAD <ref type="bibr" target="#b1">[2]</ref> and RNN <ref type="bibr" target="#b15">[16]</ref>, have also been explored, but excessive computation or view ordering is required. Differently, by analyzing the gradient flow of max-view pooling, we propose soft-view pooling that adaptively aggregates features with attentive weights in a view-order invariant manner.</p><p>Differentiable Rendering. The conventional 3D graphics rendering pipeline involves rasterization and visibility test, which are non-differentiable discretization operations with respect to the projected point coordinates and viewdependent depths <ref type="bibr" target="#b29">[30]</ref>. Thus supervision signals cannot flow from the 2D image space to the 3D shape space, preventing the integration of this pipeline into neural networks for end-to-end learning. Recently researchers have designed several differentiable rendering frameworks <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b63">64,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b29">30]</ref> that incorporate approximated gradient formulations for the discretization operations. Among them, Soft Rasterizer (SoftRas), a state-of-the-art differentiable renderer developed by Liu et al. <ref type="bibr" target="#b29">[30]</ref>, treats mesh rendering as a process of probabilistic aggregation of triangles. In this work, we modify SoftRas to extend its application to point cloud rendering and adopt a hard-forward soft-backward scheme.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Methodology</head><p>Given a 3D point cloud P, we aim at training a neural network f that can extract a discriminative local descriptor for a point p ∈ P in an end-to-end manner. To this end, we perform projective analysis on the local geometry of p by using a multi-view representation. Compared to point cloud patches or voxel grids, the multi-view representation can capture different levels of local context more easily <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b41">42]</ref>.</p><p>Our network f is comprised of three stages as shown in <ref type="figure" target="#fig_0">Fig. 1</ref>. First, the network f directly takes the point cloud P and the point of interest p as inputs and employs SoftRas <ref type="bibr" target="#b29">[30]</ref> to render the local neighborhood of p as multi-view patches (Sec. 3.1). Second, we extract convolutional feature maps from each rendered view patch through a lightweight 2D CNN (Sec. 3.2). Lastly, all the extracted view features are compactly fused together by a novel soft-view pooling module to obtain the local descriptor (Sec. 3.3). The three stages of f are jointly trained in an end-to-end manner such that descriptors of corresponding points that are geometrically and semantically similar are close to each other, while descriptors of non-corresponding points are distant to each other (Sec. 3.4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Multi-view Rendering</head><p>Optimizable Viewpoints. Existing multi-view approaches select a set of rendering viewpoints according to certain rules, e.g., by clustering <ref type="bibr" target="#b18">[19]</ref> or circling around a viewing center at a fixed step <ref type="bibr" target="#b49">[50,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b8">9]</ref>. However, this view selection process is detached from the subsequent multiview fusion stage, and thus might produce less representative inputs for the latter. SoftRas allows the viewpoints to be optimizable parameters, which can be jointly trained with other network parameters in later stages. To set up virtual cameras in a look-at manner <ref type="bibr" target="#b0">[1]</ref>, we define the viewpoint parameters as {c k = (θ k , φ k , ρ k , u)} n k=1 using spherical coordinates, where n is the number of viewpoints. Each viewpoint c k is represented by two angles θ k and φ k , the distance ρ k from the local origin and a consistent upright orientation u. Given the point of interest p as the origin, the local reference frame (LRF) for {c k } is defined as follows ( <ref type="figure" target="#fig_1">Fig. 2)</ref>: the z-axis is collinear to the normal of p; the x-axis is the cross product of u and the z-axis (a small per-turbation to u if the normal is parallel to u); and the y-axis is the cross product of the z-axis and x-axis. We constrain {c k } to be within the hemisphere where the point normal resides (Sec. 3.4). To augment rotation invariance in the learned descriptors, we rotate each rendered view patch at 90-degree intervals <ref type="bibr" target="#b18">[19]</ref> (i.e., 4 in-plane rotations) within the network. Thus, a set of 4n view patches are obtained through rendering as detailed next. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Differentiable Rendering.</head><p>To address the nondifferentiable issue of the conventional 3D graphics rendering pipeline ( <ref type="figure" target="#fig_2">Fig. 3-a)</ref>, SoftRas treats mesh rendering as a process of probabilistic aggregation of triangles in 2D. To render the point cloud P as view patches with {c k }, one approach is to firstly transform P to a mesh via surface reconstruction <ref type="bibr" target="#b21">[22]</ref>, which, however, is challenging to integrate into our end-to-end framework and may not handle noise well (e.g., in laser scans of outdoor scenes). Instead, we modify SoftRas to make it amenable to point cloud rendering ( <ref type="figure" target="#fig_2">Fig. 3-b</ref>). We consider each point q j ∈ P as a sphere <ref type="bibr" target="#b18">[19]</ref>, whose radius can be a fixed value <ref type="bibr" target="#b18">[19]</ref> or derived from the average distance between q j and its local neighbors. After perspective projection with a specific viewpoint c k , the point q j produces a probability map D j that describes the probability of each output pixel being covered by q j <ref type="bibr" target="#b29">[30]</ref>. The i-th pixel in the rendering output I (of size 64 × 64) is defined as</p><formula xml:id="formula_0">I i = j w(D i j , z j )C j + w b C b ,<label>(1)</label></formula><p>where C j is the rendered attribute (e.g., color or viewdependent depth) of q j , C b is a default background value, and z j is the depth of q j . The weighting function w(·) designed in <ref type="bibr" target="#b29">[30]</ref> is biased to points that are closer to the camera and the i-th pixel, and j w(·) + w b = 1. Such a linear formulation in Eq. 1 approximates the rasterization and visibility test in the conventional rendering pipeline <ref type="figure" target="#fig_2">(Fig. 3)</ref>, and it is naturally differentiable. Since input point clouds may lack color information, we use view-dependent depth as C j <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b59">60]</ref>, which is invariant to illumination changes. We refer the interested reader to <ref type="bibr" target="#b29">[30]</ref> for detailed implementations and discussions of D j and w(·).  Although the differentiability of Eq. 1 makes it possible for in-network rendering, we observed artifacts, such as blurry pixels at regions with large depth discontinuity, in the rendering outputs (see <ref type="figure" target="#fig_3">Fig. 4</ref>). To mitigate the influence of artifacts on the subsequent feature extraction, we instead adopt a hard-forward soft-backward scheme for rendering point clouds with SoftRas, sharing a similar idea to <ref type="bibr" target="#b20">[21]</ref>. Specifically, in the forward pass, we perform rasterization and visibility test to obtain rendering results in the same way as the conventional rendering pipeline ( <ref type="figure" target="#fig_2">Fig. 3-a)</ref>. In the backward pass, we compute approximated gradients for the rendering using Eq. 1 of SoftRas. We found that this approximation scheme works well in our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Feature Extraction</head><formula xml:id="formula_1">Let {I k } 4n</formula><p>k=1 be the set of multi-view patches produced in the rendering stage for the point p. This 2D representation can naturally lend itself to existing patch analysis networks. We adopt a lightweight CNN backbone similar to L2-Net <ref type="bibr" target="#b50">[51,</ref><ref type="bibr" target="#b33">34]</ref>, a state-of-the-art network for learning local image descriptors. Concretely, the network is composed of six stacked convolutional layers, each followed by normalization <ref type="bibr" target="#b53">[54]</ref> and ReLU layers. We feed each patch I k to the network and obtain a corresponding feature map denoted as F k , which is of size 8 × 8 with 128 channels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Multi-view Fusion</head><p>Given the set of feature maps {F k } 4n k=1 as input, we perform feature fusion across views to obtain a more compact multi-view representation. LetF i denote the feature value at location i of the fused outputF (the same size as F k ), and i iterates over all spatial and channel-wise positions ( <ref type="figure" target="#fig_4">Fig. 5</ref>). Max-view pooling is a widely adopted fusion approach for its simple computation and invariance to view ordering. However, this operation suffers from the following gradient flow problem in back-propagation. Mathematically, max-view pooling can be expressed as</p><formula xml:id="formula_2">F i = k α i k F i k ,<label>(2)</label></formula><p>where k α i k = 1 and the weights {α i k } are in a one-hot form for selecting the maximum value. In the backward pass, the gradient of Eq. 2 is</p><formula xml:id="formula_3">∂F i ∂F i k = 1 if F i k is the maximum value, 0 otherwise.<label>(3)</label></formula><p>Thus, according to the chain rule, supervision signals from loss functions cannot flow into certain locations in F k if the locations do not have the maximum feature values, which may guide CNNs to overlook some details in feature extraction. An alternative approach is average-view pooling with α i k = 1 4n to alleviate the gradient flow problem. However, as shown in existing studies <ref type="bibr" target="#b18">[19]</ref>, this approach performs worse than max-view pooling, partially because treating features equally across views may reduce the contribution of useful features while increasing the effect of insignificant features, leading to less discriminative descriptors.</p><p>Based on the above analysis, we propose soft-view pooling that adaptively estimates attentive weights {α i k } with a sub-network. Specifically, the sub-network takes each F k as input and follows an encoder-decoder design to regress the corresponding weights. The sub-network performs downsampling and then upsampling by a factor of 2 for both spatial size and channel depth, using a 3 × 3 convolutional layer and a 3 × 3 up-convolutional layer respectively, and a ReLU layer in-between. The output weight map is denoted as α k (the same size as F k ). Afterward, for each location i as defined above, the softmax function is applied to {α i k } for normalization so that k α i k = 1 holds. Note that the above computation is invariant to view orders.</p><p>At last, the network f embeds the fused featureF to a d-dimensional descriptor space with a fully-connected layer and a subsequent l2 normalization layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Training</head><p>To train the network f , we sample matching point pairs in the overlapped region of two point clouds (at least 30% overlap). Given a batch of matching point pairs B = {(p i , q i )}, we follow <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b17">18]</ref> to adopt a batch-hard (BH) triplet loss</p><formula xml:id="formula_4">L BH = 1 |B| |B| i=1 m + f (p i ) − f (q i ) 2 − min j=1···|B| j =i f (p i ) − f (q j ) 2 + ,<label>(4)</label></formula><p>where [·] + = max(·, 0), and m is a margin and set to 1. For a training triplet, q i is the positive sample of p i , and L BH considers the hardest negative sample q j within the batch B for p i . As mentioned in Sec. 3.1, we also impose range constraints for the optimizable viewpoints as follows:</p><formula xml:id="formula_5">L OV = 1 n n k=1 x∈{θ k ,φ k ,ρ k } [|x − x a + x b 2 | − x b − x a 2 ] + ,<label>(5)</label></formula><p>where x a = {0, 0, 0.3} and x b = {2π, π/2, 1} for θ k , φ k and ρ k respectively. Thus, the total loss is L = L BH + λL OV , where λ is empirically set to 1.</p><p>We implemented the network with PyTorch <ref type="bibr" target="#b37">[38]</ref>. We set the viewpoint number n = 8 and the descriptor dimension d = 32 (Sec. 4.4). The viewpoint parameters θ k , φ k , and ρ k were initialized randomly within the range in Eq. 5, and u was initialized to [0, −1, 0] . We use Adam <ref type="bibr" target="#b24">[25]</ref> for stochastic gradient descent with |B| = 24 and an initial learning rate of 0.001. The network is trained for 16 epochs, and the learning rate is decayed by 0.1 every 4 epochs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">3DMatch Benchmark</head><p>Dataset. We evaluate the proposed method on the widely adopted geometric registration benchmark from 3DMatch <ref type="bibr" target="#b65">[66]</ref>. The benchmark consists of RGB-D scans of 62 indoor scenes, an ensemble of several existing RGB-D datasets <ref type="bibr" target="#b54">[55,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b58">59,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b13">14]</ref>. The data is split into 54 scenes for training and validation, and 8 scenes for testing. In each scene, point cloud fragments are obtained by fusing 50 consecutive depth frames. For each fragment in the testing set, a set of 5,000 randomly sampled points is provided as keypoints for descriptor extraction.</p><p>Metric. The recall metric is used for comparisons on the testing set by averaging the number of matched point cloud fragments <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b11">12]</ref>. Consider a set of point cloud fragment pairs G = {(P, Q)}, where point clouds P and Q have at least 30% overlap after alignment. For a specific descriptor extraction method g(·), the set of putative matching points between P and Q is computed in the descriptor space as follows:</p><formula xml:id="formula_6">M = {(p ∈ P, q ∈ Q)|g(p) = nn(g(q), g(P))∧ g(q) = nn(g(p), g(Q))},<label>(6)</label></formula><p>where p and q are keypoints and nn(·) is the nearest neighbor search. The recall metric R is then defined as follows:</p><formula xml:id="formula_7">R = 1 |G| |G| i=1 1 |M i | p,q∈Mi p − T i (q) 2 &lt; τ 1 &gt; τ 2 ,<label>(7)</label></formula><p>where [·] is the Iverson bracket, and T i (·) is the groundtruth transformation for aligning the i-th fragment pair in G. The distance threshold τ 1 for matching points is set to 10 cm. The inlier ratio τ 2 ranges from 0.05 to 0.2. To reliably find correct alignment parameters between two overlapping point clouds, the number of RANSAC <ref type="bibr" target="#b9">[10]</ref> iterations is 55,000 for τ 2 = 0.05 and 860 for τ 2 = 0.2 <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b11">12]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Evaluation Results</head><p>Following <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b11">12]</ref>, we compare our method (32-d) with several existing 3D local descriptors on the benchmark. For hand-crafted descriptors, FPFH <ref type="bibr">[</ref>  <ref type="table">Table 1</ref>: Average recall (%) of different methods on the 3DMatch benchmark with τ 1 = 10cm and τ 2 = 0.05 or 0.2.</p><p>LMVCNN with the same CNN backbone and descriptor dimensionality (32-d) as our method. We use the implementations and trained weights from the authors for 3DMatch, CGF and 3DSmoothNet. Since the implementations of PPFNet and PPF-FoldNet are not publicly accessible, we include their reported performance for completeness. <ref type="table">Table 1</ref> shows the comparison results on the benchmark. For τ 2 = 0.05, our method achieves an average recall of 97.5%, outperforming all the competing descriptors. Nevertheless, τ 2 = 0.05 is a relatively loose threshold on 3DMatch, since 3DSmoothNet (95.0%), LMVCNN (96.5%) and our method all have achieved almost saturated performance with relatively small difference. Even so, our method obtains higher recalls in most testing scenes than 3DSmoothNet and LMVCNN. More notably, for a stricter condition τ 2 = 0.2, there is significant improvement of our method over the other competitors. Specifically, our method maintains a high average recall of 86.9%, while 3DSmooth-Net and LMVCNN drop to 72.9% and 81.0%, respectively. The performance of FPFH, SHOT, 3DMatch, and CGF falls below 30%.</p><p>In <ref type="figure" target="#fig_6">Fig. 6</ref>, we plot the average recalls with respect to a range of τ 2 , illustrating the consistency of improvement brought by our method over the compared descriptors under different inlier ratio conditions. Additionally, <ref type="table" target="#tab_2">Table 2</ref> lists the average number of correct correspondences found by each descriptor, which is computed as</p><formula xml:id="formula_8">1 |G| |G| i=1</formula><p>p,q∈Mi p − T i (q) 2 &lt; τ 1 , using the same notations as in Eq. 7. It is observed that our multi-view descriptor is about 1.5× and 1.3× the average number of correspondences of 3DSmoothNet and LMVCNN, respectively. This clearly accounts for the dominant robustness of our descriptor. Additionally, <ref type="figure" target="#fig_8">Fig. 7</ref> visualizes some point cloud registration results obtained by different descriptors with RANSAC. Particularly, it is observed that our descriptor is robust in the registration of fragments with large flat regions (the second row).</p><p>Rotated 3DMatch Benchmark. To evaluate the robustness of the descriptors against rotations, we construct a rotated 3DMatch benchmark <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b11">12]</ref> by rotating the test-      bustness of the descriptors against point density, we follow <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b11">12]</ref> to construct a sparse 3DMatch benchmark. Concretely, for each testing fragment, the keypoints are firstly retained and then 50% or 25% of the remaining points are randomly selected. The evaluation results are shown in Table 3 (the last two columns). It is found that owing to the sphere-based rendering, our method is able to handle different point densities, like LMVCNN and 3DSmoothNet, and maintains the superior performance.   Running Time. <ref type="table" target="#tab_5">Table 4</ref> summarizes the running time for the learned descriptors on the standard 3DMatch benchmark. All the experiments were performed on a PC with an Intel Core i7 @ 3.6GHz, a 32GB RAM and an NVIDIA GTX 1080Ti GPU. The input preparation in <ref type="table" target="#tab_5">Table 4</ref> refers to voxelization with TDF <ref type="bibr" target="#b65">[66]</ref> for 3DMatch, spherical histogram computation <ref type="bibr" target="#b23">[24]</ref> for CGF, LRF computation and SDV voxelization <ref type="bibr" target="#b11">[12]</ref> for 3DSmoothNet, and multi-view rendering (Sec. 3.1) for our method. The inference in <ref type="table" target="#tab_5">Table 4</ref> refers to descriptor extraction from the prepared inputs with neural networks. The results show that the input preparation stage dominates the running time of our method. Additionally, for sphere-based rendering (Sec. 3.1), it takes 0.16ms to determine a point radius by neighborhood query with FLANN <ref type="bibr" target="#b35">[36]</ref> (used in our implementation), while alternatively the computation can be eschewed by using a fixed radius as in <ref type="bibr" target="#b18">[19]</ref>. Nevertheless, our method still demonstrates competitive running time performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Generalization to Outdoor Scenes</head><p>We further evaluate the generalization ability of the descriptors on an outdoor-scene benchmark constructed by Gojcic et al. <ref type="bibr" target="#b11">[12]</ref> with point clouds from the ETH dataset <ref type="bibr" target="#b39">[40]</ref>. This benchmark consists of four scenes, including Gazebo-Summer, Gazebo-Winter, Wood-Summer and Wood-Autumn. The point clouds were obtained by a laser scanner and mostly about outdoor vegetation. Thus, the point clouds are in a large spatial range with a low resolution and contain complex and noisy local geometry. Identical to the 3DMatch benchmark, 5,000 keypoints are randomly sampled in each point cloud for descriptor extraction. The evaluation metric is the same as that in Sec. 4.1. Following <ref type="bibr" target="#b11">[12]</ref>, no fine-tuning is performed for the descriptors trained on the 3DMatch benchmark. To accommodate the low resolution and large spatial range of the point clouds, the voxel grids for 3DMatch and 3DSmoothNet are enlarged with longer edges (3× and 5× respectively) than those in Sec. 4.2. The radius of spherical histogram in CGF is 3.3× longer. For LMVCNN and our method, the distance ρ k in each viewpoint c k is multiplied by a factor of 3.</p><p>The average recall results are shown in <ref type="table" target="#tab_7">Table 5</ref>. Our method (79.9%) achieves comparable performance to 3DSmoothNet (79.0%). Meanwhile, our method significantly outperforms LMVCNN (39.7%) and SHOT (61.1%), and the other descriptors (including CGF, 3DMatch and FPFH) fall below 25%. To account for the deteriorated performance of LMVCNN, further experiments on its used view selection and multi-view fusion strategies are performed in Sec. 4.4. The above results show that our method trained on the 3DMatch benchmark can generalize well to outdoor scenes.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Ablation Study</head><p>Descriptor Dimension &amp; Viewpoint Number. In <ref type="figure" target="#fig_10">Fig. 8</ref> we plot the average recalls of our method with different descriptor dimensions d and viewpoint numbers n (as defined in Sec. 3.3 and Sec. 3.1). It is found that increased descriptor dimensions (d ≥ 32) and viewpoint numbers (n ≥ 8) lead to saturated performance. Thus we adopt d = 32 and n = 8 for our method in the experiments.</p><p>Viewpoints. In <ref type="table">Table 6</ref> (top), we show the performance of our network f trained with different viewpoint selection rules in multi-view rendering. Concretely, the straightforward random sampling rule places the viewpoints randomly within the range in Eq. 5. The viewpoint clustering rule used in LMVCNN <ref type="bibr" target="#b18">[19]</ref> selects three representative viewing directions via K-medoids clustering. The orbited placement rule sets the viewpoints with ρ = 0.3, φ = π/6, and θ at a π/4 step (Sec. 3.1), similar to the strategy used in 3D shape recognition works <ref type="bibr" target="#b49">[50,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b8">9]</ref>. The performance of f without rotation augmentation to the rendered view patches is also provided. It is found that our optimizable viewpoints produce better performance than these alternative view selection rules, especially on the generalization ability to the ETH outdoor dataset.</p><p>Multi-view Fusion. We perform experiments to compare our soft-view pooling with several alternative multiview fusion approaches, including max-view pooling <ref type="bibr" target="#b18">[19]</ref>, Fuseption <ref type="bibr" target="#b66">[67]</ref>, and NetVLAD <ref type="bibr" target="#b1">[2]</ref>. We list the performance of the network f trained with the above fusion approaches in <ref type="table">Table 6</ref> (bottom). While on the 3DMatch dataset the improvement of soft-view pooling is small compared with max-view pooling, our method shows significantly better generalization on the ETH outdoor dataset. This is partially because the low-resolution scans of outdoor vegetation in ETH would produce relatively noisy renderings, presenting challenges to max-view pooling for selecting the strongest feature response. Differently, the response is adaptively gathered in our method with attention. <ref type="bibr" target="#b15">16</ref> 32 64 128 Descriptor Dimension d    <ref type="table">Table 6</ref>: Ablation study of viewpoint selection and multiview fusion on the 3DMatch and ETH benchmarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>We have presented a novel end-to-end framework for learning local multi-view descriptors of 3D point clouds. Our framework performs in-network multi-view rendering with optimizable viewpoints that can be jointly trained with later stages, and integrates convolutional features across views attentively via soft-view pooling. We demonstrate the superior performance of our method and its generalization to outdoor scenes through experiments. For future work, it is worth investigating the acceleration of differentiable multi-view rendering of point clouds and the extension of our framework to other tasks such as 3D object detection and recognition in point clouds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Supplementary Material</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">CNN</head><p>In Sec. 3.2 of the main text, we adopt a CNN architecture similar to L2-Net <ref type="bibr" target="#b50">[51]</ref> to extract feature maps for each view patch. The detailed configuration of the network is listed in <ref type="table">Table 7</ref>. Note that the network input is of size 64×64 with a single depth channel, and the final output is of size 8×8 with 128 feature channels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head># Layer</head><p>Kernel Stride Padding  <ref type="table">Table 7</ref>: CNN backbone for feature extraction of each view patch. In the Kernel column, the first two numbers represent the kernel size, and the third number is the number of output feature channels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Multi-view Rendering</head><p>In <ref type="figure">Fig. 9</ref>, we visualize the optimizable viewpoints after training. We also show the viewpoints obtained by a clustering scheme similar to the one in <ref type="bibr" target="#b18">[19]</ref>. Specifically, 150 spherical coordinates (θ, φ) are randomly sampled on the hemisphere where point normals reside, and then the kmedoids clustering algorithm is applied to select three viewing directions. For each viewing direction, a virtual camera is placed at distances of 0.3m, 0.6m, 0.9m to the points of interest, and each rendered view patch is augmented with four in-plane rotations.</p><p>As shown in <ref type="figure">Fig. 9</ref>, there are mainly two differences between the hand-crafted rule and our method. First, the hand-crafted rule places some viewpoints far from points of interest, while the learnt viewpoints have more concentrated distance range, indicating the relatively low importance of broader global context. Second, the hand-crafted rule selects some dominant viewing directions through clustering, whereas the learnt viewpoints have more distributed viewing directions around the points of interests, which can help to capture more local geometry variance. In sum, the learnt viewpoints effectively balance the extent of contextawareness and local details in extracted descriptors, challenging the design wisdom of hand-crafted rules. <ref type="figure">Figure 9</ref>: Visualization of viewpoints obtained by a clustering scheme and our method. The red spheres denote the points of interest, and the pyramids represent virtual cameras.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.">Multi-view Fusion</head><p>In Sec. 4.4 of the main text, we compared the proposed soft-view pooling with alternative fusion approaches including max-view pooling <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b41">42]</ref>, Fuseption <ref type="bibr" target="#b66">[67]</ref>, and NetVLAD <ref type="bibr" target="#b1">[2]</ref>. Fuseption has two branches: in the first branch, the feature maps of all the views are first channelwise concatenated together in a specific order and then fed into a convolutional block; in the second branch, maxpooling is applied to the inputs and the results are added to the output of the first branch, serving as a shortcut connection. NetVLAD is a descriptor pooling method that summarizes the residuals of each input w.r.t. several learnable cluster centers. The number of cluster centers is a hyper parameter, which is set to eight in our experiments. The network f is trained with the alternative fusion approaches, while the other stages are kept unchanged. The descriptor dimension d is set to 32, and the optimizable viewpoint number n is set to 8.</p><p>In <ref type="figure" target="#fig_0">Fig. 10</ref>, we visualize the rendered multi-view inputs to CNNs, extracted feature maps for each view, and fused feature maps across views. It is observed that the CNN is influenced by multi-view fusion for feature extraction. Before fusion, for soft-view pooling and NetVLAD, the feature maps of each view extracted by the CNN tend to have more response, compared to max-view pooling and Fuseption. After fusion, the feature maps produced by max-view pooling and NetVLAD tend to have more high response than soft-view pooling and Fuseption. Note that for each location in the fused feature maps, max-view pooling only selects the strongest input response across views and discards the rest, while our soft-view pooling collectively considers all the inputs in an attentive manner for integration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4.">Comparisons with 3DSmoothNet</head><p>In <ref type="figure" target="#fig_0">Fig. 11</ref>, we visualize the color-coded local descriptors for all the points in the point clouds. Specifically, we project the high dimensional descriptors with PCA and keep the first three components, which are color-coded. It is observed that the descriptors of 3DSmoothNet and our method are both geometry-aware. Particularly, our method is able to capture more geometric changes in the point clouds (see the highlighted wall, pillow and floor regions of the point clouds in <ref type="figure" target="#fig_0">Fig. 11</ref>). In <ref type="figure" target="#fig_0">Fig. 12</ref>, we show additional geometric registration results of point cloud pairs, which further demonstrate the above advantage of our method.</p><p>For the running time of 3DSmoothNet in Sec. 4.2 of the main text, we observed some gap between our experiment results (input prep: 39.4ms; inference: 0.2ms) and the performance reported by the authors (input prep: 4.2ms; inference: 0.3ms). We used the source code 1 of 3DSmoothNet released by the authors, and the running time gap of input preparation is likely due to the difference of hardware configurations. In <ref type="bibr" target="#b11">[12]</ref>, they used a PC with an Intel Xeon E5-1650, a 32GB RAM and an NVIDIA GeForce GTX 1080 GPU, while we used a PC with an Intel Core i7 @ 3.6GHz, a 32GB RAM and an NVIDIA GTX 1080Ti GPU. Their input preparation stage involving LRF computation and SDV voxelization runs on CPU, which may be accelerated with GPU for further improvement.   </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>An end-to-end network that learns local multi-view descriptors for point clouds. The network takes point clouds as input and performs in-network multi-view rendering with a differentiable renderer for points of interest. Feature maps are extracted individually from each view and fused together via a soft-view pooling module to obtain the final descriptors.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Local spherical coordinates (θ k , φ k , ρ k ) for a viewpoint c k .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Rendering pipelines for point clouds: (a) Conventional 3D graphics rendering; (b) Soft Rasterizer<ref type="bibr" target="#b29">[30]</ref> extended to 3D point cloud rendering.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Multi-view rendering samples (depth, size = 64×64) for a point p. Top: renderings of our hard-forward soft-backward scheme (Fig. 3-a); Bottom: renderings of Soft Rasterizer<ref type="bibr" target="#b29">[30]</ref> (Fig. 3-b).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Multi-view fusion at location i that iterates over all spatial and channel-wise positions (top: feature maps of each view; bottom: fused feature maps).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Average recall (%) w.r.t inlier ratio τ 2 on the 3DMatch benchmark.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>FPFH</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 7 :</head><label>7</label><figDesc>Geometric registration of point cloud 1 and point cloud 2 by different descriptors with RANSAC.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 8 :</head><label>8</label><figDesc>Average recall (%) w.r.t descriptor dimension d and viewpoint number n on the 3DMatch benchmark.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 10 :</head><label>10</label><figDesc>Visualizations for multi-view fusion by different methods. The top part is for the red keypoint while the bottom part is for the green keypoint. In each block, we visualize the view patches (depth) rendered with eight optimizable viewpoints on the left. On the right are the corresponding convolutional feature maps (with channel indices {1, 2, 4, 8, 16, 32, 64, 128}) before fusion, and each row is for a specific view. Fused feature maps across views are placed on the bottom.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 11 :</head><label>11</label><figDesc>Visualization of local descriptors for 3DSmoothNet and our method. The high dimensional descriptors are projected with PCA to 3D space and color-coded. The highlighted regions show that our method can better capture geometric changes in the point clouds.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 12 :</head><label>12</label><figDesc>More geometric registration results with RANSAC for 3DSmoothNet and our method.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Average number of correct correspondences on the 3DMatch benchmark.ing fragments with randomly sampled axes and angles in [0, 2π]. The keypoint indices of each fragment are kept unchanged.Table 3gives the average recalls for each descriptor in the Rotated column. Our method achieves average recalls of 96.9% and 82.1% for τ 2 = 0.05 and 0.2 respectively, both surpassing the performance of 3DSmoothNet</figDesc><table /><note>(94.9% and 72.7%), LMVCNN (95.7% and 76.7%) as well as the other descriptors. The evaluation results indicate that our method can handle rotation well. Sparse 3DMatch Benchmark. To evaluate the ro-</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Average recall (%) on a rotated or sparse 3DMatch benchmark with τ 1 = 10cm and τ 2 = 0.05 or 0.2.</figDesc><table><row><cell></cell><cell cols="3">Input prep. Inference Total</cell></row><row><cell>3DMatch</cell><cell>0.1</cell><cell>2.0</cell><cell>2.1</cell></row><row><cell>CGF</cell><cell>10.6</cell><cell>0.1</cell><cell>10.7</cell></row><row><cell>3DSmoothNet</cell><cell>39.4</cell><cell>0.2</cell><cell>39.6</cell></row><row><cell>Ours</cell><cell>7.2</cell><cell>1.5</cell><cell>8.7</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Average running time (ms) per point on the 3DMatch benchmark.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 :</head><label>5</label><figDesc>Average recall (%) on the ETH benchmark with τ 1 = 10cm and τ 2 = 0.05.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/zgojcic/3DSmoothNet</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Interactive Computer Graphics: A Top-Down Approach with Shader-Based OpenGL</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Angel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dave</forename><surname>Shreiner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
	<note>6th edition</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">NetVLAD: CNN architecture for weakly supervised place recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Relja</forename><surname>Arandjelovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petr</forename><surname>Gronat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akihiko</forename><surname>Torii</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Pajdla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Sivic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE CVPR</title>
		<meeting>IEEE CVPR</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Learning to predict 3d objects with an interpolation-based differentiable renderer. CoRR, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenzheng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huan</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><forename type="middle">J</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaakko</forename><surname>Lehtinen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Jacobson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanja</forename><surname>Fidler</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1210" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Robust reconstruction of indoor scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungjoon</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian-Yi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE CVPR</title>
		<meeting>IEEE CVPR</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">PPF-FoldNet: Unsupervised learning of rotation invariant 3d local descriptors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haowen</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tolga</forename><surname>Birdal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slobodan</forename><surname>Ilic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">PPFNet: Global context aware local features for robust 3d point matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haowen</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tolga</forename><surname>Birdal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slobodan</forename><surname>Ilic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE CVPR</title>
		<meeting>IEEE CVPR</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">3D local features for direct pairwise registration. CoRR, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haowen</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tolga</forename><surname>Birdal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slobodan</forename><surname>Ilic</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1904" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">3D point cloud registration for localization using a deep neural network autoencoder</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Elbaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Avraham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fischer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE CVPR</title>
		<meeting>IEEE CVPR</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="2472" to="2481" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">GVCNN: Group-view convolutional neural networks for 3d shape recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifan</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zizhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xibin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rongrong</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE CVPR</title>
		<meeting>IEEE CVPR</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Random sample consensus: A paradigm for model fitting with applications to image analysis and automated cartography</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">C</forename><surname>Fischler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bolles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">381395</biblScope>
			<date type="published" when="1981-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Recognizing objects in range data using regional point descriptors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Frome</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Huber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ravi</forename><surname>Kolluri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Bülow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="224" to="237" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The perfect match: 3d point cloud matching with smoothed densities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zan</forename><surname>Gojcic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caifa</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><forename type="middle">D</forename><surname>Wegner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Wieser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE CVPR</title>
		<meeting>IEEE CVPR</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A comprehensive performance evaluation of 3d local feature descriptors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammed</forename><surname>Bennamoun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ferdous</forename><surname>Sohel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianwei</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ngai Ming</forename><surname>Kwok</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">116</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="66" to="89" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Structured global registration of rgb-d scans in indoor environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maciej</forename><surname>Halber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">A</forename><surname>Funkhouser</surname></persName>
		</author>
		<idno>abs/1607.08539</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">MatchNet: Unifying feature and metric learning for patchbased matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xufeng</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sukthankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE CVPR</title>
		<meeting>IEEE CVPR</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3279" to="3286" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">SeqViews2SeqLabels: Learning 3d global features via aggregating sequential views by rnn with attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Vong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zwicker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L P</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TIP</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="658" to="672" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">View n-gram network for 3d object retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinwei</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tengteng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Bai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ICCV</title>
		<meeting>IEEE ICCV</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">In defense of the triplet loss for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Hermans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bastian</forename><surname>Leibe</surname></persName>
		</author>
		<idno>abs/1703.07737</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Learning local shape descriptors from part correspondences with multiview convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haibin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evangelos</forename><surname>Kalogerakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddhartha</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duygu</forename><surname>Ceylan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><forename type="middle">G</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ersin</forename><surname>Yumer</surname></persName>
		</author>
		<idno>6:1-6:14</idno>
	</analytic>
	<monogr>
		<title level="j">ACM TOG</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">11</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Using spin images for efficient object recognition in cluttered 3d scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="433" to="449" />
			<date type="published" when="1999-05-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Neural 3d mesh renderer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroharu</forename><surname>Kato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshitaka</forename><surname>Ushiku</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tatsuya</forename><surname>Harada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE CVPR</title>
		<meeting>IEEE CVPR</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Poisson surface reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Kazhdan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Bolitho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugues</forename><surname>Hoppe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SGP</title>
		<meeting>SGP</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="61" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Learning deep descriptors with scaleaware triplet networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Keller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zetao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabiola</forename><surname>Maffra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrik</forename><surname>Schmuck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margarita</forename><surname>Chli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE CVPR</title>
		<meeting>IEEE CVPR</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Learning compact geometric features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Khoury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian-Yi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ICCV</title>
		<meeting>IEEE ICCV</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Unsupervised feature learning for 3d scene labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICRA</title>
		<meeting>ICRA</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="3050" to="3057" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Sketch-R2CNN: An attentive network for vector sketch recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changqing</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youyi</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingkun</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongbo</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chiew-Lan</forename><surname>Tai</surname></persName>
		</author>
		<idno>abs/1811.08170</idno>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Paparazzi: Surface editing by way of multi-view image processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hsueh-Ti Derek</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Jacobson</surname></persName>
		</author>
		<idno>221:1-221:11</idno>
		<imprint>
			<date type="published" when="2002" />
			<publisher>ACM TOG</publisher>
			<biblScope unit="volume">37</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Soft Rasterizer: A differentiable renderer for image-based 3d reasoning. CoRR, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shichen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianye</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weikai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1786" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">OpenDR: An approximate differentiable renderer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Loper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">GeoDesc: Learning local descriptors by integrating geometry constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zixin</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianwei</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siyu</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Runze</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yao</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tian</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Quan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">VoxNet: A 3d convolutional neural network for real-time object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Maturana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Scherer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IROS</title>
		<meeting>IROS</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="922" to="928" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Working hard to know your neighbor&apos;s margins: Local descriptor learning loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anastasiya</forename><surname>Mishchuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmytro</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filip</forename><surname>Radenovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiri</forename><surname>Matas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="4826" to="4837" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Repeatability is not enough: Learning affine regions via discriminability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmytro</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filip</forename><surname>Radenovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiri</forename><surname>Matas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Fast approximate nearest neighbors with automatic algorithm configuration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>Muja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">G</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VIS-APP</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Generalized max pooling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naila</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florent</forename><surname>Perronnin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE CVPR</title>
		<meeting>IEEE CVPR</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">PyTorch: An imperative style, high-performance deep learning library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Raison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chilamkurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8026" to="8037" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Pix2Vex: Image-to-geometry reconstruction using a smooth differentiable renderer. CoRR, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Petersen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Amit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oliver</forename><surname>Bermano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Deussen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cohen-Or</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1903" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Challenging data sets for point cloud registration algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">François</forename><surname>Pomerleau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francis</forename><surname>Colas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roland</forename><surname>Siegwart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The International Journal of Robotics Research</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page" from="1705" to="1711" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">PointNet: Deep learning on point sets for 3d classification and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><forename type="middle">R</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaichun</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE CVPR</title>
		<meeting>IEEE CVPR</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Volumetric and multi-view cnns for object classification on 3d data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><forename type="middle">R</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Niessner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengyuan</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE CVPR</title>
		<meeting>IEEE CVPR</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A network architecture for point cloud classification via automatic depth images generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Riccardo</forename><surname>Roveri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukas</forename><surname>Rahmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cengiz</forename><surname>Oztireli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Gross</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE CVPR</title>
		<meeting>IEEE CVPR</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="page" from="211" to="252" />
		</imprint>
	</monogr>
	<note>ImageNet large scale visual recognition challenge. IJCV</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Fast point feature histograms (fpfh) for 3d registration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Blodow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Beetz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICRA</title>
		<meeting>ICRA</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="3212" to="3217" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Aligning point cloud views using persistent feature histograms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Blodow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><forename type="middle">C</forename><surname>Marton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Beetz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IROS</title>
		<meeting>IROS</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="3384" to="3391" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">3D is here: Point Cloud Library (PCL)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cousins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICRA</title>
		<meeting>ICRA</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">SHOT: Unique signatures of histograms for surface and texture description</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuele</forename><surname>Salti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federico</forename><surname>Tombari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luigi</forename><surname>Di</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">125</biblScope>
			<biblScope unit="page" from="251" to="264" />
		</imprint>
		<respStmt>
			<orgName>CVIU</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Scene coordinate regression forests for camera relocalization in rgb-d images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shotton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Glocker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Izadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Criminisi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fitzgibbon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE CVPR</title>
		<meeting>IEEE CVPR</meeting>
		<imprint>
			<date type="published" when="2013-06" />
			<biblScope unit="page" from="2930" to="2937" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Evangelos Kalogerakis, and Erik Learned-Miller. Multi-view convolutional neural networks for 3d shape recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhransu</forename><surname>Maji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ICCV</title>
		<meeting>IEEE ICCV</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">L2-Net: Deep learning of discriminative patch descriptor in euclidean space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE CVPR</title>
		<meeting>IEEE CVPR</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Unique shape context for 3d data description</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federico</forename><surname>Tombari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuele</forename><surname>Salti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luigi</forename><forename type="middle">Di</forename><surname>Stefano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 3DOR</title>
		<meeting>3DOR</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="57" to="62" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Unique signatures of histograms for local surface description</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federico</forename><surname>Tombari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuele</forename><surname>Salti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luigi</forename><forename type="middle">Di</forename><surname>Stefano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="356" to="369" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Instance Normalization: The missing ingredient for fast stylization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Ulyanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><forename type="middle">S</forename><surname>Lempitsky</surname></persName>
		</author>
		<idno>abs/1607.08022</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Shahram Izadi, and Cem Keskin. Learning to navigate the energy landscape</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">C</forename><surname>Julien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Valentin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">;</forename><surname>Nießner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Torr</surname></persName>
		</author>
		<idno>abs/1603.05772</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
	<note>Pushmeet Kohli</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Dominant set clustering and pooling for multi-view 3d object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Pelillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaleem</forename><surname>Siddiqi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. BMVC</title>
		<meeting>BMVC</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Learning 3d keypoint descriptors for non-rigid shape matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianwei</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong-Ming</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weize</forename><surname>Quan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaopeng</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">3D ShapeNets: A deep representation for volumetric shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhirong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fisher</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linguang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE CVPR</title>
		<meeting>IEEE CVPR</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1912" to="1920" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">SUN3D: A database of big spaces reconstructed using sfm and object labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxiong</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Owens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ICCV</title>
		<meeting>IEEE ICCV</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Projective feature learning for 3d shapes with multi-view depth images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhige</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ligang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yueshan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CGF</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">3DTNet: Learning local features using 2d and 3d cues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 3DV</title>
		<meeting>3DV</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="435" to="443" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">3DFeat-Net: Weakly supervised local 3d features for point cloud registration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gim Hee</forename><surname>Zi Jian Yew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">LIFT: Learned invariant feature transform</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Kwang Moo Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Trulls</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Lepetit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="467" to="483" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">Differentiable surface splatting for point-based geometry processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename><surname>Yifan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felice</forename><surname>Serena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shihao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cengizöztireli</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Sorkine-Hornung</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ACM TOG</publisher>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Stochastic pooling for regularization of deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Zeiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">3DMatch: Learning local geometric descriptors from rgb-d reconstructions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuran</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Niessner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxiong</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Funkhouser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE CVPR</title>
		<meeting>IEEE CVPR</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Learning and matching multi-view descriptors for registration of point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siyu</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zixin</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianwei</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Runze</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingmin</forename><surname>Zhen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tian</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Quan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
