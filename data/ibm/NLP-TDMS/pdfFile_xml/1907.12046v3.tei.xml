<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Dilated Point Convolutions: On the Receptive Field Size of Point Convolutions on 3D Point Clouds</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francis</forename><surname>Engelmann</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theodora</forename><surname>Kontogianni</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bastian</forename><surname>Leibe</surname></persName>
						</author>
						<title level="a" type="main">Dilated Point Convolutions: On the Receptive Field Size of Point Convolutions on 3D Point Clouds</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T16:14+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this work, we propose Dilated Point Convolutions (DPC). In a thorough ablation study, we show that the receptive field size is directly related to the performance of 3D point cloud processing tasks, including semantic segmentation and object classification. Point convolutions are widely used to efficiently process 3D data representations such as point clouds or graphs. However, we observe that the receptive field size of recent point convolutional networks is inherently limited. Our dilated point convolutions alleviate this issue, they significantly increase the receptive field size of point convolutions. Importantly, our dilation mechanism can easily be integrated into most existing point convolutional networks. To evaluate the resulting network architectures, we visualize the receptive field and report competitive scores on popular point cloud benchmarks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>The past years have witnessed a tremendous development of 3D scene understanding methods on several tasks including semantic segmentation <ref type="bibr" target="#b17">[18]</ref>, object detection <ref type="bibr" target="#b31">[32]</ref>, and instance segmentation <ref type="bibr" target="#b4">[5]</ref>. Recent advancements such as point convolutional layers <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b26">[27]</ref> which can directly operate on 3D point clouds further boosted the field.</p><p>In the 2D image domain, analyzing the receptive field is an important tool for diagnosing and comprehending convolutional neural networks (CNN). The receptive field of a neural unit describes the region of the input data that influences its output value. All input data outside of the receptive field does not contribute to the output. Hence, large receptive fields are important since they enable reasoning on a larger input context. Current successful architectures operating on grid-like data (e.g. images <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b7">[8]</ref>), increase the receptive field implicitly by using deeper network architectures. However, only few works explicitly study the influence of receptive fields in the domain of 2D image CNNs <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b16">[17]</ref>. So far, there is no work analyzing the receptive fields of deep networks operating directly on 3D point clouds. Such a study is particularly challenging, since the theoretical size of receptive fields is difficult to compute due to the non-uniform structure of 3D point clouds. Nevertheless, we argue that the concept of receptive fields is equally important in the 3D domain.</p><p>Point convolutional layers <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b26">[27]</ref> are a major driving force behind the success of networks that can directly operate on unstructured data such as 3D point clouds. Furthermore, they can be seen as a generalization of discrete convolutions. While continuous point convolutions operate <ref type="bibr" target="#b0">1</ref>: All authors are with the Computer Vision Group, Visual Computing Institute at RWTH Aachen University in Aachen, Germany.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Input 3D Point Cloud</head><p>Receptive Field Semantic Segmentation Dilated Point Convolutional Network <ref type="figure">Fig. 1</ref>. This work presents Dilated Point Convolutions (DPC). We observe that existing point convolutional networks have inherently small receptive field sizes. Assisted by this observation, we compare different network architectures and propose our dilation mechanism as a simple yet elegant solution to significantly increase the receptive field size of point convolutions and improve their performance on multiple point cloud processing tasks.</p><p>on data sampled at continuous positions in space, discrete convolutions operate on grid-structured data such as images or voxel-grids, i.e. the data is sampled at discrete positions.</p><p>As such, we propose to visualize the receptive fields to analyze different network architectures and we present a thorough ablation study comparing several strategies which increase the receptive field of point convolutions. Specifically, we look at common strategies to increase the receptive field by 1) stacking convolutional layers and 2) using larger kernel sizes. By visually analyzing the extent of the resulting receptive fields, we notice that their influence still remains rather limited. Motivated by these observations, we propose Dilated Point Convolutions as a means to significantly increase the receptive field size of point convolutions.</p><p>The paper is structured as follows: We start by discussing current methods for 3D point cloud processing and existing works analyzing receptive fields on discrete convolutions. Then, we review Point Convolutions as an instance of continuous convolutions on 3D point clouds. Next, we describe and visualize well established methods for increasing receptive fields, which leads us to the derivation of Dilated Point Convolutions. Finally, in the experimental section, we compare the aforementioned strategies.</p><p>Our contributions are as follows: <ref type="bibr" target="#b0">(1)</ref> We evaluate most commonly used strategies to increase the receptive fields in current methods using point convolutions. <ref type="bibr" target="#b1">(2)</ref> We propose to visualize the receptive field of point convolutions to make educated network design choices. (3) From these observations, we derive Dilated Point Convolutions (DPC) as an elegant mechanism to significantly increase the receptive field size. (4) Using DPCs we are able to report competitive scores on the task of 3D semantic segmentation on S3DIS <ref type="bibr" target="#b0">[1]</ref> and Scan-Net <ref type="bibr" target="#b3">[4]</ref> as well as shape classification on ModelNet40 <ref type="bibr" target="#b27">[28]</ref>.    We propose dilated point convolutions as an elegant mechanism to significantly increase the receptive field of point convolutions resulting in a notable boost in performance at almost no additional computational cost (see <ref type="table" target="#tab_2">Table IV</ref>). Instead of computing the kernel weights g(·) over the k nearest neighbors, we propose to compute the kernel weights over a dilated neighborhood obtained by computing the sorted k · d nearest neighbors and preserving only every d-th point.</p><formula xml:id="formula_0">/ C N z i f Y N i K F w d A Z 3 f x r q Y M D t u a 0 = " &gt; A A A B 9 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B a h F 0 u i o h 4 L X j x W s B / Q h r D Z b t q l m 2 T d 3 R R K 0 t / h x Y M i X v 0 x 3 v w 3 b t s c t P X B w O O 9 G W b m + Y I</formula><formula xml:id="formula_1">0 Z p Y + C W J q K N J q r v y d S H C o 1 C X 3 T G W I 9 V M v e T P z P 6 y Y 6 u H V T F o l E 0 4 g s F g U J R z p G s w R Q n 0 l K N J 8 Y g o l k 5 l Z E h l h i o k 1 O J R O C s / z y K m l d 1 J z L m v N w V a l X 8 z i K c A K n U A U H b q A O 9 9 C A J h B 4 g m d 4 h T d r b L 1 Y 7 9 b H o r V g 5 T P H 8 A f W 5 w + i 4 Z F G &lt; / l a t e x i t &gt; g(p0 p1)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " r z e 0 v I + 1 8 c V Q B F N B K a u a N m L 9 U + 4 = " &gt; A A A B 8 3 i c b V B N S w M x E J 2 t X 7 V + V T 1 6 C V a h H i y 7 V d B j w Y v H C v Y D 2 m X J p t k 2 N J s N S V Y o S / + G F w + K e P X P e P P f m L Z 7 0 N Y H A 4 / 3 Z p i Z F 0 r O t H H d b 6 e w t r 6 x u V X c L u 3 s 7 u 0 f l A + P 2 j p J F a E t k v B E d U O s K W e C t g w z n H a l o j g O O e 2 E 4 7 u Z 3 3 m i S r N E P J q J p H 6 M h 4 J F j G B j p f 6 w K g M X X S I Z e B d B u e L W 3 D n Q K v F y U o E c z a D 8 1 R 8 k J I 2 p M I R j r X u e K 4 2 f Y W U Y 4 X R a 6 q e a S k z G e E h 7 l g o c U + 1 n 8 5 u n 6 N w q A x Q l y p Y w a K 7 + n s h w r P U k D m 1 n j M 1 I L 3 s z 8 T + v l 5 r o 1 s + Y k K m h g i w W R S l H J k G z A N C A K U o M n 1 i C i W L 2 V k R G W G F i b E w l G 4 K 3 / P I q a d d r 3 l X N e 7 i u N M 7 y O I p w A q d Q B Q 9 u o A H 3 0 I Q W E J D w D K / w 5 q T O i / P u f C x a C 0 4 + c w x / 4 H z + A J Q I j / s = &lt; / l a t e x i t &gt; g(p0 p2)</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " L B h 1 e f 3 F i K r 4 L c H o z Y j 2 I Z 8 H 8 s s = " &gt; A A A B 8 3 i c b V B N S w M x E J 2 t X 7 V + V T 1 6 C V a h H i y 7 V d B j w Y v H C v Y D 2 m X J p t k 2 N J s N S V Y o S / + G F w + K e P X P e P P f m L Z 7 0 N Y H A 4 / 3 Z p i Z F 0 r O t H H d b 6 e w t r 6 x u V X c L u 3 s 7 u 0 f l A + P 2 j p J F a E t k v B E d U O s K W e C t g w z n H a l o j g O O e 2 E 4 7 u Z 3 3 m i S r N E P J q J p H 6 M h 4 J F j G B j p f 6 w K g M X X S I Z 1 C + C c s W t u X O g V e L l p A I 5 m k H 5 q z 9 I S B p T Y Q j H W v c 8 V x o / w 8 o w w u m 0 1 E 8 1 l Z i M 8 Z D 2 L B U 4 p t r P 5 j d P 0 b l V B i h K l C 1 h 0 F z 9 P Z H h W O t J H N r O G J u R X v Z m 4 n 9 e L z X R r Z 8 x I V N D B V k s i l K O T I J m A a A B U 5 Q Y P r E E E 8 X s r Y i M s M L E 2 J h K N g R v + e V V 0 q 7 X v K u a 9 3 B d a Z z l c R T h B E 6 h C h 7 c Q A P u o Q k t I C D h G V 7 h z U m d F + f d + V i 0 F p x 8 5 h j + w P n 8 A Z W N j / w = &lt; / l a t e x i t &gt; g(p0 p3)</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " s Q 1 q j F S 1 w s K Q m E K Q N b Q K h K W W p O o = " &gt; A A A B 8 3 i c b V B N S w M x E J 2 t X 7 V + V T 1 6 C V a h H i y 7 V t B j w Y v H C v Y D 2 m X J p t k 2 N J s N S V Y o S / + G F w + K e P X P e P P f m L Z 7 0 N Y H A 4 / 3 Z p i Z F 0 r O t H H d b 6 e w t r 6 x u V X c L u 3 s 7 u 0 f l A + P 2 j p J F a E t k v B E d U O s K W e C t g w z n H a l o j g O O e 2 E 4 7 u Z 3 3 m i S r N E P J q J p H 6 M h 4 J F j G B j p f 6 w K g M X X S I Z 1 C + C c s W t u X O g V e L l p A I 5 m k H 5 q z 9 I S B p T Y Q j H W v c 8 V x o / w 8 o w w u m 0 1 E 8 1 l Z i M 8 Z D 2 L B U 4 p t r P 5 j d P 0 b l V B i h K l C 1 h 0 F z 9 P Z H h W O t J H N r O G J u R X v Z m 4 n 9 e L z X R r Z 8 x I V N D B V k s i l K O T I J m A a A B U 5 Q Y P r E E E 8 X s r Y i M s M L E 2 J h K N g R v + e V V 0 r 6 q e f W a 9 3 B d a Z z l c R T h B E 6 h C h 7 c Q A P u o Q k t I C D h G V 7 h z U m d F + f d + V i 0 F p x 8 5 h j + w P n 8 A Z c S j / 0 = &lt; / l a t e x i t &gt; g(p0 p2)</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " L B h 1 e f 3 F i K r 4 L c H o z Y j 2 I Z 8 H 8 s s = " &gt; A A A B 8 3 i c b V B N S w M x E J 2 t X 7 V + V T 1 6 C V a h H i y 7 V d B j w Y v H C v Y D 2 m X J p t k 2 N J s N S V Y o S / + G F w + K e P X P e P P f m L Z 7 0 N Y H A 4 / 3 Z p i Z F 0 r O t H H d b 6 e w t r 6 x u V X c L u 3 s 7 u 0 f l A + P 2 j p J F a E t k v B E d U O s K W e C t g w z n H a l o j g O O e 2 E 4 7 u Z 3 3 m i S r N E P J q J p H 6 M h 4 J F j G B j p f 6 w K g M X X S I Z 1 C + C c s W t u X O g V e L l p A I 5 m k H 5 q z 9 I S B p T Y Q j H W v c 8 V x o / w 8 o w w u m 0 1 E 8 1 l Z i M 8 Z D 2 L B U 4 p t r P 5 j d P 0 b l V B i h K l C 1 h 0 F z 9 P Z H h W O t J H N r O G J u R X v Z m 4 n 9 e L z X R r Z 8 x I V N D B V k s i l K O T I J m A a A B U 5 Q Y P r E E E 8 X s r Y i M s M L E 2 J h K N g R v + e V V 0 q 7 X v K u a 9 3 B d a Z z l c R T h B E 6 h C h 7 c Q A P u o Q k t I C D h G</head><p>II. RELATED WORK 2D Projection Representation. Qi et al. <ref type="bibr" target="#b18">[19]</ref> and Boulch et al. <ref type="bibr" target="#b1">[2]</ref> project 3D point clouds into 2D representations, then apply 2D convolutional networks and finally fuse the results back into 3D space. These type of projections do not make use of the underlying geometric structure as they only operate on the projected appearance of the point clouds.</p><p>3D Volumetric Grid Representation. Maturana and Scherer <ref type="bibr" target="#b15">[16]</ref> and Song et al. <ref type="bibr" target="#b27">[28]</ref> voxelize point clouds into regular volumetric grids and apply 3D convolutions. These approaches are constrained by the fixed resolution of the 3D grid. Coarse grids lead to loss of detail and fine ones suffer from high memory and computational costs. The use of octrees <ref type="bibr" target="#b20">[21]</ref> and kd-trees <ref type="bibr" target="#b9">[10]</ref> offer improved grid resolutions. Recently, Graham et al. <ref type="bibr" target="#b6">[7]</ref> offered a speed-and memoryefficient approach for sparse 3D convolutions which are applied only on occupied voxels. However, voxelized point clouds can still be problematic if adjacent points are far apart, which can hinder information flow.</p><p>3D Feature Learning on Point Sets. Numerous methods operate directly on 3D point clouds <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b26">[27]</ref>. They follow-up on the seminal work of PointNet <ref type="bibr" target="#b17">[18]</ref> which applies point-wise multi-layer-perceptrons (MLP) followed by max-pooling over all points to extract a global point cloud descriptor but fails to capture local structure. Local structure is implicitly considered in 2D images and 3D voxels by using spatial grids. Filters that incorporate the information of the neighboring points in the grid are then learned. Numerous methods rely on similar types of spatial neighborhoods in an unstructured point cloud: Hua et al. <ref type="bibr" target="#b8">[9]</ref> compute nearest neighbors on the fly and bin them into spatial cells before using fully convolutional networks. Landrieu and Boussaha <ref type="bibr" target="#b10">[11]</ref> compute neighborhoods by oversegmenting 3D point clouds into superpoints. However, the most popular method used by <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b26">[27]</ref> consists in computing the k nearest neighbors (KNN) of every point to represent its neighborhood. EdgeConvs <ref type="bibr" target="#b25">[26]</ref> establish this neighborhood on the feature space while PointConv <ref type="bibr" target="#b26">[27]</ref>, PointNet++ <ref type="bibr" target="#b19">[20]</ref> and PointCNN <ref type="bibr" target="#b13">[14]</ref> use the spatial coordinates. Engelmann et al. <ref type="bibr" target="#b5">[6]</ref> use KNN in the feature space and k-means in the world coordinate system to create neighborhoods.</p><p>Receptive Field Analysis. Few works systematically study the influence of receptive fields on 2D image CNNs <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b16">[17]</ref>. In general, deeper networks which stack multiple layers of 2D convolutions have proven to work better <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b22">[23]</ref>. Dilated convolutions <ref type="bibr" target="#b29">[30]</ref>, previously introduced as atrous convolutions <ref type="bibr" target="#b2">[3]</ref>, used in 2D image semantic segmentation, allow to efficiently enlarge the receptive field of filters to incorporate larger context without increasing the number of model parameters. In this work, we propose a simple yet effective dilation mechanism for 3D point convolutions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. APPROACH</head><p>In this section, we formally define point convolutions and examine the importance of a large receptive field size in the context of 3D point cloud processing. We revisit existing strategies to increase the receptive field. Then, we propose our main contribution dilated point convolutions, an elegant yet easy technique to significantly increase the receptive field size of point convolutional networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Point Convolutions</head><p>Point convolutions can be formulated using the general definition of continuous convolutions in a D-dimensional space. Continuous convolutions are defined as</p><formula xml:id="formula_2">f * g (p i ) = +∞ −∞ f (p j ) g(p i − p j ) dp j ,<label>(1)</label></formula><p>where is the Hadamard-product of the continuous feature function f : R D → R F assigning a feature-vector f (p j ) ∈ R F to each position p j ∈ R D , and the continuous kernel function g : R D → R F mapping a relative position to a kernel weight. In the case of 3D point clouds, we have D = 3 and the feature vector could for example contain the point position, color, and normal such that f (p) ∈ R 9 , see <ref type="figure" target="#fig_3">Figure 2</ref>. In most practical applications, e.g. reconstructed 3D point clouds, the feature function f is not fully known since only a limited number N of point positions p n are observed or even occupied. Using Monte-Carlo integration, the continuous convolution can then be approximated as where recent methods implement the kernel function g(·) as a learned parametric function based on a multi-layer perceptron (MLP)</p><formula xml:id="formula_3">f * g (p i ) ≈ 1 N N n=1 f (p n ) g(p i − p n ),<label>(2)</label></formula><formula xml:id="formula_4">g(p; θ) = MLP(p ; θ),<label>(3)</label></formula><p>where p is the relative position between two points and θ is a set of learned parameters. In order to extract high-frequency signals it is important to define localized kernels <ref type="bibr" target="#b30">[31]</ref>. In 2D image CNNs, this is implemented by e.g. 3 × 3 or 5 × 5 pixel kernels. For point convolutions, this effect is achieved by limiting the cardinality of the local kernel support, i.e. by defining a local neighborhood N i around each point p i</p><formula xml:id="formula_5">f * g (p i ) ≈ 1 |N i | p k ∈Ni f (p k ) g(p i − p k ).<label>(4)</label></formula><p>The above definition of continuous convolutions is used in Wang et al. <ref type="bibr" target="#b24">[25]</ref> and PointConv <ref type="bibr" target="#b26">[27]</ref> which additionally proposes to weight the kernel function using the inverse local density to compensate for the non-uniform distribution of point samples. In SpiderCNN, Xu et al. <ref type="bibr" target="#b28">[29]</ref> propose to replace the MLP by a combination of step functions and Taylor expansions to capture rich spatial information. A broader interpretation of continuous convolutions is used in EdgeConv <ref type="bibr" target="#b25">[26]</ref>, where the kernel function g(·) is not only defined over relative positions but also over the difference of learned point features. Independent of the concrete implementation, all previously mentioned methods, including PointCNN <ref type="bibr" target="#b13">[14]</ref>, rely on k nearest neighbors (KNN) to define a local neighborhood N resulting in local kernels. Next, after looking at the receptive field size, we use KNN neighborhoods to define dilated point convolutions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Receptive Field Size.</head><p>A large receptive field is directly related to the performance of point convolutional networks (Section IV). Thus our goal is to increase the size of the receptive field. The receptive field (or field of view) of a neural unit within a deep network describes the region of the input point cloud that influences the output of that particular unit. In the context of 3D semantic segmentation, where the task is to assign a semantic label to each point in a given point cloud, the final decision on the label for a particular point is influenced only by those points which lie inside the receptive field of that particular point. All other points outside the receptive field do not contribute to the decision, see <ref type="figure">Figure 4</ref>. It is thus essential to design architectures with receptive fields large enough to cover the necessary context for each point.</p><p>A common approach to increase the receptive field size, similar to 2D architectures, consists in stacking multiple (point) convolutional layers. EdgeConvs <ref type="bibr" target="#b25">[26]</ref>  Increasing the kernel size of the convolution is another popular technique. In the setup of point convolutions this effect is achieved by selecting a larger number k of nearest neighbors. Note, however, that this does not increase the number of model parameters since the kernel weights are computed over relative point positions using the parametric kernel function g(·), see <ref type="table" target="#tab_2">Table III</ref>. This is in stark contrast to convolutions defined over discrete grid positions (e.g. 2D image CNN) where a larger kernel increases the number of model parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Dilated Point Convolutions.</head><p>Using the previously mentioned approaches, the receptive field size still remains limited, see top 3 rows in <ref type="figure">Figure 4</ref>. Therefore, we propose dilated point convolutions (DPC) as an elegant yet efficient mechanism to increase the receptive field size. DPCs are equal to point convolutions (PC), however, they differ in the way they select neighboring points: While PCs directly use the k nearest neighbors, DPCs first compute the k·d nearest neighbors and then select every d-th neighbor, see <ref type="figure" target="#fig_3">Figure 2</ref> (right). Note that for d = 1, DPCs are identical to PCs. The dilation causes a significantly increased receptive field size (see <ref type="figure">Figure 4</ref>). However, the number of parameters remains unchanged. The larger number k · d of neighbors that needs to be computed adds a sublinear computational overhead. See <ref type="table" target="#tab_2">Table IV</ref>. Another positive aspect about DPC is that they can directly be added -with minimal modifications -to most existing point convolutional networks, if the local kernel neighborhood N originates from a nearest neighbor search.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTS</head><p>Model Architecture. In all our experiments, we use a deep convolutional model as depicted in <ref type="figure">Figure 3</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. 3D Semantic Segmentation</head><p>Task and Metrics. The goal is to predict a semantic label for each point in a given point cloud. This task is especially well-suited to analyze the effectiveness of larger receptive fields, since the label of each point is only influenced by points in its receptive field. We adopt the commonly used metrics: mean intersection over union (mIoU), mean class accuracy (mAcc), and overall accuracy (oAcc).</p><p>Datasets. We evaluate on two datasets: (1) Stanford Large-Scale 3D Indoor Spaces (S3DIS) <ref type="bibr" target="#b0">[1]</ref> contains dense 3D point clouds from 6 large-scale indoor areas, consisting of 271 rooms from 3 different buildings. The points are annotated with 13 semantic classes. We use the common train/test split, which trains on all areas except Area 5 which we keep for testing <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref>. (2) ScanNet v2 <ref type="bibr" target="#b3">[4]</ref> contains 3D scans of a wide variety of indoor scenes, including apartments, hotels, conference rooms and offices. The dataset contains 20 valid semantic classes. We use the public training, validation and test split of 1201, 312 and 100 scans, respectively.</p><p>Training Details. We train our networks using the Adam optimizer and exponential-decay learning-rate scheduling. During training we randomly sample 4092 points from crops of 3 m side length. This differs from most concurrent methods which train on 1 m or 1.5 m crops. Since our model has a much larger receptive field it can learn to make use of this additional context. In general, small training crops could hinder the network to learn from larger context as soon as the size of the receptive field exceeds the size of the training crops. Points are sampled without replacement and we use zero-padding if there are less than 4092 points.</p><p>Results and Discussion We report scores of our best performing models on the ScanNet v2 dataset <ref type="bibr" target="#b3">[4]</ref> and the S3DIS dataset <ref type="bibr" target="#b0">[1]</ref> in <ref type="table" target="#tab_2">Table I</ref>. Our dilated point convolutional model is able to outperform other recent KNN-based point convolutional networks by a significant margin on S3DIS,  and provides competitive scores on ScanNet, specifically among point convolutional approaches. In <ref type="figure">Figure 5</ref>, we show qualitative results on the ScanNet validation dataset. We highlight wrong predictions in red (see right-most column).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. 3D Object Classification</head><p>Dataset. ModelNet40 consists of CAD models that belong to one of 40 different categories. We use the official split of 9843 shapes for training and 2468 for testing, as in <ref type="bibr" target="#b19">[20]</ref>. We randomly sample 4,000 points from the 3D model of an object. The input features are the 3D coordinates and the surface normals (6 input channels in total). Comparison. <ref type="table" target="#tab_2">Table II</ref> shows the comparison between our method and prior methods. We report overall classification accuracy (oAcc) and mean classification accuracy (mAcc). Next, we present an ablation study of all model hyper-parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Ablation Study</head><p>We perform an ablation study on the previously introduced mechanisms for increasing the receptive field size. The hyper-parameters that we analyze in particular are the number of point convolutional layers, the nearest neighbors k and the dilation factor d. The main results are presented in <ref type="table" target="#tab_2">Table III and Table IV</ref>. The ablation studies are performed on Area 5 of the S3DIS dataset <ref type="bibr" target="#b0">[1]</ref>. In the following, we discuss the influence of the individual parameters.</p><p>Depth and Number of Neighbors k <ref type="table" target="#tab_2">(Table III)</ref>. By increasing the number of convolutional layers, we can build deeper networks. Similar to discrete convolutions, deep point convolutional networks perform better than shallow ones.  Equally, the performance increases with the number of neighbors. However, increasing the number of neighbors increases the computational cost, resulting in slower inference times. Furthermore, increasing the number of convolutions leads to additional memory consumption. Dilation Factor d <ref type="table" target="#tab_2">(Table IV)</ref>. Dilated Point Convolutions are an efficient tool to rapidly increase the receptive field of convolutions. Using dilation, the receptive field can be increased significantly <ref type="figure">(Figure 4</ref>) at constant memory requirements and a marginal increment in processing time. The improved performance on the semantic segmentation task shows that indeed a larger receptive field is important. However, the rapidly increasing receptive field resulting in large receptive fields in later layers is also responsible for sparsely sampled neighborhoods in earlier layers. We assume that this makes it harder for the network to learn high-frequency or local features. In future work, it could be interesting to investigate deep convolutional networks using Dilated Point Convolutions with a dilation rate d that increases with the depth of the network. Intuitively, such a network could learn localized signals in the earlier stages and higher level information at later stages.</p><p>Model Size. Note that, since the kernel function g(p) is defined over relative point positions p, the number of trainable parameters is independent of the number of neighbors k (and hence the dilation factor d). As such, increasing the number of neighbors k (or the dilation factor d) increases the receptive field without increasing the model size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSION</head><p>In this work, we reviewed several mechanisms to increase the receptive field size of 3D point convolutions. We analyzed and compared different network architectures based on the receptive field size which we showed to be directly related to the performance of point convolutional networks. Specifically, we have proposed dilated point convolutions as an elegant and efficient technique to significantly increase the receptive field size of point convolutions. As a result, we were able to report solid improvements over well-known baseline methods for 3D semantic segmentation and 3D object classification. More importantly, our dilation mechanism can easily be integrated into most existing point convolutional networks. We hope these insights enable the research community to develop better performing models.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>f</head><label></label><figDesc>(p4) &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " l Y s v C d 8 8 z 8 M m j 3 Z i 9 s g S c R e Z z F I = " &gt; A A A B 7 X i c b V B N S w M x E J 2 t X 7 V + V T 1 6 C R a h X s q u F v R Y 8 O K x g q 2 F d i n Z N N v G Z p O Q Z I W y 9 D 9 4 8 a C I V / + P N / + N a b s H b X 0 w 8 H h v h p l 5 k e L M W N / / 9 g p r 6 x u b W 8 X t 0 s 7 u 3 v 5 B + f C o b W S q C W 0 R y a X u R N h Q z g R t W W Y 5 7 S h N c R J x + h C N b 2 b + w x P V h k l x b y e K h g k e C h Y z g q 2 T 2 n F V 9 e v n / X L F r / l z o F U S 5 K Q C O Z r 9 8 l d v I E m a U G E J x 8 Z 0 A 1 / Z M M P a M s L p t N R L D V W Y j P G Q d h 0 V O K E m z O b X T t G Z U w Y o l t q V s G i u / p 7 I c G L M J I l c Z 4 L t y C x 7 M / E / r 5 v a + D r M m F C p p Y I s F s U p R 1 a i 2 e t o w D Q l l k 8 c w U Q z d y s i I 6 w x s S 6 g k g s h W H 5 5 l b Q v a s F l L b i r V x r V P I 4 i n M A p V C G A K 2 j A L T S h B Q Q e 4 R l e 4 c 2 T 3 o v 3 7 n 0 s W g t e P n M M f + B 9 / g C F A I 5 Z &lt; / l a t e x i t &gt; f (p5) &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " M u P 7 h t g s v X z y o D 7 + R 8 h R Z 4 l G 3 D k = " &gt; A A A B 7 X i c b V D L S g M x F L 3 j s 9 Z X 1 a W b Y B H q p s z 4 Q J c F N y 4 r 2 A e 0 Q 8 m k m T Y 2 k 4 Q k I 5 S h / + D G h S J u / R 9 3 / o 1 p O w t t P X D h c M 6 9 3 H t P p D g z 1 v e / v Z X V t f W N z c J W c X t n d 2 + / d H D Y N D L V h D a I 5 F K 3 I 2 w o Z 4 I 2 L L O c t p W m O I k 4 b U W j 2 6 n f e q L a M C k e 7 F j R M M E D w W J G s H V S M 6 6 o 3 t V Z r 1 T 2 q / 4 M a J k E O S l D j n q v 9 N X t S 5 I m V F j C s T G d w F c 2 z L C 2 j H A 6 K X Z T Q x U m I z y g H U c F T q g J s 9 m 1 E 3 T q l D 6 K p X Y l L J q p v y c y n B g z T i L X m W A 7 N I v e V P z P 6 6 Q 2 v g k z J l R q q S D z R X H K k Z V o + j r q M 0 2 J 5 W N H M N H M 3 Y r I E G t M r A u o 6 E I I F l 9 e J s 3 z a n B R D e 4 v y 7 V K H k c B j u E E K h D A N d T g D u r Q A A K P 8 A y v 8 O Z J 7 8 V 7 9 z 7 m r S t e P n M E f + B 9 / g C G h Y 5 a &lt; / l a t e x i t &gt; f (p6) &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 0 g O Z z 1 T g j X + Q 7 u 3 c 0 z f t V Y A F D Q 8 = " &gt; A A A B 7 X i c b V B N S w M x E J 3 1 s 9 a v q k c v w S L U S 9 l V U Y 8 F L x 4 r 2 A 9 o l 5 J N s 2 1 s N g l J V i h L / 4 M X D 4 p 4 9 f 9 4 8 9 + Y t n v Q 1 g c D j / d m m J k X K c 6 M 9 f 1 v b 2 V 1 b X 1 j s 7 B V 3 N 7 Z 3 d s v H R w 2 j U w 1 o Q 0 i u d T t C B v K m a A N y y y n b a U p T i J O W 9 H o d u q 3 n q g 2 T I o H O 1 Y 0 T P B A s J g R b J 3 U j C u q d 3 X W K 5 X 9 q j 8 D W i Z B T s q Q o 9 4 r f X X 7 k q Q J F Z Z w b E w n 8 J U N M 6 w t I 5 x O i t 3 U U I X J C A 9 o x 1 G B E 2 r C b H b t B J 0 6 p Y 9 i q V 0 J i 2 b q 7 4 k M J 8 a M k 8 h 1 J t g O z a I 3 F f / z O q m N b 8 K M C Z V a K s h 8 U Z x y Z C W a v o 7 6 T F N i + d g R T D R z t y I y x B o T 6 w I q u h C C x Z e X S f O 8 G l x U g / v L c q 2 S x 1 G A Y z i B C g R w D T W 4 g z o 0 g M A j P M M r v H n S e / H e v Y 9 5 6 4 q X z x z B H 3 i f P 4 g K j l s = &lt; / l a t e x i t &gt; ||p0 p1|| &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " B j 3 T h J e I j K L 0 W 0 o a c K b l X A v f 9 7 I = " &gt; A A A B 9 H i c b V B N S w M x E J 3 1 s 9 a v q k c v w S L 0 Y t l V Q Y 8 F L x 4 r 2 A 9 o l y W b Z t v Q b D Y m 2 U L Z 9 n d 4 8 a C I V 3 + M N / + N a b s H b X 0 w 8 H h v h p l 5 o e R M G 9 f 9 d t b W N z a 3 t g s 7 x d 2 9 / Y P D 0 t F x U y e p I r R B E p 6 o d o g 1 5 U z Q h m G G 0 7 Z U F M c h p 6 1 w e D f z W y O q N E v E o x l L 6 s e 4 L 1 j E C D Z W 8 i c T G b j o A s n A m 0 y C U t m t u n O g V e L l p A w 5 6 k H p q 9 t L S B p T Y Q j H W n c 8 V x o / w 8 o w w u m 0 2 E 0 1 l Z g M c Z 9 2 L B U 4 p t r P 5 k d P 0 b l V e i h K l C 1 h 0 F z 9 P Z H h W O t x H N r O G J u B X v Z m 4 n 9 e J z X R r Z 8 x I V N D B V k s i l K O T I J m C a A e U 5 Q Y P r Y E E 8 X s r Y g M s M L E 2 J y K N g R v + e V V 0 r y s e l d V 7 + G 6 X K v k c R T g F M 6 g A h 7 c Q A 3 u o Q 4 N I P A E z / A K b 8 7 I e X H e n Y 9 F 6 5 q T z 5 z A H z i f P 5 t D k U E = &lt; / l a t e x i t &gt; ||p0 p2|| &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " F I K p Y M 6 z / 4 A d y z T j 3 0 + + R g 2 q c B 0 = " &gt; A A A B 9 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B a h F 0 t S B T 0 W v H i s Y D + g D W G z 3 b R L N 5 u 4 u y m U p L / D i w d F v P p j v P l v 3 L Y 5 a O u D g c d 7 M 8 z M 8 2 P O l L b t b 6 u w s b m 1v V P c L e 3 t H x w e l Y 9 P 2 i p K J K E t E v F I d n 2 s K G e C t j T T n H Z j S X H o c 9 r x x 3 d z v z O h U r F I P O p p T N 0 Q D w U L G M H a S G 6 W x Z 6 N L l H s 1 b P M K 1 f s m r 0 A W i d O T i q Q o + m V v / q D i C Q h F Z p w r F T P s W P t p l h q R j i d l f q J o j E m Y z y k P U M F D q l y 0 8 X R M 3 R h lA E K I m l K a L R Q f 0 + k O F R q G v q m M 8 R 6 p F a 9 u f i f 1 0 t 0 c O u m T M S J p o I s F w U J R z p C 8 w T Q g E l K N J 8 a g o l k 5 l Z E R l h i o k 1 O J R O C s / r y O m n X a 8 5 V z X m 4 r j S q e R x F O I N z q I I D N 9 C A e 2 h C C w g 8 w T O 8 w p s 1 s V 6 s d + t j 2 V q w 8 p l T + A P r 8 w e c y Z F C &lt; / l a t e x i t &gt; ||p0 p3|| &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " b x d Y 3 e S / S 1 3 6 m 3 L V 2 D c C Q p E + K p 0 = " &gt; A A A B 9 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B a h F 0 t i B T 0 W v H i s Y D + g D W G z 3 b R L N 5 u 4 u y m U p L / D i w d F v P p j v P l v 3 L Y 5 a O u D g c d 7 M 8 z M 8 2 P O l L b t b 6 u w s b m 1 v V P c L e 3 t H x w e l Y 9 P 2 i p K J K E t E v F I d n 2 s K G e C t j T T n H Z j S X H o c 9 r x x 3 d z v z O h U r F I P O p p T N 0 Q D w U L G M H a S G 6 W x Z 6 N L l H s 1 b P M K 1 f s m r 0 A W i d O T i q Q o + m V v / q D i C Q h F Z p w r F T P s W P t p l h q R j i d l f q J o j E m Y z y k P U M F D q l y 0 8 X R M 3 R h l A E K I m l K a L R Q f 0 + k O F R q G v q m M 8 R 6 p F a 9 u f i f 1 0 t 0 c O u m T M S J p o I s F w U J R z p C 8 w T Q g E l K N J 8 a g o l k 5 l Z E R l h i o k 1 O J R O C s / r y O m l f 1 Z x 6 z X m 4 r j S q e R x F O I N z q I I D N 9 C A e 2 h C C w g 8 w T O 8 w p s 1 s V 6 s d + t j 2 V q w 8 p l T + A P r 8 w e e T 5 F D &lt; / l a t e x i t &gt; ||p0 p4|| &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 9 c G C L U V k 7 q j 7 r c 0 Q T 0 C E a + R 6 B E s = " &gt; A A A B 9 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B a h F 0 u i B T 0 W v H i s Y D + g D W G z 3 b R L N 5 u 4 u y m U p L / D i w d F v P p j v P l v 3 L Y 5 a O u D g c d 7 M 8 z M 8 2 P O l L b t b 6 u w s b m 1 v V P c L e 3 t H x w e l Y 9 P 2 i p K J K E t E v F I d n 2 s K G e C t j T T n H Z j S X H o c 9 r x x 3 d z v z O h U r F I P O p p T N 0 Q D w U L G M H a S G 6 W x Z 6 N L l H s 1 b P M K 1 f s m r 0 A W i d O T i q Q o + m V v / q D i C Q h F Z p w r F T P s W P t p l h q R j i d l f q J o j E m Y z y k P U M F D q l y 0 8 X R M 3 R h l A E K I m l K a L R Q f 0 + k O F R q G v q m M 8 R 6 p F a 9 u f i f 1 0 t 0 c O u m T M S J p o I s F w U J R z p C 8 w T Q g E l K N J 8 a g o l k 5 l Z E R l h i o k 1 O J R O C s / r y O m l f 1 Z z r m v N Q r z S q e R x F O I N z q I I D N 9 C A e 2 h C C w g 8 w T O 8 w p s 1 s V 6 s d + t j 2 V q w 8 p l T + A P r 8 w e f 1 Z F E &lt; / l a t e x i t &gt; ||p0 p5|| &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " M D B A k 5 v z J u A 9 L c b 6 M U v c y g 5 J i g 8= " &gt; A A A B 9 H i c b V D L S s N A F L 2 p r 1 p f V Z d u B o v Q j S X x g S 4 L b l x W s A 9 o Q 5 h M J + 3 Q S T L O T A o l 6 X e 4 c a G I W z / G n X / j t M 1 C W w 9 c O J x z L / f e 4 w v O l L b t b 6 u w t r 6 x u V X c L u 3 s 7 u 0 f l A + P W i p O J K F N E v N Y d n y s K G c R b W q m O e 0 I S X H o c 9 r 2 R 3 c z v z 2 m U r E 4 e t Q T Q d 0 Q D y I W M I K 1 k d w s E 5 6 N z p H w r r P M K 1 f s m j 0 H W i V O T i q Q o + G V v 3 r 9 m C Q h j T T h W K m u Y w v t p l h q R j i d l n q J o g K T E R 7 Q r q E R D q l y 0 / n R U 3 R m l D 4 K Y m k q 0 m i u / p 5 I c a j U J P R N Z 4 j 1 U C 1 7 M / E / r 5 v o 4 N Z N W S Q S T S O y W B Q k H O k Y z R J A f S Y p 0 X x i C C a S m V s R G W K J i T Y 5 l U w I z v L L q 6 R 1 U X M u a 8 7 D V a V e z e M o w g m c Q h U c u I E 6 3 E M D m k D g C Z 7 h F d 6 s s f V i v V s f i 9 a C l c 8 c w x 9 Y n z + h W 5 F F &lt; / l a t e x i t &gt;||p0 p6|| &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " / C N z i f Y N i K F w d A Z 3 f x r q Y M D t u a 0 = " &gt; A A A B 9 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B a h F 0 u i o h 4 L X j x W s B / Q h r D Z b t q l m 2 T d 3 R R K 0 t / h x Y M i X v 0 x 3 v w 3 b t s c t P X B w O O 9 G W b m + Y I z p W 3 7 2 y q s r W 9 s b h W 3 S z u 7 e / s H 5 c O j l o o T S W i T x D y W H R 8 r y l l E m 5 p p T j t C U h z 6 n L b 9 0 d 3 M b 4 + p V C y O H v V E U D f E g 4 g F j G B t J D f L h G e j c y S 8 6 y z z y h W 7 Z s + B V o m T k w r k a H j l r 1 4 / J k l I I 0 0 4 V q r r 2 E K 7 K Z a a E U 6 n p V 6 i q M B k h A e 0 a 2 i E Q 6 r c d H 7 0 F J 0 Z p Y + C W J q K N J q r v y d S H C o 1 C X 3 T G W I 9 V M v e T P z P 6 y Y 6 u H V T F o l E 0 4 g s F g U J R z p G s w R Q n 0 l K N J 8 Y g o l k 5 l Z E h l h i o k 1 O J R O C s / z y K m l d 1 J z L m v N w V a l X 8 z i K c A K n U A U H b q A O 9 9 C A J h B 4 g m d 4 h T d r b L 1 Y 7 9 b H o r V g 5 T P H 8 A f W 5 w + i 4 Z F G &lt; / l a t e x i t &gt; ||p0 p1|| &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " B j 3 T h J e I j K L 0 W 0 o a c K b l X A v f 9 7 I = " &gt; A A A B 9 H i c b V B N S w M x E J 3 1 s 9 a v q k c v w S L 0 Y t l V Q Y 8 F L x 4 r 2 A 9 o l y W b Z t v Q b D Y m 2 U L Z 9 n d 4 8 a C I V 3 + M N / + N a b s H b X 0 w 8 H h v h p l 5 o e R M G 9 f 9 d t b W N z a 3 t g s 7 x d 2 9 / Y P D 0 t F x U y e p I r R B E p 6 o d o g 1 5 U z Q h m G G 0 7 Z U F M c h p 6 1 w e D f z W y O q N E v E o x l L 6 s e 4 L 1 j E C D Z W 8 i c T G b j o A s n A m 0 y C U t m t u n O g V e L l p A w 5 6 k H p q 9 t L S B p T Y Q j H W n c 8 V x o / w 8 o w w u m 0 2 E 0 1 l Z g M c Z 9 2 L B U 4 p t r P 5 k d P 0 b l V e i h K l C 1 h 0 F z 9 P Z H h W O t x H N r O G J u B X v Z m 4 n 9 e J z X R r Z 8 x I V N D B V k s i l K O T I J m C a A e U 5 Q Y P r Y E E 8 X s r Y g M s M L E 2 J y K N g R v + e V V 0 r y s e l d V 7 + G 6 X K v k c R T g F M 6 g A h 7 c Q A 3 u o Q 4 N I P A E z / A K b 8 7 I e X H e n Y 9 F 6 5 q T z 5 z A H z i f P 5 t D k U E = &lt; / l a t e x i t &gt; ||p0 p2|| &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " F I K p Y M 6 z / 4 A d y z T j 3 0 + + R g 2 q c B 0 = " &gt; A A A B 9 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B a h F 0 t S B T 0 W v H i s Y D + g D W G z 3 b R L N 5 u 4 u y m U p L / D i w d F v P p j v P l v 3 L Y 5 a O u D g c d 7 M 8 z M 8 2 P O l L b t b 6 u w s b m 1 v V P c L e 3 t H x w e l Y 9 P 2 i p K J K E t E v F I d n 2 s K G e C t j T T n H Z j S X H o c 9 r x x 3 d z v z O h U r F I P O p p T N 0 Q D w U L G M H a S G 6 W x Z 6 N L l H s 1 b P M K 1 f s m r 0 A W i d O T i q Q o + m V v / q D i C Q h F Z p w r F T P s W P t p l h q R j i d l f q J o j E m Y z y k P U M F D q l y 0 8 X R M 3 R h l A E K I m l K a L R Q f 0 + k O F R q G v q m M 8 R 6 p F a 9 u f i f 1 0 t 0 c O u m T M S J p o I s F w U J R z p C 8 w T Q g E l K N J 8 a g o l k 5 l Z E R l h i o k 1 O J R O C s / r y O m n X a 8 5 V z X m 4 r j S q e R x F O I N z q I I D N 9 C A e 2 h C C w g 8 w T O 8 w p s 1 s V 6 s d + t j 2 V q w 8 p l T + A P r 8 w e c y Z F C &lt; / l a t e x i t &gt; ||p0 p3|| &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " b x d Y 3 e S / S 1 3 6 m 3 L V 2 D c C Q p E + K p 0 = " &gt; A A A B 9 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B a h F 0 t i B T 0 W v H i s Y D + g D W G z 3 b R L N 5 u 4 u y m U p L / D i w d F v P p j v P l v 3 L Y 5 a O u D g c d 7 M 8 z M 8 2 P O l L b t b 6 u w s b m 1 v V P c L e 3 t H x w e l Y 9 P 2 i p K J K E t E v F I d n 2 s K G e C t j T T n H Z j S X H o c 9 r x x 3 d z v z O h U r F I P O p p T N 0 Q D w U L G M H a S G 6 W x Z 6 N L l H s 1 b P M K 1 f s m r 0 A W i d O T i q Q o + m V v / q D i C Q h F Z p w r F T P s W P t p l h q R j i d l f q J o j E m Y z y k P U M F D q l y 0 8 X R M 3 R h l A E K I m l K a L R Q f 0 + k O F R q G v q m M 8 R 6 p F a 9 u f i f 1 0 t 0 c O u m T M S J p o I s F w U J R z p C 8 w T Q g E l K N J 8 a g o l k 5 l Z E R l h i o k 1 O J R O C s / r y O m l f 1 Z x 6 z X m 4 r j S q e R x F O I N z q I I D N 9 C A e 2 h C C w g 8 w T O 8 w p s 1 s V 6 s d + t j 2 V q w 8 p l T + A P r 8 w e e T 5 F D &lt; / l a t e x i t &gt; ||p0 p4|| &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 9 c G C L U V k 7 q j 7 r c 0 Q T 0 C E a + R 6 B E s = " &gt; A A A B 9 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B a h F 0 u i B T 0 W v H i s Y D + g D W G z 3 b R L N 5 u 4 u y m U p L / D i w d F v P p j v P l v 3 L Y 5 a O u D g c d 7 M 8 z M 8 2 P O l L b t b 6 u w s b m 1 v V P c L e 3 t H x w e l Y 9 P 2 i p K J K E t E v F I d n 2 s K G e C t j T T n H Z j S X H o c 9 r x x 3 d z v z O h U r F I P O p p T N 0 Q D w U L G M H a S G 6 W x Z 6 N L l H s 1 b P M K 1 f s m r 0 A W i d O T i q Q o + m V v / q D i C Q h F Z p w r F T P s W P t p l h q R j i d l f q J o j E m Y z y k P U M F D q l y 0 8 X R M 3 R h l A E K I m l K a L R Q f 0 + k O F R q G v q m M 8 R 6 p F a 9 u f i f 1 0 t 0 c O u m T M S J p o I s F w U J R z p C 8 w T Q g E l K N J 8 a g o l k 5 l Z E R l h i o k 1 O J R O C s / r y O m l f 1 Z z r m v N Q r z S q e R x F O I N z q I I D N 9 C A e 2 h C C w g 8 w T O 8 w p s 1 s V 6 s d + t j 2 V q w 8 p l T + A P r 8 w e f 1 Z F E &lt; / l a t e x i t &gt; ||p0 p5|| &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " M D B A k 5 v z J u A 9 L c b 6 M U v c y g 5 J i g 8 = " &gt; A A A B 9 H i c b V D L S s N A F L 2 p r 1 p f V Z d u B o v Q j S X x g S 4 L b l x W s A 9 o Q 5 h M J + 3 Q S T L O T A o l 6 X e 4 c a G I W z / G n X / j t M 1 C W w 9 c O J x z L / f e 4 w v O l L b t b 6 u w t r 6 x u V X c L u 3 s 7 u 0 f l A + P W i p O J K F N E v N Y d n y s K G c R b W q m O e 0 I S X H o c 9 r 2 R 3 c z v z 2 m U r E 4 e t Q T Q d 0 Q D y I W M I K 1 k d w s E 5 6 N z p H w r r P M K 1 f s m j 0 H W i V O T i q Q o + G V v 3 r 9 m C Q h j T T h W K m u Y w v t p l h q R j i d l n q J o g K T E R 7 Q r q E R D q l y 0 / n R U 3 R m l D 4 K Y m k q 0 m i u / p 5 I c a j U J P R N Z 4 j 1 U C 1 7 M / E / r 5 v o 4 N Z N W S Q S T S O y W B Q k H O k Y z R J A f S Y p 0 X x i C C a S m V s R G W K J i T Y 5 l U w I z v L L q 6 R 1 U X M u a 8 7 D V a V e z e M o w g m c Q h U c u I E 6 3 E M D m k D g C Z 7 h F d 6 s s f V i v V s f i 9 a C l c 8 c w x 9 Y n z + h W 5 F F &lt; / l a t e x i t &gt; ||p0 p6|| &lt; l a t e x i t s h a 1 _ b a s e 6 4 = "</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>z p W 3 7 2 y q s r W 9 s b h W 3 S z u 7 e / s H 5 c O j l o o T S W i T x D y W H R 8 r y l l E m 5 p p T j t C U h z 6 n L b 9 0 d 3 M b 4 + p V C y O H v V E U D f E g 4 g F j G B t J D f L h G e j c y S 8 6 y z z y h W 7 Z s + B V o m T k w r k a H j l r 1 4 / J k l I I 0 0 4 V q r r 2 E K 7 K Z a a E U 6 n p V 6 i q M B k h A e 0 a 2 i E Q 6 r c d H 7 0 F J</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>V 7 h z U m d F + f d + V i 0 F p x 8 5 h j + w P n 8 A Z W N j / w = &lt; / l a t e x i t &gt; g(p0 p4) &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 4 m N c a 0 k 8 U J s u e L D 9 I e c M j q 3 M F t Y = " &gt; A A A B 8 3 i c b V B N S w M x E J 2 t X 7 V + V T 1 6 C V a h H i y 7 W t B j w Y v H C v Y D 2 m X J p t k 2 N J s N S V Y o S / + G F w + K e P X P e P P f m L Z 7 0 N Y H A 4 / 3 Z p i Z F 0 r O t H H d b 6 e w t r 6 x u V X c L u 3 s 7 u 0 f l A + P 2 j p J F a E t k v B E d U O s K W e C t g w z n H a l o j g O O e 2 E 4 7 u Z 3 3 m i S r N E P J q J p H 6 M h 4 J F j G B j p f 6 w K g M X X S I Z 1 C + C c s W t u X O g V e L l p A I 5 m k H 5 q z 9 I S B p T Y Q j H W v c 8 V x o / w 8 o w w u m 0 1 E 8 1 l Z i M 8 Z D 2 L B U 4 p t r P 5 j d P 0 b l V B i h K l C 1 h 0 F z 9 P Z H h W O t J H N r O G J u R X v Z m 4 n 9 e L z X R r Z 8 x I V N D B V k s i l K O T I J m A a A B U 5 Q Y P r E E E 8 X s r Y i M s M L E 2 J h K N g R v + e V V 0 r 6 q e d c 1 7 6 F e a Z z l c R T h B E 6 h C h 7 c Q A P u o Q k t I C D h G V 7 h z U m d F + f d + V i 0 F p x 8 5 h j + w P n 8 A Z i X j / 4 = &lt; / l a t e x i t &gt; g(p0 p6) &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " j H l z o P r u q U A x h q z q 8 K 5 m H M f z w X Y = " &gt; A A A B 8 3 i c b V B N S w M x E J 2 t X 7 V + V T 1 6 C V a h H i y 7 K u q x 4 M V j B f s B 7 b J k 0 2 w b m s 2 G J C u U p X / D i w d F v P p n v P l v T N s 9 a O u D g c d 7 M 8 z M C y V n 2 r j u t 1 N Y W V 1 b 3 y h u l r a 2 d 3 b 3 y v s H L Z 2 k i t A m S X i i O i H W l D N B m 4 Y Z T j t S U R y H n L b D 0 d 3 U b z 9 R p V k i H s 1 Y U j / G A 8 E i R r C x U m 9 Q l Y G L z p E M r s + C c s W t u T O g Z e L l p A I 5 G k H 5 q 9 d P S B p T Y Q j H W n c 9 V x o / w 8 o w w u m k 1 E s 1 l Z i M 8 I B 2 L R U 4 p t r P Z j d P 0 K l V + i h K l C 1 h 0 E z 9 P Z H h W O t x H N r O G J u h X v S m 4 n 9 e N z X R r Z 8 x I V N D B Z k v i l K O T I K m A a A + U 5 Q Y P r Y E E 8 X s r Y g M s c L E 2 J h K N g R v 8 e V l 0 r q o e Z c 1 7 + G q U j / J 4 y j C E R x D F T y 4 g T r c Q w O a Q E D C M 7 z C m 5 M 6 L 8 6 7 8 z F v L T j 5 z C H 8 g f P 5 A 5 u h k A A = &lt; / l a t e x i t &gt; k = 3 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " o E 4 N x U h Q y 2 U C B J / e X E r m A V q 6 Z m E = " &gt; A A A B 7 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B a h p 5 J Y Q S 9 C w Y v H C q Y t t K F s t p N 2 6 W Y T d j d C K f 0 N X j w o 4 t U f 5 M 1 / 4 7 b N Q V s f D D z e m 2 F m X p g K r o 3 r f j u F j c 2 t 7 Z 3 i b m l v / + D w q H x 8 0 t J J p h j 6 L B G J 6 o R U o + A S f c O N w E 6 q k M a h w H Y 4 v p v 7 7 S d U m i f y 0 U x S D G I 6 l D z i j B o r + W N y S + r 9 c s W t u Q u Q d e L l p A I 5 m v 3 y V 2 + Q s C x G a Z i g W n c 9 N z X B l C r D m c B Z q Z d p T C k b 0 y F 2 L Z U 0 R h 1 M F 8 f O y I V V B i R K l C 1 p y E L 9 P T G l s d a T O L S d M T U j v e r N x f + 8 b m a i m 2 D K Z Z o Z l G y 5 K M o E M Q m Z f 0 4 G X C E z Y m I J Z Y r b W w k b U U W Z s f m U b A j e 6 s v r p H V Z 8 + o 1 7 + G q 0 q j m c R T h D M 6 h C h 5 c Q w P u o Q k + M O D w D K / w 5 k j n x X l 3 P p a t B S e f O Y U / c D 5 / A G z P j b A = &lt; / l a t e x i t &gt; k 0 = 3 · d with d = 2 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 0 v X X 1 S B k h A c l Y 5 1 e d f O f F f 9 O j a k = " &gt; A A A C C 3 i c b V C 7 T g J B F J 3 F F + I L t b S Z Q I x U Z B d M t C E h s b H E R B 4 J b M j s 7 A A T Z m c 3 M 3 d V s q G 3 8 V d s L D T G 1 h + w 8 2 + c B Q o F T 3 K T M + f c m 7 n 3 e J H g G m z 7 2 8 q s r W 9 s b m W 3 c z u 7 e / s H + c O j l g 5 j R V m T h i J U H Y 9 o J r h k T e A g W C d S j A S e Y G 1 v f J X 6 7 T u m N A / l L U w i 5 g Z k K P m A U w J G 6 u c L 4 z N c w 9 U e 9 U P A P u 4 B e 4 A E 3 3 M Y 4 a l 5 1 3 A l 1 8 8 X 7 b I 9 A 1 4 l z o I U 0 Q K N f v 6 r 5 4 c 0 D p g E K o j W X c e O w E 2 I A k 4 F m + Z 6 s W Y R o W M y Z F 1 D J Q m Y d p P Z L V N 8 a h Q f D 0 J l S g K e q b 8 n E h J o P Q k 8 0 x k Q G O l l L x X / 8 7 o x D C 7 d h M s o B i b p / K N B L D C E O A 0 G + 1 w x C m J i C K G K m 1 0 x H R F F K J j 4 0 h C c 5 Z N X S a t S d q p l 5 + a 8 W C 8 t 4 s i i E 1 R A J e S g C 1 R H 1 6 i B m o i i R / S M X t G b 9 W S 9 W O / W x 7 w 1 Y y 1 m j t E f W J 8 / n l W Y J g = = &lt; / l a t e x i t &gt; distance to p0 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " D P i C v L c I J 3 1 X U h p W u j 9 9 l D P P h / U = " &gt; A A A B / 3 i c b V A 9 S w N B E N 2 L X z F + n Q o 2 N o t B S B X u V N A y Y G M Z w X x A E s L e Z p I s 2 d s 7 d u f E c K b w r 9 h Y K G L r 3 7 D z 3 7 i X p N D E B w O P 9 2 a Y m R f E U h j 0 v G 8 n t 7 K 6 t r 6 R 3 y x s b e / s 7 r n 7 B 3 U T J Z p D j U c y 0 s 2 A G Z B C Q Q 0 F S m j G G l g Y S G g E o + v M b 9 y D N i J S d z i O o R O y g R J 9 w R l a q e s e t R E e M O 3 Z T U x x o B j R S d z 1 u m 7 R K 3t T 0 G X i z 0 m R z F H t u l / t X s S T E B R y y Y x p + V 6 M n Z R p F F z C p N B O D M S M j 9 g A W p Y q F o L p p N P 7 J / T U K j 3 a j 7 Q t h X S q / p 5 I W W j M O A x s Z 8 h w a B a 9 T P z P a y X Y v + q k Q s U J g u K z R f 1 E Z l 9 m Y d C e 0 M B R j i 1 h X A t 7 K + V D p h l H G 1 n B h u A v v r x M 6 m d l / 7 z s 3 1 4 U K 6 V 5 H H l y T E 5 I i f j k k l T I D a m S G u H k k T y T V / L m P D k v z r v z M W v N O f O Z Q / I H z u c P 9 V S V 9 g = = &lt; / l a t e x i t &gt; distance to p0 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " D P i C v L c I J 3 1 X U h p W u j 9 9 l D P P h / U = " &gt; A A A B / 3 i c b V A 9 S w N B E N 2 L X z F + n Q o 2 N o t B S B X u V N A y Y G M Z w X x A E s L e Z p I s 2 d s 7 d u f E c K b w r 9 h Y K G L r 3 7 D z 3 7 i X p N D E B w O P 9 2 a Y m R f E U h j 0 v G 8 n t 7 K 6 t r 6 R 3 y x s b e / s 7 r n 7 B 3 U T J Z p D j U c y 0 s 2 A G Z B C Q Q 0 F S m j G G l g Y S G g E o + v M b 9 y D N i J S d z i O o R O y g R J 9 w R l a q e s e t R E e M O 3 Z T U x x o B j R S d z 1 u m 7 R K 3 t T 0 G X i z 0 m R z F H t u l / t X s S T E B R y y Y x p + V 6 M n Z R p F F z C p N B O D M S M j 9 g A W p Y q F o L p p N P 7 J / T U K j 3 a j 7 Q t h X S q / p 5 I W W j M O A x s Z 8 h w a B a 9 T P z P a y X Y v + q k Q s U J g u K z R f 1 E Z l 9 m Y d C e 0 M B R j i 1 h X A t 7 K + V D p h l H G 1 n B h u A v v r x M 6 m d l / 7 z s 3 1 4 U K 6 V 5 H H l y T E 5 I i f j k k l T I D a m S G u H k k T y T V / L m P D k v z r v z M W v N O f O Z Q / IH z u c P 9 V S V 9 g = = &lt; / l a t e x i t &gt; k Nearest Neighbors &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " z 6 J T 5 C 5 m Y t E d f 1 G h g y t j Z D 4 9 3 S Y = " &gt; A A A C B H i c b V C 7 S g N B F J 3 1 G e N r 1 T L N Y B B S h V 0 V t A z Y W E k E 8 4 B k C b O T u 8 m Q 2 Q c z d 8 W w p L D x V 2 w s F L H 1 I + z 8 G y f J F p p 4 4 H I P 5 9 z L z D 1 + I o V G x / m 2 V l b X 1 j c 2 C 1 v F 7 Z 3 d v X 3 7 4 L C p 4 1 R x a P B Y x q r t M w 1 S R N B A g R L a i Q I W + h J a / u h q 6 r f u Q W k R R 3 c 4 T s A L 2 S A S g e A M j d S z S y P a R X j A j N 4 A U 6 D R d D E Y + r H S k 5 5 d d q r O D H S Z u D k p k x z 1 n v 3 V 7 c c 8 D S F C L p n W H d d J 0 M u Y Q s E l T I r d V E P C + I g N o G N o x E L Q X j Y 7 Y k J P j N K n Q a x M R U h n 6 u + N j I V a j 0 P f T I Y M h 3 r R m 4 r / e Z 0 U g 0 s v E 1 G S I k R 8 / l C Q S o o x n S Z C + 0 I B R z k 2 h H E l z F 8 p H z L F O J r c i i Y E d / H k Z d I 8 r b p n V f f 2 v F y r 5 H E U S I k c k w p x y Q W p k W t S J w 3 C y S N 5 J q / k z X q y X q x 3 6 2 M + u m L l O 0 f k D 6 z P H 5 L 0 l / k = &lt; / l a t e x i t &gt; Dilated &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " w D e 2 C B M i v o r r M o y 3 N J 5 c e 7 l Z F H Y = " &gt; A A A B 9 X i c b V D L S g N B E J y N r x h f U Y 9 e B o O Q U 9 h V Q Y 8 B P X i M Y B 6 Q r G F 2 t j c Z M v t g p l c N S / 7 D i w d F v P o v 3 v w b J 8 k e N L G g o a j q p r v L S 6 T Q a N v f V m F l d W 1 9 o 7 h Z 2 t r e 2 d 0 r 7 x + 0 d J w q D k 0 e y 1 h 1 P K Z B i g i a K F B C J 1 H A Q k 9 C 2 x t d T f 3 2 A y g t 4 u g O x w m 4 I R t E I h C c o Z H u e w h P m F 0 L y R D 8 S b 9 c s W v 2 D H S Z O D m p k B y N f v m r 5 8 c 8 D S F C L p n W X c d O 0 M 2 Y Q s E l T E q 9 V E P C + I g N o G t o x E L Q b j a 7 e k J P j O L T I F a m I q Q z 9 f d E x k K t x 6 F n O k O G Q 7 3 o T c X / v G 6 K w a W b i S h J E S I + X x S k k m J M p x F Q X y j g K M e G M K 6 E u Z X y I V O M o w m q Z E J w F l 9 e J q 3 T m n N W c 2 7 P K / V q H k e R H J F j U i U O u S B 1 c k M a p E k 4 U e S Z v J I 3 6 9 F 6 s d 6 t j 3 l r w c p n D s k f W J 8 / / x S S v w = = &lt; / l a t e x i t &gt; k Nearest Neighbors &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " z 6 J T 5 C 5 m Y t E d f 1 G h g y t j Z D 4 9 3 S Y = " &gt; A A A C B H i c b V C 7 S g N B F J 3 1 G e N r 1 T L N Y B B S h V 0 V t A z Y W E k E 8 4 B k C b O T u 8 m Q 2 Q c z d 8 W w p L D x V 2 w s F L H 1 I + z 8 G y f J F p p 4 4 H I P 5 9 z L z D 1 + I o V G x / m 2 V l b X 1 j c 2 C 1 v F 7 Z 3 d v X 3 7 4 L C p 4 1 R x a P B Y x q r t M w 1 S R N B A g R L a i Q I W + h J a / u h q 6 r f u Q W k R R 3 c 4 T s A L 2 S A S g e A M j d S z S y P a R X j A j N 4 A U 6 D R d D E Y + r H S k 5 5 d d q r O D H S Z u D k p k x z 1 n v 3 V 7 c c 8 D S F C L p n W H d d J 0 M u Y Q s E l T I r d V E P C + I g N o G N o x E L Q X j Y 7 Y k J P j N K n Q a x M R U h n 6 u + N j I V a j 0 P f T I Y M h 3 r R m 4 r / e Z 0 U g 0 s v E 1 G S I k R 8 / l C Q S o o x n S Z C + 0 I B R z k 2 h H E l z F 8 p H z L F O J r c i i Y E d / H k Z d I 8 r b p n V f f 2 v F y r 5 H E U S I k c k w p x y Q W p k W t S J w 3 C y S N 5 J q / k z X q y X q x 3 6 2 M + u m L l O 0 f k D 6 z P H 5 L 0 l / k = &lt; / l a t e x i t &gt; Point Convolutions Dilated Point Convolutions</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 2 .</head><label>2</label><figDesc>(Left) Point Convolutions. Schematic illustration of point convolutions. The continuous feature function f (·) assigns a feature value to continuous point positions p. (Right) Dilated Point Convolutions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>PointConv-64- 64 &lt; l a t e x i t s h a 1 _Fig. 3 .</head><label>6413</label><figDesc>b a s e 6 4 = " / k B + Q J D B 6 6 i M o A v t 6 Y c J E f 5 7 v z M = " &gt; A A A B / 3 i c b V D L S g M x F M 3 4 r P U 1 K r h x M 1 i E b i w z W t R l o R u X F e w D 2 q F k 0 k w b m k m G 5 E 6 x j F 3 4 K 2 5 c K O L W 3 3 D n 3 5 i 2 s 9 D W w 7 1 w O O d e c n O C m D M N r v t t r a y u r W 9 s 5 r b y 2 z u 7 e / v 2 w W F D y 0 Q R W i e S S 9 U K s K a c C V o H B p y 2 Y k V x F H D a D I b V q d 8 c U a W Z F P c w j q k f 4 b 5 g I S M Y j N S 1 j z t A H y C t S S a g K s X o / K p s a t K 1 C 2 7 J n c F Z J l 5 G C i h D r W t / d X q S J B E V Q D j W u u 2 5 M f g p V s A I p 5 N 8 J 9 E 0 x m S I + 7 R t q M A R 1 X 4 6 u 3 / i n B m l 5 4 R S m R b g z N T f G y m O t B 5 H g Z m M M A z 0 o j c V / / P a C Y Q 3 f s p E n A A V Z P 5 Q m H A H p D M N w + k x R Q n w s S G Y K G Z u d c g A K 0 z A R J Y 3 I X i L X 1 4 m j Y u S d 1 n y 7 s q F S j G L I 4 d O 0 C k q I g 9 d o w q 6 R T V U R w Q 9 o m f 0 i t 6 s J + v F e r c + 5 q M r V r Z z h P 7 A + v w B A O G V V w = = &lt; / l a t e x i t &gt; PointConv-64-64 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " / k B + Q J D B 6 6 i M o A v t 6 Y c J E f 5 7 v z M = " &gt; A A A B / 3 i c b V D L S g M x F M 3 4 r P U 1 K r h x M 1 i E b i w z W t R l o R u X F e w D 2 q F k 0 k w b m k m G 5 E 6 x j F 3 4 K 2 5 c K O L W 3 3 D n 3 5 i 2 s 9 D W w 7 1 w O O d e c n O C m D M N r v t t r a y u r W 9 s 5 r b y 2 z u 7 e / v 2 w W F D y 0 Q R W i e S S 9 U K s K a c C V o H B p y 2 Y k V x F H D a D I b V q d 8 c U a W Z F P c w j q k f 4 b 5 g I S M Y j N S 1 j z t A H y C t S S a g K s X o / K p s a t K 1 C 2 7 J n c F Z J l 5 G C i h D r W t / d X q S J B E V Q D j W u u 2 5 M f g p V s A I p 5 N 8 J 9 E 0 x m S I + 7 R t q M A R 1 X 4 6 u 3 / i n B m l 5 4 R S m R b g z N T f G y m O t B 5 H g Z m M M A z 0 o j c V / / P a C Y Q 3 f s p E n A A V Z P 5 Q m H A H p D M N w + k x R Q n w s S G Y K G Z u d c g A K 0 z A R J Y 3 I X i L X 1 4 m j Y u S d 1 n y 7 s q F S j G L I 4 d O 0 C k q I g 9 d o w q 6 R T V U R w Q 9 o m f 0 i t 6 s J + v F e r c + 5 q M r V r Z z h P 7 A + v w B A O G V V w = = &lt; / l a t e x i t &gt; PointConv-64-64 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " / k B + Q J D B 6 6 i M o A v t 6 Y c J E f 5 7 v z M = " &gt; A A A B / 3 i c b V D L S g M x F M 3 4 r P U 1 K r h x M 1 i E b i w z W t R l o R u X F e w D 2 q F k 0 k w b m k m G 5 E 6 x j F 3 4 K 2 5 c K O L W 3 3 D n 3 5 i 2 s 9 D W w 7 1 w O O d e c n O C m D M N r v t t r a y u r W 9 s 5 r b y 2 z u 7 e / v 2 w W F D y 0 Q R W i e S S 9 U K s K a c C V o H B p y 2 Y k V x F H D a D I b V q d 8 c U a W Z F P c w j q k f 4 b 5 g I S M Y j N S 1 j z t A H y C t S S a g K s X o / K p s a t K 1 C 2 7 J n c F Z J l 5 G C i h D r W t / d X q S J B E V Q D j W u u 2 5 M f g p V s A I p 5 N 8 J 9 E 0 x m S I + 7 R t q M A R 1 X 4 6 u 3 / i n B m l 5 4 R S m R b g z N T f G y m O t B 5 H g Z m M M A z 0 o j c V / / P a C Y Q 3 f s p E n A A V Z P 5 Q m H A H p D M N w + k x R Q n w s S G Y K G Z u d c g A K 0 z A R J Y 3 I X i L X 1 4 m j Y u S d 1 n y 7 s q F S j G L I 4 d O 0 C k q I g 9 d o w q 6 R T V U R w Q 9 o m f 0 i t 6 s J + v F e r c + 5 q M r V r Z z h P 7 A + v w B A O G V V w = = &lt; / l a t e x i t &gt; KNN &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " m U x U F e C I c x t L X f d l j t z a / U o O / Z c = " &gt; A A A B 8 X i c b V D L S g N B E J z 1 G e M r 6 t H L Y B B y C r s q 6 D H g R R B C B P P A Z A m z k 0 4 y Z H Z 2 m e k V w 5 K / 8 O J B E a / + j T f / x k m y B 0 0 s a C i q u u n u C m I p D L r u t 7 O y u r a + s Z n b y m / v 7 O 7 t F w 4 O G y Z K N I c 6 j 2 S k W w E z I I W C O g q U 0 I o 1 s D C Q 0 A x G 1 1 O / + Q j a i E j d 4 z g G P 2 Q D J f q C M 7 T S Q w f h C d P b a n X S L R T d s j s D X S Z e R o o k Q 6 1 b + O r 0 I p 6 E o J B L Z k z b c 2 P 0 U 6 Z R c A m T f C c x E D M + Y g N o W 6 p Y C M Z P Z x d P 6 K l V e r Q f a V s K 6 U z 9 P Z G y 0 J h x G N j O k O H Q L H p T 8 T + v n W D / y k + F i h M E x e e L + o m k G N H p + 7 Q n N H C U Y 0 s Y 1 8 L e S v m Q a c b R h p S 3 I X i L L y + T x l n Z O y 9 7 d x f F S i m L I 0 e O y Q k p E Y 9 c k g q 5 I T V S J 5 w o 8 k x e y Z t j n B f n 3 f m Y t 6 4 4 2 c w R + Q P n 8 w e Y o p D H &lt; / l a t e x i t &gt; FC-K &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 4 W W O 6 l G l S A + 5 1 G 5 1 D c R M P S A 1 X y Y = " &gt; A A A B 8 n i c b V B N S w M x E M 3 W r 1 q / q h 6 9 B I v Q i 2 V X K n o s F E T w U s F + w H Y p 2 T R t Q 7 P J k s y K Z e n P 8 O J B E a / + G m / + G 9 N 2 D 9 r 6 Y O D x 3 g w z 8 8 J Y c A O u + + 3 k 1 t Y 3 N r f y 2 4 W d 3 b 3 9 g + L h U c u o R F P W p E o o 3 Q m J Y Y J L 1 g Q O g n V i z U g U C t Y O x / W Z 3 3 5 k 2 n A l H 2 A S s y A i Q 8 k H n B K w k t 8 F 9 g T p T f 3 8 b t o r l t y K O w d e J V 5 G S i h D o 1 f 8 6 v Y V T S I m g Q p i j O + 5 M Q Q p 0 c C p Y N N C N z E s J n R M h s y 3 V J K I m S C d n z z F Z 1 b p 4 4 H S t i T g u f p 7 I i W R M Z M o t J 0 R g Z F Z 9 m b i f 5 6 f w O A 6 S L m M E 2 C S L h Y N E o F B 4 d n / u M 8 1 o y A m l h C q u b 0 V 0 x H R h I J N q W B D 8 J Z f X i W t i 4 p X r V z e V 0 u 1 c h Z H H p 2 g U 1 R G H r p C N X S L G q i J K F L o G b 2 i N w e c F + f d + V i 0 5 p x s 5 h j 9 g f P 5 A + n z k P A = &lt; / l a t e x i t &gt; FC-256 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " n e B z Z t 2 m 0 p 3 V P 0 h J d 0 5 l 0 N Z r dV o = " &gt; A A A B 9 H i c b V B N S 8 N A E N 3 U r 1 q / q h 6 9 L B a h F 0 t S W v V Y K I j H C v Y D 2 l A 2 2 0 2 7 d L O J u 5 N i C f 0 d X j w o 4 t U f 4 8 1 / 4 7 b N Q V s f D D z e m 2 F m n h c J r s G 2 v 6 3 M x u b W 9 k 5 2 N 7 e 3 f 3 B 4 l D 8 + a e k w V p Q 1 a S h C 1 f G I Z o J L 1 g Q O g n U i x U j g C d b 2 x v W 5 3 5 4 w p X k o H 2 A a M T c g Q 8 l 9 T g k Y y e 0 B e 4 L k t n 5 Z r l 7 N + v m C X b I X w O v E S U k B p W j 0 8 1 + 9 Q U j j g E m g g m j d d e w I 3 I Q o 4 F S w W a 4 X a x Y R O i Z D 1 j V U k o B p N 1 k c P c M X R h l g P 1 S m J O C F + n s i I Y H W 0 8 A z n Q G B k V 7 1 5 u J / X j c G / 8 Z N u I x i Y J I u F / m x w B D i e Q J 4 w B W j I K a G E K q 4 u R X T E V G E g s k p Z 0 J w V l 9 e J 6 1 y y a m U q v e V Q q 2 Y x p F F Z + g c F Z G D r l E N 3 a E G a i K K H t E z e k V v 1 s R 6 s d 6 t j 2 V r x k p n T t E f W J 8 / t 8 u R V g = = &lt; / l a t e x i t &gt; Concat &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " O 8 B B T R c P i J u M i c o 5 r i F i M 3 G A 8 3 Q = " &gt; A A A B 9 H i c b V B N T w I x E O 3 i F + I X 6 t F L I z H h R H b V R I 8 k X D x i I h 8 J b E i 3 D N D Q 7 a 7 t L J F s + B 1 e P G i M V 3 + M N / + N B f a g 4 E s m e X 1 v J p 1 5 Q S y F Q d f 9 d n I b m 1 v b O / n d w t 7 + w e F R 8 f i k a a J E c 2 j w S E a 6 H T A D U i h o o E A J 7 V g D C w M J r W B c m / u t C W g j I v W A 0 x j 8 k A 2 V G A j O 0 E p + F + E J 0 1 q k 7 H v W K 5 b c i r s A X S d e R k o k Q 7 1 X / O r 2 I 5 6 E o J B L Z k z H c 2 P 0 U 6 Z R c A m z Q j c x E D M + Z k P o W K p Y C M Z P F 0 v P 6 I V V + n Q Q a V s K 6 U L 9 P Z G y 0 J h p G N j O k O H I r H p z 8 T + v k + D g 1 k + F i h M E x Z c f D R J J M a L z B G h f a O Ao p 5 Y w r o X d l f I R 0 4 y j z a l g Q / B W T 1 4 n z c u K d 1 X x 7 q 9 L 1 X I W R 5 6 c k X N S J h 6 5 I V V y R + q k Q T h 5 J M / k l b w 5 E + f F e X c + l q 0 5 J 5 s 5 J X / g f P 4 A R N i S V g = = &lt; / l a t e x i t &gt; Concat &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " O 8 B B T R c P i J u M i c o 5 r i F i M 3 G A 8 3 Q = " &gt; A A A B 9 H i c b V B N T w I x E O 3 i F + I X 6 t F L I z H h R H b V R I 8 k X D x i I h 8 J b E i 3 D N D Q 7 a 7 t L J F s + B 1 e P G i M V 3 + M N / + N B f a g 4 E s m e X 1 v J p 1 5 Q S y F Q d f 9 d n I b m 1 v b O / n d w t 7 + w e F R 8 f i k a a J E c 2 j w S E a 6 H T A D U i h o o E A J 7 V g D C w M J r W B c m / u t C W g j I v W A 0 x j 8 k A 2 V G A j O 0 E p + F + E J 0 1 q k 7 H v W K 5 b c i r s A X S d e R k o k Q 7 1 X / O r 2 I 5 6 E o J B L Z k z H c 2 P 0 U 6 Z R c A m z Q j c x E D M + Z k P o W K p Y C M Z P F 0 v P 6 I V V + n Q Q a V s K 6 U L 9 P Z G y 0 J h p G N j O k O H I r H p z 8 T + v k + D g 1 k + F i h M E x Z c f D R J J M a L z B G h f a O A o p 5 Y w r o X d l f I R 0 4 y j z a l g Q / B W T 1 4 n z c u K d 1 X x 7 q 9 L 1 X I W R 5 6 c k X N S J h 6 5 I V V y R + q k Q T h 5 J M / k l b w 5 E + f F e X c + l q 0 5 J 5 s 5 J X / g f P 4 A R N i S V g = = &lt; / l a t e x i t &gt; MaxPool &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 0 6 g d u J c I F Z r n D 4 k 6 M V s s L Q u u A n A = " &gt; A A A B 9 X i c b V D L S g N B E O z 1 G e M r 6 t H L Y B B y C r s q 6 D H g x Y s Q w T w g W c P s Z J I M m d 1 Z Z n o 1 Y c l / e P G g i F f / x Z t / 4 y T Z g y Y W N B R V 3 X R 3 B b E U B l 3 3 2 1 l Z X V v f 2 M x t 5 b d 3 d v f 2 C w e H d a M S z X i N K a l 0 M 6 C G S x H x G g q U v B l r T s N A 8 k Y w v J 7 6 j U e u j V D R P Y 5 j 7 o e 0 H 4 m e Y B S t 9 N B G P s L 0 l o 6 q S s l J p 1 B 0 y + 4 M Z J l 4 G S l C h m q n 8 N X u K p a E P E I m q T E t z 4 3 R T 6 l G w S S f 5 N u J 4 T F l Q 9 r n L U s j G n L j p 7 O r J + T U K l 3 S U 9 p W h G S m / p 5 I a W j M O A x s Z 0 h x Y B a 9 q f i f 1 0 q w d + W n I o o T 5 B G b L + o l k q A i 0 w h I V 2 j O U I 4 t o U w L e y t h A 6 o p Q x t U 3 o b g L b 6 8 T O p n Z e + 8 7 N 1 d F C u l L I 4 c H M M J l M C D S 6 j A D V S h B g w 0 P M M r v D l P z o v z 7 n z M W 1 e c b O Y I / s D 5 / A E M 2 5 L I &lt; / l a t e x i t &gt; FC-256 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " n e B z Z t 2 m 0 p 3 V P 0 h J d 0 5 l 0 N Z r d V o = " &gt; A A A B 9 H i c b V B N S 8 N A E N 3 U r 1 q / q h 6 9 L B a h F 0 t S W v V Y K I j H C v Y D 2 l A 2 2 0 2 7 d L O J u 5 N i C f 0 d X j w o 4 t U f 4 8 1 / 4 7 b N Q V s f D D z e m 2 F m n h c J r s G 2 v 6 3 M x u b W 9 k 5 2 N 7 e 3 f 3 B 4 l D 8 + a e k w V p Q 1 a S h C 1 f G I Z o J L 1 g Q O g n U i x U j g C d b 2 x v W 5 3 5 4 w p X k o H 2 A a M T c g Q 8 l 9 T g k Y y e 0 B e 4 L k t n 5 Z r l 7 N + v m C X b I X w O v E S U k B p W j 0 8 1 + 9 Q U j j g E m g g m j d d e w I 3 I Q o 4 F S w W a 4 X a x Y R O i Z D 1 j V U k o B p N 1 k c P c M X R h l g P 1 S m J O C F + n s i I Y H W 0 8 A z n Q G B k V 7 1 5 u J / X j c G / 8 Z N u I x i Y J I u F / m x w B D i e Q J 4 w B W j I K a G E K q 4 u R X T E V G E g s k p Z 0 J w V l 9 e J 6 1 y y a m U q v e V Q q 2 Y x p F F Z + g c F Z G D r l E N 3 a E G a i K K H t E z e k V v 1 s R 6 s d 6 t j 2 V r x k p n T t E f W J 8 / t 8 u R V g = = &lt; / l a t e x i t &gt; PointConv-64-64 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " / k B + Q J D B 6 6 i M o A v t 6 Y c J E f 5 7 v z M = " &gt; A A A B / 3 i c b V D L S g M x F M 3 4 r P U 1 K r h x M 1 i E b i w z W t R l o R u X F e w D 2 q F k 0 k w b m k m G 5 E 6 x j F 3 4 K 2 5 c K O L W 3 3 D n 3 5 i 2 s 9 D W w 7 1 w O O d e c n O C m D M N r v t t r a y u r W 9 s 5 r b y 2 z u 7 e / v 2 w W F D y 0 Q R W i e S S 9 U K s K a c C V o H B p y 2 Y k V x F H D a D I b V q d 8 c U a W Z F P c w j q k f 4 b 5 g I S M Y j N S 1 j z t A H y C t S S a g K s X o / K p s a t K 1 C 2 7 J n c F Z J l 5 G C i h D r W t / d X q S J B E V Q D j W u u 2 5 M f g p V s A I p 5 N 8 J 9 E 0 x m S I + 7 R t q M A R 1 X 4 6 u 3 / i n B m l 5 4 R S m R b g z N T f G y m O t B 5 H g Z m M M A z 0 o j c V / / P a C Y Q 3 f s p E n A A V Z P 5 Q m H A H p D M N w + k x R Q n w s S G Y K G Z u d c g A K 0 z A R J Y 3 I X i L X 1 4 m j Y u S d 1 n y 7 s q F S j G L I 4 d O 0 C k q I g 9 d o w q 6 R T V U R w Q 9 o m f 0 i t 6 s J + v F e r c + 5 q M r V r Z z h P 7 A + v w B A O G V V w = = &lt; / l a t e x i t &gt; . . . &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " A n T W B X w 5 n R q f y e L 6 5 u Y M H k Q S A H 8 = " &gt; A A A B 7 X i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S L 0 V B I V 9 F j w 4 r G C / Y A 2 l M 1 m 0 6 7 d Z M P u R C i h / 8 G L B 0 W 8 + n + 8 + W / c t j l o 6 4 O B x 3 s z z M w L U i k M u u 6 3 s 7 a + s b m 1 X d o p 7 + 7 t H x x W j o 7 b R m W a 8 R Z T U u l u Q A 2 X I u E t F C h 5 N 9 W c x o H k n W B 8 O / M 7 T 1 w b o Z I H n K T c j + k w E Z F g F K 3 U 7 o 9 C h W Z Q q b p 1 d w 6 y S r y C V K F A c 1 D 5 6 o e K Z T F P k E l q T M 9 z U / R z q l E w y a f l f m Z 4 S t m Y D n n P 0 o T G 3 P j 5 / N o p O b d K S C K l b S V I 5 u r v i Z z G x k z i w H b G F E d m 2 Z u J / 3 m 9 D K M b P x d J m i F P 2 G J R l E m C i s x e J 6 H Q n K G c W E K Z F v Z W w k Z U U 4 Y 2 o L I N w V t + e Z W 0 L + r e Z d 2 7 v 6 o 2 a k U c J T i F M 6 i B B 9 f Q g D t o Q g s Y P M I z v M K b o 5 w X 5 9 3 5 W L S u O c X M C f y B 8 / k D r y m P H Q = = &lt; / l a t e x i t &gt; CrossEntropy &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " O 0 Z z K 7 E 1 6 7 J + 8 E L s g F D 5 t S B C t B I = " &gt; A A A B / H i c b V B N S w M x E M 3 6 W e v X a o 9 e g k X o q e y q o M d C E T x W s B / Q L i W b p m 1 o N l m S W X F Z 6 l / x 4 k E R r / 4 Q b / 4 b 0 3 Y P 2 v p g 4 P H e D D P z w l h w A 5 7 3 7 a y t b 2 x u b R d 2 i r t 7 + w e H 7 t F x y 6 h E U 9 a k S i j d C Y l h g k v W B A 6 C d W L N S B Q K 1 g 4 n 9 Z n f f m D a c C X v I Y 1 Z E J G R 5 E N O C V i p 7 5 Z 6 w B 4 h q 2 t l z I 0 E r e J 0 2 n f L X t W b A 6 8 S P y d l l K P R d 7 9 6 A 0 W T i E m g g h j T 9 b 0 Y g o x o 4 F S w a b G X G B Y T O i E j 1 r V U k o i Z I J s f P 8 V n V h n g o d K 2 J O C 5 + n s i I 5 E x a R T a z o j A 2 C x 7 M / E / r 5 v A 8 D r I u I w T Y J I u F g 0 T g U H h W R J 4 w D W j I F J L C N X c 3 o r p m G h C w e Z V t C H 4 y y + v k t Z 5 1 b + o + n e X 5 V o l j 6 O A T t A p q i A f X a E a u k U N 1 E Q U p e g Z v a I 3 5 8 l 5 c d 6 d j 0 X r m p P P l N A f O J 8 / w W a V Z g = = &lt; / l a t e x i t &gt; Semantic Segmentation Scores &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " w p 3 A Z k 8 Z y D Y n 9 X H W Y 2 X I / I b f f S I = " &gt; A A A C D H i c b V C 7 S g N B F J 2 N r x h f U U u b w S B Y S N i V i J Y B G 8 t I z A O S E G Y n N 8 m Q 2 d l l 5 q 4 Y l n y A j b 9 i Y 6 G I r R 9 g 5 9 8 4 m 6 T Q x A M D h 3 P O n c s 9 f i S F Q d f 9 d j I r q 2 v r G 9 n N 3 N b 2 z u 5 e f v + g b s J Y c 6 j x U I a 6 6 T M D U i i o o U A J z U g D C 3 w J D X 9 0 n f q N e 9 B G h O o O x x F 0 A j Z Q o i 8 4 Q y t 1 8 4 U 2 w g M m V Q i Y Q s F p F Q Y B K J y 6 t M p D D W Z i U 2 7 R n Y I u E 2 9 O C m S O S j f / 1 e 6 F P E 4 / 4 p I Z 0 / L c C D s J 0 3 a D h E m u H R u I G B + x A b Q s V S w A 0 0 m m x 0 z o i V V 6 t B 9 q + x T S q f p 7 I m G B M e P A t 8 m A 4 d A s e q n 4 n 9 e K s X / V S Y S K Y g T F Z 4 v 6 s a Q Y 0 r Q Z 2 h M a O M q x J Y x r k b b B h 0 w z j r a / n C 3 B W z x 5 m d T P i 1 6 p e H F b K p T P 5 n V k y R E 5 J q f E I 5 e k T G 5 I h d Q I J 4 / k m b y S N + f J e X H e n Y 9 Z N O P M Z w 7 J H z i f P 5 a j m + U = &lt; / l a t e x i t &gt; Ground Truth Semantic Labels &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " a W d + V c 2 N Y e X P D t n s h 9 / 4 a / 8 B e B k = " &gt; A A A C D H i c b V C 7 S g N B F J 2 N r x h f U U u b w S B Y S N i V i J Y B C y 0 s I u Y F S Q i z k 5 t k y O z s M n N X D E s + w M Z f s b F Q x N Y P s P N v n D w K T T w w c D j n 3 D v c 4 0 d S G H T d b y e 1 t L y y u p Z e z 2 x s b m 3 v Z H f 3 q i a M N Y c K D 2 W o 6 z 4 z I I W C C g q U U I 8 0 s M C X U P M H l 2 O / d g / a i F C V c R h B K 2 A 9 J b q C M 7 R S O 5 t r I j x g c q X D W H V o W c f Y p 3 c Q M I W C 0 x v m g z Q j m 3 L z 7 g R 0 k X g z k i M z l N r Z r 2 Y n 5 H E A C r l k x j Q 8 N 8 J W w r R d K m G U a c Y G I s Y H r A c N S x U L w L S S y T E j e m S V D u 2 G 2 j 6 F d K L + n k h Y Y M w w 8 G 0 y Y N g 3 8 9 5 Y / M 9 r x N i 9 a C V C R T G C 4 t O P u r G k G N J x M 7 Q j N H C U Q 0 s Y 1 2 J c A O 8 z z T j a / j K 2 B G / + 5 E V S P c 1 7 h f z Z b S F X P J n V k S Y H 5 J A c E 4 + c k y K 5 J i V S I Z w 8 k m f y S t 6 c J + f F e X c + p t G U M 5 v Z J 3 / g f P 4 A + r 2 b g Q = = &lt; / l a t e x i t &gt; Input Pointcloud &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " W 6 a b E a w V N T W 5 v o t d U t 9 i y Y D F Q z 8 = " &gt; A A A C A H i c b V C 7 T s M w F H X K q 5 R X g I G B x a J C Y k B V A k g w V m K B r U j 0 I b V R 5 T h u a 9 W J I / s G U U V Z + B U W B h B i 5 T P Y + B u c N g O 0 H M n S 0 T n 3 2 j 7 H j w X X 4 D j f V m l p e W V 1 r b x e 2 d j c 2 t 6 x d / d a W i a K s i a V Q q q O T z Q T P G J N 4 C B Y J 1 a M h L 5 g b X 9 8 n f v t B 6 Y 0 l 9 E 9 T G L m h W Q Y 8 Q G n B I z U t w 9 6 w B 4 h v Y 3 i B H B D 8 g i o k E m Q 9 e 2 q U 3 O m w I v E L U g V F W j 0 7 a 9 e I G k S s v w G o n X X d W L w U q K A U 8 G y S i / R L C Z 0 T I a s a 2 h E Q q a 9 d B o g w 8 d G C f B A K n M i w F P 1 9 0 Z K Q q 0 n o W 8 m Q w I j P e / l 4 n 9 e N 4 H B l Z f y P B 2 L 6 O y h Q S I w S J y 3 g Q O u G A U x M Y R Q x c 1 f M R 0 R R S i Y z i q m B H c + 8 i J p n d X c 8 5 p 7 d 1 G t n x Z 1 l N E h O k I n y E W X q I 5 u U A M 1 E U U Z e k a v 6 M 1 6 s l 6 s d + t j N l q y i p 1 9 9 A f W 5 w 9 9 M Z b o &lt; / l a t e x i t &gt; FC-C &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " D H c L f s L s n Y m 9 t h + W J I 8 l 0 H l 5 b m o = " &gt; A A A B 8 n i c b V B N S w M x E M 3 6 W e t X 1 a O X Y B F 6 s e x K R Y + F g n i s Y D 9 g u 5 R s m m 1 D s 8 m S z I p l 6 c / w 4 k E R r / 4 a b / 4 b 0 3 Y P 2 v p g 4 P H e D D P z w k R w A 6 7 7 7 a y t b 2 x u b R d 2 i r t 7 + w e H p a P j t l G p p q x F l V C 6 G x L D B J e s B R w E 6 y a a k T g U r B O O G z O / 8 8 i 0 4 U o + w C R h Q U y G k k e c E r C S 3 w P 2 B N l t 4 6 I x 7 Z f K b t W d A 6 8 S L y d l l K P Z L 3 3 1 B o q m M Z N A B T H G 9 9 w E g o x o 4 F S w a b G X G p Y Q O i Z D 5 l s q S c x M k M 1 P n u J z q w x w p L Q t C X i u / p 7 I S G z M J A 5 t Z 0 x g Z J a 9 m f i f 5 6 c Q 3 Q Q Z l 0 k K T N L F o i g V G B S e / Y 8 H X D M K Y m I J o Z r b W z E d E U 0 o 2 J S K N g R v + e V V 0 r 6 s e r X q 1 X 2 t X K / k c R T Q K T p D F e S h a 1 R H d 6 i J W o g i h Z 7 R K 3 p z w H l x 3 p 2 P R e u a k 8 + c o D 9 w P n 8 A 3 c u Q 6 A = = &lt; / l a t e x i t &gt; Classification Scores &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " C 1 8 b 5 6 4 R 2 L + D 8 M N s k t n 1 / t 0 S r Z c = " &gt; A A A C B 3 i c b V D L S s N A F J 3 4 r P E V d S l I s A h d l a Q o u i x 0 4 7 K i f U A T y m R 6 0 w 6 d T M L M R C i h O z f + i h s X i r j 1 F 9 z 5 N 0 7 a I N p 6 Y O B w z n 3 M P U H C q F S O 8 2 W s r K 6 t b 2 y W t s z t n d 2 9 f e v g s C 3 j V B B o k Z j F o h t g C Y x y a C m q G H Q T A T g K G H S C c S P 3 O / c g J I 3 5 n Z o k 4 E d 4 y G l I C V Z a 6 l s n H g G u Q J g N h q X 8 M T z v l s Q C Z N 8 q O 1 V n B n u Z u A U p o w L N v v X p D W K S R n o o y S f 2 X C d R f o a F o o T B 1 P R S C Q k m Y z y E n q Y c R y D 9 b H b H 1 D 7 T y s A O Y 6 E f V / Z M / d 2 R 4 U j K S R T o y g i r k V z 0 c v E / r 5 e q 8 M r P K E 9 S B Z z M F 4 U p s 1 V s 5 6 H Y A y q A K D b R B B N B 9 V 9 t M s I C E 5 2 M N H U I 7 u L J y 6 R d q 7 r n 1 Y u b W r l e K e I o o W N 0 i i r I R Z e o j q 5 R E 7 U Q Q Q / o C b 2 g V + P R e D b e j P d 5 6 Y p R 9 B y h P z A + v g F C z 5 l 9 &lt; / l a t e x i t &gt; Our model is built from a sequence of point convolutional layers (PointConv , Section III-C). Fully connected layers are denoted by FC. The bottom output branchis used for the experiments on semantic segmentation. The top output branch is used for object classification. Each task is supervised using a cross-entropy loss, with either K semantic classes for semantic segmentation or C object classes for the object classification task.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>k = 5 , d = 1 k = 10 , d = 1 k = 20 , d = 1 k = 20 , d = 2 k = 20 , d = 8 k = 20 , d = 16 Fig. 4 .</head><label>5110120120220820164</label><figDesc>Receptive field visualized in blue for different network architectures using an increasing number of Point Convolutions (columns) and increasing kernel sizes (rows) based on the number of nearest neighbors k and dilation factor d. The receptive field sizes of point convolutions without dilation (d = 1) are substantially smaller. However, for large dilations, e.g. d = 16 the receptive field is sparse in early stages of the deep network (bottom left).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>. The main branch (shown in green) consists of stacked (dilated) point convolutions. The k nearest neighbors (KNN) for each point are computed on-the-fly. The final point features are concatenated with global features obtained by max-pooling over the concatenated point features at different depth-levels.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>stack 3 convolutional layers, SpiderCNN [29] use 4 layers and PCCN [25] use 8. Here, we compare 3, 5 and 7 layers, seeTable III.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Left to right: Input RGB point cloud, semantic segmentation ground truth, semantic segmentation prediction and the error where green shows correct predictions, red shows wrong predictions and white indicates unlabeled ground truth.</figDesc><table><row><cell></cell><cell>Point Cloud</cell><cell></cell><cell></cell><cell cols="2">Ground Truth</cell><cell></cell><cell cols="2">Our Predictions</cell><cell></cell><cell cols="2">Error</cell></row><row><cell>Wall</cell><cell>Floor</cell><cell>Cabinet</cell><cell>Chair</cell><cell>Table</cell><cell>Door</cell><cell>Picture</cell><cell>Counter</cell><cell>Desk</cell><cell>Refrigerator</cell><cell>Sink</cell><cell>Otherfurn.</cell></row></table><note>Fig. 5. Results of our method on ScanNet v2 dataset [4] validation.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE I 3D</head><label>I</label><figDesc>SEMANTIC SEGMENTATION ON S3DIS (A5) AND SCANNET V2.</figDesc><table><row><cell></cell><cell>Method</cell><cell>mIoU</cell><cell>mAcc</cell><cell>oAcc</cell></row><row><cell></cell><cell>PointNet [18]</cell><cell>41.1</cell><cell>49.0</cell><cell>-</cell></row><row><cell>S3DIS Area 5</cell><cell>KWYND [6] PointCNN [14] SPG [12] PCNN [25]</cell><cell>52.2 57.3 58.0 58.3</cell><cell>59.1 63.9 66.5 67.0</cell><cell>84.2 85.9 86.4 -</cell></row><row><cell></cell><cell>DPC (Ours)</cell><cell>61.28</cell><cell>68.38</cell><cell>86.78</cell></row><row><cell>ScanNet</cell><cell>DPC (Val-set) DPC (Test-set)</cell><cell>59.52 59.2</cell><cell>67.21 -</cell><cell>85.95 -</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE II OBJECT</head><label>II</label><figDesc>CLASSIFICATION SCORES ON MODELNET40</figDesc><table><row><cell>Method</cell><cell># Points</cell><cell>oAcc</cell><cell>mAcc</cell></row><row><cell>PointNet[18]</cell><cell>1k</cell><cell>89.2</cell><cell>86.2</cell></row><row><cell>PointNet++(with normals)[20]</cell><cell>5k</cell><cell>91.9</cell><cell>-</cell></row><row><cell>Kd-Net[10]</cell><cell>32k</cell><cell>91.8</cell><cell>88.5</cell></row><row><cell>EdgeConv[26]</cell><cell>1k</cell><cell>92.2</cell><cell>90.2</cell></row><row><cell>SO-Net(with normals)[13]</cell><cell>5k</cell><cell>92.4</cell><cell>90.8</cell></row><row><cell>SpiderCNN(with normals)[29]</cell><cell>1k</cell><cell>92.4</cell><cell>-</cell></row><row><cell>DPC (Ours) with normals</cell><cell>4k</cell><cell>93.1</cell><cell>91.4</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE III ABLATION</head><label>III</label><figDesc>STUDY: STACKING POINT CONVOLUTIONS AND VARYING KERNEL SIZE k. DATASET: S3DIS AREA 5.</figDesc><table><row><cell cols="2">Number of Number of</cell><cell>Time per</cell><cell>Number of</cell></row><row><cell cols="4">PointConvs Neighbors k Forward-Pass Parameters mIoU mAcc</cell></row><row><cell>3</cell><cell>5</cell><cell>12.10 ms</cell><cell>402 · 10 3 50.04 57.42</cell></row><row><cell>3</cell><cell>10</cell><cell>13.64 ms</cell><cell>402 · 10 3 50.98 58.16</cell></row><row><cell>3</cell><cell>20</cell><cell>17.65 ms</cell><cell>402 · 10 3 52.25 60.83</cell></row><row><cell>5</cell><cell>5</cell><cell>14.53 ms</cell><cell>625 · 10 3 52.69 58.87</cell></row><row><cell>5</cell><cell>10</cell><cell>17.12 ms</cell><cell>625 · 10 3 52.91 59.57</cell></row><row><cell>5</cell><cell>20</cell><cell>23.35 ms</cell><cell>625 · 10 3 53.27 60.15</cell></row><row><cell>7</cell><cell>5</cell><cell>16.99 ms</cell><cell>880 · 10 3 52.93 59.87</cell></row><row><cell>7</cell><cell>10</cell><cell>20.68 ms</cell><cell>880 · 10 3 53.57 60.92</cell></row><row><cell>7</cell><cell>20</cell><cell>29.38 ms</cell><cell>880 · 10 3 53.93 61.73</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE IV ABLATION</head><label>IV</label><figDesc>STUDY: DILATED POINT CONVOLUTIONS. VARYING DILATION FACTORS d. DATASET: S3DIS AREA 5.</figDesc><table><row><cell cols="2">Number of Number of</cell><cell>Time per</cell><cell cols="2">Number of Dilation</cell><cell></cell></row><row><cell cols="4">PointConvs Neighbors k Forward-Pass Parameters</cell><cell>d</cell><cell>mIoU mAcc</cell></row><row><cell>7</cell><cell>20</cell><cell>29.38 ms</cell><cell>880 · 10 3</cell><cell>1</cell><cell>53.93 61.73</cell></row><row><cell>7</cell><cell>20</cell><cell>31.57 ms</cell><cell>880 · 10 3</cell><cell>2</cell><cell>55.83 61.76</cell></row><row><cell>7</cell><cell>20</cell><cell>35.36 ms</cell><cell>880 · 10 3</cell><cell>8</cell><cell>61.28 68.38</cell></row><row><cell>7</cell><cell>20</cell><cell>51.65 ms</cell><cell>880 · 10 3</cell><cell>16</cell><cell>58.79 65.84</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">3D Semantic Parsing of Large-Scale Indoor Spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iro</forename><surname>Armeni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ozan</forename><surname>Sener</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Amir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helen</forename><surname>Zamir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Brilakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">SnapNet: 3D point cloud semantic labeling with 2D deep segmentation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Boulch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joris</forename><surname>Guerry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bertrand</forename><forename type="middle">Le</forename><surname>Saux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Audebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computers &amp; Graphics</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iasonas</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">ScanNet: Richly-annotated 3D Reconstructions of Indoor Scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angel</forename><forename type="middle">X</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manolis</forename><surname>Savva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maciej</forename><surname>Halber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Funkhouser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Nießner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">3D-BEVIS: Birds-Eye-View Instance Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cathrin</forename><surname>Elich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francis</forename><surname>Engelmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonas</forename><surname>Schult</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theodora</forename><surname>Kontogianni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bastian</forename><surname>Leibe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">German Conference on Pattern Recognition (GCPR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Know What Your Neighbors Do: 3D Semantic Segmentation of Point Clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francis</forename><surname>Engelmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theodora</forename><surname>Kontogianni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonas</forename><surname>Schult</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bastian</forename><surname>Leibe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision Workshop (ECCV&apos;W)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">3D Semantic Segmentation with Submanifold Sparse Convolutional Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Engelcke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Deep Residual Learning for Image Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Pointwise Convolutional Neural Network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Binh-Son</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Khoi</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sai-Kit</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yeung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Escape from Cells: Deep Kd-Networks for the Recognition of 3D Point Cloud Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roman</forename><surname>Klokov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Point Cloud Oversegmentation with Graph-Structured Deep Metric Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Loïc</forename><surname>Landrieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Boussaha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Large-scale Point Cloud Semantic Segmentation with Superpoint Graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Loïc</forename><surname>Landrieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Simonovsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">SO-Net: Self-Organizing Network for Point Cloud Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaxin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ben</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gim Hee</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">PointCNN: Convolution On X-Transformed Points</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangyan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Bu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingchao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinhan</forename><surname>Di</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baoquan</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Understanding the effective receptive field in deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjie</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yujia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">VoxNet: A 3D Convolutional Neural Network for real-time object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Maturana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Scherer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Intelligent Robots and Systems (IROS)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Systematic Evaluation of Convolution Neural Network Advances on the Ima-geNet</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmytro</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikolay</forename><surname>Sergievskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiri</forename><surname>Matas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision and Image Understanding</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
		<respStmt>
			<orgName>CVIU</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><forename type="middle">R</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaichun</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Volumetric and Multi-View CNNs for Object Classification on 3D Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><forename type="middle">R</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Nießner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengyuan</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><forename type="middle">R</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">OctNet: Learning Deep 3D Representations at High Resolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gernot</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Osman Ulusoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Geiger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Very Deep Convolutional Networks for Large-Scale Image Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Conference on Learning Representations (ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Going Deeper with Convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><forename type="middle">E</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">SEGCloud: Semantic Segmentation of 3D Point Clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lyne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">B</forename><surname>Tchapmi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iro</forename><surname>Choy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyoung</forename><surname>Armeni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Gwak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on 3D Vision (3DV)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Deep Parametric Continuous Convolutional Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Suo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">C</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pokrovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Dynamic Graph CNN for Learning on Point Clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongbin</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjay</forename><forename type="middle">E</forename><surname>Sarma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><forename type="middle">M</forename><surname>Solomon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">PointConv: Deep Convolutional Networks on 3D Point Clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenxuan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongang</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fuxin</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">3D ShapeNets: A Deep Representation for Volumetric Shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhirong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuran</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fisher</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linguang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxiong</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Spider-CNN: Deep Learning on Point Sets with Parameterized Convolutional Filters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingye</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Qiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Multi-Scale Context Aggregation by Dilated Convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fisher</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Visualizing and Understanding Convolutional Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Zeiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">VoxelNet: End-to-End Learning for Point Cloud Based 3D Object Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oncel</forename><surname>Tuzel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
