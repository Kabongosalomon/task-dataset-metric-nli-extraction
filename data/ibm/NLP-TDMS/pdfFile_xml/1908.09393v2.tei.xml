<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Scalable Probabilistic Matrix Factorization with Graph-Based Priors</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2019-09-12">September 12, 2019</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Strahl</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution" key="instit1">Helsinki Institute for Information Technology HIIT</orgName>
								<orgName type="institution" key="instit2">Aalto University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaakko</forename><surname>Peltonen</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Faculty of Information Technology and Communication Sciences</orgName>
								<orgName type="institution">Tampere University</orgName>
								<address>
									<country key="FI">Finland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroshi</forename><surname>Mamitsuka</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution" key="instit1">Helsinki Institute for Information Technology HIIT</orgName>
								<orgName type="institution" key="instit2">Aalto University</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department" key="dep1">Bioinformatics Center</orgName>
								<orgName type="department" key="dep2">Institute for Chemical Research</orgName>
								<orgName type="institution">Kyoto University</orgName>
								<address>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Kaski</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution" key="instit1">Helsinki Institute for Information Technology HIIT</orgName>
								<orgName type="institution" key="instit2">Aalto University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Scalable Probabilistic Matrix Factorization with Graph-Based Priors</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2019-09-12">September 12, 2019</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T05:51+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In matrix factorization, available graph side-information may not be well suited for the matrix completion problem, having edges that disagree with the latent-feature relations learnt from the incomplete data matrix. We show that removing these contested edges improves prediction accuracy and scalability. We identify the contested edges through a highlyefficient graphical lasso approximation. The identification and removal of contested edges adds no computational complexity to state-of-the-art graph-regularized matrix factorization, remaining linear with respect to the number of non-zeros. Computational load even decreases proportional to the number of edges removed. Formulating a probabilistic generative model and using expectation maximization to extend graph-regularised alternating least squares (GRALS) guarantees convergence. Rich simulated experiments illustrate the desired properties of the resulting algorithm. On real data experiments we demonstrate improved prediction accuracy with fewer graph edges (empirical evidence that graph side-information is often inaccurate). A 300 thousand dimensional graph with three million edges (Yahoo music side-information) can be analyzed in under ten minutes on a standard laptop computer demonstrating the efficiency of our graph update.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Matrix factorization (MF) is popular in a number of domains including recommender systems <ref type="bibr" target="#b28">Koren et al. [2009]</ref>, <ref type="bibr">Mehta and Rana [2017]</ref>, bioinformatics <ref type="bibr" target="#b5">Brunet et al. [2004]</ref>, <ref type="bibr" target="#b26">Jacoby and Brown [2018]</ref>, <ref type="bibr" target="#b48">Stein-O'Brien et al. [2018]</ref>, <ref type="bibr">Zakeri et al. [2018]</ref>, <ref type="bibr">Zheng et al. [2013]</ref>, image restoration <ref type="bibr" target="#b51">Xue et al. [2017]</ref> and many more Davenport and Romberg <ref type="bibr">[2016]</ref>. Much of the data is of a very large scale and sparse, and additional (side-)information is usually available. Therefore, many methods focus on scalability Davenport and Romberg <ref type="bibr">[2016]</ref>, <ref type="bibr" target="#b38">Mnih and Salakhutdinov [2008]</ref>, <ref type="bibr" target="#b43">Sardianos et al. [2019]</ref> and the addition of side information (SI) <ref type="bibr">Chiang et al. [2015</ref><ref type="bibr" target="#b11">Chiang et al. [ , 2018</ref>, <ref type="bibr" target="#b20">Gönen et al. [2013]</ref>, <ref type="bibr" target="#b33">Ma et al. [2011]</ref>, Zakeri et al. <ref type="bibr">[2018]</ref>, <ref type="bibr">Zhou et al. [2012]</ref>, <ref type="bibr">Zhao et al. [2015]</ref>, and more recently scalable methods with <ref type="bibr">SI Monti et al. [2017]</ref>, <ref type="bibr" target="#b41">Rao et al. [2015]</ref>, <ref type="bibr" target="#b52">Yao and Li [2018]</ref>.</p><p>Empirical evidence shows that prediction accuracy is significantly improved by graph SI, where edges in the graph represent similarity between connected nodes <ref type="bibr" target="#b6">Cai et al. [2011]</ref>, <ref type="bibr" target="#b33">Ma et al. [2011]</ref>, <ref type="bibr" target="#b39">Monti et al. [2017]</ref>, <ref type="bibr" target="#b41">Rao et al. [2015]</ref>, <ref type="bibr" target="#b52">Yao and Li [2018]</ref>, <ref type="bibr">Zhou et al. [2012]</ref>, Zhao et al. <ref type="bibr">[2015]</ref>. MF (or low-rank matrix completion) has theoretical guarantees for exact completion without and with noise Candes and Plan <ref type="bibr">[2010]</ref>, Candès and Recht <ref type="bibr">[2009]</ref>. Introducting noisy SI is shown to reduce sample-complexity, and is reduced even further handling the noise <ref type="bibr">Chiang et al. [2015]</ref>. Reduction in sample complexity through the introduction of graph SI has also been shown <ref type="bibr" target="#b1">Ahn et al. [2018]</ref>, <ref type="bibr" target="#b41">Rao et al. [2015]</ref>, as a function of graph quality. However, to the best of our knowledge there is no work on scalable methods to handle the noise in the graph SI. <ref type="bibr" target="#b38">Mnih and Salakhutdinov Mnih and Salakhutdinov [2008]</ref> introduced probabilistic matrix factorisation (PMF), which is equivalent to 2 -regularised (alternating least squares) MF. Probabilistic interpretations for MF with graph SI are kernelized PMF <ref type="bibr">(KPMF Zhou et al. [2012]</ref>) and kernelized Bayesian MF (KBMF <ref type="bibr" target="#b20">Gönen et al. [2013]</ref>): placing priors over the columns of the latent feature matrices. This type of prior models the pairwise relation between rows, where these rows correspond to rows or columns of the incomplete data matrix. KPMF and KBMF showed good results on moderate-sized data but failed to scale to large data.</p><p>To address scalability, graph-regularised least squares (GRALS <ref type="bibr" target="#b41">Rao et al. [2015]</ref>) was proposed, with conjugate gradient descent exploiting the sparsity in the data matrix and the graphs, resulting in linear computational complexity and fast convergence. Recently there has been progress on applying deep learning to matrix completion, with and without side information, with good accuracy and showing potential for scalability <ref type="bibr" target="#b3">Berg et al. [2017]</ref>, <ref type="bibr" target="#b24">Hartford et al. [2018]</ref>, <ref type="bibr" target="#b39">Monti et al. [2017]</ref>, <ref type="bibr" target="#b52">Yao and Li [2018]</ref>.</p><p>All of the non-Bayesian or scalable methods incorporating graph <ref type="bibr">SI Cai et al. [2011]</ref>, <ref type="bibr" target="#b33">Ma et al. [2011]</ref>, <ref type="bibr" target="#b39">Monti et al. [2017]</ref>, <ref type="bibr" target="#b41">Rao et al. [2015]</ref>, <ref type="bibr">Zhou et al. [2012]</ref> fix the edges in the graph, considering them as true. However, these graphs are known to be uncertain <ref type="bibr" target="#b0">Adar and Re [2007]</ref>, <ref type="bibr" target="#b2">Asthana et al. [2004]</ref>, and furthermore, the similarities they represent (e.g. homophily <ref type="bibr" target="#b35">McPherson et al. [2001]</ref>) are rarely specific to the matrix factorization task leaving no guarantee that correlations correspond <ref type="bibr" target="#b33">Ma et al. [2011]</ref>, <ref type="bibr" target="#b45">Singla and Richardson [2008]</ref>; graphs are often formed for other purposes, and hence their usefulness for MF is uncertain. This leaves room for improving the quality of the graph, leading to a significant reduction in sample complexity <ref type="bibr" target="#b1">Ahn et al. [2018]</ref>. In this work we will introduce a solution based on contested edges, defined later in the paper.</p><p>Example of Graph Side-Information and Contested Edges To better understand how graph similarities are not task-specific (are non-specific) to MF, take a common example of a movie-recommendation problem with social network (SN) SI <ref type="bibr" target="#b33">(Ma et al. [2011]</ref> and in our experiments on Douban data). Connected users in the SN do not connect based on their similar preference of movies, instead they connect on the basis of a broader social context. Similarly, the demographic information in MovieLens 1 , used to form a user-similarity graph, is only very indirectly related to the movie preferences <ref type="bibr" target="#b35">McPherson et al. [2001]</ref>. Nevertheless, more general similarity has been shown to often work well in practice, but some parts of it may turn out to be detrimental as we illustrate below.</p><p>Figure 1 (top) shows a small movie-recommendation data matrix with SN SI (bottom-left). Without SI, if row/column observations in the data matrix are similar, latent features will be similar. This can be inaccurate, e.g. users 2 and 3 would be considered similar based on the observations, and thus predictions for user 2 would be similar to ratings of user 3, whereas actually user 2 is similar to user 1. Graph information can help by encouraging latent features of connected users, like user 1 and user 2 here, to be similar, even when there is no observed data in the matrix to indicate they should be. However, for other users such as 4 and 5 the graph may mismatch with the data, indicating similarity whereas 4 and 5 are actually negatively correlated (as seen in their ratings of movies 5 and 6), and using the graph would thus worsen their predictions. We propose using this discrepancy to contest the graph edge between users 4 and 5; removing this edge as in <ref type="figure" target="#fig_0">Figure 1</ref> (bottom-right) would improve predictions for users 4 and 5 to be consistent with their observed negative correlation, while the beneficial edge between users 1 and 2 will still remain. In real cases, mismatch between the data matrix and the SI would be detected based on much more data than in this illustration.</p><p>We do not propose to identify contested edges directly from the observed data but from correlations between the latent features. We introduce a probabilistic generative model that we call graph-based prior PMF (GPMF). Using the expectation-maximization (EM, <ref type="bibr" target="#b4">Bishop [2006]</ref>) algorithm we find a maximum a posteriori (MAP) estimate for the latent features and a maximum likelihood estimate (MLE) for the correlations of the latent features. We show in Section 3.3 how using GLASSO approximation we can remove contested edges by simply thresholding a constrained sample covariance matrix (SCM).</p><p>There exist a number of approaches to reduce the edges in a labelled graph, graph summarization, <ref type="bibr" target="#b32">Liu et al. [2018]</ref> for example. Most of these approaches do not use node attributes (labels) and to the best of our knowledge none use latent features for edge pruning. There are link prediction models that are probabilistic and use node attributes <ref type="bibr" target="#b22">Haghani and Keyvanpour [2017]</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">GPMF Generative Model and Relations to the Graph Side-Information</head><p>We are provided with a partially observed data matrix R with N rows and M columns. R is approximated as the product of two low-rank matrices, U and V . The number of latent features D is fixed; U and V have D columns, each row is a latent feature vector for each row / column of R respectively. We use an index set Ω where Ω ij is one if the element in row i and column j of R is observed, and zero otherwise. The goal is to learn latent-feature matrices U and V that most accurately represent the full matrix R.</p><p>2 -regularized MF has a scalable probabilistic interpretation: PMF. Each observed entry R ij : (i, j) ∈ {Ω = 1} is assumed to have Gaussian noise σ 2 ; each row of U and V has a zero-mean spherical Gaussian prior. Similar to KPMF Zhou et al. <ref type="bibr">[2012]</ref>, our model replaces the spherical Gaussian prior with a full-covariance Gaussian over the columns of the latent features (introducing row-wise dependencies):</p><formula xml:id="formula_0">p(R | U , V , σ 2 ) = N i=1 M j=1 N (R ij | U i: V j: , σ 2 ) Ωij (1) p(U | Λ U ) = D d=1 N (U :d | 0, Λ −1 U ) (2) p(V | Λ V ) = D d=1 N (V :d | 0, Λ −1 V ) .<label>(3)</label></formula><p>Graph SI constrains the structure of the precision matrices (Λ U or Λ V ) of (2) and (3), discussed next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Gaussian Markov Random Field (GMRF) relation to Precision matrix</head><p>An undirected graph</p><formula xml:id="formula_1">G Z = (V Z , E Z ) with a set of nodes V Z , representing a set of random variables {Z i } P i=1 , and a set of edges E Z ⊆ {(i, j) | i, j ∈ V Z },</formula><p>defines the conditional independence of the random variables, where the absence of an edge (i, j) / ∈ E Z implies that the two random variables are conditionally independent [Λ Z ] ij = 0 given the remaining random variables <ref type="bibr" target="#b4">Bishop [2006]</ref>, <ref type="bibr" target="#b25">Hastie et al. [2009]</ref>, <ref type="bibr" target="#b29">Lauritzen [1996]</ref>, <ref type="bibr" target="#b42">Rue and Held [2005]</ref>:</p><formula xml:id="formula_2">Z i ⊥ Z j | {Z k : k ∈ (1, ..., N ) \ (i, j)}.</formula><p>In the remainder of the paper we refer to the adjacency matrix of G Z : a symmetric matrix where [A Z ] ij is one if an edge exists between nodes i and j and zero otherwise. We can summarize the GMRF relation as</p><formula xml:id="formula_3">[A Z ] ij = 0 ⇐⇒ [Λ Z ] ij = 0 | i = j.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Laplacian Matrix relation to Precision Matrix</head><p>The Laplacian matrix of a graph is</p><formula xml:id="formula_4">L Z = D − A Z , where D i,i = N j=1 [A Z ] ij</formula><p>is a diagonal degree matrix, and is positive-semi-definite by definition. The regularised Laplacian L + Z = L Z + γI , γ &gt; 0 is a positive-definite matrix; a valid precision matrix retaining the GMRF property <ref type="bibr" target="#b14">Dong et al. [2016]</ref>, Egilmez et al. <ref type="bibr">[2016,</ref><ref type="bibr">2017]</ref>, <ref type="bibr" target="#b25">Hastie et al. [2009]</ref>, <ref type="bibr" target="#b31">Liu et al. [2014]</ref>:</p><formula xml:id="formula_5">[L + Z ] ij = 0 ⇐⇒ [Λ Z ] ij = 0 | i = j.</formula><p>Lemma 1. If the precision matrix in <ref type="formula">(2)</ref> and <ref type="formula" target="#formula_0">(3)</ref> is the regularised Laplacian matrix L + U , L + V , then the MAP estimator of our model has the same objective function as GRALS <ref type="bibr" target="#b41">Rao et al. [2015]</ref>. Our GPMF model therefore gives a generalization of the GRALS objective function.</p><p>Proof of Lemma 1. Our generative model is biconvex, and hence it suffices to prove for U that the posterior is equivalent to the GRALS objective. Holding V fixed and finding the log posterior of U :</p><formula xml:id="formula_6">ln p(U |R, σ 2 , V , Λ U ) ∝ ln p(R | U , V , σ 2 )p(U | Λ U ) ∝ − 1 σ 2 N i=1 M j=1 P Ω (R ij − U i: V j: ) 2 − 1 2 D d=1 U :d Λ U U :d = − 1 2 P Ω (R − U V ) 2 F − σ 2 2 tr(U L + U U )) ,<label>(4)</label></formula><p>where U i: is row i of matrix U and U :d is column d and noting that i,j U 2 ij = tr(U U ) = U 2 F . Equation <ref type="formula" target="#formula_6">(4)</ref> is the GRALS objective function <ref type="bibr" target="#b41">Rao et al. [2015]</ref>. Derivations in the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">GRAEM: Scalable EM for GPMF</head><p>We naturally extend each least-squares sub-problem of GRALS <ref type="bibr" target="#b41">Rao et al. [2015]</ref> with graph-regularised alternating EM (GRAEM), having the same global convergence guarantees as <ref type="bibr">GRALS Xu and Yin [2013]</ref>. We work through optimising U with V fixed, solving for V has the same form.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">The EM Formulation</head><p>We have an incomplete data matrix R, fixed matrix V , latent variable matrix U , and graph SI. From the graph we derive L + U (see Section 2.2), then set the precision matrix Λ U = L + U , which we consider our model parameters. We want to maximize the expectation of the joint density of the data and the latent variables, with U as our unknowns and Λ U as our input parameters:</p><formula xml:id="formula_7">Q(Λ U , Λ old U ) = U p(U |R, Λ old U ) ln p(R, U | Λ U ) dU = E p(U |R,Λ old U ) [ln p(R, U | Λ U )] .<label>(5)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">E-step: Expected Value of the Latent Variables</head><p>The expected value of our latent variables has a Gaussian posterior distribution (see supplementary material), we can therefore use the MAP, which is equivalent to the GRALS objective function as shown in Lemma 1:</p><formula xml:id="formula_8">E p(U |R,Λ old U ) [ U ] = µ post. U ≈μ M AP U .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">M-step: Removing Contested Edges</head><p>We can remove edges in the graph that correspond to negative correlations between the latent features by simply removing negative covariances from an SCM; this relationship holds for large scale and sparse problems; details follow.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">The MLE of the parameters and GLASSO</head><p>To find the MLE we maximise the Q function in Equation <ref type="formula" target="#formula_7">(5)</ref> with respect to Λ U . The maximum can be found in closed form by taking the derivative with respect to the parameter Λ U and setting to zero:</p><formula xml:id="formula_9">arg max Λ U Q(Λ U , Λ old U ) = E p(U |R,Λ old U ) 1 D D d=1 U :d U :d −1 = E S D U −1 = Λ * U .<label>(6)</label></formula><p>Equation <ref type="formula" target="#formula_9">(6)</ref> is the inverse of an SCM, where each sample is one of the columns of U . Values for U are unknown, so we use the MAP given the previous estimate of the parameters (Λ old U ). The solution (if any) is almost surely not sparse. Graphical lasso ( <ref type="bibr">GLASSO Mazumder and Hastie [2012]</ref>) finds a sparse solution for the MLE of the precision matrix, where samples are assumed to be normally distributed, in line with our model assumptions in Section 2. We therefore propose solving (6) with GLASSO.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Constrained GLASSO and Highly Efficient Approximation</head><p>GLASSO finds the MLE of the precision matrix under an 1 penalty, given an SCM S. <ref type="bibr" target="#b21">Grechkin et al. [2015]</ref> showed that the problem space can be reduced with prior knowledge on which pairwise relationships do not exist, forcing them to be zero in the solution:</p><formula xml:id="formula_10">min Λ U 0 tr(SΛ U ) − log |Λ U | + τ Λ U 1 , subject to [Λ U ] ij = 0, A 0 U ij = 0 .<label>(7)</label></formula><p>Zhang et al. <ref type="bibr">[2018]</ref> uses a relation between the sparsity structure of the τthresholded SCM and the GLASSO solution; for large-scale problems, when the solution is very sparse, the connected components are equivalent <ref type="bibr" target="#b34">Mazumder and Hastie [2012]</ref>, given further assumptions the complete sparsity structure is equivalent <ref type="bibr" target="#b19">Fattahi and Sojoudi [2019]</ref>, <ref type="bibr">Sojoudi [2016a,b]</ref>. However, this solution will locate correlations, positive and negative, with a strong magnitude, greater than τ . Next we detail how to identify edges that correspond to only negative correlations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.3">Removing a Contested Edge</head><p>The sparsity structure of the SCM and the (GLASSO) solution are equivalent under mild assumptions that are found to be true for sufficiently large τ , that result in ≈ 10N non-zeros in the solution <ref type="bibr">Sojoudi [2017, 2019]</ref>. One of these assumptions is sign-consistency where each non-zero element of the solution has the opposite sign in the SCM. Assuming sign-consistency we can identify all graph edges that correspond to negative correlations in the latent features, with E[S D U ] from Equation <ref type="formula" target="#formula_9">(6)</ref> as our SCM:</p><formula xml:id="formula_11">[A new U ] ij =          1, A 0 U ij = 1 , E S D U ij ≥ τ 0, A 0 U ij = 1 , E S D U ij &lt; τ , CE 0, otherwise, con-E,<label>(8)</label></formula><p>where A new U is the updated adjacency matrix, the threshold parameter τ is set to zero (or can be increased for a sparser solution) and A 0 U is the adjacency matrix of the graph SI; CE is a contested edge and con-E is a constrained edge. To solve Equation <ref type="formula" target="#formula_11">(8)</ref> we need to compute E[S D U ], we can decompose the problem:</p><formula xml:id="formula_12">E[S D U ] = 1 D D d=1 E U :d U :d E U :d U :d = Cov[U :d ] + E[U :d ]E[U :d ] = Σ post. U :d + µ post. U :d µ post. U :d .</formula><p>The remaining task is to efficiently approximate the posterior covariance Σ post.</p><p>U :d for each column, d, of U , which we discuss next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.4">Posterior Covariance Approximation</head><p>The posterior of our GPMF model, in Section 2, is a joint Gaussian distribution, where the likelihood in Equation <ref type="formula">(1)</ref> introduces relations between the columns of the latent features and the prior in Equation <ref type="formula">(2)</ref> introduces relations between the rows. This results in a posterior covariance matrix with an inverse Kronecker sum structure <ref type="bibr" target="#b27">Kalaitzis et al. [2013]</ref>, <ref type="bibr" target="#b44">Schacke [2004]</ref>: Σ post.</p><formula xml:id="formula_13">U = (I D ⊗ Λ U + α C) −1 where ⊗ is the Kronecker product operator and C = [c(d, d )] D d,d =1 , c(d, d ) = diag       M j=1 Ω ij V jd V jd    N i=1    .</formula><p>Column-wise independence assumption. We simplify the Kronecker sum with a column-wise independence assumption, setting all off-diagonals of C to zero:</p><formula xml:id="formula_14">Λ post. U ≈ I D ⊗ Λ U + α diag (C) = blkdiag Λ post. U :d D d=1 ,<label>(9)</label></formula><p>Λ post.</p><formula xml:id="formula_15">U :d = Λ U + α diag (C d ) , diag (C d ) = diag       M j=1 Ω i,j V 2 j,d    N i=1    ,</formula><p>where α = [σ 2 ] −1 is the inverse of the observation noise in <ref type="formula">(1)</ref>, diag takes a vector to create a diagonal matrix and blkdiag takes a sequence of matrices to construct a block-diagonal matrix.</p><p>Sparse Cholesky factorisation: EachΛ post.</p><p>U :d is still too large to invert. Assuming the high-dimensional matrix is sparse, as in Zhang et al. <ref type="bibr">[2018]</ref>, its Cholesky factorisation is computable in O(N ) time Davis et al. <ref type="bibr">[2004]</ref>. We compute K samples as an unbiased estimate for the approximate posterior covariance:Σ post.</p><formula xml:id="formula_16">U :d = Λ post. U :d −1 ≈ 1 K K k=1</formula><p>x k x k</p><p>x k ∼ N 0, Λ post.</p><formula xml:id="formula_17">U :d −1 .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">The Algorithm</head><p>The EM algorithm iterates between E-step and M-step until convergence. We initialize the latent feature matrices (U , V ) by finding the MAP with no graph SI using PMF, to learn latent features that reflect the observed entries of the data matrix. In practise any method to learn the latent features with no SI can be used. The M step uses the relations between the latent features to identify negative correlations and remove them from the graph SI. The E-step then finds the MAP of the latent features given the updated graph. In theory the E and M step could be continued until some convergence criterion was met, but this would be less efficient and we get good results with just one step. So the three steps of our algorithm are lines 1,3 and 4:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Scalability: Computational Complexity</head><p>The algorithm has three steps: lines 1,3,4 in Algorithm 1. Line 1 is linear in the number of non-zeros nz() in the data matrix O(nz(Ω)) per conjugate gradient (CG) iteration. Line 3 comprises sparse Cholesky factorisation, linear in time </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We compare our algorithm to a baseline with no graph SI (PMF, <ref type="bibr" target="#b38">Mnih and Salakhutdinov [2008]</ref>), the current most scalable method, <ref type="bibr">GRALS Rao et al. [2015]</ref>, and for accuracy less scalable methods KPMF Zhou et al. <ref type="bibr">[2012]</ref> and sRMGCNN <ref type="bibr" target="#b39">Monti et al. [2017]</ref>. For sRMGCNN we used their published code, ran it on a (NVIDIA Tesla P100) GPU and used cross validation to find a Algorithm 1 Graph-regularised alternating EM (GRAEM)</p><formula xml:id="formula_18">Input: A 0 U , A 0 V Output:Û ,V , A + U , A + V 1: U 0 , V 0 ← Initialise with PMF (GRALS with no graphs) 2: while not converged do 3: A t U , A t V ← Run M-step Equation (8) with U t−1 , V t−1 and A 0 U , A 0 V as structural constraints 4: U t , V t ← Run E-step with regularized Laplacians given A t U , A t V 5: end while</formula><p>good T value; note that this model took several orders of magnitude more time than the other methods: on Flixster data GPMF and GRALS converged in 20 seconds, PMF in 0.2 seconds, sRMGCNN took 30 minutes. We also ran KBMF <ref type="bibr" target="#b20">Gönen et al. [2013]</ref> but with an extremely long computational time on even the smallest dataset, and a large number of parameters, we failed to achieve reasonable results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experiments on Synthetic Data</head><p>To analyze the behaviour of our algorithm we generate a data matrix with a known underlying graph. Therefore we can replace true edges in the graph with corrupted edges (CEs) that contest the true underlying structure, controlling the accuracy of the graph SI. We use a block-diagonal regularised-Laplacian precision matrix. We generate a 400 × 400 data matrix by Equations (1)-(3), with proportion of corrupted edges 0.3, observation noise 0.01, 7% observed values, and 40 latent dimensions; we vary these settings in the experiments below. See supplementary material for further details. Graph Fidelity. In <ref type="figure" target="#fig_1">Figure 2 (a)</ref> we vary the number of CEs. A graph with no CEs has fidelity one (F = 1), with all CEs F = 0. GPMF consistently improves prediction accuracy over methods with graph SI for F &gt; 0, and performance is equal for F = 0. PMF with no graph performs better below F = 0.3, showing that a graph of low quality can make prediction accuracy worse.</p><p>Observation Noise. <ref type="figure" target="#fig_1">Figure 2 (b)</ref> shows the benefit of GPMF diminishes as noise increases; learning negative correlations requires learning from the observations. However, at worst GPMF is only as bad as using the original corrupted graph.</p><p>Proportion of Observations. In <ref type="figure" target="#fig_1">Figure 2</ref> (c) with just 10% of observed entries our algorithm can almost attain the same prediction accuracy as using the true graph. GRALS requires 30% to achieve a similar accuracy. At 40% of observed entries the graph is no longer beneficial. Note that most large scale matrix completion problems have fewer than 10% observed entries.</p><p>Model Capacity. <ref type="figure" target="#fig_1">Figure 2 (d)</ref> shows that with too few latent features all models are negatively effected, but overall GPMF attains the best prediction accuracy. GLASSO accuracy We analyse the accuracy of removing CEs over several simulations. With 7% of observed entries, 31.7% of CEs are correctly removed and 19% of true edges (TEs) are wrongly removed; increasing observed entries to 40%, 44.3% of CEs are removed and 0.3% of TEs. Fixing observed entries at 20%, with noise σ 2 = 0.01, 39% of CEs and 2.7% of TEs are removed, and with σ 2 = 1, 34.3% CEs and 42.7% TEs are removed. We see clearly that observation noise strongly effects the ability to identify contested edges, as shown in <ref type="figure" target="#fig_1">Figure 2</ref> (b). Accuracy improves with more observed entries, but even with low levels of noise and a reasonable amount of observations successful removal of CEs is only moderate. Regardless of this moderate accuracy, experiments show this is enough to attain significant improvements in prediciton accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experiments on Real Data</head><p>In <ref type="table" target="#tab_0">Table 1</ref> GPMF using GRAEM (our method) gives improved accuracy over GRALS on all small datasets: 3000 (3k) by 3k subsets of Flixster and Douban <ref type="bibr" target="#b39">Monti et al. [2017]</ref> (full datasets not attainable) and <ref type="bibr">MovieLens100k Harper and Konstan [2015]</ref>); the bottom rows of the table show the size and number of observations for each data matrix and the number of edges in each sideinformation graph. In <ref type="figure" target="#fig_2">Figure 3</ref> our method is shown to add no computational cost on large data: MovieLens 20 million <ref type="bibr" target="#b23">Harper and Konstan [2015]</ref>, <ref type="bibr" target="#b57">Epinions Tang et al. [2012]</ref> and Yahoo Music <ref type="bibr" target="#b41">Rao et al. [2015]</ref>, <ref type="bibr" target="#b15">Dror et al. [2011]</ref>), note that proportion of edges used by GPMF is reported in figure title. <ref type="figure" target="#fig_2">Figure 3 (a)</ref> is an example of poor quality graph side-information, we see this as PMF outperforms GRALS with the side-information; our method (GPMF using GRAEM) estimates over half the edges as contested, removing them seem to improve the quality.</p><p>We believe that there were no gains in <ref type="figure" target="#fig_2">Figure 3 (b)</ref> as the graph is extremely sparse and removing some edges has little effect. We test this hypothesis with MovieLens 20M in <ref type="table" target="#tab_0">Table 1</ref> by increasing the number of nearest neighbours from 10 to 40, we see that GRALS with the original graph decreases in performance while our algorithm continues to improve, we plot the best results in <ref type="figure" target="#fig_2">Figure 3 (c)</ref>; the computational time to estimate contested edges (between the two vertical broken lines) is a fraction of the running time of the algorithm.</p><p>We also tested general usefulness of the updated graph: We get a small improvement for Douban with KPMF using with 77 % of edges, we also get the same accuracy for Flixster with almost helf the edges.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We present a highly efficient method to improve the quality of graph sideinformation for matrix factorisation. Of the three steps in the algorithm, the initialisation of the latent features and the estimation of the latent features with the updated graph (the E-step) can be performed with any method for matrix completion without SI and with graph SI respectively. With such a small computational cost a graph update (the M-step) to improve quality seems like a valuable step when including graph side-information into matrix factorisation. Furthermore, we demonstrated the added robustness using our algorithm on real graph side-information. By increasing the number of nearest neighbours for generating graphs from feature side-information our algorithm, GRAEM, improved while GRALS worsened. Our graph update step allows for more noisy graphs to improve the matrix completion accuracy. Future work on improving the graph update could further improve this method; we showed with simulated data the GLASSO approximation is only moderately successful.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>13</head><p>Pooya Zakeri, Jaak Simm, Adam Arany, Sarah ElShal, and Yves Moreau. Gene prioritization using bayesian matrix factorization with genomic and phenotypic side information. Bioinformatics, 34 <ref type="formula" target="#formula_0">(13)</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Appendix</head><p>A Posterior of GPMF model</p><p>We derive the posterior of U , fixing V , given the data {R, Ω} and parameters Λ U for the Graph-based prior probabilitic matrix factoriation (GPMF) model. The posterior for V follows the same steps with U fixed. We start by breaking down the likelihood and prior into scalar operations:</p><formula xml:id="formula_19">log p(R | U , V , α, Λ U ) (10) ∝ − N i=1 M j=1 Ω ij α 2 R ij − U i: V j: 2 − D d=1 1 2 U :d Λ U U :d (11) = − α 2 N i=1 M j=1 Ω ij R 2 ij − 2R ij D d=1 U id V jd + D d=1 D d =1 V jd U id U id V jd (12) − 1 2 D d=1 N i=1 N i =1 U id [Λ U ] ii U i d (13) = − α 2 N i=1 M j=1 Ω ij R 2 ij − 1 2 N i=1   α M j=1 Ω ij D d=1 D d =1 [V jd U id U id V jd (14) −2U id V jd R ij ] + D d=1 N i =1 U id [Λ U ] ii U i d .<label>(15)</label></formula><p>Using the scalar expansion we recombine to form the full posterior in scalar form in Equation <ref type="formula">(20)</ref>, with respect to the vectorization of U Equation <ref type="formula">(22)</ref> and w.r.t.</p><p>the vectorization of U Equation <ref type="formula" target="#formula_0">(23)</ref>:</p><formula xml:id="formula_21">log p(U | R, α, V , Λ U ) (17) ∝ − 1 2 N i=1 M j=1 D d=1 αΩ ij D d =1 V jd U id U id V jd − 2U id V jd R ij + N i =1 U id [Λ U ] ii U i d (18) = − 1 2 N i=1 D d=1 U id   α M j=1 Ω ij D d =1 V jd U id V jd − 2V jd R ij + N i =1 [Λ U ] ii U i d   (19) = − 1 2 N i=1 N i =1 D d=1 D d =1   U id   α M j=1 [i = i ]I ij V jd V jd + [d = d ] [Λ U ] ii   U i d (20) −2αU id V jd R ij ] (21) = − 1 2 vec(U ) (I D ⊗ Λ U + αC) vec(U ) − 2α Tr(U RV ) (22) = − 1 2 vec(U ) Λ U ⊗ I D + α blkdiag {B i } N i=1 vec(U ) − 2α Tr(U V R ) ,<label>(23)</label></formula><p>where [i = j] is Iverson bracket notation where the value is one if the proposition is satisfied and zero otherwise, ⊗ is the Kronecker product, vec(X) stacks the columns of matrix X to produce a vector, Tr(X) is the trace of matrix X and finally I N is an N × N identity matrix and:</p><formula xml:id="formula_22">C =      c(1, 1) c(1, 2) · · · c(1, D) c(2, 1) c(2, 2) · · · c(2, D) . . . . . . . . . . . . c(D, 1) c(D, 2) · · · c(D, D)      (24) c(d, d ) = diag       M j=1 Ω ij V jd V jd    N i=1    (25) B i = {j:(i,j)∈{Ω=1}} V j: V j:<label>(26)</label></formula><p>Notice that in the posterior when stacking the columns vec(U ) in Equation <ref type="formula">(22)</ref> the prior precision matrix is a block diagonal matrix and the evidence matrix is a partitioned matrix with each block being diagonal, when stacking the rows vec(U ) the structural pattern is the other way around: the prior is a partitioned matrix of diagonal blocks and the evidence matrix is a block diagonal matrix. It is worth noting that Equation <ref type="formula">(22)</ref> and Equation (23) both have the structure of a Kronecker sum, A⊕D = A⊗I +I ⊗D. We look more closely at Equation <ref type="formula" target="#formula_0">(23)</ref>,</p><p>showing the relation with the scalar summations and the final notation in more detail. Firstly the linear term:</p><formula xml:id="formula_23">−2α N i=1 D d=1 U id M j=1 Ω ij V jd R ij = −2α N i=1 D d=1 U id M j=1 V jd R ij (27) = −2α D d=1 U :d RV :d (28) = −2α vec(U ) vec(RV ) (29) = −2α Tr(U RV ) (30) = −2α N i=1 U i: V [R i: ] (31) = −2α vec(U ) vec(V R ) (32) = −2α Tr(U V R ) ,<label>(33)</label></formula><p>and the quadratic term:</p><formula xml:id="formula_24">N i=1 N i =1 D d=1 D d =1 U id M j=1 [i = i ] [V jd V jd ] U i d = vec(U )   M j=1 V j: V j: ⊗ I N   vec(U ) (34) = vec(U )   diag    M j=1 V j: V j:    N   vec(U ) (35) N i=1 N i =1 D d=1 D d =1 U id [d = d ] [Λ U ] ii U i d = vec(U ) [Λ U ⊗ I D ] vec(U ) (36) = vec(U ) [I D ⊗ Λ U ] vec(U ) .<label>(37)</label></formula><p>Having organized the posterior, with respect to U , into a quadratic and a linear term we can complete the square to find the mean µ (n) U and precision matrix Λ (n) U of the conditional posterior distribution for the matrix U :</p><formula xml:id="formula_25">Λ (n) U = [Λ U ⊗ I D ] + α blkdiag {B i } N i=1 (38) µ (n) U = Λ (n) U −1 vec(V R )<label>(39)</label></formula><p>or the mean and covariance can be represented as different formulations with scalar sums (21), or vectorization of the matrix without transposing (22).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Experiments: further details</head><p>We compare our GPMF method to GRALS 2 <ref type="bibr" target="#b41">Rao et al. [2015]</ref>, PMF (GRALS with no graph side-information) <ref type="bibr" target="#b38">Mnih and Salakhutdinov [2008]</ref>, KPMF 3 Zhou et al.</p><p>[2012] and sRMGCNN 4 <ref type="bibr" target="#b39">Monti et al. [2017]</ref> . KPMF uses the regularised Laplacian graph kernel. We also tested KBMF 5 <ref type="bibr" target="#b20">Gönen et al. [2013]</ref>, but with many tuning parameters and a slow learning speed, making parameter tuninig costly and complex, making a similar effort as made for tuning the other algorithms we were not able to attain good results. GRALS, PMF, GPMF (GRAEM, our method), KPMF and KBMF experiments were run on a regular laptop computer: Hewlett Packard EliteBook 840 G3 notebook with Intel Core i5 and 16 GiB memory. sRMGCNN was run on a GPU (NVIDIA Tesla P100, running on a 2x12 core Xeon Dell PowerEdge C4130). For model learning and evaluation we use a the same training and validation set for all models. We use the same systematic search procedure (similar effort for tuning) for each model for a fair comparison.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1 Synthetic Data</head><p>Default settings for the experiments, if no other details are mentioned, are a 400 × 400 data matrix with 7 percent observed values, a graph fidelity of 0.7, observation noise σ 2 = 0.01, 40 latent feature dimensions and noise between similar latent features 0.0001. We use the graphs to create the latent feature matrices U and V according to the GPMF model. Sampling of observed entries for training and validation is according to a non-uniform distribution; to avoid rows and columns having similar numbers of observations, we use a multinomial distribution with Dirichlet prior). Each experiment setting is run five times for each model and an average is reported with the standard deviation as the height of the error bar. 3,0.5,0.5 8,2,5 0.1,0.01,0.01 0.01,0.01,0.02 GPMF ( σ2, λ L , λ U , λ V ) 1,5,1,1 0.5,5,2,5 0.05,1,0.05,0.05 0.1,0.1,0.1,0.1 KPMF (σ 2 , , γU , γV ) 0.1, 10 −6 , 1, 1 0.07, 10 −6 , 100, 100 0.2, 10 −5 , 1.1, 1.1 N/A KBMF (γU , γV , σg, σy) 1,1,0.  <ref type="figure">Figure 4</ref>: Convergence time on MovieLens 100k. We provide an updated graph with 65% of the edges learnt with GPMF to another graph-regularised matrix factorisation method <ref type="bibr">(KPMF Zhou et al. [2012]</ref>, to show that the optimised graph improves the convergence speed and precision of arbitraty algorithms for the graph regularised matrix completion problem.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>but none of them can (yet) scale to large data,<ref type="bibr" target="#b40">Nguyen and Mamitsuka [2012]</ref>, ZhaoMovieUser m 1 m 2 m 3 m 4 m 5 m 6 m 7 An illustrative movie recommendation problem. Left: data matrix where entries are user-ratings for movies: observations in black, unseen entries are blank and unseen entries to be predicted are in grey. Middle: Social Network SI; connected users assumed to have similar ratings. The edge shown in red is contested due to negative correlation of u 4 and u 5 in the data matrix. Right: a graph update with removal of the contested edge to improve prediction accuracy. et al.[2017].This paper introduces GPMF: the generative model in Section 2, the scalable constrained EM algorithm in Section 3, experiments in Section 4 and a conclusion in Section 5.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Synthetic data experiments with respect to the dimension size O(N + M ), constrained SCM computation and thresholding, O(nz(A U ) + nz(A V )) both converge in one time step. Line 4 uses GRALS with the sparsified graphs: O(nz(Ω) + nz(A + U ) + nz(A + V )) per CG iteration. Line 4 is initialised with U , V values from the PMF run, largely reducing the number of iterations required. Our algorithm remains linear with respect to the number of non-zeros. The additional M-step is a trivial additional cost, and if A + U , A + V are much sparser, reducing iteration costs in Line 3, the overall computational load can be less than GRALS using the original graphs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Convergence time; vertical lines show start and end of M-step. c) 40NN graph.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Result summary on real datasets (RMSE), A + is the graph updated with GRAEM (our method). Bold = best result.</figDesc><table><row><cell></cell><cell>Flixster</cell><cell>Douban</cell><cell>MovieLens</cell><cell>Epinions</cell><cell>Yahoo</cell><cell>MovieLens 20M</cell></row><row><cell>Algo.</cell><cell>(3k)</cell><cell>(3k)</cell><cell>100k</cell><cell></cell><cell>Music</cell><cell>(10-/20-/40-NN)</cell></row><row><cell>PMF</cell><cell>0.9809</cell><cell>0.7492</cell><cell>0.9728</cell><cell>0.31</cell><cell>22.991</cell><cell>0.7980 / 0.7980 / 0.7980</cell></row><row><cell>GRALS</cell><cell>0.9152</cell><cell>0.7504</cell><cell>0.9178</cell><cell>0.32</cell><cell>22.760</cell><cell>0.7898 / 0.7925 / 0.7922</cell></row><row><cell>GPMF / GRAEM (ours)</cell><cell>0.8857</cell><cell>0.7497</cell><cell>0.9174</cell><cell>0.28</cell><cell>22.795</cell><cell>0.7894 / 0.7895 / 0.7887</cell></row><row><cell>KPMF</cell><cell>0.9212</cell><cell>0.7324</cell><cell>0.9336</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>KPMF (A + )</cell><cell>0.9212</cell><cell>0.7323</cell><cell>0.9374</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>sRMGCNN</cell><cell>0.9108</cell><cell>0.7915</cell><cell>0.9263</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>Data dims.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Model parameter tuning for real world experiments L , λ U , λ V )</figDesc><table><row><cell></cell><cell>Flixster</cell><cell>Douban</cell><cell>MovieLens</cell><cell>Epinions</cell></row><row><cell></cell><cell>(3k)</cell><cell>(3k)</cell><cell>100k</cell><cell></cell></row><row><cell>D=</cell><cell>10</cell><cell>10</cell><cell>10</cell><cell>10</cell></row><row><cell>PMF (σ U , σ V , CG)</cell><cell>0.1,0.1,1</cell><cell>5,5,1</cell><cell>1.2,1.2,2</cell><cell>0.75,0.2,3</cell></row><row><cell>GRALS (λ</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://grouplens.org/datasets/movielens/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Acknowledgements</head><p>The research was partly funded by the Academy of Finland grant 313748 and Business Finland grant 211548, computational resources provided by the Aalto Science-IT project.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Managing uncertainty in social networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eytan</forename><surname>Adar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Re</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Data Eng. Bull</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="15" to="22" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Binary rating estimation with graph side information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kwangjun</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kangwook</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyunseung</forename><surname>Cha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changho</forename><surname>Suh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4272" to="4283" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Predicting protein complex membership using probabilistic network reliability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurabh</forename><surname>Asthana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>King</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Francis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frederick P</forename><surname>Gibbons</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome research</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1170" to="1175" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rianne</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">N</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.02263</idno>
		<title level="m">Graph convolutional matrix completion</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">M</forename><surname>Bishop</surname></persName>
		</author>
		<title level="m">Pattern Recognition and Machine Learning</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Metagenes and molecular pattern discovery using matrix factorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Philippe</forename><surname>Brunet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pablo</forename><surname>Tamayo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Todd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jill</forename><forename type="middle">P</forename><surname>Golub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mesirov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the national academy of sciences</title>
		<meeting>the national academy of sciences</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="page" from="4164" to="4169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Graph regularized nonnegative matrix factorization for data representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deng</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaofei</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1548" to="1560" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Matrix completion with noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Emmanuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaniv</forename><surname>Candes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Plan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE</title>
		<meeting>the IEEE</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="page" from="925" to="936" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Exact matrix completion via convex optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Emmanuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Candès</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Recht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations of Computational mathematics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">717</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Matrix completion with noisy side information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai-Yang</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cho-Jui</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Inderjit S</forename><surname>Dhillon</surname></persName>
		</author>
		<editor>C. Cortes, N. D</editor>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">D</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sugiyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Garnett</surname></persName>
		</author>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="3447" to="3455" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Using side information to reliably learn low-rank matrices from missing and corrupted observations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai-Yang</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Inderjit</forename><forename type="middle">S</forename><surname>Dhillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cho-Jui</forename><surname>Hsieh</surname></persName>
		</author>
		<ptr target="http://jmlr.org/papers/v19/17-112.html" />
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">76</biblScope>
			<biblScope unit="page" from="1" to="35" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">An overview of low-rank matrix recovery from incomplete observations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Davenport</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Romberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of Selected Topics in Signal Processing</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="608" to="622" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A column approximate minimum degree ordering algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Timothy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">R</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><forename type="middle">I</forename><surname>Gilbert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Esmond G</forename><surname>Larimore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Mathematical Software (TOMS)</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="353" to="376" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Learning laplacian matrix in smooth graph signal representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaowen</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dorina</forename><surname>Thanou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Frossard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">23</biblScope>
			<biblScope unit="page" from="6160" to="6173" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The yahoo! music dataset and kdd-cup&apos;11</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gideon</forename><surname>Dror</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Koenigstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yehuda</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Weimer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 International Conference on KDD Cup</title>
		<meeting>the 2011 International Conference on KDD Cup</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="3" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Graph learning with laplacian constraints: Modeling attractive gaussian markov random fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduardo</forename><surname>Hilmi E Egilmez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Pavez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ortega</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Signals, Systems and Computers, 2016 50th Asilomar Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1470" to="1474" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Graph learning from data under laplacian and structural constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduardo</forename><surname>Hilmi E Egilmez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Pavez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ortega</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of Selected Topics in Signal Processing</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="825" to="841" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Graphical lasso and thresholding: Equivalence and closed-form solutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salar</forename><surname>Fattahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Somayeh</forename><surname>Sojoudi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.09479</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Graphical lasso and thresholding: equivalence and closed-form solutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salar</forename><surname>Fattahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Somayeh</forename><surname>Sojoudi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="364" to="407" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Kernelized bayesian matrix factorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehmet</forename><surname>Gönen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suleiman</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Kaski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="864" to="872" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Grechkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maryam</forename><surname>Fazel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniela</forename><surname>Witten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Su-In</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Twenty-Ninth AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A systemic analysis of link prediction in social network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sogol</forename><surname>Haghani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><forename type="middle">Reza</forename><surname>Keyvanpour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence Review</title>
		<imprint>
			<biblScope unit="page" from="1" to="35" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">The movielens datasets: History and context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxwell</forename><surname>Harper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><forename type="middle">A</forename><surname>Konstan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions on Interactive Intelligent Systems</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Hartford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devon</forename><forename type="middle">R</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Leyton-Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siamak</forename><surname>Ravanbakhsh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.02879</idno>
		<title level="m">Deep models of interactions across sets</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">The Elements of Statistical Learning: Data Mining, Inference, and Prediction, Second Edition. Springer Series in Statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Tibshirani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Friedman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>Springer</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">The future of computational chemogenomics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edgar</forename><surname>Jacoby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational Chemogenomics</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="425" to="450" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">The bigraphical lasso</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alfredo</forename><surname>Kalaitzis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuheng</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1229" to="1237" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Matrix factorization techniques for recommender systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yehuda</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Volinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">L</forename><surname>Lauritzen</surname></persName>
		</author>
		<title level="m">Graphical Models. Oxford science publications</title>
		<imprint>
			<publisher>Clarendon Press</publisher>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Lrbm: A restricted boltzmann machine based approach for representation learning on linked data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suxin</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidong</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2014 IEEE International Conference on Data Mining</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="300" to="309" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Bayesian regularization via graph laplacian</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sounak</forename><surname>Chakraborty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aurelie</forename><forename type="middle">C</forename><surname>Lozano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bayesian Analysis</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="449" to="474" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Graph summarization methods and applications: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yike</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tara</forename><surname>Safavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhilash</forename><surname>Dighe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danai</forename><surname>Koutra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys (CSUR)</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">62</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Recommender systems with social regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dengyong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irwin</forename><surname>Michael R Lyu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>King</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fourth ACM international conference on Web search and data mining</title>
		<meeting>the fourth ACM international conference on Web search and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="287" to="296" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">The graphical lasso: New insights and alternatives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahul</forename><surname>Mazumder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Hastie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Electronic journal of statistics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">2125</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Birds of a feather: Homophily in social networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miller</forename><surname>Mcpherson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lynn</forename><surname>Smith-Lovin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James M</forename><surname>Cook</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annual review of sociology</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="415" to="444" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A review on matrix factorization techniques in recommender systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rachana</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keyur</forename><surname>Rana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 2nd International Conference on Communication Systems, Computing and IT Applications (CSCITA)</title>
		<imprint>
			<biblScope unit="page" from="269" to="274" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">IEEE</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Probabilistic matrix factorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andriy</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ruslan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1257" to="1264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Geometric matrix completion with recurrent multi-graph neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federico</forename><surname>Monti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Bresson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3697" to="3707" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Latent feature kernels for link prediction on sparse graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Canh</forename><surname>Hao Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroshi</forename><surname>Mamitsuka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on neural networks and learning systems</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="1793" to="1804" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Collaborative filtering with graph information: Consistency and scalable methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikhil</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hsiang-Fu</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Pradeep</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Inderjit S</forename><surname>Ravikumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dhillon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2107" to="2115" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Gaussian Markov Random Fields: Theory and Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Rue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Held</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<publisher>CRC Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Optimizing parallel collaborative filtering approaches for improving recommendation systems performance. Information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christos</forename><surname>Sardianos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Grigorios Ballas Papadatos, and Iraklis Varlamis</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">155</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">On the kronecker product</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathrin</forename><surname>Schacke</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
		<respStmt>
			<orgName>University of Waterloo</orgName>
		</respStmt>
	</monogr>
	<note>Master&apos;s thesis</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Yes, there is a correlation:-from social networks to personal behavior on the web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Parag</forename><surname>Singla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Richardson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th international conference on World Wide Web</title>
		<meeting>the 17th international conference on World Wide Web</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="655" to="664" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Equivalence of graphical lasso and thresholding for sparse graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Somayeh</forename><surname>Sojoudi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3943" to="3963" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Graphical lasso and thresholding: Conditions for equivalence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Somayeh</forename><surname>Sojoudi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Decision and Control (CDC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="7042" to="7048" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Enter the matrix: factorization uncovers knowledge from omics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raman</forename><surname>Genevieve L Stein-O&amp;apos;brien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Aedin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">V</forename><surname>Culhane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lana</forename><forename type="middle">X</forename><surname>Favorov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Casey</forename><forename type="middle">S</forename><surname>Garmire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Greene</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifeng</forename><surname>Goff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aloune</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ngom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ochs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in Genetics</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">mtrust: discerning multi-faceted trust in a connected world</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiliang</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huiji</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fifth ACM international conference on Web search and data mining</title>
		<meeting>the fifth ACM international conference on Web search and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="93" to="102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">A block coordinate descent method for regularized multiconvex optimization with applications to nonnegative tensor factorization and completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangyang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wotao</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on imaging sciences</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1758" to="1789" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Depth image inpainting: Improving low rank matrix completion with low gradient regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyang</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deng</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="4311" to="4320" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai-Lang</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wu-Jun</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.00754</idno>
		<title level="m">Convolutional geometric matrix completion</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Real data experiments</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">A three thousand dimensional subset matrix from the original Flixster dataset 6 as in Monti et al</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Flixster</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Where graph side information is constructed from the scores of the original matrix: G U. with 59354 edges and G V 50918 edges</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Where user graph side-information is a social network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Douban</surname></persName>
		</author>
		<ptr target="https://github.com/mehmetgonen/kbmf6https://github.com/fmonti/mgcnn" />
	</analytic>
	<monogr>
		<title level="m">A three thousand dimensional subset matrix from the orignal Douban dataset 7 as in Monti et</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>with 2688 edges. 2 GRALS code. Recurrent Multi-Graph Neural Networks code</note>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">For MovieLens 100k graph sideinformation is constructed for users, based on user demographic information using k-nearest neighbour (kNN) algorithm with ten neighbours. For MoveLens 20M graph side-information is constructed using kNN with k={10</title>
	</analytic>
	<monogr>
		<title level="m">MovieLens 100k and 20M. The GroupLens official MovieLens 8 100k and 20M datasets Harper and Konstan</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">20</biblScope>
		</imprint>
	</monogr>
	<note>40} based on movie genre data with 492956, 962644 and 1870508 edges respectively</note>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">We take the Epinions 9 dataset as described in KPMF, but we use a much larger data size 10 (22164 x 296277) with user trust network data (22164 x 22164</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">;</forename><surname>Epinions</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note>The dataset is extremely sparse (9.8312e-05 proportion of observed entries), and distributed un-uniformly. making this a difficult problem</note>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">YahooMusic The official Yahoo Music ratings data from the KDD cup Dror et al. [2011] as used in Rao et al. [2015] to demonstrate scalability. We construct the graph with exact kNN on the music covariate data (artist,genre,album) with ten neighbours. This results in a very sparse graph</title>
		<imprint/>
	</monogr>
	<note>likely connecting many</note>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">GPMF uses τ = 0 for thresholding. KPMF uses the regularised Laplacian graph kernel with graph strength γ and learning rate . KBMF is trained with uninformative priors: (α λ = 1, β λ = 1), changing these values we saw no improvents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pmf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CG iterations configuration (CG)</title>
		<imprint/>
	</monogr>
	<note>with at most one graph for each kernel multi-kernel</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
