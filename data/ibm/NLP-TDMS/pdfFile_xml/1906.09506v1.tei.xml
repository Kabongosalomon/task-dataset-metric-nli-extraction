<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Explainable Knowledge Graph-based Recommendation via Deep Reinforcement Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiping</forename><surname>Song</surname></persName>
							<email>weiping.song@pku.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhijian</forename><surname>Duan</surname></persName>
							<email>zjduan@pku.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziqing</forename><surname>Yang</surname></persName>
							<email>yangziqing@pku.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Zhu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Tang</surname></persName>
							<email>jian.tang@hec.ca</email>
							<affiliation key="aff1">
								<orgName type="institution">Mila -Quebec AI Institute</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">CIFAR AI Research Chair</orgName>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">HEC Montréal</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Explainable Knowledge Graph-based Recommendation via Deep Reinforcement Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T06:31+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper studies recommender systems with knowledge graphs, which can effectively address the problems of data sparsity and cold start. Recently, a variety of methods have been developed for this problem, which generally try to learn effective representations of users and items and then match items to users according to their representations. Though these methods have been shown quite effective, they lack good explanations, which are critical to recommender systems. In this paper, we take a different path and propose generating recommendations by finding meaningful paths from users to items. Specifically, we formulate the problem as a sequential decision process, where the target user is defined as the initial state, and the walks on the graphs are defined as actions. We shape the rewards according to existing state-of-the-art methods and then train a policy function with policy gradient methods. Experimental results on three real-world datasets show that our proposed method not only provides effective recommendations but also offers good explanations .</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Recommender systems are essential to a variety of online applications such as e-Commerce Websites and social media platforms by providing the right items or information to the users. One critical problem of recommender systems is data sparsity, i.e., some items are purchased, rated, or clicked by only a few users or no users at all. Recently, there is an increasing interest in knowledge graph-based recommender systems, since knowledge graphs can provide complementary information to alleviate the problem of data sparsity and have been proved quite useful <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b31">32]</ref>.</p><p>Generally, existing knowledge graph-based recommendation methods try to learn effective representations of users and items according to the user-item interaction graphs and item-entity knowledge graphs, and then match the items to the users according to learned representations. For example, Zhang et al. <ref type="bibr" target="#b29">[30]</ref> learn item representations by combining their representations in user-item graphs and knowledge-graphs. Zhang et al. <ref type="bibr" target="#b30">[31]</ref> learn user and item representations on the integrated user-item-entity graphs based on knowledge graph embedding (KGE) method like TransE <ref type="bibr" target="#b1">[2]</ref>. Wang et al. <ref type="bibr" target="#b21">[22]</ref> and Cao et al. <ref type="bibr" target="#b2">[3]</ref> jointly optimize the recommendation and knowledge graph embedding tasks in a multi-task learning setting via sharing item representations. These methods have been proved quite effective by integrating information from both user behaviors and knowledge graphs.</p><p>Although these methods are very effective, they lack good explanations. Intuitively, if the recommender system can give an explanation of a recommendation, the users would have more interest and trust in the recommended item <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b32">33]</ref>. Indeed, there is some existing work that aims to User-Item-Entity Graph <ref type="figure">Figure 1</ref>: Explainable recommendation via reasoning over the integrated useritem-entity graph. Our Ekar generates the recommendation (i.e., "Romeo and Juliet") by inferring a preference path "u 2 provide such explanations for the recommendation results. For example, the RippleNet <ref type="bibr" target="#b19">[20]</ref> aims to explain the recommendations by analyzing the attention scores. However, their method relies on the post analysis of the soft attention scores, which may not always be trustworthy.</p><p>In this paper, we take a different route and propose to generate a path from the target user to relevant items in the integrated user-item-entity graph. Take the movie recommendation in <ref type="figure">Figure 1</ref> as an example. For the target user u 2 , a path (the red dashed lines) is generated to the item "Romeo and Juliet" since 1) user u 2 watched movie "Titanic"; 2) "Titanic" is starred by "Leonardo DiCaprio"; and 3) "Leonardo DiCaprio" also stars in "Romeo and Juliet". We can see that such a path offers good explanations of the recommendations in addition to provide meaningful recommendations.</p><p>However, finding meaningful paths on the large user-item-entity graph is challenging. One may enumerate all paths between user-item pairs and then use a classification/ranking model to select the most meaningful paths <ref type="bibr" target="#b23">[24]</ref>. Nevertheless, enumerating paths between users and items is intractable due to the exponentially large path space in the user-item-entity graph. Although sampling a certain number of paths via breadth-first-search can be a practical substitution to enumerating, it has no assurance on the meaningfulness of sampled paths. In this paper, we formulate the generation of meaningful user-to-item paths as a sequential decision process. Specifically, the recommender agent starts from target users and extends its paths to relevant items by sequentially selecting walks on the user-item-entity graph. During training, we assign each path a positive reward if the starting user and terminal entity constitute an observation in recommendation data. Considering that the reward could be extremely sparse at the beginning due to the huge exploration space, we further augment the reward signals by reward shaping <ref type="bibr" target="#b16">[17]</ref>, where a soft reward function is first learned using state-of-the-art knowledge graph embedding methods. We use the REINFORCE <ref type="bibr" target="#b24">[25]</ref> algorithm to maximize the expected rewards of our recommender agent. Finally, we verify the effectiveness and the explainability of the proposed method on three real-world datasets. Quantitative results demonstrate that our proposed Ekar: 1) significantly outperforms existing state-of-the-art KG-based recommendation methods, 2) offers clear and convincing explanations in the form of meaningful paths from users to recommended items.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Our work is conceptually related to the explainable recommendation, knowledge graph-based recommendation, and recent advancements in applying reinforcement learning into relational reasoning.</p><p>Explainable Recommendation. As a widespread concern in the AI community, explainability has been widely discussed in recommender systems. According to Zhang and Chen <ref type="bibr" target="#b31">[32]</ref>, most of the existing explainable recommendation methods typically provide explanations via identifying users' preference on item features <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b32">33]</ref>, understanding latent factors with topic modeling <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b34">35]</ref>, or ranking over the user-item-aspect graph <ref type="bibr" target="#b7">[8]</ref>. However, these methods require external information (e.g., reviews) about items, which may be difficult to collect. Some recent advancements utilize the attention mechanism <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b18">19]</ref> to provide explanations, but they need extra efforts to explore attention scores. Since knowledge graphs (KG) provide common knowledge about our world, many recent works use knowledge graphs <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b29">30]</ref> to provide explainable recommendations, which will be further discussed in the following paragraph.</p><p>KG-based Recommendation. Our work is closely related to KG-based recommendation, which utilizes general knowledge graphs (e.g., DBpedia, YAGO, and Satori) to improve recommender systems. Existing KG-based recommendation methods can be roughly divided into two classes: embedding-based methods and path-based methods. In embedding-based methods, users and items are represented by low-dimensional vectors, where entities' embeddings from the knowledge graph are used to enhance corresponding items' representations <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b29">30]</ref>. Although these methods perform well, it's hard to explain the recommendation results because representations are in a latent space.In path-based methods, meta-paths and meta-graphs are commonly used to extract various semantic dependencies between users and items <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b33">34]</ref>. However, it is almost computationally infeasible to enumerate all the useful meta-paths or meta-graphs. Moreover, the meta-paths and metagraphs need to be manually defined and cannot generalize to new datasets. Instead of pre-defining specific paths, the RippleNet <ref type="bibr" target="#b19">[20]</ref> directly propagates users' preferences along edges in KG via the attention mechanism and then interprets the recommendations according to the attention scores, which however might not be trustworthy.The most recent work KPRN <ref type="bibr" target="#b23">[24]</ref> uses LSTM to model the paths between users and items. However, sampling paths via breadth-first-search (BFS) is inefficient and may miss meaningful paths. Different from KPRN, our method defines the path finding problem as a sequential decision problem. We train an agent to automatically generate a meaningful path between a user and his/her relevant item via policy gradient methods.</p><p>Relational Reasoning with Reinforcement Learning. Our work is also related to recent work on knowledge graph reasoning with reinforcement learning <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b26">27]</ref>, which aims to train an agent to walk on knowledge graphs to predict the missing facts. However, their goal is different from ours. We focus on the problem of recommendation with knowledge graphs and aim at finding meaningful paths for explaining the recommendation results while they focus on facts prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Proposed Method: Ekar</head><p>In this section, we first formally define our problem and then introduce our proposed Explainable knowledge aware recommendation (Ekar) model in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Problem definition</head><p>We formally denote the interactions between users and items as a bipartite graph G = (U, I), where U is the set of users, and I is the set of items. Besides, we also have access to an open knowledge graph G k = (E k , R k ), where E k is the entity set and R k is the relation set. Each triplet &lt; e h , r, e t &gt;∈ G k indicates there exists a relation r ∈ R k from head entity e h ∈ E k to tail entity e t ∈ E k . For example, &lt; Titanic, DirectedBy, JamesCameron &gt; reflects the fact that "Titanic" is directed by "James Cameron". As some items/entities are shared between I and E k , we merge the user-item bipartite graph G and the knowledge graph G k into an integrated user-item-entity graph</p><formula xml:id="formula_0">G = (V , R ), where V = U ∪ I ∪ E k .</formula><p>For the user-item interaction graph G, we assume all the edges belong to the relation "Interact", and therefore R = {"Interact"} ∪ R k .</p><p>Given a user u, our goal is to generate a path from u to a relevant item i on the user-item-entity graph G . Such a path not only allows to find the relevant item but also offers good explanations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Formulating recommendation as a Markov Decision Process</head><p>There are some existing methods <ref type="bibr" target="#b23">[24]</ref> trying to find meaningful paths between users and items. These methods first sample a collection of paths with breadth-first or depth-first search strategy and then measure the meaningfulness of the paths with a classification or ranking model. However, the number of possible paths between a user and an item could be exponentially large, and sampling a few of them could miss the meaningful ones. Moreover, the paths sampled through BFS or DFS strategy may not always be meaningful. In this paper, we take a different route and formulate the problem as a sequential decision making problem on the user-item-entity graph G . We aim to train an agent to walk on G to find relevant items. Starting from a target user u, the agent sequentially selects the next neighbor on the integrated user-item-entity graph G until it reaches the predefined maximum number of steps T . Formally, we define the states, actions, transition, and rewards of the Markov Decision Process as follows:</p><p>States. We represent the state as the sequence of traversed relations and entities so far, i.e., s t = (r 0 , e 0 , r 1 , e 1 , ..., r t , e t ) ∈ S t , where r t ∈ R and e t ∈ V are relations and entities respectively. The initial state s 0 = (r 0 , e 0 ) represents the target user, and r 0 is an artificially introduced relation to be consistent with other (r t , e t ) pairs.</p><p>Actions. When the agent is under state s t , it can choose an outgoing edge of entity e t as its next action. Formally, we define the possible actions under state s t as A t = {a = (r , e )|(e t , r , e ) ∈ G }.</p><p>Transition. For the state transition P(S t+1 = s|S t = s t , A t = a t ), we adopt a deterministic strategy and simply extend the current state s t by adding the new action a t = (r t+1 , e t+1 ) as the next state, i.e., s t+1 = (r 0 , e 0 , ..., r t , e t , r t+1 , e t+1 ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Rewards.</head><p>No intermediate reward is provided for (s t&lt;T , a t&lt;T ). The final reward depends on whether or not the agent correctly finds interacted items of the user u. Given the terminal entity e T , the final reward R T is +1 if user e 0 has interacted with e T , 0 if e T is an item but user e 0 has not interacted with it and −1 if e T is not an item-type entity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Solving recommendation MDP with policy gradient</head><p>We further parameterize the above MDP with deep neural networks and optimize it with policy gradient methods.</p><p>Parameterizing MDP with Deep Neural Networks. Since there are usually millions of entities and hundreds of relations in user-item-entity graph G , it is almost impossible to utilize discrete states and actions directly, the number of which is exponential to the number of symbolic atoms in s t and a t respectively. We, therefore, choose to represent entities and relations in G with lowdimensional embeddings. Each action a = (r, e) is represented as the concatenation of relation and entity embeddings, i.e., a = [r ; e ]. The state s t = (r 0 , e 0 , ..., r t , e t ) is encoded by an LSTM <ref type="bibr" target="#b9">[10]</ref>:</p><formula xml:id="formula_1">s 0 = LSTM(0, [r 0 ; e 0 ]), s t = LSTM(s t−1 , [r t ; e t ]), t &gt; 0<label>(1)</label></formula><p>where 0 is a zero vector and s t is the low-dimensional representation of state s t .</p><p>According to our initial definition of rewards, the agent gets a positive reward if and only if it successfully finds the target item. However, this might be problematic for a few reasons: First, for a large user-item-entity graph G , it is very difficult for the agent to reach the correct items due to the huge search space, especially at the beginning of training <ref type="bibr" target="#b26">[27]</ref>. In other words, the rewards will be very sparse. As a result, the learning process of the agent could be very inefficient and take a long time to converge. Second, the goal of recommender systems is to infer new items that users are likely to interact with in the future, rather than repeating users' historical items. However, receiving positive rewards only from historical items discourages the agent to explore new paths and items, which should be the target of recommender systems. To accelerate the training process and meanwhile encourage the agent to explore items that have not been purchased or rated by the target user, we propose to shape the rewards <ref type="bibr" target="#b16">[17]</ref> in the following way:</p><formula xml:id="formula_2">R T =    1, if e T ∈ I and &lt; e 0 ,r, e T &gt;∈ G , σ(ψ(e 0 , e T )), if e T ∈ I and &lt; e 0 ,r, e T &gt; / ∈ G , −1, otherwise,<label>(2)</label></formula><p>where</p><formula xml:id="formula_3">σ(x) = 1 1+e (−x)</formula><p>is the sigmoid function andr represents the relation "Interact". ψ(e 0 , e T ) is the score function that measures the correlation between user e 0 and the searched item e T . In our study, ψ(e 0 , e T ) is pre-trained by maximizing the likelihood of all triplets in graph G and can be the score function of any state-of-the-art knowledge graph embedding models <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b27">28]</ref>. Different from the original rewards defined in Section 3.2, items that the target user has not interacted with now receive positive rewards, which are determined by the pre-trained knowledge graph embeddings.</p><p>Policy Network. In this paper, we use the policy gradient method to solve the proposed recommendation MDP. Based on parameterized state s t and parameterized action a, we calculate the probability distribution over possible action A t as follows:</p><formula xml:id="formula_4">y t = W 2 ReLU(W 1 s t + b 1 ) + b 2 , π θ (a |s t ) = exp(a y t ) a∈At exp(a y t ) ,<label>(3)</label></formula><p>where {W 1 , W 2 } and {b 1 , b 2 } are weight matrices and weight vectors of a two-layer fully-connected neural network, ReLU(x) = max(0, x) is the non-linear activation function and π θ (a |s t ) is the probability of taken action a under state s t .</p><p>Optimization. During training, the agent starts with an initial state (r 0 , e 0 ), where e 0 is the target user, and sequentially extends its path to a maximum length of T . We then use the reward function (i.e., Eq. 2) to assign the trajectory (s 0 , a 0 , s 1 , a 1 , ..., s T ) a final reward. Formally, we define the expected rewards over all traversed paths of all users as:</p><formula xml:id="formula_5">J(θ) = E e0∈U [E a1,a2,...,a T ∼π θ (at|st) [R T ]].<label>(4)</label></formula><p>which is maximized via gradient ascent, and the gradients of all parameters θ are derived by the REINFORCE <ref type="bibr" target="#b24">[25]</ref> algorithm, i.e.,</p><formula xml:id="formula_6">θ J(θ) ≈ θ t R T log π θ (a t |s t ).<label>(5)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Further Constraints on Actions</head><p>The current action space under state s t (i.e., A t ) is defined as the set of outgoing edges of current entity e t . This could be problematic for two reasons. First, for t &lt; T , if entity e t is already the correct item (i.e., (e 0 , e t ) ∈ G), the agent should stop and not continue to walk to other entities. Second, since the REINFORCE algorithm tends to encourage the agent to repeat historical experiences which receive high rewards <ref type="bibr" target="#b5">[6]</ref>, the algorithm may discourage the agent from exploring new paths and items, which could be relevant to the target user. We address the two problems in the following ways:</p><p>Stop Action. As the length of paths may vary for different user-item pairs, we should provide the agent an option to automatically terminate when it believes that it has found the right items ahead of T . Following Lin et al. <ref type="bibr" target="#b12">[13]</ref>, we add a special link from each node to itself. In this way, we allow the agent to stay at the ground truths, which can be understood as a stop action. We show the impact of using stop action in Section 5.4 by setting different path length T .</p><p>Action Dropout. To prevent the agent from repeating historical high-reward paths and encourage it to explore more possibilities, we propose to use action dropout <ref type="bibr" target="#b12">[13]</ref> during the training. Specifically, instead of sampling an action from original π θ (a t |s t ), we use a mask upon π θ (a t |s t ) to randomly drop some actions. In addition, action dropout can also help alleviate the problem of irrelevant paths between a user and an item since these paths may be found coincidentally at the beginning of training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>In this section, we evaluate Ekar on three real-world datasets. Compared to other state-of-the-art methods, our proposed approach has the following advantages: 1) Effectiveness. Ekar significantly outperforms existing state-of-the-art KG-based recommendation methods in terms of recommendation accuracy. 2) Explainability. Case studies on generated paths demonstrate that Ekar can offer good explanations for recommended items.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Data and Experiment Settings</head><p>Data. We test Ekar on three benchmark datasets for KG-based recommendation: 1) Last.FM. This dataset contains a set of music artist listening information from a popular online music system Last.Fm.</p><p>2) MovieLens-1M. MovieLens-1M provides users' ratings towards thousands of movies. For these two datasets, we convert the explicit ratings into implicit feedback where each observed rating is treated as "1", and unobserved ratings are marked as "0"s. Following <ref type="bibr" target="#b21">[22]</ref>, we use Microsoft Satori to construct knowledge graphs for Last.FM and MovieLens-1M datasets respectively. 3) DBbook2014. This dataset provides users' reading history in the book domain. Its supporting knowledge graph is extracted from DBpedia. As we focus on KG-based recommendation, we remove items that have no matching entities in the corresponding knowledge graph. The statistics of processed datasets are presented in <ref type="table" target="#tab_1">Table 1</ref>. Following <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b23">24]</ref>, we randomly split the interactions of each user into training, validation, and test set with ratio 6:2:2. Baseline Methods. We compare Ekar with two kinds of methods: 1) Classical similarity-based methods including: ItemKNN, which recommends items that are most similar to target user's historical items; BPR-MF <ref type="bibr" target="#b28">[29]</ref>, which is a widely-used matrix factorization method using Bayesian Personalized Ranking (BPR) loss. 2) KG-based recommendation methods including: RippleNet <ref type="bibr" target="#b19">[20]</ref>, which propagates users' interests over knowledge graph with attention mechanism; CFKG <ref type="bibr" target="#b30">[31]</ref>, which learns users' and items' representations by applying TransE [2] on the graph G ; MKR <ref type="bibr" target="#b21">[22]</ref>, which learns both user-item matching task and knowledge graph embedding task under multi-task learning framework; KTUP <ref type="bibr" target="#b2">[3]</ref>, which is a state-of-the-art KG-based recommender that jointly learns translation-based recommendation <ref type="bibr" target="#b6">[7]</ref> and translation-based knowledge graph embedding; ConvE-Rec, which learns users' and items' embeddings based on integrated graph G with ConvE <ref type="bibr" target="#b4">[5]</ref>.</p><p>As we use ConvE model for reward shaping, we treat ConvE-Rec as a special recommender.</p><p>Evaluation Metrics. Following <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b18">19]</ref>, we adopt Hit Ratio (HR) and Normalized Discounted Cumulative Gain (NDCG) to evaluate the effectiveness of proposed Ekar and baseline methods. We use the same definition of HR and NDCG in <ref type="bibr" target="#b7">[8]</ref>, where HR measures whether test items are present in the recommendation list and NDCG assesses the ranking quality of test items respectively. In our study, we always report the averaged HR@K and NDCG@K scores across all users over five runs.</p><p>Implementation Details. First of all, we add &lt; e t , r −1 , e h &gt; into G if a triplet &lt; e h , r, e t &gt; exists to enhance the connectivity of graph, where r −1 is the inverse of relation r. Following <ref type="bibr" target="#b2">[3]</ref>, we only preserve those triplets that are directly connected to items in each supporting knowledge graph. We implement Ekar with Pytorch <ref type="bibr" target="#b17">[18]</ref>. Entity and relation embeddings are pre-trained by applying ConvE 1 on graph G , and the embedding size is set to 32 for all methods except for ItemKNN, which has no latent representations. Meanwhile, we use the score function of ConvE to compute augmented rewards (i.e., Equation 2). From <ref type="figure">Figure 1</ref>, we can see path patterns "User-&gt;Item-&gt;Entity-&gt;item" and "User-&gt;Item-&gt;User-&gt;Item" are more probable to be meaningful, so we empirically set the maximum path length T to 3 as our default setting. We select action dropout rate from {0.1-0.9}, dropout rate for entity/relation embeddings from {0.1-0.9} using grid search. Meanwhile, grid search is also applied to select the optimal dropout rate for other baseline methods. For training, we use Adam <ref type="bibr" target="#b10">[11]</ref> optimizer for all neural models with batch size of 512. During recommendation, we use beam search with beam size 64 to generate paths for target users. For duplicate paths leading to the same item, we keep the one with the highest probability. Finally, we adopt two different ranking strategies to generate final top-K recommendation list: (1) ranks the searched items according to the path probabilities and we denote it as Ekar, 2) ranks the searched items based on "rewards" defined by σ(ψ(e 0 , e T )) in Equation 2 and we denote it as Ekar*.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Analysis of Recommendation Performance</head><p>We report the recommendation accuracy of different methods in <ref type="table" target="#tab_2">Table 2</ref>. We can see that KG-based recommendation methods consistently outperform classical similarity-based methods, which indicates that knowledge graphs indeed help to alleviate the problem of data sparsity in the recommendation. Among KG-based recommendation methods, the RippleNet performs worst, which may be attributed to representing users with multi-hop away entities. KTUP performs strongly because it takes the advantages of both translation-based recommendation and multi-task learning. Note that the only difference between ConvE-Rec and CFKG is the used knowledge graph embedding methods; however, ConvE-Rec achieves much better performance. The reason behind this is that ConvE is a state-ofthe-art knowledge graph embedding method, which outperforms TransE used in CFKG. By using pre-trained ConvE embeddings to augment rewards, our Ekar and Ekar* significantly outperform  existing state-of-the-art KG-based recommendation methods in most cases and perform comparably to ConvE-Rec, which shows that our proposed methods are quite effective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Analysis of Explainability</head><p>After demonstrating the effectiveness of Ekar, we now illustrate its explainability, which is the main contribution of this work to recommender systems. As introduced in previous sections, Ekar provides recommendations by generating meaningful paths from users to items, where paths serve as explanations for recommended items. To give you an intuitive example, we randomly select a real user from MovieLens-1M dataset and search preference paths for her/him with Ekar. As shown in <ref type="figure">Figure 2</ref>, we can easily understand that "Airplane!" is recommended because it shares the same genre (i.e., comedy) with "Edge of Seventeen", which the user watched before. The second recommendation "Raiders of the Lost Ark" can be explained with the well-known rule "Users who like A also like B".</p><p>Beyond explanations for an individual user, we are also interested in global preference path patterns discovered by Ekar. More specifically, we try to figure out what are the typical path patterns w.r.t. different datasets. From <ref type="table">Table 3</ref>, we can see that Ekar heavily relies on the path pattern , which lead to new books that share the same WikiPage or Genre with users' historical books respectively. The reason behind the discrepancy of path patterns on two datasets may be two folds. First, note that the average number of interactions for each user in MovieLens-1M data is about 100 while this number is 12 in DBbook2014 data. Therefore it is easier to find a user sharing similar movie preference in MovieLens-1M data than to find a user with similar reading taste in DBbook2014 data. Second, the size of supporting knowledge graph for DBbook2014 data is much larger than the number of user-item interactions, so our Ekar learns to make more use of external knowledge in this case.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Ablation Study</head><p>In this section, we compare different variants of Ekar to show the influences of some essential components such as KG, reward shaping, action dropout and maximum path length T , which are denoted as Ekar-KG, Ekar-RS, Ekar-AD and Ekar (T=5) respectively in <ref type="table" target="#tab_3">Table 4</ref>. We find the influence of KG is very significant on Last.FM and DBbook2014 datasets. This is because these two datasets are extremely sparse, while the MovieLens-1M data is relatively dense. Removing reward shaping leads to a severe performance drop on all datasets because Ekar without reward shaping assigns zero rewards to all items that a user has not interacted with. In this way, the agent is penalized for exploring potential items that are of interest to users and therefore cannot effectively generate recommendations. Besides reward shaping, we also use action dropout to further encourage the agent to explore diverse paths, and we can see that Ekar-AD performs worse than the full model Ekar. At last, we try a larger maximum path length T to enable the agent to explore longer paths. We find that Ekar (T=5) performs worse than Ekar on all datasets. This is because long paths may introduce more noise and thus be less meaningful. However, thanks to the stop mechanism, the performance drop is not significant. The details about path patterns of Ekar (T=5), which further shows the role of stop action, are included in the appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Convergence Analysis</head><p>We present the running time of Ekar in <ref type="figure" target="#fig_3">Figure 3</ref>. As can be seen, Ekar converges fast on MovieLens-1M dataset with less than ten minutes, while it takes longer to converge on the other two datasets. The reason for different convergence behaviors is that it is easier to walk to correct items on dense datasets (e.g., MovieLens-1M) than on sparse datasets (e.g., DBbook2014). Overall, our Ekar is efficient because we initialize entity/relation embeddings with pre-trained knowledge graph embeddings, and we use reward shaping to augment reward signals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we introduced a novel approach to provide explanations for recommendation with knowledge graphs. Our proposed Ekar generates meaningful paths from users to relevant items by learning a walk policy on the user-item-entity graph. Experimental results show that Ekar outperforms existing KG-based recommendation methods and is quite efficient. Furthermore, we demonstrate the explainability of Ekar via insightful case studies on different datasets. Future work includes incorporating domain knowledge to design proper reward functions for recommendation task and developing a distributed version of Ekar for even larger datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Appendix</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Ekar with Different KGE Methods</head><p>Our proposed Ekar is independent of the knowledge graph embedding methods, which are utilized to pre-train entity/relation embeddings for initialization and reward shaping. Therefore we also test our model with another widely-used knowledge graph embedding method DistMult. The score functions of DistMult and ConvE are presented in <ref type="table">Table 5</ref>. For a fair comparison, we use the same experimental settings and just substitute DistMult for ConvE in our experiments. Following ConvE-Rec, we denote recommendation with DistMult as DistMult-Rec.</p><p>The results of using different knowledge graph embedding methods are presented in <ref type="table" target="#tab_4">Table 6</ref>. First, we can see that ConvE-Rec outperforms DistMult-Rec on all datasets. This is because ConvE has proven more effective than DistMult for knowledge graph embedding, as a result of which our Ekar with ConvE also outperforms Ekar with DistMult. Second, Ekar (DistMult) and Ekar* (DistMult) outperform DistMult-Rec on Last.FM and MovieLens-1M datasets and perform comparably to DistMult-Rec on DBbook2014 dataset, which is consistent with the observations of Ekar (ConvE) and Ekar* (ConvE). <ref type="table">Table 5</ref>: Score functions w.r.t. different KGE methods, where · denotes generalized inner product of three vectors, · denotes a 2D shaping of vectors, * is the convolution operator, ω denotes filters in convolutional layers, g(·) is a non-linear activation function and vec(·) converts a tensor to a vector. e 0 , e T and r are embeddings of user e 0 , entity e T and relation "Interact" respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>Score function ψ(e 0 , e T ) DistMult e 0 , r, e T ConvE g(vec(g([e 0 ; r] * ω))W)e T In the previous experiments, we see that Ekar (T=5) performs a little worse than Ekarbecause long paths may not be meaningful and thus lead to bad recommendations. Now we present the path patterns of Ekar (T=5) on dense dataset MovieLens-1M and sparse dataset Last.FM.</p><p>We have two observations from <ref type="table">Table 7</ref>. First, there are many paths of length five, which means that our agent is recommending items that have high-order similarity to users' historical items. Second, as the Last.FM dataset is very sparse, items with high-order similarity may be less relevant. Therefore our Ekar learns to take stop actions within 11.2% paths.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :Table 3 :</head><label>23</label><figDesc>Recommendations and explanations for user #2685 in MovieLens-1M dataset. "Airplane!" is recommended because it shares the same movie genre (i.e., Comedy) with "Edge of Seventeen", which the target user watched before. Most frequent path patterns during recommendation on MovieLens-1M (top) and DB-book2014 (bottom) datasets. "U", "M", "G", "B" and "WP" represent User, Movie, Genre, Book and WikiPage respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>−−→Movie" on MovieLens-1M data. Additionally, Ekar learns more diverse path patterns such as "UserInteract</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Results of running time with batch size of 512 and maximum path length of 3. The x-axis is the training time in minutes, and the y-axis is the average rewards over training samples.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>7 :</head><label>7</label><figDesc>Most frequent path patterns during recommendation on MovieLens-1M (top) and Last.FM (bottom) datasets. "U", "M", 'C', "G" and "A" represent User, Movie, Country, Genre and Artist respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Statistics of evaluation datasets and corresponding knowledge graphs.</figDesc><table><row><cell>Data</cell><cell></cell><cell cols="2">User-Item Interaction</cell><cell></cell><cell></cell><cell>Knowledge Graph</cell><cell></cell></row><row><cell></cell><cell cols="7"># Users # Items # Events Sparsity # Entities # Relations # Triplets</cell></row><row><cell>Last.FM</cell><cell>1,872</cell><cell>3,846</cell><cell>21,173</cell><cell>99.71%</cell><cell>9,366</cell><cell>60</cell><cell>15,518</cell></row><row><cell>MovieLens-1M</cell><cell>6,040</cell><cell>2,347</cell><cell cols="2">656,462 95.37%</cell><cell>7,008</cell><cell>7</cell><cell>20,782</cell></row><row><cell>DBbook2014</cell><cell>5,576</cell><cell>2,598</cell><cell>65,445</cell><cell>99.55%</cell><cell>10,149</cell><cell>13</cell><cell>135,580</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Recommendation results of different models on three datasets.</figDesc><table><row><cell>Model</cell><cell cols="7">Last.FM HR@10 NDCG@10 HR@10 NDCG@10 HR@10 NDCG@10 MovieLens-1M DBbook2014</cell></row><row><cell>ItemKNN</cell><cell>0.0605</cell><cell></cell><cell>0.0511</cell><cell>0.0738</cell><cell>0.2273</cell><cell>0.0702</cell><cell>0.0665</cell></row><row><cell>BPR-MF</cell><cell>0.1199</cell><cell></cell><cell>0.0916</cell><cell>0.0895</cell><cell>0.1914</cell><cell>0.0829</cell><cell>0.0565</cell></row><row><cell>RippleNet</cell><cell>0.1008</cell><cell></cell><cell>0.0641</cell><cell>0.1269</cell><cell>0.2516</cell><cell>0.0763</cell><cell>0.0571</cell></row><row><cell>CFKG</cell><cell>0.1781</cell><cell></cell><cell>0.1226</cell><cell>0.1393</cell><cell>0.2512</cell><cell>0.1428</cell><cell>0.1036</cell></row><row><cell>MKR</cell><cell>0.1447</cell><cell></cell><cell>0.0850</cell><cell>0.1073</cell><cell>0.2245</cell><cell>0.0863</cell><cell>0.0575</cell></row><row><cell>KTUP</cell><cell>0.1891</cell><cell></cell><cell>0.1566</cell><cell>0.1579</cell><cell>0.3230</cell><cell>0.1761</cell><cell>0.1299</cell></row><row><cell>ConvE-Rec</cell><cell>0.2426</cell><cell></cell><cell>0.1742</cell><cell>0.1993</cell><cell>0.3676</cell><cell>0.1850</cell><cell>0.1357</cell></row><row><cell>Ekar</cell><cell>0.2201</cell><cell></cell><cell>0.1552</cell><cell>0.1889</cell><cell>0.3543</cell><cell>0.1716</cell><cell>0.1266</cell></row><row><cell>Ekar*</cell><cell>0.2483</cell><cell></cell><cell>0.1766</cell><cell>0.1994</cell><cell>0.3699</cell><cell>0.1874</cell><cell>0.1371</cell></row><row><cell cols="3">Gain over KTUP 31.31%</cell><cell>13.41%</cell><cell>26.28%</cell><cell>14.52%</cell><cell>6.41%</cell><cell>5.54%</cell></row><row><cell>HasGenre</cell><cell>Comedy</cell><cell cols="2">IsGenreOf</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Edge of Seventeen</cell><cell></cell><cell></cell><cell>Airplane!</cell><cell></cell><cell></cell><cell></cell></row><row><cell>u.2685</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">InteractedBy</cell><cell>Interact</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>u.4169</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>The Boys of St. Vincent</cell><cell></cell><cell cols="2">Raiders of the Lost Ark</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Performance w.r.t. model variants, where [-] means removing that component from the Ekar.</figDesc><table><row><cell cols="2">Model</cell><cell cols="6">Last.FM HR@10 NDCG@10 HR@10 NDCG@10 HR@10 NDCG@10 MovieLens-1M DBbook2014</cell></row><row><cell cols="2">Ekar</cell><cell>0.2201</cell><cell>0.1552</cell><cell>0.1889</cell><cell>0.3543</cell><cell>0.1716</cell><cell>0.1266</cell></row><row><cell cols="2">Ekar-KG</cell><cell>0.2061</cell><cell>0.1466</cell><cell>0.1869</cell><cell>0.3489</cell><cell>0.0802</cell><cell>0.0525</cell></row><row><cell cols="2">Ekar-RS</cell><cell>0.0614</cell><cell>0.0349</cell><cell>0.0654</cell><cell>0.1132</cell><cell>0.1174</cell><cell>0.0867</cell></row><row><cell cols="2">Ekar-AD</cell><cell>0.1350</cell><cell>0.0827</cell><cell>0.1715</cell><cell>0.3217</cell><cell>0.1449</cell><cell>0.1083</cell></row><row><cell cols="3">Ekar (T=5) 0.2108</cell><cell>0.1505</cell><cell>0.1859</cell><cell>0.3500</cell><cell>0.1524</cell><cell>0.1125</cell></row><row><cell></cell><cell></cell><cell>Last.FM</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.00 0.05 0.10 Average reward</cell><cell>0</cell><cell>10 Time (minutes) 20</cell><cell>30</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 6 :</head><label>6</label><figDesc>Effectiveness comparison of using different knowledge graph methods for entity/relation initialization and reward shaping.</figDesc><table><row><cell>Model</cell><cell cols="6">Last.FM HR@10 NDCG@10 HR@10 NDCG@10 HR@10 NDCG@10 MovieLens-1M DBbook2014</cell></row><row><cell>ConvE-Rec</cell><cell>0.2426</cell><cell>0.1742</cell><cell>0.1993</cell><cell>0.3676</cell><cell>0.1850</cell><cell>0.1357</cell></row><row><cell>DistMult-Rec</cell><cell>0.1730</cell><cell>0.1174</cell><cell>0.1773</cell><cell>0.3341</cell><cell>0.1535</cell><cell>0.1090</cell></row><row><cell>Ekar (ConvE)</cell><cell>0.2201</cell><cell>0.1552</cell><cell>0.1889</cell><cell>0.3543</cell><cell>0.1716</cell><cell>0.1266</cell></row><row><cell>Ekar (DistMult)</cell><cell>0.1999</cell><cell>0.1397</cell><cell>0.1761</cell><cell>0.3352</cell><cell>0.1367</cell><cell>0.0958</cell></row><row><cell>Ekar* (ConvE)</cell><cell>0.2438</cell><cell>0.1766</cell><cell>0.1994</cell><cell>0.3699</cell><cell>0.1874</cell><cell>0.1371</cell></row><row><cell cols="2">Ekar* (DistMult) 0.1887</cell><cell>0.1265</cell><cell>0.1774</cell><cell>0.3343</cell><cell>0.1482</cell><cell>0.1061</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table</head><label></label><figDesc></figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">We also use DistMult<ref type="bibr" target="#b27">[28]</ref> model to initialize entity/relation embeddings and to shape reward. It turns out that ConvE performs better. Please see the appendix for the comparison of using two models in detail.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors would like to thank Meng Qu and Zafarali Ahmed for providing useful feedback on initial versions of the manuscript. We also thank Yue Dong and Zhaocheng Zhu for editing the manuscript. WS and MZ are partially supported by Beijing Municipal Commission of Science and Technology under Grant No. Z181100008918005 as well as the National Natural Science Foundation of China (NSFC Grant Nos.61772039 and 91646202). WS also acknowledges the financial support by Chinese Scholarship Council. JT is supported by the Natural Sciences and Engineering Research Council of Canada, as well as the Canada CIFAR AI Chair Program.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Aspect based recommendations: Recommending items with the most valuable aspects based on user reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantin</forename><surname>Bauman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Tuzhilin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;17</title>
		<meeting>the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;17<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="717" to="725" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Translating embeddings for modeling multi-relational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Garcia-Duran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oksana</forename><surname>Yakhnenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2787" to="2795" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Unifying knowledge graph learning and recommendation: Towards a better understanding of user preferences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixin</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zikun</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The World Wide Web Conference, WWW &apos;19</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="151" to="161" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Go for a walk and arrive at the answer: Reasoning over paths in knowledge bases using reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajarshi</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shehzaad</forename><surname>Dhuliawala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manzil</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Vilnis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishan</forename><surname>Durugkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akshay</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Convolutional 2d knowledge graph embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Dettmers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pasquale</forename><surname>Minervini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pontus</forename><surname>Stenetorp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence</title>
		<meeting>the Thirty-Second AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">From language to programs: Bridging reinforcement learning and maximum marginal likelihood</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kelvin</forename><surname>Guu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Panupong</forename><surname>Pasupat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1051" to="1062" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Translation-based recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruining</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang-Cheng</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh ACM Conference on Recommender Systems, RecSys &apos;17</title>
		<meeting>the Eleventh ACM Conference on Recommender Systems, RecSys &apos;17<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="161" to="169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Trirank: Review-aware explainable recommendation by modeling aspects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min-Yen</forename><surname>Kan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM International on Conference on Information and Knowledge Management, CIKM &apos;15</title>
		<meeting>the 24th ACM International on Conference on Information and Knowledge Management, CIKM &apos;15<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1661" to="1670" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Explaining collaborative filtering recommendations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><forename type="middle">L</forename><surname>Herlocker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><forename type="middle">A</forename><surname>Konstan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Riedl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2000 ACM Conference on Computer Supported Cooperative Work, CSCW &apos;00</title>
		<meeting>the 2000 ACM Conference on Computer Supported Cooperative Work, CSCW &apos;00<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2000" />
			<biblScope unit="page" from="241" to="250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Neural attentive session-based recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengjie</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhumin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaochun</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 ACM on Conference on Information and Knowledge Management, CIKM &apos;17</title>
		<meeting>the 2017 ACM on Conference on Information and Knowledge Management, CIKM &apos;17<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1419" to="1428" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Multi-hop knowledge graph reasoning with reward shaping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Xi Victoria Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3243" to="3253" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Why i like it: Multi-task learning for recommendation and explanation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichao</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruihai</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Smyth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th ACM Conference on Recommender Systems, RecSys &apos;18</title>
		<meeting>the 12th ACM Conference on Recommender Systems, RecSys &apos;18<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Jointly learning explainable rules for recommendation with knowledge graph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weizhi</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Woojeong</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenyang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiqun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoping</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Ren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The World Wide Web Conference, WWW &apos;19</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1210" to="1221" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Hidden factors and hidden topics: Understanding rating dimensions with review text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th ACM Conference on Recommender Systems, RecSys &apos;13</title>
		<meeting>the 7th ACM Conference on Recommender Systems, RecSys &apos;13<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="165" to="172" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Policy invariance under reward transformations: Theory and application to reward shaping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daishi</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stuart</forename><surname>Harada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Russell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="page" from="278" to="287" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Automatic differentiation in pytorch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Session-based social recommendation via dynamic graph attention networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiping</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiping</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining, WSDM &apos;19</title>
		<meeting>the Twelfth ACM International Conference on Web Search and Data Mining, WSDM &apos;19<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="555" to="563" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Ripplenet: Propagating user preferences on the knowledge graph for recommender systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongwei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fuzheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jialin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miao</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjie</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minyi</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th ACM International Conference on Information and Knowledge Management, CIKM &apos;18</title>
		<meeting>the 27th ACM International Conference on Information and Knowledge Management, CIKM &apos;18<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="417" to="426" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Dkn: Deep knowledge-aware network for news recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongwei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fuzheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minyi</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 World Wide Web Conference, WWW &apos;18</title>
		<meeting>the 2018 World Wide Web Conference, WWW &apos;18<address><addrLine>Republic and Canton of Geneva, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1835" to="1844" />
		</imprint>
	</monogr>
	<note>International World Wide Web Conferences Steering Committee</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Multi-task feature learning for knowledge graph enhanced recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongwei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fuzheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miao</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjie</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minyi</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The World Wide Web Conference, WWW &apos;19</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Explainable recommendation via multitask learning in opinionated text data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongning</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiling</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 41st International ACM SIGIR Conference on Research &amp; Development in Information Retrieval, SIGIR &apos;18</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="165" to="174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Explainable reasoning over knowledge graphs for recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dingxian</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Canran</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixin</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-Third AAAI Conference on Artificial Intelligence</title>
		<meeting>the Thirty-Third AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Simple statistical gradient-following algorithms for connectionist reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ronald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="229" to="256" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Flame: A probabilistic model combining aspect based opinion mining and collaborative filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Ester</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth ACM International Conference on Web Search and Data Mining, WSDM &apos;15</title>
		<meeting>the Eighth ACM International Conference on Web Search and Data Mining, WSDM &apos;15<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="199" to="208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Deeppath: A reinforcement learning method for knowledge graph reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thien</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">Yang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="564" to="573" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Embedding entities and relations for learning and inference in knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bishan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Personalized entity recommendation: A heterogeneous information network approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhou</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quanquan</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bradley</forename><surname>Sturt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Urvashi</forename><surname>Khandelwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brandon</forename><surname>Norick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th ACM International Conference on Web Search and Data Mining, WSDM &apos;14</title>
		<meeting>the 7th ACM International Conference on Web Search and Data Mining, WSDM &apos;14<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="283" to="292" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Collaborative knowledge base embedding for recommender systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fuzheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><forename type="middle">Jing</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Defu</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Ying</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22Nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;16</title>
		<meeting>the 22Nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;16<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="353" to="362" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Learning over knowledge-base embeddings for recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongfeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingyao</forename><surname>Ai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengfei</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 41th International ACM SIGIR Conference on Research &amp; Development in Information Retrieval, SIGIR &apos;18</title>
		<meeting>the 41th International ACM SIGIR Conference on Research &amp; Development in Information Retrieval, SIGIR &apos;18<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Explainable recommendation: A survey and new perspectives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongfeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.11192</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Explicit factor models for explainable recommendation based on phrase-level sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongfeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guokun</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiqun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoping</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th International ACM SIGIR Conference on Research &amp; Development in Information Retrieval, SIGIR &apos;14</title>
		<meeting>the 37th International ACM SIGIR Conference on Research &amp; Development in Information Retrieval, SIGIR &apos;14<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="83" to="92" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Meta-graph based recommendation fusion over heterogeneous information networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huan</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quanming</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianda</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqiu</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dik Lun</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;17</title>
		<meeting>the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;17<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="635" to="644" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Sar: A sentiment-aspect-region model for user preference analysis in geo-tagged reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiqi</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gao</forename><surname>Cong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quan</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenny</forename><forename type="middle">Q</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE 31st International Conference on Data Engineering</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="675" to="686" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
