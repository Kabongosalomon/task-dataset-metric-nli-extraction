<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Multivariate LSTM-FCNs for Time Series Classification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fazle</forename><surname>Karim</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Mechanical and Industrial Engineering</orgName>
								<orgName type="institution">University of Illinois at Chicago</orgName>
								<address>
									<addrLine>900 W. Taylor St</addrLine>
									<postCode>60607</postCode>
									<settlement>Chicago</settlement>
									<region>IL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Somshubra</forename><surname>Majumdar</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Computer Science</orgName>
								<orgName type="institution">University of Illinois at Chicago</orgName>
								<address>
									<addrLine>900 W. Taylor St</addrLine>
									<postCode>60607</postCode>
									<settlement>Chicago</settlement>
									<region>IL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Houshang</forename><surname>Darabi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Mechanical and Industrial Engineering</orgName>
								<orgName type="institution">University of Illinois at Chicago</orgName>
								<address>
									<addrLine>900 W. Taylor St</addrLine>
									<postCode>60607</postCode>
									<settlement>Chicago</settlement>
									<region>IL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Harford</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Mechanical and Industrial Engineering</orgName>
								<orgName type="institution">University of Illinois at Chicago</orgName>
								<address>
									<addrLine>900 W. Taylor St</addrLine>
									<postCode>60607</postCode>
									<settlement>Chicago</settlement>
									<region>IL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Multivariate LSTM-FCNs for Time Series Classification</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T18:01+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Convolutional neural network</term>
					<term>long short term memory</term>
					<term>recurrent neural network</term>
					<term>multivariate time series classification</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Over the past decade, multivariate time series classification has received great attention. We propose transforming the existing univariate time series classification models, the Long Short Term Memory Fully Convolutional Network (LSTM-FCN) and Attention LSTM-FCN (ALSTM-FCN), into a multivariate time series classification model by augmenting the fully convolutional block with a squeeze-and-excitation block to further improve accuracy. Our proposed models outperform most state-of-the-art models while requiring minimum preprocessing. The proposed models work efficiently on various complex multivariate time series classification tasks such as activity recognition or action recognition. Furthermore, the proposed models are highly efficient at test time and small enough to deploy on memory constrained systems.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Time series data is used in various fields of studies, ranging from weather readings to psychological signals <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b3">4]</ref>. A time series is a sequence of data points in a time domain, typically in a uniform interval <ref type="bibr" target="#b4">[5]</ref>. There is a significant increase of time series data being collected by sensors <ref type="bibr" target="#b5">[6]</ref>. A time series dataset can be univariate, where a sequence of measurements from the same variable are collected, or multivariate, where a sequence of measurements from multiple variables or sensors are collected <ref type="bibr" target="#b6">[7]</ref>. Over the past decade, multivariate time series classification has received significant interest. Multivariate time series classifications are applied in healthcare <ref type="bibr" target="#b7">[8]</ref>, phoneme classification <ref type="bibr" target="#b8">[9]</ref>, activity recognition, object recognition, and action recognition <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b12">13]</ref>. In this paper, we propose two deep learning models that outperform existing algorithms.</p><p>Several time series classification algorithms have been developed over the years. Distancebased methods along with k-nearest neighbors have proven to be successful in classifying multivariate time series <ref type="bibr" target="#b13">[14]</ref>. Plenty of research indicates Dynamic Time Warping (DTW) as the best distance-based measure to use along k-NN <ref type="bibr" target="#b14">[15]</ref>.</p><p>In addition to distance-based metrics, other algorithms are used. Typically, featurebased classification algorithms rely heavily on the features being extracted from the time series data <ref type="bibr" target="#b15">[16]</ref>. However, feature extraction is arduous because intrinsic features of time series data are challenging to capture. For this reason, distance-based approaches are more successful in classifying multivariate time series data <ref type="bibr" target="#b16">[17]</ref>. Hidden State Conditional Random Field (HCRF) and Hidden Unit Logistic Model (HULM) are two successful feature-based algorithms which have led to state-of-the-art results on various benchmark datasets, ranging from online character recognition to activity recognition <ref type="bibr" target="#b17">[18]</ref>. HCRF is a computationally expensive algorithm that detects latent structures of the input time series data using a chain of k-nominal latent variables. The number of parameters in the model increases linearly with the total number of latent states required <ref type="bibr" target="#b18">[19]</ref>. Further, datasets that require a large number of latent states tend to overfit the data. To overcome this, HULM proposes using H binary stochastic hidden units to model 2 H latent structures of the data with only O(H) parameters. Results indicate HULM outperforming HCRF on most datasets <ref type="bibr" target="#b17">[18]</ref>.</p><p>Traditional models, such as the naive logistic model (NL) and Fisher kernel learning (FKL) <ref type="bibr" target="#b19">[20]</ref>, show strong performance on a wide variety of time series classification problems. The NL logistic model is a linear logistic model that makes a prediction by summing the inner products between the model weights and feature vectors over time, which is followed by a softmax function <ref type="bibr" target="#b17">[18]</ref>. The FKL model is effective on time series classification problems when based on Hidden Markov Models (HMM). Subsequently, the features or representation from the FKL model is used to train a linear SVM to make a final prediction. <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b20">21]</ref> Another common approach for multivariate time series classification is by applying dimensional reduction techniques or by concatenating all dimensions of a multivariate time series into a univariate time series. Symbolic Representation for Multivariate Time Series (SMTS) <ref type="bibr" target="#b21">[22]</ref> applies a random forest on the multivariate time series to partition it into leaf nodes, each represented by a word to form a codebook. Every word is used with another random forest to classify the multivariate time series. Learned Pattern Similarity (LPS) <ref type="bibr" target="#b22">[23]</ref> is a similar model that extracts segments from the multivariate time series. These segments are used to train regression trees to find dependencies between them. Each node is represented by a word. Finally, these words are used with a similarity measure to classify the unknown multivariate time series. Ultra Fast Shapelets (UFS) <ref type="bibr" target="#b23">[24]</ref> obtains random shapelets from the multivariate time series and applies a linear SVM or a Random Forest classifier. Subsequently, UFS was enhanced by computing derivatives as features (dUFS) <ref type="bibr" target="#b23">[24]</ref>. The Auto-Regressive (AR) kernel <ref type="bibr" target="#b24">[25]</ref> applies an AR kernel-based distance measure to classify the multivariate time series. Auto-Regressive forests for multivariate time series modeling (mv-ARF) <ref type="bibr" target="#b25">[26]</ref> uses a tree ensemble, where the trees are trained with different time lags. Most recently, WEASEL+MUSE <ref type="bibr" target="#b26">[27]</ref> builds a multivariate feature vector using a classical bag of patterns approach on each variable with various sliding window sizes to capture discrete features, words, and pairs of words. Subsequently, feature selection is used to remove non-discriminative features using a Chi-squared test. The final classification is obtained using a logistic classifier on the final feature vector.</p><p>Deep learning has also yielded promising results for multivariate time series classification. In 2014, Yi et al. propose using Multi-Channel Deep Convolutional Neural Network (MC-DCNN) for multivariate time series classification. MC-DCNN takes input from each variable to detect latent features. The latent features from each channel are fed into an MLP to perform classification <ref type="bibr" target="#b16">[17]</ref>.</p><p>This paper proposes two deep learning models for multivariate time series classification. These proposed models require minimal preprocessing and are tested on 35 datasets, obtaining strong performances in most of them. Performance is the classification accuracy of a model on a particular dataset. The rest of the paper is ordered as follows. Background works are discussed in Section 2. We present the architecture of the two proposed models in Section 3. In Section 4, we discuss the dataset, evaluate the models on them, present our results and analyze our findings. In Section 5, we draw our conclusion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Background Works</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Recurrent Neural Networks</head><p>Recurrent Neural Networks (RNN) are a form of neural networks that display temporal behavior through the direct connections between individual layers. Pascanu et al. <ref type="bibr" target="#b27">[28]</ref> implement RNN to maintain a hidden vector h that is updated at time step t,</p><formula xml:id="formula_0">h t = tanh(Wh t−1 + Ix t ),<label>(1)</label></formula><p>where the hyperbolic tangent function is represented by tanh, the input vector at time step t is denoted as x t , the recurrent weight matrix is denoted by W and the projection matrix is signified by I. A prediction, y t can be made using a hidden state, h, and a weight matrix, W, y t = softmax(Wh t−1 ).</p><p>The softmax function normalizes the output predictions of the model to be a valid probability distribution and the logistic sigmoid function is declared as σ. RNNs can be stacked to create deeper networks by using the hidden state, h l−1 of a RNN layer l−1 as an input to the hidden state, h l of another RNN layer l,</p><formula xml:id="formula_2">h l t = σ(Wh l t−1 + Ih l−1 t ).<label>(3)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Long Short-Term Memory RNNs</head><p>A major issue with RNNs is that they often have to face the issue of vanishing gradients. Long short-term memory (LSTM) RNNs address this problem by integrating gating functions into their state dynamics <ref type="bibr" target="#b28">[29]</ref>. An LSTM maintains a hidden vector, h, and a memory vector, m, which control state updates and outputs at each time step, respectively.</p><p>The computation at each time step is depicted by Graves et al. <ref type="bibr" target="#b29">[30]</ref> as the following:</p><formula xml:id="formula_3">g u = σ(W u h t−1 + I u x t ) g f = σ(W f h t−1 + I f x t ) g o = σ(W o h t−1 + I o x t ) g c = tanh(W c h t−1 + I c x t ) m t = g f m t−1 + g u g c h t = tanh(g o m t )<label>(4)</label></formula><p>where g u , g f , g o , g c are the activation vectors of the input, forget, output and cell state gates respectively, h t is the hidden state vector of the LSTM unit, the logistic sigmoid function is defined by σ, the elementwise multiplication is represented by . The recurrent weight matrices are depicted using the notation W u , W f , W o , W c and the projection matrices are portrayed by I u , I f , I o , I c .</p><p>LSTMs can learn temporal dependencies. However, long-term dependencies of long sequence are challenging to learn using LSTMs. Bahdanau et al. <ref type="bibr" target="#b30">[31]</ref> proposed using an attention mechanism to learn these long-term dependencies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Attention Mechanism</head><p>An attention mechanism conditions a context vector V on the target sequence y. This method is commonly used in neural translation of texts. Bahdanau et al. <ref type="bibr" target="#b30">[31]</ref> argues the context vector v i depends on a sequence of annotations (b 1 , ..., b Tx ), of length T x which is the maximum length of the input sequence x, where an encoder maps the input sequence. Each annotation, b i , comprises information on the whole input sequence, while focusing on regions surrounding the i-th word of the input sequence. The weighted sum of each annotation, b i , is used to compute the context vector as follows:</p><formula xml:id="formula_4">v i = Tx j=1 α ij b j .<label>(5)</label></formula><p>The weight, α ij , of each annotation is calculated through :</p><formula xml:id="formula_5">α ij = exp(e ij ) Tx k=1 exp(e ik ) ,<label>(6)</label></formula><p>where the energy of alignment, e ij , is given by a(ν i−1 , b j ), which measures how well the input position, j, and the output at position, i, match using the RNN hidden state, ν i−1 , and the j-th annotation, b j , of the input sequence. Bahdanau et al. <ref type="bibr" target="#b30">[31]</ref> uses a feedforward neural network to parameterize the alignment model, a. The feedforward neural network is trained jointly with all other components of the model. In addition, the alignment model calculates a soft alignment that can backpropagate the gradient of the cost function. The gradient of the cost function trains the alignment model and the translation model simultaneously <ref type="bibr" target="#b30">[31]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Squeeze-and-Excitation Block</head><p>Hu et al <ref type="bibr" target="#b31">[32]</ref> propose a squeeze-and-excitation block that acts as a computational unit for any transformation F tr :</p><formula xml:id="formula_6">X → U, X ∈ R W ×H ×C , U ∈ R W ×H×C . The outputs of F tr are represented as U = [u 1 , u 2 , · · · , u C ] where u c = v c * X = C s=1 v s c * x s<label>(7)</label></formula><p>The convolution operation is depicted by *, and the 2D spatial kernel is depicted by v s c . The single channel of v c acts on the corresponding channel of X. Hu et al. <ref type="bibr" target="#b31">[32]</ref> models the channel interdependencies to adjust the filter responses in two steps, squeeze and excitation.</p><p>The squeeze operation exploits the contextual information outside the local receptive field by using a global average pool to generate channel-wise statistics. The transformation output, U, is shrunk through spatial dimensions, W × H, to compute the channel-wise statistics, z ∈ R C . The c-th element of z is calculated by computing F sq (u c ), which is the channel-wise global average over the spatial dimensions W × H, defined as:</p><formula xml:id="formula_7">z c = F sq (u c ) = 1 W × H W i=1 H j=1 u c (i, j)<label>(8)</label></formula><p>For temporal sequence data, the transformation output, U, is shrunk through the temporal dimension T to compute the channel-wise statistics, z ∈ R C . The c-th element of z is then calculated by computing F sq (u c ), which is the channel-wise global average over the temporal dimension T , defined as:</p><formula xml:id="formula_8">z c = F sq (u c ) = 1 T T t=1 u c (t)<label>(9)</label></formula><p>The aggregated information obtained from the squeeze operation is followed by an excite operation, whose objective is to capture the channel-wise dependencies. To achieve this, a simple gating mechanism is applied with a sigmoid activation, as follows:</p><formula xml:id="formula_9">s = F ex (z,W) = σ(g(z,W)) = σ(W 2 δ(W 1 z)),<label>(10)</label></formula><p>where F ex is parameterized as a neural network, σ is the Sigmoid activation function, δ is the ReLU activation function, W 1 ∈ R C r ×C and W 2 ∈ R C r ×C are learnable parameters of F ex and r is the reduction ratio. W 1 and W 2 are used to limit model complexity and aid with generalization. W 1 are the parameters of a dimensionality-reduction layer and W 2 are the parameters of a dimensionality-increasing layer.</p><p>Finally, the output of the block is rescaled as follows:</p><formula xml:id="formula_10">x c = F scale (u c , s c ) = s c · u c ,<label>(11)</label></formula><p>where X = [ x 1 , x 2 , ..., x C ] and F scale (u c , s c ) denotes the channel-wise multiplication between the feature map u c ∈ R T and the scale s c .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Multivariate LSTM Fully Convolutional Network</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Network Architecture</head><p>Long Short Term Memory Fully Convolutional Network (LSTM-FCN) and Attention LSTM-FCN (ALSTM-FCN) have been successful in classifying univariate time series <ref type="bibr" target="#b32">[33]</ref>. However, they have never been applied to on a multivariate time series classification problem. The models we propose, Multivariate LSTM-FCN (MLSTM-FCN) and Multivariate Attention LSTM-FCN (MALSTM-FCN), converts their respective univariate models into multivariate variants. We extend the squeeze-and-excite block to the case of 1D sequence models and augment the fully convolutional blocks of the LSTM-FCN and ALSTM-FCN models to enhance classification accuracy.</p><p>As the datasets now consist of multivariate time series, we can define a time series dataset as a tensor of shape (N, Q, M ), where N is the number of samples in the dataset, Q is the maximum number of time steps amongst all variables and M is the number of variables processed per time step. Therefore a univariate time series dataset is a special case of the above definition, where M is 1. The alteration required to the input of the LSTM-FCN and ALSTM-FCN models is to accept M inputs per time step, rather than a single input per time step. Similar to LSTM-FCN and ALSTM-FCN, the proposed models comprise a fully convolutional block and a LSTM block, as depicted in <ref type="figure" target="#fig_0">Fig. 1</ref>. The fully convolutional block contains three temporal convolutional blocks, used as a feature extractor, which is replicated from the original fully convolutional block by Wang et al <ref type="bibr" target="#b33">[34]</ref>. The convolutional blocks contain a convolutional layer with a number of filters (128, 256, and 128) and a kernel size of 8, 5, and 3 respectively. Each convolutional layer is succeeded by batch normalization, with a momentum of 0.99 and epsilon of 0.001. The batch normalization layer is succeeded by the ReLU activation function. In addition, the first two convolutional blocks conclude with a squeeze-and-excite block, which sets the proposed model apart from LSTM-FCN and ALSTM-FCN. <ref type="figure" target="#fig_1">Fig. 2</ref> summarizes the process of how the squeeze-and-excite block is computed in our architecture. For all squeeze and excitation blocks, we set the reduction ratio r to 16. The final temporal convolutional block is followed by a global average pooling layer.</p><p>The squeeze-and-excite block is an addition to the FCN block which adaptively recalibrates the input feature maps. Due to the reduction ratio r set to 16, the number of parameters required to learn these self-attention maps is reduced such that the overall model size increases by just 3-10 %. This can be computed as below:</p><formula xml:id="formula_11">P = 2 r S s=1 R s · G 2 s</formula><p>where P is the total number of additional parameters, r denotes the reduction ratio, S denotes the number of stages (each stage refers to the collection of blocks operating on feature maps of a common spatial dimension), G s denotes the number of output feature maps for stage s and R s denotes the repeated block number for stage s. Since the FCN blocks are kept consistent for all models, we can directly compute the additional number of parameters as P = 2 16 * (128 2 + 256 2 ) = 10240 for all models. Squeeze and excitation is essential to the enhanced performance on multivariate datasets, as not all feature maps may impact the subsequent layers to the same degree. This adaptive recalibration of the feature maps can be considered as a form of learned self-attention on the output feature maps of prior layers. This adaptive rescaling of the filter maps is of utmost importance to the improved performance of the MLSTM-FCN model compared to LSTM-FCN, as it incorporates learned self-attention to the inter-correlations between multiple variables at each time step, which was inadequate with the LSTM-FCN.</p><p>In addition, the multivariate time series input is passed through a dimension shuffle layer (explained more in Section 3.2), followed by the LSTM block. The LSTM block is identical to the block from the LSTM-FCN or ALSTM-FCN models <ref type="bibr" target="#b32">[33]</ref>, comprising either an LSTM layer or an Attention LSTM layer, which is followed by a dropout layer. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Network Input</head><p>Depending on the dataset, the input to the fully convolutional block and LSTM block vary. The input to the fully convolutional block is a multivariate variate time series with Q time steps having M distinct variables per time step. If there is a time series with M variables and Q time steps, the fully convolutional block will receive the data as such. Variables are defined as the channels of interconnected data streams.</p><p>In addition, the input to the LSTM can vary depending on the application of dimension shuffle. The dimension shuffle transposes the temporal dimension of the input data. If the dimension shuffle operation is not applied to the LSTM path, the LSTM will require Q time steps to process M variables at each time step. However, if the dimension shuffle is applied, the LSTM will require M time steps to process Q variables per time step. In other words, the dimension shuffle improves the efficiency of the model when the number of variables M is less than the number of time steps Q.</p><p>After the dimension shuffle, at each time step t, where 1 ≤ t ≤ M , M being the number of variables, the input provides the LSTM the entire history of that variable (data of that variable over all Q time steps). Thus, the LSTM is given the global temporal information of each variable at once. As a result, the dimension shuffle operation reduces the computation time of training and inference without losing accuracy for time series classification problems. An ablation test is performed to show the performance of a model with the dimension shuffle operation is statistically the same as a model without using it (further discussed in Section 4.4).</p><p>The proposed models take a total of 13 hours to process the MLSTM-FCN and a total of 18 hours to process the MALSTM-FCN on a single GTX 1080 Ti GPU. While the time required to train these models is significant, one can note their inference time is comparable with other standard models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>MLSTM-FCN and MALSTM-FCN have been tested on 35 datasets, in Section 4.2. The optimal number of LSTM cells for each dataset was found via grid search over 3 distinct choices -8, 64 or 128, and all other hyper parameters are kept constant. The FCN block is comprised of 3 blocks of 128-256-128 filters for all models, with kernel sizes of 8, 5, and 3 respectively, comparable with the original models proposed by Wang et al <ref type="bibr" target="#b33">[34]</ref>. Additionally, the first two FCN blocks are succeded by the squeeze-and-excitation block. We consistently chose 16 as the reduction ratio r for all squeeze-and-excitation blocks, as suggested by Hu et al <ref type="bibr" target="#b31">[32]</ref>. During the training phase, we set the total number of training epochs to 250 unless explicitly stated and the dropout rate is set to 80% to mitigate overfitting. Each of the proposed models is trained using a batch size of 128. The convolution kernels are initialized by the Uniform He initialization scheme proposed by He et al <ref type="bibr" target="#b34">[35]</ref>, which samples from the uniform distribution U ∈ − 6 d , 6 d , where d is the number of input units to the weight tensor. For datasets with class imbalance, a class weighing scheme inspired by King et al. is utilized <ref type="bibr" target="#b35">[36]</ref>, weighing the contribution of each class C i (1 ≤ i ≤ C) to the loss by the factor Gw i = N C×N C i , where Gw i is the loss scaling weight for the i -th class, N is the number of samples in the dataset, C is the number of classes and N C i is a the number of samples which belong to class C i .</p><p>We use the Adam optimizer <ref type="bibr" target="#b36">[37]</ref>, with an initial learning rate set to 1e-3 and the final learning rate set to 1e-4 to train all models. In addition, after every 100 epochs, the learning rate is reduced by a factor of 1/ 3 √ 2. The datasets were normalized and preprocessed to have zero mean and unit variance. We append variable length time series with zeros afterwards to obtain a time series dataset with a constant length Q, where Q is the maximum length of the time series. Mean-standard deviation normalization and zero padding are the only preprocessing steps performed for all models. We compute the mean and standard deviation of the training dataset and apply these values to normalize both the train and test datasets. We use the Keras <ref type="bibr" target="#b37">[38]</ref> library with the Tensorflow backend <ref type="bibr" target="#b38">[39]</ref> to train the proposed models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Evaluation Metrics</head><p>In this paper, various models, including the proposed models, are evaluated using accuracy, arithmetic rank, geometric rank, the Wilcoxon signed-rank test, and mean per class error. The arithmetic and geometric rank are the arithmetic and geometric mean of the ranks,</p><formula xml:id="formula_12">Arithmetic Mean K = N K rank K N Geometric Mean K = N K rank K N ,</formula><p>where K is the dataset and N is the number of datasets. The Wilcoxon signed-rank test is a non-parametric statistical test that hypothesizes the median of the rank between the compared models is the same. The alternative hypothesis of the Wilcoxon signed-rank test is that the median of the rank between the compared models is not the same. Finally, the mean per class error is the average error of each class for all the datasets,</p><formula xml:id="formula_13">P CE k = 1 − accuracy number of unique classes M P CE = 1 N P CE K .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Datasets</head><p>A total of 35 datasets are used to test the proposed models. Five of the 35 datasets are benchmark datasets used by Pei et al. <ref type="bibr" target="#b17">[18]</ref>, where the training and testing sets are provided online. In addition, we test the proposed models on 20 benchmark datasets, most recently utilized by Schäfer and Leser <ref type="bibr" target="#b26">[27]</ref>. These 20 datasets are trained on the same training and testing datasets as Schäfer and Leser <ref type="bibr" target="#b26">[27]</ref>. These benchmark datasets are from various fields. Some datasets encompass the domains of medical care, speech recognition and motion recognition. Further details of each dataset are depicted in <ref type="table" target="#tab_0">Table 1</ref>. The max training length in <ref type="table" target="#tab_0">Table 1</ref> is the maximum number of time steps for the entire sequence. The remaining 10 datasets of various classification tasks were obtained from the UCI repository <ref type="bibr" target="#b39">[40]</ref>. "HAR", "EEG2", and the "Occupancy" datasets have predefined training and testing sets. All the remaining datasets are partitioned into training and testing sets with a split ratio of 50:50. Each of the datasets is normalized to have zero mean and unit standard deviation. Furthermore, the datasets are padded with zeros, such that each time series length is equivalent to the maximum length of all variables in the training dataset. The dataset is summarized in <ref type="table" target="#tab_0">Table 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Results</head><p>MLSTM-FCN and MALSTM-FCN is applied on all 35 datasets. We compare our results to the existing reported state-of-the-art models(HULM <ref type="bibr" target="#b17">[18]</ref>, HCRF <ref type="bibr" target="#b18">[19]</ref>, NL <ref type="bibr" target="#b19">[20]</ref>, FKL <ref type="bibr" target="#b19">[20]</ref>, ARKernel <ref type="bibr" target="#b24">[25]</ref>, LPS <ref type="bibr" target="#b22">[23]</ref>, mv-ARF <ref type="bibr" target="#b25">[26]</ref>, SMTS <ref type="bibr" target="#b21">[22]</ref>, WEASEL+MUSE <ref type="bibr" target="#b26">[27]</ref>, and dUFS <ref type="bibr" target="#b23">[24]</ref>) of each dataset. Additionally, we compare our models with LSTM-FCN <ref type="bibr" target="#b32">[33]</ref>, ALSTM-FCN <ref type="bibr" target="#b32">[33]</ref>. Alongside these models, we also obtain baselines for these datasets by testing them on DTW, Random Forest, SVM with a linear kernel, SVM with a 3rd degree polynomial kernel and choose the highest score as the baseline.</p><p>Due to the general variance of deep learning algorithms, reproducing exact results is particularly onerous. For replicability, we ran the experiments 3-5 times on various datasets. All the results are similar, where the maximum variance of the accuracy is 3%. The results presented in <ref type="table" target="#tab_1">Table 2</ref> are obtained when the training loss is a minimum. The weights of the models trained on all of these datasets are provided online. In addition, we provide our training and evaluation scripts that will simplify the replication of similar results. 1 <ref type="table" target="#tab_1">Table 2</ref> compares the performance of various models with MLSTM-FCN and MALSTM-FCN. We define performance as the classification accuracy of a model on a particular dataset. Two datasets, "Activity" and "Action 3d", required a strided temporal convolution (stride 2) prior to the LSTM branch to reduce the amount of memory consumed when using the MALSTM-FCN model, because the models were too large to fit on a single GTX 1080 Ti processor otherwise. Both of the proposed models, MLSTM-FCN and MALSTM-FCN, outperform the state-of-the-art models (SOTA) on 28 and 27 out of the 35 datasets of this experiment respectively. "Activity" is one of the few datasets where the proposed models did not outperform the SOTA model. We postulate that the low performance is due to the large stride of the convolution prior to the LSTM branch, which led to a loss of valuable information.</p><p>MLSTM-FCN and MALSTM-FCN have an average arithmetic rank of 3.29 and 3.17 respectively, and a geometric rank of 2.58 and 2.42 respectively. <ref type="figure" target="#fig_2">Fig. 3</ref> depicts the superiority of the proposed models over the top existing models through a critical difference diagram (that applies a Nemenyi test <ref type="bibr" target="#b48">[49]</ref>) of the average arithmetic ranks.</p><p>We perform a Wilcoxon signed-rank test to compare all models that were tested on all 35 datasets, as shown in <ref type="table" target="#tab_2">Table 3</ref>. A Dunn-Sidak correction <ref type="bibr" target="#b49">[50]</ref> is applied to control the  familywise error rate, resulting in the adjusted significance of 0.0028. We statistically conclude that the proposed models have a performance score higher than the remaining model as the p-values are below 0.28 percent. The Wilcoxon signed-rank test also demonstrates the performance of MLSTM-FCN and MALSTM-FCN to be the same. Both MLSTM-FCN and MALSTM-FCN perform significantly better than LSTM-FCN and ALSTM-FCN. This indicates the squeeze-and-excitation block enhances performance significantly on multivariate time series classification through modeling the inter-dependencies between the variables. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Ablation Tests</head><p>An ablation study is conducted to determine the effect of dimension shuffle on the input to the LSTM block of the proposed models. We compare the MLSTM-FCN with and without dimension shuffle on all 35 datasets, keeping the number of LSTM cells the same as obtained via grid search for the original models. All other parameters are kept constant. MLSTM-FCN without dimension shuffle took approximately 32 hours to process all the datasets on a GTX 1080 Ti GPU. In comparison, MLSTM-FCN with dimension shuffle required 13 hours to process all the datasets. The purpose of this study is to determine the impact of the dimension shuffle operation on classification accuracy. Due to the dimension shuffle operation, the time required for training and evaluation of models is significantly reduced in several cases where the number of variables is less than the number of time steps. A Wilcoxon signed-rank test obtains a p-value of 0.136, indicating that we cannot successfully reject the null-hypothesis of the test. This demonstrates the performance of a model when the dimension shuffle operation is applied is statistically the same as when not applied. MLSTM-FCN with dimension shuffle has an MPCE of 4.21. In contrast, an MLSTM-FCN without dimension shuffle obtained a higher MPCE of 4.86. <ref type="table" target="#tab_3">Table 4</ref> summarizes how dimension shuffle affects MLSTM-FCN. In other words, the dimension shuffle operation reduces the processing time by 59 percent while maintaining the same classification accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion &amp; Future Work</head><p>The two proposed models attain state-of-the-art results in most of the datasets tested, 28 out of 35 datasets. Each of the proposed models requires minimal preprocessing and feature extraction. Furthermore, the addition of the squeeze-and-excitation block improves the performance of LSTM-FCN and ALSTM-FCN significantly. We provide a comparison of our proposed models to other existing state-of-the-art algorithms.</p><p>The proposed models will be beneficial in various multivariate time series classification tasks, such as activity recognition, or action recognition. The proposed models can quickly be deployed in real-time systems and embedded systems because the proposed models are small and efficient. Further research is being done to better understand why the squeeze-andexcitation block does not match the performance of the general LSTM-FCN or ALSTM-FCN models on a couple of datasets. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix A. Variable Definitions</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>The MLSTM-FCN architecture. LSTM cells can be replaced by Attention LSTM cells to construct the MALSTM-FCN architecture.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>The computation of the temporal squeeze-and-excite block.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Critical difference diagram of the arithmetic means of the ranks on all 35 datasets</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Properties of all datasets. The yellow cells are datasets used by Pei et al.<ref type="bibr" target="#b17">[18]</ref>, the purple cells are datasets used by Schäfer and Leser<ref type="bibr" target="#b26">[27]</ref>, and the blue cells are datasets from the UCI repository<ref type="bibr" target="#b39">[40]</ref>.</figDesc><table><row><cell>Dataset</cell><cell>Num. of Classes</cell><cell>Num. of Vari-ables</cell><cell>Max Length Train-ing</cell><cell>Task</cell><cell>Train-Test Split</cell><cell>Source</cell></row><row><cell>OHC</cell><cell>20</cell><cell>30</cell><cell>173</cell><cell>Handwriting Classification</cell><cell>10-fold</cell><cell>[41]</cell></row><row><cell>Arabic Voice</cell><cell>88</cell><cell>39</cell><cell>91</cell><cell>Speaker Recognition</cell><cell>75-25 split</cell><cell>[42]</cell></row><row><cell>Cohn-Kanade AU-coded Expression (CK+)</cell><cell>7</cell><cell>136</cell><cell>71</cell><cell>Facial Expression Classification</cell><cell>10-fold</cell><cell>[43]</cell></row><row><cell>MSR Action</cell><cell>20</cell><cell>570</cell><cell>100</cell><cell>Action Recognition</cell><cell>5 ppl in train; rest in test</cell><cell>[44]</cell></row><row><cell>MSR Activity</cell><cell>16</cell><cell>570</cell><cell>337</cell><cell>Activity Recognition</cell><cell>5 ppl in train; rest in test</cell><cell>[45]</cell></row><row><cell>ArabicDigits</cell><cell>10</cell><cell>13</cell><cell>93</cell><cell>Digit Recognition</cell><cell>75-25 split</cell><cell>[40]</cell></row><row><cell>AUSLAN</cell><cell>95</cell><cell>22</cell><cell>96</cell><cell>Sign Language Recognition</cell><cell>44-56 split</cell><cell>[40]</cell></row><row><cell>CharacterTrajectories</cell><cell>20</cell><cell>3</cell><cell>205</cell><cell>Handwriting Classification</cell><cell>10-90 split</cell><cell>[40]</cell></row><row><cell>CMU MOCAP S16</cell><cell>2</cell><cell>62</cell><cell>534</cell><cell>Action Recognition</cell><cell>50-50 split</cell><cell>[46]</cell></row><row><cell>DigitShape</cell><cell>4</cell><cell>2</cell><cell>97</cell><cell>Action Recognition</cell><cell>60-40 split</cell><cell>[47]</cell></row><row><cell>ECG</cell><cell>2</cell><cell>2</cell><cell>147</cell><cell>ECG Classification</cell><cell>50-50 split</cell><cell>[48]</cell></row><row><cell>JapaneseVowels</cell><cell>9</cell><cell>12</cell><cell>26</cell><cell>Speech Recognition</cell><cell>42-58 split</cell><cell>[40]</cell></row><row><cell>KickvsPunch</cell><cell>2</cell><cell>62</cell><cell>761</cell><cell>Action Recognition</cell><cell>62-38 split</cell><cell>[46]</cell></row><row><cell>LIBRAS</cell><cell>15</cell><cell>2</cell><cell>45</cell><cell>Sign Language Recognition</cell><cell>38-62 split</cell><cell>[40]</cell></row><row><cell>LP1</cell><cell>4</cell><cell>6</cell><cell>15</cell><cell>Robot Failure Recogntion</cell><cell>43-57 split</cell><cell>[40]</cell></row><row><cell>LP2</cell><cell>5</cell><cell>6</cell><cell>15</cell><cell>Robot Failure Recogntion</cell><cell>36-64 split</cell><cell>[40]</cell></row><row><cell>LP3</cell><cell>4</cell><cell>6</cell><cell>15</cell><cell>Robot Failure Recogntion</cell><cell>36-64 split</cell><cell>[40]</cell></row><row><cell>LP4</cell><cell>3</cell><cell>6</cell><cell>15</cell><cell>Robot Failure Recogntion</cell><cell>36-64 split</cell><cell>[40]</cell></row><row><cell>LP5</cell><cell>5</cell><cell>6</cell><cell>15</cell><cell>Robot Failure Recogntion</cell><cell>39-61 split</cell><cell>[40]</cell></row><row><cell>NetFlow</cell><cell>2</cell><cell>4</cell><cell>994</cell><cell>Action Recognition</cell><cell>60-40 split</cell><cell>[47]</cell></row><row><cell>PenDigits</cell><cell>10</cell><cell>2</cell><cell>8</cell><cell>Digit Recognition</cell><cell>2-98 split</cell><cell>[40]</cell></row><row><cell>Shapes</cell><cell>3</cell><cell>2</cell><cell>97</cell><cell>Action Recognition</cell><cell>60-40 split</cell><cell>[47]</cell></row><row><cell>Uwave</cell><cell>8</cell><cell>3</cell><cell>315</cell><cell>Gesture Recognition</cell><cell>20-80 split</cell><cell>[40]</cell></row><row><cell>Wafer</cell><cell>2</cell><cell>6</cell><cell>198</cell><cell>Manufacturing Classification</cell><cell>25-75 split</cell><cell>[48]</cell></row><row><cell>WalkVsRun</cell><cell>2</cell><cell>62</cell><cell>1918</cell><cell>Action Recognition</cell><cell>64-36 split</cell><cell>[46]</cell></row><row><cell>AREM</cell><cell>7</cell><cell>7</cell><cell>480</cell><cell>Activity Recognition</cell><cell>50-50 split</cell><cell>[40]</cell></row><row><cell>HAR</cell><cell>6</cell><cell>9</cell><cell>128</cell><cell>Activity Recognition</cell><cell>71-29 split</cell><cell>[40]</cell></row><row><cell>Daily Sport</cell><cell>19</cell><cell>45</cell><cell>125</cell><cell>Activity Recognition</cell><cell>50-50 split</cell><cell>[40]</cell></row><row><cell>Gesture Phase</cell><cell>5</cell><cell>18</cell><cell>214</cell><cell>Gesture Recognition</cell><cell>50-50 split</cell><cell>[40]</cell></row><row><cell>EEG</cell><cell>2</cell><cell>13</cell><cell>117</cell><cell>EEG Classification</cell><cell>50-50 split</cell><cell>[40]</cell></row><row><cell>EEG2</cell><cell>2</cell><cell>64</cell><cell>256</cell><cell>EEG Classification</cell><cell>20-80 split</cell><cell>[40]</cell></row><row><cell>HT Sensor</cell><cell>3</cell><cell>11</cell><cell>5396</cell><cell>Food Classification</cell><cell>50-50 split</cell><cell>[40]</cell></row><row><cell>Movement AAL</cell><cell>2</cell><cell>4</cell><cell>119</cell><cell>Movement Classification</cell><cell>50-50 split</cell><cell>[40]</cell></row><row><cell>Occupancy</cell><cell>2</cell><cell>5</cell><cell>3758</cell><cell>Occupancy Classification</cell><cell>35-65 split</cell><cell>[40]</cell></row><row><cell>Ozone</cell><cell>2</cell><cell>72</cell><cell>291</cell><cell>Weather Classification</cell><cell>50-50 split</cell><cell>[40]</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Performance comparison of proposed models with the rest on benchmark datasets. Green cells denote model with best performance. Red font indicates models that have a strided convolution prior to the LSTM block.</figDesc><table><row><cell>Datasets</cell><cell>LSTM-FCN</cell><cell>MLSTM-FCN</cell><cell>ALSTM-FCN</cell><cell>MALSTM-FCN</cell><cell>SOTA</cell></row><row><cell>Action 3d</cell><cell>71.72</cell><cell>75.42</cell><cell>72.73</cell><cell>74.74</cell><cell>70.71 [DTW]</cell></row><row><cell>Activity</cell><cell>53.13</cell><cell>61.88</cell><cell>55.63</cell><cell>58.75</cell><cell>66.25 [DTW]</cell></row><row><cell>ArabicDigits</cell><cell>100.00</cell><cell>100.00</cell><cell>99.00</cell><cell>99.00</cell><cell>99.00 [27]</cell></row><row><cell>Arabic-Voice</cell><cell>98.00</cell><cell>98.00</cell><cell>98.55</cell><cell>98.27</cell><cell>94.55 [18]</cell></row><row><cell>AREM</cell><cell>76.92</cell><cell>84.62</cell><cell>76.92</cell><cell>84.62</cell><cell>76.92 [DTW]</cell></row><row><cell>AUSLAN</cell><cell>97.00</cell><cell>97.00</cell><cell>96.00</cell><cell>96.00</cell><cell>98.00 [27]</cell></row><row><cell cols="2">CharacterTrajectories 99.00</cell><cell>100.00</cell><cell>99.00</cell><cell>100.00</cell><cell>99.00 [27]</cell></row><row><cell>CK+</cell><cell>96.07</cell><cell>96.43</cell><cell>97.10</cell><cell>97.50</cell><cell>93.56 [18]</cell></row><row><cell>CMUsubject16</cell><cell>100.00</cell><cell>100.00</cell><cell>100.00</cell><cell>100.00</cell><cell>100.00 [26]</cell></row><row><cell>Daily Sport</cell><cell>99.65</cell><cell>99.65</cell><cell>99.63</cell><cell>99.72</cell><cell>98.42 [DTW]</cell></row><row><cell>DigitShapes</cell><cell>100.00</cell><cell>100.00</cell><cell>100.00</cell><cell>100.00</cell><cell>100.00 [26]</cell></row><row><cell>ECG</cell><cell>85.00</cell><cell>86.00</cell><cell>86.00</cell><cell>86.00</cell><cell>93.00 [27]</cell></row><row><cell>EEG</cell><cell>60.94</cell><cell>65.63</cell><cell>64.06</cell><cell>64.07</cell><cell>62.50 [RF]</cell></row><row><cell>EEG2</cell><cell>90.67</cell><cell>91.00</cell><cell>90.67</cell><cell>91.33</cell><cell>77.50 [RF]</cell></row><row><cell>Gesture Phase</cell><cell>50.51</cell><cell>53.53</cell><cell>52.53</cell><cell>53.05</cell><cell>40.91 [DTW]</cell></row><row><cell>HAR</cell><cell>96.00</cell><cell>96.71</cell><cell>95.49</cell><cell>96.71</cell><cell>81.57 [RF]</cell></row><row><cell>HT Sensor</cell><cell>68.00</cell><cell>78.00</cell><cell>72.00</cell><cell>80.00</cell><cell>72.00 [DTW]</cell></row><row><cell>JapaneseVowels</cell><cell>99.00</cell><cell>100.00</cell><cell>99.00</cell><cell>99.00</cell><cell>98.00 [25]</cell></row><row><cell>KickvsPunch</cell><cell>90.00</cell><cell>100.00</cell><cell>90.00</cell><cell>100.00</cell><cell>100.00 [27]</cell></row><row><cell>Libras</cell><cell>99.00</cell><cell>97.00</cell><cell>98.00</cell><cell>97.00</cell><cell>95.00 [25]</cell></row><row><cell>LP1</cell><cell>74.00</cell><cell>86.00</cell><cell>80.00</cell><cell>82.00</cell><cell>96.00 [27]</cell></row><row><cell>LP2</cell><cell>77.00</cell><cell>83.00</cell><cell>80.00</cell><cell>77.00</cell><cell>76.00 [27]</cell></row><row><cell>LP3</cell><cell>67.00</cell><cell>80.00</cell><cell>80.00</cell><cell>73.00</cell><cell>79.00 [27]</cell></row><row><cell>LP4</cell><cell>91.00</cell><cell>92.00</cell><cell>89.00</cell><cell>93.00</cell><cell>96.00 [27]</cell></row><row><cell>LP5</cell><cell>61.00</cell><cell>66.00</cell><cell>62.00</cell><cell>67.00</cell><cell>71.00 [27]</cell></row><row><cell>Movement AAL</cell><cell>73.25</cell><cell>79.63</cell><cell>70.06</cell><cell>78.34</cell><cell>65.61 [SVM-Poly]</cell></row><row><cell>NetFlow</cell><cell>94.00</cell><cell>95.00</cell><cell>93.00</cell><cell>95.00</cell><cell>98.00 [27]</cell></row><row><cell>Occupancy</cell><cell>71.05</cell><cell>76.31</cell><cell>71.05</cell><cell>72.37</cell><cell>67.11 [DTW]</cell></row><row><cell>OHC</cell><cell>99.96</cell><cell>99.96</cell><cell>99.96</cell><cell>99.96</cell><cell>99.03 [18]</cell></row><row><cell>Ozone</cell><cell>67.63</cell><cell>81.50</cell><cell>79.19</cell><cell>79.78</cell><cell>75.14 [DTW]</cell></row><row><cell>PenDIgits</cell><cell>97.00</cell><cell>97.00</cell><cell>97.00</cell><cell>97.00</cell><cell>95.00 [25]</cell></row><row><cell>Shapes</cell><cell>100.00</cell><cell>100.00</cell><cell>100.00</cell><cell>100.00</cell><cell>100.00 [27]</cell></row><row><cell>UWave</cell><cell>97.00</cell><cell>98.00</cell><cell>97.00</cell><cell>98.00</cell><cell>98.00 [27]</cell></row><row><cell>Wafer</cell><cell>99.00</cell><cell>99.00</cell><cell>99.00</cell><cell>99.00</cell><cell>99.00 [27]</cell></row><row><cell>WalkvsRun</cell><cell>100.00</cell><cell>100.00</cell><cell>100.00</cell><cell>100.00</cell><cell>100.00 [27]</cell></row><row><cell>Arith Mean</cell><cell>4.63</cell><cell>3.29</cell><cell>4.17</cell><cell>3.17</cell><cell>-</cell></row><row><cell>Geo Mean</cell><cell>3.72</cell><cell>2.58</cell><cell>3.21</cell><cell>2.42</cell><cell>-</cell></row><row><cell>Count</cell><cell>22.00</cell><cell>28.00</cell><cell>26.00</cell><cell>27.00</cell><cell>-</cell></row><row><cell>MPCE</cell><cell>5.01</cell><cell>4.21</cell><cell>4.93</cell><cell>4.19</cell><cell>-</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Wilcoxon signed-rank test comparison of Each Model. Red cells denote models where we fail to reject the hypothesis and claim that the models have similar performance.</figDesc><table><row><cell></cell><cell>LSTM-FCN</cell><cell>MLSTM-FCN</cell><cell>ALSTM-FCN</cell><cell>MALSTM-FCN</cell><cell>DTW</cell><cell>SVM Lin.</cell><cell>SVM Poly</cell><cell>RF</cell><cell>NL</cell><cell>FKL</cell><cell>HCRF</cell><cell>HULM</cell><cell>dUFS</cell><cell>SMTS</cell><cell>LPS</cell><cell>mv-ARF</cell><cell>ARKernel</cell></row><row><cell>MLSTM-FCN</cell><cell>2.76E-04</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>ALSTM-FCN</cell><cell>2.41E-01</cell><cell>1.93E-03</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>MALSTM-FCN</cell><cell>4.40E-04</cell><cell>2.48E-01</cell><cell>3.76E-04</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>DTW</cell><cell>8.22E-08</cell><cell>4.72E-09</cell><cell>6.98E-08</cell><cell>3.67E-09</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>SVM Lin.</cell><cell>1.11E-10</cell><cell>1.11E-10</cell><cell>1.31E-10</cell><cell>1.11E-10</cell><cell>1.31E-10</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">SVM Poly 1.54E-10</cell><cell>1.11E-10</cell><cell>1.54E-10</cell><cell>1.11E-10</cell><cell cols="2">2.14E-10 2.81E-10</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>RF</cell><cell>3.68E-10</cell><cell>1.54E-10</cell><cell>4.56E-10</cell><cell>2.26E-10</cell><cell cols="3">1.88E-09 1.17E-10 1.54E-10</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>NL</cell><cell>1.11E-10</cell><cell>1.11E-10</cell><cell>1.11E-10</cell><cell>1.11E-10</cell><cell cols="4">1.24E-10 1.17E-10 1.46E-10 1.82E-10</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>FKL</cell><cell>1.11E-10</cell><cell>1.31E-10</cell><cell>1.24E-10</cell><cell>1.24E-10</cell><cell cols="5">1.63E-10 1.11E-10 1.17E-10 1.17E-10 1.31E-10</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>HCRF</cell><cell>1.11E-10</cell><cell>1.11E-10</cell><cell>1.11E-10</cell><cell>1.11E-10</cell><cell cols="6">1.72E-10 1.11E-10 1.11E-10 1.31E-10 1.31E-10 1.63E-10</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>HULM</cell><cell>1.17E-10</cell><cell>1.38E-10</cell><cell>1.31E-10</cell><cell>1.11E-10</cell><cell cols="7">1.63E-10 1.11E-10 1.11E-10 1.11E-10 1.11E-10 1.46E-10 1.46E-10</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>dUFS</cell><cell>1.06E-09</cell><cell>2.09E-09</cell><cell>2.20E-09</cell><cell>2.09E-09</cell><cell cols="8">1.17E-10 1.11E-10 1.11E-10 1.11E-10 1.11E-10 1.11E-10 1.11E-10 1.11E-10</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>SMTS</cell><cell>5.22E-09</cell><cell>1.05E-08</cell><cell>1.05E-08</cell><cell>7.42E-09</cell><cell cols="9">4.32E-10 1.11E-10 1.11E-10 1.11E-10 1.11E-10 1.11E-10 1.11E-10 1.11E-10 5.35E-10</cell><cell></cell><cell></cell><cell></cell></row><row><cell>LPS</cell><cell>1.41E-08</cell><cell>1.34E-08</cell><cell>1.80E-08</cell><cell>8.19E-09</cell><cell cols="10">4.94E-10 1.11E-10 1.11E-10 1.11E-10 1.11E-10 1.11E-10 1.11E-10 1.11E-10 4.09E-10 1.16E-08</cell><cell></cell><cell></cell></row><row><cell>mv-ARF</cell><cell>1.10E-08</cell><cell>4.27E-09</cell><cell>6.39E-09</cell><cell>2.44E-09</cell><cell cols="11">4.56E-10 1.11E-10 1.11E-10 1.11E-10 1.11E-10 1.11E-10 1.11E-10 1.11E-10 2.88E-10 7.60E-09 7.80E-09</cell><cell></cell></row><row><cell cols="2">ARKernel 4.27E-09</cell><cell>1.61E-09</cell><cell>1.61E-09</cell><cell>1.38E-09</cell><cell cols="12">5.79E-10 1.11E-10 1.11E-10 1.11E-10 1.11E-10 1.11E-10 1.11E-10 1.11E-10 5.64E-10 1.28E-08 1.05E-08 9.05E-09</cell></row><row><cell>WEASEL MUSE</cell><cell>2.84E-09</cell><cell>1.05E-08</cell><cell>6.71E-09</cell><cell>9.51E-09</cell><cell cols="13">1.31E-10 1.11E-10 1.11E-10 1.11E-10 1.11E-10 1.11E-10 1.11E-10 1.11E-10 2.32E-09 2.44E-09 1.79E-09 1.18E-09 5.07E-10</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Comparison of MLSTM-FCN With and Without Dimension Shuffle</figDesc><table><row><cell></cell><cell>MLSTM-FCN With</cell><cell>MLSTM-FCN Without</cell></row><row><cell></cell><cell>Dimension Shuffle</cell><cell>Dimension Shuffle</cell></row><row><cell>MPCE</cell><cell>4.21</cell><cell>4.86</cell></row><row><cell>Time (hrs)</cell><cell>13</cell><cell>32</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table A .</head><label>A</label><figDesc>5: Definition of all variables</figDesc><table><row><cell>Variable</cell><cell>Definition</cell><cell>First Introduced</cell></row><row><cell>ht</cell><cell>Hidden vector at time step t</cell><cell>2.1</cell></row><row><cell>I</cell><cell>Projection matrix</cell><cell>2.1</cell></row><row><cell>l</cell><cell>Layer</cell><cell>2.1</cell></row><row><cell>σ</cell><cell>Sigmoid function</cell><cell>2.1</cell></row><row><cell>t</cell><cell>Time step</cell><cell>2.1</cell></row><row><cell>tanh</cell><cell>Hyperbolic tangent function</cell><cell>2.1</cell></row><row><cell>W</cell><cell>Weight matrix</cell><cell>2.1</cell></row><row><cell>xt</cell><cell>Input vector at time step t</cell><cell>2.1</cell></row><row><cell>yt</cell><cell>Prediction at time step t</cell><cell>2.1</cell></row><row><cell></cell><cell>Elementwise multiplication</cell><cell>2.2</cell></row><row><cell>c</cell><cell>Cell gate</cell><cell>2.2</cell></row><row><cell>f</cell><cell>Forget gate</cell><cell>2.2</cell></row><row><cell>g</cell><cell>Activation function</cell><cell>2.2</cell></row><row><cell>h</cell><cell>Hidden vector</cell><cell>2.2</cell></row><row><cell>m</cell><cell>Memory vector</cell><cell>2.2</cell></row><row><cell>o</cell><cell>Output gate</cell><cell>2.2</cell></row><row><cell>u</cell><cell>Input gate</cell><cell>2.2</cell></row><row><cell>a</cell><cell>Alignment</cell><cell>2.3</cell></row><row><cell>αij</cell><cell>Weight</cell><cell>2.3</cell></row><row><cell>bi</cell><cell>Annotation</cell><cell>2.3</cell></row><row><cell>eij</cell><cell>Energy of element</cell><cell>2.3</cell></row><row><cell>i</cell><cell>Output position</cell><cell>2.3</cell></row><row><cell>j</cell><cell>Input position</cell><cell>2.3</cell></row><row><cell>Tx</cell><cell>Maximum length of input sequence x</cell><cell>2.3</cell></row><row><cell>V</cell><cell>context vector</cell><cell>2.3</cell></row><row><cell>vi</cell><cell>context vector</cell><cell>2.3</cell></row><row><cell>ν</cell><cell>RNN hidden state</cell><cell>2.3</cell></row><row><cell>*</cell><cell>Convolution operation</cell><cell>2.4</cell></row><row><cell>Fsq(uc)</cell><cell>Channel-wise multiplication between the feature map and the scale</cell><cell>2.4</cell></row><row><cell>Ftr</cell><cell>Computational unit for any transformation</cell><cell>2.4</cell></row><row><cell>Fex</cell><cell>Parameterized as a neural network</cell><cell>2.4</cell></row><row><cell>sc)</cell><cell>Channel-wise global average over the temporal dimension T</cell><cell>2.4</cell></row><row><cell>H</cell><cell>Spatial dimension</cell><cell>2.4</cell></row><row><cell>r</cell><cell>Reduction ratio</cell><cell>2.4</cell></row><row><cell>T</cell><cell>Temporal dimension</cell><cell>2.4</cell></row><row><cell>U</cell><cell>Outputs of Ftr</cell><cell>2.4</cell></row><row><cell>v s c</cell><cell>2D spatial kernel on channel c</cell><cell>2.4</cell></row><row><cell>W</cell><cell>Spatial dimension</cell><cell>2.4</cell></row><row><cell>W1</cell><cell>Learnable parameters of Fex</cell><cell>2.4</cell></row><row><cell>W2</cell><cell>Learnable parameters of Fex</cell><cell>2.4</cell></row><row><cell>X</cell><cell>Image of shape HxW xC</cell><cell>2.4</cell></row><row><cell>xc</cell><cell>Output of the block rescaled</cell><cell>2.4</cell></row><row><cell>z</cell><cell>Channel wise statistic</cell><cell>2.4</cell></row><row><cell>zc</cell><cell>cth elment of z</cell><cell>2.4</cell></row><row><cell>δ</cell><cell>ReLU activation function</cell><cell>2.4</cell></row><row><cell>σ</cell><cell>Sigmoid activation function</cell><cell>2.4</cell></row><row><cell>Gs</cell><cell>Number of output feature maps for stage s</cell><cell>3.1</cell></row><row><cell>M</cell><cell>Number of variables processed per time step</cell><cell>3.1</cell></row><row><cell>P</cell><cell>Total number of additional parameters</cell><cell>3.1</cell></row><row><cell>Q</cell><cell>Maximum number of time steps amongst all variables</cell><cell>3.1</cell></row><row><cell>Rs</cell><cell>Repeated block number for stage s</cell><cell>3.1</cell></row><row><cell>S</cell><cell>Number of stages</cell><cell>3.1</cell></row><row><cell>s</cell><cell>Stage</cell><cell>3.1</cell></row><row><cell>Ci</cell><cell>Contribution of each class</cell><cell>4</cell></row><row><cell>d</cell><cell>Number of input units to the weight tensor</cell><cell>4</cell></row><row><cell>Gwi</cell><cell>loss scaling weight for the i-th class</cell><cell>4</cell></row><row><cell>N</cell><cell>number of samples in the dataset</cell><cell>4</cell></row><row><cell>NC i</cell><cell>number of samples that belong to class Ci</cell><cell>4</cell></row><row><cell>U</cell><cell>uniform distribution</cell><cell>4</cell></row><row><cell>K</cell><cell>dataset</cell><cell>4.1</cell></row><row><cell>M P CE</cell><cell>mean per class error</cell><cell>4.1</cell></row><row><cell>N</cell><cell>number of datasets</cell><cell>4.1</cell></row><row><cell>P CEk</cell><cell>per class error for dataset k</cell><cell>4.1</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">The codes and weights of all models are available at https://github.com/houshd/MLSTM-FCN</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Temporal Classification: Extending the Classification Paradigm to Multivariate Time Series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">W</forename><surname>Kadous</surname></persName>
		</author>
		<imprint>
			<pubPlace>New South Wales, Australia</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Efficient classification of long time series by 3-d dynamic time warping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sharabiani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Darabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rezaei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Harford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Karim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man, and Cybernetics: Systems</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Predictive modular neural networks for time series classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kehagias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Petridis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="31" to="49" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Complex rotation quantum dynamic neural networks (crqdnn) using complex quantum neuron (cqn): applications to time series prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="page" from="11" to="26" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">An effective multivariate time series classification approach using echo state network and adaptive differential evolution algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="237" to="249" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Pattern recognition and classification for multivariate time series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Spiegel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gaebler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lommatzsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>De Luca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Albayrak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fifth international workshop on knowledge discovery from sensor data</title>
		<meeting>the fifth international workshop on knowledge discovery from sensor data</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="34" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Stacking for multivariate time series classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">J</forename><surname>Prieto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Alonso-González</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Rodríguez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Analysis and Applications</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="297" to="312" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Bayesian common spatial patterns for multi-subject eeg classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="39" to="50" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Framewise phoneme classification with bidirectional lstm and other neural network architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">5-6</biblScope>
			<biblScope unit="page" from="602" to="610" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Human Activity Recognition and Prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Pattern extraction for time series classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Geurts</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<publisher>Springer</publisher>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="115" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Time-series classification using mixed-state dynamic bayesian networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Pavlovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Frey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1999" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="609" to="615" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Real-time human action classification using a dynamic neural model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="page" from="29" to="43" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Combining discrete svm and fixed cardinality warping distances for multivariate time series classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Orsenigo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Vercellis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="3787" to="3794" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Multivariate time series classification using dynamic time warping template selection for human activity recognition, in: Computational Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Seto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Symposium Series on</title>
		<imprint>
			<biblScope unit="page" from="1399" to="1406" />
			<date type="published" when="2015" />
			<publisher>IEEE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A brief survey on sequence classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Keogh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Sigkdd Explorations Newsletter</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="40" to="48" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Time series classification using multi-channels deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Web-Age Information Management</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="298" to="310" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Multivariate time-series classification using the hidden-unit logistic model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Dibeklioglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Tax</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Quattoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-P</forename><surname>Morency</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<title level="m">Hidden conditional random fields</title>
		<imprint>
			<biblScope unit="page">29</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A discriminative framework for detecting remote protein homologies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Jaakkola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Diekhans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Haussler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of computational biology</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="95" to="114" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Learning discriminative fisher kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Maaten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Machine Learning (ICML-11)</title>
		<meeting>the 28th International Conference on Machine Learning (ICML-11)</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="217" to="224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Learning a symbolic representation for multivariate time series classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G</forename><surname>Baydogan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Runger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Mining and Knowledge Discovery</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="400" to="422" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Time series representation and similarity based on local autopatterns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G</forename><surname>Baydogan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Runger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Mining and Knowledge Discovery</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="476" to="509" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wistuba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Grabocka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Schmidt-Thieme</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1503.05018</idno>
		<title level="m">-fast shapelets for time series classification</title>
		<meeting><address><addrLine>Ultra</addrLine></address></meeting>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cuturi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Doucet</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1101.0673</idno>
		<title level="m">Autoregressive kernels for time series</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Autoregressive forests for multivariate time series modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">S</forename><surname>Tuncel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G</forename><surname>Baydogan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page" from="202" to="215" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Schäfer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Leser</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.11343</idno>
		<title level="m">Multivariate time series classification with weasel+ muse</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6026</idno>
		<title level="m">How to Construct Deep Recurrent Neural Networks</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Long Short-Term Memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<title level="m">Supervised Sequence Labelling with Recurrent Neural Networks</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="volume">385</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.0473</idno>
		<title level="m">Neural Machine Translation by Jointly Learning to Align and Translate</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.01507</idno>
		<title level="m">Squeeze-and-excitation networks</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Lstm fully convolutional networks for time series classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Karim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Majumdar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Darabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>IEEE Access</publisher>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Oates</surname></persName>
		</author>
		<title level="m">Time Series Classification from Scratch with Deep Neural Networks: A Strong Baseline</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1578" to="1585" />
		</imprint>
	</monogr>
	<note>2017 International Joint Conference on</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Delving Deep into Rectifiers: Surpassing Human-Level Performance on Imagenet Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1026" to="1034" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Logistic Regression in Rare Events Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Political analysis</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="137" to="163" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<title level="m">Adam: A Method for Stochastic Optimization</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Chollet</surname></persName>
		</author>
		<ptr target="https://github.com/fchollet/keras" />
	</analytic>
	<monogr>
		<title level="j">Keras</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">TensorFlow: Large-scale machine learning on heterogeneous systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Brevdo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Citro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Harp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kudlur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Levenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mané</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Monga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Olah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Viégas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Warden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wattenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wicke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zheng</surname></persName>
		</author>
		<ptr target="https://www.tensorflow.org/" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>software available from tensorflow.org</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lichman</surname></persName>
		</author>
		<ptr target="http://archive.ics.uci.edu/ml" />
		<title level="m">UCI machine learning repository</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Modelling motion primitives and their timing in biologically executed movements</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Toussaint</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Storkey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1609" to="1616" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Improved tree model for arabic speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Hammami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bedda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Science and Information Technology (ICCSIT), 2010 3rd IEEE International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="521" to="526" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Action unit classification using active appearance models and conditional random fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hendriks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive processing</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="507" to="518" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Action recognition based on a bag of 3d points</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition Workshops (CVPRW)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="9" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Mining actionlet ensemble for action recognition with depth cameras</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1290" to="1297" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Carnegie mellon university -cmu graphics lab -motion capture library</title>
		<ptr target="http://mocap.cs.cmu.edu/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Probabilistic sequence clustering with spectral learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">C</forename><surname>Sübakan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kurt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">T</forename><surname>Cemgil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sankur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Digital Signal Processing</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="1" to="19" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T</forename><surname>Olszewski</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Distribution-free multiple comparisons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Nemenyi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INTERNATIONAL BIO-METRIC SOC 1441 I ST</title>
		<meeting><address><addrLine>NW, SUITE 700, WASHINGTON, DC</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1962" />
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page">263</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Rectangular confidence regions for the means of multivariate normal distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Šidák</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">318</biblScope>
			<biblScope unit="page" from="626" to="633" />
			<date type="published" when="1967" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
