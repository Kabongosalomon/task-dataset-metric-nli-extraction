<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">The Single-Noun Prior for Image Clustering</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niv</forename><surname>Cohen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">The Hebrew University of Jerusalem</orgName>
								<address>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yedid</forename><surname>Hoshen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">The Hebrew University of Jerusalem</orgName>
								<address>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">The Single-Noun Prior for Image Clustering</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T09:35+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Self-supervised clustering methods have achieved increasing accuracy in recent years but do not yet perform as well as supervised classification methods. This contrasts with the situation for feature learning, where selfsupervised features have recently surpassed the performance of supervised features on several important tasks. We hypothesize that the performance gap is due to the difficulty of specifying, without supervision, which features correspond to class differences that are semantic to humans. To reduce the performance gap, we introduce the "singlenoun" prior -which states that semantic clusters tend to correspond to concepts that humans label by a single-noun. By utilizing a pre-trained network that maps images and sentences into a common space, we impose this prior obtaining a constrained optimization task. We show that our formulation is a special case of the facility location problem, and introduce a simple-yet-effective approach for solving this optimization task at scale. We test our approach on several commonly reported image clustering datasets and obtain significant accuracy gains over the best existing approaches.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>One of the core tasks of computer vision is to classify images into semantic classes. When supervision is available, this can be done at very high accuracy. Image clustering aims to solve this task when supervision is unavailable by dividing the images into a number of groups that are balanced in size and semantically consistent. Consistency typically means that images within a given group have lowvariability according to some semantic similarity measure. Recent advances in deep feature learning have significantly improved the performance of image clustering methods, by self-supervised learning of image representations that better align with human semantic similarity measures. Despite this amazing progress, image clustering performance still significantly lags behind supervised classification.</p><p>One major issue with using self-supervised features is that they represent many possible attributes, most of which, are not relevant for the ground-truth clusters. As an illustrative example, we can consider the "bird" and "airplane" classes in CIFAR10 (see <ref type="figure">Fig.1</ref>). While most humans would cluster the images according to object category, clustering by other attributes such as color, background (e.g. "sky" or "land") or object pose (e.g. "top view" or "profile") is apriori perfectly valid. The task description does not specify which of the many attributes should be used for clustering. To address this problem, a line of recent works presented approaches to indirectly "hint" the clustering algorithm which images should be clustered together, by using image augmentation to remove unwanted attributes <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b46">47]</ref>.</p><p>We will discuss such approaches in Sec.2.</p><p>The main idea in this work is based on the observation that the groundtruth attributes of most image clustering tasks are nouns rather than adjectives. For example if we consider CIFAR10, we find that the ground truth clusters are given by class names which are nouns such as "airplane" or "horse" rather than adjectives such as color or viewing angle. This motivates our proposed "single-noun prior" which constrains images within a cluster to be describable by a single-noun of the English language. In order to map between images and language, we rely on a recent pretrained neural network that maps images and sentences into a common latent space. An alternative approach is to use zero-shot classification (as in CLIP <ref type="bibr" target="#b35">[36]</ref>) with an extensive dictionary of English nouns. However, this approach has a different objective, classifying each image into its most suitable finegrained category rather than grouping images into a small number (K) of clusters. In zero-shot classification, single classes fragment into an extremely large set of nouns, as the groundtruth class name is only a coarse description of each image. Instead, we must learn to select K nouns, out of the entire dictionary, to cluster our images.</p><p>Our key technical challenge is therefore to select the K nouns that cluster the images into semantically consistent groups out of a long list of English language nouns (82, 115 nouns) . We show that this task can be formulated as an unconstrained K facility location problem, a commonly studied NP-hard problem in algorithmic theory. Although ad- <ref type="figure">Figure 1</ref>. While ground truth CIFAR10 labels associate classes according to object category, clustering according to color or viewing angle can be equally valid. Our "whitelisting" approach uses nouns as the only attributes that can be used for clustering. vanced methods exist for the solution with approximation guarantees, the most popular methods do not scale to our tasks. Instead, we suggest to solve the optimization task using a more scalable approach, that can be seen as discretized version of K-means</p><p>Using an extensive English dictionary of nouns presents another issue: some uninformative nouns such as "entity" have an embedding similar to a large proportion of images. We propose a unsupervised criterion for selecting a sublist of performant, informative nouns. We extensively evaluate our method against top clustering methods that do not use our single-noun prior and show that it yields significant performance gains.</p><p>Our main contribution are:</p><p>1. Introducing the single-noun prior to address the problem of finding meaningful image clusters.</p><p>2. Mapping image clustering under the single-noun prior to the well-studied facility location problem.</p><p>3. Suggesting a scalable and empirically effective solution for solving the optimization task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.</head><p>Proposing an unsupervised criterion for removing uniformative nuisance nouns from the noun list.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Works</head><p>Self-supervised deep image clustering: Deep features trained using self-supervised criteria are used extensively for image clustering. Early methods learned deep features using an auto-encoder with a reconstruction constraint <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b48">49]</ref>. More recent approaches directly optimize clustering objectives during feature learning. Specifically, a common approach is to cluster images according to their learned features, and use this approximate clustering for further improvement of the features (this can be done iteratively or jointly) <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b13">14]</ref>. An issue that remains is that such approaches are "free" to learn arbitrary sets of features, and therefore might clusters according to attributes not related to the ground truth labels. To overcome this issue, a promising line of approaches use carefully selected augmentations to remove the nuisance attributes and direct learning towards more semantic features <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b46">47]</ref>. These ideas are often combined with contrastive learning <ref type="bibr" target="#b41">[42]</ref>. The work by Van Gansbeke et al. <ref type="bibr" target="#b44">[45]</ref> suggested a two stage approach, where features are first learned using a self-supervised task, and then used as a prior for learning the features for clustering. In practice, we often look for clusters which would be balanced in size, at least approximately. Many works utilize an information theoretic criterion to impose such balancing <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b18">19]</ref>.</p><p>Clustering using pretrained features: Some research has also been done on image clustering using features pretrained on some auxiliary supervised data <ref type="bibr" target="#b11">[12]</ref>. While pretrained features are not always applicable, they are often general enough to boost performance on datasets significantly different than the auxiliary data <ref type="bibr" target="#b22">[23]</ref>. However, using this extra supervision alone does not result in performance increase with respect to to the best self-unsupervised methods. We will also show similar results in this work.</p><p>Color name-based features: Color quantization, divides all colors into a discrete number of color groups. Although simple K-means approaches are common, it has been argued that grouping according to a list of colors that have names in the English language provides superior results to simple clustering only based on the pixel color statistics <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b51">52]</ref>. Color name-based identification was further applied to other tasks, such as image classification, visual tracking and action recognition <ref type="bibr" target="#b42">[43]</ref>. As one example, for the task of person re-identification in surveillance, color names were used as a prior in order to define better similarity metrics, which led to better performance <ref type="bibr" target="#b50">[51]</ref>, and scalability <ref type="bibr" target="#b33">[34]</ref>. Our approach can be seen as extending these ideas from pixel colors to whole images.</p><p>Joint embedding for images and text: Finding the joint embedding of images and text is a long-standing research task <ref type="bibr" target="#b30">[31]</ref>. A key motivation for looking into such joint embedding is reducing the requirement for image annotations, needed for supervised machine learning classifiers. This can instead be done by utilizing freely-available text captions from the web <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b37">38]</ref>. It was also suggested that such learned representations can be used for transfer learning <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b27">28]</ref>. Radford et al. <ref type="bibr" target="#b35">[36]</ref> presented a new method, CLIP, that also maps images and sentences into a common space. CLIP was trained using a contrastive objective and provides encoders for images and text. It was shown that CLIP can be used for very accurate zero-shot classification of standard image datasets, by first mapping all category names to embeddings and then for each image choosing the category name with the embedding nearest to it. Our method relies on the outstanding infrastructure provided by CLIP but tackles image clustering rather than zero-shot classification. The essential difference is that in CLIP the set of image labels is provided whereas in clustering the set of categories is unknown.</p><p>Uncapacitated facility location problem (UFLP): The UFLP problem is a long-studied task in economics, computer science, operations research and discrete optimization. It aims to open a set of facilities, so that they serve all clients at a minimal cost. Since its introduction in the 1960s (e.g. Kuehn <ref type="bibr" target="#b24">[25]</ref>), it attracted many theoretical and heuristic solutions. It has been shown by <ref type="bibr">Guha and Khuller [13]</ref> that the metric UFLP can be solved with a constant approximation guarantee bounded by ρ &gt; 1.463. Different solutions methodologies have been applied to the task including: greedy methods <ref type="bibr" target="#b0">[1]</ref>, linear-programming with rounding <ref type="bibr" target="#b39">[40]</ref> and linear-programming primal-dual methods <ref type="bibr" target="#b17">[18]</ref>. Here, we are concerned with the Uncapcitated K-Facility Location Problem (UKFLP) <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b16">17]</ref>, which limits the number of facilities to K. We formulate our optimization ojective as the UKFLP and use a fast, relaxed variant of the method of Arya et al. <ref type="bibr" target="#b0">[1]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Image Clustering with the Single-Noun Prior</head><p>Our goal is to cluster images in a semantically meaningful way. We are given N I images, which are mapped into feature vectors {v 1 ..v N I }, v i ∈ R d . We further assume a list of N W nouns, such that every noun is mapped into a vector embedding {u 1 ..u N W }, u i ∈ R d . The list of all noun embeddings is denoted as W. The images and nouns are assumed to be embedded in the same feature space, in the sense that for each image, its nearest noun in feature space provides a good description of the content of the image. We aim to divide the images into K clusters {S 1 ..S K }. Each cluster should consist of semantically similar images. We denote the cluster centers by a set of vectors</p><formula xml:id="formula_0">{c 1 ..c K }, c k ∈ R d .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">On the Effectiveness of Features for Clustering</head><p>The above formulation of clustering essentially relies on the availability of some automatic measure for evaluating semantic similarity. This is poorly specified as similarity may be determined by a large number of attributes such as object category, color, shape, texture, pose etc. (See <ref type="figure">Fig.1</ref>). The choice of image features determines what attributes will be used for measuring similarity. Low level features such as raw pixels, color histograms or edge descriptors (e.g. SIFT <ref type="bibr" target="#b26">[27]</ref> or HOG <ref type="bibr" target="#b8">[9]</ref>) are sensitive to low-level attributes such as color or simple measures of object pose. More recently, self-supervised deep image features enabled clustering according to high-level semantic attributes towards the goal of clustering by object category. Despite the more semantic nature of deep features, they still contain information on many attributes beyond the object category (including color, texture, pose etc.). Without further supervision, self-supervised deep features do not perform as well as supervised classification methods at separating groups according to classes. Although augmentation methods are able to remove some attributes from the learned features, hand-crafting augmentations for all nuisance attributes is a daunting (and probably an impossible) task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">The Single-Noun Prior</head><p>Our main proposed idea is to further constrain the clustering task, beyond merely the visual cluster coherence requirement. Instead of using augmentations as a way of specifying the attributes we do not wish to cluster by ("blacklisting") -we provide a list of the possible attributes that may be used for clustering ("whitelisting"). The whitelisting approach is more accurate than the blacklisting approach, as the number of unwanted attributes is potentially infinite and augmentations that remove all those attributes may not be known.</p><p>Our technical approach is called the "single-noun" prior. We first utilize a pre-trained network for mapping images and nouns into a common feature space. We replace the within-image coherence requirement, by the requirement that embeddings of images in a given cluster v ∈ S k will be similar to the embedding of a single-noun of our dictionary w ∈ W describing the cluster. The set of plausible nouns (W) can be chosen given the specification of the whitelisted attributes.</p><p>In the clustering literature, it is typically required to cluster a set of images by their object category attribute. We observe that the set of object category names is a subset of the commonly used nouns in the English language. For example, in CIFAR10, the class names are 10 commonly used English nouns ("airplane", "automobile", "bird", etc.). We therefore take the entire list of nouns in the WordNet dataset (over 82k nouns) <ref type="bibr" target="#b28">[29]</ref> and calculate the embedding for each noun using the pretrained network, obtaining the noun list W (for details see Sec.5.5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Removing Non-Specific Nouns</head><p>While almost all plausible nouns are contained in the list W, some nouns in the list may have a meaning that is too general, which may describe images taken out of more than one groundtruth class, or even be related to all the images in the dataset. Examples for such nouns are: 'entity', 'abstraction', 'thing', 'object', 'whole'. We would like to filter out of our list those nouns that are ambiguous w.r.t. the ground truth classes of each dataset, in order to prevent "false" clusters. To this end, we first score the "generality" of each noun by calculating the average noun embedding:</p><formula xml:id="formula_1">u avg = 1 N W i=1..N W u i (1)</formula><p>We calculate the generality score s for each noun, as the inner product between its embedding u i and the average noun embedding u avg :</p><formula xml:id="formula_2">s(u i ) = u i · u avg<label>(2)</label></formula><p>We find that this score is indeed higher for the less specific nouns described earlier. We remove from the list all nouns that have a "generality score" s higher than some quantile level 0 &lt; q ≤ 1, and define the new sublist W q ⊆ W (|W q | ≈ q · |W|, where |.| denotes the length of a set). We choose the quantile q for each dataset using an unsupervised criterion which considers the balance of the resulting clusters. Our unsupervised criterion will be detailed in Sec.6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Semantically Coherent Clusters</head><p>We consider a cluster S k describable by a single-noun c k if the embeddings of its associated images are near the embedding of the noun c k ∈ W q . We formulate this objective, using the within-cluster sum of squares (WCSS) loss:</p><formula xml:id="formula_3">min {c1..c K },{S1..S K } K j=1 v∈Sj v − c j 2 s.t. c j ∈ W q<label>(3)</label></formula><p>The objective is to find assignments {S 1 ..S k } and nouns {c 1 ..c k } ⊆ W q , so that the sum of square distances for each cluster between the assigned images and the corresponding noun is minimal. Note that this is not the same as K-means, as the cluster centers are constrained within the discrete set of nouns W whereas in K-means they are unconstrained.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Optimization</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">The Uncapacitated Facility Location Problem</head><p>We first formalize our optimization problem, by restating it as an uncapacitated K-facility location problem (UK-FLP). The UKFLP is a long studied discrete optimization task (see Sec. 2). In the UKFLP task we are asked to "open" K "facilities" out of a larger set of sites W q , and assign each "client" to one of the K facilities, such that the sum of distances between the "clients" and their assigned "facilities" is minimal. In our case, the clients are the image embeddings v 1 , v 2 ..v N I , which are assigned to a set of K noun embeddings selected from the complete list W q . We look to optimize an assignment variable x ij ∈ {0, 1} indicating whether the "client" v i is assigned to the "facility", the noun u j . We also use a variable y j ∈ {0, 1} to determine if a facility was opened in site j (if the noun u j is the center of a cluster). The optimal assignment should minimize the sum squared distance between each image and its assigned noun. The squared distance between image v i and noun u j is denoted d ij . We can now restate our loss as:</p><formula xml:id="formula_4">min xij ,yj i∈1..N,j∈1..N W d ij x ij s.t. ∀i ∈ 1..N : j∈1..N W x ij = 1 x ij ≤ y j j∈1..N W y j ≤ K<label>(4)</label></formula><p>Where the bottom two constraints limit the number of nouns to be at most K.</p><p>Solving UKFLP is NP-hard, and the problem of approximation algorithms for UKFLP have been studied extensively both in terms of complexity and approximation ratio guarantees (see Sec.2). Yet, as the distance matrix d ij is very large, we could not run the existing solutions at the scale of most of our datasets (there may be as many as 82k allowed nouns-"sites" and 260k images-"clients"). We therefore suggest a relaxed version of the popular Local Search algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Local Search algorithm</head><p>The Local Search algorithm <ref type="bibr" target="#b0">[1]</ref> is an effective, established method for solving facility location problems. It starts with "forward greedy" initialization: in the first K steps, we open the new facility (choose a new noun as center) that minimizes the loss the most among all unopened sites (unselected nouns). For better results, we instead use Ward's clustering initialization as described in the end of this section. After initialization, we iteratively perform the following procedure: In each step, we look to swap p of our selected nouns by p unselected nouns, such that the loss is decreased. If such nouns are found, the swap is applied. We repeat this step until better swaps cannot be found or the maximal number of iterations is reached. The complexity of this algorithm is O(N I · N W ), making it slow to run even for our smallest dataset. Therefore, we report the results only on the STL10 dataset in Sec. 5.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Local Search Location Relaxation Method</head><p>As our task is very high-dimensional, running Local Search (or similar UKFLP algorithms) becomes too slow to be practical. Therefore, we suggest an alternative, a continuous relaxation approach which is much faster to compute (with complexity O(N I + N W )). In short, our method first finds the optimal (unconstrained) centered, and than map them to the allowed set W q . We iterates the following steps until convergence:</p><p>We first assign each of our images v 1 ..v N to clusters {S 1 ..S K } according to the nearest cluster center ("Voronoi tessellation")</p><formula xml:id="formula_5">S k = {v i | v i − c k 2 ≤ v i − c k 2 , ∀k}<label>(5)</label></formula><p>After assignment, the center locations {c 1 ..c K } are set to be the average feature in each cluster, which minimizes the WCSS (Eq.3) loss without the constraint. Precisely, we recompute each cluster center according to the image assignment S k : c j = 1 |Sj | v∈Sj v. However, this is an infeasible solution as cluster centers will generally not be in W q . We therefore replace each cluster center c j with its nearest neighbour noun in W q . The result of this step is a new set of K nouns that form the cluster centers. Instead of using this new list of nouns as the new cluster centers, we keep K − p nouns from the previous iteration and select p nouns from the current set, such that the combined set of nouns decreases the loss in Eq. 3. This is similar to the swap in the Local Search algorithm, but differently from it, we limit our search space to the new set of K nouns rather than the entire noun list W q . If no loss decreasing swap is found, we terminate.</p><p>Empty and excessively large clusters: In some cases, the discrete nature of the single-noun constraint results in excessively large clusters or one of our K centers being "empty" of samples. In the case of empty clusters, we replace the center location with that of a word which would "attract" more samples. Specifically, we choose that noun that has the most samples as its nearest neighbours (among those not already is use). To address the problem of excessively large clusters, we split the samples in that cluster among the nouns in W q (by distance), and replace the center of the largest cluster with the noun that was chosen by the largest number of images across the entire dataset. Images that only loosely fit the cluster are therefore likely to be reassigned to other clusters.</p><p>Cluster initialization: We initialize the cluster assignments using Ward's clustering on the image embeddings v 1 , v 2 ..v N I . See Sec.5.5 for implementation details and Sec.5.4 for alternatives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head><p>We report the results of our method on the datasets that are most commonly used for evaluating image clustering, comparing our results with both fully unsupervised and pretrained clustering methods. We use the three most common clustering metrics: accuracy (ACC), normalized mutual information (NMI) and adjusted rand index (ARI).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Benchmarks</head><p>In this section, we describe the datasets used in our experimental comparison. The statistics of the datasets are summarized in in Tab.1.</p><p>CIFAR10: The most commonly used dataset for clustering evaluation <ref type="bibr" target="#b23">[24]</ref>. Due to the unsupervised nature of this <ref type="bibr" target="#b0">1</ref> ImageNet dimension may vary between images <ref type="figure">Figure 2</ref>. A qualitative illustration of our results. Left: we present 3 images of the clusters containing the 'Norwegian elkhound' dogs of the ImageNet Dogs datasets. The results of our method are on top, while the pre-trained visual clustering baseline is at the bottom. We can see that the cluster computed by our method is more invariant to different factors of non-semantic variation while the visual-only baseline clusters similar looking dogs together even if they do not belong to the same species. Right: The noun 'Cerberus' (a mythical 3-headed dog) demonstrates a peculiar failure mode of our method w.r.t. to the ImageNet-Dog ground truth classes, as it forms clusters containing multiple dogs regardless of their breed. STL10: Another commonly used dataset for image clustering evaluation <ref type="bibr" target="#b6">[7]</ref>. Similarly to CIFAR10, we combine the train and test sets. We only use the test set images for which groundtruth labels exist (a total of 13, 000 images).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CIFAR20-100:</head><p>We use the coarse-grained 20-class version of CIFAR100 <ref type="bibr" target="#b23">[24]</ref>. we use the combination of the train and test sets for both training and evaluation (a total of 60, 000 images).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ImageNet dataset:</head><p>We follow the top performing methods <ref type="bibr" target="#b44">[45]</ref>  <ref type="bibr" target="#b41">[42]</ref>, and compare on subsets of the ImageNet-Dog and ImageNet-50/100/200 derived dataset 2 . </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Baseline Methods</head><p>Here, we summarize several top performing, relevant baselines methods. A more general overview of the recently published related works is presented in Sec.2, and a specific reference for each compared method can be found in Tab.2.</p><p>SCAN <ref type="bibr" target="#b44">[45]</ref>: This method presented a two stage approach, which first learns a representation of the data using a self-supervised task, and later uses that representation as a prior to optimize the features for clustering. The selfsupervised feature learning method (namely, SimCLR <ref type="bibr" target="#b4">[5]</ref> or MoCo <ref type="bibr" target="#b5">[6]</ref>) is used to retrieve the nearest neighbours of each image using high level features. The features are then optimized to satisfy: i) similarity within nearest neighbours ii) entropy (uniform distribution among clusters).</p><p>MICE <ref type="bibr" target="#b41">[42]</ref>: This method combines a mixture of contrastive experts. A gating function is used to weight the experts based on the the input image. As the gating function serves as a soft partitioning of the dataset, each expert is trained to solve a subtask conditional on the gating function assignment.</p><p>Pretrained: We present a naive baseline, based on purely visual clustering of our image features. The cluster assignment resulting from this naive method is also used as the initialization of our algorithm (see Sec. 4.3). This baseline performs better then previously published pretrained baselines (Guerinat al. <ref type="bibr" target="#b11">[12]</ref> achieves at most 60.8% on CI-FAR10), this is mainly due to the better feature extractor. It serves as a good comparison point for our method, exploring the utility of our single-noun prior.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Clustering Results</head><p>We present our clustering results on the described benchmarks in Tab.2. We compare our results to a large number of previous methods using the numbers reported in the cited paper, when available, and otherwise leave a blank entry. We also present in a comparison against SCAN <ref type="bibr" target="#b44">[45]</ref> and its features on the three random subsets of the ImageNet dataset in Tab.3. We can see that our method achieves the highest results on all compared benchmarks.</p><p>Noun-based priors: Our single-noun prior improves results significantly for all datasets except CIFAR20-100. The pretrained features do not by themselves achieve better clustering accuracy than the self supervised method on most benchmarks, demonstrating that our prior is critical. We can see in Tab.5 that the class names of CIFAR10, and the nouns that our method chose as the centers of the corresponding clusters, are closely related. While the class names used by the creators of the datasets are only rarely recovered exactly, for most classes the cluster centers are a typical subcategory of the original class ("jowett" for car", "bulbul" for "bird", "egyptian cat" for cat", etc.). A second type of center, is a noun describing a component or an activity strongly associated with the "true" class ("ramjet" for "airplane" or "chukker" for "horse"). Yet, as can be seen Tab.4, the centers we found are often on par with the groundtruth class names in terms of the optimization loss (Eq. 3), and in some cases also in terms of accuracy. Non-semantic clusters: For CIFAR20-100, our singlenoun prior, not only does not help, but actually impairs the results of the pretrained features. A deeper inspection into the 20 aggregated classes of the CIFAR20-100 dataset, finds that the aggregate classes contain mixtures of classes that are not strongly semantically related. For example, compare "vehicles 1" aggregate class ("bicycle, bus, motorcycle, pickup truck, train") to "vehicles 2" aggregate class ("lawn-mower, rocket, streetcar, tank, tractor"). It is not reasonable to assume that "rocket" should be clustered semantically, or visually, with "lawn-mower" rather than with "train". The single-noun prior therefore does not make sense in such an artificial setting. On the other hand,for the full CIFAR100 labels (100 classes), which is not commonly used for benchmarking clustering, our single-noun prior does improve the pretrained results from an accuracy of 37.7% to an accuracy of 41.8%. Comparison of the underlying features: Our setting assumes the availability of two components not assumed by previous methods: pretrained visual features and a common feature space for text and images. Our pretrained base-line, which utilizes the pretrained visual features alone, only outperforms other methods on CIFAR20-100 and STL10 datasets, while it underperforms on CIFAR10, ImageNet-Dog and the three other ImageNet derived datasets. We conclude that while pretrained features, when available, are a strong naive baseline, they are insufficient to convincingly outperform the top unsupervised methods (e.g. SCAN, MICE). To evaluate the strength of the CLIP pretrained features used in our method, we compare the CLIP encoder to an ImageNet pretrained wideResnet50x2 <ref type="bibr" target="#b52">[53]</ref> and find the the CLIP features compare favourably (Tab.7).</p><p>To further understand the importance of our pretrained image features, we compare their performance against the MoCo features of SCAN <ref type="bibr" target="#b44">[45]</ref> (one of the top performing method) on the ImageNet 50, 100, and 200 benchmarks. We evaluate clustering using our pretrained visual features both with K-means and Ward's clustering. The results are reported in Tab.3. We see again that the pretrained visual features of CLIP used in our method by themselves yield inferior results to the top unsupervised methods. Instead, our strong performance is due to the new single-noun prior.</p><p>Self labeling: SCAN <ref type="bibr" target="#b44">[45]</ref> suggested adding an extra self-labelling step to further boost results. Our method without self-labeling outperforms SCAN with self-labeling on most datasets. The exception is CIFAR10 where SCAN with self-labeling achieves 87.6% which is higher than our results without self-labeling. We therefore run our method on CIFAR10 with an extra self-labeling step using Fix-Match <ref type="bibr" target="#b40">[41]</ref>, and achieve an accuracy of 92.8%. This suggest that self-labeling boosts performance independently of the base clustering method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Ablation studies</head><p>Facility location optimization methods: As explained in Sec.4.3, our optimization method can be viewed as a relaxed version of the Local Search algorithm. We initially ignore the discrete constraint, optimize the centers locations, and then apply a "rounding" process. For STL10 -our smallest datasets, we were able to run the original Local Search algorithm with a single swap in each step (also known as the Portioning around Medoids algorithm or PAM). As can be seen in Tab.6, PAM reaches compara-ble losses to our method, both methods achieve loss values that are lower than the loss with the groundtruth nouns as center (L gt = 1.48). These metrics suggest that both methods can effectively optimize the objective, and differences in results are due to the stochastic nature of the methods and the fact the objective does not perfectly specify the full image classification task. Yet, the time complexity of PAM is significantly greater than that of our relaxed version.</p><p>It was theoretically shown that the approximation bound on the loss acieved by PAM improves as the number of swaps per-iterations p is increased. On the other hand, the runtime complexity is exponential in p. We explored the performance of our method with all possible numbers of swap. Different choices of the number of swaps p achieved very similar accuracy, suggesting the minima we find typically are unaffected by it. Design choices: In Tab.7 we compare different initialization options of our method. Ward's agglomerative clustering initialization is better than K-means clustering, probably as K-means tends to "get stuck" in local minima. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.">Implementation details</head><p>Optimization: We run our algorithm with p = #classes 2 swaps per iteration. For every experiment we run our algorithm for 30 iterations which was checked to be enough for convergence for all datasets. We note that in our variation of relaxed Local Search, we randomly replace p of our centers with the new ones, and execute the replacement if the loss with the new centers is lower. Dictionary: For each dataset we try different quantile levels q of "generality" filtering. We use 20 q values between 0.05, and 1 in 0.05 intervals and choose between them using our unsupervised criterion as we will show in Sec.6.</p><p>Features: We used the CLIP <ref type="bibr" target="#b35">[36]</ref> pretrained model for our pretrained visual and text features. For the visual features we choose the ViT-B-32 network. For the text features we use the suggested transformer, applied with a "This is a photo of a ***" prompt, where *** is a single-noun from our dictionary.</p><p>Feature normalization: Following CLIP <ref type="bibr" target="#b35">[36]</ref>, we L 2 normalize our image and text features at initialization, and at each step of our algorithm. Working with normalized features implies that the Euclidean distance used throughout our algorithm is equivalent to the cosine similarity metric.</p><p>Metrics: For the NMI and accuracy score we used the code 3 provided by Shiran et. al. <ref type="bibr" target="#b38">[39]</ref>. For the ARI score, we use the adjusted rand score function from scikit-learn library <ref type="bibr" target="#b32">[33]</ref>.</p><p>Nearest neighbours retrieval: For nearest neighbours retrieval and plain K-means clustering we use faiss library <ref type="bibr" target="#b19">[20]</ref>.</p><p>Clustering initialization: For Ward's agglomerative clustering we use scikit-learn library <ref type="bibr" target="#b32">[33]</ref>.</p><p>Self-labelling: We use the FixMatch <ref type="bibr" target="#b40">[41]</ref> PyTorch implementation, initializing it with the 100 most confident samples in each of our clusters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Analysis</head><p>The expressivity of our model: We report the accuracy on CIFAR10 using the groundtruth class names as the nouns (See Tab.4). We see that the solution we found for CIFAR10 is close to optimal zero-shot classification result. We note that the while the CLIP <ref type="bibr" target="#b35">[36]</ref> paper reports better classification results, it uses extensive prompts engineering which is beyond the scope of this paper. Furthermore, as the ground truth results actually achieve a similar loss to ours, a further improvement of our method is more likely to come from extending the expressivity of our model rather than a better optimization process.</p><p>Filtering our nouns list: Before running the algorithm, we filter out nouns whose "generality" score is above some quantile q, as mentioned in Sec.3.3. To do so in unsupervised way, we try a set of values for q (see implementation details 5.5), and run our algorithm with each them. For each value of q, we obtain cluster assignments, and calculate the entropy. We choose to use the q value for which our noun list W q gives the most balanced clustering for each dataset, measured as the highest entropy cluster assignment. For illustration, in <ref type="figure" target="#fig_0">Fig.3</ref> we show that the accuracy of our clustering, and the entropy value are correlated for different quantile threshold q.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusion</head><p>We presented the "single-noun" prior for biasing clustering methods towards more semantic clusters. The task was shown to be mathematically equivalent to the uncapcitated K-facility location problem, and we suggested an efficient optimization method for solving it. While our approach is very effective, we acknowledge that not all clusters are defined by nouns. Other datasets classes, such as ones in which classes are defined by activities, might benefit from other lists, for example those of single-adjectives. Exploring this setting is left for future work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 .</head><label>3</label><figDesc>CIFAR10 Accuracy vs. Unsupervised criterion</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Statistics of datasets used in our experiments</figDesc><table><row><cell>Name</cell><cell cols="2">Classes Images</cell><cell>Dimension</cell></row><row><cell>CIFAR-10</cell><cell>10</cell><cell>60,000</cell><cell>32×32×3</cell></row><row><cell>CIFAR-100/20</cell><cell>20</cell><cell>60,000</cell><cell>32×32×3</cell></row><row><cell>STL-10</cell><cell>10</cell><cell>13,000</cell><cell>96×96×3</cell></row><row><cell>ImageNet-Dog</cell><cell>15</cell><cell cols="2">19,500 256 1 ×256×3</cell></row><row><cell>ImageNet-50</cell><cell>50</cell><cell>65,000</cell><cell>256×256×3</cell></row><row><cell>ImageNet-100</cell><cell>100</cell><cell cols="2">130,000 256×256×3</cell></row><row><cell>ImageNet-200</cell><cell>200</cell><cell cols="2">260,000 256×256×3</cell></row><row><cell cols="4">task, we use the combination of the train and test sets for</cell></row><row><cell cols="4">both training and evaluation (a total of 60, 000 images).</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Clustering performance comparison on the commonly used benchmarks (%)</figDesc><table><row><cell></cell><cell></cell><cell>CIFAR-10</cell><cell></cell><cell cols="3">CIFAR-20/100</cell><cell></cell><cell>STL-10</cell><cell></cell><cell cols="3">ImageNet-Dog</cell></row><row><cell></cell><cell cols="12">NMI ACC ARI NMI ACC ARI NMI ACC ARI NMI ACC ARI</cell></row><row><cell>k-means [26]</cell><cell>8.7</cell><cell>22.9</cell><cell>4.9</cell><cell>8.4</cell><cell>13.0</cell><cell>2.8</cell><cell>12.5</cell><cell>19.2</cell><cell>6.1</cell><cell>5.5</cell><cell>10.5</cell><cell>2.0</cell></row><row><cell>SC [54]</cell><cell>10.3</cell><cell>24.7</cell><cell>8.5</cell><cell>9.0</cell><cell>13.6</cell><cell>2.2</cell><cell>9.8</cell><cell>15.9</cell><cell>4.8</cell><cell>3.8</cell><cell>11.1</cell><cell>1.3</cell></row><row><cell>AE † [2]</cell><cell>23.9</cell><cell cols="3">31.4 16.9 10.0</cell><cell>16.5</cell><cell>4.8</cell><cell>25.0</cell><cell cols="3">30.3 16.1 10.4</cell><cell>18.5</cell><cell>7.3</cell></row><row><cell>DAE † [46]</cell><cell>25.1</cell><cell cols="3">29.7 16.3 11.1</cell><cell>15.1</cell><cell>4.6</cell><cell>22.4</cell><cell cols="3">30.2 15.2 10.4</cell><cell>19.0</cell><cell>7.8</cell></row><row><cell>SWWAE † [55]</cell><cell>23.3</cell><cell cols="3">28.4 16.4 10.3</cell><cell>14.7</cell><cell>3.9</cell><cell>19.6</cell><cell cols="2">27.0 13.6</cell><cell>9.4</cell><cell>15.9</cell><cell>7.6</cell></row><row><cell>GAN † [37]</cell><cell>26.5</cell><cell cols="3">31.5 17.6 12.0</cell><cell>15.3</cell><cell>4.5</cell><cell>21.0</cell><cell cols="3">29.8 13.9 12.1</cell><cell>17.4</cell><cell>7.8</cell></row><row><cell>VAE † [22]</cell><cell>24.5</cell><cell cols="3">29.1 16.7 10.8</cell><cell>15.2</cell><cell>4.0</cell><cell>20.0</cell><cell cols="3">28.2 14.6 10.7</cell><cell>17.9</cell><cell>7.9</cell></row><row><cell>JULE [50]</cell><cell>19.2</cell><cell cols="3">27.2 13.8 10.3</cell><cell>13.7</cell><cell>3.3</cell><cell>18.2</cell><cell cols="2">27.7 16.4</cell><cell>5.4</cell><cell>13.8</cell><cell>2.8</cell></row><row><cell>DEC [48]</cell><cell>25.7</cell><cell cols="3">30.1 16.1 13.6</cell><cell>18.5</cell><cell>5.0</cell><cell>27.6</cell><cell cols="3">35.9 18.6 12.2</cell><cell>19.5</cell><cell>7.9</cell></row><row><cell>DAC [4]</cell><cell>39.6</cell><cell cols="3">52.2 30.6 18.5</cell><cell>23.8</cell><cell>8.8</cell><cell>36.6</cell><cell cols="3">47.0 25.7 21.9</cell><cell cols="2">27.5 11.1</cell></row><row><cell>DCCM [47]</cell><cell>49.6</cell><cell cols="3">62.3 40.8 28.5</cell><cell cols="3">32.7 17.3 37.6</cell><cell cols="3">48.2 26.2 32.1</cell><cell cols="2">38.3 18.2</cell></row><row><cell>IIC [19]</cell><cell>-</cell><cell>61.7</cell><cell>-</cell><cell>-</cell><cell>25.7</cell><cell>-</cell><cell>-</cell><cell>49.9</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>DHOG [10]</cell><cell>58.5</cell><cell cols="3">66.6 49.2 25.8</cell><cell cols="3">26.1 11.8 41.3</cell><cell cols="2">48.3 27.2</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell cols="2">AttentionCluster [32] 47.5</cell><cell cols="3">61.0 40.2 21.5</cell><cell cols="3">28.1 11.6 44.6</cell><cell cols="3">58.3 36.3 28.1</cell><cell cols="2">32.2 16.3</cell></row><row><cell>MMDC [39]</cell><cell>57.2</cell><cell>70.0</cell><cell>-</cell><cell>25.9</cell><cell>31.2</cell><cell>-</cell><cell>49.8</cell><cell>61.1</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>PICA [16]</cell><cell>59.1</cell><cell cols="3">69.6 51.2 31.0</cell><cell cols="3">33.7 17.1 61.1</cell><cell cols="3">71.3 53.1 35.2</cell><cell cols="2">35.2 20.1</cell></row><row><cell>SCAN [45]</cell><cell>71.2</cell><cell cols="3">81.8 66.5 44.1</cell><cell cols="3">42.2 26.7 65.4</cell><cell cols="2">75.5 59.0</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>MICE [42]</cell><cell>73.5</cell><cell cols="3">83.4 69.5 43.0</cell><cell cols="3">42.2 27.7 61.3</cell><cell cols="3">72.0 53.2 39.4</cell><cell cols="2">39.0 24.7</cell></row><row><cell>Pretrained</cell><cell>66.8</cell><cell cols="3">72.6 57.0 45.1</cell><cell cols="3">46.7 26.2 90.2</cell><cell cols="3">94.9 88.9 28.4</cell><cell cols="2">31.0 17.5</cell></row><row><cell>Ours</cell><cell>73.1</cell><cell cols="3">85.3 70.2 44.4</cell><cell cols="3">43.3 26.3 92.9</cell><cell cols="3">97.0 93.4 50.5</cell><cell cols="2">55.1 38.1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>Clustering performance comparison on randomly selected classes from ImageNet (%)</figDesc><table><row><cell>ImangeNet</cell><cell></cell><cell>50 classes</cell><cell>100 classes</cell><cell>200 classes</cell></row><row><cell></cell><cell cols="4">NMI ACC ARI NMI ACC ARI NMI ACC ARI</cell></row><row><cell>MoCo K-means</cell><cell>77.5</cell><cell>65.9 57.9 76.1</cell><cell>59.7 50.8 75.5</cell><cell>52.5 43.2</cell></row><row><cell>SCAN</cell><cell>80.5</cell><cell>75.1 63.5 78.7</cell><cell>66.2 54.4 75.7</cell><cell>56.3 44.1</cell></row><row><cell cols="2">Pretrained K-means 77.6</cell><cell>66.0 57.6 75.0</cell><cell>61.7 51.9 72.1</cell><cell>53.5 43.8</cell></row><row><cell>Pretrained Ward's</cell><cell>80.4</cell><cell>73.5 61.3 76.2</cell><cell>64.9 52.6 62.0</cell><cell>34.2 23.0</cell></row><row><cell>Ours</cell><cell>84.7</cell><cell>82.7 74.4 80.5</cell><cell>73.1 62.8 74.9</cell><cell>59.8 48.6</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 .</head><label>4</label><figDesc></figDesc><table><row><cell cols="3">Comparison to supervised cluster names (CIFAR10)</cell></row><row><cell></cell><cell cols="2">Ours Groundtruth Class names</cell></row><row><cell cols="2">Acc (%) 85.3</cell><cell>86.0</cell></row><row><cell>Loss</cell><cell>1.43</cell><cell>1.43</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 .</head><label>5</label><figDesc>Glossary of CIFAR10 class names and assigned nouns</figDesc><table><row><cell>Classname</cell><cell>Cluster</cell><cell>Classname</cell><cell>Cluster</cell></row><row><cell>airplane</cell><cell>ramjet</cell><cell>dog</cell><cell>maltese dog</cell></row><row><cell>truck</cell><cell>milk float</cell><cell>frog</cell><cell>barking frog</cell></row><row><cell>automobile</cell><cell>jowett</cell><cell>ship</cell><cell>pilot boat</cell></row><row><cell>horse</cell><cell>chukker</cell><cell>cat</cell><cell>egyptian cat</cell></row><row><cell>bird</cell><cell>bulbul</cell><cell>deer</cell><cell>pere david's deer</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 .</head><label>6</label><figDesc>Comparison between PAM and our method (STL10)</figDesc><table><row><cell></cell><cell>Ours PAM</cell></row><row><cell cols="2">Acc (%) 96.8 96.3</cell></row><row><cell>Loss</cell><cell>1.47 1.47</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 7 .</head><label>7</label><figDesc></figDesc><table><row><cell></cell><cell cols="3">Comparison of initialization methods (CIFAR10)</cell></row><row><cell></cell><cell cols="3">CLIP-Ward CLIP-Kmeans ResNet-Ward</cell></row><row><cell>Acc (%)</cell><cell>72.6</cell><cell>69.4</cell><cell>64.6</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://github.com/vector-1127/DAC/tree/master/Datasets description</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">https://github.com/guysrn/mmdc/blob/main/utils/metrics.py</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work was partly supported by the Federmann Cyber Security Research Center in conjunction with the Israel National Cyber Directorate.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Local search heuristics for k-median and facility location problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Arya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naveen</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rohit</forename><surname>Khandekar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Meyerson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kamesh</forename><surname>Munagala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vinayaka</forename><surname>Pandit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on computing</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="544" to="562" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Greedy layer-wise training of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Lamblin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Popovici</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page">153</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Deep clustering for unsupervised learning of visual features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathilde</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthijs</forename><surname>Douze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="132" to="149" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Shiming Xiang, and Chunhong Pan</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianlong</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingfeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaofeng</forename><surname>Meng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5879" to="5887" />
		</imprint>
	</monogr>
	<note>Deep adaptive image clustering</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1597" to="1607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinlei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.04297</idno>
		<title level="m">Improved baselines with momentum contrastive learning</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">An analysis of single-layer networks in unsupervised feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fourteenth international conference on artificial intelligence and statistics</title>
		<meeting>the fourteenth international conference on artificial intelligence and statistics</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="215" to="223" />
		</imprint>
	</monogr>
	<note>JMLR Workshop and Conference Proceedings</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">The uncapicitated facility location problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gérard</forename><surname>Cornuéjols</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Nemhauser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurence</forename><surname>Wolsey</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983" />
		</imprint>
		<respStmt>
			<orgName>Cornell University Operations Research and Industrial Engineering</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Histograms of oriented gradients for human detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navneet</forename><surname>Dalal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Triggs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE computer society conference on computer vision and pattern recognition (CVPR&apos;05)</title>
		<imprint>
			<publisher>Ieee</publisher>
			<date type="published" when="2005" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="886" to="893" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Nicholas Darlow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amos</forename><surname>Storkey</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.08821</idno>
		<title level="m">Dhog: Deep hierarchical object grouping</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karan</forename><surname>Desai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Johnson</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.06666</idno>
		<title level="m">Virtex: Learning visual representations from textual annotations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Combining pretrained cnn feature extractors to enhance clustering of complex natural images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joris</forename><surname>Guérin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephane</forename><surname>Thiery</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Nyiri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Gibaru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Byron</forename><surname>Boots</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">423</biblScope>
			<biblScope unit="page" from="551" to="571" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Greedy strikes back: Improved facility location algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sudipto</forename><surname>Guha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samir</forename><surname>Khuller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of algorithms</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="228" to="248" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Associative deep clustering: Training a classification network with no labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Haeusser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Plapp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Golkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elie</forename><surname>Aljalbout</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Cremers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">German Conference on Pattern Recognition</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="18" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Learning discrete representations via information maximizing self-augmented training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weihua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeru</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seiya</forename><surname>Tokui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eiichi</forename><surname>Matsumoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masashi</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1558" to="1567" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Deep semantic clustering by partition confidence maximisation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiabo</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaogang</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiatian</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="8849" to="8858" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A new greedy approach for facility location problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kamal</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Mahdian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amin</forename><surname>Saberi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the thiry-fourth annual ACM symposium on Theory of computing</title>
		<meeting>the thiry-fourth annual ACM symposium on Theory of computing</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="731" to="740" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Approximation algorithms for metric facility location and k-median problems using the primal-dual schema and lagrangian relaxation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kamal</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vijay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vazirani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the ACM (JACM)</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="274" to="296" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Invariant information clustering for unsupervised image classification and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>João</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Henriques</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vedaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9865" to="9874" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Billionscale similarity search with gpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthijs</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hervé</forename><surname>Jégou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Big Data</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Learning visual features from large weakly supervised data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Allan</forename><surname>Jabri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Vasilache</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="67" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Auto-encoding variational bayes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6114</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Do better imagenet models transfer better?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2661" to="2671" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A heuristic program for locating warehouses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Alfred</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Kuehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hamburger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management science</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="643" to="666" />
			<date type="published" when="1963" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Least squares quantization in pcm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stuart</forename><surname>Lloyd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on information theory</title>
		<imprint>
			<date type="published" when="1982" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="129" to="137" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Object recognition from local scale-invariant features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the seventh IEEE international conference on computer vision</title>
		<meeting>the seventh IEEE international conference on computer vision</meeting>
		<imprint>
			<publisher>Ieee</publisher>
			<date type="published" when="1999" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1150" to="1157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Exploring the limits of weakly supervised pretraining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Mahajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vignesh</forename><surname>Ramanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manohar</forename><surname>Paluri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashwin</forename><surname>Bharambe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="181" to="196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Wordnet: a lexical database for english</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>George</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="39" to="41" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A computational model for color naming and describing color composition of images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksandra</forename><surname>Mojsilovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image processing</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="690" to="699" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Image-to-word transformation based on dividing and vector quantizing images with words</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yasuhide</forename><surname>Mori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hironobu</forename><surname>Takahashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryuichi</forename><surname>Oka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">First international workshop on multimedia intelligent storage and retrieval management</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="1999" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Gatcluster: Self-supervised gaussian-attention network for image clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuang</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ge</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimin</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="735" to="751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Scikit-learn: Machine learning in python. the</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaël</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bertrand</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathieu</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ron</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Dubourg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine Learning research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Predominant color name indexing structure for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raphael</forename><surname>Prates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Cristianne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William Robson</forename><surname>Dutra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE International Conference on Image Processing (ICIP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="779" to="783" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Learning visual representations using images with captions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ariadna</forename><surname>Quattoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2007 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Learning transferable visual models from natural language supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jong</forename><forename type="middle">Wook</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Hallacy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Goh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandhini</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Girish</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pamela</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jack</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">2</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Unsupervised representation learning with deep convolutional generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06434</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mert</forename><surname>Bulent Sariyildiz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diane</forename><surname>Larlus</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2008.01392</idno>
		<title level="m">Learning visual representations with caption annotations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Multi-modal deep clustering: Unsupervised partitioning of images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guy</forename><surname>Shiran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daphna</forename><surname>Weinshall</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.02678</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Approximation algorithms for facility location problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Éva</forename><surname>Shmoys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Tardos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Aardal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the twenty-ninth annual ACM symposium on Theory of computing</title>
		<meeting>the twenty-ninth annual ACM symposium on Theory of computing</meeting>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="265" to="274" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Fixmatch: Simplifying semisupervised learning with consistency and confidence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun-Liang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zizhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Raffel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.07685</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Mi{ce}: Mixture of contrastive experts for unsupervised image clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chongxuan</forename><surname>Tsung Wei Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">An overview of color name applications in computer vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joost</forename><surname>Van De Weijer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fahad</forename><surname>Shahbaz Khan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Workshop on Computational Color Imaging</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="16" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Learning color names for real-world applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joost</forename><surname>Van De Weijer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Verbeek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diane</forename><surname>Larlus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1512" to="1523" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Scan: Learning to classify images without labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Wouter Van Gansbeke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stamatios</forename><surname>Vandenhende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Georgoulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Proesmans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="268" to="285" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabelle</forename><surname>Lajoie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre-Antoine</forename><surname>Manzagol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">12</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Deep comprehensive correlation mining for image clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianlong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keyu</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhouchen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongbin</forename><surname>Zha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8150" to="8159" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Unsupervised deep embedding for clustering analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyuan</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="478" to="487" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Towards k-means-friendly spaces: Simultaneous deep learning and clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Nicholas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingyi</forename><surname>Sidiropoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">international conference on machine learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3861" to="3870" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Joint unsupervised learning of deep representations and image clusters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianwei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Batra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="5147" to="5156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Salient color names for person reidentification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengcai</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stan</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="536" to="551" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Beyond eleven color names for image understanding. Machine Vision and Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lichao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joost</forename><surname>Van De Weijer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fahad</forename><surname>Shahbaz Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongmei</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C Alejandro</forename><surname>Parraga</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="361" to="373" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Zagoruyko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Komodakis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.07146</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">Wide residual networks. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Self-tuning spectral clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lihi</forename><surname>Zelnik-Manor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">17</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Stacked what-where auto-encoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junbo</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Mathieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Goroshin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.02351</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
