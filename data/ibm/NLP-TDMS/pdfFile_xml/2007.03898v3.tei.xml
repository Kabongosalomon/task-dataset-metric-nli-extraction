<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">NVAE: A Deep Hierarchical Variational Autoencoder</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arash</forename><surname>Vahdat</surname></persName>
							<email>avahdat@nvidia.com</email>
							<affiliation key="aff0">
								<orgName type="institution">NVIDIA</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Kautz</surname></persName>
							<email>jkautz@nvidia.com</email>
							<affiliation key="aff0">
								<orgName type="institution">NVIDIA</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">NVAE: A Deep Hierarchical Variational Autoencoder</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T16:24+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Normalizing flows, autoregressive models, variational autoencoders (VAEs), and deep energy-based models are among competing likelihood-based frameworks for deep generative learning. Among them, VAEs have the advantage of fast and tractable sampling and easy-to-access encoding networks. However, they are currently outperformed by other models such as normalizing flows and autoregressive models. While the majority of the research in VAEs is focused on the statistical challenges, we explore the orthogonal direction of carefully designing neural architectures for hierarchical VAEs. We propose Nouveau VAE (NVAE), a deep hierarchical VAE built for image generation using depth-wise separable convolutions and batch normalization. NVAE is equipped with a residual parameterization of Normal distributions and its training is stabilized by spectral regularization. We show that NVAE achieves state-of-the-art results among non-autoregressive likelihood-based models on the MNIST, CIFAR-10, CelebA 64, and CelebA HQ datasets and it provides a strong baseline on FFHQ. For example, on CIFAR-10, NVAE pushes the state-of-the-art from 2.98 to 2.91 bits per dimension, and it produces high-quality images on CelebA HQ as shown in <ref type="figure">Fig. 1</ref>. To the best of our knowledge, NVAE is the first successful VAE applied to natural images as large as 256×256 pixels. The source code is available at https://github.com/NVlabs/NVAE.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The majority of the research efforts on improving VAEs <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref> is dedicated to the statistical challenges, such as reducing the gap between approximate and true posterior distributions <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b9">10]</ref>, formulating tighter bounds <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b13">14]</ref>, reducing the gradient noise <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b15">16]</ref>, extending VAEs to discrete variables <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b22">23]</ref>, or tackling posterior collapse <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b26">27]</ref>. The role of neural network architectures for VAEs is somewhat overlooked, as most previous work borrows the architectures from classification tasks. <ref type="figure">Figure 1</ref>: 256×256-pixel samples generated by NVAE, trained on CelebA HQ <ref type="bibr" target="#b27">[28]</ref>.</p><p>However, VAEs can benefit from designing special network architectures as they have fundamentally different requirements. First, VAEs maximize the mutual information between the input and latent variables <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b29">30]</ref>, requiring the networks to retain the information content of the input data as much as possible. This is in contrast with classification networks that discard information regarding the input <ref type="bibr" target="#b30">[31]</ref>. Second, VAEs often respond differently to the over-parameterization in neural networks. Since the marginal log-likelihood only depends on the generative model, overparameterizing the decoder network may hurt the test log-likelihood, whereas powerful encoders can yield better models because of reducing the amortization gap <ref type="bibr" target="#b5">[6]</ref>. Wu et al. <ref type="bibr" target="#b31">[32]</ref> observe that the marginal loglikelihood, estimated by non-encoder-based methods, is not sensitive to the encoder overfitting (see also <ref type="figure">Fig. 9</ref> in <ref type="bibr" target="#b18">[19]</ref>). Moreover, the neural networks for VAEs should model long-range correlations in data <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b34">35]</ref>, requiring the networks to have large receptive fields. Finally, due to the unbounded Kullback-Leibler (KL) divergence in the variational lower bound, training very deep hierarchical VAEs is often unstable. The current state-of-the-art VAEs <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b35">36]</ref> omit batch normalization (BN) <ref type="bibr" target="#b36">[37]</ref> to combat the sources of randomness that could potentially amplify their instability.</p><p>In this paper, we aim to make VAEs great again by architecture design. We propose Nouveau VAE (NVAE), a deep hierarchical VAE with a carefully designed network architecture that produces highquality images. NVAE obtains the state-of-the-art results among non-autoregressive likelihood-based generative models, reducing the gap with autoregressive models. The main building block of our network is depthwise convolutions <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b38">39]</ref> that rapidly increase the receptive field of the network without dramatically increasing the number of parameters.</p><p>In contrast to the previous work, we find that BN is an important component of the success of deep VAEs. We also observe that instability of training remains a major roadblock when the number of hierarchical groups is increased, independent of the presence of BN. To combat this, we propose a residual parameterization of the approximate posterior parameters to improve minimizing the KL term, and we show that spectral regularization is key to stabilizing VAE training.</p><p>In summary, we make the following contributions: i) We propose a novel deep hierarchical VAE, called NVAE, with depthwise convolutions in its generative model. ii) We propose a new residual parameterization of the approximate posteriors. iii) We stabilize training deep VAEs with spectral regularization. iv) We provide practical solutions to reduce the memory burden of VAEs. v) We show that deep hierarchical VAEs can obtain state-of-the-art results on several image datasets, and can produce high-quality samples even when trained with the original VAE objective. To the best of our knowledge, NVAE is the first successful application of VAEs to images as large as 256×256 pixels.</p><p>Related Work: Recently, VQ-VAE-2 <ref type="bibr" target="#b39">[40]</ref> demonstrated high-quality generative performance for large images. Although VQ-VAE's formulation is motivated by VAEs, its objective does not correspond to a lower bound on data log-likelihood. In contrast, NVAE is trained directly with the VAE objective. Moreover, VQ-VAE-2 uses PixelCNN <ref type="bibr" target="#b40">[41]</ref> in its prior for latent variables up to 128×128 dims that is very slow to sample from, while NVAE uses an unconditional decoder in the data space.</p><p>Our work is related to VAEs with inverse autoregressive flows (IAF-VAEs) <ref type="bibr" target="#b3">[4]</ref>. NVAE borrows the statistical models (i.e., hierarchical prior and approximate posterior, etc.etc) from IAF-VAEs. But, it differs from IAF-VAEs in terms of i) neural networks implementing these models, ii) the parameterization of approximate posteriors, and iii) scaling up the training to large images. Nevertheless, we provide ablation experiments on these aspects, and we show that NVAE outperform the original IAF-VAEs by a large gap. Recently, BIVA <ref type="bibr" target="#b35">[36]</ref> showed state-of-the-art VAE results by extending bidirectional inference to latent variables. However, BIVA uses neural networks similar to IAF-VAE, and it is trained on images as large as 64×64 px. To keep matters simple, we use the hierarchical structure from IAF-VAEs, and we focus on carefully designing the neural networks. We expect improvements in performance if more complex hierarchical models from BIVA are used. Early works DRAW <ref type="bibr" target="#b4">[5]</ref> and Conv DRAW <ref type="bibr" target="#b41">[42]</ref> use recurrent neural networks to model hierarchical dependencies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>Here, we review VAEs, their hierarchical extension, and bidirectional encoder networks <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b42">43]</ref>.</p><p>The goal of VAEs <ref type="bibr" target="#b0">[1]</ref> is to train a generative model in the form of p(x x x, z z z) = p(z z z)p(x x x|z z z) where p(z z z) is a prior distribution over latent variables z z z and p(x x x|z z z) is the likelihood function or decoder that generates data x x x given latent variables z z z. Since the true posterior p(z z z|x x x) is in general intractable, the generative model is trained with the aid of an approximate posterior distribution or encoder q(z z z|x x x).</p><p>In deep hierarchical VAEs <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b43">44]</ref>, to increase the expressiveness of both the approximate posterior and prior, the latent variables are partitioned into disjoint groups, z z z = {z z z 1 , z z z 1 , . . . , z z z L }, where L is the number of groups. Then, the prior is represented by p(z z z) = l p(z z z l |z z z &lt;l ) and the approximate posterior by q(z z z|x x x) = l q(z z z l |z z z &lt;l , x x x) where each conditional in the prior (p(z z z l |z z z &lt;l ) and the approximate posterior (q(z z z l |z z z &lt;l , x x x)) are represented by factorial Normal distributions. We can write the variational lower bound L VAE (x x x) on log p(x x x) as:  where q(z z z &lt;l |x x x) := l−1 i=1 q(z z z i |x x x, z z z &lt;i ) is the approximate posterior up to the (l − 1) th group. The objective is trained using the reparameterization trick <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>.</p><formula xml:id="formula_0">L VAE (x x x) := E q(z z z|x x x) [log p(x x x|z z z)] − KL(q(z z z1|x x x)||p(z z z1)) − L l=2 E q(z z z &lt;l |x x x) [KL(q(z z z l |x x x, z z z &lt;l )||p(z z z l |z z z &lt;l ))] ,</formula><p>The main question here is how to implement the conditionals in p(x x x, z z z) and q(z z z|x x x) using neural networks. For modeling the generative model, a top-down network generates the parameters of each conditional. After sampling from each group, the samples are combined with deterministic feature maps and passed to the next group ( <ref type="figure" target="#fig_1">Fig. 2b</ref>). For inferring the latent variables in q(z z z|x x x), we require a bottom-up deterministic network to extract representation from input x x x. Since the order of latent variable groups are shared between q(z z z|x x x) and p(z z z), we also require an additional top-down network to infer latent variables group-by-group. To avoid the computation cost of an additional top-down model, in bidirectional inference <ref type="bibr" target="#b3">[4]</ref>, the representation extracted in the top-down model in the generative model is reused for inferring latent variables ( <ref type="figure" target="#fig_1">Fig. 2a</ref>). IAF-VAEs <ref type="bibr" target="#b3">[4]</ref> relies on regular residual networks <ref type="bibr" target="#b44">[45]</ref> for both top-down and bottom-up models without any batch normalization, and it has been examined on small images only.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head><p>In this paper, we propose a deep hierarchical VAE called NVAE that generates large high-quality images. NVAE's design focuses on tackling two main challenges: (i) designing expressive neural networks specifically for VAEs, and (ii) scaling up the training to a large number of hierarchical groups and image sizes while maintaining training stability. NVAE uses the conditional dependencies from <ref type="figure" target="#fig_1">Fig. 2</ref>, however, to address the above-mentioned challenges, it is equipped with novel network architecture modules and parameterization of approximate posteriors. Sec. 3.1 introduces NVAE's residual cells. Sec. 3.2 presents our parameterization of posteriors and our solution for stable training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Residual Cells for Variational Autoencoders</head><p>One of the key challenges in deep generative learning is to model the long-range correlations in data. For example, these correlations in the images of faces are manifested by a uniform skin tone and the general left-right symmetry. In the case of VAEs with unconditional decoder, such long-range correlations are encoded in the latent space and are projected back to the pixel space by the decoder.</p><p>A common solution to the long-range correlations is to build a VAE using a hierarchical multi-scale model. Our generative model starts from a small spatially arranged latent variables as z z z 1 and samples from the hierarchy group-by-group while gradually doubling the spatial dimensions. This multi-scale approach enables NVAE to capture global long-range correlations at the top of the hierarchy and local fine-grained dependencies at the lower groups.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Residual Cells for the Generative Model</head><p>In addition to hierarchical modeling, we can improve modeling the long-range correlations by increasing the receptive field of the networks. Since the encoder and decoder in NVAE are implemented by deep residual networks <ref type="bibr" target="#b44">[45]</ref>, this can be done by increasing the kernel sizes in the convolutional path.  <ref type="figure">Figure 3</ref>: The NVAE residual cells for generative and encoder models are shown in (a) and (b). The number of output channels is shown above. The residual cell in (a) expands the number of channels E times before applying the depthwise separable convolution, and then maps it back to C channels. The cell in (b) applies two series of BN-Swish-Conv without changing the number of channels.</p><p>However, large filter sizes come with the cost of large parameter sizes and computational complexity. In our early experiments, we empirically observed that depthwise convolutions outperform regular convolutions while keeping the number of parameters and the computational complexity orders of magnitudes smaller 1 . However, depthwise convolutions have limited expressivity as they operate in each channel separately. To tackle this issue, following MobileNetV2 <ref type="bibr" target="#b45">[46]</ref>, we apply these convolutions after expanding the number of channels by a 1 × 1 regular convolution and we map their output back to original channel size using another 1 × 1 regular convolution.</p><p>Batch Normalization: The state-of-the-art VAE <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b35">36]</ref> models have omitted BN as they observed that "the noise introduced by batch normalization hurts performance" <ref type="bibr" target="#b3">[4]</ref> and have relied on weight normalization (WN) <ref type="bibr" target="#b46">[47]</ref> instead. In our early experiments, we observed that the negative impact of BN is during evaluation, not training. Because of using running statistics in BN, the output of each BN layer can be slightly shifted during evaluation, causing a dramatic change in the network output.</p><p>To fix this, we adjust the momentum hyperparameter of BN, and we apply a regularization on the norm of scaling parameters in BN layers to ensure that a small mismatch in statistics is not amplified by BN. This follows our network smoothness regularization that is discussed in Sec. 3.2.</p><p>Swish Activation: The Swish activation <ref type="bibr" target="#b47">[48]</ref>, f (u) = u 1+e −u , has been recently shown promising results in many applications <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b49">50]</ref>. We also observe that the combination of BN and Swish outperforms WN and ELU activation <ref type="bibr" target="#b50">[51]</ref> used by the previous works <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b35">36]</ref>.</p><p>Squeeze and Excitation (SE): SE [52] is a simple channel-wise gating layer that has been used widely in classification problems <ref type="bibr" target="#b48">[49]</ref>. We show that SE can also improve VAEs.</p><p>Final cell: Our residual cells with depthwise convolutions are visualized in <ref type="figure">Fig. 3</ref>(a). Our cell is similar to MobileNetV2 <ref type="bibr" target="#b45">[46]</ref>, with three crucial differences; It has two additional BN layers at the beginning and the end of the cell and it uses Swish activation function and SE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Residual Cells for the Encoder Model</head><p>We empirically observe that depthwise convolutions are effective in the generative model and do not improve the performance of NVAE when they are applied to the bottom-up model in encoder. Since regular convolutions require less memory, we build the bottom-up model in encoder by residual cells visualized in <ref type="figure">Fig. 3(b)</ref>. We empirically observe that BN-Activation-Conv performs better than the original Conv-BN-Activation <ref type="bibr" target="#b44">[45]</ref> in regular residual cells. A similar observation was made in <ref type="bibr" target="#b52">[53]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3">Reducing the Memory Requirements</head><p>The main challenge in using depthwise convolutions is the high memory requirement imposed by the expanded features. To tackle this issue, we use two tricks: (i) We define our model in mixed-precision using the NVIDIA APEX library <ref type="bibr" target="#b53">[54]</ref>. This library has a list of operations (including convolutions) that can safely be cast to half-precision floats. This enables us to reduce the GPU memory by 40%.</p><p>(ii) A careful examination of the residual cells in <ref type="figure">Fig. 3</ref> reveals that one copy of feature maps for each operation is stored for the backward pass 2 . To reduce the memory, we fuse BN and Swish and we store only one feature map for the backward pass, instead of two. This trick is known as gradient check-pointing <ref type="bibr" target="#b54">[55,</ref><ref type="bibr" target="#b55">56]</ref> and it requires recomputing BN in the backward pass. The additional BN computation does not change the training time significantly, but it results in another 18% reduction in memory usage for our model on CIFAR-10. These two tricks together help us roughly double the training throughput using a larger batch size (from 34 images/sec to 64 images/sec).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Taming the Unbounded KL Term</head><p>In practice, training deep hierarchical VAE poses a great optimization challenge due to unbounded KL from q(z z z l |x x x, z z z &lt;l ) to p(z z z l |z z z &lt;l ) in the objective. It is common to use two separate neural networks to generate the parameters of these distributions. However, in the case of a large number of latent variable groups, keeping these distributions in harmony is very challenging. If the encoder and decoder produce distributions far from each other during training, the sharp gradient update, resulting from KL, will push the model parameters to an unstable region, from which it is difficult to recover. Here, we propose two approaches for improving KL optimization and stabilizing the training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Residual Normal Distributions:</head><p>We propose a residual distribution that parameterizes q(z z z|x x x)</p><formula xml:id="formula_1">relative to p(z z z). Let p(z i l |z z z &lt;l ) := N (µ i (z z z &lt;l ), σ i (z z z &lt;l )) be a Normal distribution for the i th variable in z z z l in prior. We define q(z i l |z z z &lt;l , x x x) := N (µ i (z z z &lt;l ) + ∆µ i (z z z &lt;l , x x x), σ i (z z z &lt;l ) · ∆σ i (z z z &lt;l , x x x)), where ∆µ i (z z z &lt;l , x x x) and ∆σ i (z z z &lt;l , x x x)</formula><p>are the relative location and scale of the approximate posterior with respect to the prior. With this parameterization, when the prior moves, the approximate posterior moves accordingly, if not changed. The benefit of this formulation can be also seen when we examine the KL term in L VAE :</p><formula xml:id="formula_2">KL q(z i |x x x)||p(z i ) = 1 2 ∆µ 2 i σ 2 i + ∆σ 2 i − log ∆σ 2 i − 1 ,<label>(2)</label></formula><p>where we have dropped subscript l and the dependencies for the ease of notation. As we can see above, if σ i , generated by the decoder, is bounded from below, the KL term mainly depends on the relative parameters, generated by the single encoder network. We hypothesize that minimizing KL in this parameterization is easier than when q(z i l |z z z &lt;l , x x x) predicts the absolute location and scale. With a similar motivation, a weighted averaging of approximate posterior and prior parameters is also introduced in <ref type="bibr" target="#b42">[43]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Spectral Regularization (SR):</head><p>The residual Normal distributions do not suffice for stabilizing VAE training as KL in Eq. 2 is still unbounded. To bound KL, we need to ensure that the encoder output does not change dramatically as its input changes. This notion of smoothness is characterized by the Lipschitz constant. We hypothesize that by regularizing the Lipschitz constant, we can ensure that the latent codes predicted by the encoder remain bounded, resulting in a stable KL minimization.</p><p>Since estimating the Lipschitz constant of a network is intractable, we use the SR <ref type="bibr" target="#b56">[57]</ref> that minimizes the Lipschitz constant for each layer. Formally, we add the term L SR = λ i s (i) to L VAE , where s (i) is the largest singular value of the i th conventional layer, estimated using a single power iteration update <ref type="bibr" target="#b56">[57,</ref><ref type="bibr" target="#b57">58]</ref>. Here, λ controls to the level of smoothness imposed by L SR .</p><p>More Expressive Approximate Posteriors with Normalizing Flows: In NVAE, p(z z z) and q(z z z|x x x) are modeled by autoregressive distributions among groups and independent distributions in each group. This enables us to sample from each group in parallel efficiently. But, it also comes with the cost of less expressive distributions. A simple solution to this problem is to apply a few additional normalizing flows to the samples generated at each group in q(z z z|x x x). Since they are applied only in the encoder network, i) we can rely on the inverse autoregressive flows (IAF) <ref type="bibr" target="#b3">[4]</ref>, as we do not require the explicit inversion of the flows, and ii) the sampling time is not increased because of the flows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>In this section, we examine NVAE on several image datasets. We present the main quantitative results in Sec. 4.1, qualitative results in Sec. 4.2 and ablation experiments in Sec. 4.3. <ref type="table">Table 1</ref>: Comparison against the state-of-the-art likelihood-based generative models. The performance is measured in bits/dimension (bpd) for all the datasets but MNIST in which negative log-likelihood in nats is reported (lower is better in all cases). NVAE outperforms previous non-autoregressive models on most datasets and reduces the gap with autoregressive models. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Main Quantitative Results</head><p>We examine NVAE on the dynamically binarized MNIST <ref type="bibr" target="#b71">[72]</ref>, CIFAR-10 <ref type="bibr" target="#b72">[73]</ref>, ImageNet 32×32 <ref type="bibr" target="#b73">[74]</ref>, CelebA 64 × 64 <ref type="bibr" target="#b74">[75,</ref><ref type="bibr" target="#b75">76]</ref>, CelebA HQ 256×256 <ref type="bibr" target="#b27">[28]</ref>, and FFHQ 256×256 <ref type="bibr" target="#b76">[77]</ref> datasets. All the datasets except FFHQ are commonly used for evaluating likelihood-based generative models. FFHQ is a challenging dataset, consisting of facial images. We reduce the resolution of the images in FFHQ to 256×256. To the best of our knowledge, NVAE is the first VAE model trained on FFHQ.</p><p>We build NVAE using the hierarchical structure shown in <ref type="figure" target="#fig_1">Fig. 2</ref> and residual cells shown in <ref type="figure">Fig. 3</ref>.</p><p>For large image datasets such as CelebA HQ and FFHQ, NVAE consists of 36 groups of latent variables starting from 8 × 8 dims, scaled up to 128 × 128 dims with two residual cells per latent variable groups. The implementation details are provided in Sec. A in Appendix.</p><p>The results are reported in <ref type="table">Table 1</ref>. NVAE outperforms the state-of-the-art non-autoregressive flow and VAE models including IAF-VAE <ref type="bibr" target="#b3">[4]</ref> and BIVA <ref type="bibr" target="#b35">[36]</ref> on all the datasets, but ImageNet, in which NVAE comes second after Flow++ <ref type="bibr" target="#b60">[61]</ref>. On CIFAR-10, NVAE improves the state-of-the-art from 2.98 to 2.91 bpd. It also achieves very competitive performance compared to the autoregressive models. Moreover, we can see that NVAE's performance is only slightly improved by applying flows in the encoder, and the model without flows outperforms many existing generative models by itself. This indicates that the network architecture is an important component in VAEs and a carefully designed network with Normal distributions in encoder can compensate for some of the statistical challenges.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Qualitative Results</head><p>For visualizing generated samples on challenging datasets such as CelebA HQ, it is common to lower the temperature of the prior to samples from the potentially high probability region in the model <ref type="bibr" target="#b61">[62]</ref>.  <ref type="figure">Figure 4</ref>: (a)-(e) Sampled images from NVAE with the temperature in prior (t). (f)-(g) A few images generated by MaCow <ref type="bibr" target="#b66">[67]</ref> and Glow <ref type="bibr" target="#b61">[62]</ref> are shown for comparison (images are from the original publications). NVAE generates diverse high quality samples even with a small temperature, and it exhibits remarkably better hair details and diversity (best seen when zoomed in). This is done by scaling down the standard deviation of the Normal distributions in each conditional in the prior, and it often improves the quality of the samples, but it also reduces their diversity.</p><p>In NVAE, we observe that if we use the single batch statistics during sampling for the BN layers, instead of the default running averages, we obtain much more diverse and higher quality samples even with small temperatures 3 . A similar observation was made in BigGAN <ref type="bibr" target="#b77">[78]</ref> and DCGAN <ref type="bibr" target="#b78">[79]</ref>. However, in this case, samples will depend on other data points in the batch. To avoid this, similar to BigGAN, we readjust running mean and standard deviation in the BN layers by sampling from the generative model 500 times for the given temperature, and then we use the readjusted statistics for the final sampling <ref type="bibr" target="#b3">4</ref> . We visualize samples with the default BN behavior in Sec. B.2 in the appendix.   <ref type="figure">Fig. 4</ref> visualizes the samples generated by NVAE along with the samples from MaCow <ref type="bibr" target="#b66">[67]</ref> and Glow <ref type="bibr" target="#b61">[62]</ref> on CelebA HQ for comparison. As we can see, NVAE produces high quality and diverse samples even with small temperatures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Ablation Studies</head><p>In this section, we perform ablation experiments to provide a better insight into different components in NVAE. All the experiments in this section are performed on CIFAR-10 using a small NVAE, constructed by halving the number of channels in residual cells and removing the normalizing flows. Normalization and Activation Functions: We examine the effect of normalization and activation functions on a VAE with cells visualized in <ref type="figure">Fig. 3b</ref> for different numbers of groups (L). ELU with WN and data-dependent initialization were used in IAF-VAE <ref type="bibr" target="#b3">[4]</ref> and BIVA <ref type="bibr" target="#b35">[36]</ref>. As we can see in <ref type="table" target="#tab_2">Table 2</ref>, replacing WN with BN improves ELU's training, especially for L = 40, but BN achieves better results with Swish. Residual Cells: In <ref type="table" target="#tab_3">Table 3</ref>, we examine the cells in <ref type="figure">Fig 3</ref> for the bottom-up encoder and top-down generative models. Here, "Separable" and "Regular" refer to the cells in <ref type="figure" target="#fig_3">Fig. 3a</ref> and <ref type="figure">Fig. 3b</ref> respectively. We observe that the residual cell with depthwise convolution in the generative model outperforms the regular cells, but it does not change the performance when it is in the bottom-up model. Given the lower memory and faster training with regular cells, we use these cells for the bottom-up model and depthwise cells for the top-down model. Residual Normal Distributions: A natural question is whether the residual distributions improve the optimization of the KL term in the VAE objective or whether they only further contribute to the approximate posterior collapse. In <ref type="table" target="#tab_4">Table 4</ref>, we train the 40-group model from <ref type="table" target="#tab_2">Table 2</ref> with and without the residual distributions, and we report the number of active channels in the latent variables 5 , the average training KL, reconstruction loss, and variational bound in bpd. Here, the baseline without residual distribution corresponds to the parameterization used in IAF-VAE <ref type="bibr" target="#b3">[4]</ref>. As we can see, the residual distribution does virtually not change the number of active latent variables or reconstruction loss. However, it does improve the KL term by 0.04 bpd in training, and the final test log-likelihood by 0.03 bpd (see Sec. B.4 in Appendix for additional details). The Effect of SR and SE: In <ref type="table" target="#tab_5">Table 5</ref>, we train the same 40-group model from <ref type="table" target="#tab_2">Table 2</ref> without spectral regularization (SR) or squeezeand-excitation (SE). We can see that removing any of these components hurts performance. Although we introduce SR for stabilizing training, we find that it also slightly improves the generative performance (see Sec. B.5 in the appendix for an experiment, stabilized by SR). Reconstruction: <ref type="figure" target="#fig_3">Fig. 5a</ref> visualizes the reconstruction results on CelebA HQ datasets. As we can see, the reconstructed images in NVAE are indistinguishable from the training images.</p><p>Posterior Collapse: Since we are using more latent variables than the data dimensionality, it is natural for the model to turn off many latent variables. However, our KL balancing mechanism (Sec. A) stops a hierarchical group from turning off entirely. In <ref type="figure" target="#fig_4">Fig. 5b</ref>, we visualize KL per group in CIFAR-10 (for 30 groups). Note how most groups obtain a similar KL on average, and only one group is turned off. We apply KL balancing mechanism only during KL warm-up (the first ∼ 25000 iterations). In the remaining iterations, we are using the original VAE objective without any KL balancing (Eq. 1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>In this paper, we proposed Nouveau VAE, a deep hierarchical VAE with a carefully designed architecture. NVAE uses depthwise separable convolutions for the generative model and regular convolutions for the encoder model. We introduced residual parameterization of Normal distributions in the encoder and spectral regularization for stabilizing the training of very deep models. We also presented practical remedies for reducing the memory usage of deep VAEs, enabling us to speed up training by ∼ 2×. NVAE achieves state-of-the-art results on MNIST, CIFAR-10, CelebA 64, and CelebA HQ-256, and it provides a strong baseline on FFHQ-256. To the best of our knowledge, NVAE is the first VAE that can produce large high-quality images and it is trained without changing the objective function of VAEs. Our results show that we can achieve state-of-the-art generative performance by carefully designing neural network architectures for VAEs. The future work includes scaling up the training for larger images, experimenting with more complex normalizing flows, automating the architecture design by neural architecture search, and studying the role of batch normalization in VAEs. We have released our source-code to facilitate research in these directions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Impact Statement</head><p>This paper's contributions are mostly centered around the fundamental challenges in designing expressive neural architectures for image VAEs, and the ideas, here, are examined on commonly used public datasets. This work has applications in content generation, computer graphics, data augmentation, semi-supervised learning, and representation learning.</p><p>VAEs are known to represent the data distribution more faithfully than commonly used generative adversarial networks (GANs), as VAEs do not suffer from the mode collapse problem. Thus, in the long run, enabling VAEs to generate high-quality images will help us reduce bias in the generated content, produce diverse output, and represent minorities better.</p><p>One should also take into consideration that VAEs are trained to mimic the training data distribution, and, any bias introduced in data collection will make VAEs generate samples with a similar bias. Additional bias could be introduced during model design, training, or when VAEs are sampled using small temperatures. Bias correction in generative learning is an active area of research, and we recommend the interested readers to check this area <ref type="bibr" target="#b79">[80]</ref> before building applications using this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Additional Implementation Details</head><p>Warming-up the KL Term: Similar to the previous work, we warm-up the KL term at the beginning of training <ref type="bibr" target="#b42">[43]</ref>. Formally, we optimize the following objective:</p><p>E q(z z z|x x x) [log p(x x x|z z z)] − βKL(q(z z z|x x x)||p(z z z)) , where β is annealed from 0 to 1 at the first 30% of training.</p><p>Balancing the KL Terms: In hierarchical VAEs, the KL term is defined by:</p><formula xml:id="formula_3">KL(q(z z z|x x x)||p(z z z)) = L l=1 E q(z z z &lt;l |x x x) [KL(q(z z z l |x x x, z z z &lt;l )||p(z z z l |z z z &lt;l ))] ,</formula><p>where each KL(q(z z z l |x x x, z z z &lt;l )||p(z z z l |z z z &lt;l )) can be thought as the amount of information encoded in the l th group. In deep hierarchical VAEs, during training, some groups of latent variables can easily become deactivated by matching the approximate posterior with the prior (i.e., posterior collapse). One simple solution is to use KL balancing coefficients <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b65">66]</ref> to ensure that an equal amount of information is encoded in each group using:</p><formula xml:id="formula_4">KL(q(z z z|x x x)||p(z z z)) = L l=1 γ l E q(z z z &lt;l |x x x) [KL(q(z z z l |x x x, z z z &lt;l )||p(z z z l |z z z &lt;l ))] .</formula><p>The balancing coefficient γ l is set to a small value when the KL term is small for that group to encourage the model to use the latent variables in that group, and it is set a large value when the KL term is large. The KL balancing coefficients are only applied during the KL warm-up period, and they are set to 1 afterwards to ensure that we optimize the variational bound. DVAE++ <ref type="bibr" target="#b19">[20]</ref> sets γ l proportional to E x x x∼M E q(z z z &lt;l |x x x) [KL(q(z z z l |x x x, z z z &lt;l )||p(z z z l |z z z &lt;l ))] in each parameter update using the batch M. However, since we have latent variable groups in different scales (i.e., spatial dimensions), we observe that setting γ l proportional to also the size of each group performs better,</p><formula xml:id="formula_5">i.e., γ l ∝ s l E x x x∼M E q(z z z &lt;l |x x x) [KL(q(z z z l |x x x, z z z &lt;l )||p(z z z l |z z z &lt;l ))]</formula><p>Annealing λ λ λ: The coefficient of the smoothness loss λ is set to a fixed value in {10 −2 , 10 −1 } for almost all the experiments. We used 10 −1 only when training was unstable at 10 −2 . However, on Celeb-A HQ and FFHQ, we observe that training is initially unstable unless for λ ∈ {1, 10} which applies a very strong smoothness. For these datasets, we anneal λ with exponential decay from 10 to a small value shown in Table. 6 in the same number of iterations that the KL coefficient is annealed. Note that the smoothness loss is applied to both encoder and decoder. We hypothesize that a sharp decoder may require a sharp encoder, causing more instability in training.</p><p>Weight Normalization (WN): WN cannot be used with BN as BN removes any scaling of weights introduced by WN. However, previous works have seen improvements in using WN for VAEs. In NVAE, we apply WN to any convolutional layer that is not followed by BN, e.g., convolutional layers that produce the parameters of Normal distributions in encoder or decoder.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Inverse Autoregressive Flows (IAFs):</head><p>We apply simple volume-preserving normalizing flows of the form z z z = z z z + b b b(z z z) to the samples generated by the encoder at each level, where b b b(z z z) is produced by an autoregressive network. In each flow operation, the autoregressive network is created using a cell similar to <ref type="figure" target="#fig_3">Fig. 3 (a)</ref> with the masking mechanism introduced in PixelCNN <ref type="bibr" target="#b40">[41]</ref>. In the autoregressive cell, BN is replaced with WN, and SE is omitted, as these operations break the autoregressive dependency. We initially examined non-volume-preserving affine transformations in the form of z z z = a a a(z z z) z z z + b b b(z z z), but we did not observe any improvements. Similar results are reported by Kingma et al. <ref type="bibr" target="#b3">[4]</ref> (See <ref type="table" target="#tab_3">Table 3</ref>).</p><p>Optimization: For all the experiments, we use the AdaMax <ref type="bibr" target="#b80">[81]</ref> optimizer for training with the initial learning rate of 0.01 and with cosine learning rate decay. For FFHQ experiments, we reduce the learning rate to 0.008 to further stabilize the training.</p><p>Image Decoder p(x x x|z z z) : For all the datasets but MNIST, we use the mixture of discretized Logistic distribution <ref type="bibr" target="#b69">[70]</ref>. In MNIST, we use a Bernoulli distribution. Note that in all the cases, our decoder is unconditional across the spatial locations in the image.</p><p>Evaluation: For estimating log-likelihood on the test datasets in evaluation, we use importance weighted sampling using the encoder <ref type="bibr" target="#b10">[11]</ref>. We use 1000 importance weighted samples for evaluation. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Channel Sizes:</head><p>We only set the initial number of channels in the bottom-up encoder. When we downsample the features spatially, we double the number of channels in the encoder. The number of channels is set in the reverse order for the top-down model.</p><p>Expansion Ratio E: The depthwise residual cell in <ref type="figure" target="#fig_3">Fig. 3a</ref> requires setting an expansion ratio E. We use E = 6 similar to MobileNetV2 <ref type="bibr" target="#b45">[46]</ref>. In a few cells, we set E = 3 to reduce the memory. Please see our code for additional details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Datasets:</head><p>We examine NVAE on the dynamically binarized MNIST <ref type="bibr" target="#b71">[72]</ref>, CIFAR-10 <ref type="bibr" target="#b72">[73]</ref>, ImageNet 32 × 32 <ref type="bibr" target="#b73">[74]</ref>, CelebA 64 × 64 <ref type="bibr" target="#b74">[75,</ref><ref type="bibr" target="#b75">76]</ref>, CelebA HQ <ref type="bibr" target="#b27">[28]</ref>, and FFHQ 256×256 <ref type="bibr" target="#b76">[77]</ref>. For all the datasets but FFHQ, we follow Glow <ref type="bibr" target="#b61">[62]</ref> for the train and test splits. In FFHQ, we use 63K images for training, and 7K for test. Images in FFHQ and CelebA HQ are downsampled to 256 × 256 pixels, and are quantized in 5 bits per pixel/channel to have a fair comparison with prior work <ref type="bibr" target="#b61">[62]</ref>.</p><p>Hyperparameters: Given a large number of datasets and the heavy compute requirements, we do not exhaustively optimize the hyperparameters. In our early experiments, we observed that the larger the model is, the better it performs. We often see improvements with wider networks, a larger number of hierarchical groups, and more residual cells per group. However, they also come with smaller training batch size and slower training. We set the number of hierarchical groups to around 30, and we used two residual cells per group. We set the remaining hyperparameters such that the model could be trained in no more than about a week. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Additional Experiments and Visualizations</head><p>In this section, we provide additional insights into NVAE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1 Is NVAE Memorizing the Training Set?</head><p>In VAEs, since we can compute the log-likelihood on a held-out set, we can ensure that the model is not memorizing the training set. In fact, in our experiments, as we increase the model capacity (depth and width), we never observe any overfitting behavior especially on the datasets with large images. In most cases, we stop making the model large because of the compute and training time</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Samples</head><p>Retrieved Images from Training Set considerations. However, since the images generated by NVAE are realistic, this may raise a question on whether NVAE memorizes the training set.</p><p>In <ref type="figure" target="#fig_5">Fig. 6</ref>, we visualize a few samples generated by NVAE and the most similar images from the training data. For measuring the similarity, we downsample the images by 4×, and we measure L 2 distance using the central crop of the images. Since images are aligned, this way we can compare images using the most distinct facial features (eyes, nose, and mouth). As we can see, the sampled images are not present in the training set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 Changing the Temperature of the Prior in NVAE</head><p>It is common to lower the temperature of the prior when sampling from VAEs on challenging datasets. In <ref type="figure" target="#fig_7">Fig. 7</ref>, we examine different temperatures in the prior with different settings for the batch norm layers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.3 Additional Generated Samples</head><p>In <ref type="figure">Fig. 8</ref> and <ref type="figure">Fig. 9</ref>, we visualize additional generated samples by NVAE, trained on CelebA HQ. In these figures, we use higher temperatures (t ∈ {0.6, 0.7, 0.8, 0.9}), but we manually select the samples.</p><p>B.4 More on the Impact of Residual Normal Distributions <ref type="figure" target="#fig_9">Fig. 10</ref> visualizes the total number of active channels in all latent variables during training. Here, we compare the residual Normal distributions against the model that predicts the absolute parameters of the Normal distributions in the approximate posterior. This figure corresponds to the experiment that we reported in <ref type="table">Table.</ref> 4. As we can see, in the initial stage of training, the model without residual distributions turns off more latent variables.  : Randomly sampled images from NVAE with different temperatures in the prior for the CelebA HQ dataset (best seen when zoomed in). In the batch normalization layers during sampling, we examine two settings: i) the default mode that uses the running averages from training (on the left), and ii) readjusted mode in which the running averages are re-tuned by sampling from the model 500 times with the given temperature (on the right). Readjusted BN statistics improve the diversity and quality of the images, especially for small temperatures. <ref type="figure">Figure 8</ref>: Additional 256×256-pixel samples generated by NVAE, trained on CelebA HQ <ref type="bibr" target="#b27">[28]</ref>. In this figure, we use higher temperatures (t ∈ {0.6, 0.7, 0.8, 0.9}), but we manually select the samples. <ref type="figure">Figure 9</ref>: Additional 256×256-pixel samples generated by NVAE, trained on CelebA HQ <ref type="bibr" target="#b27">[28]</ref>. In this figure, we use higher temperatures (t ∈ {0.6, 0.7, 0.8, 0.9}), but we manually select the samples.   <ref type="table">Table.</ref> 4)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.5 Stabilizing the Training with Spectral Regularization</head><p>In our experiments, we came across many cases whose training was unstable due to the KL term, and it was stabilized by spectral regularization. Initially, instead of spectral regularization, we examined common approaches such as gradient clipping or limiting the parameters of the Normal distributions to a small range. But, none could stabilize the training without negatively affecting the performance. <ref type="figure">Fig. 11</ref> shows an experiment on the FFHQ dataset. The training is stabilized by increasing the spectral regularization coefficient (λ) from 0.1 to 1.0.  <ref type="figure">Figure 11</ref>: An example experiment on the FFHQ dataset. All the hyper-parameters are identical between the two runs. However, training is unstable due to the KL term in the objective. We stabilize the training by increasing the spectral regularization coefficient λ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.6 Long-Range Correlations</head><p>NVAE's hierarchical structure is composed of many latent variable groups operating at different scales. For example, on CelebA HQ 256 × 256, the generative model consists of five scales. It starts from a spatially arranged latent variable group of the size 8 × 8 at the top, and it samples from the hierarchy group-by-group while gradually doubling the spatial dimensions up to 128 × 128.</p><p>A natural question to ask is what information is captured at different scales. In <ref type="figure" target="#fig_1">Fig. 12</ref>, we visualize how the generator's output changes as we fix the samples at different scales. As we can see, the global long-range correlations are captured mostly at the top of the hierarchy, and the local variations are recorded at the lower groups. In each row, we fix the samples at a number of top scales and we sample from the rest of the hierarchy. As we can see, the long-range global structure is mostly recorded at the top of the hierarchy in the 8 × 8 dimensional groups. The second scale does apply some global modifications such as changing eyes, hair color, skin tone, and the shape of the face. The bottom groups capture mostly low-level variations. However, the lowest scale can still make some subtle long-range modifications. For example, the hair color is slightly modified when we are only sampling from the lowest scale in the last row. This is potentially enabled because of the large receptive field in our depthwise separable residual cell.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>The neural networks implementing an encoder q(z z z|x x x) and generative model p(x x x, z z z) for a 3-group hierarchical VAE. r denotes residual neural networks, + denotes feature combination (e.g., concatenation), and h is a trainable parameter.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>(a) MNIST (t = 1.0) (b) CIFAR-10 (t = 0.7) (c) CelebA 64 (t = 0.6) (d) CelebA HQ (t = 0.6) (e) FFHQ (t = 0.5) (f) MaCow [67] trained on CelebA HQ (t = 0.7) (g) Glow [62] trained on CelebA HQ (t = 0.7)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>( a )</head><label>a</label><figDesc>Reconstruction results (best seen when zoomed in). Average KL per group.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>(a) Input input on the left and reconstructed images on the right for CelebA HQ. (b) KL per group on CIFAR-10.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Top retrieved images from the training set are visualized for samples generated by NVAE in each row. The generated instances do not exist in the training set (best seen when zoomed in).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7</head><label>7</label><figDesc>Figure 7: Randomly sampled images from NVAE with different temperatures in the prior for the CelebA HQ dataset (best seen when zoomed in). In the batch normalization layers during sampling, we examine two settings: i) the default mode that uses the running averages from training (on the left), and ii) readjusted mode in which the running averages are re-tuned by sampling from the model 500 times with the given temperature (on the right). Readjusted BN statistics improve the diversity and quality of the images, especially for small temperatures.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 10 :</head><label>10</label><figDesc>The total number of active channels in z z z is reported for two models with and without residual distributions. The model with residual distribution keeps more latent variables active in the KL warm-up phase (up to 8K iterations), and it achieves a better KL value at the end of the training (see</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 12 :</head><label>12</label><figDesc>Where does our hierarchical model capture long-range correlations? NVAE on CelebA HQ consists of latent variable groups that are operating at five scales (starting from 8 × 8 up to 128 × 128).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table><row><cell cols="4">Normalization &amp; activation</cell></row><row><cell cols="4">Functions L = 10 L = 20 L = 40</cell></row><row><cell cols="2">WN + ELU 3.36</cell><cell>3.27</cell><cell>3.31</cell></row><row><cell>BN + ELU</cell><cell>3.36</cell><cell>3.26</cell><cell>3.22</cell></row><row><cell cols="2">BN + Swish 3.34</cell><cell>3.23</cell><cell>3.16</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Residual cells in NVAE</figDesc><table><row><cell cols="2">Bottom-up Top-down Test Train Mem.</cell></row><row><cell>model</cell><cell>model (bpd) time (h) (GB)</cell></row><row><cell cols="2">Regular Regular 3.11 43.3 6.3</cell></row><row><cell cols="2">Separable Regular 3.12 49.0 10.6</cell></row><row><cell cols="2">Regular Separable 3.07 48.0 10.7</cell></row><row><cell cols="2">Separable Separable 3.07 50.4 14.9</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>The impact of residual dist. KL Rec. LVAE LL w/ Res. Dist. 53 1.32 1.80 3.12 3.16 w/o Res. Dist. 54 1.36 1.80 3.16 3.19</figDesc><table><row><cell>Model</cell><cell># Act.</cell><cell>Training</cell><cell>Test</cell></row><row><cell></cell><cell>z z z</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>SR &amp; SE</figDesc><table><row><cell>Model</cell><cell>Test NLL</cell></row><row><cell>NVAE</cell><cell>3.16</cell></row><row><cell cols="2">NVAE w/o SR 3.18</cell></row><row><cell>NVAE w/o SE</cell><cell>3.22</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>Sampling Speed: Due to the unconditional decoder, NVAE's sampling is fast. On a 12-GB Titan V GPU, we can sample a batch of 36 images of the size 256×256 px in 2.03 seconds (56 ms/image). MaCow<ref type="bibr" target="#b66">[67]</ref> reports 434.2 ms/image in a similar batched-sampling experiment (∼ 8× slower).</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 6 :</head><label>6</label><figDesc>A summary of hyperparameters used in training NVAE with additional information. D 2 indicates a latent variable with the spatial dimensions of D × D. As an example, the MNIST model consists of 15 groups of latent variables in total, covering two different scales. In the first scale, we have five groups of 4 × 4 × 20-dimensional latent variables (in the form of height×width×channel). In the second scale, we have 10 groups of 8 × 8 × 20-dimensional variables. A smaller model with 24 initial channels instead of 32, could be trained on only 8 GPUs in the same time (with the batch size of 6). The smaller models obtain only 0.01 bpd higher negative log-likelihood on these datasets.</figDesc><table><row><cell>Hyperparamter</cell><cell>MNIST</cell><cell>CIFAR-10</cell><cell>ImageNet</cell><cell>CelebA</cell><cell>CelebA HQ</cell><cell>FFHQ</cell></row><row><cell></cell><cell>28×28</cell><cell>32×32</cell><cell>32×32</cell><cell>64×64</cell><cell>256×256</cell><cell>256×256</cell></row><row><cell># epochs</cell><cell>400</cell><cell>400</cell><cell>45</cell><cell>90</cell><cell>300</cell><cell>200</cell></row><row><cell>batch size per GPU</cell><cell>200</cell><cell>32</cell><cell>24</cell><cell>16</cell><cell>4</cell><cell>4</cell></row><row><cell># normalizing flows</cell><cell>0</cell><cell>2</cell><cell>2</cell><cell>2</cell><cell>4</cell><cell>4</cell></row><row><cell># latent variable scales</cell><cell>2</cell><cell>1</cell><cell>1</cell><cell>3</cell><cell>5</cell><cell>5</cell></row><row><cell># groups in each scale</cell><cell>5, 10</cell><cell>30</cell><cell>28</cell><cell>5, 10, 20</cell><cell>4, 4, 4, 8, 16</cell><cell>4, 4, 4, 8, 16</cell></row><row><cell>spatial dims of z z z in each scale</cell><cell>4 2 , 8 2</cell><cell>16 2</cell><cell>16 2</cell><cell cols="3">8 2 , 16 2 , 32 2 8 2 , 16 2 , 32 2 , 8 2 , 16 2 , 32 2 , 64 2 , 128 2 64 2 , 128 2</cell></row><row><cell># channel in z z z</cell><cell>20</cell><cell>20</cell><cell>20</cell><cell>20</cell><cell>20</cell><cell>20</cell></row><row><cell># initial channels in enc.</cell><cell>32</cell><cell>128</cell><cell>192</cell><cell>64</cell><cell>30</cell><cell>30</cell></row><row><cell># residual cells per group</cell><cell>1</cell><cell>2</cell><cell>2</cell><cell>2</cell><cell>2</cell><cell>2</cell></row><row><cell>λ</cell><cell>0.01</cell><cell>0.1</cell><cell>0.01</cell><cell>0.1</cell><cell>0.01</cell><cell>0.1</cell></row><row><cell>GPU type</cell><cell cols="6">16-GB V100 16-GB V100 32-GB V100 16-GB V100 32-GB V100 32-GB V100</cell></row><row><cell># GPUs</cell><cell>2</cell><cell>8</cell><cell>24</cell><cell>8</cell><cell>24 *</cell><cell>24 *</cell></row><row><cell>total train time (h)</cell><cell>21</cell><cell>55</cell><cell>70</cell><cell>92</cell><cell>94</cell><cell>160</cell></row></table><note>*</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>Table. 6 summarizes the hyperparameters used in our experiments.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">A k × k regular convolution, mapping a C-channel tensor to the same size, has k 2 C 2 parameters and computational complexity of O(k 2 C 2 ) per spatial location, whereas a depthwise convolution operating in the same regime has k 2 C parameters and O(k 2 C) complexity per location.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Swish cannot be done in place and it requires additional memory for the backward pass.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">For the evaluation in Sec. 4.1, we do use the default setting to ensure that our reported results are valid.<ref type="bibr" target="#b3">4</ref> This intriguing effect of BN on VAEs and GANs requires further study in future work. We could not obtain the same quantitative and qualitative results with instance norm which is a batch-independent extension to BN.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">To measure the number of the active channels, the average of KL across training batch and spatial dimensions is computed for each channel in latent variables. A channel is considered active if the average is above 0.1.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>The authors would like to thank Karsten Kreis and Margaret Albrecht for providing feedback on the early version of this work. They also would like to extend their sincere gratitude to Sangkug Lym for providing suggestions for accelerating NVAE. Last but not least, they are grateful to Sabu Nadarajan, Nithya Natesan, Sivakumar Arayandi Thottakara, and Jung Seok Jin for providing compute support.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Auto-encoding variational bayes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Stochastic backpropagation and approximate inference in deep generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danilo</forename><surname>Jimenez Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shakir</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1278" to="1286" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danilo</forename><surname>Jimenez Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shakir</forename><surname>Mohamed</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1505.05770</idno>
		<title level="m">Variational inference with normalizing flows</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Improved variational inference with inverse autoregressive flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rafal</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4743" to="4751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Draw: A recurrent neural network for image generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karol</forename><surname>Gregor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivo</forename><surname>Danihelka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danilo</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1462" to="1471" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Inference suboptimality in variational autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Cremer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuechen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Duvenaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th International Conference on Machine Learning</title>
		<meeting>the 35th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Iterative amortized inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joe</forename><surname>Marino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yisong</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Mandt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th International Conference on Machine Learning</title>
		<meeting>the 35th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Auxiliary deep generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><surname>Maaløe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Casper</forename><forename type="middle">Kaae</forename><surname>Sønderby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ole</forename><surname>Søren Kaae Sønderby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Winther</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 33rd International Conference on Machine Learning</title>
		<meeting>The 33rd International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Hierarchical variational models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajesh</forename><surname>Ranganath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dustin</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 33rd International Conference on Machine Learning</title>
		<meeting>The 33rd International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Undirected graphical models as approximate posteriors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arash</forename><surname>Vahdat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeny</forename><surname>Andriyash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">G</forename><surname>Macready</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuri</forename><surname>Burda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger</forename><surname>Grosse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1509.00519</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">Importance weighted autoencoders. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Rényi divergence variational inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingzhen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">E</forename><surname>Turner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1073" to="1081" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Bidirectional Helmholtz machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jorg</forename><surname>Bornschein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samira</forename><surname>Shabanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asja</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2511" to="2519" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The thermodynamic variational objective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vaden</forename><surname>Masrani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tuan</forename><forename type="middle">Anh</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Wood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="11521" to="11530" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Sticking the landing: Simple, lower-variance gradient estimators for variational inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Roeder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhuai</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">K</forename><surname>Duvenaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6925" to="6934" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Doubly reparameterized gradient estimators for Monte Carlo objectives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dieterich</forename><surname>Lawson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shixiang</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><forename type="middle">J</forename><surname>Maddison</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04152</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">The concrete distribution: A continuous relaxation of discrete random variables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andriy</forename><surname>Chris J Maddison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee Whye</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Teh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.00712</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shixiang</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Poole</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.01144</idno>
		<title level="m">Categorical reparameterization with Gumbel-Softmax</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Tyler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rolfe</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1609.02200</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">Discrete variational autoencoders. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">DVAE++: Discrete variational autoencoders with overlapping transformations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arash</forename><surname>Vahdat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">G</forename><surname>Macready</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengbing</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Khoshaman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeny</forename><surname>Andriyash</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">DVAE#: Discrete variational autoencoders with relaxed Boltzmann priors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arash</forename><surname>Vahdat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeny</forename><surname>Andriyash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">G</forename><surname>Macready</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">REBAR: Low-variance, unbiased gradient estimates for discrete latent variable models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andriy</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><forename type="middle">J</forename><surname>Maddison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Lawson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jascha</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2624" to="2633" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Backpropagation through the void: Optimizing control variates for black-box gradient estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Grathwohl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dami</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhuai</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoff</forename><surname>Roeder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Duvenaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Generating sentences from a continuous space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Samuel R Bowman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vilnis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rafal</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 20th SIGNLL Conference on Computational Natural Language Learning</title>
		<meeting>The 20th SIGNLL Conference on Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="10" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Preventing posterior collapse with delta-vaes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Razavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aäron</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vinyals</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishaan</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kundan</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Faruk</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrien</forename><forename type="middle">Ali</forename><surname>Taiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesco</forename><surname>Visin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Vazquez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.05013</idno>
		<title level="m">PixelVAE: A latent variable model for natural images</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Don&apos;t blame the elbo! a linear vae perspective on posterior collapse</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Roger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Grosse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Norouzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9403" to="9413" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Progressive growing of GANs for improved quality, stability, and variation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tero</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Aila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuli</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaakko</forename><surname>Lehtinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Information maximization in noisy channels: A variational approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Barber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Felix V Agakov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Deep variational information bottleneck</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Alexander A Alemi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">V</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Dillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Murphy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The International Conference on Learning Representations (ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Opening the black box of deep neural networks via information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ravid</forename><surname>Shwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-Ziv</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naftali</forename><surname>Tishby</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.00810</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">On the quantitative analysis of decoder-based generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhuai</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuri</forename><surname>Burda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger</forename><surname>Grosse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The International Conference on Learning Representations (ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">The challenge of realistic music generation: modelling raw audio at scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sander</forename><surname>Dieleman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7989" to="7999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">PixelSNAIL: An improved autoregressive generative model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikhil</forename><surname>Xi Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mostafa</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Rohaninejad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hossein</forename><surname>Sadeghi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeny</forename><surname>Andriyash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Walter</forename><surname>Vinci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenzo</forename><surname>Buffoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad H</forename><surname>Amin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.09948</idno>
		<title level="m">Pixelvae++: Improved pixelvae with discrete prior</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">BIVA: A very deep hierarchy of latent variables for generative modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><surname>Maaløe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Fraccaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Valentin</forename><surname>Liévin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ole</forename><surname>Winther</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6548" to="6558" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="448" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Learning visual representations at scale. ICLR invited talk</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Xception: Deep learning with depthwise separable convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">François</forename><surname>Chollet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1251" to="1258" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Generating diverse high-fidelity images with vq-vae-2</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Razavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="14837" to="14847" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Pixel recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aäron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd International Conference on International Conference on Machine Learning</title>
		<meeting>the 33rd International Conference on International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1747" to="1756" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Towards conceptual compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karol</forename><surname>Gregor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frederic</forename><surname>Besse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danilo</forename><surname>Jimenez Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivo</forename><surname>Danihelka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances In Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3549" to="3557" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Ladder variational autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tapani</forename><surname>Casper Kaae Sønderby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><surname>Raiko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Maaløe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ole</forename><surname>Søren Kaae Sønderby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Winther</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3738" to="3746" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Learning hierarchical priors in vaes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexej</forename><surname>Klushyn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nutan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Kurle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Botond</forename><surname>Cseke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Van Der</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smagt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Mobilenetv2: Inverted residuals and linear bottlenecks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menglong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrey</forename><surname>Zhmoginov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4510" to="4520" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Weight normalization: A simple reparameterization to accelerate training of deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Durk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kingma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">29</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prajit</forename><surname>Ramachandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.05941</idno>
		<title level="m">Searching for activation functions</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Efficientnet: Rethinking model scaling for convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6105" to="6114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Residual flows for invertible generative modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">Q</forename><surname>Ricky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Behrmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jörn-Henrik</forename><surname>Duvenaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jacobsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Fast and accurate deep network learning by exponential linear units (elus)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Djork-Arné</forename><surname>Clevert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.07289</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Squeeze-and-excitation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.01507</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Identity mappings in deep residual networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="630" to="645" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Nvidia. Nvidia/apex</title>
		<imprint>
			<date type="published" when="2020-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Training deep nets with sublinear memory cost</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chiyuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Guestrin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1604.06174</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Training deep and recurrent networks with hessian-free optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Martens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural networks: Tricks of the trade</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="479" to="535" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuichi</forename><surname>Yoshida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeru</forename><surname>Miyato</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.10941</idno>
		<title level="m">Spectral norm regularization for improving the generalizability of deep learning</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Spectral normalization for generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeru</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toshiki</forename><surname>Kataoka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masanori</forename><surname>Koyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuichi</forename><surname>Yoshida</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Vflow: More expressive generative flows with variational data augmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Biqi</forename><surname>Chenli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tian</forename><surname>Tian</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.09741</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Wei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Dinh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.07101</idno>
		<title level="m">Augmented normalizing flows: Bridging the gap between generative flows and latent variable models</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Flow++: Improving flow-based generative models with variational dequantization and architecture design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aravind</forename><surname>Srinivas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Conference on Machine Learning</title>
		<meeting>the 36th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Glow: Generative flow with invertible 1x1 convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Durk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prafulla</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dhariwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 31</title>
		<editor>S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett</editor>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="10236" to="10245" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Dinh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.08803</idno>
		<title level="m">Jascha Sohl-Dickstein, and Samy Bengio. Density estimation using real NVP</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Vae with a vampprior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakub</forename><surname>Tomczak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1214" to="1223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">MAE: Mutual posterior-divergence regularization for variational autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuezhe</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunting</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prafulla</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schulman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.02731</idno>
		<title level="m">Ilya Sutskever, and Pieter Abbeel. Variational lossy autoencoder</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">MaCow: Masked convolutional generative flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuezhe</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shanghang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Generating high fidelity images with subscale pixel networks and multidimensional upscaling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Menick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Image transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Ku</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dustin</forename><surname>Tran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">PixelCNN++: Improving the pixelCNN with discretized logistic mixture likelihood and other modifications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik P</forename><surname>Kingma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.05517</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Conditional image generation with pixelCNN decoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lasse</forename><surname>Espeholt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4790" to="4798" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<title level="m" type="main">The mnist database of handwritten digits</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<ptr target="http://yann.lecun.com/exdb/mnist/" />
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">ImageNet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Deep learning face attributes in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Computer Vision (ICCV)</title>
		<meeting>International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2015-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Autoencoding beyond pixels using a learned similarity metric</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Boesen Lindbo Larsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Søren</forename><forename type="middle">Kaae</forename><surname>Sønderby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ole</forename><surname>Winther</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning. PMLR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">A style-based generator architecture for generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tero</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuli</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Aila</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4401" to="4410" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Large scale GAN training for high fidelity natural image synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Brock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
		<title level="m" type="main">Unsupervised representation learning with deep convolutional generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06434</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Bias correction of learned generative models using likelihood-free importance weighting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Grover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaming</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Kapoor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alekh</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">J</forename><surname>Horvitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Ermon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="11056" to="11068" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
