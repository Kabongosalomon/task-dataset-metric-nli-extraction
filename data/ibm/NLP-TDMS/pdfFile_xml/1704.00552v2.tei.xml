<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Transition-Based Directed Acyclic Graph Parser for UCCA</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2017-04-04">4 Apr 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Hershcovich</surname></persName>
							<email>danielh@cs.huji.ac.il</email>
							<affiliation key="aff0">
								<orgName type="department">The Edmond and Lily Safra Center for Brain Sciences</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">Hebrew University of Jerusalem</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omri</forename><surname>Abend</surname></persName>
							<email>oabend@cs.huji.ac.il</email>
							<affiliation key="aff1">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">Hebrew University of Jerusalem</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ari</forename><surname>Rappoport</surname></persName>
							<email>arir@cs.huji.ac.il</email>
							<affiliation key="aff1">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">Hebrew University of Jerusalem</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">A Transition-Based Directed Acyclic Graph Parser for UCCA</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2017-04-04">4 Apr 2017</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T12:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present the first parser for UCCA, a cross-linguistically applicable framework for semantic representation, which builds on extensive typological work and supports rapid annotation. UCCA poses a challenge for existing parsing techniques, as it exhibits reentrancy (resulting in DAG structures), discontinuous structures and non-terminal nodes corresponding to complex semantic units. To our knowledge, the conjunction of these formal properties is not supported by any existing parser. Our transition-based parser, which uses a novel transition set and features based on bidirectional LSTMs, has value not just for UCCA parsing: its ability to handle more general graph structures can inform the development of parsers for other semantic DAG structures, and in languages that frequently use discontinuous structures.</p><p>Shashi Narayan and Claire Gardent. 2014. Hybrid simplification using deep semantics and machine translation. In Proc. of ACL. pages 435-445. . 2015. SemEval 2015 task 18: Broad-coverage semantic dependency parsing. In Proc. of SemEval. pages 915-926.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Universal Conceptual Cognitive Annotation (UCCA, <ref type="bibr" target="#b0">Abend and Rappoport, 2013)</ref> is a cross-linguistically applicable semantic representation scheme, building on the established Basic Linguistic Theory typological framework <ref type="bibr" target="#b18">(Dixon, 2010a</ref><ref type="bibr">(Dixon, ,b, 2012</ref>, and Cognitive Linguistics literature <ref type="bibr" target="#b16">(Croft and Cruse, 2004)</ref>. It has demonstrated applicability to multiple languages, including English, French, German and Czech, support for rapid annotation by non-experts (assisted by an accessible annotation interface ), and stability under translation <ref type="bibr">(Sulem et al., 2015)</ref>. It has also proven useful for machine translation evaluation <ref type="bibr" target="#b11">(Birch et al., 2016)</ref>. UCCA differs from syntactic schemes in terms of content and formal structure. It exhibits reentrancy, discontinuous nodes and non-terminals, which no single existing parser supports. Lacking a parser, UCCA's applicability has been so far limited, a gap this work addresses.</p><p>We present the first UCCA parser, TUPA (Transition-based UCCA Parser), building on recent advances in discontinuous constituency and dependency graph parsing, and further introducing novel transitions and features for UCCA. Transition-based techniques are a natural starting point for UCCA parsing, given the conceptual similarity of UCCA's distinctions, centered around predicate-argument structures, to distinctions expressed by dependency schemes, and the achievements of transition-based methods in dependency parsing <ref type="bibr" target="#b22">(Dyer et al., 2015;</ref><ref type="bibr" target="#b8">Andor et al., 2016;</ref><ref type="bibr">Kiperwasser and Goldberg, 2016)</ref>.</p><p>We are further motivated by the strength of transition-based methods in related tasks, including dependency graph parsing <ref type="bibr">(Sagae and Tsujii, 2008;</ref><ref type="bibr">Ribeyre et al., 2014;</ref><ref type="bibr">Tokgöz and Eryigit, 2015)</ref>, constituency parsing <ref type="bibr">(Sagae and Lavie, 2005;</ref><ref type="bibr">Zhang and Clark, 2009;</ref><ref type="bibr">Zhu et al., 2013;</ref><ref type="bibr">Maier, 2015;</ref><ref type="bibr">Maier and Lichte, 2016)</ref>, AMR parsing <ref type="bibr">(Wang et al., 2015a</ref><ref type="bibr">(Wang et al., ,b, 2016</ref><ref type="bibr">Misra and Artzi, 2016;</ref><ref type="bibr" target="#b28">Goodman et al., 2016;</ref><ref type="bibr">Zhou et al., 2016;</ref><ref type="bibr" target="#b17">Damonte et al., 2017)</ref> and CCG parsing <ref type="bibr">(Zhang and Clark, 2011;</ref><ref type="bibr" target="#b6">Ambati et al., 2015</ref><ref type="bibr" target="#b7">Ambati et al., , 2016</ref>.</p><p>We evaluate TUPA on the English UCCA corpora, including in-domain and out-of-domain settings. To assess the ability of existing parsers to tackle the task, we develop a conversion procedure from UCCA to bilexical graphs and trees. Results show superior performance for TUPA, demonstrating the effectiveness of the presented approach. <ref type="bibr">1</ref> The rest of the paper is structured as follows: Section 2 describes UCCA in more detail. Section 3 introduces TUPA. Section 4 discusses the data and experimental setup. Section 5 presents the experimental results. Section 6 summarizes related work, and Section 7 concludes the paper.</p><p>2 The UCCA Scheme UCCA graphs are labeled, directed acyclic graphs (DAGs), whose leaves correspond to the tokens of the text. A node (or unit) corresponds to a terminal or to several terminals (not necessarily contiguous) viewed as a single entity according to semantic or cognitive considerations. Edges bear a category, indicating the role of the sub-unit in the parent relation. <ref type="figure" target="#fig_0">Figure 1</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>presents a few examples.</head><p>UCCA is a multi-layered representation, where each layer corresponds to a "module" of semantic distinctions. UCCA's foundational layer, targeted in this paper, covers the predicate-argument structure evoked by predicates of all grammatical categories <ref type="bibr">(verbal, nominal, adjectival and others)</ref>, the inter-relations between them, and other major linguistic phenomena such as coordination and multi-word expressions. The layer's basic notion is the scene, describing a state, action, movement or some other relation that evolves in time. Each scene contains one main relation (marked as either a Process or a State), as well as one or more Participants. For example, the sentence "After graduation, John moved to Paris" <ref type="figure" target="#fig_0">(Figure 1a</ref>) contains two scenes, whose main relations are "graduation" and "moved". "John" is a Participant in both scenes, while "Paris" only in the latter. Further categories account for inter-scene relations and the internal structure of complex arguments and relations (e.g. coordination, multi-word expressions and modification).</p><p>One incoming edge for each non-root node is marked as primary, and the rest (mostly used for implicit relations and arguments) as remote edges, a distinction made by the annotator. The primary edges thus form a tree structure, whereas the remote edges enable reentrancy, forming a DAG.</p><p>While parsing technology in general, and transition-based parsing in particular, is wellestablished for syntactic parsing, UCCA has several distinct properties that distinguish it from syntactic representations, mostly UCCA's tendency to abstract away from syntactic detail that do not affect argument structure. For instance, consider the following examples where the concept of a scene has a different rationale from the syntactic concept of a clause. First, non-verbal predicates in UCCA are represented like verbal ones, such as when they appear in copula clauses or noun phrases. Indeed, in <ref type="figure" target="#fig_0">Figure 1a</ref>, "graduation" and "moved" are considered separate events, despite appearing in the same clause. Second, in the same example, "John" is marked as a (remote) Participant in the graduation scene, despite not being overtly marked. Third, consider the possessive construction in <ref type="bibr">Figure 1c</ref>. While in UCCA "trip" evokes a scene in which "John and Mary" is a Participant, a syntactic scheme would analyze this phrase similarly to "John and Mary's shoes".</p><p>These examples demonstrate that a UCCA parser, and more generally semantic parsers, face an additional level of ambiguity compared to their syntactic counterparts (e.g., "after graduation" is formally very similar to "after 2pm", which does not evoke a scene). Section 6 discusses UCCA in the context of other semantic schemes, such as AMR <ref type="bibr" target="#b10">(Banarescu et al., 2013)</ref>.</p><p>Alongside recent progress in dependency parsing into projective trees, there is increasing interest in parsing into representations with more general structural properties (see Section 6). One such property is reentrancy, namely the sharing of semantic units between predicates. For in-stance, in <ref type="figure" target="#fig_0">Figure 1a</ref>, "John" is an argument of both "graduation" and "moved", yielding a DAG rather than a tree. A second property is discontinuity, as in <ref type="figure" target="#fig_0">Figure 1b</ref>, where "gave up" forms a discontinuous semantic unit. Discontinuities are pervasive, e.g., with multi-word expressions <ref type="bibr">(Schneider et al., 2014)</ref>. Finally, unlike most dependency schemes, UCCA uses non-terminal nodes to represent units comprising more than one word. The use of non-terminal nodes is motivated by constructions with no clear head, including coordination structures (e.g., "John and Mary" in <ref type="figure" target="#fig_0">Figure 1c</ref>), some multi-word expressions (e.g., "The Haves and the Have Nots"), and prepositional phrases (either the preposition or the head noun can serve as the constituent's head). To our knowledge, no existing parser supports all structural properties required for UCCA parsing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Transition-based UCCA Parsing</head><p>We now turn to presenting TUPA. Building on previous work on parsing reentrancies, discontinuities and non-terminal nodes, we define an extended set of transitions and features that supports the conjunction of these properties.</p><p>Transition-based parsers <ref type="bibr">(Nivre, 2003)</ref> scan the text from start to end, and create the parse incrementally by applying a transition at each step to the parser's state, defined using three data structures: a buffer B of tokens and nodes to be processed, a stack S of nodes currently being processed, and a graph G = (V, E, ℓ) of constructed nodes and edges, where V is the set of nodes, E is the set of edges, and ℓ : E → L is the label function, L being the set of possible labels. Some states are marked as terminal, meaning that G is the final output. A classifier is used at each step to select the next transition based on features encoding the parser's current state. During training, an oracle creates training instances for the classifier, based on gold-standard annotations.</p><p>Transition Set. Given a sequence of tokens w 1 , . . . , w n , we predict a UCCA graph G over the sequence. Parsing starts with a single node on the stack (an artificial root node), and the input tokens in the buffer. <ref type="figure">Figure 2</ref> shows the transition set.</p><p>In addition to the standard SHIFT and REDUCE operations, we follow previous work in transitionbased constituency parsing <ref type="bibr">(Sagae and Lavie, 2005)</ref>, adding the NODE transition for creating new non-terminal nodes. For every X ∈ L, NODE X creates a new node on the buffer as a parent of the first element on the stack, with an Xlabeled edge. LEFT-EDGE X and RIGHT-EDGE X create a new primary X-labeled edge between the first two elements on the stack, where the parent is the left or the right node, respectively. As a UCCA node may only have one incoming primary edge, EDGE transitions are disallowed if the child node already has an incoming primary edge. LEFT-REMOTE X and RIGHT-REMOTE X do not have this restriction, and the created edge is additionally marked as remote. We distinguish between these two pairs of transitions to allow the parser to create remote edges without the possibility of producing invalid graphs. To support the prediction of multiple parents, node and edge transitions leave the stack unchanged, as in other work on transition-based dependency graph parsing <ref type="bibr">(Sagae and Tsujii, 2008;</ref><ref type="bibr">Ribeyre et al., 2014;</ref><ref type="bibr">Tokgöz and Eryigit, 2015)</ref>. REDUCE pops the stack, to allow removing a node once all its edges have been created. To handle discontinuous nodes, SWAP pops the second node on the stack and adds it to the top of the buffer, as with the similarly named transition in previous work <ref type="bibr">(Nivre, 2009;</ref><ref type="bibr">Maier, 2015)</ref>. Finally, FINISH pops the root node and marks the state as terminal.</p><p>Classifier. The choice of classifier and feature representation has been shown to play an important role in transition-based parsing <ref type="bibr" target="#b13">(Chen and Manning, 2014;</ref><ref type="bibr" target="#b8">Andor et al., 2016;</ref><ref type="bibr">Kiperwasser and Goldberg, 2016)</ref>. To investigate the impact of the type of transition classifier in UCCA parsing, we experiment with three different models. </p><formula xml:id="formula_0">S x | B V E SHIFT S | x B V E − S | x B V E REDUCE S B V E − S | x B V E NODE X S | x y | B V ∪ {y} E ∪ {(y, x) X } − x = root S | y, x B V E LEFT-EDGE X S | y, x B V E ∪ {(x, y) X } −    x ∈ w 1:n , y = root, y ❀ G x S | x, y B V E RIGHT-EDGE X S | x, y B V E ∪ {(x, y) X } − S | y, x B V E LEFT-REMOTE X S | y, x B V E ∪ {(x, y) * X } − S | x, y B V E RIGHT-REMOTE X S | x, y B V E ∪ {(x, y) * X } − S | x, y B V E SWAP S | y x | B V E − i(x) &lt; i(y) [root] ∅ V E FINISH ∅ ∅ V E + Figure 2:</formula><p>The transition set of TUPA. We write the stack with its top to the right and the buffer with its head to the left. (·, ·)X denotes a primary X-labeled edge, and (·, ·) * X a remote X-labeled edge. i(x) is a running index for the created nodes. In addition to the specified conditions, the prospective child in an EDGE transition must not already have a primary parent.</p><p>uses an architecture similar to that of <ref type="bibr" target="#b13">Chen and Manning (2014)</ref>, but with two rectified linear layers instead of one layer with cube activation. The embeddings and classifier are trained jointly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Finally, TUPA BiLSTM uses a bidirectional</head><p>LSTM for feature representation, on top of the dense embedding features, an architecture similar to Kiperwasser and <ref type="bibr">Goldberg (2016)</ref>. The BiLSTM runs on the input tokens in forward and backward directions, yielding a vector representation that is then concatenated with dense features representing the parser state (e.g., existing edge labels and previous parser actions; see below). This representation is then fed into a feedforward network similar to TUPA MLP . The feedforward layers, BiLSTM and embeddings are all trained jointly.</p><p>For all classifiers, inference is performed greedily, i.e., without beam search. Hyperparameters are tuned on the development set (see Section 4).</p><p>Features. TUPA Sparse uses binary indicator features representing the words, POS tags, syntactic dependency labels and existing edge labels related to the top four stack elements and the next three buffer elements, in addition to their children and grandchildren in the graph. We also use bi-and trigram features based on these values <ref type="bibr">(Zhang and Clark, 2009;</ref><ref type="bibr">Zhu et al., 2013)</ref>, features related to discontinuous nodes (Maier, 2015, including separating punctuation and gap type), features representing existing edges and the number of parents and children, as well as the past actions taken by the parser. In addition, we use use a novel, UCCA-specific feature: number of remote children. <ref type="bibr">3</ref> For TUPA MLP and TUPA BiLSTM , we replace all indicator features by a concatenation of the vector embeddings of all represented elements: words, POS tags, syntactic dependency labels, edge labels, punctuation, gap type and parser actions. These embeddings are initialized randomly. We additionally use external word embeddings initialized with pre-trained word2vec vectors <ref type="bibr">(Mikolov et al., 2013)</ref>, 4 updated during training. In addition to dropout between NN layers, we apply word dropout (Kiperwasser and <ref type="bibr">Goldberg, 2016)</ref>: with a certain probability, the embedding for a word is replaced with a zero vector. We do not apply word dropout to the external word embeddings.</p><p>Finally, for all classifiers we add a novel realvalued feature to the input vector, ratio, corresponding to the ratio between the number of terminals to number of nodes in the graph G. This feature serves as a regularizer for the creation of new nodes, and should be beneficial for other transition-based constituency parsers too.</p><p>Training. For training the transition classifiers, we use a dynamic oracle <ref type="bibr" target="#b27">(Goldberg and Nivre, 2012)</ref>, i.e., an oracle that outputs a set of optimal transitions: when applied to the current parser state, the gold standard graph is reachable from the resulting state. For example, the oracle would predict a NODE transition if the stack has on its top a parent in the gold graph that has not been created, but would predict a RIGHT-EDGE transition if the second stack element is a parent of the first element according to the gold graph and the edge between them has not been created. The transition predicted by the classifier is deemed correct and is applied to the parser state to reach the subsequent state, if the transition is included in the set of optimal transitions. Otherwise, a random optimal transition is applied, and for the perceptronbased parser, the classifier's weights are updated according to the perceptron update rule.</p><p>POS tags and syntactic dependency labels are extracted using spaCy <ref type="bibr">(Honnibal and Johnson, 2015)</ref>. <ref type="bibr">5</ref>   Evaluation. We define a simple measure for comparing UCCA structures G p = (V p , E p , ℓ p ) and G g = (V g , E g , ℓ g ), the predicted and goldstandard graphs, respectively, over the same sequence of terminals W = {w 1 , . . . , w n }. For an edge e = (u, v) in either graph, u being the parent and v the child, its yield y(e) ⊆ W is the set of terminals in W that are descendants of v. Define the set of mutual edges between G p and G g :  <ref type="figure" target="#fig_0">Figure 1</ref>.</p><formula xml:id="formula_1">M (Gp, Gg) = {(e1, e2) ∈ Ep × Eg | y(e1) = y(e2) ∧ ℓp(e1) = ℓg(e2)}</formula><p>Labeled precision and recall are defined by dividing |M (G p , G g )| by |E p | and |E g |, respectively, and F-score by taking their harmonic mean. We report two variants of this measure: one where we consider only primary edges, and another for remote edges (see Section 2). Performance on remote edges is of pivotal importance in this investigation, which focuses on extending the class of graphs supported by statistical parsers.</p><p>We note that the measure collapses to the standard PARSEVAL constituency evaluation measure if G p and G g are trees. Punctuation is excluded from the evaluation, but not from the datasets.</p><p>Comparison to bilexical graph parsers. As no direct comparison with existing parsers is possible, we compare TUPA to bilexical dependency graph parsers, which support reentrancy and discontinuity but not non-terminal nodes.</p><p>To facilitate the comparison, we convert our training set into bilexical graphs (see examples in <ref type="figure" target="#fig_2">Figure 4</ref>), train each of the parsers, and evaluate them by applying them to the test set and then reconstructing UCCA graphs, which are compared with the gold standard. The conversion to bilexical graphs is done by heuristically selecting a head terminal for each non-terminal node, and attaching all terminal descendents to the head terminal. In the inverse conversion, we traverse the bilexical graph in topological order, creating non-terminal parents for all terminals, and attaching them to the previously-created non-terminals corresponding to the bilexical heads. In Section 5 we report the upper bounds on the achievable scores due to the error resulting from the removal of non-terminal nodes.</p><p>Comparison to tree parsers. For completeness, and as parsing technology is considerably more mature for tree (rather than graph) parsing, we also perform a tree approximation experiment, converting UCCA to (bilexical) trees and evaluating constituency and dependency tree parsers on them (see examples in <ref type="figure">Figure 5</ref>). Our approach is similar to the tree approximation approach used for dependency graph parsing <ref type="bibr" target="#b4">(Agić et al., 2015;</ref><ref type="bibr" target="#b23">Fernández-González and Martins, 2015)</ref>, where dependency graphs were converted into dependency trees and then parsed by dependency tree parsers. In our setting, the conversion to trees consists simply of removing remote edges from the graph, and then to bilexical trees by applying the same procedure as for bilexical graphs.    <ref type="table" target="#tab_4">Table 2</ref> presents our main experimental results, as well as upper bounds for the baseline parsers, reflecting the error resulting from the conversion. 10 DAGParser and UPARSE are most directly comparable to TUPA Sparse , as they also use a perceptron classifier with sparse features. TUPA Sparse considerably outperforms both, where DAGParser does not predict any remote edges in the out-ofdomain setting. TurboParser fares worse in this comparison, despite somewhat better results on remote edges. The LSTM parser of <ref type="bibr" target="#b22">Dyer et al. (2015)</ref> obtains the highest primary F-score among the baseline parsers, with a considerable margin.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>Using a feedforward NN and embedding features, TUPA MLP obtains higher scores than TUPA Sparse , but is outperformed by the LSTM parser on primary edges. However, using better input encoding allowing virtual look-ahead and look-behind in the token representation, TUPA BiLSTM obtains substantially higher scores <ref type="bibr">10</ref> The low upper bound for remote edges is partly due to the removal of implicit nodes (not supported in bilexical representations), where the whole sub-graph headed by such nodes, often containing remote edges, must be discarded.</p><p>than TUPA MLP and all other parsers, on both primary and remote edges, both in the in-domain and out-of-domain settings. Its performance in absolute terms, of 73.5% F-score on primary edges, is encouraging in light of UCCA's interannotator agreement of 80-85% F-score on them <ref type="bibr" target="#b0">(Abend and Rappoport, 2013)</ref>.</p><p>The parsers resulting from tree approximation are unable to recover any remote edges, as these are removed in the conversion. <ref type="bibr">11</ref> The bilexical DAG parsers are quite limited in this respect as well. While some of the DAG parsers' difficulty can be attributed to the conversion upper bound of 58.3%, this in itself cannot account for their poor performance on remote edges, which is an order of magnitude lower than that of TUPA BiLSTM .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>While earlier work on anchored 12 semantic parsing has mostly concentrated on shallow semantic analysis, focusing on semantic role labeling of verbal argument structures, the focus has recently shifted to parsing of more elaborate representations that account for a wider range of phenomena <ref type="bibr">11</ref> We also experimented with a simpler version of TUPA lacking REMOTE transitions, obtaining an increase of up to 2 labeled F-score points on primary edges, at the cost of not being able to predict remote edges. <ref type="bibr">12</ref> By anchored we mean that the semantic representation directly corresponds to the words and phrases of the text. .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Grammar-Based</head><p>Parsing. Linguistically expressive grammars such as HPSG <ref type="bibr">(Pollard and Sag, 1994)</ref>, <ref type="bibr">CCG (Steedman, 2000)</ref> and TAG (Joshi and Schabes, 1997) provide a theory of the syntax-semantics interface, and have been used as a basis for semantic parsers by defining compositional semantics on top of them <ref type="bibr" target="#b25">(Flickinger, 2000;</ref><ref type="bibr">Bos, 2005, among others)</ref>. Depending on the grammar and the implementation, such semantic parsers can support some or all of the structural properties UCCA exhibits. Nevertheless, this line of work differs from our approach in two important ways. First, the representations are different. UCCA does not attempt to model the syntax-semantics interface and is thus less coupled with syntax. Second, while grammar-based parsers explicitly model syntax, our approach directly models the relation between tokens and semantic structures, without explicit composition rules.</p><p>Broad-Coverage Semantic Parsing. Most closely related to this work is Broad-Coverage Semantic Dependency Parsing (SDP), addressed in two SemEval tasks <ref type="bibr">(Oepen et al., 2014</ref><ref type="bibr" target="#b4">(Oepen et al., , 2015</ref>. Like UCCA parsing, SDP addresses a wide range of semantic phenomena, and supports discontinuous units and reentrancy. In SDP, however, bilexical dependencies are used, and a head must be selected for every relation-even in constructions that have no clear head, such as coordination <ref type="bibr">(Ivanova et al., 2012)</ref>. The use of non-terminal nodes is a simple way to avoid this liability. SDP also differs from UCCA in the type of distinctions it makes, which are more tightly coupled with syntactic considerations, where UCCA aims to capture purely semantic cross-linguistically applicable notions. For instance, the "poss" label in the DM target representation is used to annotate syntactic possessive constructions, regardless of whether they correspond to semantic ownership (e.g., "John's dog") or other semantic relations, such as marking an argument of a nominal predicate (e.g., "John's kick"). UCCA reflects the difference between these constructions.</p><p>Recent interest in SDP has yielded numerous works on graph parsing <ref type="bibr">(Ribeyre et al., 2014;</ref><ref type="bibr" target="#b24">Thomson et al., 2014;</ref><ref type="bibr" target="#b5">Almeida and Martins, 2015;</ref><ref type="bibr" target="#b21">Du et al., 2015)</ref>, including tree approximation <ref type="bibr" target="#b3">(Agić and Koller, 2014;</ref><ref type="bibr">Schluter et al., 2014)</ref> and joint syntactic/semantic parsing <ref type="bibr">(Henderson et al., 2013;</ref><ref type="bibr">Swayamdipta et al., 2016)</ref>.</p><p>Abstract Meaning Representation. Another line of work addresses parsing into AMRs <ref type="bibr" target="#b24">(Flanigan et al., 2014;</ref><ref type="bibr">Vanderwende et al., 2015;</ref><ref type="bibr">Pust et al., 2015;</ref><ref type="bibr" target="#b9">Artzi et al., 2015)</ref>, which, like UCCA, abstract away from syntactic distinctions and represent meaning directly, using OntoNotes predicates <ref type="bibr">(Weischedel et al., 2013)</ref>. Events in AMR may also be evoked by non-verbal predicates, including possessive constructions.</p><p>Unlike in UCCA, the alignment between AMR concepts and the text is not explicitly marked. While sharing much of this work's motivation, not anchoring the representation in the text complicates the parsing task, as it requires the alignment to be automatically (and imprecisely) detected.</p><p>Indeed, despite considerable technical effort <ref type="bibr" target="#b24">(Flanigan et al., 2014;</ref><ref type="bibr">Pourdamghani et al., 2014;</ref><ref type="bibr">Werling et al., 2015)</ref>, concept identification is only about 80%-90% accurate. Furthermore, anchoring allows breaking down sentences into semantically meaningful sub-spans, which is useful for many applications <ref type="bibr" target="#b23">(Fernández-González and Martins, 2015;</ref><ref type="bibr" target="#b11">Birch et al., 2016)</ref>.</p><p>Several transition-based AMR parsers have been proposed:</p><p>CAMR assumes syntactically parsed input, processing dependency trees into AMR <ref type="bibr">(Wang et al., 2015a</ref><ref type="bibr">(Wang et al., ,b, 2016</ref><ref type="bibr" target="#b28">Goodman et al., 2016)</ref>. In contrast, the parsers of <ref type="bibr" target="#b17">Damonte et al. (2017)</ref> and <ref type="bibr">Zhou et al. (2016)</ref> do not require syntactic pre-processing. <ref type="bibr" target="#b17">Damonte et al. (2017)</ref> perform concept identification using a simple heuristic selecting the most frequent graph for each token, and Zhou et al. (2016) perform concept identification and parsing jointly. UCCA parsing does not require separately aligning the input tokens to the graph. TUPA creates non-terminal units as part of the parsing process.</p><p>Furthermore, existing transition-based AMR parsers are not general DAG parsers. They are only able to predict a subset of reentrancies and discontinuities, as they may remove nodes before their parents have been predicted <ref type="bibr" target="#b17">(Damonte et al., 2017)</ref>. They are thus limited to a sub-class of AMRs in particular, and specifically cannot produce arbitrary DAG parses. TUPA's transition set, on the other hand, allows general DAG parsing. 13</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>We present TUPA, the first parser for UCCA. Evaluated in in-domain and out-of-domain settings, we show that coupled with a NN classifier and BiLSTM feature extractor, it accurately predicts UCCA graphs from text, outperforming a variety of strong baselines by a margin.</p><p>Despite the recent diversity of semantic parsing work, the effectiveness of different approaches for structurally and semantically different schemes is not well-understood <ref type="bibr">(Kuhlmann and Oepen, 2016)</ref>. Our contribution to this literature is a general parser that supports multiple parents, discontinuous units and non-terminal nodes.</p><p>Future work will evaluate TUPA in a multilingual setting, assessing UCCA's cross-linguistic applicability. We will also apply the TUPA transition scheme to different target representations, including AMR and SDP, exploring the limits of its generality. In addition, we will explore different conversion procedures <ref type="bibr">(Kong et al., 2015)</ref> to compare different representations, suggesting ways for a data-driven design of semantic annotation.</p><p>A parser for UCCA will enable using the framework for new tasks, in addition to existing applications such as machine translation evaluation <ref type="bibr" target="#b11">(Birch et al., 2016)</ref>. We believe UCCA's merits in providing a cross-linguistically applicable, broadcoverage annotation will support ongoing efforts to incorporate deeper semantic structures into various applications, such as sentence simplification (Narayan and Gardent, 2014) and summarization <ref type="bibr">(Liu et al., 2015)</ref>. A Feature Templates <ref type="figure">Figure 6</ref> presents the feature templates used by TUPA Sparse . All feature templates define binary features. The other classifiers use the same elements listed in the feature templates, but all categorical features are replaced by vector embeddings, and all count-based features are replaced by their numeric value. For some of the features, we used the notion of head word, defined by the h * function (see <ref type="bibr">Appendix D)</ref>. While head words are not explicitly represented in the UCCA scheme, these features prove useful as means of encoding word-to-word relations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Extended Presentation of UCCA</head><p>This work does not handle two important constructions in the UCCA foundational layer: Linkage, representing discourse relations, and Implicit, representing covert entities. <ref type="table" target="#tab_7">Table 3</ref> shows the statistics of linkage nodes and edges and implicit nodes in the corpora.  Linkage. <ref type="figure" target="#fig_5">Figure 7</ref> demonstrates a linkage relation, omitted from <ref type="figure" target="#fig_0">Figure 1a</ref>. The linkage relation is represented by the gray node. LA is link argument, and LR is link relation. The relation represents the fact that the linker "After" links the two parallel scenes that are the arguments of the linkage. Linkage relations are another source of multiple parents for a node, which we do not yet handle in parsing and evaluation.</p><p>Implicit units. UCCA graphs may contain implicit units with no correspondent in the text. <ref type="figure" target="#fig_6">Figure 8</ref> shows the annotation for the sentence "A similar technique is almost impossible to apply to other crops, such as cotton, soybeans and rice.". The sentence was used by <ref type="bibr" target="#b4">Oepen et al. (2015)</ref> to compare between different semantic dependency schemes. It includes a single scene, whose main relation is "apply", a secondary relation "almost impossible", as well as two complex arguments: "a similar technique" and the coordinated argument "such as cotton, soybeans, and rice." In addition, the scene includes an implicit argument, which represents the agent of the "apply" relation. The parsing of these units is deferred to future work, as it is likely to require different methods than those explored in this paper <ref type="bibr">(Roth and Frank, 2015)</ref>. <ref type="table" target="#tab_9">Table 4</ref> lists the hyperparameter values we found for the different classifiers by tuning on the development set. Note that learning rate decay is multiplicative and is applied at each epoch. Mini-batch size is in number of transitions, but a mini-batch must contain only whole sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Hyperparameter Values</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Bilexical Graph Conversion</head><p>Here we describe the algorithms used in the conversion referred to in Section 4.</p><p>Notation. Let L be the set of possible edge labels. A UCCA graph over a sequence of tokens w 1 , . . . , w n is a directed acyclic graph G = (V, E, ℓ), where ℓ : E → L maps edges to labels. For each token w i there exists a leaf (terminal) t i ∈ V . A bilexical (dependency) graph over the same text consists of a set A of labeled   dependency arcs (t ′ , l, t) between the terminals of G, where t ′ is the head, t is the dependent and l is the edge label.</p><p>Conversion to bilexical graphs. Let G = (V, E, ℓ) be a UCCA graph with labels ℓ : E → L. The conversion to a bilexical graph requires calculating the set A. All non-terminals in G are removed.</p><p>We define a linear order over possible edge labels L (see <ref type="figure" target="#fig_7">Figure 9</ref>). The priority order generally places core-like categories before adjunct-like ones, and was decided heuristically. For each node u ∈ V , denote by h(u) its child with the highestpriority edge label. The leftmost edge is chosen in case of a tie. Let h * (u) be the terminal reached by recursively applying h(·) over u. For each termi-nal t, we define</p><formula xml:id="formula_2">N (t) = {(u, v) ∈ E | t = h * (v) ∧ t = h * (u)}</formula><p>For each edge (u, v) ∈ N (t), we add h * (u) as a head of t in A, with the label ℓ <ref type="bibr">(u, v)</ref>. This procedure is given in Algorithm 1.</p><formula xml:id="formula_3">Data: UCCA graph G = (V, E, ℓ) Result: set A of labeled bilexical arcs A ← ∅; foreach t ∈ Terminals(V ) do foreach (u, v) ∈ N (t) do A ← A ∪ {(h * (u), ℓ(u, v), t)}; end end</formula><p>Algorithm 1: Conversion to bilexical graphs.</p><p>Note that this conversion procedure is simpler than the head percolation procedure used for converting syntactic constituency trees to dependency trees <ref type="bibr" target="#b14">(Collins, 1997)</ref>, since h(u) (similar to u's head-containing child) depends only on ℓ(u, h(u)) and not on the sub-tree spanned by u, because edge labels in UCCA directly express the role of the child in the parent unit, and are thus sufficient for determining which of u's children contains the head node.</p><p>Conversion from bilexical graphs. The inverse conversion introduces non-terminal nodes back into the graph. As the distinction between lowand high-attaching nodes is lost in the conversion, we assume that attachments are always lowattaching. Let A be a the labeled arc set of a bilexical graph. Iterating over the terminals in topological order according to A, we add its members as terminals to graph and create a pre-terminal parent u t for each terminal t, with an edge labeled as Terminal between them. The parents of the preterminals are determined by the terminal's parent in the bilexical graph: if t ′ is a head of t in A, then u t ′ will be a parent of u t . We add an intermediate node in between if t has any dependents in A, to allow adding their pre-terminals as children later. Edge labels for the intermediate edges are determined by a rule-based function, denoted by Label(t). This procedure is given in Algorithm 2.</p><p>Data: list T of terminals, set A of labeled bilexical arcs Result:</p><formula xml:id="formula_4">UCCA graph G = (V, E, ℓ) V ← ∅, E ← ∅; foreach t ∈ TopologicalSort(T, A) do u t ← Node(); V ← V ∪ {u t , t}, E ← E ∪ {(u t , t)}; ℓ(u t , t) ← Terminal ; foreach t ′ ∈ T, l ∈ L do if (t ′ , l, t) ∈ A then if ∃t ′′ ∈ T, l ′ ∈ L : (t, l ′ , t ′′ ) ∈ A then u ← Node(); V ← V ∪ {u}, E ← E ∪ {(u, u t )}; ℓ(u, u t ) ← Label(t); else u ← u t ; end E ← E ∪ {(u t ′ , u)}; ℓ(u t ′ , u) ← l; end end end Function Label</formula><p>Data: node t ∈ T Result: label l ∈ L if IsPunctuation(t) then return Punctuation; else if ∃t ′ ∈ T : (t, ParallelScene, t ′ ) ∈ A then return ParallelScene; else if ∃t ′ ∈ T : (t, Participant, t ′ ) ∈ A then return Process; else return Center; Algorithm 2: Conversion from bilexical graphs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Proof Sketch for Completeness of the TUPA Transition Set</head><p>Here we sketch a proof for the fact that the transition set defined in Section 3 is capable of producing any rooted, labeled, anchored DAG. This proves that the transition set is complete with respect to the class of graphs that comprise UCCA. Let G = (V, E, ℓ) be a graph with labels ℓ : E → L over a sequence of tokens w 1 , . . . , w n . Parsing starts with w 1 , . . . , w n on the buffer, and the root node on the stack.</p><p>First we show that every node can be created, by induction on the node height: every terminal (height zero) already exists at the beginning of the parse (and so does the root node). Let v ∈ V be of height k, and assume all nodes of height less than k can be created. Take any (primary) child u of v: its height must be less than k. If u is a terminal, apply SHIFT until it lies at the head of the buffer. Otherwise, by our assumption, u can still be created. Right after u is created, it lies at the head of the buffer. A SHIFT transition followed by a NODE ℓ(v,u) transition will move u to the stack and create v on the buffer, with the correct edge label.</p><p>Next, we show that every edge can be created. Let (v, u) ∈ E be any edge with parent v and child u. Assume v and u have both been created (we already showed that both are created eventually). If either v or u are in the buffer, apply SHIFT until both are in the stack. If both are in the stack but neither is at the stack top, apply SWAP transitions until either moves to the buffer, and then apply SHIFT. Now, assume either v or u is at the stack top. If the other is not the second element on the stack, apply SWAP transitions until it is. Finally, v and u are the top two elements on the stack. If they are in that order, apply RIGHT-EDGE ℓ(v,u) (or <ref type="bibr">RIGHT-REMOTE ℓ(v,u)</ref> if the edge between them is remote). Otherwise, apply LEFT-EDGE ℓ(v,u) (or <ref type="bibr">LEFT-REMOTE ℓ(v,u)</ref> if the edge between them is remote). This creates (v, u) with the correct edge label.</p><p>Once all nodes and edges have been created, we can apply REDUCE until only the root node remains on the stack, and then FINISH. This yields exactly the graph G.</p><p>Note that the distinction we made between primary and remote transitions is suitable for UCCA parsing. For general graph parsing without this distinction, the REMOTE transitions can be removed, as well as the single-primary-parent restriction on EDGE transition.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>UCCA structures demonstrating three structural properties exhibited by the scheme. (a) includes a remote edge (dashed), resulting in "John" having two parents. (b) includes a discontinuous unit ("gave ... up"). (c) includes a coordination construction ("John and Mary"). Pre-terminal nodes are omitted for brevity. Right: legend of edge labels.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Illustration of the TUPA model. Top: parser state (stack, buffer and intermediate graph). Bottom: TUPABiLTSM architecture. Vector representation for the input tokens is computed by two layers of bidirectional LSTMs. The vectors for specific tokens are concatenated with embedding and numeric features from the parser state (for existing edge labels, number of children, etc.), and fed into the MLP for selecting the next transition.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Bilexical graph approximation (dependency graph) for the sentences in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>8 8Figure 5 :</head><label>85</label><figDesc>See Appendix D for a detailed description of the conver-Tree approximation (constituency) for the sentence inFigure 1a(top), and bilexical tree approximation (dependency) for the same sentence (bottom). These are identical to the original graphs, apart from the removal of remote edges.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Baseline parsers. We evaluate two bilexical graph semantic dependency parsers: DAGParser (Ribeyre et al., 2014), the leading transitionbased parser in SemEval 2014 (Oepen et al., 2014) and TurboParser (Almeida and Martins, 2015), a graph-based parser from SemEval 2015 (Oepen et al., 2015); UPARSE (Maier and Lichte, 2016), a transition-based constituency parser supporting discontinuous constituents; and two bilexical tree parsers: MaltParser (Nivre et al., 2007), and the stack LSTM-based parser of Dyer et al. (2015, henceforce "LSTM Parser"). Default settings are used in all cases. 9 DAGParser and UPsion procedures. 9 For MaltParser we use the ARCEAGER transition set and SVM classifier. Other configurations yielded lower scores.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>FeaturesFigure 7 :</head><label>7</label><figDesc>from (Zhang and Clark, 2009):    unigrams s 0 tde, s 0 we, s 1 tde, s 1 we, s 2 tde, s 2 we, s 3 tde, s 3 we, b 0 wtd, b 1 wtd, b 2 wtd, b 3 wtd, s 0 lwe, s 0 rwe, s 0 uwe, s 1 lwe, s 1 rwe, s 1 uwe bigrams s 0 ws 1 w, s 0 ws 1 e, s 0 es 1 w, s 0 es 1 e, s 0 wb 0 w, s 0 wb 0 td, s 0 eb 0 w, s 0 eb 0 td, s 1 wb 0 w, s 1 wb 0 td, s 1 eb 0 w, s 1 eb 0 td, b 0 wb 1 w, b 0 wb 1 td, b 0 tdb 1 w, b 0 tdb 1 td trigrams s 0 es 1 es 2 w, s 0 es 1 es 2 e, s 0 es 1 eb 0 w, s 0 es 1 eb 0 td, s 0 es 1 wb 0 w, s 0 es 1 wb 0 td, s 0 ws 1 es 2 e, s 0 ws 1 eb 0 td separator s 0 wp, s 0 wep, s 0 wq, s 0 wcq, s 0 es 1 ep, s 0 es 1 eq, s 1 wp, s 1 wep, s 1 wq, s 1 weq extended(Zhu et al., 2013)   s 0 llwe, s 0 lrwe, s 0 luwe, s 0 rlwe, s 0 rrwe, s 0 ruwe, s 0 ulwe, s 0 urwe, s 0 uuwe, s 1 llwe, s 1 lrwe, s 1 luwe, s 1 rlwe, s 1 rrwe, s 1 ruwe disco(Maier, 2015)   s 0 xwe, s 1 xwe, s 2 xwe, s 3 xwe, s 0 xtde, s 1 xtde, s 2 xtde, s 3 xtde, s 0 xy, s 1 xy, s 2 xy, s 3 xy s 0 xs 1 e, s 0 xs 1 w, s 0 xs 1 x, s 0 ws 1 x, s 0 es 1 x, s 0 xs 2 e, s 0 xs 2 w, s 0 xs 2 x, s 0 ws 2 x, s 0 es 2 x, s 0 ys 1 y, s 0 ys 2 y, s 0 xb 0 td, s 0 xb 0 wFeatures from (Tokgöz and Eryigit, 2015): counts s 0 P, s 0 C, s 0 wP, s 0 wC, b 0 P, b 0 C, b 0 wP, b 0 wC edges s 0 s 1 , s 1 s 0 , s 0 b 0 , b 0 s 0 , s 0 b 0 e, b 0 s 0 e history a 0 , a 1 remote (Novel, UCCA-specific features) s 0 R, s 0 wR, b 0 R, b 0 wRFigure 6: Binary feature templates for TUPASparse. Notation: si, bi: ith stack and buffer items. w, t, d: word form, POS tag and syntactic dependency label of the terminal returned by h * (·) (see Appendix D). e: edge label to the node returned by h(·). l, r (ll, rr): leftmost and rightmost (grand)children. u (uu): unary (grand)child, when only one exists. p: unique separator punctuation between s0 and s1. q: separator count.x: gap type ("none", "pass" or "gap") at the sub-graph under the current node. y: sum of gap lengths (Maier and Lichte, 2009). P , C: number of parents and children. R: number of remote children. ai: action taken i steps back. UCCA example with linkage.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 :</head><label>8</label><figDesc>UCCA example with an implicit unit.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 9 :</head><label>9</label><figDesc>Priority order of edge labels used by h(u).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>We use the categorical cross-entropy objective function and optimize the NN classifiers with the Adam optimizer (Kingma and Ba, 2014). We conduct our experiments on the UCCA Wikipedia corpus (henceforth, Wiki), and use the English part of the UCCA Twenty Thousand Leagues Under the Sea English-French parallel corpus (henceforth, 20K Leagues) as out-5 https://spacy.io</figDesc><table><row><cell>4 Experimental Setup Data. Wiki Train Dev # passages 300 34 # sentences 4268 454 # nodes 298,993 33,704 35,718 29,315 20K Test Leagues 33 154 503 506 % terminal 42.96 43.54 42.87 42.09 % non-term. 58.33 57.60 58.35 60.01 % discont. 0.54 0.53 0.44 0.81 % reentrant 2.38 1.88 2.15 2.03 # edges 287,914 32,460 34,336 27,749 % primary 98.25 98.75 98.74 97.73 % remote 1.75 1.25 1.26 2.27 Average per non-terminal node # children 1.67 1.68 1.66 1.61</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Statistics of the Wiki and 20K Leagues UCCA corpora. All counts exclude the root node, implicit nodes, and linkage nodes and edges.of-domain data. 6Table 1presents some statistics for the two corpora. We use passages of indices up to 676 of the Wiki corpus as our training set, passages 688-808 as development set, and passages 942-1028 as in-domain test set. While UCCA edges can cross sentence boundaries, we adhere to the common practice in semantic parsing and train our parsers on individual sentences, discarding inter-relations between them (0.18% of the edges). We also discard linkage nodes and edges (as they often express inter-sentence relations and are thus mostly redundant when applied at the sentence level) as well as implicit nodes.7  In the out-of-domain experiments, we apply the same parsers (trained on the Wiki training set) to the 20K Leagues corpus without parameter re-tuning.Implementation. We use the DyNet package(Neubig et al., 2017)  for implementing the NN classifiers. Unless otherwise noted, we use the default values provided by the package. See Appendix C for the hyperparameter values we found by tuning on the development set.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>63.7 64.1 19.8 13.4 16 59.6 59.9 59.8 22.2 7.7 11.5 TUPA MLP 65.2 64.6 64.9 23.7 13.2 16.9 62.3 62.6 62.5 20.9 6.3 9.7 TUPA BiLSTM 74.4 72.7 73.5 47.4 51.6 49.4 68.7 68.5 68.6 38.6 18.8 25.3</figDesc><table><row><cell></cell><cell></cell><cell cols="3">Wiki (in-domain)</cell><cell></cell><cell></cell><cell></cell><cell cols="4">20K Leagues (out-of-domain)</cell></row><row><cell></cell><cell></cell><cell>Primary</cell><cell></cell><cell cols="2">Remote</cell><cell></cell><cell></cell><cell>Primary</cell><cell></cell><cell></cell><cell>Remote</cell></row><row><cell></cell><cell>LP</cell><cell>LR</cell><cell>LF</cell><cell>LP</cell><cell>LR</cell><cell>LF</cell><cell>LP</cell><cell>LR</cell><cell>LF</cell><cell>LP</cell><cell>LR</cell><cell>LF</cell></row><row><cell cols="5">TUPA Sparse 64.5 Bilexical Approximation (Dependency DAG Parsers)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Upper Bound</cell><cell></cell><cell></cell><cell>91</cell><cell></cell><cell></cell><cell>58.3</cell><cell></cell><cell></cell><cell>91.3</cell><cell></cell><cell></cell><cell>43.4</cell></row><row><cell>DAGParser</cell><cell cols="4">61.8 55.8 58.6 9.5</cell><cell>0.5</cell><cell>1</cell><cell cols="3">56.4 50.6 53.4</cell><cell>-</cell><cell>0</cell><cell>0</cell></row><row><cell>TurboParser</cell><cell cols="5">57.7 46 51.2 77.8 1.8</cell><cell>3.7</cell><cell cols="5">50.3 37.7 43.1 100 0.4</cell><cell>0.8</cell></row><row><cell cols="5">Tree Approximation (Constituency Tree Parser)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Upper Bound</cell><cell></cell><cell></cell><cell>100</cell><cell></cell><cell></cell><cell>-</cell><cell></cell><cell></cell><cell>100</cell><cell></cell><cell></cell><cell>-</cell></row><row><cell>UPARSE</cell><cell cols="3">60.9 61.2 61.1</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell cols="3">52.7 52.8 52.8</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell cols="6">Bilexical Tree Approximation (Dependency Tree Parsers)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Upper Bound</cell><cell></cell><cell></cell><cell>91</cell><cell></cell><cell></cell><cell>-</cell><cell></cell><cell></cell><cell>91.3</cell><cell></cell><cell></cell><cell>-</cell></row><row><cell>MaltParser</cell><cell cols="3">62.8 57.7 60.2</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell cols="3">57.8 53 55.3</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell cols="4">LSTM Parser 73.2 66.9 69.9</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell cols="3">66.1 61.1 63.5</cell><cell>-</cell><cell>-</cell><cell>-</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table /><note>Experimental results, in percents, on the Wiki test set (left) and the 20K Leagues set (right). Columns correspond to labeled precision, recall and F-score, for both primary and remote edges. F-score upper bounds are reported for the conversions. For the tree approximation experiments, only primary edges scores are reported, as they are unable to predict remote edges. TUPABiLSTM obtains the highest F-scores in all metrics, surpassing the bilexical parsers, tree parsers and other classifiers.ARSE use beam search by default, with a beam size of 5 and 4 respectively. The other parsers are greedy.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 3 :</head><label>3</label><figDesc>Statistics of linkage and implicit nodes in the Wiki and 20K Leagues UCCA corpora. Cf. Table 1.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 4 :</head><label>4</label><figDesc>Hyperparameters used for the different classifiers.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">All parsing and conversion code, as well as trained parser models, are available at https://github.com/danielhers/tupa.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">We also experimented with a linear model using dense embedding features, trained with the averaged structured perceptron algorithm. It performed worse than the sparse perceptron model and was hence discarded.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">See Appendix A for a full list of used feature templates. 4 https://goo.gl/6ovEhC</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">http://cs.huji.ac.il/˜oabend/ucca.html 7 Appendix B further discusses linkage and implicit units.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="13">See Appendix E for a proof sketch for the completeness of TUPA's transition set.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was supported by the HUJI Cyber Security Research Center in conjunction with the Israel National Cyber Bureau in the Prime Minister's Office, and by the Intel Collaborative Research Institute for Computational Intelligence (ICRI-CI). The first author was supported by a fellowship from the Edmond and Lily Safra Center for Brain Sciences. We thank Wolfgang Maier, Nathan Schneider, Elior Sulem and the anonymous reviewers for their helpful comments.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Universal Conceptual Cognitive Annotation (UCCA)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omri</forename><surname>Abend</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ari</forename><surname>Rappoport</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="228" to="238" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The state of the art in semantic representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omri</forename><surname>Abend</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ari</forename><surname>Rappoport</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>To appear</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">UCCAApp: Web-application for syntactic and semantic phrase-based annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omri</forename><surname>Abend</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shai</forename><surname>Yerushalmi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ari</forename><surname>Rappoport</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL: System Demonstration Papers</title>
		<meeting>of ACL: System Demonstration Papers</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>To appear</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Potsdam: Semantic dependency parsing by bidirectional graphtree transformations and syntactic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeljko</forename><surname>Agić</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Koller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SemEval</title>
		<meeting>of SemEval</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="465" to="470" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Semantic dependency graph parsing using tree approximations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeljko</forename><surname>Agić</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Koller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Oepen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IWCS</title>
		<meeting>of IWCS</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="217" to="227" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Lisbon: Evaluating TurboSemanticParser on multiple languages and out-of-domain data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>Mariana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">T</forename><surname>André</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Martins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SemEval</title>
		<meeting>of SemEval</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="970" to="973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">An incremental algorithm for transition-based CCG parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bharat</forename><forename type="middle">Ram</forename><surname>Ambati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tejaswini</forename><surname>Deoskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Steedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NAACL</title>
		<meeting>of NAACL</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="53" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Shift-reduce CCG parsing using neural network models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bharat</forename><forename type="middle">Ram</forename><surname>Ambati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tejaswini</forename><surname>Deoskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Steedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NAACL-HLT</title>
		<meeting>of NAACL-HLT</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="447" to="453" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Globally normalized transition-based neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Andor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Alberti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aliaksei</forename><surname>Severyn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Presta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuzman</forename><surname>Ganchev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2442" to="2452" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Broad-coverage CCG semantic parsing with AMR</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Artzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1699" to="1710" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Abstract Meaning Representation for sembanking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Banarescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Bonial</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Madalina</forename><surname>Georgescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kira</forename><surname>Griffitt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulf</forename><surname>Hermjakob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Schneider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Linguistic Annotation Workshop</title>
		<meeting>of the Linguistic Annotation Workshop</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">HUME: Human UCCAbased evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omri</forename><surname>Abend</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondřej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1264" to="1274" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Towards wide-coverage semantic interpretation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johan</forename><surname>Bos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IWCS</title>
		<meeting>of IWCS</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="42" to="53" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A fast and accurate dependency parser using neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="740" to="750" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Three generative lexicalized models for statistical parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL. ACL, Madrid</title>
		<meeting>of ACL. ACL, Madrid</meeting>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="16" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Incremental parsing with the perceptron algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Roark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="111" to="118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Cognitive linguistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Cruse</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">An incremental parser for abstract meaning representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Damonte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shay</forename><forename type="middle">B</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giorgio</forename><surname>Satta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EACL</title>
		<meeting>EACL</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Basic Linguistic Theory: Grammatical Topics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">W</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dixon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>Oxford University Press</publisher>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Basic Linguistic Theory: Methodology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">W</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dixon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>Oxford University Press</publisher>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Basic Linguistic Theory: Further Grammatical Topics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">W</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dixon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>Oxford University Press</publisher>
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Peking: Building semantic dependency graphs with a hybrid parser</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yantao</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiwei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Wan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of SemEval</title>
		<meeting>of SemEval</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="927" to="931" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Transitionbased dependeny parsing with stack long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Austin</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="334" to="343" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Parsing as reduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Fernández</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-González</forename><surname>André</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">T</forename><surname>Martins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1523" to="1533" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A discriminative graph-based parser for the abstract meaning representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Flanigan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaime</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1426" to="1436" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">On building a more efficient grammar by exploiting types</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Flickinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Collaborative Language Engineering</title>
		<meeting><address><addrLine>Stanford, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="15" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Learning sparser perceptron models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Elhadad</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A dynamic oracle for arc-eager dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of COLING</title>
		<meeting>of COLING</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="959" to="976" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Noise reduction and targeted exploration in imitation learning for Abstract Meaning Representation parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Vlachos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Naradowsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
