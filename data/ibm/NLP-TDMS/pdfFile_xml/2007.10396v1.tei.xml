<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">NSGANetV2: Evolutionary Multi-Objective Surrogate-Assisted Neural Architecture Search</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhichao</forename><surname>Lu</surname></persName>
							<email>luzhicha@msu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Michigan State University</orgName>
								<address>
									<postCode>48824</postCode>
									<settlement>East Lansing</settlement>
									<region>MI</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kalyanmoy</forename><surname>Deb</surname></persName>
							<email>kdeb@msu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Michigan State University</orgName>
								<address>
									<postCode>48824</postCode>
									<settlement>East Lansing</settlement>
									<region>MI</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Goodman</surname></persName>
							<email>goodman@msu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Michigan State University</orgName>
								<address>
									<postCode>48824</postCode>
									<settlement>East Lansing</settlement>
									<region>MI</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Banzhaf</surname></persName>
							<email>banzhafw@msu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Michigan State University</orgName>
								<address>
									<postCode>48824</postCode>
									<settlement>East Lansing</settlement>
									<region>MI</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vishnu</forename><forename type="middle">Naresh</forename><surname>Boddeti</surname></persName>
							<email>vishnu@msu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Michigan State University</orgName>
								<address>
									<postCode>48824</postCode>
									<settlement>East Lansing</settlement>
									<region>MI</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">NSGANetV2: Evolutionary Multi-Objective Surrogate-Assisted Neural Architecture Search</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T07:42+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>NAS</term>
					<term>Evolutionary Algorithms</term>
					<term>Surrogate-Assisted Search</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we propose an efficient NAS algorithm for generating task-specific models that are competitive under multiple competing objectives. It comprises of two surrogates, one at the architecture level to improve sample efficiency and one at the weights level, through a supernet, to improve gradient descent training efficiency. On standard benchmark datasets (C10, C100, ImageNet), the resulting models, dubbed NSGANetV2, either match or outperform models from existing approaches with the search being orders of magnitude more sample efficient. Furthermore, we demonstrate the effectiveness and versatility of the proposed method on six diverse non-standard datasets, e.g. STL-10, Flowers102, Oxford Pets, FGVC Aircrafts etc. In all cases, NSGANetV2s improve the state-of-the-art (under mobile setting), suggesting that NAS can be a viable alternative to conventional transfer learning approaches in handling diverse scenarios such as small-scale or fine-grained datasets. Code is available at https://github.com/mikelzc1990/nsganetv2.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Neural networks have achieved remarkable performance on large scale supervised learning tasks in computer vision. A majority of this progress was achieved by architectures designed manually by skilled practitioners. Neural Architecture Search (NAS) <ref type="bibr" target="#b43">[43]</ref> attempts to automate this process to find good architectures for a given dataset. This promise has led to tremendous improvements in convolutional neural network architectures, in terms of predictive performance, computational complexity and model size on standard large-scale image classification benchmarks such as ImageNet <ref type="bibr" target="#b31">[32]</ref>, CIFAR-10 <ref type="bibr" target="#b16">[17]</ref>, CIFAR-100 <ref type="bibr" target="#b16">[17]</ref> etc. However, the utility of these developments, has so far eluded more widespread and practical applications. These are cases where one wishes to use NAS to obtain high-performance models on custom non-standard datasets, optimizing possibly multiple competing objectives, and to do so without the steep computation burden of existing NAS methods.</p><p>The goal of NAS is to obtain both the optimal architecture and its associated optimal weights. The key barrier to realizing the full potential of NAS is the <ref type="figure">Fig. 1</ref>: Overview: Given a dataset and objectives, MSuNAS obtains a taskspecific set of models that are competitive in all objectives with high search efficiency. It comprises of two surrogates, one at the upper level to improve sample efficiency and one at the lower level, through a supernet, to improve weight learning efficiency. nature of its formulation. NAS is typically treated as a bi-level optimization problem, where an inner optimization loops over the weights of the network for a given architecture, while the outer optimization loops over the network architecture itself. The computational challenge of solving this problem stems from both the upper and lower level optimization. Learning the optimal weights of the network in the lower level necessitates costly iterations of stochastic gradient descent. Similarly, exhaustively searching the optimal architecture is prohibitive due to the discrete nature of the architecture description, size of search space and our desire to optimize multiple, possibly competing, objectives. Mitigating both of these challenges explicitly and simultaneously is the goal of this paper.</p><p>Many approaches have been proposed to improve the efficiency of NAS algorithms, both in terms of the upper level and the lower level. A majority of them focuses on the lower level, including weight sharing <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b19">20]</ref>, proxy models <ref type="bibr" target="#b43">[43,</ref><ref type="bibr" target="#b30">31]</ref>, coarse training <ref type="bibr" target="#b35">[35]</ref>, etc. But these approaches still have to sample, explicitly or implicitly, a large number of architectures to evaluate in the upper level. In contrast, there is relatively little focus on improving the sample efficiency of the upper level optimization. A few recent approaches <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b9">10]</ref> adopt surrogates that predict the lower level performance with the goal of navigating the upper level search space efficiently. However, these surrogate predictive models are still very sample inefficient since they are learned in an offline stage by first sampling a large number of architectures that require full lower level optimization.</p><p>In this paper, we propose a practically efficient NAS algorithm, by adopting explicit surrogate models simultaneously at both the upper and the lower level. Our lower level surrogate adopts a fine-tuning approach, where the initial weights for fine-tuning are obtained by a supernet model, such as <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b4">5]</ref>. Our upper level surrogate adopts an online learning algorithm, that focuses on architectures in the search space that are close to the current trade-off front, as opposed to a random/uniform set of architectures used in the offline surrogate approaches <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b18">19]</ref>. Our online surrogate significantly improves the sample NASNet <ref type="bibr" target="#b43">[43]</ref> RL C10 ENAS <ref type="bibr" target="#b29">[30]</ref> RL C10 PNAS <ref type="bibr" target="#b18">[19]</ref> SBMO C10 DPP-Net <ref type="bibr" target="#b12">[13]</ref> SBMO C10 DARTS <ref type="bibr" target="#b19">[20]</ref> Gradient C10 LEMONADE <ref type="bibr" target="#b13">[14]</ref> EA C10, C100 ProxylessNAS <ref type="bibr" target="#b5">[6]</ref> RL + gradient C10, ImageNet MnasNet <ref type="bibr" target="#b35">[35]</ref> RL ImageNet ChamNet <ref type="bibr" target="#b9">[10]</ref> EA ImageNet MobileNetV3 <ref type="bibr" target="#b14">[15]</ref> RL + expert ImageNet An overview of our approach is shown in <ref type="figure">Fig.1</ref>. We refer to the proposed NAS algorithm as MSuNAS and the resulting architectures as NSGANetV2. Our method is designed to provide a set of high-performance models on a custom dataset (large or small scale, multi-class or fine-grained) while optimizing possibly multiple objectives of interest. Our key contributions are:</p><p>-An alternative approach to solve the bi-level NAS problem, i.e., simultaneously optimizing the architecture and learn the optimal model weights. However, instead of gradient based relaxations (e.g., DARTS), we advocate for surrogate models. Overall, given a dataset and a set of objectives to optimize, MSuNAS can design custom neural network architectures as efficiently as DARTS but with higher performance and extends to multiple, possibly competing objectives.</p><p>-A simple, yet highly effective, online surrogate model for the upper level optimization in NAS, resulting in a significant increase in sampling efficiency over other surrogate-based approaches.</p><p>-Scalability and practicality of MSuNAS on many datasets corresponding to different scenarios. These include standard datasets like ImageNet, CIFAR-10 and CIFAR-100, and six non-standard datasets like CINIC-10 <ref type="bibr" target="#b10">[11]</ref> (multi-class), STL-10 <ref type="bibr" target="#b8">[9]</ref>(small scale mutli-class), Oxford Flowers102 <ref type="bibr" target="#b27">[28]</ref>(small scale fine-grained) etc. Under mobile settings (≤ 600M MAdds), MSuNAS leads to SOTA performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Lower Level Surrogate: Existing approaches <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b22">23]</ref> primarily focus on mitigating the computational overhead induced by SGD-based weight optimization in the lower level, as this process needs to be repeated for every architecture sampled by a NAS method in the upper level. A common theme among these methods involves training a supernet which contains all searchable architectures as its sub-networks. During search, accuracy using the weights inherited from the supernet becomes the metric to select architectures. However, completely relying on supernet as a substitute of actual weight optimization for evaluating candidate architectures is unreliable. Numerous studies <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b40">40,</ref><ref type="bibr" target="#b41">41]</ref> reported a weak correlation between the performance of the searched architectures (predicted by weight sharing) and the ones trained from scratch (using SGD) during the evaluation phase. MSuNAS instead uses the weights inherited from the supernet only as an initialization to the lower level optimization. Such a fine-tuning process affords the computation benefit of the supernet, while at the same time improving the correlation in the performance of the weights initialized from the supernet and those trained from scratch.</p><p>Upper Level Surrogate: MetaQNN <ref type="bibr" target="#b0">[1]</ref> uses surrogate models to predict the final accuracy of candidate architectures (as a time-series prediction) from the first 25% of the learning curve from SGD training. PNAS <ref type="bibr" target="#b18">[19]</ref> uses a surrogate model to predict the top-1 accuracy of architectures with an additional branch added to the cell structure that are repeatedly stacked together. Fundamentally, both of these approaches seek to extrapolate rather than interpolate the performance of the architecture using the surrogates. Consequently, as we show later in the paper, the rank-order between the predicted accuracy and the true accuracy is very low 2 (0.476). OnceForAll <ref type="bibr" target="#b4">[5]</ref> also uses a surrogate model to predict accuracy from architecture encoding. However, the surrogate model is trained offline for the entire search space, thereby needing a large number of samples for learning (16K samples -&gt; 2 GPU-days -&gt; 2x search cost of DARTS for just constructing the surrogate model). Instead of using uniformly sampled architectures and their validation accuracy to train the surrogate model to approximate the entire landscape, ChamNet <ref type="bibr" target="#b9">[10]</ref> trains many architectures through full lower level optimization and selects only 300 samples with high accuracy with diverse efficiency (FLOPs, Latency, Energy) to train a surrogate model offline. In contrast, MSuNAS learns a surrogate model in an online fashion only on the samples that are close to the current trade-off front as we explore the search space. The online learning approach significantly improves the sample efficiency of our search, since we only need lower level optimization (full or surrogate assisted) for the samples near the current Pareto front.</p><p>Multi-Objective NAS: Approaches that consider more than one objective to optimize the architecture can be categorized into two groups: (i) scalarization, and (ii) population based approaches. The former include, ProxylessNAS <ref type="bibr" target="#b5">[6]</ref>, MnasNet <ref type="bibr" target="#b35">[35]</ref>, FBNet <ref type="bibr" target="#b39">[39]</ref>, and MobileNetV3 <ref type="bibr" target="#b14">[15]</ref> which use a scalarized objective that encourages high accuracy and penalizes compute inefficiency at the same time, e.g., maximize Acc * (Latency/T arget) −0.07 . These methods require a pre-defined preference weighting of the importance of different objectives before the search, which typically requires a numbers of trials. Methods in the latter category include <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b20">21]</ref> and aim to approximate the entire Pareto-efficient frontier simultaneously. These approaches rely on heuristics (e.g., EA) to efficiently navigate the search space, which allows practitioners to visualize the trade-off between the objectives and to choose a suitable network a posteriori to the search. MSuNAS falls in the latter category using surrogate models to mitigate the computational overhead.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Proposed Approach</head><p>The neural architecture search problem for a target dataset D = {D trn , D vld , D tst } can be formulated as the following bilevel optimization problem <ref type="bibr" target="#b2">[3]</ref>,</p><formula xml:id="formula_0">minimize F(α) = f 1 (α; w * (α)), . . . , f k (α; w * (α)), f k+1 (α), . . . , f m (α) T , subject to w * (α) ∈ argmin L(w; α), α ∈ Ω α , w ∈ Ω w ,<label>(1)</label></formula><p>where the upper level variable α defines a candidate CNN architecture, and the lower level variable w(α) defines the associated weights. L(w; α) denotes the cross-entropy loss on the training data D trn for a given architecture α. F : Ω → R m constitutes m desired objectives. These objectives can be further divided into two groups, where the first group (f 1 to f k ) consists of objectives that depend on both the architecture and the weights-e.g., predictive performance on validation data D vld , robustness to adversarial attack, etc. The other group (f k+1 to f m ) consists of objectives that only depend on the architecture-e.g., number of parameters, floating point operations, latency etc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Search Space</head><p>MSuNAS searches over four important dimensions of convolutional neural networks (CNNs), including depth (# of layers), width (# of channels), kernel size and input resolution. Following previous works <ref type="bibr" target="#b35">[35,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b4">5]</ref>, we decompose a CNN architecture into five sequentially connected blocks, with gradually reduced feature map size and increased number of channels. In each block, we search over the number of layers, where only the first layer uses stride 2 if the feature map size decreases, and we allow each block to have minimum of two and maximum of four layers. Every layer adopts the inverted bottleneck structure <ref type="bibr" target="#b32">[33]</ref> and we search over the expansion rate in the first 1 × 1 convolution and the kernel size of the depth-wise separable convolution. Additionally, we allow the input image size to range from 192 to 256. We use an integer string to encode these architectural choices, and we pad zeros to the strings of architectures that have fewer layers so that we have a fixed-length encoding. A pictorial overview of this search space and encoding is shown in <ref type="figure">Fig. 2</ref>. (c) Fix-length encoding </p><formula xml:id="formula_1">Layers | Kernel size | Expansion rate | Resolutions 2 3 4 | 3 5 7 | 3 4 6 | 192 196 200 ⋯ ⋯ 252 256 3 | 3 | 3 | 17 (a)</formula><formula xml:id="formula_2">Input Stem !"#$% 1 !"#$% 2 !"#$% 3 !"#$% 4 !"#$% 5 Penultimate Output ,-./0 1 ↓ 1 × 1 ↓ Depth-wise Conv ↓ 1 × 1 ↓ ⋮ ,-./0 , ↓ 1 × 1 ↓ Depth-wise Conv ↓ 1 × 1 ↓ / 4 (6) (expansion rate) % 4 (6) (kernel size) ⋮ /4 (8) (expansion rate)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Overall Algorithm Description</head><p>The problem in Eq. 1 poses two main computational bottlenecks for conventional bi-level optimization methods. First, the lower level problem of learning the optimal weights w * (α) for a given architecture α involves a prolonged training process-e.g., one complete SGD training on ImageNet dataset takes two days on an 8-GPU server. Second, even though there exist techniques like weightsharing to bypass the gradient-descent-based weight learning process, extensively sampling architectures at the upper level can still render the overall process computationally prohibitive, e.g., 10,000 evaluations on ImageNet take 24 GPU hours, and for methods like NASNet, AmoebaNet that require more than 20,000 samples, it still requires days to complete the search even with weight-sharing. Algorithm 1 and <ref type="figure" target="#fig_2">Fig. 3</ref> show the pseudocode and corresponding steps from a sample run of MSuNAS on ImageNet, respectively. To overcome the aforementioned bottlenecks, we use surrogate models at both upper and lower levels to make our NAS algorithm practically useful for a variety of datasets and objectives. At the upper level, we construct a surrogate model that predicts the top-1 accuracy from integer strings that encode architectures. Previous approaches <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b4">5]</ref> that also used surrogate-modeling of the accuracy follow an offline approach, where the accuracy predictor is built from samples collected separately prior to the architecture search and not refined during the search. We argue that such a process makes the search outcome highly dependent on the initial training samples. As an alternative, we propose to model and refine the accuracy predictor iteratively in an online manner during the search. In particular, we start with an accuracy predictor constructed from only a limited number of architectures sampled randomly from the search space. We then use a standard multi-objective algorithm (NSGA-II <ref type="bibr" target="#b11">[12]</ref>, in our case) to search using the constructed accuracy predictor along with other objectives that are also of interest to the user. We then evaluate the outcome architectures from NSGA-II and refine the accuracy predictor model with these architectures as new training samples. We repeat this process for a pre-specified number of iterations and output the non-dominated solutions from the pool of evaluated architectures.  </p><formula xml:id="formula_3">Algorithm 1: MSuNAS Input : SS (search space), Sw (supernet), C (complexity obj), N (initial samples), K (max. iterations). 1 A ← ∅; 2 while i &lt; N do 3 α ← sample(SS) 4 wo ← Sw(α) 5 acc ← SGD(α, wo) 6 A ← A ∪ (α, acc) 7 end 8 while j &lt; K do 9 Sf ← construct from A // (MLP / CART / RBF / GP) 10α ← NSGA-II(Sf , C) 11 α ← subset fromα 12 for α in α do 13 wo ← Sw(α) 14 acc ← SGD(α, wo) 15 A ← A ∪ (α,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Speeding Up Upper Level Optimization</head><p>Recall that the nested nature of the bi-level problem makes the upper level optimization computationally very expensive, as every upper level function evaluation requires another optimization at the lower level. Hence, to improve the efficiency of our approach at the upper level, we focus on reducing the number of architectures that we send to the lower level for learning optimal weights. To achieve this goal, we need a surrogate model to predict the accuracy of an architecture before we actually train it. There are two desired properties of such a predictor: (1) high rank-order correlation between predicted and true performance; and (2) sample efficient such that the required number of architectures to be trained through SGD are minimized for constructing the predictor.</p><p>We first collected four different surrogate models for accuracy prediction from the literature, namely, Multi Layer Perceptron (MLP) <ref type="bibr" target="#b18">[19]</ref>, Classification And Regression Trees (CART) <ref type="bibr" target="#b33">[34]</ref>, Radial Basis Function (RBF) <ref type="bibr" target="#b0">[1]</ref> and Gaussian Process (GP) <ref type="bibr" target="#b9">[10]</ref>. From our ablation study, we observed that no one surrogate model is consistently better than others in terms of the above two criteria on all datasets (see section 4.1). Hence, we propose a selection mechanism, dubbed Adaptive Switching (AS), which constructs all four types of surrogate models at every iteration and adaptively selects the best model via cross-validation.</p><p>With the accuracy predictor selected by AS, we apply the NSGA-II algorithm to simultaneously optimize for both accuracy (predicted) and other objectives of interest to the user (line 10 in Algorithm 1). For the purpose of illustration, we assume that the user is interested in optimizing #MAdds as the second objective. At the conclusion of the NSGA-II search, a set of non-dominated architectures is output, see <ref type="figure" target="#fig_2">Fig. 3</ref>(b). Often times, we cannot afford to train all architectures in the set. To select a subset, we first select the architecture with highest predicted accuracy. Then we project all other architecture candidates to the #MAdds axis, and pick the remaining architectures from the sparse regions that help in extending the Pareto frontier to diverse #MAdds regimes, see <ref type="figure" target="#fig_2">Fig. 3</ref></p><formula xml:id="formula_4">(c) -(d).</formula><p>The architectures from the chosen subset are then sent to the lower level for SGD training. We finally add these architectures to the training samples to refine our accuracy predictor models and proceed to next iteration, see <ref type="figure" target="#fig_2">Fig. 3</ref>(e).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Speeding Up Lower Level Optimization</head><p>To further improve the search efficiency of the proposed algorithm, we adopt the widely-used weight-sharing technique <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b24">25]</ref>. First, we need a supernet such that all searchable architectures are sub-networks of it. We construct such a supernet by taking the searched architectural hyperparameters at their maximum values, i.e., with four layers in each of the five blocks, with expansion ratio set to 6 and kernel size set to 7 in each layer (See <ref type="figure">Fig. 2</ref>). Then we follow the progressive shrinking algorithm <ref type="bibr" target="#b4">[5]</ref> to train the supernet. This process is executed once before the architecture search. The weights inherited from the trained supernet are used as a warm-start for the gradient descent algorithm during architecture search.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments and Results</head><p>In this section, we evaluate the surrogate predictor, the search efficiency and the obtained architectures on CIFAR-10 <ref type="bibr" target="#b16">[17]</ref>, CIFAR-100 <ref type="bibr" target="#b16">[17]</ref>, and ImageNet <ref type="bibr" target="#b31">[32]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Performance of the Surrogate Predictors</head><p>To evaluate the effectiveness of the considered surrogate models, we uniformly sample 2,000 architectures from our search space, and train them using SGD for 150 epochs on each of the three datasets and record their accuracy on 5,000 held-out images from the training set. We then fit surrogate models with different number of samples randomly selected from the 2,000 collected. We repeat the process for 10 trials to compare the mean and standard deviation of the rank-order correlation between the predicted and true accuracy, see <ref type="figure" target="#fig_3">Fig. 4</ref>. In general, we observe that no single surrogate model consistently outperforms the others on all three datasets. Hence, at every iteration, we adopt an Adaptive Switching (AS) routine that compares the four surrogate models and chooses the best based on 10-fold cross-validation. It is evident from <ref type="figure" target="#fig_3">Fig. 4</ref> that AS works better than any one of the four surrogate models alone on all three datasets. The construction time of the AS is negligible (relatively to the search cost).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Search Efficiency</head><p>In this section, we first compare the search efficiency of MSuNAS to other singleobjective methods on both CIFAR-10 and ImageNet. To quantify the speedup, we compare the two governing factors, namely, the total number of architectures evaluated by each method to reach the reported accuracy and the number of epochs undertaken to train each sampled architecture during search. The results are provided in <ref type="table" target="#tab_3">Table 2</ref>. We observe that MSuNAS is 20x faster than methods that use RL or EA. When compared to PNAS <ref type="bibr" target="#b18">[19]</ref>, which also utilizes an accuracy predictor, MSuNAS is still at least 3x faster.</p><p>We then compare the search efficiency of MSuNAS to NSGANet <ref type="bibr" target="#b21">[22]</ref> and random search under a bi-objective setup: Top-1 accuracy and #MAdds. To perform the comparison, we run MSuNAS for 30 iterations, leading to 350  architectures evaluated in total. We record the cumulative hypervolume <ref type="bibr" target="#b42">[42]</ref> achieved against the number of architectures evaluated. We repeat this process five times on both ImageNet and CIFAR-10 datasets to capture the variance in performance due to randomness in the search initialization. For a fair comparison to NSGANet, we apply the search code to our search space and record the number of architectures evaluated by NSGANet to reach a similar hypervolume than that achieved by MSuNAS. The random search baseline is performed by uniformly sampling from our search space. We plot the mean and the standard deviation of the hypervolume values achieved by each method in <ref type="figure" target="#fig_4">Fig. 5</ref>. Based on the incremental rate of hypervolume metric, we observe that MSuNAS is 2 -5x faster, on average, in achieving a better Pareto frontier in terms of number of architectures evaluated. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Results on Standard Datasets</head><p>Prior to the search, we train the supernet following the training hyperparameters setting from <ref type="bibr" target="#b4">[5]</ref>. For each dataset, we start MSuNAS with 100 randomly sampled architectures and run for 30 iterations. In each iteration, we evaluate 8 architectures selected from the candidates recommended by NSGA-II according to the accuracy predictor. For searching on CIFAR-10 and CIFAR-100, we fine tune the weights inherited from the supernet for five epochs then evaluate on 5K held-out validation images from the original training set. For searching on ImageNet, we re-calibrate the running statistics of the BN layers after inheriting the weights from the supernet, and evaluate on 10K held-out validation images from the original training set. At the conclusion of the search, we pick the four architectures from the achieved Pareto front, and further fine-tune for additional 150-300 epochs on the entire training sets. For reference purpose, we name the obtained architectures as NSGANetV2-s/m/l/xl in ascending #MAdds order. Architectural details can be found in the Appendix C. <ref type="table" target="#tab_4">Table 3</ref> shows the performance of our models on the ImageNet 2012 benchmark <ref type="bibr" target="#b31">[32]</ref>. We compare models in terms of predictive performance on the validation set, model efficiency (measured by #MAdds and latencies on different hardware), and associated search cost. Overall, NSGANetV2 consistently either matches or outperforms other models across different accuracy levels with highly competitive search costs. In particular, NSGANetV2-s is 2.2% more accurate than Mo-bileNetV3 <ref type="bibr" target="#b14">[15]</ref>  accurate and 1.2x more efficient than EfficientNet-B1 <ref type="bibr" target="#b36">[36]</ref>. Additional comparisons to models from multi-objective approaches are provided in <ref type="figure">Fig. 6</ref>. For CIFAR datasets, <ref type="figure">Fig. 6</ref> compares our models with other approaches in terms of both predictive performance and computational efficiency. On CIFAR-10, we observe that NSGANetV2 dominates all previous models including (1) NASNet-A <ref type="bibr" target="#b43">[43]</ref>, PNASNet-5 <ref type="bibr" target="#b18">[19]</ref> and NSGANet <ref type="bibr" target="#b21">[22]</ref> that search on CIFAR-10 directly, and (2) EfficientNet <ref type="bibr" target="#b36">[36]</ref>, MobileNetV3 <ref type="bibr" target="#b14">[15]</ref> and MixNet <ref type="bibr" target="#b37">[37]</ref> that fine-tune from ImageNet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Scalability of MSuNAS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Types of Datasets</head><p>Existing NAS approaches are rarely evaluated for their search ability beyond standard benchmark datasets, i.e., ImageNet, CIFAR-10, and CIFAR-100. Instead, they follow a conventional transfer learning setup, in which the architectures found by searching on standard benchmark datasets are transferred, with weights fine-tuned, to new datasets. We argue that such a process is conceptually contradictory to the goal of NAS, and the architectures identified under such a process are sub-optimal. In this section we demonstrate the scalability of MSuNAS to six additional datasets with various forms of difficulties, in terms of diversity in classification classes (multi-classes vs. fine-grained) and size of training  <ref type="figure">Fig. 7</ref>: Performance of the set of task-specific models, i.e. NSGANetV2s, on six different types of non-standard datasets, compared to SOTA from transfer learning <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b36">36]</ref> and semi-/un-supervised learning <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b38">38]</ref>.</p><p>set (see <ref type="table">Table 4</ref>). We adopt the settings of the CIFAR datasets as outlined in Section 3. For each dataset, one search takes less than one day on 8 GPU cards.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Datasets</head><p>Type #Classes #Train #Test CINIC-10 [11] multi-class 10 90,000 90,000 STL-10 <ref type="bibr" target="#b8">[9]</ref> multi-class 10 5,000 8,000 Flowers102 <ref type="bibr" target="#b27">[28]</ref> fine-grained 102 2,040 6,149 Pets <ref type="bibr" target="#b28">[29]</ref> fine-grained 37 3,680 3,369 DTD <ref type="bibr" target="#b7">[8]</ref> fine-grained 47 3,760 1,880 Aircraft <ref type="bibr" target="#b23">[24]</ref> fine-grained 100 6,667 3,333 <ref type="table">Table 4</ref>: Non-standard Datasets for MSuNAS <ref type="figure">Fig. 7 (Bottom)</ref> compares the performance of NSGANetV2 obtained by searching directly on the respective datasets to models from other approaches that transfer architectures learned from either CIFAR-10 or Im-ageNet. Overall, we observe that NSGANetV2 significantly outperforms other models on all three datasets. In particular, NS-GANetV2 achieves a better performance than the currently known state-ofthe-art on CINIC-10 <ref type="bibr" target="#b26">[27]</ref> and STL-10 <ref type="bibr" target="#b1">[2]</ref>. Furthermore, on Oxford Flowers102, NSGANetV2 achieves better accuracy to that of EfficientNet-B3 [36] while using 1.4B fewer MAdds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Number of Objectives</head><p>Single-objective Formulation: Adding a hardware efficiency target as a penalty term to the objective of maximizing predictive performance is a common workaround to handle multiple objectives in the NAS literature <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b35">35,</ref><ref type="bibr" target="#b39">39]</ref>. We demonstrate that our proposed algorithm can also effectively handle such a scalarized single-objective search. Following the scalarization method in <ref type="bibr" target="#b35">[35]</ref>, we apply MSuNAS to maximize validation accuracy on ImageNet with 600M MAdds as the targeted efficiency. The accumulative top-1 accuracy achieved and the performance of the accuracy predictor are provided in <ref type="figure" target="#fig_6">Fig. 8a</ref>. Without further fine-tuning, the obtained architecture yields 79.56% accuracy with 596M MAdds on the ImageNet validation set, which is more accurate and 100M fewer MAdds than EfficientNet-B1 <ref type="bibr" target="#b36">[36]</ref>.   Many-objective Formulation: Practical deployment of learned models are rarely driven by a single objective, and most often, seek to trade-off many different, possibly competing, objectives. As an example of one such scenario, we use MSuNAS to simultaneously optimize five objectives-namely, the accuracy on ImageNet, #Params, #MAdds, CPU and GPU latency. We follow the same search setup as in the main experiments and increase the budget to ensure a thorough search on the expanded objective space. We show the obtained Paretooptimal (to five objectives) architectures in <ref type="figure" target="#fig_6">Fig. 8b</ref>. We use color and marker size to indicate CPU and GPU latency, respectively. We observe that a Pareto surface emerges, shown in the left 3D scatter plot, suggesting that trade-offs exist between objectives, i.e., #Params and #MAdds are not fully correlated.</p><p>We then project all architectures to 2D, visualizing accuracy vs. each one of the four considered efficiency measurements, and highlight the architectures that are non-dominated in the corresponding two-objective cases. We observe that many architectures that are non-dominated in the five-objective case are now dominated when only considering two objectives. Empirically, we observe that accuracy is highly correlated with #MAdds, CPU and GPU latency, but not with #Params, to some extent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>This paper introduced MSuNAS, an efficient neural architecture search algorithm for rapidly designing task-specific models under multiple competing objectives. The efficiency of our approach stems from (i) online surrogate-modeling at the level of the architecture to improve the sample efficiency of search, and (ii) a supernet based surrogate-model to improve the weights learning efficiency via fine-tuning. On standard datasets (CIFAR-10, CIFAR-100 and ImageNet), NSGANetV2 matches the state-of-the-art with a search cost of one day. The utility and versatility of MSuNAS are further demonstrated on non-standard datasets of various types of difficulties and on different number of objectives. Improvements beyond the state-on-the-art on STL-10 and Flowers102 (under mobile setting) suggest that NAS is a more effective alternative to conventional transfer learning approaches.</p><p>In MSuNAS, we iteratively fit and refine surrogate models using only architectures that are close to the Pareto frontier. Hence, surrogate models can focus on interpolating across a much restricted region (models close to the current pareto front) in the search space, leading to a significant better rank-order correlation achieved as opposed to existing methods <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b12">13]</ref>, i.e., ∼ 0.9 for MSuNAS vs 0.476 for ProgressiveNas <ref type="bibr" target="#b18">[19]</ref>. Furthermore, we empirically observe that high rank-order correlation in a surrogate model translates into better search performance (lower sample complexity), measured by hypervolume <ref type="bibr" target="#b42">[42]</ref>, when paired with MSuNAS. On ImageNet, RBF outperforms the other three surrogate models considered. However, to improve generalization to other datasets, we follow an adaptive switching routine that compares all four surrogate models and selects the best based on cross validation (see Section 3.3 in the main paper).  GPU latency. At the end of the evolution, we identify the non-dominated architectures and visualize their architectural choices in <ref type="figure" target="#fig_7">Fig. 10a -10d</ref>. We observe that the efficient architectures under MAdds, CPU and GPU latency requirements are similar, indicating positive correlation among them, which is not the case with Params. We notice that MSuNAS implicitly exploits the fact that Params is agnostic to the image resolution, and choose to use input images at highest allowed resolution to improve predictive performance (see the Input Resolution heatmap in <ref type="figure" target="#fig_7">Fig. 10b)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 Transfer Across Objectives</head><p>Further post-optimal analysis of the set of non-dominated architectures often times reveals valuable design principles, referred to as derived heuristics <ref type="bibr" target="#b25">[26]</ref>. Such derived heuristics can be utilized for novel tasks. Here we consider one such example, transferring architectures and associated weights from models that were searched with respect to one pair of objectives to architectures that are optimal with respect to a different pair of objectives. The idea is that if the objectives that we want to transfer across are related but not identical, for instance, MAdds and Latency, we can improve search efficiency by exploiting such correlations. More specifically, we can search for optimal architectures with respect to a target set of objectives by initializing the search with architectures from a source set of objectives much more efficiently, compared to starting the search from scratch. As a demonstration of this property, we conduct the following experiment: -Approach 1 ("from scratch"): MSuNAS from randomly (uniformly) initialized architectures. -Approach 2 ("from objective transfer"): MSuNAS from architectures sampled from distribution constructed from non-dominated architectures of source objectives, namely, predictive performance and MAdds <ref type="figure" target="#fig_7">(Fig. 10a</ref>).</p><p>In Approach 1, we initialize the search process for the target objectives from randomly sampled architectures (uniformly on the search space). In contrast, in Approach 2, we initialize the search process for the target objectives by architectures sampled from the insights obtained by searching on a related pair of source objectives (predictive performance and MAdds) i.e., from the distribution in <ref type="figure" target="#fig_7">Fig. 10b(a)</ref>.</p><p>In <ref type="figure" target="#fig_8">Fig. 11</ref>, we first compare the hypervolume achieved by these two approaches over five runs. We visualize the obtained Pareto front (from the run with median hypervolume) in <ref type="figure" target="#fig_8">Fig. 11</ref> (Right). We observe that utilizing insights from searching on related objectives can significantly improve search performance. In general, we believe that heuristics can be derived and utilized to improve search performance on related tasks (e.g. MAdds and CPU latency), which is another desirable property of MSuNAS, where a set of architectures are obtained in a single run. The efficiency gains from the objective transfer (Approach 2) we demonstrate here are directly proportional to the correlation between the source and target objectives. However, if the source and target objectives are not related, then Approach 2 may not be more efficient than Approach 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Evolved Architectures</head><p>In this section, we visualize the obtained architectures in <ref type="figure" target="#fig_9">Fig. 12</ref>  is only possible by directly searching on the target dataset, which is the case in MSuNAS.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>%4 ( 8 )Fig. 2 :</head><label>82</label><figDesc>(kernel size) Search Space: A candidate architecture comprises five computational blocks. Parameters we search for include image resolution, number of layers (L) in each block and the expansion rate (e) and the kernel size (k) in each layer.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 :</head><label>3</label><figDesc>A sample run of MSuNAS on ImageNet: In each iteration, accuracyprediction surrogate models S f are constructed from an archive of previously evaluated architectures (a). New candidate architectures brown boxes in (b) are obtained by solving the auxiliary single-level multi-objective problemF = {S f , C} (line 10 in Algo 1). A subset of the candidate architectures is chosen to diversify the Pareto front (c) -(d). The selected candidate architectures are then evaluated and added to the archive (e). At the conclusion of search, we report the nondominated architectures from the archive. The x-axis in all sub-figures is #MAdds.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 :</head><label>4</label><figDesc>Comparing the relative prediction performance of the proposed Adaptive Switching (AS) method to the existing four surrogate models. Top row compares Spearman rank-order correlation coefficient as number of training samples increases. Bottom row visualizes the true vs. predicted accuracy under 500 training samples (RBF method is omitted to conserve space).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 :</head><label>5</label><figDesc>Comparing the relative search efficiency of MSuNAS to other methods under bi-objective setup on ImageNet (a) and CIFAR-10 (b). The left plots in each subfigure compares the hypervolume metric [42], where a larger value indicates a better Pareto front achieved. The right plots in each subfigure show the Spearman rank-order correlation (top) and the root mean square error (bottom) of MSuNAS. All results are averaged over five runs with standard deviation shown in shaded regions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 8 :</head><label>8</label><figDesc>Scalability of MSuNAS to different numbers and types of objectives: optimizing (a) a scalarized single-objective on ImageNet; (b) five objectives including accuracy, Params, MAdds, CPU and GPU latency, simultaneously. (c) Post-optimal analysis on the architectures that are non-dominated according to different efficiency objectives.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 10 :</head><label>10</label><figDesc>The layer-wise architectural choice frequency of the non-dominated architectures obtained by MSuNAS when optimizing predictive performance and MAdds (a) / Params (b) / CPU (c) / GPU latency (d).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 11 :</head><label>11</label><figDesc>Comparing MSuNAS's search performance when initialized (1) from randomly sampled architectures and (2) by sampling from distribution constructed from efficient architectures on a related task (MAdds).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 12 :</head><label>12</label><figDesc>The architectures of NSGANetV2s referred to in Fig. 1 (main paper) and Fig. 6 (main paper). The stem layers in all architectures are the same and not searched. All architectures consist of five blocks, denoted with dashed lines. The first layer in blocks 1, 2, 3, and 5 use stride 2. We use color to denote kernel size and height to denote expansion ratio (legends). For each dataset, architectures are arranged in ascending #MAdds order from top to bottom, i.e. architectures on the top rows have smaller MAdds than those on the bottom rows.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Comparison of Existing NAS methods</figDesc><table><row><cell>Methods</cell><cell>Search Method</cell><cell>Performance Prediction</cell><cell>Weight Sharing</cell><cell>Multiple Objective</cell><cell>Dataset Searched</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>efficiency of the upper level optimization problem in comparison to the offline surrogates. For instance, OnceForAll [5] and PNAS [19] sample 16,000 and 1,160 1 architectures, respectively, to learn the upper level surrogate. In contrast, we only have to sample 350 architectures to obtain a model with similar performance.</figDesc><table><row><cell></cell><cell></cell><cell>C10, C100, ImageNet,</cell></row><row><cell>MSuNAS (ours)</cell><cell>EA</cell><cell>Pets, STL-10, Aircraft,</cell></row><row><cell></cell><cell></cell><cell>DTD, CINIC-10, Flowers102</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>acc) 16 end 17 end 18 Return NDsort(A).</figDesc><table><row><cell></cell><cell></cell><cell cols="2">Allarchectures</cell><cell></cell><cell>Candidate</cell><cell cols="2">Selectedcandidate</cell><cell></cell><cell cols="3">Selectedcandidate</cell></row><row><cell></cell><cell></cell><cell cols="3">evaluatedsofar</cell><cell>architectures</cell><cell cols="3">architecturestoevaluate</cell><cell cols="3">architecturesevaluated</cell></row><row><cell></cell><cell>24</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>24</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Top1ValidationError(%)</cell><cell>18 20 22</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>18 20 22</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>16</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>200</cell><cell></cell><cell>300</cell><cell>400</cell><cell cols="2">500 600 700 800 900</cell><cell>200</cell><cell>300</cell><cell>400</cell><cell cols="2">500 600 700 800 900</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>(a)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(e)</cell><cell></cell></row><row><cell></cell><cell>24</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>24</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Top1ValidationError(%)</cell><cell>18 20 22</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>18 20 22</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>16</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>16</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">200</cell><cell>300</cell><cell>400</cell><cell cols="2">500 600 700 800 900</cell><cell>200</cell><cell>300</cell><cell>400</cell><cell cols="2">500 600 700 800 900</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>(b)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(d)</cell><cell></cell></row><row><cell></cell><cell>10</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Histogram</cell><cell>5</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0</cell><cell>400</cell><cell cols="2">450</cell><cell>500</cell><cell>550</cell><cell>600</cell><cell>650</cell><cell>700</cell><cell>750</cell><cell>800</cell><cell>850</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(c)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Comparing the relative search efficiency of MSuNAS to other singleobjective methods: "#Model" is the total number of architectures evaluated during search, "#Epochs" is the number of epochs used to train each architecture during search. † and ‡ denote training epochs with and without a supernet to warm-start the weights, respectively.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Method</cell><cell></cell><cell></cell><cell cols="2">Type</cell><cell cols="6">Top1 Acc. #MAdds</cell><cell></cell><cell cols="3">#Model Speedup</cell><cell></cell><cell cols="5">#Epochs Speedup</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">NASNet-A [43]</cell><cell cols="2">RL</cell><cell></cell><cell cols="2">97.4%</cell><cell></cell><cell cols="2">569M</cell><cell></cell><cell>20,000</cell><cell></cell><cell>57x</cell><cell></cell><cell>20</cell><cell></cell><cell></cell><cell cols="2">up to 4x</cell></row><row><cell></cell><cell></cell><cell cols="3">CIFAR-10</cell><cell cols="6">AmoebaNet-B [31] EA PNASNet-5 [19] SMBO</cell><cell></cell><cell cols="2">97.5% 96.6%</cell><cell></cell><cell cols="2">555M 588M</cell><cell></cell><cell>27,000 1,160</cell><cell></cell><cell>77x 3.3x</cell><cell></cell><cell>25 20</cell><cell></cell><cell></cell><cell cols="2">up to 5x up to 4x</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">MSuNAS(ours)</cell><cell cols="2">EA</cell><cell></cell><cell cols="2">98.4%</cell><cell></cell><cell cols="2">468M</cell><cell></cell><cell>350</cell><cell></cell><cell>1x</cell><cell></cell><cell cols="2">5  † / 20  ‡</cell><cell></cell><cell>1x</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">MnasNet-A [35]</cell><cell cols="2">RL</cell><cell></cell><cell cols="2">75.2%</cell><cell></cell><cell cols="2">312M</cell><cell></cell><cell>8,000</cell><cell></cell><cell>23x</cell><cell></cell><cell>5</cell><cell></cell><cell></cell><cell cols="2">up to 5x</cell></row><row><cell></cell><cell></cell><cell cols="3">ImageNet</cell><cell cols="3">OnceForAll [5]</cell><cell></cell><cell cols="2">EA</cell><cell></cell><cell cols="2">76.0%</cell><cell></cell><cell cols="2">230M</cell><cell></cell><cell>16,000</cell><cell></cell><cell>46x</cell><cell></cell><cell>0</cell><cell></cell><cell></cell><cell>-</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">MSuNAS(ours)</cell><cell cols="2">EA</cell><cell></cell><cell cols="2">75.9%</cell><cell></cell><cell cols="2">225M</cell><cell></cell><cell>350</cell><cell></cell><cell>1x</cell><cell></cell><cell cols="2">0  † / 5  ‡</cell><cell></cell><cell>1x</cell></row><row><cell>Hypervolume</cell><cell>0.68 0.7 0.72 0.74</cell><cell></cell><cell></cell><cell></cell><cell>5x</cell><cell></cell><cell></cell><cell></cell><cell>Rank-order Correlation</cell><cell>100 0.5 0.6 0.7 0.8 0.9 1 3</cell><cell>150</cell><cell>200</cell><cell>250</cell><cell>300</cell><cell>Hypervolume</cell><cell>0.66 0.68 0.7 0.72 0.74</cell><cell></cell><cell></cell><cell></cell><cell>2x</cell><cell></cell><cell></cell><cell>Rank-order Correlation</cell><cell>6 7 8 9 10 100 0.2 0.4 0.6 0.8 1</cell><cell>150</cell><cell>200</cell><cell>250</cell><cell>300</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>5</cell><cell></cell></row><row><cell></cell><cell>0.64 0.66</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">NSGANet-v2 NSGANet Random Search</cell><cell>RMSError</cell><cell>1 2</cell><cell></cell><cell></cell><cell cols="2">NSGANet-v2</cell><cell></cell><cell>0.62 0.64</cell><cell></cell><cell></cell><cell></cell><cell cols="3">NSGANet-v2 NSGANet Random Search</cell><cell>RMSError</cell><cell>4 5 6 7 8 9 1 2 3 4</cell><cell></cell><cell>NSGANet-v2</cell></row><row><cell></cell><cell>0.62</cell><cell>200</cell><cell>400</cell><cell>600</cell><cell>800</cell><cell>1000</cell><cell>1200</cell><cell>1400</cell><cell>1600</cell><cell>100</cell><cell>150</cell><cell>200</cell><cell>250</cell><cell>300</cell><cell></cell><cell>100 0.6</cell><cell>200</cell><cell>300</cell><cell>400</cell><cell>500</cell><cell>600</cell><cell>700</cell><cell></cell><cell>100 3</cell><cell>150</cell><cell>200</cell><cell>250</cell><cell>300</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">Number of architectures sampled</cell><cell></cell><cell></cell><cell cols="5">Number of architectures sampled</cell><cell></cell><cell></cell><cell></cell><cell cols="3">Number of architectures sampled</cell><cell></cell><cell></cell><cell></cell><cell cols="3">Number of architectures sampled</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="5">(a) ImageNet</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">(b) CIFAR-10</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>ImageNet Classification<ref type="bibr" target="#b31">[32]</ref>: comparing NSGANetV2 with manual and automated design of efficient networks. Models are grouped into sections for better visualization. Our results are underlined and best result in each section is in bold. CPU latency (batchsize=1) is measured on Intel i7-8700K and GPU latency (batchsize=64) is measured on 1080Ti. † The search cost excludes the supernet training cost. ‡ Estimated based on the claim that PNAS is 8x faster than NASNet from<ref type="bibr" target="#b18">[19]</ref>.</figDesc><table><row><cell>Model</cell><cell>Type</cell><cell>Search Cost (GPU days)</cell><cell cols="2">#Params #MAdds</cell><cell>CPU Lat. (ms)</cell><cell>GPU Lat. (ms)</cell><cell>Top-1 Acc. (%)</cell><cell>Top-5 Acc. (%)</cell></row><row><cell>NSGANetV2-s</cell><cell>auto</cell><cell>1  †</cell><cell>6.1M</cell><cell>225M</cell><cell>9.1</cell><cell>30</cell><cell>77.4</cell><cell>93.5</cell></row><row><cell>MobileNetV2 [33]</cell><cell>manual</cell><cell>0</cell><cell>3.4M</cell><cell>300M</cell><cell>8.3</cell><cell>23</cell><cell>72.0</cell><cell>91.0</cell></row><row><cell>FBNet-C [39]</cell><cell>auto</cell><cell>9</cell><cell>5.5M</cell><cell>375M</cell><cell>9.1</cell><cell>31</cell><cell>74.9</cell><cell>-</cell></row><row><cell>ProxylessNAS [6]</cell><cell>auto</cell><cell>8.3</cell><cell>7.1M</cell><cell>465M</cell><cell>8.5</cell><cell>27</cell><cell>75.1</cell><cell>92.5</cell></row><row><cell cols="2">MobileNetV3 [15] combined</cell><cell>-</cell><cell>5.4M</cell><cell>219M</cell><cell>10.0</cell><cell>33</cell><cell>75.2</cell><cell>-</cell></row><row><cell>OnceForAll [5]</cell><cell>auto</cell><cell>2  †</cell><cell>6.1M</cell><cell>230M</cell><cell>9.5</cell><cell>31</cell><cell>76.9</cell><cell>-</cell></row><row><cell>NSGANetV2-m</cell><cell>auto</cell><cell>1  †</cell><cell>7.7M</cell><cell>312M</cell><cell>11.4</cell><cell>37</cell><cell>78.3</cell><cell>94.1</cell></row><row><cell cols="2">EfficientNet-B0 [36] auto</cell><cell>-</cell><cell>5.3M</cell><cell>390M</cell><cell>14.4</cell><cell>46</cell><cell>76.3</cell><cell>93.2</cell></row><row><cell>MixNet-M [37]</cell><cell>auto</cell><cell>-</cell><cell>5.0M</cell><cell>360M</cell><cell>24.3</cell><cell>79</cell><cell>77.0</cell><cell>93.3</cell></row><row><cell>AtomNAS-C+ [25]</cell><cell>auto</cell><cell>1  †</cell><cell>5.5M</cell><cell>329M</cell><cell>-</cell><cell>-</cell><cell>77.2</cell><cell>93.5</cell></row><row><cell>NSGANetV2-l</cell><cell>auto</cell><cell>1  †</cell><cell>8.0M</cell><cell>400M</cell><cell>12.9</cell><cell>52</cell><cell>79.1</cell><cell>94.5</cell></row><row><cell>PNASNet-5 [19]</cell><cell>auto</cell><cell>250  ‡</cell><cell>5.1M</cell><cell>588M</cell><cell>35.6</cell><cell>82</cell><cell>74.2</cell><cell>91.9</cell></row><row><cell>NSGANetV2-xl</cell><cell>auto</cell><cell>1  †</cell><cell>8.7M</cell><cell>593M</cell><cell>16.7</cell><cell>73</cell><cell>80.4</cell><cell>95.2</cell></row><row><cell cols="2">EfficientNet-B1 [36] auto</cell><cell>-</cell><cell>7.8M</cell><cell>700M</cell><cell>21.5</cell><cell>78</cell><cell>78.8</cell><cell>94.4</cell></row><row><cell>MixNet-L [37]</cell><cell>auto</cell><cell>-</cell><cell>7.3M</cell><cell>565M</cell><cell>29.4</cell><cell>105</cell><cell>78.9</cell><cell>94.2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>while being equivalent in #MAdds and latencies; NSGANetV2-xl achieves 80.4% Top-1 accuracy under 600M MAdds, which is 1.5% more</figDesc><table><row><cell></cell><cell></cell><cell cols="5">NSGANetV2 (ours)</cell><cell></cell><cell></cell><cell cols="2">MUXNet</cell><cell></cell><cell></cell><cell cols="2">FairNAS</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">NSGANet</cell><cell></cell><cell></cell><cell cols="3">DPP-Net</cell><cell></cell><cell cols="3">EfficientNet-B0</cell><cell>MixNet-M</cell></row><row><cell></cell><cell></cell><cell cols="4">Mobilenet v3</cell><cell></cell><cell></cell><cell></cell><cell cols="2">PNASNet-5</cell><cell></cell><cell></cell><cell cols="2">NASNet-A</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">MobileNet v2</cell><cell></cell><cell cols="3">DenseNet-169</cell><cell></cell><cell cols="3">ResNet-50</cell><cell>Inception v3</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">ImageNet</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">CIFAR-10</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>CIFAR-100</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>98.5</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>80</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>88</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>98</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Top-1 Acc (%)</cell><cell>74 76 78</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>96 96.5 97 97.5</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>84 86</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>95.5</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>82</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>72</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>95</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>2</cell><cell>3</cell><cell></cell><cell>4</cell><cell>5</cell><cell>6</cell><cell>7</cell><cell>8</cell><cell>9</cell><cell>100</cell><cell></cell><cell></cell><cell>2</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell></cell><cell>5</cell><cell>6</cell><cell>7</cell><cell>8 9</cell><cell>100</cell><cell></cell><cell>2</cell><cell></cell><cell>3</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>6</cell><cell>7</cell><cell>8 9</cell><cell>100</cell><cell>2</cell><cell>3</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="6">GPU Latency (ms)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>98.5</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>80</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>88</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>98</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Top-1 Acc (%)</cell><cell>74 76 78</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>96 96.5 97 97.5</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>84 86</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>95.5</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>82</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>72</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>95</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell cols="2">6 7 8 9 1000</cell><cell></cell><cell></cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>6 7</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell cols="4">6 7 8 9 1000</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>6 7</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>6 7 8 9 1000</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>6 7</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="5">#MAdds (M)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>Fig. 6: Accuracy vs Efficiency: Top row compares predictive accuracy vs. GPU latency on a batch of 64 images. Bottom row compares predictive accuracy vs. number of multi-adds in millions. Models from multi-objective approaches are joined with lines. Our models are obtained by directly searching on the respective datasets. In most problems, MSuNAS finds more accurate solutions with fewer parameters.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>Kendalls Tau<ref type="bibr" target="#b15">[16]</ref> rank-order correlation comparison among different surrogate models. For each model, we calculate the correlation on 350 architectures fully trained and evaluated during the search and we report the mean value over five runs. Right: MSuNAS search performance, measured by hypervolume<ref type="bibr" target="#b42">[42]</ref>, with different surrogate models. Empirically, we observe a positive correlation between rank-order correlation in surrogate model predictions and the search performance when paired with MSuNAS. All experiments are performed on ImageNet<ref type="bibr" target="#b31">[32]</ref>. In general, the rank-order correlation of MSuNAS (∼ 0.9) is significantly better than that achieved by ProgressiveNAS<ref type="bibr" target="#b18">[19]</ref> (0.476). Mining for Insights Every single run of MSuNAS generates a set of architectures. Mining the information that is generated through that process allows practitioners to choose a suitable architecture a posteriori to the search. To demonstrate one such scenario, we ran MSuNAS to optimize the predictive performance along with one of four different efficiency related measurements, namely MAdds, Params, CPU and</figDesc><table><row><cell>Input</cell><cell></cell><cell>Layerwise</cell><cell></cell><cell></cell><cell></cell><cell>Input</cell><cell></cell><cell>Layerwise</cell><cell></cell></row><row><cell cols="2">Resolution</cell><cell>[ExpansionRate,KernelSize]</cell><cell></cell><cell></cell><cell></cell><cell cols="2">Resolution</cell><cell>[ExpansionRate,KernelSize]</cell><cell></cell></row><row><cell></cell><cell>Skip</cell><cell></cell><cell>1</cell><cell></cell><cell></cell><cell></cell><cell>Skip</cell><cell></cell><cell></cell><cell>1</cell></row><row><cell>140</cell><cell>[33]</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>140</cell><cell>[33]</cell><cell></cell><cell></cell></row><row><cell></cell><cell>[35]</cell><cell></cell><cell>0.8</cell><cell></cell><cell></cell><cell></cell><cell>[35]</cell><cell></cell><cell></cell><cell>0.8</cell></row><row><cell>160</cell><cell>[37]</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>160</cell><cell>[37]</cell><cell></cell><cell></cell></row><row><cell></cell><cell>[43]</cell><cell></cell><cell>0.6</cell><cell></cell><cell></cell><cell></cell><cell>[43]</cell><cell></cell><cell></cell><cell>0.6</cell></row><row><cell>180</cell><cell>[45]</cell><cell></cell><cell>0.4</cell><cell></cell><cell></cell><cell>180</cell><cell>[45]</cell><cell></cell><cell></cell><cell>0.4</cell></row><row><cell></cell><cell>[47]</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>[47]</cell><cell></cell><cell></cell></row><row><cell>200</cell><cell>[63]</cell><cell></cell><cell>0.2</cell><cell></cell><cell></cell><cell>200</cell><cell>[63]</cell><cell></cell><cell></cell><cell>0.2</cell></row><row><cell></cell><cell>[65]</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>[65]</cell><cell></cell><cell></cell></row><row><cell cols="3">Tau= 0.90 70 Tau= 0.95 70 Predicted MLP RBF Fig. 9: Left: B Post Search Analysis 75 70 75 Tau= 0.83 68 70 72 70 75 75 70 75 Tau= 0.89 70 70 75 Predicted FullEvaluation FullEvaluation CART GP 5 10 15 20 [67] (a) MAdds 220 200 180 160 140 5 10 15 20 [67] [65] [63] [47] [45] [43] [37] [35] [33] Skip Input Resolution Layerwise [ExpansionRate,KernelSize] B.1 220 (c) CPU latency</cell><cell>74 75 MLP 0 0 0.2 0.4 0.6 0.8 1</cell><cell>76</cell><cell>CART Hypervolume</cell><cell cols="2">100 RBF Input 220 0.62 0.64 0.66 0.68 0.7 0.72 0.74 220 200 180 160 140 Resolution [67] GP [67] [65] [63] [47] [45] [43] [37] [35] [33] Skip</cell><cell>150 Numberofarcitecturessampled 200 250 5 10 15 (b) Params 5 10 15 Layerwise [ExpansionRate,KernelSize] (d) GPU latency</cell><cell>300</cell><cell>20 20</cell><cell>350</cell><cell>0 0 0.2 0.4 0.6 0.8 1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>. All architectures are found by simultaneously maximizing predictive performance and minimizing MAdds. We observe that different datasets require different architectures for an efficient trade-off between MAdds and performance. Finding such architectures</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Legend</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>K=3 E=3</cell><cell>K=3 E=4</cell><cell>K=3 E=6</cell><cell>K=5 E=3</cell><cell>K=5 E=4</cell><cell>K=5 E=6</cell><cell>K=7 E=3</cell><cell>K=7 E=4</cell><cell>K=7 E=6</cell><cell>Skip</cell></row><row><cell>Stage 1</cell><cell>Stage 2</cell><cell>Stage 3</cell><cell>Stage 4</cell><cell>Stage 5</cell><cell></cell><cell></cell><cell></cell><cell>Stage 1</cell><cell>Stage 2</cell><cell>Stage 3</cell><cell>Stage 4</cell><cell>Stage 5</cell></row><row><cell>Stem</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Tail</cell><cell></cell><cell>Stem</cell><cell></cell><cell></cell><cell>Tail</cell></row><row><cell>Stem</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Tail</cell><cell></cell><cell>Stem</cell><cell></cell><cell></cell><cell>Tail</cell></row><row><cell>Stem</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Tail</cell><cell></cell><cell>Stem</cell><cell></cell><cell></cell><cell>Tail</cell></row><row><cell>Stem</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Tail</cell><cell></cell><cell>Stem</cell><cell></cell><cell></cell><cell>Tail</cell></row><row><cell></cell><cell cols="3">(a) ImageNet</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">(b) CIFAR-10</cell></row><row><cell>Stage 1</cell><cell>Stage 2</cell><cell>Stage 3</cell><cell>Stage 4</cell><cell>Stage 5</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Stem</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Tail</cell><cell></cell><cell></cell><cell>Stage 1</cell><cell>Stage 2</cell><cell>Stage 3</cell><cell>Stage 4</cell><cell>Stage 5</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Stem</cell><cell></cell><cell></cell><cell>Tail</cell></row><row><cell>Stem</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Tail</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Stem</cell><cell></cell><cell></cell><cell>Tail</cell></row><row><cell>Stem</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Tail</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Stem</cell><cell></cell><cell></cell><cell>Tail</cell></row><row><cell>Stem</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Tail</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">(d) CINIC-10</cell></row><row><cell></cell><cell cols="3">(c) CIFAR-100</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Stage 1</cell><cell>Stage 2</cell><cell>Stage 3</cell><cell>Stage 4</cell><cell>Stage 5</cell><cell></cell><cell></cell><cell></cell><cell>Stage 1</cell><cell>Stage 2</cell><cell>Stage 3</cell><cell>Stage 4</cell><cell>Stage 5</cell></row><row><cell>Stem</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Tail</cell><cell></cell><cell>Stem</cell><cell></cell><cell></cell><cell>Tail</cell></row><row><cell>Stem</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Tail</cell><cell></cell><cell>Stem</cell><cell></cell><cell></cell><cell>Tail</cell></row><row><cell>Stem</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Tail</cell><cell></cell><cell>Stem</cell><cell></cell><cell></cell><cell>Tail</cell></row><row><cell></cell><cell cols="3">(e) STL-10</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">(f) Oxford Flowers-102</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Estimate from # of models evaluated by PNAS, actual sample size is not reported.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">In the Appendix A we show that better rank-order correlation at the search stage ultimately leads to finding better performing architectures.</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix</head><p>Recall that Neural Architecture Search (NAS) is formulated as a bi-level optimization problem in the original paper. The key idea of MSuNAS is to adopt a surrogate model at both the upper and lower level in order to improve the efficiency of solving the NAS bi-level problem. In this appendix, we include the following material: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Correlation Between Search Performance and Surrogate Model</head><p>In MSuNAS, we use a surrogate model at the upper architecture level to reduce the number of architectures sent to the lower level for weight learning. There are at least two desired properties of a surrogate model, namely:</p><p>-a high rank-order correlation between the performance predicted by the surrogate model and the true performance -a high sample-efficiency such that the number of architectures, that are fully trained and evaluated, for constructing the surrogate model is as low as possible</p><p>In this section, we aim to quantify the correlation between the surrogate model's rank-order correlation (Kendall' Tau <ref type="bibr" target="#b15">[16]</ref>) and MSuNAS's search performance. On ImageNet dataset, we run MSuNAS with four different surrogate models, including Multi-Layer Perceptron (MLP), Classification And Regression Trees (CART), Radial Basis Function (RBF) and Gaussian Processes (GP). We record the accumulative hypervolume <ref type="bibr" target="#b42">[42]</ref> and calculate the rank-order correlation on all architectures evaluated during the search. The results are provided in <ref type="figure">Fig. 9</ref>.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Accelerating neural architecture search using performance prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Raskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Naik</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.10823</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Mixmatch: A holistic approach to semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>Raffel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Mathematical programs with optimization problems in the constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bracken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Mcgill</surname></persName>
		</author>
		<ptr target="http://www.jstor.org/stable/169087" />
	</analytic>
	<monogr>
		<title level="j">Operations Research</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="37" to="44" />
			<date type="published" when="1973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">SMASH: One-shot model architecture search through hypernetworks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Brock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ritchie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Once for all: Train one network and specialize it for efficient deployment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">ProxylessNAS: Direct neural architecture search on target task and hardware</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Fairnas: Rethinking evaluation fairness of weight sharing neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.01845</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Describing textures in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cimpoi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">An analysis of single-layer networks in unsupervised feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics</title>
		<meeting>the Fourteenth International Conference on Artificial Intelligence and Statistics</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Chamnet: Towards efficient network design through platform-aware model adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dukhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">N</forename><surname>Darlow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Crowley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Antoniou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Storkey</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.03505</idno>
		<title level="m">Cinic-10 is not imagenet or cifar-10</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A fast and elitist multiobjective genetic algorithm: Nsga-ii</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pratap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Meyarivan</surname></persName>
		</author>
		<idno type="DOI">10.1109/4235.996017</idno>
		<ptr target="https://doi.org/10.1109/4235.996017" />
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="182" to="197" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Dpp-net: Device-aware progressive search for pareto-optimal neural architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">C</forename><surname>Juan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Efficient multi-objective neural architecture search via lamarckian evolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Elsken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Metzen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Adam</surname></persName>
		</author>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>Searching for mobilenetv3</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A NEW MEASURE OF RANK CORRELATION</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G</forename><surname>Kendall</surname></persName>
		</author>
		<idno type="DOI">10.1093/biomet/30.1-2.81</idno>
		<ptr target="https://doi.org/10.1093/biomet/30.1-2.81" />
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="81" to="93" />
			<date type="published" when="1938-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>Citeseer</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Tech. rep</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Talwalkar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.07638</idno>
		<title level="m">Random search and reproducibility for neural architecture search</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Progressive neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">DARTS: Differentiable architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Muxconv: Information multiplexing in convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">N</forename><surname>Boddeti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Nsga-net: Neural architecture search using multi-objective genetic algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Whalen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Boddeti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Dhebar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Banzhaf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Genetic and Evolutionary Computation Conference (GECCO)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">Y</forename><surname>Liu</surname></persName>
		</author>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>Neural architecture optimization</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Fine-grained visual classification of aircraft</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kannala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rahtu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Blaschko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Tech. rep</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Atom{nas}: Finegrained end-to-end neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Derived heuristics-based consistent optimization of material flow in a gold processing plant</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Myburgh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Deb</surname></persName>
		</author>
		<idno type="DOI">10.1080/0305215X.2017.1296436</idno>
		<ptr target="https://doi.org/10.1080/0305215X.2017.1296436" />
	</analytic>
	<monogr>
		<title level="j">Engineering Optimization</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="18" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Xnas: Neural architecture search with expert advice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Nayman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Noy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ridnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zelnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Automated flower classification over a large number of classes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nilsback</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Sixth Indian Conference on Computer Vision, Graphics Image Processing</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Cats and dogs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">M</forename><surname>Parkhi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Jawahar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Efficient neural architecture search via parameters sharing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Regularized evolution for image classifier architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Real</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Imagenet large scale visual recognition challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bernstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="252" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zhmoginov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">C</forename><surname>Chen</surname></persName>
		</author>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>Mobilenetv2: Inverted residuals and linear bottlenecks</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Surrogate-assisted evolutionary deep learning using an end-to-end random forest-based performance predictor</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">G</forename><surname>Yen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title/>
		<idno type="DOI">10.1109/TEVC.2019.2924461</idno>
		<ptr target="https://doi.org/10.1109/TEVC.2019.2924461" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Mnasnet: Platform-aware neural architecture search for mobile</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Efficientnet: Rethinking model scaling for convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Mixconv: Mixed depthwise convolutional kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">British Machine Vision Conference (BMVC)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Enaet: Self-trained ensemble autoencoding transformations for semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kihara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">J</forename><surname>Qi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.09265</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Fbnet: Hardware-aware efficient convnet design via differentiable neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vajda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Keutzer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Exploring randomly wired neural networks for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kirillov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Evaluating the search phase of neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sciuto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jaggi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Musat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Salzmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Multiobjective optimization using evolutionary algorithmsa comparative case study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Zitzler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Thiele</surname></persName>
		</author>
		<editor>Eiben, A.E., Bäck, T., Schoenauer, M., Schwefel, H.P.</editor>
		<imprint>
			<date type="published" when="1998" />
			<publisher>Springer</publisher>
			<biblScope unit="page" from="292" to="301" />
			<pubPlace>Berlin Heidelberg; Berlin; Heidelberg</pubPlace>
		</imprint>
	</monogr>
	<note>Parallel Problem Solving from Nature -PPSN V</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Learning transferable architectures for scalable image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
