<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Local Spectral Graph Convolution for Point Set Feature Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chu</forename><surname>Wang</surname></persName>
							<email>chuwang@cim.mcgill.ca</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Center for Intelligent Machines</orgName>
								<orgName type="institution">McGill University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Babak</forename><surname>Samari</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Center for Intelligent Machines</orgName>
								<orgName type="institution">McGill University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaleem</forename><surname>Siddiqi</surname></persName>
							<email>siddiqi@cim.mcgill.ca</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Center for Intelligent Machines</orgName>
								<orgName type="institution">McGill University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Local Spectral Graph Convolution for Point Set Feature Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T22:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Point Set Features</term>
					<term>Graph Convolution</term>
					<term>Spectral Filtering</term>
					<term>Spectral Coordinates</term>
					<term>Clustering</term>
					<term>Deep Learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Feature learning on point clouds has shown great promise, with the introduction of effective and generalizable deep learning frameworks such as point-net++. Thus far, however, point features have been abstracted in an independent and isolated manner, ignoring the relative layout of neighboring points as well as their features. In the present article, we propose to overcome this limitation by using spectral graph convolution on a local graph, combined with a novel graph pooling strategy. In our approach, graph convolution is carried out on a nearest neighbor graph constructed from a point's neighborhood, such that features are jointly learned. We replace the standard max pooling step with a recursive clustering and pooling strategy, devised to aggregate information from within clusters of nodes that are close to one another in their spectral coordinates, leading to richer overall feature descriptors. Through extensive experiments on diverse datasets, we show a consistent demonstrable advantage for the tasks of both point set classification and segmentation.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>With the present availability of registered depth and appearance images of complex realworld scenes, there is tremendous interest in feature processing algorithms for classic computer vision problems including object detection, classification and segmentation. In their latest incarnation, for example, depth sensors are now found in the apple iPhone X camera, making a whole new range of computer vision technology available to the common user. For such data it is particularly attractive to work directly with the unorganized 3D point clouds and to not require an intermediate representation such as a surface mesh. The processing of 3D point clouds from such sensors remains challenging, since the sensed depth points can vary in spatial density, can be incomplete due to occlusion or perspective effects and can suffer from sensor noise.</p><p>Motivated by the need to handle unstructured 3D point clouds while leveraging the power of deep neural networks, the pointnet++ framework has shown promise for 3D point cloud feature processing for the tasks of recognition and segmentation <ref type="bibr" target="#b12">[13]</ref>. In this approach a network structure is designed to work directly with point cloud data, while aggregating information in a hierarchical fashion, in the spirit of traditional CNNs on arXiv:1803.05827v1 [cs.CV] 15 Mar 2018 Then, for each neighborhood, spectral convolution is carried out followed by recursive cluster pooling. After several layers of sampling, spectral convolution and cluster pooling, we perform segmentation or classification. BOTTOM: The green dashed box details the process of recursive spectral cluster pooling on the Fiedler vector of a sample neighborhood. See text in Section 4 for a discussion. regular grids. To do so, a centroid sampling is first applied on the input point cloud, followed by a radius search to form point neighborhoods. Then the point neighborhoods are processed by multi-layer perceptrons <ref type="bibr" target="#b10">[11]</ref> and the resulting point features are abstracted by a pooling operation. Through hierarchical multi-layer learning on the point cloud data, the pointnet++ framework exhibits impressive performance in both segmentation and classification on challenging benchmarks, while treating the input data as an unorganized point cloud.</p><p>In a parallel development, Defferrard et al. have sought to extend CNNs, traditionally applied on regular domains, such as sampled image pixels in 2D or voxels in 3D, to irregular domains represented as graphs <ref type="bibr" target="#b3">[4]</ref>. Their approach uses Chebyshev polynomials to approximate spectral graph filters; an initial graph is processed by convolutional operations to yield features which are then coarsened using sub-sampling and pooling methods. Kipf and Welling <ref type="bibr" target="#b5">[6]</ref> simplify the higher order polynomial approximations in Defferrard et al. and propose a first order linear approximation of spectral graph filters. The aforementioned spectral approaches operate on the full graph and have the limitation that the graph Laplacian and the graph coarsening hierarchy have to be precomputed, in an offline manner, before the network training or testing. This adds significant overhead when the full graph is large.</p><p>In this article we propose to leverage the power of spectral graph CNNs in the pointnet++ framework, while adopting a different pooling strategy. This allows us to address two limitations of present deep learning methods from point clouds: 1) the fact that for each point sample the learning of features is carried out in an isolated manner in a local neighborhood and 2) that the aggregation of information in later layers uses a greedy winner-take-all max pooling strategy. Instead, we adopt a different pooling module, as illustrated by the detailed example in <ref type="figure" target="#fig_0">Fig. 1</ref>. Further, our method requires no precomputation, in contrast to existing spectral graph CNN approaches <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b5">6]</ref>. Our combination of local spectral feature learning with recursive clustering and pooling provides a novel architecture for point set feature abstraction from unorganized point clouds. Our main methodological contributions are the following:</p><p>-The use of local spectral graph convolution in point set feature learning to incorporate structural information in the neighborhood of each point. -An implementation of the local spectral graph convolution layer that requires no offline computation and is trainable in an end-to-end manner. We build the graph dynamically during runtime and compute the Laplacian and pooling hierarchy on the fly. -The use of a novel and effective graph pooling strategy, which aggregates features at graph nodes by recursively clustering the spectral coordinates.</p><p>The proposed architecture leads to new state-of-the-art object recognition and segmentation results on diverse datasets, as demonstrated by extensive experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Challenges in point set feature learning</head><p>A limitation of feature learning in the pointnet++ framework <ref type="bibr" target="#b12">[13]</ref>, is that features from the k nearest neighbors (k-NN) of a point are learned in an isolated fashion. Let h represent the output of an arbitrary hidden layer in a deep network, typically a multilayer perceptron. In pointnet++ the individual features for each point in the k-NN are achieved with h(x i ), i ∈ 1, 2, ..., k. Unfortunately, this hidden layer function does not model the joint relationship between points in the k-NN. A convolution kernel that jointly learns features from all points in the k-NN would capture topological information related to the geometric layout of the points, as well as features related to the input point samples themselves, e.g., color, texture, or other attributes. In the following section we shall extend approaches such as the pointnet++ framework to achieve this goal by using local graph convolution, but in the spectral domain. Another limitation in pointnet++ is that the set activation function for the k-NN is achieved by max pooling across the hidden layer's output for each point, such that</p><formula xml:id="formula_0">f (x 1 , x 2 , ..., x k ) = max i∈1,...,k h(x i ).<label>(1)</label></formula><p>Max pooling does not allow for the preservation of information from disjoint sets of points within the neighborhood, as in the case of the legs of the ant in <ref type="figure" target="#fig_0">Fig. 1</ref>. To address this limitation we introduce a recursive spectral clustering and pooling module that yields an improved set activation function for the k-NN, as discussed in Section (4). The combined point set feature abstraction operation in this paper can be summarized by where h i is the convolution output h(x 1 , x 2 , ..., x k ) evaluated at the i-th point and ⊕ stands for our proposed set activation function. <ref type="figure" target="#fig_1">Fig. 2</ref> provides a comparison between the point-wise MLP in pointnet++ <ref type="bibr" target="#b12">[13]</ref> and our spectral graph convolution, to better illustrate our motivation. Whereas pointnet++ abstracts point features in an isolated manner, spectral graph convolution considers all points in a local neighborhood in a joint manner, incorporating both features at neighboring points as well as structural information encoded in the graph topology in the abstraction. More formally, this is accomplished via the graph Fourier transform and spectral modulation steps, which blend neighborhood features using the eigenspace of the graph Laplacian (see <ref type="figure" target="#fig_2">Fig. 3</ref>). In the following section, we provide theoretical background and implementation details of our spectral graph convolution kernel.</p><formula xml:id="formula_1">f (x 1 , x 2 , ..., x k ) = ⊕(h 1 , h 2 , ..., h k ),<label>(2)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Graph Convolution</head><p>The convolution operation in the spatial domain (directly on vertices in the graph) is described by</p><formula xml:id="formula_2">h = X * g,<label>(3)</label></formula><p>where X stands for the input point set features and g for a spatial convolution kernel. This is equivalent to an element-wise Hadamard product in the graph spectral domain, as is shown in Defferrard et al. <ref type="bibr" target="#b3">[4]</ref> and Shuman et al. <ref type="bibr" target="#b14">[15]</ref> h =X g.</p><p>HereX stands for the graph Fourier transform of the point set features,g stands for the filter in the graph Fourier domain andh for the filtered output. In order to acquire the filtered output in the original spatial (vertex) domain, an inverse Fourier transform is required. We elaborate on the graph Fourier transform and the spectrum filtering below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Graph Formulation of a Local Neighborhood</head><p>Given a set of k points x 1 , x 2 , ..., x k in a local neighborhood, we build a representation graph G k whose vertices V are the points and whose edges E ⊆ V × V carry weights w : E → R * + based on a measurement of pair-wise distance, such as Euclidean distance between xyz spatial coordinates or distance in a feature space provided by the deep network. This provides a graph adjacency matrix W , which is k × k nonnegative, symmetric, with entries W ij = dist(x i , x j ). We then compute the graph spectrum based on this adjacency matrix and perform a graph Fourier transform, spectral filtering and finally an inverse Fourier transform.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Graph Fourier Transform</head><p>To compute a graph Fourier Transform of the point features X ∈ R k×m , which are graph signals on vertices of G k , we first need to compute the normalized graph Laplacian defined as</p><formula xml:id="formula_4">L = I − D 1/2 W D 1/2 ,<label>(5)</label></formula><p>where I is the identity matrix and D ∈ R k×k is the diagonal degree matrix with entries D ii = j W ij . It follows that L is a real symmetric positive semidefinite matrix, and has a complete set of orthonormal eigenvectors which comprise the graph Fourier basis</p><formula xml:id="formula_5">U = [u 0 , u 1 , ..., u k−1 ] ∈ R k×k .<label>(6)</label></formula><p>The eigenvalues can be used to construct a diagonal matrix</p><formula xml:id="formula_6">Λ = diag([λ 0 , λ 1 , ..., λ k−1 ]) ∈ R k×k<label>(7)</label></formula><p>which contains the frequencies of the graph. Then it follows that L = U ΛU T . The graph Fourier transform of X is then defined asX = U T X and its inverse as X = UX.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Spectral Filtering</head><p>The convolution operation is defined in the Fourier domain as</p><formula xml:id="formula_7">x * g = U ((U T x) (U T g)),<label>(8)</label></formula><p>following Shuman et al. <ref type="bibr" target="#b14">[15]</ref>, where is the element-wise Hadamard product, x is an arbitrary graph signal and g is a spatial filter. If we define y = x * g as the output of the graph convolution, it follows that a graph signal X ∈ R k×m filtered by g can be written as</p><formula xml:id="formula_8">y =g θ (L)X =g θ (U ΛU T )X = Ug θ (Λ)X,<label>(9)</label></formula><p>where θ stands for an arbitrary parametrization. In the following section, we describe our implementation of spectral filtering, which is introduced as a module on top of the existing pointnet++ <ref type="bibr" target="#b12">[13]</ref> framework, using TensorFlow.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Implementation of Spectral Filtering</head><p>We carry out spectral graph convolution using standard unparametrized Fourier kernels, where the entries ofg θ (Λ) are all learnable. With m the input feature dimension and m the output dimension, convolution of a graph signal X ∈ R k×m with spectral filters can be achieved by the following three steps:</p><p>1. Spectral modulation which outputs P = GX, with the diagonal matrix G being the unparametrized kernelg θ (Λ). The k diagonal entries of G are all free parameters in the unparametrized Fourier kernel formulation. 2. Feature filtering which expands the input dimension from m to m . The output of this step is a feature matrix Q ∈ R k×m . The entry q k,i is the i-th output feature of the k-th point and is given by q k,i = m j=1 p k,j w j,i . Here p k,j is the entry of P corresponding to the j-th input feature of the k-th point defined in the previous step and w j,i is the filter coefficient between the i-th input feature with j-th output feature. This step can be represented by Q = P W , where W is the matrix of learnable filter parameters. The filtering operation in steps 1 and 2 can be summarized as Q = (GX)W.</p><p>3. Reverse Fourier transform which provides convolution outputs in the spatial graph signal domain via y = U Q.</p><p>The above formulation resembles that of <ref type="bibr" target="#b3">[4]</ref> and <ref type="bibr" target="#b5">[6]</ref>, with the difference that we build the k-NN graph during runtime, computing its Laplacian and pooling hierarchy on the fly, thereby requiring no offline precomputation. We further note that the weights of the feature filter W , as well as the spectral modulation matrix G, are shared by all the different local neighborhoods in a given graph convolution layer. Thus, unlike <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b5">6]</ref>, the learned parameters in our work do not depend on the underlying graph structure. <ref type="figure" target="#fig_1">Fig. 2</ref> (bottom) illustrates the above spectral filtering process. While the more sophisticated efficient kernels of <ref type="bibr" target="#b3">[4]</ref> could be used, our goal was to demonstrate the improvement obtained by graph CNNs in general. The overhead of eigenvalue decomposition (EVD) in our unparametrized spectral kernel does not significantly affect runtime since the EVD is computed on local k-NN graphs, with k being very small. This computation is easily handled by parallel computing on GPUs as demonstrated by the experiments showing training time cost in our model ablation study in Section 5.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Pooling on Local k-NN Graph</head><p>The set activation function discussed in Section 2, whose aim is to summarize information from a k-NN graph, is essentially a form of graph pooling, where a graph of k vertices is abstracted via feature pooling to a single vertex. We propose a novel k-NN graph pooling algorithm using hierarchical clustering and within-cluster pooling.</p><p>The general strategy is to pool information during learning in a manner that does so only within a cluster of similar abstract point features, in contrast to the greedy strategy of max pooling, which is commonly applied in regular CNNs as well as in pointnet++. The intuition here is that multiple sets of distinct features may together contribute towards a salient property for the task at hand, and that the detection of these clusters combined with within cluster pooling will improve performance. For example, for the task of classifying a point set sampled from a human head one would want to simultaneously learn and capture nose-like, chin-like and ear-like features and not assume that only one of these would be discriminative for this object category. We discuss each of our steps in turn.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Spectral Clustering</head><p>We propose to group features into clusters according to a local k-NN's geometric information that is embedded using spectral coordinates. The spectral coordinates we use are based on the low frequency eigenvectors of the Graph Laplacian L, which capture coarse shape properties since the Laplacian itself encodes pairwise distances in the k-NN graph. As exploited in <ref type="bibr" target="#b8">[9]</ref> [1] for computing point-to-point correspondences on meshes or for feature description, the low frequency spectral coordinates provide a discriminative spectral embedding of an object's local geometry (see <ref type="figure" target="#fig_0">Fig. 1</ref> bottom and <ref type="figure" target="#fig_2">Fig. 3</ref>). The eigenvector corresponding to the second smallest eigenvalue, the Fiedler vector <ref type="bibr" target="#b1">[2]</ref>, is widely used for spectral clustering <ref type="bibr" target="#b13">[14]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Clustering, Pooling and Recurrences</head><p>Following the normalized cuts clustering algorithm <ref type="bibr" target="#b13">[14]</ref>, we partition the Fiedler vector to perform spectral clustering in a local k-NN. We first sort the entries of the Fiedler vector in ascending order of their numerical value, and then evenly cut it into k 1 sections in the first iteration. The points in the neighborhood whose Fiedler vector entries fall in the same section will be clustered together. This results in k 1 clusters with a cluster size of c = k k1 . After obtaining a partition into k 1 clusters, we perform pooling operations only within each cluster. This allows the network to take advantage of separated features from possibly disjoint components in the k-NN graph.</p><p>The above steps result in a coarsened k 1 -NN graph with aggregated point features. The same process is then repeated on the coarsened graph in a recursive manner, to obtain k i clusters for each iteration i. Note that we alternate between max pooling and average pooling between different recurrences to further increase the discriminative power of the graph pooling algorithm. The proposed algorithm terminates when the number of vertices remaining is smaller or equal to a prescribed cluster size. A regular full stride pooling is then applied on the resultant graph signals. We formalize the above steps in Algorithm 1.</p><p>In practice, we found that using k = 2c 2 as a relationship between cluster size and neighborhood size gave good results, with two recurrences of cluster pooling and a final pooling of size 2. We used max pooling as the first stage in the alternating pooling scheme, and fixed these configurations for all our experiments in Section 5. We implemented the recursive cluster pooling module in TensorFlow, integrating it fully with the spectral graph convolution layer to make the resultant network end-to-end trainable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Datasets</head><p>We evaluate our approach against present state-of-the-art methods on the following 5 datasets:</p><p>-MNIST: This contains images of handwritten digits with 60k training and 10k testing samples. It has been used to benchmark related graph CNN approaches <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b9">10]</ref> as well as pointnet++ <ref type="bibr" target="#b12">[13]</ref>. -ShapeNet part segmentation dataset <ref type="bibr" target="#b19">[20]</ref>: This dataset contains 16,881 shapes from 16 classes, with the points of each model labeled into one of 50 part types. We use the official training/testing split, following <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b20">21]</ref>, where the challenge is to assign a part label to each point in the test set. -ScanNet Indoor Scene dataset <ref type="bibr" target="#b2">[3]</ref>: This dataset contains 1513 scanned and reconstructed indoor scenes, with rich annotations including semantic voxel labels. We follow the experimental settings for segmentation in <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b2">3]</ref>   <ref type="table" target="#tab_0">Table 1</ref>: Network architectures for the 1k experiments (left) and the 2k experiments (right). Here, for each layer, C stands for the number of centroids, k stands for the size of the k-NN, and m stands for the output feature dimension.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Network Architecture and Training</head><p>We provide details of our network structures for the case of 1024 input points (1k) and 2048 input points (2k). The network structure for the 2k experiments is designed to be "wider" to better accommodate the increased input point density. <ref type="table" target="#tab_0">Table 1</ref> lists all the variations of the pointnet++ and our spectral point convolution network structures, which we will later to refer to when presenting experimental results. The 3l-pointnet++ is that defined in the "pointnet2 cls ssg.py" model file on the pointnet++ GitHub page 1 . We replace the kernels from 4l-pointnet++ with spectral graph convolution kernels to acquire the 4l-spec-max model. Replacing max pooling with recursive cluster pooling in the 4l-spec-max model results in the 4l-spec-cp model.</p><p>Configurations for the layers after L3/L4 in <ref type="table" target="#tab_0">Table 1</ref> differ for the classification and segmentation tasks. For classification on the McGill Shape Benchmark, ModelNet40 and MNIST, we used 3 fully connected layers with drop out, i.e., FC(512, 0.5) → FC(256, 0.5) → FC(#classes). For segmentation on the ShapeNet Part Segmentation and ScanNet datasets, feature propagation (FP) layers (as in <ref type="bibr" target="#b12">[13]</ref>) are applied after   <ref type="table" target="#tab_0">Table 1</ref>.</p><p>L3/L4. The number of FP layers and their input/output dimensions are the same as those of the corresponding previous set activation layers. After the FP layers, two fully connected layers are applied to map learned features to point labels. In all our experiments, we applied the following strategy for network training. We used the Adam optimizer <ref type="bibr" target="#b4">[5]</ref> with an initial learning rate of 0.001 and an exponential decay on the learning rate with a ratio of 0.5 applied every 20 epochs. We chose to use the Relu activation function and applied batch normalization (BN) with a size of 32 and a decay rate set to increase from 0.5 to 0.99. Throughout we followed the strategy in pointnet++ <ref type="bibr" target="#b12">[13]</ref> for data augmentation: random rotation around the up-right direction, small rotation perturbation around the x, y, z axes, point location perturbation, and random scaling and translation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Ablation Study for Network Models</head><p>We now evaluate the effect of the novel components in our framework: 1) local spectral filtering on a k-NN and 2) recursive cluster pooling for local outputs. We apply a 4 layer pointnet++ structure as the baseline method, then add spectral filters to each layer, and then replace max pooling with recursive cluster pooling. We also include results obtained using the 3 layer structure used in <ref type="bibr" target="#b12">[13]</ref>. In addition, we consider the scalability of both approaches, by varying the number of input points, the effect of including additional features such as surface normals, and training time. These results are presented in <ref type="table" target="#tab_4">Table (2)</ref>.</p><p>From the model ablation study in <ref type="table" target="#tab_4">Table 2</ref>, it is evident that our proposed model, which incorporates spectral graph convolution together with recursive cluster pooling, provides a non-trivial improvement over pointnet++ on both the classification and segmentation tasks. We make the following observations: 1) 3l-pointnet++ performs better than the 4 layer version. This is likely because in the 4 layer version the neighborhood size is half of that in the 3 layer version. Since features are learned at each point in an isolated fashion in pointnet++, the use of larger neighborhoods gives an advantage. 2) Spectral graph convolution on local k-NNs performs better than point-wise MLP. The 4l-spec-max model outperforms 4l-pointnet++. This implies that the topological information encoded by spectral graph convolution benefits feature learning. 3) Recursive cluster pooling further boosts the performance of the spectral graph convolution layer. This suggests that information aggregation following spectral coordinates increases the discriminative power of the learned point features, benefiting both classification and segmentation. 4) The runtime of our model is comparable to those of pointnet++. The eigenvalue decomposition used in spectral convolution and recursive cluster pooling could in theory be costly, but since we use local neighborhoods the impact is not severe. Our best model, 4l-spec-cp, has roughly the same training time as that of 3l-pointnet++, which is the best model from pointnet++. Spectral graph convolution kernels are as fast as the point-wise MLP kernels, which can be seen by comparing the runtime of the 4l-spec-max and 4l-pointnet++ models.</p><p>We now provide comparisons against the present state-of-the-art methods, in both classification and segmentation tasks, on various datasets described in Section 5.1. When comparing against pointnet++, unless stated otherwise, we apply the 3l-pointnet++ model since it gives better results than the 4 layer version in our model ablation study in <ref type="table" target="#tab_4">Table 2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Classification Experiments</head><p>McGill Shape Benchmark The classification results for the McGill Shape Benchmark are presented in <ref type="table">Table 3</ref>, using 1024 xyz points as the inputs in all cases. Spectral graph convolution on point sets provides a consistent boost in both average instance level accuracy and category level accuracy. Further, the use of recursive cluster pooling grants our model another 0.7% boost in overall instance level accuracy over max pooling. Since the k-NNs may contain disjoint sets of points, a recursive aggregation of k-NN features by clustering the spectral coordinates appears to increase discriminative power for articulated objects.  <ref type="table">Table 3</ref>: McGill Shape Benchmark classification results. We report the instance and category level accuracy on both the entire database and on subsets (see <ref type="table" target="#tab_0">Table 1</ref> for network structures).</p><p>MNIST dataset 2D images can be treated as a grid graph <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b9">10]</ref> or a 2D point cloud <ref type="bibr" target="#b12">[13]</ref>. We provide results on the MNIST dataset using our proposed best model, 4l-speccp, from the previous model ablation study. We compare our results with the stateof-the-art methods in graph CNNs <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b9">10]</ref>, in point sets <ref type="bibr" target="#b12">[13]</ref> 2 and with regular neural network/CNN approaches applied on the 2D image domain <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b7">8]</ref>.</p><p>For both pointnet++ and our method, 784 points are provided as inputs to the network and we use the 1k experimental network, where the first layer samples 512 centroids (see <ref type="table" target="#tab_0">Table 1</ref>). The results in <ref type="table">Table 4</ref> show that approaches which favor local operations on the input domain usually yield better performance, for instance, MLP vs. LeNet, and our method vs. ChebNet. Our approach gives a 20% error rate reduction over pointnet++, demonstrating the advantage of spectral convolution on a local k-NN graph over the isolated learning process in point-wise MLP. In addition, our performance surpasses that of the Network in Network model <ref type="bibr" target="#b7">[8]</ref>, which is a strong regular image CNN model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Domain Kernel Error Rate(%)</p><p>Multi-layer perceptron <ref type="bibr" target="#b16">[17]</ref> full image spatial MLP 1.60 LeNet5 <ref type="bibr" target="#b6">[7]</ref> local img patch spatial conv 0.80 Network in Network <ref type="bibr" target="#b7">[8]</ref> local img patch spatial conv 0.47</p><p>ChebNet <ref type="bibr" target="#b3">[4]</ref> full graph spectral graph conv 0.86 MoNet <ref type="bibr" target="#b9">[10]</ref> local graph spatial graph conv 0.81 3l-pointnet++ <ref type="bibr" target="#b12">[13]</ref> local points spatial point-MLP 0.55 4l-spec-cp local k-NN graph spectral graph conv 0.42 <ref type="table">Table 4</ref>: Results on the MNIST dataset. For the pointnet++ results, we reproduced their experiments, as discussed in <ref type="bibr" target="#b12">[13]</ref>.</p><p>ModelNet 40 Dataset We present ModelNet40 3D shape recognition results in <ref type="table" target="#tab_7">Table  5</ref>, where we compare our method with representative competitive approaches. We were able to reproduce the results from pointnet++, to get very similar performance to that reported by the authors in <ref type="bibr" target="#b12">[13]</ref>. We report two sets of accuracy results. In the first 1024 xyz point coordinates are used as inputs, with the network structure following the 1k configurations in <ref type="table" target="#tab_0">Table 1</ref>. In the second 2048 xyz points along with their surface normals are used as inputs, with the network structure following the 2k configurations in <ref type="table" target="#tab_0">Table 1</ref>. Our use of spectral graph convolution and recursive cluster pooling provides a consistent improvement over pointnet++, and leads to state-of-the-art level classification performance on the ModelNet40 Benchmark.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Segmentation Experiments</head><p>Point segmentation is a labeling task for each point in a 3D point set, and is more challenging than point set classification. We present experimental results on ShapeNet <ref type="bibr" target="#b19">[20]</ref> and ScanNet <ref type="bibr" target="#b2">[3]</ref> in <ref type="table">Table 6</ref>. We then provide details on experimental settings for each case.   <ref type="table">Table 6</ref>: A comparison between our method and the present state-of-the-art approaches in segmentation tasks. For ShapeNet, mIOU stands for mean intersection over union on points, and for ScanNet, Acc stands for voxel label prediction accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Shapenet Part Segmentation Dataset</head><p>We compare our method with state-of-the-art approaches, as well as the reproduced results from pointnet++. Following the setting in <ref type="bibr" target="#b19">[20]</ref>, we evaluate our approach assuming that a category label for each shape is already known and we use the same mIoU (mean intersection over union) metric on points. 2048 xyz points and their surface normals are used as input features and the network structure follows that of the 2k configurations in <ref type="table" target="#tab_0">Table 1</ref>. More specifically, 3l-pointnet++ model is applied for pointnet++ and 4l-spec-cp is applied for our method.</p><p>ScanNet Dataset ScanNet is a large-scale semantic segmentation dataset constructed from real-world 3D scans of indoor scenes, and as such is more challenging than the synthesized 3D models in ShapeNet. Following <ref type="bibr" target="#b12">[13]</ref>[3], we remove RGB information in our experiments in <ref type="table">Table 6</ref> and we use the semantic voxel label prediction accuracy for evaluation. The training and testing procedures follow those in pointnet++ <ref type="bibr" target="#b12">[13]</ref>. 8192 xyz points are used as input features and the network structure is that of the 2k configurations in <ref type="table" target="#tab_0">Table 1</ref>. More specifically, the 4l-pointnet++ model is applied for pointnet++ and the 4l-spec-cp is applied for our method. 3 handbag skate-board  <ref type="table">Table 6</ref>), our 41-spec-cp model (middle row, 85.4% in <ref type="table">Table 6</ref>), and the ground truth labels (bottom row). Our method appears to better capture fine local structures (see text for a discussion).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results and Discussion</head><p>The use of spectral graph convolution combined with cluster pooling in our approach once again provides a non-trivial improvement over point-net++, achieving state-of-the-art level performance on both part segmentation (ShapeNet) and indoor scene semantic segmentation (ScanNet). We provide an illustrative visualization of the part segmentation results on selected models in <ref type="figure">Fig. 4</ref>. In these examples, when compared to pointnet++, our approach gives results that are closer to the ground truth overall and better captures fine local structures, such as the axles of the skateboard, and the feet of the table. In addition, spectral graph convolution with cluster pooling provides a more faithful representation of changes in local geometry. This allows us to successfully segment connected parts of a 3D object, such as the strap from the body of the hand bag, the wings from the tail fins of the airplane and the handle from the blade of the knife.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>The use of spectral graph convolution on local point neighborhoods, followed by recursive cluster pooling on the resultant representations, holds great promise for feature learning from unorganized 3D point sets. Our method's ability to capture local structural information and geometric cues presents an advance in deep learning approaches to feature abstraction from unorganized point sets in 3D computer vision. Considering its strong experimental performance, acceptable runtime, and versatility in handling a variety of datasets and tasks, our approach could have considerable practical value as 3D depth sensors begin to become more and more common place.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 :</head><label>1</label><figDesc>TOP: Starting from a point cloud, farthest point sampling leads to centroids, from which k-NN's are sampled.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 :</head><label>2</label><figDesc>TOP: A comparison between point-wise MLP in pointnet++ (left) and our spectral graph convolution (right) in a local neighborhood. For each point, the spectral graph convolution output depends on all points in its neighborhood, whereas in point-wise MLP the output only depends on the point itself. BOTTOM: We illustrate the network operations in a spectral graph convolutional layer, with the corresponding input/output dimensions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 :</head><label>3</label><figDesc>A visualization of spectral coordinates for models of a bird and a human, both from the McGill Shape Benchmark. λ i , i ∈ {0, 1, ..., k − 1} is the i-th eigenvalue of the graph Laplacian.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Algorithm 1</head><label>1</label><figDesc>Recursive Cluster Pooling INPUTS: pts ← point features (R k×m ), csize ← cluster size, and POOL ← the Pool method. OUTPUT: Pooled point features (R 1×m ). METHODS: ARG SORT(x) returns the sorted indices of x, REARRENGE(x,y) permutes x along its 1st dimension according to the given indices y, POOL(x) pools x along its 1st dimension.</figDesc><table><row><cell>procedure CLUSTER(pts, csize, POOL)</cell><cell>procedure MAIN(pts, csize)</cell></row><row><cell>G ← ADJ MATRIX(pts)</cell><cell>POOL← MAX POOL</cell></row><row><cell>L ← LAPLACIAN(G)</cell><cell>while COUNT(pts)&gt;csize do</cell></row><row><cell>[Λ, U ] ← EVD(L)</cell><cell>pts←CLUSTER(pts, csize, POOL)</cell></row><row><cell>fiedler vector← U [:, 1]</cell><cell>if POOL == MAX POOL then</cell></row><row><cell>inds← ARG SORT(fiedler vector)</cell><cell>POOL← AVG POOL</cell></row><row><cell>REARRENGE(pts, inds)</cell><cell>else</cell></row><row><cell>RESHAPE(pts, [:, csize])</cell><cell>POOL← MAX POOL</cell></row><row><cell>return POOL(pts)</cell><cell>return POOL(pts)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>-</head><label></label><figDesc>ModelNet40 [19]: This contains CAD models of 40 categories, sampled into point</figDesc><table /><note>clouds. We use the official split, with 9,843 training and 2,468 testing examples.-McGill Shape Benchmark [16]: This dataset contains 456 CAD models of 19 object level categories. We sample the meshes into point clouds and use the first two- thirds of the examples in each category for training and the remaining one-third for testing. The dataset is also divided into articulated (254 models) versus non- articulated (202 models) sub-categories.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 :</head><label>2</label><figDesc>Model Ablation Study on ModelNet40 (classification) and ShapeNet (segmentation). Acc stands for classification accuracy, 1k/2k refers to the number of points used and "+N" indicates the addition of surface normal features to xyz. For the segmentation experiments, mIOU stands for mean intersection over union. Here we only compare the best models from pointnet++ with ours. Training time is with respect to the number of epochs used in each experiment. Adding normals only increases the training time by a negligible amount, therefore only one runtime column is provided for the 1k experiments. Network structures for all the reported experiments are in</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 :</head><label>5</label><figDesc>ModelNet40 results. "Acc" stands for 1k experiments with only xyz points as input features. "Acc + N" stands for 2k experiments with xyz points along with their surface normals as input features."graph-cp" stands for recursive cluster pooling, introduced in section 4.</figDesc><table><row><cell>Method</cell><cell>Domain</cell><cell cols="3">Kernel ShapeNet-mIOU (%) ScanNet-Acc (%)</cell></row><row><cell>Yi et al. [20]</cell><cell>-</cell><cell>-</cell><cell>81.4</cell><cell>-</cell></row><row><cell>Dai et al. [3]</cell><cell>Voxel Grid</cell><cell>3D conv</cell><cell>-</cell><cell>73.0</cell></row><row><cell cols="3">SynSpecCNN [22] Full k-NN Graph graph conv</cell><cell>84.7</cell><cell>-</cell></row><row><cell>PointNet [11]</cell><cell>Full Points</cell><cell>point-MLP</cell><cell>83.7</cell><cell>73.9</cell></row><row><cell>Pointnet++ [13]</cell><cell>Local Points</cell><cell>point-MLP</cell><cell>84.9</cell><cell>84.0</cell></row><row><cell>4l-spec-cp</cell><cell cols="2">Local k-NN Graphs graph conv</cell><cell>85.4</cell><cell>84.8</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/charlesq34/pointnet2/blob/master/models/ pointnet2_cls_ssg.py</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">We tried to reproduce the pointnet++ results on MNIST. Our 0.55% error rate is very close to the 0.5% error rate reported by the authors.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">The 3l-pointnet++ model leads to inferior performance on this large-scale indoor dataset. For both networks, for all experiments reported in this paper, single scale grouping (SSG in<ref type="bibr" target="#b12">[13]</ref>) is applied for a fair comparison.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Numerical Geometry of Non-rigid Shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kimmel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Monographs in Computer Science</title>
		<imprint>
			<date type="published" when="2008" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">R</forename><surname>Chung</surname></persName>
		</author>
		<title level="m">Spectral graph theory. No. 92 in Regional Conference Series in Mathematics</title>
		<imprint>
			<publisher>American Mathematical Soc</publisher>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Scannet: Richlyannotated 3d reconstructions of indoor scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">X</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Savva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Halber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Funkhouser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nießner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Convolutional neural networks on graphs with fast localized spectral filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Defferrard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bresson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3844" to="3852" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<title level="m">Adam: A method for stochastic optimization</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.02907</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.4400</idno>
		<title level="m">Network in network</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Focusr: feature oriented correspondence using spectral regularization-a method for precise surface matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lombaert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Grady</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Cheriet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2143" to="60" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Monti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Boscaini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Masci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rodolà</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Svoboda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
		<title level="m">Geometric deep learning on graphs and manifolds using mixture model cnns. CVPR 2017</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1612.00593</idno>
		<title level="m">Pointnet: Deep learning on point sets for 3d classification and segmentation</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Volumetric and Multi-View CNNs for Object Classification on 3D Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Niessner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Pointnet++: Deep hierarchical feature learning on point sets in a metric space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Normalized cuts and image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="888" to="905" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The emerging field of signal processing on graphs: Extending high-dimensional data analysis to networks and other irregular domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">I</forename><surname>Shuman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Frossard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ortega</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Magazine</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="83" to="98" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Retrieving articulated 3d models using medial surfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Siddiqi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Macrini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shokoufandeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bouix</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dickinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Vision and Applications</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="261" to="274" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Best practices for convolutional neural networks applied to visual document analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">Y</forename><surname>Simard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Steinkraus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Platt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In: ICDAR</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="958" to="962" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Multi-view convolutional neural networks for 3D shape recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kalogerakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Learned-Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">3D shapenets: A deep representation for volumetric shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A scalable active framework for region annotation in 3d shape collections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">G</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ceylan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sheffer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">210</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Syncspeccnn: Synchronized spectral cnn for 3d shape segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Guibas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Syncspeccnn: Synchronized spectral cnn for 3d shape segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
