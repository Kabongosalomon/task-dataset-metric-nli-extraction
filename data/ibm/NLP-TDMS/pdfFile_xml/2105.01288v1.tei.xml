<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Walk in the Cloud: Learning Curves for Point Clouds Shape Analysis</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiange</forename><surname>Xiang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Sydney</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaoyi</forename><surname>Zhang</surname></persName>
							<email>chaoyi.zhang@sydney.edu.au</email>
							<affiliation key="aff1">
								<orgName type="institution">University of Sydney</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Song</surname></persName>
							<email>yang.song1@unsw.edu.au</email>
							<affiliation key="aff2">
								<orgName type="institution">University of New</orgName>
								<address>
									<country>South Wales</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianhui</forename><surname>Yu</surname></persName>
							<email>jianhui.yu@sydney.edu.au</email>
							<affiliation key="aff3">
								<orgName type="institution">University of Sydney</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weidong</forename><surname>Cai</surname></persName>
							<affiliation key="aff4">
								<orgName type="institution">University of Sydney</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Walk in the Cloud: Learning Curves for Point Clouds Shape Analysis</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T11:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Discrete point cloud objects lack sufficient shape descriptors of 3D geometries. In this paper, we present a novel method for aggregating hypothetical curves in point clouds. Sequences of connected points (curves) are initially grouped by taking guided walks in the point clouds, and then subsequently aggregated back to augment their pointwise features. We provide an effective implementation of the proposed aggregation strategy including a novel curve grouping operator followed by a curve aggregation operator. Our method was benchmarked on several point cloud analysis tasks where we achieved the state-of-the-art classification accuracy of 94.2% on the ModelNet40 classification task, instance IoU of 86.8% on the ShapeNetPart segmentation task and cosine error of 0.11 on the ModelNet40 normal estimation task. Our project page is available at: https</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The point cloud is a primary data structure in a string of indoor/outdoor computer vision applications. A large variety of 3D sensors (e.g. LiDAR sensors) are now able to capture real-world objects, and their projections to digital forms can be made by sampling discrete points on the surface. To reach a better understanding of the 3D targets, effective point cloud analysis techniques and methods are in great demand. With the thriving of deep learning, the pioneer works <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b27">28]</ref> and their followers <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b46">47]</ref> processed point clouds through well-designed neural networks to learn the latent mappings between input point coordinates and the ground truth labels. Differing from conventional 2D vision tasks, the points are usually in irregular and unordered forms, hence, the effective designs of feature aggregation and message passing schemes among point clouds still remains challenging.</p><p>Local feature aggregation is a basic operation that has been widely studied recently. For each key point, its neighborhood point features are first grouped by pre-defined rules</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Local aggregation</head><p>Non-local aggregation Curve aggregation (ours) <ref type="figure">Figure 1</ref>. Common aggregations and the curve aggregation. Blue circles denote key points, orange circles denote query points or query range. In curve aggregation, query features will be aggregated into all points.</p><p>(e.g. KNN). The relative position encodings between the query point and neighboring points will be computed subsequently and then passed into various point-based transformation and aggregation modules for local feature extraction. Although the above operations help depict local patterns to some extent, long-range point relations are neglected. While the non-local module <ref type="bibr" target="#b33">[34]</ref> provides a solution to aggregate global features, we argue that the global point-to-point mapping might still be insufficient to extract underlying patterns implied by the point cloud shapes.</p><p>To this end, we propose to improve the point cloud geometry learning through generating continuous sequences of point segments on the point cloud surface. We posit that such continuous descriptors are more adequate for depicting the geometry of point cloud objects, compared to popular existing local and non-local operators nowadays. We denote such continuous descriptors as curves. By regarding a point cloud as an undirected graph, where the discrete points serve as the graph nodes and the neighbor point connections as the graph edges, a curve can therefore be described as a walk in the graph. <ref type="figure">Figure 1</ref> intuitively compares the local aggregation, non-local aggregation, and our curve aggregation operators. In this paper, we first revisit the local feature aggregation in its general form and provide in-depth discussions on why long-range feature aggregation strategies are desired (Sec. 3.1). We then formulate our method formally by defining the curve grouping policy (Sec. <ref type="bibr">3.2)</ref> and the aggregation between curve features and point fea-tures (Sec. <ref type="bibr">3.3)</ref>. A novel point cloud processing network, CurveNet, is constructed by integrating the proposed modules along with several basic building blocks into a ResNet <ref type="bibr" target="#b3">[4]</ref> style network.</p><p>Our main contributions are three-fold: (1) We propose a novel feature aggregation paradigm for point cloud shape analysis. Sequences of points (curves) are grouped and aggregated for better depiction of point cloud object geometries. A novel curve grouping operator along with a curve aggregation operator are proposed to achieve curve feature propagation. <ref type="bibr" target="#b1">(2)</ref> We study potential drawbacks of grouping loops and provide our solutions to alleviate them. Moreover, a dynamic encoding strategy is proposed so that curves can contain richer information while suppressing potential crossovers. (3) We embed the curve modules into a network named CurveNet, which achieves state-of-the-art results on the object classification, normal estimation, and object part segmentation tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Works</head><p>3D point cloud processing. One of the greatest challenges to point cloud analysis is processing unstructured representations. Starting from indirect representation transformation methods <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b12">13]</ref> to the direct feature propagation methods <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b5">6]</ref>, many works have been progressing toward effective point cloud analysis.</p><p>As one of the pioneer direct approaches, Point-Net/PointNet++ <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b27">28]</ref> utilize shared MLPs to learn pointwise features. Following them, recent works have extended the point-wise method to various directions, which include designing advanced convolution operations <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b18">19]</ref>, considering a wider neighborhood <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b20">21]</ref>, and the adaptive aggregation of it <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b43">44]</ref>. The success of the above methods is inseparable from the help of feature aggregation operators, which achieve the direct message passing of discrete points in deep networks.</p><p>Current feature aggregation operators can be generally classified into two categories: local feature aggregation and non-local feature aggregation. As a representative of local aggregation operator, EdgeConv <ref type="bibr" target="#b34">[35]</ref> learns semantic displacement between key points and their feature-space neighbors. The thrive of non-local aggregation operator starts from the non-local network <ref type="bibr" target="#b33">[34]</ref>, with which global features are transformed and aggregated together to learn many-to-one feature mappings. With the recent success of applying Transformer <ref type="bibr" target="#b32">[33]</ref> in vision tasks, Guo et al. <ref type="bibr" target="#b2">[3]</ref> designed a point cloud processing architecture comprised of simple Transformers.</p><p>Beyond the local and non-local feature aggregation operators, we suggest that point cloud analysis can be better achieved with special consideration of shape segments, edges, and curves. By aggregating the additional curve features, latent information can be enriched, resulting in better feature depictions. Sampling techniques for 3D point cloud. Sampling technologies aggregate indicative point patterns and are hence essential to all point cloud processing methods. Voxelization-based approaches <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b22">23]</ref> transform the discrete point space into 3D grid (voxels), where the input point clouds behave as the discrete sampling on a continuous 3D space. However, the quality of such sampling is highly sensitive to the subdivision frequency. Similar to voxelization-based sampling methods, view-based approaches <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b38">39]</ref> sample 3D information by capturing 2D snapshots of point clouds from different angles, and make predictions based on the collections of 2D images. The loss of spatial information is inevitable during such image samplings.</p><p>Advanced sampling methods from recent literatures overcome the above drawbacks, and obtain promising results on basic point cloud analysis tasks. GS-Net <ref type="bibr" target="#b40">[41]</ref> exploits an Eigen-Graph to group points with similar Euclidean distance and geometric information. PointASNL <ref type="bibr" target="#b42">[43]</ref> and SOCNN <ref type="bibr" target="#b45">[46]</ref> sample both adjacent and global points for a complete description of point cloud objects. Unlike the above methods, PAT <ref type="bibr" target="#b43">[44]</ref> models point clouds with the help of a Transformer <ref type="bibr" target="#b32">[33]</ref> and learns the point sampling through a Gumbel-Softmax gate. In a recent work, RandLA-Net <ref type="bibr" target="#b5">[6]</ref> reviewes multiple different sampling techniques and adopts the random sampling for an extremely efficient point cloud processing. Differing from all existing sampling methods, we sample and group contiguous segments of points as curves, which contain rich information describing object shapes and geometry.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Methods</head><p>In this section, we present the proposed operators to group and aggregate curves for any point cloud P = {p} and its point-wise features F = {f }. As aforementioned, a curve represents a connected sequence of points in the point cloud, and can be formally defined as: Definition 1. Curves in point cloud. Given P, F and an isomorphic graph G = (F, E) with the connectivity E computed by the KNN algorithm on P. A curve c with length l in feature space, is generated as a sequence of point features in F, such that c = {s 1 , · · · , s l |s ∈ F}. To group curves, we consider a walk policy π defined on the isomorphic graph G that starts a walk (curve) from a starting point s 1 and transits for l steps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Rethinking Local Feature Aggregation</head><p>The general purpose of local feature aggregation is to learn the underlying patterns within a local space of k elements. For each point p, the neighborhood N = {p 1 , · · · , p k } is first grouped by a deterministic rule, and KNN is the most frequently used grouping algorithm <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b45">46]</ref> due to its computational efficiency. Then, pair-wise differences Φ between every two elements in N are computed and stacked together. Finally, shared MLPs are employed to further aggregate the computed encodings leading to the locally aggregated features g. Formally, the above local feature aggregation process can be formulated as:</p><formula xml:id="formula_0">g = pooling({MLP(Φ(f , f j )|f j ∈ N )}).<label>(1)</label></formula><p>Using Manhattan distance Φ(f , f j ) = f − f j as the relative encoding is the most natural practice and has been widely adopted. However, we argue that such encoding method does not provide abundant relative signals since most g in a point cloud contains nearly identical information in the same feature channel (regardless of pooling strategy), especially in shallow layers, as shown in <ref type="figure" target="#fig_0">Figure 2</ref>. As the raw point cloud sampled from an explicit representation R of 3D objects is unordered, the point cloud P can be regarded as a set of random variables sampled in a particular probability density function (PDF) U modeled on R, such that P ∼ U(R). After propagating through a certain number of network layers, F becomes the transformation over the random variable set P.</p><p>We first consider an extreme case where F represents the initial point features, such that F = P. Using a simple 2D plane ( Restricted by the geometry of R, the distribution of point C query neighbors is considerably different than A and B, which leads to varying {p C − p j C }. Based on the above observation, we claim that in any structured PDF that ensures the same sampling behaviour on similar geometries, g in Eq. 1 is dependent on the distribution of F and P. Point cloud objects, which have similar geometry information at most parts, turn out encoding similar and indistinguishable information in g. As shown in <ref type="figure" target="#fig_0">Figure 2</ref> right, the chair's back and seat have close features in the same channel, especially in shallow layers. One possible strategy to enrich g is using more relative encoding rules rather than element-wise difference solely <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b0">1]</ref>. In this paper, we enrich the local features g by combining the features aggregated from curves, as illustrated in <ref type="figure" target="#fig_0">Figure  2</ref> left bottom. Each curve covers a long path in the point cloud encoding unique geometric information, which could be used to further increase point feature diversity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Curve Grouping</head><p>In this subsection, we present the details on grouping curves in the feature space of point clouds. The starting point of a curve is essential to the overall grouping quality. To group n curves simultaneously, the starting point set in R n×||f || needs to be determined beforehand. Borrowing the top-k selection method from <ref type="bibr" target="#b1">[2]</ref>, we employ a sigmoid gated MLP to learn the selection score for each of the point features in F. The starting points are the points with top n scores. To enable gradient flow, we multiply the scores back to F via a self-attention manner.</p><p>After the construction of the starting point set, a walk W then starts from one of the starting points s 1 and transits for exactly l steps. The points traveled by W are grouped to form a curve c. Given an intermediate state of curve s i (s i numerically equals f i when grouping curves in feature space) arrived after walking for i steps, we are interested in finding a walk policy π(s i ) that determines the next state of curve at the i + 1 step. With a predefined π(·), a curve c = {s 1 , · · · , s l } can be finally grouped by executing the following equation iteratively for l times:</p><formula xml:id="formula_1">s i+1 = π(s i ), 1 &lt;= i ∈ Z + &lt;= l.<label>(2)</label></formula><p>A good π(·) is essential to guarantee an effective curve grouping. Instead of a deterministic policy, we present a learnable π(·) that can be optimized along with the backbone network. In more detail, for a state s, we apply MLPs on a state descriptor h s ∈ R 2||s|| to decide the next step. A state descriptor is constructed as the concatenation of point feature s i and a curve descriptor r i , which will be introduced later in this subsection. Selection logits α on all neighboring points in N s can therefore be learned via the MLPs. We then feed α to a scoring function (e.g. softmax) to distribute each of the neighbors a score-based multiplier within [0, 1]. The point with the greatest score is then the output of our π(·). Formally, we formulate π(s) as:</p><formula xml:id="formula_2">si si-1 si si+1 si-1 s1 s2 s3 s4 s5 si si-1 N ! s si si-1 s1 s 2 s3 s 4 s 5 ! (α)1 ! (α) 2 ! (α)3 ! (α) 4 ! (α) 5 =argmax one-hot =softmax Eq. 3. Eq. 5. si-1 s i ⃗ c # q # $ (s # $ ) q # % q # &amp; q # ' q # ( s # % s # &amp; s # ' s # ( s ! " s i θ d ! " = cos(θ)+1 s ! # si θ d ! # =1</formula><formula xml:id="formula_3">α = {MLP(h s j |s j ∈ N s )},<label>(3)</label></formula><formula xml:id="formula_4">π(s) = F[arg max(softmax(α))],<label>(4)</label></formula><p>where h s j is the state descriptor of a KNN neighbor s j . In forward propagation, Eq. 4 determines the next state with the computed α. However, during backward propagation, arg max obscures gradients, and hence the MLP in Eq. 3 is not able to be updated as expected. Given the computed α, we present an alternative equation to Eq. 4 that discards the arg max gate and enables gradient flow. First, we generate a hard one-hot style score vector for α instead of soft scores obtained from softmax function. By using gumbel-softmax [9, 22, 44] 1 as the scoring function, logits can be converted into an one-hot vector based on the arg max index. Gradients through gumbelsoftmax are computed identically to the ones through softmax. Then, we broadcastly multiply the query neighbors by the one-hot score vector and sum the multiplications together. The final result of the above operations is numerically identical to the ones computed by Eq. 4. Consequently, our learnable policy is defined as follows:</p><formula xml:id="formula_5">π(s) = k 1 (gumbel-softmax(α) · N s )),<label>(5)</label></formula><p>where · denotes broadcast multiplication along the feature dimension. An overview of the above pipeline is shown in <ref type="figure" target="#fig_2">Figure 3</ref> bottom. By extending the curve with the highest score point, π(·) essentially determines the traveling direction of the curve based on the state descriptors in the neighborhood. We firstly follow a simple approach that constructs the state descriptor h s j as the direct concatenation of s and the neighbor s j . However, such naive approach can easily lead to <ref type="bibr" target="#b0">1</ref> Gumbel samplings are disabled for avoiding any randomness.  loops, as Eq. 3 will always have the same output for the same input at each point. A loop is a c = {s 1 , · · · , s l } with repeated s, which carries redundant and limited information, and hence should be avoided. <ref type="figure" target="#fig_4">Figure 4</ref> shows four kinds of possible loops, among which self loop can be easily avoided by excluding the key point itself during KNN computation. To avoid the other loops, the simple state descriptor formation will not suffice. Dynamic momentum. The key to avoid loops lies in a dynamic encoding of state descriptor with consideration of current curve progress. We maintain a curve descriptor r i ∈ R ||s|| that encodes the prefix of the curve at step i. The state descriptor h s j for each neighbor of the key point s i now becomes the concatenation of s j i and r i . Inspired by <ref type="bibr" target="#b7">[8]</ref>, we update r i following the momentum paradigm. However, we find that setting a fixed momentum coefficient β is limited in terms of the final result. We propose that the prefix r of a curve can be better encoded by a dynamic momentum variant, such that:</p><formula xml:id="formula_6">β = softmax(MLP([r i−1 , s i ])), r i = βr i−1 + (1 − β)s i ,<label>(6)</label></formula><p>where [·] represents concatenation. <ref type="figure" target="#fig_2">Figure 3</ref> bottom illustrates the dynamic momentum paradigm. Crossover suppression. Although the dynamic momentum strategy avoids loops, curves may still encounter crossovers. Unlike loops, small number of crossovers may imply useful patterns and should not be avoided completely. However, when a large number of crossovers occurs, same node will be included repeatedly, hurting the curve representation. Therefore, we propose to suppress crossovers by investigating the curve's traveling direction.</p><p>We first construct a support vector − → c i = s i − r i−1 representing the general direction of the current curve at step i. Subsequently, for each query neighbor of the curve head s i , we compute the candidate vector as − → q j i = s j i − s i . The Top-K Selection</p><formula xml:id="formula_7">n x N C x n x l C x N C x N LPFA MLP Concat(P, P k , P k -P) F k -F F: C x N idx: N x k P: 3 x N 9 x N x k C x N x k C x N x k C x N x k C x N x k MLP Average Pooling C x N x k C x N</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Curve Aggregation</head><p>Task-Specified Head</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MLP Linear</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Max Pooling</head><p>Linear + DP  <ref type="figure">Figure 5</ref>. CurveNet overview. The network is comprised of a stack of building blocks. FPS denotes the farthest point sampling method <ref type="bibr" target="#b27">[28]</ref>. Dotted blocks and lines are optional regarding different blocks. Building blocks are matched in abbreviation and color.</p><formula xml:id="formula_8">C x n x l C x n C x l F: C x N Cmid x l Cmid x n Cmid x N N x l N x n Cmid x l Cmid x n Cmid x N Cmid x N 2Cmid x N C x N : matrix</formula><p>included angle θ between − → c and − → q j indicates whether the curve is about to go straight or make a turn. We suppress crossovers by scaling down α j that has large θ (i.e. likely to turn around and cause potential crossovers). Specifically, we determine the angle distance between − → c and − → q j through cosine similarity and the measurement for each vector pair strictly falls into the range [−1, 1]. A value close to −1 represents the two vectors are in the opposite direction (should be suppressed) and 1 represents they are in the same direction (should not be suppressed). Considering there exist boundaries in the latent space, a curve cannot go straight forever without making a turn. We therefore set a tolerance threshold angleθ 2 , so that only the candidate vector with included angle greater thanθ needs to be suppressed. Following the above intuition, we then construct the crossover suppression multiplier d j by shifting and clipping the cosine similarity score into [0, 1]. Potential crossovers are suppressed by scaling the candidate logit α j with d j . An illustration of the crossover suppression strategy is outlined in <ref type="figure" target="#fig_2">Figure 3</ref> bottom.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Curve Aggregation and CurveNet</head><p>As discussed in Sec 3.1, the purpose of curve aggregation is to enrich the intra-channel feature variety of the relative encodings φ and eventually provides a better description to g. For notation simplicity, we define the number of feature channels as C, the number of points as P , and a ba- <ref type="bibr" target="#b1">2</ref> Learning such value yields poorer results in our experiments. sic Attentive-Pooling operator <ref type="bibr" target="#b5">[6]</ref> as AP. In AP, the input features ∈ R C× * are scaled in the self-attention style and summed up along the * dimension, resulting in R C×1 .</p><p>Given the grouped curves C = {c 1 , · · · , c n } ∈ R C×n×l , to aggregate the features in curves, we consider both inter-relations among the curves and intra-relations within each curve. We first learn an inter-curve feature vector f inter ∈ R C×l and an intra-curve feature vector f intra ∈ R C×n by applying AP on C along different axis. Point features F together with f intra and f inter are then fed to three individual bottleneck MLPs to reduce feature dimensions. We apply matrix multiplication on the reduced F with reduced f intra and f inter separately to learn the respective curve-point mappings. Softmax functions are employed to convert the mappings into scores. In another branch, the reduced f intra and f inter are further transformed with two extra MLPs, which are then fused with the computed mapping scores by matrix multiplication separately. The above process ends up with two fine-grained feature vectors f intra and f inter in the same shape of R C×P . We concatenate f intra and f inter along the feature axis and feed into a final MLP. The output of our curve aggregation is the residual addition to the origin input.</p><p>We embed our Curve Grouping (CG) block and Curve Aggregation (CA) block into a Curve Intervention Convolution (CIC) block. In each CIC block, curves are first grouped (Sec 3.2) and then aggregated to all point features (Sec 3.3). We stack 8 CIC blocks together to construct a ResNet <ref type="bibr" target="#b3">[4]</ref> style network, referred to as CurveNet. Our CurveNet initially learns a relative local encoding of the input points coordinates through the Local Point-Feature Aggregation (LPFA) block, which projects the relative point difference into a higher dimension. CurveNet eventually makes predictions through the Task-Specified Head (TSH) regarding of different point cloud processing tasks. For classification task, the extracted point features are first pooled and then passed into two fully-connected layers. For segmentation task, we use an attention U-Net <ref type="bibr" target="#b23">[24]</ref> style decoder that concatenates attentive shortcut connections from the encoder. <ref type="figure">Figure 5</ref> gives an overview of our CurveNet. Network structure and building block details are presented in the supplemental materials.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>We present experimental results for our point cloud object analysis methods on object classification, shape part segmentation, and normal estimation tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Implementation Details</head><p>In all experiments, Dropout layers <ref type="bibr" target="#b30">[31]</ref> were adopted in final linear layers with probability 0.5 <ref type="bibr" target="#b34">[35]</ref>. We used LeakyReLU as the activation function in the backbone subnetwork and ReLU in the task-specific heads.θ was set to 90 • . To eliminate the influence of randomness, random seed was fixed in all experiments, which were implemented in the PyTorch framework <ref type="bibr" target="#b24">[25]</ref>.</p><p>For classification tasks, we used SGD with momentum 0.9 as the optimizer and set the number of neighbors in KNN to 20. For segmentation tasks, the number of KNN neighbors was set dynamically according to different radius with no more than 32. The point features were interpolated similar to <ref type="bibr" target="#b25">[26]</ref> during upsampling. The distances between predictions and ground truth labels were minimized through cross entropy loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Benchmarks</head><p>Object classification. ModelNet 10/40 datasets <ref type="bibr" target="#b37">[38]</ref> are the most commonly used datasets for object shape classification benchmarks, which collect meshed CAD models across a variety of objects. ModelNet10 dataset is comprised of 4899 individual models that are distributed into 10 different categories. We split the training and testing samples following the same schema as in <ref type="bibr" target="#b17">[18]</ref>. In a larger homogeneous dataset, ModelNet40 consists of 12311 models that are classified into 40 categories. In both datasets, we only used the coordinates of 1024 uniformly sampled points as network inputs. The points were normalized into unit spheres before feeding into networks. A random scaling multiplier within the range [0.66, 1.5] was first multiplied on the sampled points. Then, each point was translated along the three directions by random displacements within [-0.2, 0.2]. The scaling and translation settings were <ref type="table">Table 1</ref>. ModelNet10 (M10) and ModelNet40 (M40) classification accuracy (%). 'nr' denotes using normal vectors as extra inputs. '*' denotes methods evaluated with voting strategy <ref type="bibr" target="#b18">[19]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head><p>Input #point M10↑ M40↑ PointNet <ref type="bibr" target="#b25">[26]</ref> xyz  consistent to the ones used in <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b18">19]</ref>. We trained the models for 200 epochs, starting with a learning rate of 0.1 and cosineannealling scheduled to 0.001 in 200 epochs. Batch size was set to 32 for training, and 16 for validation. <ref type="table">Table 1</ref> reports the comparison results between our Cur-veNet and the most recent methods. With only 1024 uniformly sampled points, our method achieved the state-ofthe-art result on the large scale ModelNet40 dataset at 93.8% without voting <ref type="bibr" target="#b18">[19]</ref> and reached 94.2% when averages 10 prediction votes. We also achieved 96.3% on the ModelNet10 subset, which is the second best result among all methods with the same training data. We visualize the local aggregated features along with the aggregated longrange features and some randomly selected curves in <ref type="figure" target="#fig_6">Figure  6</ref>. Curves are able to cover long-range semantics and hence bring channel diversity to a great extent. Object part segmentation. We validated our method on the ShapeNetPart dataset <ref type="bibr" target="#b44">[45]</ref> for the 3D shape part segmentation task. The dataset collects 16881 shape models across 16 categories. Most objects in the dataset have been labeled with less than 6 parts, results in a total number of 50 different parts. Our training and testing split scheme follows <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b27">28]</ref>, such that 12137 individual models were used as training samples while the rest were used as validation and testing. 2048 points were uniformly sampled from each model to be the input to our networks. We trained the models for 150 epochs with batch size 32, starting with a learning rate of 0.05 which decayed by 0.1 at the 140 and 180 epoch. The momentum and weight decay are set to 0.9 and 0.0001, respectively. We inserted a simple SE <ref type="bibr" target="#b4">[5]</ref> module before the last linear layer of our CurveNet. Same to <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b0">1]</ref>, the one-hot class label vector and global feature vectors are also adopted.</p><p>Mean intersection of union (mIoU) results across instances are reported in <ref type="table">Table 2</ref>, and the category-wise mIoU scores are presented in the supplemental materials. Our method achieves state-of-the-art overall mIoU of 86.6%, surpasses all existing methods. Without grouping any curves, our base architecture reaches 85.9%, proving the effectiveness of involving curves in point cloud shape segmentation task. Moreover, we visualized four cases qual- itatively along with the learned curves in <ref type="figure" target="#fig_7">Figure 7</ref>. The grouped curves were able to explore both short and long range shape relations. Model complexity is reported and analyzed in the supplementary materials. Object normal estimation. Object surface normal is essential to 3D modeling and rendering. Differing from understanding objects part by part, estimating normal requires a comprehensive understanding of the entire object shape and geometry. We validate our CurveNet on estimating normal by using ModelNet40 dataset, where each point in the point cloud has been labeled with its three-directional normal. CurveNet architecture is constructed similarly to the one used in segmentation task, excluding the one-hot class label vector and global feature vectors. Models are trained with an initial learning rate of 0.05 and cosineanealing scheduled to 0.0005 in 200 epochs. <ref type="table" target="#tab_2">Table 3</ref> shows the average cosine-distance error comparisons of CurveNet and state-of-the-art methods. Without any curves, our base CurveNet architecture achieves an average error of 0.16, which is closed to <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b2">3]</ref>. When curves are involved, our full CurveNet demonstrates a superior performance with 0.11 average error, setting a new benchmark to the normal estimation task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Ablation Studies</head><p>We conducted extensive experiments on ModelNet40 dataset to study our proposed method comprehensively. Unless explicitly specified, implementation details remained the same as the ones described in the benchmark section. All the ablative studies were examined without voting. Component studies. The impact of individual component of CurveNet was examined by simply removing or replacing them from the full CurveNet architecture. We conducted experiments on replacing LPFA with the common local feature aggregation as in Eq. 1, disabling the dynamic momentum and the crossover suppression strategies, and re-  placing the proposed CA operator to the vanilla non-local module (i.e. intra-relations and inter-relations are not separated). The results are reported in <ref type="table" target="#tab_3">Table 4</ref>. We observed that, although using LPFA solely cannot bring significant performance improvement (models A and B), with the intervention of curves, the presence of LPFA is able to make a huge difference in terms of the classification result (models F and G). As shown in models C and D, both the proposed dynamic momentum and crossover suppression strategy are empirically effective as expected. Moreover, from model E, we find that the proposed curve aggregation operator plays the most significant role in the Cur-veNet. When aggregating grouped curve features through the vanilla non-local module, the accuracy is dropped by 0.7%, with no benefit on the inference latency. Shallow layer vs deep layer. In Sec. 3.1, we claimed that shallow features after local aggregation lack single channel diversity, and curve features could be more desired at shallow layers than at deep layers of a network. We conducted experiments on aggregating curves with various quantities and lengths on different groups of our CurveNet, the results are shown in the supplemental materials <ref type="figure">(Figure 1</ref>). Aggregating curves at shallow layers (group 1/2) yield better results than at deep layers (group 3/4), which proved our claim empirically. Accuracy (%) <ref type="figure">Figure 9</ref>. Left: Comparison on sparser training and testing inputs. Right: Comparison on noisy inputs, with voting enabled.</p><p>Curve quantity vs curve length. Curve quantity n and length l are the two hyper parameters determining the network performance directly. Short curves cannot capture long-range patterns, while long curves require better guidance and may contain redundant information. To study the relations between curve quantity and curve length, we conducted experiments on fixed total point number in curves. <ref type="figure">Figure 1</ref> bottom right in the supplemental materials shows that although a long curve (length 50) is able to achieve the best result, the network performance degrades as the curve extends further. Aggregating longer curves is also computational inefficient, as the transition of nodes cannot be computed parallelly. To verify whether the curves are trapped in a local region, we present the average euclidean distances between each node of the curves to the starting/last point in <ref type="figure" target="#fig_8">Figure 8</ref>. The curves are capable of jumping out of the maximum local KNN range to explore longer range relations. Sparser input points and noisy testing points. Curve grouping could be sensitive to point cloud sparsity and noise. We conduct extensive experiments on (1) training and testing with sparser input points and (2) training on 1024-point raw coordinates and testing with noisy points <ref type="bibr" target="#b42">[43]</ref>. As shown in <ref type="figure">Figure 9</ref> left, our CurveNet achieves the best results on all experiments regarding of different number of input points. For noise tests, we add an extra max pooling layer following the first LPFA block. Our CurveNet outperforms <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b25">26]</ref> in all experiments and achieves on par results to <ref type="bibr" target="#b42">[43]</ref>, demonstrating the robustness to noise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, we proposed a long-range feature aggregation method, namely curve aggregation, for point clouds shape analysis. We first discussed the potential drawbacks of the existing local feature aggregation paradigm, and claimed the need for the aggregation of point cloud geometry. We then presented our method in two sequential steps: the rules for grouping curves in a point cloud and the integration of the grouped curve features with the extracted point features. During the process, potential problems were defined and resolved. Our method achieved state-of-the-art results on multiple point clouds object analysis tasks.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>Left: A point cloud projected on the 2D plane. Left top: Three key points and their k=9 query neighbors. Left bottom: A possible curve through the three key points connected by red lines. Curve aggregation fuses the features along the curve. Right: Visualizations of a random channel in g of a ModelNet40 chair object under different layers of local feature aggregation and different pooling strategies.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Figure 2 left) as an exemplary R, the sparse points are scattered on a compact subspace of R 2 . In Figure 2 left top, three key points are highlighted with their KNN computed neighbors. It can be practically observed that, after sampling the points, {p A − p j A } and {p B − p j B } are most likely to have similar values, as the key points are surrounded by their query neighbors in a similar pattern. However, point C at the boundary (an edge or an irregular segment of surface in 3D space) stands as an exception.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Top: An overview of our curve grouping process. Bottom: Visualization of the proposed dynamic momentum and the crossover suppression strategies.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 .</head><label>4</label><figDesc>Four possible loops in a curve. The orange circle denotes current curve head, and the red arrow denotes current curve traveling direction.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 .</head><label>6</label><figDesc>Visualizations of curves and curve features. Left: Loops are avoided and crossovers are suppressed in the grouped curves. Right: Point features can be enriched by combining the long-range curve features.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 .</head><label>7</label><figDesc>Visualizations of curves and segmentation results. Random selected curves are plotted with random colors.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 8 .</head><label>8</label><figDesc>How far do the curves go? Left are two objects with distinct shapes. Right are the average euclidean distances to the start node and the last node of all curves with 30 steps in group 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>Normal estimation results in avg cosine-distance error.</figDesc><table><row><cell>Methods</cell><cell cols="3">Input #point Error↓</cell></row><row><cell>PointNet [26]</cell><cell>xyz</cell><cell>1024</cell><cell>0.47</cell></row><row><cell>DGCNN [35]</cell><cell>xyz</cell><cell>1024</cell><cell>0.29</cell></row><row><cell>RS-CNN [19]</cell><cell>xyz</cell><cell>1024</cell><cell>0.15</cell></row><row><cell>PCT [3]</cell><cell>xyz</cell><cell>1024</cell><cell>0.13</cell></row><row><cell>CurveNet w/o curve (Ours)</cell><cell>xyz</cell><cell>1024</cell><cell>0.16</cell></row><row><cell>CurveNet (Ours)</cell><cell>xyz</cell><cell>1024</cell><cell>0.11</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 .</head><label>4</label><figDesc>Component study results. Top-1 classification accuracy and per point cloud (per batch) inference time are reported. LPFA: the Local Point-Feature Aggregation, CG: the Curve Grouping operator, DM: the Dynamic Momentum strategy, CS: the Crossover Suppression strategy, and CA: the Curve Aggregation operator.</figDesc><table><row><cell>A curve</cell><cell>Another curve</cell><cell>Curve aggregated feature</cell><cell>Point feature</cell></row><row><cell></cell><cell></cell><cell>CG</cell><cell></cell></row><row><cell cols="4">Model LPFA DM CS CA Acc (%) latency (ms)</cell></row><row><cell>A</cell><cell></cell><cell>93.1</cell><cell>37.6(140)</cell></row><row><cell>B</cell><cell></cell><cell>93.3</cell><cell>37.5(143)</cell></row><row><cell>C</cell><cell></cell><cell>93.4</cell><cell>44.3(145)</cell></row><row><cell>D</cell><cell></cell><cell>93.3</cell><cell>44.1(144)</cell></row><row><cell>E</cell><cell></cell><cell>93.1</cell><cell>45.0(146)</cell></row><row><cell>F</cell><cell></cell><cell>93.4</cell><cell>44.8(143)</cell></row><row><cell>G</cell><cell></cell><cell>93.8</cell><cell>45.2(146)</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Local-area-learning network: Meaningful local areas for efficient point cloud analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qendrim</forename><surname>Bytyqi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicola</forename><surname>Wolpert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elmar</forename><surname>Schömer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.07226</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuiwang</forename><surname>Ji</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.05178</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">Graph U-Nets. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Xiong</forename><surname>Meng-Hao Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng-Ning</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tai-Jiang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shi-Min</forename><surname>Ralph R Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.09688</idno>
		<title level="m">Pct: Point cloud transformer</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Squeeze-and-excitation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7132" to="7141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Randla-net: Efficient semantic segmentation of large-scale point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingyong</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linhai</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Rosa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhihua</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Trigoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Markham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="11108" to="11117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">JSENet: Joint semantic segmentation and edge detection network for 3D point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeyu</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingmin</forename><surname>Zhen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuyang</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongbo</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chiew-Lan</forename><surname>Tai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="222" to="239" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.03167</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Categorical reparameterization with gumbel-softmax</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shixiang</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Poole</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.01144</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">RotationNet: Learning object classification using unsupervised viewpoint estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asako</forename><surname>Kanezaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Matsushita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nishida</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>CoRR abs/1603.06208, 3</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Escape from cells: Deep kd-networks for the recognition of 3D point cloud models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roman</forename><surname>Klokov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="863" to="872" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A-CNN: Annularly convolutional neural networks on point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Artem</forename><surname>Komarichev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zichun</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Hua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="7421" to="7430" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Octree guided cnn with spherical kernels for 3D point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huan</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naveed</forename><surname>Akhtar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ajmal</forename><surname>Mian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9631" to="9640" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">So-Net: Selforganizing network for point cloud analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaxin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ben</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gim Hee</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="9397" to="9406" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">PointCNN: Convolution on Xtransformed points</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangyan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Bu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingchao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinhan</forename><surname>Di</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baoquan</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="820" to="830" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">FPNN: Field probing neural networks for 3D data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangyan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soeren</forename><surname>Pirk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Charles R Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="307" to="315" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changjian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nenglun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-King</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenping</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.00230</idno>
		<title level="m">Point2skeleton: Learning skeletal representations from point clouds</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Point2Sequence: Learning the shape representation of 3D point clouds with an attention-based sequence to sequence network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinhai</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhizhong</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Shen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Zwicker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="8778" to="8785" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Relation-shape convolutional neural network for point cloud analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongcheng</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8895" to="8904" />
		</imprint>
	</monogr>
	<note>Bin Fan, Shiming Xiang, and Chunhong Pan</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">A closer look at local aggregation operators in point cloud analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ze</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Tong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.01294</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">LPD-Net: 3D point cloud learning for large-scale place recognition and environment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shunbo</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuanzhe</forename><surname>Suo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hesheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun-Hui</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2831" to="2840" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andriy</forename><surname>Chris J Maddison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee Whye</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Teh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.00712</idno>
		<title level="m">The concrete distribution: A continuous relaxation of discrete random variables</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">VoxNet: A 3D convolutional neural network for real-time object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Maturana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Scherer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="922" to="928" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ozan</forename><surname>Oktay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jo</forename><surname>Schlemper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Loic</forename><forename type="middle">Le</forename><surname>Folgoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mattias</forename><surname>Heinrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazunari</forename><surname>Misawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kensaku</forename><surname>Mori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Mcdonagh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Nils</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Hammerla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kainz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.03999</idno>
		<title level="m">Attention U-Net: Learning where to look for the pancreas</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">PyTorch: An imperative style, high-performance deep learning library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalia</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8024" to="8035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">PointNet: Deep learning on point sets for 3D classification and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Charles R Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaichun</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="652" to="660" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Volumetric and multi-view CNNs for object classification on 3D data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Charles R Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Nießner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengyuan</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="5648" to="5656" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">PointNet++: Deep hierarchical feature learning on point sets in a metric space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Charles Ruizhongtai Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5099" to="5108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">OctNet: Learning deep 3D representations at high resolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gernot</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Osman Ulusoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Geiger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3577" to="3586" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Mining point cloud local structures by kernel correlation and graph pooling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiru</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaoqing</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4548" to="4557" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Dropout: a simple way to prevent neural networks from overfitting. The journal of machine learning research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Evangelos Kalogerakis, and Erik Learned-Miller. Multi-view convolutional neural networks for 3D shape recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhransu</forename><surname>Maji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="945" to="953" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Łukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Non-local neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7794" to="7803" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Dynamic graph CNN for learning on point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongbin</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Sanjay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sarma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><forename type="middle">M</forename><surname>Michael M Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Solomon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions On Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Learning a probabilistic latent space of object shapes via 3d generative-adversarial modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiajun</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengkai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianfan</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josh</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="82" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Pointconv: Deep convolutional networks on 3D point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenxuan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongang</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fuxin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9621" to="9630" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">3d shapenets: A deep representation for volumetric shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhirong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuran</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fisher</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linguang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxiong</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1912" to="1920" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">DeepShape: Deep-learned shape descriptor for 3d shape retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoxian</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Edward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="1335" to="1345" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mutian</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Runyu</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojuan</forename><surname>Qi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.14635</idno>
		<title level="m">Paconv: Position adaptive convolution with dynamic kernel assembling on point clouds</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Geometry sharing network for 3d point cloud classification and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingye</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhipeng</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Qiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="12500" to="12507" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Grid-GCN for fast and scalable point cloud learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiangeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xudong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cho-Ying</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Panqu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulrich</forename><surname>Neumann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="5661" to="5670" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">PointASNL: Robust point clouds processing using nonlocal neural networks with adaptive sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaoda</forename><surname>Xu Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuguang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="5589" to="5598" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Modeling point clouds with self-attention and gumbel subset sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiancheng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingbing</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linguo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinxian</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengdie</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3323" to="3332" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Alla Sheffer, and Leonidas Guibas. A scalable active framework for region annotation in 3D shape collections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Vladimir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duygu</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I-Chao</forename><surname>Ceylan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengyan</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cewu</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qixing</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (ToG)</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Shape-oriented convolution neural network for point cloud analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaoyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lina</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weidong</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="12773" to="12780" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Exploiting edge-oriented reasoning for 3d point-based scene graph analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaoyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianhui</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weidong</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">PCAN: 3D attention map learning using contextual information for point cloud based retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenxiao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunxia</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="12436" to="12445" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Pointweb: Enhancing local neighborhood features for point cloud processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi-Wing</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5565" to="5573" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
