<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Asymmetric Co-Teaching for Unsupervised Cross-Domain Person Re-Identification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fengxiang</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Artificial Intelligence Department</orgName>
								<orgName type="institution">Xiamen University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Li</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Tencent Youtu Lab</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhun</forename><surname>Zhong</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Artificial Intelligence Department</orgName>
								<orgName type="institution">Xiamen University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiming</forename><surname>Luo</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Post Doctoral Mobile Station of Information and Communication Engineering</orgName>
								<orgName type="institution">Xiamen University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Sun</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Tencent Youtu Lab</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Cheng</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Tencent Youtu Lab</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaowei</forename><surname>Guo</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Tencent Youtu Lab</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feiyue</forename><surname>Huang</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Tencent Youtu Lab</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rongrong</forename><surname>Ji</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Artificial Intelligence Department</orgName>
								<orgName type="institution">Xiamen University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaozi</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Artificial Intelligence Department</orgName>
								<orgName type="institution">Xiamen University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Asymmetric Co-Teaching for Unsupervised Cross-Domain Person Re-Identification</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T16:12+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Person re-identification (re-ID), is a challenging task due to the high variance within identity samples and imaging conditions. Although recent advances in deep learning have achieved remarkable accuracy in settled scenes, i.e., source domain, few works can generalize well on the unseen target domain. One popular solution is assigning unlabeled target images with pseudo labels by clustering, and then retraining the model. However, clustering methods tend to introduce noisy labels and discard low confidence samples as outliers, which may hinder the retraining process and thus limit the generalization ability. In this study, we argue that by explicitly adding a sample filtering procedure after the clustering, the mined examples can be much more efficiently used. To this end, we design an asymmetric co-teaching framework, which resists noisy labels by cooperating two models to select data with possibly clean labels for each other. Meanwhile, one of the models receives samples as pure as possible, while the other takes in samples as diverse as possible. This procedure encourages that the selected training samples can be both clean and miscellaneous, and that the two models can promote each other iteratively. Extensive experiments show that the proposed framework can consistently benefit most clustering based methods, and boost the state-of-the-art adaptation accuracy. Our code is available at https://github.com</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Person re-identification (re-ID) <ref type="bibr" target="#b11">(Sun et al. 2018;</ref><ref type="bibr" target="#b13">Zheng, Yang, and Hauptmann 2016;</ref><ref type="bibr" target="#b9">Li, Zhu, and Gong 2018b)</ref> aims to locate the target person in surveillance videos with a given probe image. With the rapid evolution of deep learning models, the accuracy of person re-ID has been greatly boosted in the public datasets. However, models trained on the source domain often suffer from domain shifts, leading to a performance decline on a different target domain.</p><p>To alleviate this issue, recent works <ref type="bibr" target="#b16">(Zhong et al. 2019b;</ref><ref type="bibr" target="#b15">Zhong et al. 2018b</ref>) make efforts on the unsupervised do-main adaptation (UDA), which aims to transfer the knowledge from the labeled source domain to the unlabeled target domain. These works mainly lie in two aspects, distribution aligning <ref type="bibr" target="#b12">(Wei et al. 2018;</ref><ref type="bibr" target="#b2">Deng et al. 2018;</ref><ref type="bibr" target="#b0">Chang et al. 2019;</ref><ref type="bibr" target="#b9">Lin et al. 2018;</ref>) and target pseudo label discovering <ref type="bibr" target="#b3">(Fan, Zheng, and Yang 2018;</ref><ref type="bibr" target="#b10">Song et al. 2018;</ref><ref type="bibr" target="#b8">Li, Zhu, and Gong 2018a)</ref>. The former aims to reduce the distribution gap between domains in a common space, such as image-level <ref type="bibr" target="#b12">(Wei et al. 2018;</ref><ref type="bibr" target="#b2">Deng et al. 2018</ref>) and attribute-level <ref type="bibr" target="#b0">(Chang et al. 2019;</ref><ref type="bibr" target="#b9">Lin et al. 2018;</ref> spaces. The latter attempts to leverage the underlying relations among target samples and predict pseudo labels for model retraining, e.g. assigning pseudo labels based on clustering <ref type="bibr" target="#b3">(Fan, Zheng, and Yang 2018;</ref><ref type="bibr" target="#b10">Song et al. 2018;</ref><ref type="bibr" target="#b8">Li, Zhu, and Gong 2018a)</ref> and knearest neighbors <ref type="bibr" target="#b16">(Zhong et al. 2019a;</ref>). Among them, clustering based methods have reported very competitive accuracy for UDA in person re-ID. These methods usually employ an iterative process of predicting pseudo identities for unlabeled target samples according to the clusters and fine-tuning the model with those predicted samples. Despite their promising results, clustering based methods are restricted by two main drawbacks. On the one hand, the clustering accuracy can not be guaranteed even using the modern approaches, so that pseudo labels assigned by clusters can be noisy. Training the model with noisy labels that assigned to wrong identities will undoubtedly damage the re-ID performance. On the other hand, most clustering methods tend to leave low confidence samples as outliers and do not assign cluster labels to them, e.g., <ref type="bibr">DBSCAN (Ester et al. 1996)</ref>. These outliers are usually hard samples that encounter high image variations. Without considering such samples during training, the model may have a problem in discriminating high variation testing samples. However, directly assigning them to the nearest cluster will bring more noisy labels, hindering the retraining of the model.</p><p>Co-Teaching (CT) <ref type="bibr" target="#b4">(Han et al. 2018</ref>) is a commonly used algorithm for training model with noisy labels, which learns two networks by feeding samples with small losses of one network to another. However, most co-teaching frameworks utilize symmetric inputs for both networks, which do not effectively apply to the context of clustering based cross-arXiv:1912.01349v1 [cs.CV] 3 Dec 2019 L tri L tri <ref type="figure" target="#fig_1">Figure 1</ref>: The proposed asymmetric co-teaching framework (ACT). "M" and "C" denote the main model and the collaborator model, respectively. We first train CNN on the source labeled data and fine-tune it on target data with pseudo labels predicted by clustering to get initial weights for "M" and "C". "M" receives samples as diverse as possible from inliers and outliers, while "C" takes in samples as pure as possible from inliers during ACT. This process encourages the two models to mutually promote the discriminative ability of each other. More details can be found at Sec. 3.4. domain re-ID. This is because that the training samples with low-confidence commonly have large losses during training. Using symmetric inputs leads the model to always select easy samples and ignore the low-confidence samples within the training mini-batch. As a consequence, the second shortcoming mentioned above will still remain and will lead re-ID model to a local minimum.</p><p>To this end, we choose the state-of-the-art clustering based method proposed in <ref type="bibr" target="#b10">(Song et al. 2018</ref>) as our baseline, and propose an asymmetric co-teaching framework to eliminate the negative effects of the above two shortcomings. Specifically, we first divide the target samples into inliers and outliers, according to the clustering results (as shown in <ref type="figure" target="#fig_1">Fig. 1</ref>). In this paper, we regard the low-confident samples recognized by the clustering method as outliers while remaining as inliers. After that, our framework is trained with two models. The first one is the main model which aims to infer samples with small losses from the inliers, while the second one is the collaborator model that estimates samples with small losses from the outliers. The samples inferred/estimated by the certain model are selected for the training of another model. This training process is similar to the traditional co-teaching, except that the inputs of the two models are asymmetric, i.e. the data for training the two models comes from two different data flows. In this manner, selecting samples with small losses ensure that the models can be trained with possibly clean data. Moreover, these two models are iteratively promoted by each other. On the one hand, the main model attempts to mine as pure as possible samples from the inliers for maintaining the basic representation of the collaborator model. On the other hand, the collaborator model tries to select as diverse as possible samples from the outliers for further improving the discriminative ability of the main model. Our contributions are summarized in three-fold:</p><p>• We introduce to employ co-teaching technique for resisting noisy labels generated by clustering in the crossdomain person re-ID. Experiments show that learning with filtered data can consistently improve adaptation accuracy.</p><p>• We divide the unlabeled target data into inliers and outliers and design an asymmetric co-teaching (ACT) framework to make re-ID model see hard samples at the early stage of adaptation. Experiments demonstrate that the asymmetric approach is more effective in handling hard samples than the symmetric one.</p><p>• Experiments conducted on three large-scale datasets show that our method can apply to various clustering based methods and produces state-of-the-art adaptation accuracy in person re-ID.</p><p>2 Related Work</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Cross-Domain Person Re-identification</head><p>Recent studies in cross-domain re-ID can mainly group into distribution aligning <ref type="bibr" target="#b12">(Wei et al. 2018;</ref><ref type="bibr" target="#b2">Deng et al. 2018;</ref><ref type="bibr" target="#b9">Lin et al. 2018;</ref>) and clustering-based adaptation <ref type="bibr" target="#b3">(Fan, Zheng, and Yang 2018;</ref><ref type="bibr" target="#b10">Song et al. 2018</ref>). Distribution aligning tries to reduce the distribution gap in a common space, which can be further summarized into imagelevel and attribute-level. For image-level adaptation methods, PT-GAN <ref type="bibr" target="#b12">(Wei et al. 2018)</ref> uses Cycle-GAN  or Star-GAN <ref type="bibr" target="#b1">(Choi et al. 2018)</ref> to translate the foreground of labeled source images to target camera style for adaptation. Similarly, SPGAN <ref type="bibr" target="#b2">(Deng et al. 2018</ref>) utilizes Cycle-GAN and additional constraints named "selfsimilarity " and "domain-dissimilarity" for higher accuracy. However, the image-level adaptation algorithms cannot guarantee the identity of generated images, since the generated images still have a large gap compared with real im-ages. For attribute-level adaptation methods, MMFA (Lin et al. 2018) tries to align the distribution of mid-level semantic attributes between different datasets by minimizing the mean maximum discrepancy (MMD). TJ-AIDL (Wang et al. 2018) leverages a multi-branch network to establish an identity-discriminative and attribute-sensitive feature representation space most optimal for the target domain. These works require attribute annotations of source data, which are hard to obtain in practice.</p><p>Clustering-based adaptation is another straight-forward approach to adapt re-ID model. <ref type="bibr" target="#b3">Fan et al. (Fan, Zheng, and Yang 2018)</ref> use the k-means (Lloyd 1982) to predict pseudo labels of unlabeled target data for model fine-tuning. However, it is hard to decide correct k value for clustering. Song et al. <ref type="bibr" target="#b10">(Song et al. 2018</ref>) present a DBSCAN-based adaptation method, which can discover the number of clusters based on the density of features. Although clustering-based methods can achieve high re-ID accuracy for domain adaptation, most of them neglect the wrongly labeled samples in the clustering results and directly use them for training, which cloud have a negative influence on model's performance. find the drawbacks of mean-absolute loss and cross-entropy loss when applied in this task and further propose a generalized loss function that benefits both losses. However, robust loss methods always have certain constraints, which limit their applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Learning with Noisy Labels</head><p>Lee et al. <ref type="bibr" target="#b6">(Lee et al. 2018</ref>) propose a CleanNet for tackling this problem. It deploys an additional network to assign a weight score for each sample in training set, and gives lower weight for noise samples to eliminate their negative effects. However, CleanNet needs clean samples for initialization, which can not satisfied for many real-world applications. The co-teaching and co-training frameworks <ref type="bibr" target="#b4">(Han et al. 2018;</ref><ref type="bibr" target="#b9">Ma et al. 2017</ref>) adopt a learning to teach strategy for dealing with noise and unlabeled data. It leverages two networks for synergistic training, in which each network chooses high confidence training samples for the other network. By doing so, these two models can help each other to resist noisy labels. We draw inspiration from these two co-teaching/training methods and develop an asymmetric framework for cross-domain person re-ID.  3 The Proposed Method</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Overview</head><p>Let T be the unlabeled target training set and S be the labeled source training set. Unsupervised domain adaptation tries to leverage both T and S to learn a re-ID model that can generalize well on the target testing set.</p><p>Our proposed ACT is designed to solve this problem, which contains three stages: (1) Source Model Training.</p><p>(2) Clustering-based Adaptation.</p><p>(3) Asymmetric Co-Teaching for Adaptation. The first two stages aim to obtain a model with basic discriminability by initializing on labeled source data and fine-tuning on target data with pseudo labels generated by the clustering. The third stage attempts to cope with the noisy labels through the cooperation of two models (main model M main and collaborator model M co ) initialized by the adapted model in the second stage. During the third stage, we first split the target training set into inliers (T i ) and outliers (T o ) according to the clustering results and then train the model M main /M co with the small-loss samples from T o /T i mined by M co /M main . The overall procedure of our method is illustrated in Alg.1. Next, we will describe the proposed method in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Source Model Training</head><p>In the first stage of our method, we train the source model M src with labeled source dataset S through the crossentropy loss and the triplet loss <ref type="bibr" target="#b5">(Hermans, Beyer, and Leibe 2017)</ref>. Model M src trained on the source data has the basic discriminability for adaptation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Clustering-based Adaptation</head><p>Due to the domain shift between source and target dataset, the obtained source model M src usually can not generalize well on a new dataset. To solve this problem, we follow a robust and reliable adaptation framework <ref type="bibr" target="#b10">(Song et al. 2018)</ref>. It adopts M src (source model) to extract pooling-5 features of target images and divide T into inliers T i and outliers T o according to the clustering results of DBSCAN. Further training can proceed with the annotated inliers T i . We present the adaptation algorithm by introducing its distance metric for clustering and loss function.</p><p>Distance metric for clustering. k-reciprocal encoding and Jaccard distance are chosen to be the distance metric for clustering. In detail, we first compute the pair-wise similarity matrix M by:</p><formula xml:id="formula_0">M i,j = e −||xi−xj || 2 , j ∈ R * (i, k) 0, otherwise ,<label>(1)</label></formula><p>where M i,j is the similarity between sample i and j by using the pooling-5 feature, R * (i, k) is the refined k-reciprocal set for sample i which are obtained by adding some specific reliable constrains as mentioned in <ref type="bibr" target="#b13">(Zhong et al. 2017)</ref>. After obtaining the similarity matrix M, the Jaccard distance d J (i, j) can be computed by:</p><formula xml:id="formula_1">d J (i, j) = 1 − Nt k=1 min(M ik , M jk ) Nt k=1 max(M ik , M jk ) ,<label>(2)</label></formula><p>where N t is the total image number of the target training dataset. To enhance the degree of similarity, each target feature should close to some source features as mentioned in (Panareda Busto and Gall 2017), i.e., to minimize:</p><formula xml:id="formula_2">d W = 1 − e ||xi−Ns(xi)|| 2 ,<label>(3)</label></formula><p>where N s (x i ) is the nearest neighbor in the source domain for target image i. Taking the d J and d W into consideration, the final distance metric for clustering is computed by:</p><formula xml:id="formula_3">d i,j = λ[d W (x i ) + d W (x j )] + (1 − λ)d J (i, j),<label>(4)</label></formula><p>where λ ∈ [0, 1] is the balancing factor, and we set it to 0.1 in this study.</p><p>Loss function. Given the computed distance matrix M, we perform DBSCAN on the unlabeled target dataset T and divide it into inliers T i and outliers T o . Each sample in the T i is assigned to a cluster. Therefore, we can fine-tune M src with pseudo labels of T i and update the clustering results based on the optimized M src iteratively. We only use triplet loss for the fine-tuning of M src . The triplet loss is computed for each batch data by using both pooling-5 and fc-2048 features via:</p><formula xml:id="formula_4">L tri = N b i=1 ||x p − x a || 2 − ||x n − x a || 2 + m + ,<label>(5)</label></formula><p>where N b is the training batch size, p and n are the most dissimilar positive sample and most similar negative sample for anchor image a. x p , x n and x a denote corresponding features of positive, negative and anchor samples. After adaptation, we obtain a much better re-ID model M ada . However, as mentioned in Sec. 1, features extracted by the model are not reliable enough for downstream clustering task, due to the inconsistent distribution of source and target domain. Therefore, clustering results may contain many noisy labels. To further adapt the model against the noisy dataset, we propose ACT in the third stage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Asymmetric Co-Teaching for Adaptation</head><p>Original co-teaching <ref type="bibr" target="#b4">(Han et al. 2018</ref>) deploys two networks to find possibly clean labels, i.e., small loss samples in the noisy dataset. By sending these samples mined by one network to another for optimization, the influence of incorrect labels can be largely reduced. However, co-teaching does not effectively apply to the context of cross-domain re-ID. On the one hand, selected small loss samples are easy for the model to learn and have a limited positive effect for boosting re-ID accuracy. On the other hand, hard samples with high loss values are difficult to be taken into consideration during the co-teaching process, which may limit the diversity of training samples for adaptation. In short, the conventional co-teaching is prone to make re-ID model converge to local minimum, which is not beneficial to train a robust network.</p><p>To handle the issues mentioned above, we propose a novel co-teaching-like framework for unsupervised cross-domain re-ID in the third stage. In our framework, we initialize main model M main and collaborator model M co with previously obtained M ada . M main and M co are then trained in asymmetric manners. M co tries to infer pure data from the outliers for training of the M main , which encourages M main to train with more reliable but diverse samples. M main focuses on mining as clean as possible samples from inliers for the training of M co , which ensures that M co can maintain the basic representation with easily clustering samples. The whole ACT process has been shown in <ref type="figure" target="#fig_1">Fig. 1</ref>. Specifically, it contains two steps:</p><p>Step 1: Inliers/Outliers Generation.We adopt M ada to initialize M main and M co and then extract pooling-5 features for all unlabeled target images for DBSCAN-based pseudo label assignment. DBSCAN is a density-based clustering method, which assigns pseudo labels for samples in high-density area and regards samples in low-density area <ref type="table">Table 1</ref>: Comparison with state-of-the-art methods on Market-1501 (M), DukeMTMC-reID (D) and CUHK03 (C). Our proposed algorithm outperforms image-level (SP-GAN, PT-GAN), attribute-level (TJ-AIDL, MMFA, CFSM), clustering-based (Theory) and hybrid (HHL, ECN) methods by a large margin. "*": reproduced by this paper. as outliers. By doing so, T can be naturally divided into T i and T o . In <ref type="bibr" target="#b10">(Song et al. 2018)</ref>, the obtained T o are directly discarded. However, we argue that these images are crucial to further boost re-ID accuracy and must be used in a reasonable way. In view of that, we need to give pseudo labels for T o . In our experiments, we assign a pseudo label for each T o sample according to its nearest neighbor in T i .</p><formula xml:id="formula_5">Source → Target M → D M → C C → M C → D D → M D → C mAP</formula><p>Step 2: Asymmetric Co-Teaching. In this step, we employ the main model M main and the collaborator model M co for mining useful clean samples from the noisy data and improve the performance cooperatively. Next, we will introduce the training process of M main and M co , respectively.</p><p>(a) For the training of M main , we sample a mini-batch t o with B s samples from T o , and build corresponding B s triplets. Then, we adopt M co to compute the triplet loss for each triplet and choose K% anchors with the smallest loss values as possibly clean samples. We combine the selected anchors with another B s samples (t i ) obtained from T i to form a training mini-batch for the fine-tuning of M main . In this part, M co plays a significant role to encourage M main to receive samples as diverse as possible and the re-trained M main is more capable of discriminating hard samples.</p><p>(b) For the training of M co , we first sample B s images from T i to form t i , and then utilize M main in (a) to mine small loss samples from t i for optimizing M co . In this part, M main mainly focus on ensuring the training samples for M co as pure as possible the re-trained M co can keep basic discriminability for selecting pure samples.</p><p>We repeat step 1 and step 2 of ACT for a certain number of rounds to adequately train both models. After training procedure finished, we regard the well-trained M main as our final adapted model for evaluation. It should be noted that we use a different strategy from the original CT to obtain small-loss samples. In our setting, we choose training samples from triplets. Anchors with the smallest K% triplet losses are selected as the reliable samples for fine-tuning. The mechanism behind our selecting strategy is that highconfident anchors are more likely to achieve small losses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiment</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Settings</head><p>We conduct experiments on three large-scale benchmark datasets: <ref type="bibr">Market-1501</ref><ref type="bibr" target="#b13">(Zheng et al. 2015</ref>, DukeMTMC-reID <ref type="bibr" target="#b10">(Ristani et al. 2016;</ref><ref type="bibr" target="#b13">Zheng, Zheng, and Yang 2017)</ref> and CUHK03 <ref type="bibr" target="#b7">(Li et al. 2014)</ref>. The mAP and rank-1 accuracy are adopted as evaluation metrics. We use the new-protocol proposed in <ref type="bibr" target="#b13">(Zhong et al. 2017)</ref> for evaluating CUHK03.</p><p>In the source model training stage, we adopt both crossentropy loss and triplet loss for the training of ImageNetpretrained ResNet-50 model. Adam solver is used to optimize the re-ID model with an initial learning rate of 3 × 10 −4 . We train re-ID model for 150 epochs and the learning rate is linearly decreased to 0 for the last 50 epochs. Margin m in the triplet loss is set to 0.3. Training batch size B s = 64. Input images are resized to 128 × 64. We also use random flip and random erasing <ref type="bibr" target="#b17">(Zhong et al. 2020)</ref> for data argumentation.</p><p>In the clustering-based adaptation stage, we constrain the minimum size of a cluster to 4 and set density radius p = 1.6 × 10 −3 . After a clustering step, we train the model for 30 epochs, and iterate this procedure for 30 rounds. Other parameters are kept the same as in <ref type="bibr" target="#b10">(Song et al. 2018</ref>).</p><p>In the last asymmetric co-teaching stage, we form triplet samples in a batch to compute triplet loss for each anchor image. Anchors with the smallest K% losses are selected for further training. We set the small loss ratio K = 20% and linearly increase it to 100% for the whole R co epochs, R co = 10. Adam is used to fine-tune the models for 10 epoch with a fixed learning rate of 6 × 10 −5 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Comparison with state-of-the-arts</head><p>In Tab. 1, we compare our method with several stateof-the-art jobs on three large scale benchmarks (Market-1501, DukeMTMC-reID and CUHK03). Our method outperforms other algorithms by a large margin on all tasks. Take D→M and M→D tasks for example. For image-level SP-GAN, it can only get slightly performance gain than the direct transfer baseline. The attribute-level adaptation methods can achieve better performance than the image-level ones. However, our ACT achieves around 32% and 27% mAP improvement over the MMFA and the CFSM. The <ref type="figure">Figure 2</ref>: Visualization of small loss samples. We choose images with small loss values from T i and merge them into their corresponding clusters. Chosen images are not serious affected by illumination and occlusion compared with most images in T i , which may be helpful for model refinement.</p><p>hybrid method "ECN" investigates the exemplar-, camera-, and neighborhood-invariance inside the target domain, and can boost the mAP to 43% and 49% on both D→M and M→D tasks. However, their method still achieves lower re-ID accuracies than ours. Compared with the clusteringbased method "Theory", our ACT can boost mAP scores by 6.9% and 5.5% on both adaptation tasks. Similar results can be found in other adaptation tasks. Our method has better accuracies on all experiments, which demonstrates the validity of ACT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Visualization of Small Loss Samples</head><p>In <ref type="figure">Fig. 2</ref>, we visualize the small loss samples mining of the collaborator network during the ACT procedure on the Market-1501 dataset. As can be seen, most outliers in T o are high variance samples caused by occlusion and illumination, which can be hardly assigned correct pseudo labels. After computing the loss in T i against the collaborator network, we can obtain relative reliable training images in T i with high diversity, and these samples are helpful for training the main network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Ablation Study</head><p>Our proposed framework achieves better performance by using asymmetric structure. To argue the effectiveness of our proposed method, we conduct extensive experiments under three different settings in <ref type="figure">Fig. 3 to show:</ref> (1) The necessity of taking T o into training process.  <ref type="figure">Figure 3</ref>: Three different learning strategies compared in our ablation study. We compare Co-Teaching, Revised Co-Teaching (CT with T o ) and Asymmetric Co-Teaching to see which structure achieves the highest re-ID accuracies. Dash lines are basic operations without back-propagation process. improve mAP scores by 2.7% and 0.7% for both adaptation tasks, which indicates the necessity of taking T o into training process. However, possible noisy labels in training samples may hinder the further improvement on re-ID accuracies. To demonstrate (2), we conduct CT to filter out noisy samples. As the third line of Tab. 2 shows, the original CT has a slight improvement for adaptation in a certain degree. The results may be caused by the aforementioned weakness, so we conduct another experiment, which takes T o into each round of CT process to make re-ID model escape the local minimum. The details of CT and revised CT (CT with T o ) are shown in <ref type="figure">Fig. 3-(a)</ref> and <ref type="figure">Fig. 3-(b)</ref>. From the fourth line of Tab. 2 we may see that CT with outliers can achieve higher but not significant mAP scores. For (3), we further evaluate the effectiveness of our proposed asymmetric structure. Detailed workflow in ACT is shown in <ref type="figure">Fig. 3-(c)</ref>. Our ACT can achieve the highest accuracies on both adaptation tasks with 60.6% and 54.5% mAP scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Variant Evaluation</head><p>How much difference between the main model and the collaborator model? To show the difference between these two models, we report mAP and rank-1 scores of both models during the ACT stage. As can be seen from <ref type="figure" target="#fig_3">Fig. 4</ref>, M co is always inferior to M main . Since the collaborator model only accepts samples with small loss values mined from the inliers T i by M main , its training data are more likely to have 2: Ablation study. We evaluate five settings. "Theory", "Theory" with outliers, co-teaching (CT), CT with outliers and our asymmetric co-teaching (ACT). Our method gives the best result among other competitors."*":reproduced by this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head><p>Duke   more easy samples than hard ones. Whether the clustering accuracy increase along with the training iteration? We evaluate the clustering results after each DBSCAN clustering step to see whether the accuracy improves. We adopt F-score to measure the quality of clustering after merging T o images. As shown in <ref type="figure">Fig. 5-(a)</ref>, F-score continues increasing for each iteration, which means the discriminative of the adapted model is also increasing. In <ref type="figure">Fig. 5-(b)</ref>, we also record the size of outliers T o . With the decrease of T o , we can get better clusters for adaptation.</p><p>Is the proposed pipeline compatible with other clustering methods ? We replace the DBSCAN in our method with k-means to see whether the proposed pipeline is compatible with other clustering methods. It should be noted that k-means does not generate outliers directly, which is different from DBSCAN. However, we can consider the furthest u% samples far away from their centroids as outliers. In our experiment, we conduct u=20 and u=30 to see whether ACT benefits k-means-based adaptation methods. For convenience, we set k exactly the number of identities for target dataset. As is shown in Tab. 3, when u=20, we achieve 56.0% and 49.8% mAP scores for both transferring <ref type="figure">Figure 5</ref>: Evaluation of clustering quality during asymmetric co-teaching. (a), F-scores during the adaptation. (b), number of images in T o (|T o |) for the whole 10 epochs. We may say that asymmetric co-teaching has positive effect for crossdomain re-ID.</p><p>tasks. For u=30, our method still outperforms the vanilla k-means-based adaptation with 55.0% and 49.5% mAP scores, respectively. Our ACT can achieve 3.3% and 3.1% improvements on both transferring tasks. In the last two lines of Tab. 3, we compare k-means-based algorithm with DBSCAN-based version. The results demonstrate that ACT can also benefit other clustering-based adaptation methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we propose a novel asymmetric co-training framework for unsupervised cross-domain re-ID. Our framework is composed of two networks initialized with the same weights named "Main Model" and "Collaborator Model". By selecting possibly clean samples from target for each other, adapted main model can resist noisy labels. Furthermore, we design different data flow for both networks to make main model accepts training samples as diverse as possible while collaborator model as pure as possible. The proposed method works fine on three large-scale datasets. We consider applying our work to more unsupervised domain adaptation tasks such as face recognition in the future.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Training deep model on noisy dataset have been widely studied in recent years. Transition matrix<ref type="bibr" target="#b10">(Sukhbaatar et al. 2014;</ref><ref type="bibr" target="#b9">Patrini et al. 2017)</ref>, robust loss function(Natarajan et  al. 2013;<ref type="bibr" target="#b13">Zhang and Sabuncu 2018)</ref> and CleanNet<ref type="bibr" target="#b6">(Lee et al. 2018</ref>) are three main efforts for this problem.Transition matrix tries to capture the transition probabilities between noisy labels and true labels, based on an assumption that the transition probability between different classes are identical. Sukhbaatar et al.(Sukhbaatar et al. 2014) add an extra linear layer to capture the relationship between true and corrupted labels. Patrini et al. (Patrini et al. 2017) estimate the transition matrix by a corresponded loss correction algorithm. However, these kinds of methods do not generalize well on large scale dataset. Another solution is to design robust loss for model training against noisy labels. Natarajan et al. (Natarajan et al. 2013) present an unbiased estimator to give loss correction for model training. Zhang et al. (Zhang and Sabuncu 2018)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Algorithm 1</head><label>1</label><figDesc>Procedure of the proposed method. Inputs: Labeled source dataset S, unlabeled target dataset T , ImageNet pre-trained model M . Training epochs e 1 , e 2 and e 3 . Maximum round r 2 , r 3 . Outputs: Adapted model M ada . 1: ****************** Stage 1 ******************* 2: Train M on S through triplet loss and cross-entropy loss with e 1 epochs ⇒ source model M src ; 3: ****************** Stage 2 ******************* 4: Divide T into inliers T i and outliers T o according to DB-SCAN results; 5: Fine-tune M src with T i for e 2 epochs and repeat line 4 to 5 for r 2 rounds ⇒ adapted model M ada ; 6: ****************** Stage 3 ******************* 7: Main model M main ⇐ M ada , collaborator model M co ⇐ M ada ; 8: for i = 1 to r 3 do 9: Deploy M main and DBSCAN to divide T into T i and T o ; 10:for j = 1 to e 3 do</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>(2) The necessity of clean noisy labels.(3) The effectiveness of asymmetric structure. All the experiments are conducted in D→M and M→D tasks. We take "Theory"<ref type="bibr" target="#b10">(Song et al. 2018</ref>) as our baseline model and its re-ID accuracies are shown in the first line of Tab. 2.For(1), we directly merge T o into the training process by giving labels to T o based on their nearest neighbour in T i . The new dataset is then sent to re-ID network for fine-tuning. As the second line of Tab. 2 shows, merging T o into T i can</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Evaluation of re-ID accuracies for two networks. Main model is always better than collaborator model because of diversity and purity of training data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>repeat 13 :</head><label>13</label><figDesc>Sample mini-batch t i and t o from T i and T o ; Deploy M co to choose samples with small loss values from t o and mix them with t i for optimizing M main ; Deploy M main to choose samples with small loss values from t i for optimizing M co ; M ada ⇐ M main .</figDesc><table><row><cell>14:</cell><cell>if iter % 2 == 0 then</cell></row><row><cell>15:</cell><cell>// Optimize Main Model.</cell></row><row><cell>16:</cell><cell></cell></row><row><cell>17:</cell><cell>else</cell></row><row><cell>18:</cell><cell>// Optimize Collaborator Model.</cell></row><row><cell>19:</cell><cell></cell></row><row><cell>20:</cell><cell>end if</cell></row><row><cell>21:</cell><cell>iter ++;</cell></row><row><cell>22:</cell><cell>until T i has been enumerated</cell></row><row><cell>23:</cell><cell>end for</cell></row><row><cell cols="2">24: end for</cell></row><row><cell>25:</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table</head><label></label><figDesc></figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3</head><label>3</label><figDesc></figDesc><table><row><cell cols="5">: Asymmetric co-teaching with different clustering</cell></row><row><cell cols="5">methods. ACT is compatible with different clustering meth-</cell></row><row><cell cols="3">ods like k-means and DBSCAN.</cell><cell></cell><cell></cell></row><row><cell>Methods</cell><cell cols="4">Duke → Market Market → Duke mAP rank-1 mAP rank-1</cell></row><row><cell>k-means</cell><cell>52.7</cell><cell>74.4</cell><cell>46.7</cell><cell>66.7</cell></row><row><cell cols="2">+ACT (20%) 56.0</cell><cell>76.8</cell><cell>49.8</cell><cell>69.6</cell></row><row><cell cols="2">+ACT (30%) 55.0</cell><cell>75.5</cell><cell>49.5</cell><cell>68.1</cell></row><row><cell>DBSCAN</cell><cell>52.0</cell><cell>74.1</cell><cell>48.4</cell><cell>67.0</cell></row><row><cell>+ACT</cell><cell>60.6</cell><cell>80.5</cell><cell>54.5</cell><cell>72.4</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgment</head></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Disjoint label space transfer learning with common factorised space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>References</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Stargan: Unified generative adversarial networks for multi-domain image-to-image translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Image-image domain adaptation with preserved self-similarity and domain-dissimilarity for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A density-based algorithm for discovering clusters in large spatial databases with noise</title>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<publisher>ACM TOMM</publisher>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
	<note>Unsupervised person re-identification: Clustering and fine-tuning</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Co-teaching: Robust training of deep neural networks with extremely noisy labels</title>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beyer</forename><surname>Hermans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hermans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Leibe</surname></persName>
		</author>
		<title level="m">defense of the triplet loss for person re-identification</title>
		<imprint>
			<publisher>Arxiv</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Cleannet: Transfer learning for scalable image classifier training with label noise</title>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Deepreid: Deep filter pairing neural network for person re-identification</title>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Unsupervised person re-identification by deep learning tracklet association</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Multi-task mid-level feature alignment network for unsupervised cross-dataset person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS. [Panareda Busto and Gall</title>
		<meeting><address><addrLine>Lloyd</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1982" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="129" to="137" />
		</imprint>
	</monogr>
	<note>CVPR</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Performance measures and a data set for multi-target, multi-camera tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Ristani</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.11334</idno>
		<idno>arXiv:1406.2080</idno>
	</analytic>
	<monogr>
		<title level="m">Training convolutional networks with noisy labels</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>ECCV</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Beyond part models: Person retrieval with refined part pooling (and a strong convolutional baseline)</title>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>CVPR</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Person transfer gan to bridge domain gap for person re-identification</title>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Unlabeled samples generated by gan improve the person re-identification baseline in vitro</title>
		<idno type="arXiv">arXiv:1811.02074</idno>
		<idno>arXiv:1610.02984</idno>
	</analytic>
	<monogr>
		<title level="m">CVPR. [Zheng, Yang, and Hauptmann</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>CVPR</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Generalizing a person retrieval model hetero-and homogeneously</title>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Camstyle: A novel data augmentation method for person re-identification</title>
	</analytic>
	<monogr>
		<title level="j">IEEE TIP</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1176" to="1190" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Invariance matters: Exemplar memory for domain adaptive person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Zhong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.00485</idno>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Learning to adapt invariance in memory for person re-identification</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Random erasing data augmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename></persName>
		</author>
		<idno>Zhong et al. 2020</idno>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Unpaired image-to-image translation using cycle-consistent adversarial networks</title>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
