<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Unsupervised Deep Structured Semantic Models for Commonsense Reasoning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuohang</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Singapore Management University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Zhang</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Johns Hopkins University</orgName>
								<address>
									<addrLine>3 Microsoft</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yelong</forename><surname>Shen</surname></persName>
							<email>yelongshen@tencent.com</email>
							<affiliation key="aff2">
								<orgName type="department">Tencent AI Lab</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Liu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingjing</forename><surname>Liu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
							<email>jfgao@microsoft.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Jiang</surname></persName>
							<email>jingjiang@smu.edu.sg</email>
							<affiliation key="aff0">
								<orgName type="institution">Singapore Management University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Unsupervised Deep Structured Semantic Models for Commonsense Reasoning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T17:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Commonsense reasoning is fundamental to natural language understanding. While traditional methods rely heavily on humancrafted features and knowledge bases, we explore learning commonsense knowledge from a large amount of raw text via unsupervised learning. We propose two neural network models based on the Deep Structured Semantic Models (DSSM) framework to tackle two classic commonsense reasoning tasks, Winograd Schema challenges (WSC) and Pronoun Disambiguation (PDP). Evaluation shows that the proposed models effectively capture contextual information in the sentence and coreference information between pronouns and nouns, and achieve significant improvement over previous state-of-the-art approaches.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Commonsense reasoning is concerned with simulating the human ability to make presumptions about the type and essence of ordinary situations they encounter every day <ref type="bibr" target="#b6">(Davis and Marcus, 2015)</ref>. It is one of the key challenges in natural language understanding, and has drawn increasing attention in recent years <ref type="bibr" target="#b10">(Levesque et al., 2011;</ref><ref type="bibr" target="#b25">Roemmele et al., 2011;</ref><ref type="bibr" target="#b33">Zhang et al., 2017;</ref><ref type="bibr">Rashkin et al., 2018a,b;</ref><ref type="bibr" target="#b31">Zellers et al., 2018;</ref><ref type="bibr" target="#b29">Trinh and Le, 2018)</ref>. However, due to the lack of labeled training data or comprehensive hand-crafted knowledge bases, commonsense reasoning tasks such as Winograd Schema Challenge <ref type="bibr" target="#b10">(Levesque et al., 2011)</ref> are still far from being solved.</p><p>In this work, we propose two effective unsupervised models for commonsense reasoning, and evaluate them on two classic commonsense reasoning tasks: Winograd Schema Challenge (WSC) and Pronoun Disambiguation Problems (PDP). Compared to other commonsense reasoning tasks, * Work done when the author was at Microsoft 1. The city councilmen refused the demonstrators a permit because they feared violence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Who feared violence?</head><p>A. The city councilmen B. The demonstrators 2. The city councilmen refused the demonstrators a permit because they advocated violence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Who advocated violence?</head><p>A. The city councilmen B. The demonstrators WSC and PDP better approximate real human reasoning, and can be more easily solved by native English-speaking adults <ref type="bibr" target="#b10">(Levesque et al., 2011)</ref>. In addition, they are also technically challenging. For example, the best reported result on WSC is only 20 percentage points better than random guess in accuracy <ref type="bibr" target="#b21">(Radford et al., 2019)</ref>. <ref type="table" target="#tab_0">Table 1</ref> shows two examples from WSC. In order to resolve the co-reference in these two examples, one cannot predict what "they" refers to unless she is equipped with the commonsense knowledge that "demonstrators usually cause violence and city councilmen usually fear violence".</p><p>As no labeled training data is available for these tasks, previous approaches are based on either hand-crafted knowledge bases or large-scale language models. For example, <ref type="bibr" target="#b13">Liu et al. (2017)</ref> used existing knowledge bases such as ConceptNet <ref type="bibr" target="#b11">(Liu and Singh, 2004)</ref> and <ref type="bibr">WordNet (Miller, 1995)</ref> for external supervision to train word embeddings and solve the WSC challenge. <ref type="bibr">Recently, Trinh and Le (2018)</ref> first used raw text from books/news to train a neural Language Model (LM), and then em-ployed the trained model to compare the probabilities of the sequences, where the pronouns are replaced by each of the candidate references, and to pick the candidate that leads to the highest probability as the answer.</p><p>Because none of the existing hand-crafted knowledge bases is comprehensive enough to cover all the world knowledge 1 , we focus on building unsupervised models that can learn commonsense knowledge directly from unlimited raw text. Different from the neural language models, our models are optimized for co-reference resolution and achieve much better results on both the PDP and WSC tasks.</p><p>In this work we formulate the two commonsense reasoning tasks in WSC and PDP as a pairwise ranking problem. As the first example in <ref type="table" target="#tab_0">Table 1</ref>, we want to develop a pair-wise scoring model Score θ (x i , y) that scores the correct antecedent-pronoun pair ("councilmen", "they") higher than the incorrect one ("demonstrators", "they"). These scores depend to a large degree upon the contextual information of the pronoun (e.g., they) and the candidate antecedent (e.g., councilmen). In other words, it requires to capture the semantic meaning of the pronoun and the candidate antecedent based on the sentences where they occur, respectively.</p><p>To tackle this issue, we propose two models based on the framework of Deep Structured Similarity Model (DSSM) <ref type="bibr" target="#b8">(Huang et al., 2013)</ref>, as shown in <ref type="figure" target="#fig_0">Figure 1(a)</ref>. Formally, let S x be the sentence containing the candidate antecedent x i and S y the sentence containing the pronoun y which we're interested in. DSSM measures the semantic similarity of a pair of inputs (x i , y) by 1) mapping x i and y, together with their context information, into two vectors in a semantic space using deep neural networks f 1 and f 2 , parameterized by θ; and 2) computing cosine similarity 2 between them. In our case, we need to learn a task-specific semantic space where the distance between two vectors measures how likely they co-refer. Commonsense knowledge such as "demonstrators usually cause violence" can be implicitly captured in the semantic space through DSSM, which is trained on a large amount of raw text.</p><p>DSSM requires labeled pairs for training.Since there is no labeled data for our tasks, we propose two unsupervised DSSMs, or UDSSMs. As shown in <ref type="figure" target="#fig_0">Figure 1</ref>(b) and 1(c), (S x , S y ) are encoded into contextual representations by deep neural networks f 1 and f 2 ; then we compute pair-wise their co-reference scores.</p><p>In what follows, we will describe two assumptions we propose to harvest training data from raw text. Assumption I: A pronoun refers to one of its preceding nouns in the same sentence. The sentences generated by this assumption will be used for training UDSSM-I. Some examples will be shown in the "data generation" section. Assumption II: In a sentence, pronouns of the same gender and plurality are more likely to refer to the same antecedent than other pronouns. Similarly, the sentences following the assumption will be used for training UDSSM-II.</p><p>Note that the two models, UDSSM-I and UDSSM-II are trained on different types of pairwise training data, thus the model structures are different, as illustrated in <ref type="figure" target="#fig_0">Figure 1</ref> Among all these commonsense reasoning tasks, the Winograd Schema Challenge (WSC) and Pronoun Disambiguation Problems (PDP) <ref type="bibr" target="#b10">(Levesque et al., 2011)</ref> are known as the most challenging tasks for commonsense reasoning. Although both tasks are based on pronoun disambiguation, a subtask of coreference resolution <ref type="bibr">(Soon et al., 2001;</ref><ref type="bibr" target="#b17">Ng and Cardie, 2002;</ref><ref type="bibr" target="#b19">Peng et al., 2016)</ref>, PDP and WSC differ from normal pronoun disambiguation due to their unique properties, which are based on commonsense, selecting the most likely antecedent from both candidates in the directly preceding context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Previous efforts on solving the Winograd Schema Challenge and Pronoun Disambiguation</head><p>Problems mostly rely on human-labeled data, sophisticated rules, hand-crafted features, or external knowledge bases <ref type="bibr" target="#b18">(Peng et al., 2015;</ref><ref type="bibr" target="#b0">Bailey et al., 2015;</ref><ref type="bibr" target="#b26">Schüller, 2014)</ref>. <ref type="bibr" target="#b22">Rahman and Ng (2012)</ref> hired workers to annotate supervised training data and designed 70K hand-crafted features. <ref type="bibr" target="#b27">Sharma et al. (2015)</ref>; Schüller (2014); <ref type="bibr" target="#b0">Bailey et al. (2015)</ref>; <ref type="bibr" target="#b13">Liu et al. (2017)</ref> utilized expensive knowledge bases in their reasoning processes. Recently, Trinh and Le 2018 applied neural language models trained with a massive amount of unlabeled data to the Winograd Schema Challenge and improved the performance by a large margin. In contrast, our unsupervised method based on DSSM significantly outperforms the previous state-of-theart method, with the advantage of capturing more contextual information in the data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Approach</head><p>As shown in <ref type="figure" target="#fig_0">Figure 1</ref>, we propose two unsupervised deep structured semantic models (UDSSM-I and UDSSM-II), which consist of two components: DNN encoding and co-reference scoring. For the model UDSSM-I, the co-referred word pairs are automatically learned through an attention mechanism, where the attention weights are the co-reference scores for word pairs. For the second model UDSSM-II, we will directly optimize the co-reference score during training. After all, we will get the co-reference scoring function, Score θ (x i , y), to compare the candidate answers in the tasks of PDP/WSC. Next, we will show the details of our models trained in an unsupervised way.</p><p>In the following sections, we will use uppercase symbols in bold, e.g., S x , to represent matrices. Lowercase symbols in bold, e.g., h x , represent vectors. A regular uppercase symbol, e.g., S x , represents a lexical sequence. A regular lowercase symbol, e.g., x i or y, represents a token.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">UDSSM-I Model</head><p>This model is developed based on Assumption I. Its architecture is shown in <ref type="figure">Figure 2</ref>. The sentences generated based on this assumption contain a pronoun y and a set of its preceding nouns {x i , x j ...}, which includes the referred word by pronoun. For example, the sentence in <ref type="figure">Figure 2</ref>. As there is no clear label for the co-referred word pairs under this assumption, our model will rank the set of nouns {x i , x j ...} which contains the noun that the pronoun y refers to higher than the set which does not. And the co-reference score between words will not be optimized directly during  <ref type="figure">Figure 2</ref>: The procedure of using UDSSM-I to compute the co-reference scores of a positive example and a negative example respectively. The positive example is generated from the sentence 'Two Northwest Airlines pilots failed to make radio contact with ground controllers for more than an hour and overflew their Minneapolis destination by 150 miles before discovering the mistake and turning around.". The negative one replaces the second sequence with one sequence from different sentence. training, but is learned indirectly through the attention mechanism. We will describe in turn how the training data is generated from raw text, the model architecture, and the co-reference scoring function for the final prediction on the tasks of PDP/WSC.</p><formula xml:id="formula_0">(a) Positive example (b) Negative example h k-1 h k h k+1 h j-1 h j h j+1 h k-1 h k h k+1 h j-1 h j h j+1 &lt;bos&gt; He tried but she did h k-1 ; h k+1 ] h j-1 ; h j+1 ] DNN Input Contextual Representation Scoring h i-1 h i h j-1 h j h j+1 h i-1 h i h i+1 h j h j+1 call her but she did h i-1 : [ ; h i+1 ] h j-1 ; h j+1 ] : [ : [ : [ h x &lt; l a</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Data Generation</head><p>The main challenge of PDP/WSC tasks is that it has no labeled training data. Here we introduce a simple method to collect unsupervised training data by leveraging some linguistic patterns. Following Assumption 1, the first hypothesis we make is that "the pronoun refers to one of the preceding nouns", which is a common phenomenon in well-written stories or news. In this way, we generate (S x , S y ) pairs from raw text as follows:</p><p>• Parse the sentences in the raw text to obtain entity names, nouns and pronouns.</p><p>• Pick sentences that contain at least one pronoun and multiple nouns preceding it. • Split each sentence into two sub-sentences to form a positive pair (S x , S y ), where S x is the first sub-sentence with identified nouns and entity names while S y is the second sub-sentence with a pronoun. • One or more negative pairs are generated from (S x , S y ) by replacing S y with S y neg randomly sampled from other positive pairs.</p><p>We split the sentence with pronouns and nouns into two sub-sequences separated by the previous word of the pronoun. Therefore, the example sentence in the <ref type="figure">Figure 2</ref> can be split into two subsentences as shown below:</p><p>• S x : " Two Northwest Airlines pilots failed to make radio contact with ground controllers for more than an hour and" • S y : "overflew their Minneapolis destination by 150 miles before discovering the mistake and turning around".</p><p>As the sentences are collected from raw text, the co-reference words are not given. Our proposed UDSSM-I model will learn the co-reference scoring function through attention mechanism based on the generated sequence pairs. Next, we will introduce the details of this model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Model Architecture</head><p>This method takes the pair of sequences, (S x , S y ), as inputs, and computes similarity between the sequences collected from the same sentence. As we hypothesize that one of the nouns in the first sequence and the pronoun in the second are coreferred, we only use the contextual representations of nouns and pronoun to represent the sequences. To obtain the contextual representation, we first use a bi-directional LSTM to process these sequences 3 :</p><formula xml:id="formula_1">H x = Bi-LSTM(S x ), H y = Bi-LSTM(S y ), (1)</formula><p>where S x ∈ R d×X , S y ∈ R d×Y are the word embeddings of the two sequences. d is the dimension of the word embeddings. X, Y are the lengths of the two sequences. H x ∈ R l×X and H y ∈ R l×Y are the hidden states of bi-directional LSTM. Our model is task-specifically constructed, so we directly use the hidden state of the first pronoun in the second sequence as its representation:</p><formula xml:id="formula_2">f 2 (S y ) = h y = h y 2 ,<label>(2)</label></formula><p>where h y 2 ∈ R l is the second 4 vector from H y and it represents the contextual information of the pronoun. Next, we will get the representation of the first sequence. As there are multiple nouns in the first sequence and the pronoun usually refers to only one of them, we use the weighted sum of all the LSTM hidden states of the nouns to represent the sequence,ĥ x ∈ R l , as follows: <ref type="bibr">3</ref> We use two different LSTMs to process the sequences S x and S Y here. This is to make the negative sampling in Eqn. (4) more efficient, so that we can directly use the other representations in the same batch as negative ones. <ref type="bibr">4</ref> We assign the word just before the pronoun to the second sequence, so the pronoun always appears in the second position of the sequence.</p><formula xml:id="formula_3">H n = [h x i ; h x j ; ...] α = SoftMax (W g H n + b g ⊗ e N ) T h y , f 1 (S x ) =ĥ x = H n α,<label>(3)</label></formula><p>where i, j... are the positions of the nouns in the sequence S x and [; ] is the concatenation of two vectors. H n ∈ R l×N are all the hidden states of the nouns 5 in H x in the sequence. N is the number of nouns in the sequence. α ∈ R N is the weights assigned for the different nouns andĥ x ∈ R l is the weighted sum of all the hidden states of the nouns. W g ∈ R l×l and b g ∈ R l are the parameters to learn; e N ∈ R N is a vector of all 1s and it is used to repeat the bias vector N times into the matrix. Then we will maximize the similarity of the contextual representations of (ĥ x , h y ). Meanwhile, we also need some negative samples h y neg k forĥ x . Then our loss function for this method is constructed:</p><formula xml:id="formula_4">L = − log   exp ĥ x h y exp ĥx h y + K k exp ĥx h y neg k   ,<label>(4)</label></formula><p>where h y neg k ∈ R l is the randomly sampled hidden state of pronoun from the sequences not in the same sentence with S y .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3">Co-reference Scoring Function</head><p>Overall, the model tries to make the co-reference states similar to each other. The co-reference scoring function is defined:</p><formula xml:id="formula_5">Score θ (x i , y) = g(h x i , h y ) = (W g h x i + b g ) T h y ,<label>(5)</label></formula><p>where the candidate located at the i-th position is represented by its LSTM hidden state h x i and the pronoun in the snippet is represented by h y . And the output value of this function for each candidate will be used for the final prediction. Next, we will introduce the other unsupervised method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">UDSSM-II Model</head><p>This model is developed based on Assumption II. Its architecture is shown in <ref type="figure" target="#fig_2">Figure 3</ref>. As the model is similar to the previous one, we will introduce the details in a similar way.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Data Generation</head><p>The second assumption is that "the pronoun pairs in a single sentence are co-reference words if they are of the same gender and plurality; otherwise they are not." Based on this assumption, we can directly construct the co-reference training pairs as follows:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Experimental Results</head><p>The experiment results are shown in <ref type="table">Table 2</ref>. Most of the performance in the top of the <ref type="table">Table 2</ref> are the models trained with external knowledge bases, such as Cause-Effect <ref type="bibr" target="#b12">(Liu et al., 2016)</ref>, <ref type="bibr">Word-Net (Miller, 1995)</ref>, ConceptNet <ref type="bibr" target="#b11">(Liu and Singh, 2004)</ref> knowledge bases. Unsupervised Semantic Similarity Method (USSM) <ref type="bibr" target="#b13">(Liu et al., 2017)</ref> is based on the skip-gram model <ref type="bibr" target="#b14">(Mikolov et al., 2013)</ref> to train word embeddings and the embeddings of all the words connected by knowledge bases are optimized to be closer. Neural Knowledge Activated Method (NKAM) <ref type="bibr" target="#b13">(Liu et al., 2017)</ref> trained a binary classification model based on whether the word pairs appear in the knowledge base. One limitation of these methods is that they rely heavily on the external knowledge bases. Another limitation is that they just linearly aggregate the embeddings of the words in the context, and that's hard to integrate the word order information. Instead, our model with LSTM can better represent the contextual information. Besides, our model don't need any external knowledge bases, and achieve a significant improvement on both of the datasets.</p><p>We further compare our models with the unsupervised baselines, ELMo <ref type="bibr" target="#b20">(Peters et al., 2018)</ref> which selects the candidate based on the cosine similarity of the hidden states of noun and pronoun. Another unsupervised baseline, Google Language Model for commonsense reasoning (Trinh and Le, 2018), which compares the perplexities of the new sentences by replacing the pronoun with candidates. To make a fair comparison to Trinh and Le (2018)'s work, we also train our single model on the corpus of Gutenberg only. We can see that both of our methods get significant improvement on the PDP dataset, and our UDSSM-II can achieve much better performance on the WSC dataset. We also report our ensemble model (nine models with different hyperparameters) trained with both corpus of Gutenberg and 1 Billion Word, and it also achieve better performance than Google Language Model trained with the same corpus.</p><p>Finally, we also compare to the pre-trained Coreference Resolution Tool <ref type="bibr">(Clark and Manning, 2016a,b)</ref>  <ref type="bibr">12</ref> , and we can see that it doesn't adapt to our commonsense reasoning tasks and can't tell 12 https://github.com/huggingface/ neuralcoref the difference between each pair of sentences from WSC. In this way, our model can get much better performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Analysis</head><p>WSC 1: Paul tried to call George on the phone, but he wasn't successful. Ours 1: He tried to call 911 using her cell phone but that he could n't get the phone to work.</p><p>WSC 2: Paul tried to call George on the phone, but he was n't available . Ours 2: He tried twice to call her but she did not answer the phone . In this subsection, we will conduct further analysis on the reason that our models work, the benefit of our models comparing to a baseline, and the limitation of our proposed models.</p><p>We have a further analysis on the pair-wise sentences, which we collected for training, to check how our model can work. We find that some reasoning problems can somehow be converted to the paraphrase problem. For example, in <ref type="table" target="#tab_1">Table 3</ref>, we make use of Lucene Index 13 with BM25 to retrieve the similar sentences to the WSC sentences from our training dataset, and make a comparison. We can see that these pairs are somehow paraphrased each other respectively. For the first pair, the contextual representations of "Paul" and "he" in WSC could be similar to the contextual representations of "he" in our training sentence. As these representations are used to compute the co-reference score, the final scores would be similar. The pseudo label "positive" for our first sentence will make the positive probability of the golden co-references "Paul" and "he" in WSC higher. And for the second pair in <ref type="table" target="#tab_1">Table 3</ref>, the pseudo label of positive in our second sentence will make the positive probability of the golden co-references "George" and "he" in WSC 2 higher. In this way, these kinds of co-reference patterns from training data can be directly mapped to solve the Winograd Schema Challenges.</p><p>Here's another example from PDP demonstrating the benefit of our method: "Always before, Larry had helped Dad with his work. But he could not help him now, for Dad said that ". Trinh and Le (2018) failed on this one, probably because language models are not good at solving long distance dependence, and tends to predict that "he " refers to "his" in the near context rather the correct answer "Larry". And our model can give the correct prediction.</p><p>We further analysis the predictions of our model. We find that some specific commonsense knowledge are still hard to learn, such as the following pairs:</p><p>• The trophy doesn't fit into the brown suitcase because it is too small. • The trophy doesn't fit into the brown suitcase because it is too large.</p><p>To solve this problem, the model should learn the knowledge to compare the size of the objects. However, all of our models trained with different hyper-parameters select the same candidate as the co-referred word for "it" in both sentences. To solve the problem, broader data need to collect for learning more commonsense knowledge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In conclusion, to overcome the lack of human labeled data, we proposed two unsupervised deep structured semantic models (UDSSM) for commonsense reasoning. We evaluated our models on the commonsense reasoning tasks of Pronoun Disambiguation Problems (PDP) and Winograd Schema Challenge <ref type="bibr" target="#b10">(Levesque et al., 2011)</ref>, where the questions are quite easy for human to answer, but quite challenging for the machine. Without using any hand-craft knowledge base, our model achieved stat-of-the-art performance on the two tasks.</p><p>In the future work, we will use Transformer, which is proved to be more powerful than LSTM, as the encoder of our unsupervised deep structured semantic models, and we will collect a larger corpus from Common Crawl to train our model.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>(b) and 1(c), respectively. Experiments demonstrated that our methods outperform stat-of-the-art performance on the tasks of WSC and PDP. An overview of (a) the general framework of Deep Structured Semantic Model (DSSM) and our two unsupervised models based on DSSM: (b) UDSSM-I and (c) UDSSM-II. Compared with DSSM, both UDSSM-I and UDSSM-II compute co-reference scores instead of similarity. evaluates a machine's ability of commonsense reasoning in reading comprehension.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>t e x i t s h a 1 _ b a s e 6 4 = " f F T R f b x r R i Y Y v C 4 t / y 6 z S B s 3 a u k = " &gt; A A A B 7 n i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K o k I 6 q 3 o x W M F Y w t t K J P t p l 2 7 2 c T d j V B C / 4 Q X D y p e / T 3 e / D d u 2 x y 0 9 c H A 4 7 0 Z Z u a F q e D a u O 6 3 s 7 S 8 s r q 2 X t o o b 2 5 t 7 + x W 9 v b v d Z I p y n y a i E S 1 Q t R M c M l 8 w 4 1 g r V Q x j E P B m u H w e u I 3 n 5 j S P J F 3 Z p S y I M a + 5 B G n a K z U 6 q B I B 9 h 9 6 F a q b s 2 d g i w S r y B V K N D o V r 4 6 v Y R m M Z O G C t S 6 7 b m p C X J U h l P B x u V O p l m K d I h 9 1 r Z U Y s x 0 k E / v H Z N j q / R I l C h b 0 pC p + n s i x 1 j r U R z a z h j N Q M 9 7 E / E / r 5 2 Z 6 C L I u U w z w y S d L Y o y Q U x C J s + T H l e M G j G y B K n i 9 l Z C B 6 i Q G h t R 2 Y b g z b + 8 S P z T 2 m X N v T 2 r 1 q + K N E p w C E d w A h 6 c Q x 1 u o A E + U B D w D K / w 5 j w 6 L 8 6 7 8 z F r X X K K m Q P 4 A + f z B 3 a P j 8 g = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " f F T R f b x r R i Y Y v C 4 t / y 6 z S B s 3 a u k = " &gt; A A A B 7 n i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K o k I 6 q 3 o x W M F Y w t t K J P t p l 2 7 2 c T d j V B C / 4 Q X D y p e / T 3 e / D d u 2 x y 0 9 c H A 4 7 0 Z Z u a F q e D a u O 6 3 s 7 S 8 s r q 2 X t o o b 2 5 t 7 + x W 9 v b v d Z I p y n y a i E S 1 Q t R M c M l 8 w 4 1 g r V Q x j E P B m u H w e u I 3 n 5 j S P J F 3 Z p S y I M a + 5 B G n a K z U 6 q B I B 9 h 9 6 F a q b s 2 d g i w S r y B V K N D o V r 4 6 v Y R m M Z O G C t S 6 7 b m p C X J U h l P B x u V O p l m K d I h 9 1 r Z U Y s x 0 k E / v H Z N j q / R I l C h b 0 p C p + n s i x 1 j r U R z a z h j N Q M 9 7 E / E / r 5 2 Z 6 C L I u U w z w y S d L Y o y Q U x C J s + T H l e M G j G y B K n i 9 l Z C B 6 i Q G h t R 2 Y b g z b + 8 S P z T 2 m X N v T 2 r 1 q + K N E p w C E d w A h 6 c Q x 1 u o A E + U B D w D K / w 5 j w 6 L 8 6 7 8 z F r X X K K m Q P 4 A + f z B 3 a P j 8 g = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " f F T R f b x r R i Y Y v C 4 t / y 6 z S B s 3 a u k = " &gt; A A A B 7 n i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K o k I 6 q 3 o x W M F Y w t t K J P t p l 2 7 2 c T d j V B C / 4 Q X D y p e / T 3 e / D d u 2 x y 0 9 c H A 4 7 0 Z Z u a F q e D a u O 6 3 s 7 S 8 s r q 2 X t o o b 2 5 t 7 + x W 9 v b v d Z I p y n y a i E S 1 Q t R M c M l 8 w 4 1 g r V Q x j E P B m u H w e u I 3 n 5 j S P J F 3 Z p S y I M a + 5 B G n a K z U 6 q B I B 9 h 9 6 F a q b s 2 d g i w S r y B V K N D o V r 4 6 v Y R m M Z O G C t S 6 7 b m p C X J U h l P B x u V O p l m K d I h 9 1 r Z U Y s x 0 k E / v H Z N j q / R I l C h b 0 p C p + n s i x 1 j r U R z a z h j N Q M 9 7 E / E / r 5 2 Z 6 C L I u U w z w y S d L Y o y Q U x C J s + T H l e M G j G y B K n i 9 l Z C B 6 i Q G h t R 2 Y b g z b + 8 S P z T 2 m X N v T 2 r 1 q + K N E p w C E d w A h 6 c Q x 1 u o A E + U B D w D K / w 5 j w 6 L 8 6 7 8 z F r X X K K m Q P 4 A + f z B 3 a P j 8 g = &lt; / l a t e x i t &gt; ↵ j &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " f F T R f b x r R i Y Y v C 4 t / y 6 z S B s 3 a u k = " &gt; A A A B 7 n i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K o k I 6 q 3 o x W M F Y w t t K J P t p l 2 7 2 c T d j V B C / 4 Q X D y p e / T 3 e / D d u 2 x y 0 9 c H A 4 7 0 Z Z u a F q e D a u O 6 3 s 7 S 8 s r q 2 X t o o b 2 5 t 7 + x W 9 v b v d Z I p y n y a i E S 1 Q t R M c M l 8 w 4 1 g r V Q x j E P B m u H w e u I 3 n 5 j S P J F 3 Z p S y I M a + 5 B G n a K z U 6 q B I B 9 h 9 6 F a q b s 2 d g i w S r y B V K N D o V r 4 6 v Y R m M Z O G C t S 6 7 b m p C X J U h l P B x u V O p l m K d I h 9 1 r Z U Y s x 0 k E / v H Z N j q / R I l C h b 0 p C p + n s i x 1 j r U R z a z h j N Q M 9 7 E / E / r 5 2 Z 6 C L I u U w z w y S d L Y o y Q U x C J s + T H l e M G j G y B K n i 9 l Z C B 6 i Q G h t R 2 Y b g z b + 8 S P z T 2 m X N v T 2 r 1 q + K N E p w C E d w A h 6 c Q x 1 u o A E + U B D w D K / w 5 j w 6 L 8 6 7 8 z F r X X K K m Q P 4 A + f z B 3 a P j 8 g = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " f F T R f b x r R i Y Y v C 4 t / y 6 z S B s 3 a u k = " &gt; A A A B 7 n i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K o k I 6 q 3 o x W M F Y w t t K J P t p l 2 7 2 c T d j V B C / 4 Q X D y p e / T 3 e / D d u 2 x y 0 9 c H A 4 7 0 Z Z u a F q e D a u O 6 3 s 7 S 8 s r q 2 X t o o b 2 5 t 7 + x W 9 v b v d Z I p y n y a i E S 1 Q t R M c M l 8 w 4 1 g r V Q x j E P B m u H w e u I 3 n 5 j S P J F 3 Z p S y I M a + 5 B G n a K z U 6 q B I B 9 h 9 6 F a q b s 2 d g i w S r y B V K N D o V r 4 6 v Y R m M Z O G C t S 6 7 b m p C X J U h l P B x u V O p l m K d I h 9 1 r Z U Y s x 0 k E / v H Z N j q / R I l C h b 0 p C p + n s i x 1 j r U R z a z h j N Q M 9 7 E / E / r 5 2 Z 6 C L I u U w z w y S d L Y o y Q U x C J s + T H l e M G j G y B K n i 9 l Z C B 6 i Q G h t R 2 Y b g z b + 8 S P z T 2 m X N v T 2 r 1 q + K N E p w C E d w A h 6 c Q x 1 u o A E + U B D w D K / w 5 j w 6 L 8 6 7 8 z F r X X K K m Q P 4 A + f z B 3 a P j 8 g = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " f F TR f b x r R i Y Y v C 4 t / y 6 z S B s 3 a u k = " &gt; A A A B 7 n i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K o k I 6 q 3 o x W M F Y w t t K J P t p l 2 7 2 c T d j V B C / 4 Q X D y p e / T 3 e / D d u 2 x y 0 9 c H A 4 7 0 Z Z u a F q e D a u O 6 3 s 7 S 8 s r q 2 X t o o b 2 5 t 7 + x W 9 v b v d Z I p y n y a i E S 1 Q t R M c M l 8 w 4 1 g r V Q x j E P B m u H w e u I 3 n 5 j S P J F 3 Z p S y I M a + 5 B G n a K z U 6 q B I B 9 h 9 6 F a q b s 2 d g i w S r y B V K N D o V r 4 6 v Y R m M Z O G C t S 6 7 b m p C X J U h l P B x u V O p l m K d I h 9 1 r Z U Y s x 0 k E / v H Z N j q / R I l C h b 0 p C p + n s i x 1 j r U R z a z h j N Q M 9 7 E / E / r 5 2 Z 6 C L I u U w z w y S d L Y o y Q U x C J s + T H l e M G j G y B K n i 9 l Z C B 6 i Q G h t R 2 Y b g z b + 8 S P z T 2 m X N v T 2 r 1 q + K N E p w C E d w A h 6 c Q x 1 u o A E + U B D w D K / w 5 j w 6 L 8 6 7 8 z F r X X K K m Q P 4 A + f z B 3 a P j 8 g = &lt; / l a t e x i t &gt; ↵ k &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " w A 5 q + P m Z 2 4 s v y 4 i v / W / 0 Q I D y / 4 A = " &gt; A A A B 7 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E U G 9 F L x 4 r G F t o Q 5 l s N + 3 S z S b u b o Q S + i e 8 e F D x 6 u / x 5 r 9 x 2 + a g r Q 8 G H u / N M D M v T A X X x n W / n d L K 6 t r 6 R n m z s r W 9 s 7 t X 3 T 9 4 0 E m m K P N p I h L V D l E z w S X z D T e C t V P F M A 4 F a 4 W j m 6 n f e m J K 8 0 T e m 3 H K g h g H k k e c o r F S u 4 s i H W J v 1 K v W 3 L o 7 A 1 k m X k F q U K D Z q 3 5 1 + w n N Y i Y N F a h 1 x 3 N T E + S o D K e C T S r d T L M U 6 Q g H r G O p x J j p I J / d O y E n V u m T K F G 2 p C E z 9 f d E j r H W 4 z i 0 n T G a o V 7 0 p u J / X i c z 0 W W Q c 5 l m h k k 6 X x R l g p i E T J 8 n f a 4 Y N W J s C V L F 7 a 2 E D l E h N T a i i g 3 B W 3 x 5 m f h n 9 a u 6 e 3 d e a 1 w X a Z T h C I 7 h F D y 4 g A b c Q h N 8 o C D g G V 7 h z X l 0 X p x 3 5 2 P e W n K K m U P 4 A + f z B 3 g S j 8 k = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " w A 5 q + P m Z 2 4 s v y 4 i v / W / 0 Q I D y / 4 A = " &gt; A A A B 7 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E U G 9 F L x 4 r G F t o Q 5 l s N + 3 S z S b u b o Q S + i e 8 e F D x 6 u / x 5 r 9 x 2 + a g r Q 8 G H u / N M D M v T A X X x n W / n d L K 6 t r 6 R n m z s r W 9 s 7 t X 3 T 9 4 0 E m m K P N p I h L V D l E z w S X z D T e C t V P F M A 4 F a 4 W j m 6 n f e m J K 8 0 T e m 3 H K g h g H k k e c o r F S u 4 s i H W J v 1 K v W 3 L o 7 A 1 k m X k F q U K D Z q 3 5 1 + w n N Y i Y N F a h 1 x 3 N T E + S o D K e C T S r d T L M U 6 Q g H r G O p x J j p I J / d O y E n V u m T K F G 2 p C E z 9 f d E j r H W 4 z i 0 n T G a o V 7 0 p u J / X i c z 0 W W Q c 5 l m h k k 6 X x R l g p i E T J 8 n f a 4 Y N W J s C V L F 7 a 2 E D l E h N T a i i g 3 B W 3 x 5 m f h n 9 a u 6 e 3 d e a 1 w X a Z T h C I 7 h F D y 4 g A b c Q h N 8 o C D g G V 7 h z X l 0 X p x 3 5 2 P e W n K K m U P 4 A + f z B 3 g S j 8 k = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " w A 5 q + P m Z 2 4 s v y 4 i v / W / 0 Q I D y / 4 A = " &gt; A A A B 7 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E U G 9 F L x 4 r G F t o Q 5 l s N + 3 S z S b u b o Q S + i e 8 e F D x 6 u / x 5 r 9 x 2 + a g r Q 8 G H u / N M D M v T A X X x n W / n d L K 6 t r 6 R n m z s r W 9 s 7 t X 3 T 9 4 0 E m m K P N p I h L V D l E z w S X z D T e C t V P F M A 4 F a 4 W j m 6 n f e m J K 8 0 T e m 3 H K g h g H k k e c o r F S u 4 s i H W J v 1 K v W 3 L o 7 A 1 k m X k F q U K D Z q 3 5 1 + w n N Y i Y N F a h 1 x 3 N T E + S o D K e C T S r d T L M U 6 Q g H r G O p x J j p I J / d O y E n V u m T K F G 2 p C E z 9 f d E j r H W 4 z i 0 n T G a o V 7 0 p u J / X i c z 0 W W Q c 5 l m h k k 6 X x R l g p i E T J 8 n f a 4 Y N W J s C V L F 7 a 2 E D l E h N T a i i g 3 B W 3 x 5 m f h n 9 a u 6 e 3 d e a 1 w X a Z T h C I 7 h F D y 4 g A b c Q h N 8 o C D g G V 7 h z X l 0 X p x 3 5 2 P e W n K K m U P 4 A + f z B 3 g S j 8 k = &lt; / l a t e x i t &gt; t e x i t s h a 1 _ b a s e 6 4 = " f F T R f b x r R i Y Y v C 4 t / y 6 z S B s 3 a u k = " &gt; A A A B 7 n i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K o k I 6 q 3 o x W M F Y w t t K J P t p l 2 7 2 c T d j V B C / 4 Q X D y p e / T 3 e / D d u 2 x y 0 9 c H A 4 7 0 Z Z u a F q e D a u O 6 3 s 7 S 8 s r q 2 X t o o b 2 5 t 7 + x W 9 v b v d Z I p y n y a i E S 1 Q t R M c M l 8 w 4 1 g r V Q x j E P B m u H w e u I 3 n 5 j S P J F 3 Z p S y I M a + 5 B G n a K z U 6 q B I B 9 h 9 6 F a q b s 2 d g i w S r y B V K N D o V r 4 6 v Y R m M Z O G C t S 6 7 b m p C X J U h l P B x u V O p l m K d I h 9 1 r Z U Y s x 0 k E / v H Z N j q / R I l C h b 0 p C p + n s i x 1 j r U R z a z h j N Q M 9 7 E / E / r 5 2 Z 6 C L I u U w z w y S d L Y o y Q U x C J s + T H l e M G j G y B K n i 9 l Z C B 6 i Q G h t R 2 Y b g z b + 8 S P z T 2 m X N v T 2 r 1 q + K N E p w C E d w A h 6 c Q x 1 u o A E + U B D w D K / w 5 j w 6 L 8 6 7 8 z F r X X K K m Q P 4 A + f z B 3 a P j 8 g = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " f F T R f b x r R i Y Y v C 4 t / y 6 z S B s 3 a u k = " &gt; A A A B 7 n i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K o k I 6 q 3 o x W M F Y w t t K J P t p l 2 7 2 c T d j V B C / 4 Q X D y p e / T 3 e / D d u 2 x y 0 9 c H A 4 7 0 Z Z u a F q e D a u O 6 3 s 7 S 8 s r q 2 X t o o b 2 5 t 7 + x W 9 v b v d Z I p y n y a i E S 1 Q t R M c M l 8 w 4 1 g r V Q x j E P B m u H w e u I 3 n 5 j S P J F 3 Z p S y I M a + 5 B G n a K z U 6 q B I B 9 h 9 6 F a q b s 2 d g i w S r y B V K N D o V r 4 6 v Y R m M Z O G C t S 6 7 b m p C X J U h l P B x u V O p l m K d I h 9 1 r Z U Y s x 0 k E / v H Z N j q / R I l C h b 0 p C p + n s i x 1 j r U R z a z h j N Q M 9 7 E / E / r 5 2 Z 6 C L I u U w z w y S d L Y o y Q U x C J s + T H l e M G j G y B K n i 9 l Z C B 6 i Q G h t R 2 Y b g z b + 8 S P z T 2 m X N v T 2 r 1 q + K N E p w C E d w A h 6 c Q x 1 u o A E + U B D w D K / w 5 j w 6 L 8 6 7 8 z F r X X K K m Q P 4 A + f z B 3 a P j 8 g = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " f F T R f b x r R i Y Y v C 4 t / y 6 z S B s 3 a u k = " &gt; A A A B 7 n i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K o k I 6 q 3 o x W M F Y w t t K J P t p l 2 7 2 c T d j V B C / 4 Q X D y p e / T 3 e / D d u 2 x y 0 9 c H A 4 7 0 Z Z u a F q e D a u O 6 3 s 7 S 8 s r q 2 X t o o b 2 5 t 7 + x W 9 v b v d Z I p y n y a i E S 1 Q t R M c M l 8 w 4 1 g r V Q x j E P B m u H w e u I 3 n 5 j S P J F 3 Z p S y I M a + 5 B G n a K z U 6 q B I B 9 h 9 6 F a q b s 2 d g i w S r y B V K N D o V r 4 6 v Y R m M Z O G C t S 6 7 b m p C X J U h l P B x u V O p l m K d I h 9 1 r Z U Y s x 0 k E / v H Z N j q / R I l C h b 0 p C p + n s i x 1 j r U R z a z h j N Q M 9 7 E / E / r 5 2 Z 6 C L I u U w z w y S d L Y o y Q U x C J s + T H l e M G j G y B K n i 9 l Z C B 6 i Q G h t R 2 Y b g z b + 8 S P z T 2 m X N v T 2 r 1 q + K N E p w C E d w A h 6 c Q x 1 u o A E + U B D w D K / w 5 j w 6 L 8 6 7 8 z F r X X K K m Q P 4 A + f z B 3 a P j 8 g = &lt; / l a t e x i t &gt; ↵ j &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " f F T R f b x r R i Y Y v C 4 t / y 6 z S B s 3 a u k = " &gt; A A A B 7 n i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K o k I 6 q 3 o x W M F Y w t t K J P t p l 2 7 2 c T d j V B C / 4 Q X D y p e / T 3 e / D d u 2 x y 0 9 c H A 4 7 0 Z Z u a F q e D a u O 6 3 s 7 S 8 s r q 2 X t o o b 2 5 t 7 + x W 9 v b v d Z I p y n y a i E S 1 Q t R M c M l 8 w 4 1 g r V Q x j E P B m u H w e u I 3 n 5 j S P J F 3 Z p S y I M a + 5 B G n a K z U 6 q B I B 9 h 9 6 F a q b s 2 d g i w S r y B V K N D o V r 4 6 v Y R m M Z O G C t S 6 7 b m p C X J U h l P B x u V O p l m K d I h 9 1 r Z U Y s x 0 k E / v H Z N j q / R I l C h b 0 p C p + n s i x 1 j r U R z a z h j N Q M 9 7 E / E / r 5 2 Z 6 C L I u U w z w y S d L Y o y Q U x C J s + T H l e M G j G y B K n i 9 l Z C B 6 i Q G h t R 2 Y b g z b + 8 S P z T 2 m X N v T 2 r 1 q + K N E p w C E d w A h 6 c Q x 1 u o A E + U B D w D K / w 5 j w 6 L 8 6 7 8 z F r X X K K m Q P 4 A + f z B 3 a P j 8 g = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " f F T R f b x r R i Y Y v C 4 t / y 6 z S B s 3 a u k = " &gt; A A A B 7 n i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K o k I 6 q 3 o x W M F Y w t t K J P t p l 2 7 2 c T d j V B C / 4 Q X D y p e / T 3 e / D d u 2 x y 0 9 c H A 4 7 0 Z Z u a F q e D a u O 6 3 s 7 S 8 s r q 2 X t o o b 2 5 t 7 + x W 9 v b v d Z I p y n y a i E S 1 Q t R M c M l 8 w 4 1 g r V Q x j E P B m u H w e u I 3 n 5 j S P J F 3 Z p S y I M a + 5 B G n a K z U 6 q B I B 9 h 9 6 F a q b s 2 d g i w S r y B V K N D o V r 4 6 v Y R m M Z O G C t S 6 7 b m p C X J U h l P B x u V O p l m K d I h 9 1 r Z U Y s x 0 k E / v H Z N j q / R I l C h b 0 p C p + n s i x 1 j r U R z a z h j N Q M 9 7 E / E / r 5 2 Z 6 C L I u U w z w y S d L Y o y Q U x C J s + T H l e M G j G y B K n i 9 l Z C B 6 i Q G h t R 2 Y b g z b + 8 S P z T 2 m X N v T 2 r 1 q + K N E p w C E d w A h 6 c Q x 1 u o A E + U B D w D K / w 5 j w 6 L 8 6 7 8 z F r X X K K m Q P 4 A + f z B 3 a P j 8 g = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " f F T R f b x r R i Y Y v C 4 t / y 6 z S B s 3 a u k = " &gt; A A A B 7 n i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K o k I 6 q 3 o x W M F Y w t t K J P t p l 2 7 2 c T d j V B C / 4 Q X D y p e / T 3 e / D d u 2 x y 0 9 c H A 4 7 0 Z Z u a F q e D a u O 6 3 s 7 S 8 s r q 2 X t o o b 2 5 t 7 + x W 9 v b v d Z I p y n y a i E S 1 Q t R M c M l 8 w 4 1 g r V Q x j E P B m u H w e u I 3 n 5 j S P J F 3 Z p S y I M a + 5 B G n a K z U 6 q B I B 9 h 9 6 F a q b s 2 d g i w S r y B V K N D o V r 4 6 v Y R m M Z O G C t S 6 7 b m p C X J U h l P B x u V O p l m K d I h 9 1 r Z U Y s x 0 k E / v H Z N j q / R I l C h b 0 p C p + n s i x 1 j r U R z a z h j N Q M 9 7 E / E / r 5 2 Z 6 C L I u U w z w y S d L Y o y Q U x C J s + T H l e M G j G y B K n i 9 l Z C B 6 i Q G h t R 2 Y b g z b + 8 S P z T 2 m X N v T 2 r 1 q + K N E p w C E d w A h 6 c Q x 1 u o A E + U B D w D K / w 5 j w 6 L 8 6 7 8 z F r X X K K m Q P 4 A + f z B 3 a P j 8 g = &lt; / l a t e x i t &gt; ↵ k &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " w A 5 q + P m Z 2 4 s v y 4 i v / W / 0 Q I D y / 4 A = " &gt; A A A B 7 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E U G 9 F L x 4 r G F t o Q 5 l s N + 3 S z S b u b o Q S + i e 8 e F D x 6 u / x 5 r 9 x 2 + a g r Q 8 G H u / N M D M v T A X X x n W / n d L K 6 t r 6 R n m z s r W 9 s 7 t X 3 T 9 4 0 E m m K P N p I h L V D l E z w S X z D T e C t V P F M A 4 F a 4 W j m 6 n f e m J K 8 0 T e m 3 H K g h g H k k e c o r F S u 4 s i H W J v 1 K v W 3 L o 7 A 1 k m X k F q U K D Z q 3 5 1 + w n N Y i Y N F a h 1 x 3 N T E + S o D K e C T S r d T L M U 6 Q g H r G O p x J j p I J / d O y E n V u m T K F G 2 p C E z 9 f d E j r H W 4 z i 0 n T G a o V 7 0 p u J / X i c z 0 W W Q c 5 l m h k k 6 X x R l g p i E T J 8 n f a 4 Y N W J s C V L F 7 a 2 E D l E h N T a i i g 3 B W 3 x 5 m f h n 9 a u 6 e 3 d e a 1 w X a Z T h C I 7 h F D y 4 g A b c Q h N 8 o C D g G V 7 h z X l 0 X p x 3 5 2 P e W n K K m U P 4 A + f z B 3 g S j 8 k = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " w A 5 q + P m Z 2 4 s v y 4 i v / W / 0 Q I D y / 4 A = " &gt; A A A B 7 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E U G 9 F L x 4 r G F t o Q 5 l s N + 3 S z S b u b o Q S + i e 8 e F D x 6 u / x 5 r 9 x 2 + a g r Q 8 G H u / N M D M v T A X X x n W / n d L K 6 t r 6 R n m z s r W 9 s 7 t X 3 T 9 4 0 E m m K P N p I h L V D l E z w S X z D T e C t V P F M A 4 F a 4 W j m 6 n f e m J K 8 0 T e m 3 H K g h g H k k e c o r F S u 4 s i H W J v 1 K v W 3 L o 7 A 1 k m X k F q U K D Z q 3 5 1 + w n N Y i Y N F a h 1 x 3 N T E + S o D K e C T S r d T L M U 6 Q g H r G O p x J j p I J / d O y E n V u m T K F G 2 p C E z 9 f d E j r H W 4 z i 0 n T G a o V 7 0 p u J / X i c z 0 W W Q c 5 l m h k k 6 X x R l g p i E T J 8 n f a 4 Y N W J s C V L F 7 a 2 E D l E h N T a i i g 3 B W 3 x 5 m f h n 9 a u 6 e 3 d e a 1 w X a Z T h C I 7 h F D y 4 g A b c Q h N 8 o C D g G V 7 h z X l 0 X p x 3 5 2 P e W n K K m U P 4 A + f z B 3 g S j 8 k = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " w A 5 q + P m Z 2 4 s v y 4 i v / W / 0 Q I D y / 4 A = " &gt; A A A B 7 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E U G 9 F L x 4 r G F t o Q 5 l s N + 3 S z S b u b o Q S + i e 8 e F D x 6 u / x 5 r 9 x 2 + a g r Q 8 G H u / N M D M v T A X X x n W / n d L K 6 t r 6 R n m z s r W 9 s 7 t X 3 T 9 4 0 E m m K P N p I h L V D l E z w S X z D T e C t V P F M A 4 F a 4 W j m 6 n f e m J K 8 0 T e m 3 H K g h g H k k e c o r F S u 4 s i H W J v 1 K v W 3 L o 7 A 1 k m X k F q U K D Z q 3 5 1 + w n N Y i Y N F a h 1 x 3 N T E + S o D K e C T S r d T L M U 6 Q g H r G O p x J j p I J / d O y E n V u m T K F G 2 p C E z 9 f d E j r H W 4 z i 0 n T G a o V 7 0 p u J / X i c z 0 W W Q c 5 l m h k k 6 X x R l g p i E T J 8 n f a 4 Y N W J s C V L F 7 a 2 E D l E h N T a i i g 3 B W 3 x 5 m f h n 9 a u 6 e 3 d e a 1 w X a Z T h C I 7 h F D y 4 g A b c Q h N 8 o C D g G V 7 h z X l 0 X p x 3 5 2 P e W n K K m U P 4 A + f z B 3 g S j 8 k = &lt; / l a t e x i t &gt; h x &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " e 6 q X S Q N v t Y Y I Q U 2 L 7 j V 9 c x k 6 E g E = " &gt; A A A C A X i c b V B N S 8 N A E N 3 4 W e t X 1 J N 4 C R b B U 0 l E U G 9 F L x 4 r G F t o Y t l s N 8 3 S z S b s T q Q l B C / + F S 8 e V L z 6 L 7 z 5 b 9 y 0 P W j r g 4 H H e z P M z A t S z h T Y 9 r e x s L i 0 v L J a W a u u b 2 x u b Z s 7 u 3 c q y S S h L k l 4 I t s B V p Q z Q V 1 g w G k 7 l R T H A a e t Y H B V + q 0 H K h V L x C 2 M U u r H u C 9 Y y A g G L X X N f S / C k H s x h i g I 8 6 g o 7 j 2 g Q 8 i H R d e s 2 X V 7 D G u e O F N S Q 1 M 0 u + a X 1 0 t I F l M B h G O l O o 6 d g p 9 j C Y x w W l S 9 T N E U k w H u 0 4 6 m A s d U + f n 4 h c I 6 0 k r P C h O p S 4 A 1 V n 9 P 5 D h W a h Q H u r O 8 V c 1 6 p f i f 1 8 k g P P d z J t I M q C C T R W H G L U i s M g + r x y Q l w E e a Y C K Z v t U i E Z a Y g E 6 t q k N w Z l + e J + 5 J / a J u 3 5 z W G p f T N C r o A B 2 i Y + S g M 9 R A 1 6 i J X E T Q I 3 p G r + j N e D J e j H f j Y 9 K 6 Y E x n 9 t A f G J 8 / M e i Y J g = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " e 6 q X S Q N v t Y Y I Q U 2 L 7 j V 9 c x k 6 E g E = " &gt; A A A C A X i c b V B N S 8 N A E N 3 4 W e t X 1 J N 4 C R b B U 0 l E U G 9 F L x 4 r G F t o Y t l s N 8 3 S z S b s T q Q l B C / + F S 8 e V L z 6 L 7 z 5 b 9 y 0 P W j r g 4 H H e z P M z A t S z h T Y 9 r e x s L i 0 v L J a W a u u b 2 x u b Z s 7 u 3 c q y S S h L k l 4 I t s B V p Q z Q V 1 g w G k 7 l R T H A a e t Y H B V + q 0 H K h V L x C 2 M U u r H u C 9 Y y A g G L X X N f S / C k H s x h i g I 8 6 g o 7 j 2 g Q 8 i H R d e s 2 X V 7 D G u e O F N S Q 1 M 0 u + a X 1 0 t I F l M B h G O l O o 6 d g p 9 j C Y x w W l S 9 T N E U k w H u 0 4 6 m A s d U + f n 4 h c I 6 0 k r P C h O p S 4 A 1 V n 9 P 5 D h W a h Q H u r O 8 V c 1 6 p f i f 1 8 k g P P d z J t I M q C C T R W H G L U i s M g + r x y Q l w E e a Y C K Z v t U i E Z a Y g E 6 t q k N w Z l + e J + 5 J / a J u 3 5 z W G p f T N C r o A B 2 i Y + S g M 9 R A 1 6 i J X E T Q I 3 p G r + j N e D J e j H f j Y 9 K 6 Y E x n 9 t A f G J 8 / M e i Y J g = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " e 6 q X S Q N v t Y Y I Q U 2 L 7 j V 9 c x k 6 E g E = " &gt; A A A C A X i c b V B N S 8 N A E N 3 4 W e t X 1 J N 4 C R b B U 0 l E U G 9 F L x 4 r G F t o Y t l s N 8 3 S z S b s T q Q l B C / + F S 8 e V L z 6 L 7 z 5 b 9 y 0 P W j r g 4 H H e z P M z A t S z h T Y 9 r e x s L i 0 v L J a W a u u b 2 x u b Z s 7 u 3 c q y S S h L k l 4 I t s B V p Q z Q V 1 g w G k 7 l R T H A a e t Y H B V + q 0 H K h V L x C 2 M U u r H u C 9 Y y A g G L X X N f S / C k H s x h i g I 8 6 g o 7 j 2 g Q 8 i H R d e s 2 X V 7 D G u e O F N S Q 1 M 0 u + a X 1 0 t I F l M B h G O l O o 6 d g p 9 j C Y x w W l S 9 T N E U k w H u 0 4 6 m A s d U + f n 4 h c I 6 0 k r P C h O p S 4 A 1 V n 9 P 5 D h W a h Q H u r O 8 V c 1 6 p f i f 1 8 k g P P d z J t I M q C C T R W H G L U i s M g + r x y Q l w E e a Y C K Z v t U i E Z a Y g E 6 t q k N w Z l + e J + 5 J / a J u 3 5 z W G p f T N C r o A B 2 i Y + S g M 9 R A 1 6 i J X E T Q I 3 p G r + j N e D J e j H f j Y 9 K 6 Y E x n 9 t A f G J 8 / M e i Y J g = = &lt; / l a t e x i t &gt;ĥ x &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " e 6 q X S Q N v t Y Y I Q U 2 L 7 j V 9 c x k 6 E g E = " &gt; A A A C A X i c b V B N S 8 N A E N 3 4 W e t X 1 J N 4 C R b B U 0 l E U G 9 F L x 4 r G F t o Y t l s N 8 3 S z S b s T q Q l B C / + F S 8 e V L z 6 L 7 z 5 b 9 y 0 P W j r g 4 H H e z P M z A t S z h T Y 9 r e x s L i 0 v L J a W a u u b 2 x u b Z s 7 u 3 c q y S S h L k l 4 I t s B V p Q z Q V 1 g w G k 7 l R T H A a e t Y H B V + q 0 H K h V L x C 2 M U u r H u C 9 Y y A g G L X X N f S / C k H s x h i g I 8 6 g o 7 j 2 g Q 8 i H R d e s 2 X V 7 D G u e O F N S Q 1 M 0 u + a X 1 0 t I F l M B h G O l O o 6 d g p 9 j C Y x w W l S 9 T N E U k w H u 0 4 6 m A s d U + f n 4 h c I 6 0 k r P C h O p S 4 A 1 V n 9 P 5 D h W a h Q H u r O 8 V c 1 6 p f i f 1 8 k g P P d z J t I M q C C T R W H G L U i s M g + r x y Q l w E e a Y C K Z v t U i E Z a Y g E 6 t q k N w Z l + e J + 5 J / a J u 3 5 z W G p f T N C r o A B 2 i Y + S g M 9 R A 1 6 i J X E T Q I 3 p G r + j N e D J e j H f j Y 9 K 6 Y E x n 9 t A f G J 8 / M e i Y J g = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " e 6 q X S Q N v t Y Y I Q U 2 L 7 j V 9 c x k 6 E g E = " &gt; A A A C A X i c b V B N S 8 N A E N 3 4 W e t X 1 J N 4 C R b B U 0 l E U G 9 F L x 4 r G F t o Y t l s N 8 3 S z S b s T q Q l B C / + F S 8 e V L z 6 L 7 z 5 b 9 y 0 P W j r g 4 H H e z P M z A t S z h T Y 9 r e x s L i 0 v L J a W a u u b 2 x u b Z s 7 u 3 c q y S S h L k l 4 I t s B V p Q z Q V 1 g w G k 7 l R T H A a e t Y H B V + q 0 H K h V L x C 2 M U u r H u C 9 Y y A g G L X X N f S / C k H s x h i g I 8 6 g o 7 j 2 g Q 8 i H R d e s 2 X V 7 D G u e O F N S Q 1 M 0 u + a X 1 0 t I F l M B h G O l O o 6 d g p 9 j C Y x w W l S 9 T N E U k w H u 0 4 6 m A s d U + f n 4 h c I 6 0 k r P C h O p S 4 A 1 V n 9 P 5 D h W a h Q H u r O 8 V c 1 6 p f i f 1 8 k g P P d z J t I M q C C T R W H G L U i s M g + r x y Q l w E e a Y C K Z v t U i E Z a Y g E 6 t q k N w Z l + e J + 5 J / a J u 3 5 z W G p f T N C r o A B 2 i Y + S g M 9 R A 1 6 i J X E T Q I 3 p G r + j N e D J e j H f j Y 9 K 6 Y E x n 9 t A f G J 8 / M e i Y J g = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " e 6 q X S Q N v t Y Y I Q U 2 L 7 j V 9 c x k 6 E g E = " &gt; A A A C A X i c b V B N S 8 N A E N 3 4 W e t X 1 J N 4 C R b B U 0 l E U G 9 F L x 4 r G F t o Y t l s N 8 3 S z S b s T q Q l B C / + F S 8 e V L z 6 L 7 z 5 b 9 y 0 P W j r g 4 H H e z P M z A t S z h T Y 9 r e x s L i 0 v L J a W a u u b 2 x u b Z s 7 u 3 c q y S S h L k l 4 I t s B V p Q z Q V 1 g w G k 7 l R T H A a e t Y H B V + q 0 H K h V L x C 2 M U u r H u C 9 Y y A g G L X X N f S / C k H s x h i g I 8 6 g o 7 j 2 g Q 8 i H R d e s 2 X V 7 D G u e O F N S Q 1 M 0 u + a X 1 0 t I F l M B h G O l O o 6 d g p 9 j C Y x w W l S 9 T N E U k w H u 0 4 6 m A s d U + f n 4 h c I 6 0 k r P C h O p S 4 A 1 V n 9 P 5 D h W a h Q H u r O 8 V c 1 6 p f i f 1 8 k g P P d z J t I M q C C T R W H G L U i s M g + r x y Q l w E e a Y C K Z v t U i E Z a Y g E 6 t q k N w Z l + e J + 5 J / a J u 3 5 z W G p f T N C r o A B 2 i Y + S g M 9 R A 1 6 i J X E T Q I 3 p G r + j N e D J e j H f j Y 9 K 6 Y E x n 9 t A f G J 8 / M e i Y J g = = &lt; / l a t e x i t &gt; h y &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " G 5 n / 1 F g h u 5 2 A x 5 D m E D M 5 l T 1 g J P I = " &gt; A A A B + 3 i c b V B N S 8 N A F N z 4 W e t X t E c v w S J 4 K o k I 6 q 3 o x W M F Y w t N L J v t p l 2 6 2 Y T d F z G E + F e 8 e F D x 6 h / x 5 r 9 x 0 + a g r Q M L w 8 x 7 v N k J E s 4 U 2 P a 3 s b S 8 s r q 2 X t u o b 2 5 t 7 + y a e / t 3 K k 4 l o S 6 J e S x 7 A V a U M 0 F d Y M B p L 5 E U R w G n 3 W B y V f r d B y o V i 8 U t Z A n 1 I z w S L G Q E g 5 Y G Z s O L M I y D M B 8 X 9 x 7 Q R 8 i z Y m A 2 7 Z Y 9 h b V I n I o 0 U Y X O w P z y h j F J I y q A c K x U 3 7 E T 8 H M s g R F O i 7 q X K p p g M s E j 2 t d U 4 I g q P 5 + G L 6 w j r Q y t M J b 6 C b C m 6 u + N H E d K Z V G g J 8 u o a t 4 r x f + 8 f g r h u Z 8 z k a R A B Z k d C l N u Q W y V T V h D J i k B n m m C i W Q 6 q 0 X G W G I C u q + 6 L s G Z / / I i c U 9 a F y 3 7 5 r T Z v q z a q K E D d I i O k Y P O U B t d o w 5 y E U E Z e k a v 6 M 1 4 M l 6 M d + N j N r p k V D s N 9 A f G 5 w 8 8 6 5 V a &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " G 5 n / 1 F g h u 5 2 A x 5 D m E D M 5 l T 1 g J P I = " &gt; A A A B + 3 i c b V B N S 8 N A F N z 4 W e t X t E c v w S J 4 K o k I 6 q 3 o x W M F Y w t N L J v t p l 2 6 2 Y T d F z G E + F e 8 e F D x 6 h / x 5 r 9 x 0 + a g r Q M L w 8 x 7 v N k J E s 4 U 2 P a 3 s b S 8 s r q 2 X t u o b 2 5 t 7 + y a e / t 3 K k 4 l o S 6 J e S x 7 A V a U M 0 F d Y M B p L 5 E U R w G n 3 W B y V f r d B y o V i 8 U t Z A n 1 I z w S L G Q E g 5 Y G Z s O L M I y D M B 8 X 9 x 7 Q R 8 i z Y m A 2 7 Z Y 9 h b V I n I o 0 U Y X O w P z y h j F J I y q A c K x U 3 7 E T 8 H M s g R F O i 7 q X K p p g M s E j 2 t d U 4 I g q P 5 + G L 6 w j r Q y t M J b 6 C b C m 6 u + N H E d K Z V G g J 8 u o a t 4 r x f + 8 f g r h u Z 8 z k a R A B Z k d C l N u Q W y V T V h D J i k B n m m C i W Q 6 q 0 X G W G I C u q + 6 L s G Z / / I i c U 9 a F y 3 7 5 r T Z v q z a q K E D d I i O k Y P O U B t d o w 5 y E U E Z e k a v 6 M 1 4 M l 6 M d + N j N r p k V D s N 9 A f G 5 w 8 8 6 5 V a &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " G 5 n / 1 F g h u 5 2 A x 5 D m E D M 5 l T 1 g J P I = " &gt; A A A B + 3 i c b V B N S 8 N A F N z 4 W e t X t E c v w S J 4 K o k I 6 q 3 o x W M F Y w t N L J v t p l 2 6 2 Y T d F z G E + F e 8 e F D x 6 h / x 5 r 9 x 0 + a g r Q M L w 8 x 7 v N k J E s 4 U 2 P a 3 s b S 8 s r q 2 X t u o b 2 5 t 7 + y a e / t 3 K k 4 l o S 6 J e S x 7 A V a U M 0 F d Y M B p L 5 E U R w G n 3 W B y V f r d B y o V i 8 U t Z A n 1 I z w S L G Q E g 5 Y G Z s O L M I y D M B 8 X 9 x 7 Q R 8 i z Y m A 2 7 Z Y 9 h b V I n I o 0 U Y X O w P z y h j F J I y q A c K x U 3 7 E T 8 H M s g R F O i 7 q X K p p g M s E j 2 t d U 4 I g q P 5 + G L 6 w j r Q y t M J b 6 C b C m 6 u + N H E d K Z V G g J 8 u o a t 4 r x f + 8 f g r h u Z 8 z k a R A B Z k d C l N u Q W y V T V h D J i k B n m m C i W Q 6 q 0 X G W G I C u q + 6 L s G Z / / I i c U 9 a F y 3 7 5 r T Z v q z a q K E D d I i O k Y P O U B t d o w 5 y E U E Z e k a v 6 M 1 4 M l 6 M d + N j N r p k V D s N 9 A f G 5 w 8 8 6 5 V a &lt; / l a t e x i t &gt; h y &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " G 5 n / 1 F g h u 5 2 A x 5 D m E D M 5 l T 1 g J P I = " &gt; A A A B + 3 i c b V B N S 8 N A F N z 4 W e t X t E c v w S J 4 K o k I 6 q 3 o x W M F Y w t N L J v t p l 2 6 2 Y T d F z G E + F e 8 e F D x 6 h / x 5 r 9 x 0 + a g r Q M L w 8 x 7 v N k J E s 4 U 2 P a 3 s b S 8 s r q 2 X t u o b 2 5 t 7 + y a e / t 3 K k 4 l o S 6 J e S x 7 A V a U M 0 F d Y M B p L 5 E U R w G n 3 W B y V f r d B y o V i 8 U t Z A n 1 I z w S L G Q E g 5 Y G Z s O L M I y D M B 8 X 9 x 7 Q R 8 i z Y m A 2 7 Z Y 9 h b V I n I o 0 U Y X O w P z y h j F J I y q A c K x U 3 7 E T 8 H M s g R F O i 7 q X K p p g M s E j 2 t d U 4 I g q P 5 + G L 6 w j r Q y t M J b 6 C b C m 6 u + N H E d K Z V G g J 8 u o a t 4 r x f + 8 f g r h u Z 8 z k a R A B Z k d C l N u Q W y V T V h D J i k B n m m C i W Q 6 q 0 X G W G I C u q + 6 L s G Z / / I i c U 9 a F y 3 7 5 r T Z v q z a q K E D d I i O k Y P O U B t d o w 5 y E U E Z e k a v 6 M 1 4 M l 6 M d + N j N r p k V D s N 9 A f G 5 w 8 8 6 5 V a &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " G 5 n / 1 F g h u 5 2 A x 5 D m E D M 5 l T 1 g J P I = " &gt; A A A B + 3 i c b V B N S 8 N A F N z 4 W e t X t E c v w S J 4 K o k I 6 q 3 o x W M F Y w t N L J v t p l 2 6 2 Y T d F z G E + F e 8 e F D x 6 h / x 5 r 9 x 0 + a g r Q M L w 8 x 7 v N k J E s 4 U 2 P a 3 s b S 8 s r q 2 X t u o b 2 5 t 7 + y a e / t 3 K k 4 l o S 6 J e S x 7 A V a U M 0 F d Y M B p L 5 E U R w G n 3 W B y V f r d B y o V i 8 U t Z A n 1 I z w S L G Q E g 5 Y G Z s O L M I y D M B 8 X 9 x 7 Q R 8 i z Y m A 2 7 Z Y 9 h b V I n I o 0 U Y X O w P z y h j F J I y q A c K x U 3 7 E T 8 H M s g R F O i 7 q X K p p g M s E j 2 t d U 4 I g q P 5 + G L 6 w j r Q y t M J b 6 C b C m 6 u + N H E d K Z V G g J 8 u o a t 4 r x f + 8 f g r h u Z 8 z k a R A B Z k d C l N u Q W y V T V h D J i k B n m m C i W Q 6 q 0 X G W G I C u q + 6 L s G Z / / I i c U 9 a F y 3 7 5 r T Z v q z a q K E D d I i O k Y P O U B t d o w 5 y E U E Z e k a v 6 M 1 4 M l 6 M d + N j N r p k V D s N 9 A f G 5 w 8 8 6 5 V a &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " G 5 n / 1 F g h u 5 2 A x 5 D m E D M 5 l T 1 g J P I = " &gt; A A A B + 3 i c b V B N S 8 N A F N z 4 W e t X t E c v w S J 4 K o k I 6 q 3 o x W M F Y w t N L J v t p l 2 6 2 Y T d F z G E + F e 8 e F D x 6 h / x 5 r 9 x 0 + a g r Q M L w 8 x 7 v N k J E s 4 U 2 P a 3 s b S 8 s r q 2 X t u o b 2 5 t 7 + y a e / t 3 K k 4 l o S 6 J e S x 7 A V a U M 0 F d Y M B p L 5 E U R w G n 3 W B y V f r d B y o V i 8 U t Z A n 1 I z w S L G Q E g 5 Y G Z s O L M I y D M B 8 X 9 x 7 Q R 8 i z Y m A 2 7 Z Y 9 h b V I n I o 0 U Y X O w P z y h j F J I y q A c K x U 3 7 E T 8 H M s g R F O i 7 q X K p p g M s E j 2 t d U 4 I g q P 5 + G L 6 w j r Q y t M J b 6 C b C m 6 u + N H E d K Z V G g J 8 u o a t 4 r x f + 8 f g r h u Z 8 z k a R A B Z k d C l N u Q W y V T V h D J i k B n m m C i W Q 6 q 0 X G W G I C u q + 6 L s G Z / / I i c U 9 a F y 3 7 5 r T Z v q z a q K E D d I i O k Y P O U B t d o w 5 y E U E Z e k a v 6 M 1 4 M l 6 M d + N j N r p k V D s N 9 A f G 5 w 8 8 6 5 V a &lt; / l a t e x i t &gt;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>t e x i t s h a 1 _ b a s e 6 4 = " Y n t z H W V Y 8 z r I D Q / S i e J 4 X w 3 1 X i k = " &gt; A A A B + 3 i c b V B N S 8 N A F N z U r 1 q / o j 1 6 C R b B U 0 l E U G 9 F L x 4 r G F t o Y 9 l s N + 3 S z S b s v k h D i H / F i w c V r / 4 R b / 4 b N 2 0 O 2 j q w M M y 8 x 5 s d P + Z M g W 1 / G 5 W V 1 b X 1 j e p m b W t 7 Z 3 f P 3 D + 4 V 1 E i C X V J x C P Z 9 b G i n A n q A g N O u 7 G k O P Q 5 7 f i T 6 8 L v P F K p W C T u I I 2 p F + K R Y A E j G L Q 0 M O v 9 E M P Y D 7 J x / t A H O o V s m g / M h t 2 0 Z 7 C W i V O S B i r R H p h f / W F E k p A K I B w r 1 X P s G L w M S 2 C E 0 7 z W T x S N M Z n g E e 1 p K n B I l Z f N w u f W s V a G V h B J / Q R Y M / X 3 R o Z D p d L Q 1 5 N F V L X o F e J / X i + B 4 M L L m I g T o I L M D w U J t y C y i i a s I Z O U A E 8 1 w U Q y n d U i Y y w x A d 1 X T Z f g L H 5 5 m b i n z c u m f X v W a F 2 V b V T R I T p C J 8 h B 5 6 i F b l A b u Y i g F D 2 j V / R m P B k v x r v x M R + t G O V O H f 2 B 8 f k D O 2 e V W Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " Y n t z H W V Y 8 z r I D Q / S i e J 4 X w 3 1 X i k = " &gt; A A A B + 3 i c b V B N S 8 N A F N z U r 1 q / o j 1 6 C R b B U 0 l E U G 9 F L x 4 r G F t o Y 9 l s N + 3 S z S b s v k h D i H / F i w c V r / 4 R b / 4 b N 2 0 O 2 j q w M M y 8 x 5 s d P + Z M g W 1 / G 5 W V 1 b X 1 j e p m b W t 7 Z 3 f P 3 D + 4 V 1 E i C X V J x C P Z 9 b G i n A n q A g N O u 7 G k O P Q 5 7 f i T 6 8 L v P F K p W C T u I I 2 p F + K R Y A E j G L Q 0 M O v 9 E M P Y D 7 J x / t A H O o V s m g / M h t 2 0 Z 7 C W i V O S B i r R H p h f / W F E k p A K I B w r 1 X P s G L w M S 2 C E 0 7 z W T x S N M Z n g E e 1 p K n B I l Z f N w u f W s V a G V h B J / Q R Y M / X 3 R o Z D p d L Q 1 5 N F V L X o F e J / X i + B 4 M L L m I g T o I L M D w U J t y C y i i a s I Z O U A E 8 1 w U Q y n d U i Y y w x A d 1 X T Z f g L H 5 5 m b i n z c u m f X v W a F 2 V b V T R I T p C J 8 h B 5 6 i F b l A b u Y i g F D 2 j V / R m P B k v x r v x M R + t G O V O H f 2 B 8 f k D O 2 e V W Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " Y n t z H W V Y 8 z r I D Q / S i e J 4 X w 3 1 X i k = " &gt; A A A B + 3 i c b V B N S 8 N A F N z U r 1 q / o j 1 6 C R b B U 0 l E U G 9 F L x 4 r G F t o Y 9 l s N + 3 S z S b s v k h D i H / F i w c V r / 4 R b / 4 b N 2 0 O 2 j q w M M y 8 x 5 s d P + Z M g W 1 / G 5 W V 1 b X 1 j e p m b W t 7 Z 3 f P 3 D + 4 V 1 E i C X V J x C P Z 9 b G i n A n q A g N O u 7 G k O P Q 5 7 f i T 6 8 L v P F K p W C T u I I 2 p F + K R Y A E j G L Q 0 M O v 9 E M P Y D 7 J x / t A H O o V s m g / M h t 2 0 Z 7 CW i V O S B i r R H p h f / W F E k p A K I B w r 1 X P s G L w M S 2 C E 0 7 z W T x S N M Z n g E e 1 p K n B I l Z f N w u f W s V a G V h B J / Q R Y M / X 3 R o Z D p d L Q 1 5 N F V L X o F e J / X i + B 4 M L L m I g T o I L M D w U J t y C y i i a s I Z O U A E 8 1 w U Q y n d U i Y y w x A d 1 X T Z f g L H 5 5 m b i n z c u m f X v W a F 2 V b V T R I T p C J 8 h B 5 6 i F b l A b u Y i g F D 2 j V / R m P B k v x r v x M R + t G O V O H f 2 B 8 f k D O 2 e V W Q = = &lt; / l a t e x i t &gt; &lt; l at e x i t s h a 1 _ b a s e 6 4 = " C 3 9 O h B + I c z R c j L N I N X H 2 9 e 9 l t 8 M = " &gt; A A A B 2 H i c b Z D N S g M x F I X v 1 L 8 6 V q 1 r N 8 E i u C p T N + p O c O O y g m M L 7 V A y m T t t a C Y z J H e E M v Q F X L h R f D B 3 v o 3 p z 0 K t B w I f 5 y T k 3 h M X S l o K g i + v t r W 9 s 7 t X 3 / c P G v 7 h 0 X G z 8 W T z 0 g g M R a 5 y 0 4 + 5 R S U 1 h i R J Y b 8 w y L N Y Y S + e 3 i 3 y 3 j M a K 3 P 9 S L M C o 4 y P t U y l 4 O S s 7 q j Z C t r B U m w T O m t o w V q j 5 u c w y U W Z o S a h u L W D T l B Q V H F D U i i c + 8 P S Y s H F l I 9 x 4 F D z D G 1 U L c e c s 3 P n J C z N j T u a 2 N L 9 + a L i m b W z L H Y 3 M 0 4 T + z d b m P 9 l g 5 L S 6 6 i S u i g J t V h 9 l J a K U c 4 W O 7 N E G h S k Z g 6 4 M N L N y s S E G y 7 I N e O 7 D j p / N 9 6 E 8 L J 9 0 w 4 e A q j D K Z z B B X T g C m 7 h H r o Q g o A E X u D N m 3 i v 3 v u q q p q 3 7 u w E f s n 7 + A a p 5 I o M &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " g z C d q p s 4 E 2 G C n 6 b K 5 Z Z 1 J D r m X e c = " &gt; A A A B 8 H i c b V B N S 8 N A F H y p X 7 V W j X r 0 E i y C p 5 J 4 U W + C F 4 8 V j C 0 0 s W y 2 m 3 b p 5 o P d F 2 k I 8 a 9 4 8 a D i r / H m v 3 H T 9 q C t A w v D z H u 8 2 Q l S w R X a 9 r d R W 1 v f 2 N y q b z d 2 m r t 7 + + Z B 8 0 E l m a T M p Y l I Z C 8 g i g k e M x c 5 C t Z L J S N R I F g 3 m N x U f v e J S c W T + B 7 z l P k R G c U 8 5 J S g l g b m kR c R H A d h M S 4 f P W R T L K b l w G z Z b X s G a 5 U 4 C 9 K C B T o D 8 8 s b J j S L W I x U E K X 6 j p 2 i X x C J n A p W N r x M s Z T Q C R m x v q Y x i Z j y i 1 n 4 0 j r V y t A K E 6 l f j N Z M / b 1 R k E i p P A r 0 Z B V V L X u V + J / X z z C 8 9 A s e p x m y m M 4 P h Z m w M L G q J q w h l 4 y i y D U h V H K d 1 a J j I g l F 3 V d D l + A s f 3 m V u O f t q 7 Z 9 Z 0 M d j u E E z s C B C 7 i G W + i A C x R y e I E 3 e D e e j V f j Y 9 5 W z V j U d g h / Y H z + A M 5 T k / M = &lt; / l a t e x i t &gt; &lt; l at e x i t s h a 1 _ b a s e 6 4 = " g z C d q p s 4 E 2 G C n 6 b K 5 Z Z 1 J D r m X e c = " &gt; A A A B 8 H i c b V B N S 8 N A F H y p X 7 V W j X r 0 E i y C p 5 J 4 U W + C F 4 8 V j C 0 0 s W y 2 m 3 b p 5 o P d F 2 k I 8 a 9 4 8 a D i r / H m v 3 H T 9 q C t A w v D z H u 8 2 Q l S w R X a 9 r d R W 1 v f 2 N y q b z d 2 m r t 7 + + Z B 8 0 E l m a T M p Y l I Z C 8 g i g k e M x c 5 C t Z L J S N R I F g 3 m N x U f v e J S c W T + B 7 z l P k R G c U 8 5 J S g l g b m k R c R H A d h M S 4 f P W R T L K b l w G z Z b X s G a 5 U 4 C 9 K C B T o D 8 8 s b J j S L W I x U E K X 6 j p 2 i X x C J n A p W N r x M s Z T Q C R m x v q Y x i Z j y i 1 n 4 0 j r V y t A K E 6 l f j N Z M / b 1 R k E i p P A r 0 Z B V V L X u V + J / X z z C 8 9 A s e p x m y m M 4 P h Z m w M L G q J q w h l 4 y i y D U h V H K d 1 a J j I g l F 3 V d D l + A s f 3 m V u O f t q 7 Z 9 Z 0 M d j u E E z s C B C 7 i G W + i A C x R y e I E 3 e D e e j V f j Y 9 5 W z V j U d g h / Y H z + A M 5 T k / M = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " m 6 2 G 6 G S y p t 9 B N Z T 8 m z d 7 T a q 3 4 F 0 = " &gt; A A A B + 3 i c b V C 7 T s M w F H V 4 l v I K d G S x q J C Y q o Q F 2 C p Y G I t E a K U m V I 7 r t F a d h + w b 1 C g K v 8 L C A I i V H 2 H j b 3 D a D N B y J E t H 5 9 y r e 3 z 8 R H A F l v V t r K y u r W 9 s 1 r b q 2 z u 7 e / v m w e G 9 i l N J m U N j E c u e T x Q T P G I O c B C s l 0 h G Q l + w r j + 5 L v 3 u I 5 O K x 9 E d Z A n z Q j K K e M A p A S 0 N z I Y b E h j 7 Q T 4 u H l x g U 8 i n x c B s W i 1 r B r x M 7 I o 0 U Y X O w P x y h z F N Q x Y B F U S p v m 0 l 4 O V E A q e C F X U 3 V S w h d E J G r K 9 p R E K m v H w W v s A n W h n i I J b 6 R Y B n 6 u + N n I R K Z a G v J 8 u o a t E r x f + 8 f g r B h Z f z K E m B R X R + K E g F h h i X T e A h l 4 y C y D Q h V H K d F d M x k Y S C 7 q u u S 7 A X v 7 x M n L P W Z c u 6 t Z r t q 6 q N G j p C x + g U 2 e g c t d E N 6 i A H U Z S h Z / S K 3 o w n 4 8 V 4 N z 7 m o y t G t d N A f 2 B 8 / g A 6 J 5 V V &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " Y n t z H W V Y 8 z r I D Q / S i e J 4 X w 3 1X i k = " &gt; A A A B + 3 i c b V B N S 8 N A F N z U r 1 q / o j 1 6 C R b B U 0 l E U G 9 F L x 4 r G F t o Y 9 l s N + 3 S z S b s v k h D i H / F i w c V r / 4 R b / 4 b N 2 0 O 2 j q w M M y 8 x 5 s d P + Z M g W 1 / G 5 W V 1 b X 1 j e p m b W t 7 Z 3 f P 3 D + 4 V 1 E i C X V J x C P Z 9 b G i n A n q A g N O u 7 G k O P Q 5 7 f i T 6 8 L v P F K p W C T u I I 2 p F + K R Y A E j G L Q 0 M O v 9 E M P Y D 7 J x / t A H O o V s m g / M h t 2 0 Z 7 C W i V O S B i r R H p h f / W F E k p A K I B w r 1 X P s G L w M S 2 C E 0 7 z W T x S N M Z n g E e 1 p K n B I l Z f N w u f W s V a G V h B J / Q R Y M / X 3 R o Z D p d L Q 1 5 N F V L X o F e J / X i + B 4 M L L m I g T o I L M D w U J t y C y i i a s I Z O U A E 8 1 w U Q y n d U i Y y w x A d 1 X T Z f g L H 5 5 m b i n z c u m f X v W a F 2 V b V T R I T p C J 8 h B 5 6 i F b l A b u Y i g F D 2 j V / R m P B k v x r v x M R + t G O V O H f 2 B 8 f k D O 2 e V W Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " Y n t z H W V Y 8 z r I D Q / S i e J 4 X w 3 1 X i k = " &gt; A A A B + 3 i c b V B N S 8 N A F N z U r 1 q / o j 1 6 C R b B U 0 l E U G 9 F L x 4 r G F t o Y 9 l s N + 3 S z S b s v k h D i H / F i w c V r / 4 R b / 4 b N 2 0 O 2 j q w M M y 8 x 5 s d P + Z M g W 1 / G 5 W V 1 b X 1 j e p m b W t 7 Z 3 f P 3 D + 4 V 1 E i C X V J x C P Z 9 b G i n A n q A g N O u 7 G k O P Q 5 7 f i T 6 8 L v P F K p W C T u I I 2 p F + K R Y A E j G L Q 0 M O v 9 E M P Y D 7 J x / t A H O o V s m g / M h t 2 0 Z 7 C W i V O S B i r R H p h f / W F E k p A K I B w r 1 X P s G L w M S 2 C E 0 7 z W T x S N M Z n g E e 1 p K n B I l Z f N w u f W s V a G V h B J / Q R Y M / X 3 R o Z D p d L Q 1 5 N F V L X o F e J / X i + B 4 M L L m I g T o I L M D w U J t y C y i i a s I Z O U A E 8 1 w U Q y n d U i Y y w x A d 1 X T Z f g L H 5 5 m b i n z c u m f X v W a F 2 V b V T R I T p C J 8 h B 5 6 i F b l A b u Y i g F D 2 j V / R m P B k v x r v x M R + t G O V O H f 2 B 8 f k D O 2 e V W Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " Y n t z H W V Y 8 z r I D Q / S i e J 4 X w 3 1 X i k = " &gt; A A A B + 3 i c b V B N S 8 N A F N z U r 1 q / o j 1 6 C R b B U 0 l E U G 9 F L x 4 r G F t o Y 9 l s N + 3 S z S b s v k h D i H / F i w c V r / 4 R b / 4 b N 2 0 O 2 j q w M M y 8 x 5 s d P + Z M g W 1 / G 5 W V 1 b X 1 j e p m b W t 7 Z 3 f P 3 D + 4 V 1 E i C X V J x C P Z 9 b G i n A n q A g N O u 7 G k O P Q 5 7 f i T 6 8 L v P F K p W C T u I I 2 p F + K R Y A E j G L Q 0 M O v 9 E M P Y D 7 J x / t A H O o V s m g / M h t 2 0 Z 7 C W i V O S B i r R H p h f / W F E k p A K I B w r 1 X P s G L w M S 2 C E 0 7 z W T x S N M Z n g E e 1 p K n B I l Z f N w u f W s V a G V h B J / Q R Y M / X 3 R o Z D p d L Q 1 5 N F V L X o F e J / X i + B 4 M L L m I g T o I L M D w U J t y C y i i a s I Z O U A E 8 1 w U Q y n d U i Y y w x A d 1 X T Z f g L H 5 5 m b i n z c u m f X v W a F 2 V b V T R I T p C J 8 h B 5 6 i F b l A b u Y i g F D 2 j V / R m P B k v x r v x M R + t G O V O H f 2 B 8 f k D O 2 e V W Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " Y n t z H W V Y 8 z r I D Q / S i e J 4 X w 3 1 X i k = " &gt; A A A B + 3 i c b V B N S 8 N A F N z U r 1 q / o j 1 6 C R b B U 0 l E U G 9 F L x 4 r G F t o Y 9 l s N + 3 S z S b s v k h D i H / F i w c V r / 4 R b / 4 b N 2 0 O 2 j q w M M y 8 x 5 s d P + Z M g W 1 / G 5 W V 1 b X 1 j e p m b W t 7 Z 3 f P 3 D + 4 V 1 E i C X V J x C P Z 9 b G i n A n q A g N O u 7 G k O P Q 5 7 f i T 6 8 L v P F K p W C T u I I 2 p F + K R Y A E j G L Q 0 M O v 9 E M P Y D 7 J x / t A H O o V s m g / M h t 2 0 Z 7 C W i V O S B i r R H p h f / W F E k p A K I B w r 1 X P s G L w M S 2 C E 0 7 z W T x S N M Z n g E e 1 p K n B I l Z f N w u f W s V a G V h B J / Q R Y M / X 3 R o Z D p d L Q 1 5 N F V L X o F e J / X i + B 4 M L L m I g T o I L M D w U J t y C y i i a s I Z O U A E 8 1 w U Q y n d U i Y y w x A d 1 X T Z f g L H 5 5 m b i n z c u m f X v W a F 2 V b V T R I T p C J 8 h B 5 6 i F b l A b u Y i g F D 2 j V / R m P B k v x r v x M R + t G O V O H f 2 B 8 f k D O 2 e V W Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " Y n t z H W V Y 8 z r I D Q / S i e J 4 X w 3 1 X i k = " &gt; A A A B + 3 i c b V B N S 8 N A F N z U r 1 q / o j 1 6 C R b B U 0 l E U G 9 F L x 4 r G F t o Y 9 l s N + 3 S z S b s v k h D i H / F i w c V r / 4 R b / 4 b N 2 0 O 2 j q w M M y 8 x 5 s d P + Z M g W 1 / G 5 W V 1 b X 1 j e p m b W t 7 Z 3 f P 3 D + 4 V 1 E i C X V J x C P Z 9 b G i n A n q A g N O u 7 G k O P Q 5 7 f i T 6 8 L v P F K p W C T u I I 2 p F + K R Y A E j G L Q 0 M O v 9 E M P Y D 7 J x / t A H O o V s m g / M h t 2 0 Z 7 C W i V O S B i r R H p h f / W F E k p A K I B w r 1 X P s G L w M S 2 C E 0 7 z W T x S N M Z n g E e 1 p K n B I l Z f N w u f W s V a G V h B J / Q R Y M / X 3 R o Z D p d L Q 1 5 N F V L X o F e J / X i + B 4 M L L m I g T o I L M D w U J t y C y i i a s I Z O U A E 8 1 w U Q y n d U i Y y w x A d 1 X T Z f g L H 5 5 m b i n z c u m f X v W a F 2 V b V T R I T p C J 8 h B 5 6 i F b l A b u Y i g F D 2 j V / R m P B k v x r v x M R + t G O V O H f 2 B 8 f k D O 2 e V W Q = = &lt; / l a t e x i t &gt; h x &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " Y n t z H W V Y 8 z r I D Q / S i e J 4 X w 3 1 X i k = " &gt; A A A B + 3 i c b V B N S 8 N A F N z U r 1 q / o j 1 6 C R b B U 0 l E U G 9 F L x 4 r G F t o Y 9 l s N + 3 S z S b s v k h D i H / F i w c V r / 4 R b / 4 b N 2 0 O 2 j q w M M y 8 x 5 s d P + Z M g W 1 / G 5 W V 1 b X 1 j e p m b W t 7 Z 3 f P 3 D + 4 V 1 E i C X V J x C P Z 9 b G i n A n q A g N O u 7 G k O P Q 5 7 f i T 6 8 L v P F K p W C T u I I 2 p F + K R Y A E j G L Q 0 M O v 9 E M P Y D 7 J x / t A H O o V s m g / M h t 2 0 Z 7 C W i V O S B i r R H p h f / W F E k p A K I B w r 1 X P s G L w M S 2 C E 0 7 z W T x S N M Z n g E e 1 p K n B I l Z f N w u f W s V a G V h B J / Q R Y M / X 3 R o Z D p d L Q 1 5 N F V L X o F e J / X i + B 4 M L L m I g T o I L M D w U J t y C y i i a s I Z O U A E 8 1 w U Q y n d U i Y y w x A d 1 X T Z f g L H 5 5 m b i n z c u m f X v W a F 2 V b V T R I T p C J 8 h B 5 6 i F b l A b u Y i g F D 2 j V / R m P B k v x r v x M R + t G O V OH f 2 B 8 f k D O 2 e V W Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " Y n t z H W V Y 8 z r I D Q / S i e J 4 X w 3 1 X i k = " &gt; A A A B + 3 i c b V B N S 8 N A F N z U r 1 q / o j 1 6 C R b B U 0 l E U G 9 F L x 4 r G F t o Y 9 l s N + 3 S z S b s v k h D i H / F i w c V r / 4 R b / 4 b N 2 0 O 2 j q w M M y 8 x 5 s d P + Z M g W 1 / G 5 W V 1 b X 1 j e p m b W t 7 Z 3 f P 3 D + 4 V 1 E i C X V J x C P Z 9 b G i n A n q A g N O u 7 G k O P Q 5 7 f i T 6 8 L v P F K p W C T u I I 2 p F + K R Y A E j G L Q 0 M O v 9 E M P Y D 7 J x / t A H O o V s m g / M h t 2 0 Z 7 C W i V O S B i r R H p h f / W F E k p A K I B w r 1 X P s G L w M S 2 C E 0 7 z W T x S N M Z n g E e 1 p K n B I l Z f N w u f W s V a G V h B J / Q R Y M / X 3 R o Z D p d L Q 1 5 N F V L X o F e J / X i + B 4 M L L m I g T o I L M D w U J t y C y i i a s I Z O U A E 8 1 w U Q y n d U i Y y w x A d 1 X T Z f g L H 5 5 m b i n z c u m f X v W a F 2 V b V T R I T p C J 8 h B 5 6 i F b l A b u Y i g F D 2 j V / R m P B k v x r v x M R + t G O V O H f 2 B 8 f k D O 2 e V W Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " Y n t z H W V Y 8 z r I D Q / S i e J 4 X w 3 1 X i k = " &gt; A A A B + 3 i c b V B N S 8 N A F N z U r 1 q / o j 1 6 C R b B U 0 l E U G 9 F L x 4 r G F t o Y 9 l s N + 3 S z S b s v k h D i H / F i w c V r / 4 R b / 4 b N 2 0 O 2 j q w M M y 8 x 5 s d P + Z M g W 1 / G 5 W V 1 b X 1 j e p m b W t 7 Z 3 f P 3 D + 4 V 1 E i C X V J x C P Z 9 b G i n A n q A g N O u 7 G k O P Q 5 7 f i T 6 8 L v P F K p W C T u I I 2 p F + K R Y A E j G L Q 0 M O v 9 E M P Y D 7 J x / t A H O o V s m g / M h t 2 0 Z 7 C W i V O S B i r R H p h f / W F E k p A K I B w r 1 X P s G L w M S 2 C E 0 7 z W T x S N M Z n g E e 1 p K n B I l Z f N w u f W s V a G V h B J / Q R Y M / X 3 R o Z D p d L Q 1 5 N F V L X o F e J / X i + B 4 M L L m I g T o I L M D w U J t y C y i i a s I Z O U A E 8 1 w U Q y n d U i Y y w x A d 1 X T Z f g L H 5 5 m b i n z c u m f X v W a F 2 V b V T R I T p C J 8 h B 5 6 i F b l A b u Y i g F D 2 j V / R m P B k v x r v x M R + t G O V O H f 2 B 8 f k D O 2 e V W Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " C 3 9 O h B + I c z R c j L N I N X H 2 9 e 9 l t 8 M = " &gt; A A A B 2 H i c b Z D N S g M x F I X v 1 L 8 6 V q 1 r N 8 E i u C p T N + p O c O O y g m M L 7 V A y m T t t a C Y z J H e E M v Q F X L h R f D B 3 v o 3 p z 0 K t B w I f 5 y T k 3 h M X S l o K g i + v t r W 9 s 7 t X 3 / c P G v 7 h 0 X G z 8 W T z 0 g g M R a 5 y 0 4 + 5 R S U 1 h i R J Y b 8 w y L N Y Y S + e 3 i 3 y 3 j M a K 3 P 9 S L M C o 4 y P t U y l 4 O S s 7 q j Z C t r B U m w T O m t o w V q j 5 u c w y U W Z o S a h u L W D T l B Q V H F D U i i c + 8 P S Y s H F l I 9 x 4 F D z D G 1 U L c e c s 3 P n J C z N j T u a 2 N L 9 + a L i m b W z L H Y 3 M 0 4 T + z d b m P 9 l g 5 L S 6 6 i S u i g J t V h 9 l J a K U c 4 W O 7 N E G h S k Z g 6 4 M N L N y s S E G y 7 I N e O 7 D j p / N 9 6 E 8 L J 9 0 w 4 e A q j D K Z z B B X T g C m 7 h H r o Q g o A E X u D N m 3 i v 3 v u q q p q 3 7 u w E f s n 7 + A a p 5 I o M &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " g z C d q p s 4 E 2 G C n 6 b K 5 Z Z 1 J D r m X e c = " &gt; A A A B 8 H i c b V B N S 8 N A F H y p X 7 V W j X r 0 E i y C p 5 J 4 U W + C F 4 8 V j C 0 0 s W y 2 m 3 b p 5 o P d F 2 k I 8 a 9 4 8 a D i r / H m v 3 H T 9 q C t A w v D z H u 8 2 Q l S w R X a 9 r d R W 1 v f 2 N y q b z d 2 m r t 7 + + Z B 8 0 E l m a T M p Y l I Z C 8 g i g k e M x c 5 C t Z L J S N R I F g 3 m N x U f v e J S c W T + B 7 z l P k R G c U 8 5 J S g l g b m k R c R H A d h M S 4 f P W R T L K b l w G z Z b X s G a 5 U 4 C 9 K C B T o D 8 8 s b J j S L W I x U E K X 6 j p 2 i X x C J n A p W N r x M s Z T Q C R m x v q Y x i Z j y i 1 n 4 0 j r V y t A K E 6 l f j N Z M / b 1 R k E i p P A r 0 Z B V V L X u V + J / X z z C 8 9 A s e p x m y m M 4 P h Z m w M L G q J q w h l 4 y i y D U h V H K d 1 a J j I g l F 3 V d D l + A s f 3 m V u O f t q 7 Z 9 Z 0 M d j u E E z s C B C 7 i G W + i A C x R y e I E 3 e D e e j V f j Y 9 5 W z V j U d g h / Y H z + A M 5 T k / M = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " g z C d q p s 4 E 2 G C n 6 b K 5 Z Z 1 J D r m X e c = " &gt; A A A B 8 H i c b V B N S 8 N A F H y p X 7 V W j X r 0 E i y C p 5 J 4 U W + C F 4 8 V j C 0 0 s W y 2 m 3 b p 5 o P d F 2 k I 8 a 9 4 8 a D i r / H m v 3 H T 9 q C t A w v D z H u 8 2 Q l S w R X a 9 r d R W 1 v f 2 N y q b z d 2 m r t 7 + + Z B 8 0 E l m a T M p Y l I Z C 8 g i g k e M x c 5 C t Z L J S N R I F g 3 m N x U f v e J S c W T + B 7 z l P k R G c U 8 5 J S g l g b m k R c R H A d h M S 4 f P W R T L K b l w G z Z b X s G a 5 U 4 C 9 K C B T o D 8 8 s b J j S L W I x U E K X 6 j p 2 i X x C J n A p W N r x M s Z T Q C R m x v q Y x i Z j y i 1 n 4 0 j r V y t A K E 6 l f j N Z M / b 1 R k E i p P A r 0 Z B V V L X u V + J / X z z C 8 9 A s e p x m y m M 4 P h Z m w M L G q J q w h l 4 y i y D U h V H K d 1 a J j I g l F 3 V d D l + A s f 3 m V u O f t q 7 Z 9 Z 0 M d j u E E z s C B C 7 i G W + i A C x R y e I E 3 e D e e j V f j Y 9 5 W z V j U d g h / Y H z + A M 5 T k / M = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " m 6 2 G 6 G S y p t 9 B N Z T 8 m z d 7 T a q 3 4 F 0 = " &gt; A A A B + 3 i c b V C 7 T s M w F H V 4 l v I K d G S x q J C Y q o Q F 2 C p Y G I t E a K U m V I 7 r t F a d h + w b 1 C g K v 8 L C A I i V H 2 H j b 3 D a D N B y J E t H 5 9 y r e 3 z 8 R H A F l v V t r K y u r W 9 s 1 r b q 2 z u 7 e / v m w e G 9 i l N J m U N j E c u e T x Q T P G I O c B C s l 0 h G Q l + w r j + 5 L v 3 u I 5 O K x 9 E d Z A n z Q j K K e M A p A S 0 N z I Y b E h j 7 Q T 4 u H l x g U 8 i n x c B s W i 1 r B r x M 7 I o 0 U Y X O w P x y h z F N Q x Y B F U S p v m 0 l 4 O V E A q e C F X U 3 V S w h d E J G r K 9 p R E K m v H w W v s A n W h n i I J b 6 R Y B n 6 u + N n I R K Z a G v J 8 u o a t E r x f + 8 f g r B h Z f z K E m B R X R + K E g F h h i X T e A h l 4 y C y D Q h V H K d F d M x k Y S C 7 q u u S 7 A X v 7 x M n L P W Z c u 6 t Z r t q 6 q N G j p C x + g U 2 e g c t d E N 6 i A H U Z S h Z / S K 3 o w n 4 8 V 4 N z 7 m o y t G t d N A f 2 B 8 / g A 6 J 5 V V &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " Y n t z H W V Y 8 z r I D Q / S i e J 4 X w 3 1 X i k = " &gt; A A A B + 3 i c b V B N S 8 N A F N z U r 1 q / o j 1 6 C R b B U 0 l E U G 9 F L x 4 r G F t o Y 9 l s N + 3 S z S b s v k h D i H / F i w c V r / 4 R b / 4 b N 2 0 O 2 j q w M M y 8 x 5 s d P + Z M g W 1 / G 5 W V 1 b X 1 j e p m b W t 7 Z 3 f P 3 D + 4 V 1 E i C X V J x C P Z 9 b G i n A n q A g N O u 7 G k O P Q 5 7 f i T 6 8 L v P F K p W C T u I I 2 p F + K R Y A E j G L Q 0 M O v 9 E M P Y D 7 J x / t A H O o V s m g / M h t 2 0 Z 7 C W i V O S B i r R H p h f / W F E k p A K I B w r 1 X P s G L w M S 2 C E 0 7 z W T x S N M Z n g E e 1 p K n B I l Z f N w u f W s V a G V h B J / Q R Y M / X 3 R o Z D p d L Q 1 5 N F V L X o F e J / X i + B 4 M L L m I g T o I L M D w U J t y C y i i a s I Z O U A E 8 1 w U Q y n d U i Y y w x A d 1 X T Z f g L H 5 5 m b i n z c u m f X v W a F 2 V b V T R I T p C J 8 h B 5 6 i F b l A b u Y i g F D 2 j V / R m P B k v x r v x M R + t G O V O H f 2 B 8 f k D O 2 e V W Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " Y n t z H W V Y 8 z r I D Q / S i e J 4 X w 3 1 X i k = " &gt; A A A B + 3 i c b V B N S 8 N A F N z U r 1 q / o j 1 6 C R b B U 0 l E U G 9 F L x 4 r G F t o Y 9 l s N + 3 S z S b s v k h D i H / F i w c V r / 4 R b / 4 b N 2 0 O 2 j q w M M y 8 x 5 s d P + Z M g W 1 / G 5 W V 1 b X 1 j e p m b W t 7 Z 3 f P 3 D + 4 V 1 E i C X V J x C P Z 9 b G i n A n q A g N O u 7 G k O P Q 5 7 f i T 6 8 L v P F K p W C T u I I 2 p F + K R Y A E j G L Q 0 M O v 9 E M P Y D 7 J x / t A H O o V s m g / M h t 2 0 Z 7 C W i V O S B i r R H p h f / W F E k p A K I B w r 1 X P s G L w M S 2 C E 0 7 z W T x S N M Z n g E e 1 p K n B I l Z f N w u f W s V a G V h B J / Q R Y M / X 3 R o Z D p d L Q 1 5 N F V L X o F e J / X i + B 4 M L L m I g T o I L M D w U J t y C y i i a s I Z O U A E 8 1 w U Q y n d U i Y y w x A d 1 X T Z f g L H 5 5 m b i n z c u m f X v W a F 2 V b V T R I T p C J 8 h B 5 6 i F b l A b u Y i g F D 2 j V / R m P B k v x r v x M R + t G O V O H f 2 B 8 f k D O 2 e V W Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " Y n t z H W V Y 8 z r I D Q / S i e J 4 X w 3 1 X i k = " &gt; A A A B + 3 i c b V B N S 8 N A F N z U r 1 q / o j 1 6 C R b B U 0 l E U G 9 F L x 4 r G F t o Y 9 l s N + 3 S z S b s v k h D i H / F i w c V r / 4 R b / 4 b N 2 0 O 2 j q w M M y 8 x 5 s d P + Z M g W 1 / G 5 W V 1 b X 1 j e p m b W t 7 Z 3 f P 3 D + 4 V 1 E i C X V J x C P Z 9 b G i n A n q A g N O u 7 G k O P Q 5 7 f i T 6 8 L v P F K p W C T u I I 2 p F + K R Y A E j G L Q 0 M O v 9 E M P Y D 7 J x / t A H O o V s m g / M h t 2 0 Z 7 C W i V O S B i r R H p h f / W F E k p A K I B w r 1 X P s G L w M S 2 C E 0 7 z W T x S N M Z n g E e 1 p K n B I l Z f N w u f W s V a G V h B J / Q R Y M / X 3 R o Z D p d L Q 1 5 N F V L X o F e J / X i + B 4 M L L m I g T o I L M D w U J t y C y i i a s I Z O U A E 8 1 w U Q y n d U i Y y w x A d 1 X T Z f g L H 5 5 m b i n z c u m f X v W a F 2 V b V T R I T p C J 8 h B 5 6 i F b l A b u Y i g F D 2 j V / R m P B k v x r v x M R + t G O V O H f 2 B 8 f k D O 2 e V W Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " Y n t z H W V Y 8 z r I D Q / S i e J 4 X w 3 1 X i k = " &gt; A A A B + 3 i c b V B N S 8 N A F N z U r 1 q / o j 1 6 C R b B U 0 l E U G 9 F L x 4 r G F t o Y 9 l s N + 3 S z S b s v k h D i H / F i w c V r / 4 R b / 4 b N 2 0 O 2 j q w M M y 8 x 5 s d P + Z M g W 1 / G 5 W V 1 b X 1 j e p m b W t 7 Z 3 f P 3 D + 4 V 1 E i C X V J x C P Z 9 b G i n A n q A g N O u 7 G k O P Q 5 7 f i T 6 8 L v P F K p W C T u I I 2 p F + K R Y A E j G L Q 0 M O v 9 E M P Y D 7 J x / t A H O o V s m g / M h t 2 0 Z 7 C W i V O S B i r R H p h f / W F E k p A K I B w r 1 X P s G L w M S 2 C E 0 7 z W T x S N M Z n g E e 1 p K n B I l Z f N w u f W s V a G V h B J / Q R Y M / X 3 R o Z D p d L Q 1 5 N F V L X o F e J / X i + B 4 M L L m I g T o I L M D w U J t y C y i i a s I Z O U A E 8 1 w U Q y n d U i Y y w x A d 1 X T Z f g L H 5 5 m b i n z c u m f X v W a F 2 V b V T R I T p C J 8 h B 5 6 i F b l A b u Y i g F D 2 j V / R m P B k v x r v x M R + t G O V O H f 2 B 8 f k D O 2 e V W Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " Y n t z H W V Y 8 z r I D Q / S i e J 4 X w 3 1 X i k = " &gt; A A A B + 3 i c b V B N S 8 N A F N z U r 1 q / o j 1 6 C R b B U 0 l E U G 9 F L x 4 r G F t o Y 9 l s N + 3 S z S b s v k h D i H / F i w c V r / 4 R b / 4 b N 2 0 O 2 j q w M M y 8 x 5 s d P + Z M g W 1 / G 5 W V 1 b X 1 j e p m b W t 7 Z 3 f P 3 D + 4 V 1 E i C X V J x C P Z 9 b G i n A n q A g N O u 7 G k O P Q 5 7 f i T 6 8 L v P F K p W C T u I I 2 p F + K R Y A E j G L Q 0 M O v 9 E M P Y D 7 J x / t A H O o V s m g / M h t 2 0 Z 7 C W i V O S B i r R H p h f / W F E k p A K I B w r 1 X P s G L w M S 2 C E 0 7 z W T x S N M Z n g E e 1 p K n B I l Z f N w u f W s V a G V h B J / Q R Y M / X 3 R o Z D p d L Q 1 5 N F V L X o F e J / X i + B 4 M L L m I g T o I L M D w U J t y C y i i a s I Z O U A E 8 1 w U Q y n d U i Y y w x A d 1 X T Z f g L H 5 5 m b i n z c u m f X v W a F 2 V b V T R I T p C J 8 h B 5 6 i F b l A b u Y i g F D 2 j V / R m P B k v x r v x M R + t G O V O H f 2 B 8 f k D O 2 e V W Q = = &lt; / l a t e x i t &gt; h y &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " G 5 n / 1 F g h u 5 2 A x 5 D m E D M 5 l T 1 g J P I = " &gt; A A A B + 3 i c b V B N S 8 N A F N z 4 W e t X t E c v w S J 4 K o k I 6 q 3 o x W M F Y w t N L J v t p l 2 6 2 Y T d F z G E + F e 8 e F D x 6 h / x 5 r 9 x 0 + a g r Q M L w 8 x 7 v N k J E s 4 U 2 P a 3 s b S 8 s r q 2 X t u o b 2 5 t 7 + y a e / t 3 K k 4 l o S 6 J e S x 7 A V a U M 0 F d Y M B p L 5 E U R w G n 3 W B y V f r d B y o V i 8 U t Z A n 1 I z w S L G Q E g 5 Y G Z s O L M I y D M B 8 X 9 x 7 Q R 8 i z Y m A 2 7 Z Y 9 h b V I n I o 0 U Y X O w P z y h j F J I y q A c K x U 3 7 E T 8 H M s g R F O i 7 q X K p p g M s E j 2 t d U 4 I g q P 5 + G L 6 w j r Q y t M J b 6 C b C m 6 u + N H E d K Z V G g J 8 u o a t 4 r x f + 8 f g r h u Z 8 z k a R A B Z k d C l N u Q W y V T V h D J i k B n m m C i W Q 6 q 0 X G W G I C u q + 6 L s G Z / / I i c U 9 a F y 3 7 5 r T Z v q z a q K E D d I i O k Y P O U B t d o w 5 y E U E Z e k a v 6 M 1 4 M l 6 M d + N j N r p k V D s N 9 A f G 5 w 8 8 6 5 V a &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " G 5 n / 1 F g h u 5 2 A x 5 D m E D M 5 l T 1 g J P I = " &gt; A A A B + 3 i c b V B N S 8 N A F N z 4 W e t X t E c v w S J 4 K o k I 6 q 3 o x W M F Y w t N L J v t p l 2 6 2 Y T d F z G E + F e 8 e F D x 6 h / x 5 r 9 x 0 + a g r Q M L w 8 x 7 v N k J E s 4 U 2 P a 3 s b S 8 s r q 2 X t u o b 2 5 t 7 + y a e / t 3 K k 4 l o S 6 J e S x 7 A V a U M 0 F d Y M B p L 5 E U R w G n 3 W B y V f r d B y o V i 8 U t Z A n 1 I z w S L G Q E g 5 Y G Z s O L M I y D M B 8 X 9 x 7 Q R 8 i z Y m A 2 7 Z Y 9 h b V I n I o 0 U Y X O w P z y h j F J I y q A c K x U 3 7 E T 8 H M s g R F O i 7 q X K p p g M s E j 2 t d U 4 I g q P 5 + G L 6 w j r Q y t M J b 6 C b C m 6 u + N H E d K Z V G g J 8 u o a t 4 r x f + 8 f g r h u Z 8 z k a R A B Z k d C l N u Q W y V T V h D J i k B n m m C i W Q 6 q 0 X G W G I C u q + 6 L s G Z / / I i c U 9 a F y 3 7 5 r T Z v q z a q K E D d I i O k Y P O U B t d o w 5 y E U E Z e k a v 6 M 1 4 M l 6 M d + N j N r p k V D s N 9 A f G 5 w 8 8 6 5 V a &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " G 5 n / 1 F g h u 5 2 A x 5 D m E D M 5 l T 1 g J P I = " &gt; A A A B + 3 i c b V B N S 8 N A F N z 4 W e t X t E c v w S J 4 K o k I 6 q 3 o x W M F Y w t N L J v t p l 2 6 2 Y T d F z G E + F e 8 e F D x 6 h / x 5 r 9 x 0 + a g r Q M L w 8 x 7 v N k J E s 4 U 2 P a 3 s b S 8 s r q 2 X t u o b 2 5 t 7 + y a e / t 3 K k 4 l o S 6 J e S x 7 A V a U M 0 F d Y M B p L 5 E U R w G n 3 W B y V f r d B y o V i 8 U t Z A n 1 I z w S L G Q E g 5 Y G Z s O L M I y D M B 8 X 9 x 7 Q R 8 i z Y m A 2 7 Z Y 9 h b V I n I o 0 U Y X O w P z y h j F J I y q A c K x U 3 7 E T 8 H M s g R F O i 7 q X K p p g M s E j 2 t d U 4 I g q P 5 + G L 6 w j r Q y t M J b 6 C b C m 6 u + N H E d K Z V G g J 8 u o a t 4 r x f + 8 f g r h u Z 8 z k a R A B Z k d C l N u Q W y V T V h D J i k B n m m C i W Q 6 q 0 X G W G I C u q + 6 L s G Z / / I i c U 9 a F y 3 7 5 r T Z v q z a q K E D d I i O k Y P O U B t d o w 5 y E U E Z e k a v 6 M 1 4 M l 6 M d + N j N r p k V D s N 9 A f G 5 w 8 8 6 5 V a &lt; / l a t e x i t &gt; h y &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " G 5 n / 1 F g h u 5 2 A x 5 D m E D M 5 l T 1 g J P I = " &gt; A A A B + 3 i c b V B N S 8 N A F N z 4 W e t X t E c v w S J 4 K o k I 6 q 3 o x W M F Y w t N L J v t p l 2 6 2 Y T d F z G E + F e 8 e F D x 6 h / x 5 r 9 x 0 + a g r Q M L w 8 x 7 v N k J E s 4 U 2 P a 3 s b S 8 s r q 2 X t u o b 2 5 t 7 + y a e / t 3 K k 4 l o S 6 J e S x 7 A V a U M 0 F d Y M B p L 5 E U R w G n 3 W B y V f r d B y o V i 8 U t Z A n 1 I z w S L G Q E g 5 Y G Z s O L M I y D M B 8 X 9 x 7 Q R 8 i z Y m A 2 7 Z Y 9 h b V I n I o 0 U Y X O w P z y h j F J I y q A c K x U 3 7 E T 8 H M s g R F O i 7 q X K p p g M s E j 2 t d U 4 I g q P 5 + G L 6 w j r Q y t M J b 6 C b C m 6 u + N H E d K Z V G g J 8 u o a t 4 r x f + 8 f g r h u Z 8 z k a R A B Z k d C l N u Q W y V T V h D J i k B n m m C i W Q 6 q 0 X G W G I C u q + 6 L s G Z / / I i c U 9 a F y 3 7 5 r T Z v q z a q K E D d I i O k Y P O U B t d o w 5 y E U E Z e k a v 6 M 1 4 M l 6 M d + N j N r p k V D s N 9 A f G 5 w 8 8 6 5 V a &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " G 5 n / 1 F g h u 5 2 A x 5 D m E D M 5 l T 1 g J P I = " &gt; A A A B + 3 i c b V B N S 8 N A F N z 4 W e t X t E c v w S J 4 K o k I 6 q 3 o x W M F Y w t N L J v t p l 2 6 2 Y T d F z G E + F e 8 e F D x 6 h / x 5 r 9 x 0 + a g r Q M L w 8 x 7 v N k J E s 4 U 2 P a 3 s b S 8 s r q 2 X t u o b 2 5 t 7 + y a e / t 3 K k 4 l o S 6 J e S x 7 A V a U M 0 F d Y M B p L 5 E U R w G n 3 W B y V f r d B y o V i 8 U t Z A n 1 I z w S L G Q E g 5 Y G Z s O L M I y D M B 8 X 9 x 7 Q R 8 i z Y m A 2 7 Z Y 9 h b V I n I o 0 U Y X O w P z y h j F J I y q A c K x U 3 7 E T 8 H M s g R F O i 7 q X K p p g M s E j 2 t d U 4 I g q P 5 + G L 6 w j r Q y t M J b 6 C b C m 6 u + N H E d K Z V G g J 8 u o a t 4 r x f + 8 f g r h u Z 8 z k a R A B Z k d C l N u Q W y V T V h D J i k B n m m C i W Q 6 q 0 X G W G I C u q + 6 L s G Z / / I i c U 9 a F y 3 7 5 r T Z v q z a q K E D d I i O k Y P O U B t d o w 5 y E U E Z e k a v 6 M 1 4 M l 6 M d + N j N r p k V D s N 9 A f G 5 w 8 8 6 5 V a &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " G 5 n / 1 F g h u 5 2 A x 5 D m E D M 5 l T 1 g J P I = " &gt; A A A B + 3 i c b V B N S 8 N A F N z 4 W e t X t E c v w S J 4 K o k I 6 q 3 o x W M F Y w t N L J v t p l 2 6 2 Y T d F z G E + F e 8 e F D x 6 h / x 5 r 9 x 0 + a g r Q M L w 8 x 7 v N k J E s 4 U 2 P a 3 s b S 8 s r q 2 X t u o b 2 5 t 7 + y a e / t 3 K k 4 l o S 6 J e S x 7 A V a U M 0 F d Y M B p L 5 E U R w G n 3 W B y V f r d B y o V i 8 U t Z A n 1 I z w S L G Q E g 5 Y G Z s O L M I y D M B 8 X 9 x 7 Q R 8 i z Y m A 2 7 Z Y 9 h b V I n I o 0 U Y X O w P z y h j F J I y q A c K x U 3 7 E T 8 H M s g R F O i 7 q X K p p g M s E j 2 t d U 4 I g q P 5 + G L 6 w j r Q y t M J b 6 C b C m 6 u + N H E d K Z V G g J 8 u o a t 4 r x f + 8 f g r h u Z 8 z k a R A B Z k d C l N u Q W y V T V h D J i k B n m m C i W Q 6 q 0 X G W G I C u q + 6 L s G Z / / I i c U 9 a F y 3 7 5 r T Z v q z a q K E D d I i O k Y P O U B t d o w 5 y E U E Z e k a v 6 M 1 4 M l 6 M d + N j N r p k V D s N 9 A f G 5 w 8 8 6 5 V a &lt; / l a t e x i t &gt; The procedure of using UDSSM-II to compute the co-reference scores of a positive example and a negative example respectively. Both examples are generated from the sentence "He tried twice to call her but she did not answer the phone".</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Examples from Winograd Schema Challenge (WSC). The task is to identify the reference of the pronoun in bold.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 3 :</head><label>3</label><figDesc>Comparison of the data from WSC and our training data. Our sentences are retrieved from the UDSSM-II training dataset based on the BM25 value for analysis. The pseudo labels in our training data can help identify the co-references in WSC.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">We don't believe it is possible to construct such a knowledge base given that the world is changing constantly.2 DSSMs can be applied to a wide range of tasks depending on the definition of (x, y). For example, (x, y) is a querydocument pair for Web search ranking, a document pair in recommendation, a question-answer pair in QA, and so on. See Chapter 2 of for a survey.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">We use the toolkit of spaCy in Python for POS and NER, and we will remove the sequences that contain less than 2 nouns.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9">https://cs.nyu.edu/faculty/davise/ papers/WinogradSchemas/PDPChallenge2016. xml 10 https://cs.nyu.edu/faculty/davise/ papers/WinogradSchemas/WSCollection.xml 11 https://github.com/stanfordnlp/GloVe</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="13">http://lucene.apache.org/pylucene/</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>• Parse the raw sentences to identify pronouns.</p><p>• Pick sentences that contain at least two pronouns.</p><p>• The sub-sequence pair with pronouns of the same gender and plurality is labeled as a positive pair; otherwise it is labeled as negative.</p><p>• Replace the corresponding pronoun pairs with a special token "@Ponoun".</p><p>Take the following sentence as an example: "He tried twice to call her but she did not answer the phone." There are three pronouns detected in the sentence, and we assume that the words her and she are co-reference words, while pairs (she, He) and (her, He) are not. Thus we can obtain three training examples from the given sentence. However, in the PDP and WSC tasks, models are asked to compute the co-reference scores between pronoun and candidate nouns, instead of two pronouns. Therefore, we replace the first pronoun in the sentence with a place holder; i.e., a negative training pair is generated by splitting the raw sentence into the following two sub-sequences:</p><p>• S x : " @Ponoun tried twice to call her" • S y : "but she did not answer the phone."</p><p>• label: Negative and the positive training pair can be generated by the same way:</p><p>• S x : " He tried twice to call @Ponoun" • S y : "but she did not answer the phone."</p><p>• label: Positive Thus, we could directly train the encoder and coreference scoring components through the generated training pairs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Model Architecture</head><p>The previous method, UDSSM-I, follows the task setting of PDP/WSC, and builds the model based on the similarity of the representations between nouns and the pronoun. As there is no signal indicating the exact alignment between co-reference words, the model tries to learn it based on the co-occurrence information from large scale unlabelled corpus. For the method of UDSSM-II, each representation pair (h x , h y ) has a clear signal, r, indicating whether they are co-referred or not. For simplicity, we do not have to split the sentence into two parts. We first use LSTM to process the sentence as follows:</p><p>where we can concatenate the word embeddings,</p><p>H are the hidden states of the corresponding LSTM. Suppose that the pronoun pair in the sentence are located at the i-th and j-th positions as shown in the bottom part of <ref type="figure">Figure 3</ref>(a). We use the hidden states around the pronouns as their contextual representations as follows:</p><p>where · · is the concatenation of all the vectors inside it. Then we further concatenate these representation pair:</p><p>where h c ∈ R 4l , and it will be the input of loss function with cross entropy as follows:</p><p>where r ∈ {0, 1} indicates whether the pronouns at the m-th and n-th positions should be considered co-reference or not. w p ∈ R 4l and w n ∈ R 4l are the parameters to learn.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Co-reference Scoring Function</head><p>Similar to the Eqn.(5), for each candidate, we use co-reference scoring function Score θ (x i , y) for the answer selection:</p><p>where i is the position of the candidate in the sentence and j is the position of the pronoun.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>In this section, we will introduce the datasets to train and evaluate our models for commonsense reasoning, the hyper-parameters of our model, and the analysis of our results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets</head><p>Training Corpus We make use of the raw text from Gutenberg 7 , a corpus offerring over 57,000 free eBooks, and 1 Billion Word 8 , a corpus of news, to train our model. We first ignore the sentences that contain less than 10 tokens or longer than 50 tokens. Then, for the model UDSSM-I, we collect all the sentences with the pronoun before which there're at least two nouns. For UDSSM-II, we collect all the sentences with at least 2 pronouns. In total, we collect around 4 million training pairs from each corpus for our proposed method respectively, and we split 5% as validation set.</p><p>Evaluation Dataset We evaluate our model on the commonsense reasoning datasets, Pronoun <ref type="bibr">6</ref> The best models reported in the works of <ref type="bibr" target="#b21">Radford et al. (2019)</ref> and <ref type="bibr" target="#b29">Trinh and Le (2018)</ref> are trained on a much larger corpus from Common Crawl. 7 http://www.gutenberg.org 8 https://github.com/ciprian-chelba/ 1-billion-word-language-modeling-benchmark Disambiguation Problems (PDP) 9 and Winograd Schema challenges (WSC) 10 , which include 60 and 285 questions respectively. Both of the tasks are constructed for testing commonsense reasoning and all the questions from these challenges are obvious for human beings to solve with commonsense knowledge, but hard for machines to solve with statistical techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experimental Setting</head><p>We use the same setting for both our models. The hidden state dimension of a single-directional LSTM is set to be 300. We use 300 dimensional GloVe embeddings 11 for initialization. We use Adamax to optimise the model, set learning rate to be 0.002, dropout rate on all layers are tuned from [0, 0.1, 0.2] and the batch size from <ref type="bibr">[30,</ref><ref type="bibr">50,</ref><ref type="bibr">100,</ref><ref type="bibr">200]</ref>. For the model UDSSM-I, in one batch, we treat all sequence pairs not from the same sentence as negative cases. And it takes around 30 hours on a single K40 GPU to train our models, which are much faster than training a large LM <ref type="bibr" target="#b9">(Jozefowicz et al., 2016)</ref> taking weeks on multiple GPUs.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The winograd schema challenge and reasoning about correlation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Bailey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amelia</forename><surname>Harrison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuliya</forename><surname>Lierler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Lifschitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Michael</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Knowledge Representation; Coreference Resolution; Reasoning</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A large annotated corpus for learning natural language inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabor</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Angeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Potts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Deep reinforcement learning for mention-ranking coreference models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Improving coreference resolution by learning entitylevel distributed representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Association for Computational Linguistics</title>
		<meeting>the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Using the framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robin</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dick</forename><surname>Crouch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Van Eijck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johan</forename><surname>Van Genabith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Jaspars</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans</forename><surname>Kamp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Milward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manfred</forename><surname>Pinkal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimo</forename><surname>Poesio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Pulman</surname></persName>
		</author>
		<idno>LRE 62-051 D- 16</idno>
		<imprint>
			<date type="published" when="1996" />
			<publisher>The FraCaS Consortium</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The pascal recognising textual entailment challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Ido Dagan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernardo</forename><surname>Glickman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Magnini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning Challenges. Evaluating Predictive Uncertainty, Visual Object Classification, and Recognising Tectual Entailment</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Commonsense reasoning and commonsense knowledge in artificial intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ernest</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gary</forename><surname>Marcus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lihong</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.08267</idno>
		<title level="m">Neural approaches to conversational ai</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning deep structured semantic models for web search using clickthrough data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Po-Sen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Acero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry</forename><surname>Heck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM international conference on Conference on information &amp; knowledge management</title>
		<meeting>the 22nd ACM international conference on Conference on information &amp; knowledge management</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Exploring the limits of language modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rafal</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonghui</forename><surname>Wu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.02410</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The winograd schema challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hector</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ernest</forename><surname>Levesque</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leora</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Morgenstern</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI spring symposium: Logical formalizations of commonsense reasoning</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Conceptneta practical commonsense reasoning tool-kit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Push</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BT technology journal</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="211" to="226" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Evdokimov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen-Hua</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Si</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Hu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.07704</idno>
		<title level="m">Probabilistic reasoning via deep learning: Neural association models</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Combing context and commonsense knowledge through neural networks for solving winograd schema problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen-Hua</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Si</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Spring Symposium Series</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Wordnet: a lexical database for english</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>George</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A corpus and cloze evaluation for deeper understanding of commonsense stories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nasrin</forename><surname>Mostafazadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathanael</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucy</forename><surname>Vanderwende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pushmeet</forename><surname>Kohli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Allen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Improving machine learning approaches to coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Association for Computational Linguistics. Association for Computational Linguistics</title>
		<meeting>the Association for Computational Linguistics. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Solving hard coreference problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoruo</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Khashabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Event detection and co-reference with minimal supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoruo</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqiu</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the conference on empirical methods in natural language processing</title>
		<meeting>the conference on empirical methods in natural language processing</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Deep contextualized word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference of the North American Chapter</title>
		<meeting>the Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Language models are unsupervised multitask learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Resolving complex cases of definite pronouns: The winograd schema challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Altaf</forename><surname>Rahman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Modeling naive psychology of characters in simple commonsense stories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannah</forename><surname>Rashkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bosselut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maarten</forename><surname>Sap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.06533</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Event2mind: Commonsense inference on events, intents, and reactions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maarten</forename><surname>Hannah Rashkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><surname>Sap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Allaway</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Association for Computational Linguistics</title>
		<meeting>the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Choice of plausible alternatives: An evaluation of commonsense causal reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melissa</forename><surname>Roemmele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew S</forename><surname>Cosmin Adrian Bejan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gordon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Spring Symposium: Logical Formalizations of Commonsense Reasoning</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Tackling winograd schemas by formalizing relevance theory in knowledge graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Schüller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Knowledge Representation and Reasoning Conference</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Towards addressing the winograd schema challenge: Building and using a semantic parser and a knowledge hunting module</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arpit</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Somak</forename><surname>Vo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chitta</forename><surname>Aditya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Baral</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Artificial Intelligence</title>
		<meeting>the International Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">A machine learning approach to coreference resolution of noun phrases</title>
		<editor>Wee Meng Soon, Hwee Tou Ng, and Daniel Chung Yong Lim</editor>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
	<note>Computational linguistics</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">A simple method for commonsense reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Trieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Trinh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.02847</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A broad-coverage challenge corpus for sentence understanding through inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adina</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikita</forename><surname>Nangia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Bowman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies)</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Swag: A large-scale adversarial dataset for grounded commonsense inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rowan</forename><surname>Zellers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonatan</forename><surname>Bisk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingjing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Duh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.12885</idno>
		<title level="m">ReCoRD: Bridging the Gap between Human and Machine Commonsense Reading Comprehension</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Ordinal common-sense inference. Transactions of the Association for Computational Linguistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rachel</forename><surname>Rudinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Duh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
