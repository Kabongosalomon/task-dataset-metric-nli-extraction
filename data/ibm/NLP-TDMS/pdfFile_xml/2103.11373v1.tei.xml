<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">ProgressiveSpinalNet architecture for FC layers</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Praveen</forename><surname>Chopra</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">IIT Jodhpur</orgName>
								<address>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">ProgressiveSpinalNet architecture for FC layers</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T16:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms FC Layers</term>
					<term>SpinalNet</term>
					<term>DeepLearning</term>
					<term>DNN</term>
					<term>CNN</term>
					<term>ResNet</term>
					<term>VGG</term>
					<term>Transfer Learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In deeplearning models the FC (fully connected) layer has biggest important role for classification of the input based on the learned features from previous layers. The FC layers has highest numbers of parameters and fine-tuning these large numbers of parameters, consumes most of the computational resources, so in this paper it is aimed to reduce these large numbers of parameters significantly with improved performance. The motivation is inspired from SpinalNet and other biological architecture. The proposed architecture has a gradient highway between input to output layers and this solves the problem of diminishing gradient in deep networks. In this all the layers receives the input from previous layers as well as the CNN layer output and this way all layers contribute in decision making with last layer. This approach has improved classification performance over the SpinalNet architecture and has SOTA performance on many datasets such as Caltech101, KMNIST, QMNIST and EMNIST. The source code is available at "https://github.com/praveenchopra/ProgressiveSpinalNet"</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>DeepLearning has given state of the art performance in various scientific and engineering fields, but it requires very large computational power and with lot of time for training. With advancement in the DeepLearning, more and more deep networks are being developed and training these deep network requires very large size of training dataset. These deep networks has millions of features and the final FC layers also becomes very big due to large size of input. The FC layers contains most of the parameters and plays most significant role in the classification performance. In a typical model the learned features from previous convolution layers are feed to these FC layers and the classification is made by these FC layers. In a typical structure the size of the first FC equals to CNN output and gradually size is increased and then gradually decreased to make final FC layer size equal to number of classes.</p><p>This FC architecture has been improved by Kabir <ref type="bibr" target="#b0">[1]</ref> with SpinalNet, where all the input layers are connected to output layers and all layers contribute in the classification at final FC layer. This architecture was inspired with biological Spinal architecture where the human spinal cord receives senses of touch from different locations in different parts of it <ref type="bibr" target="#b1">[2]</ref>. Then these inputs are given to brain for decision making.</p><p>In biological network the human Spinal does some processing of the inputs and then the processed features are given to the brain for final action <ref type="bibr" target="#b1">[2]</ref>. With the same inspiration this ProgressiveSpinalNet architecture is designed. In this architecture, the input is progressively processed at each stage instead of merging all layers output at last FC stage. The final classification at last FC layer is based on the progressively processed inputs of previous layers. In this architecture final stage of FC layer receives the processed features from previous layers with the actual features of the CNN, so the classification performance is better than the SpinlNet and it has given state of the art performance (SOTA) in many of the datasets and in other datasets it has comparable performance. This enhancement in the performance is also due to the elimination of the vanishing gradient problem in the DNN's. In this architecture there is a gradient super highway from output to input such as in LSTM. This FC architecture can be easily plugged in various Deeplearning models with changing the size of input and output. Due to progressive architecture this FC network is called as ProgressiveSpinalNet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Proposed architecture</head><p>The proposed architecture has an input to output connection as shown in the figure 1 given below. The human spinal is also works similar way where all the sensory inputs are collected be super nerves from small nerves and then feed to brain. In this transportation of the information the processing of the information is also done as reported in literatures by many biological theory's <ref type="bibr" target="#b5">[6]</ref> [7] <ref type="bibr" target="#b7">[8]</ref>. The working of the spinal can be understood by from R. D'mello <ref type="bibr" target="#b1">[2]</ref> theory that the Pain signal transmitted through the spinal are amplified at various stages and some pre-processing also done, so that if a pathway is not working, the information can be transmitted by other one. This is the basic working principle of our ProgressiveSpinalNet architecture.</p><p>In the ProgressiveSpinalNet architecture, the final layer of FC network receive the processed or extracted features in a hierarchical manner. So finally layer receives the both features extracted from CNN layers as well as features learned from previous layers of FC network. So, the decision making at final layer of FC is better than only using the previous FC layer FC layer features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 1 Human spinal and ProgressiveSpinalNet architecture</head><p>This concept is similar to FractalNet <ref type="bibr" target="#b4">[5]</ref> as given in <ref type="figure" target="#fig_0">figure 2</ref>, which uses the similar type of processing in CNN layers. A. Byerl <ref type="bibr" target="#b2">[3]</ref> and D. Ciregan <ref type="bibr" target="#b3">[4]</ref> also proposed similar types of architectures for various CNN based networks for feature extraction. In our approach, instead of training with a single branch in an iteration, the ProgressiveSpinalNet train the whole FC network in a single iteration. The gradients are propagated back from last layer of FC to directly each layer of the FC due to connectivity available from first layer of FC to last layer of the FC. This way the network eliminates the problem of the vanishing gradients. This path from last layer to first layer of the FC works as the gradient super highway like LSTM. The size of each layer is progressively increased in each layer of the FC. This gradual increase does not makes the network very bulky as the increment is equal to size of the first layer output. This much amount of neuron are added into each step of the FC network. In the proposed ProgressiveSpinalNet architecture, the output size is kept same for each FC layer. This made the network design simple and more effectively manageable. The <ref type="figure">figure 3</ref> shows a typical ProgressiveSpinalNet architecture with input size and size of different layers of FC layers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 3 ProgressiveSpinalNet FC connections gradient flow</head><p>The general network of FC is a simple DNN network and has limitation on its depth, as deeper we go, the lesser the accuracy we achieves due to vanishing gradients problem. So the normal FC networks are mostly limited to depth of the 3-4 layers max. But the ProgressiveSpinalNet, does not suffers from the problem of the vanishing gradients so it depth can be much more than the normal FC network. This FC network has been tested with 6 layers and the performance was at par or better than the 3 layer normal FC network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>The performance of this ProgressiveSpinalNet architecture has been checked for various datasets and it has performed very well. In most of the datasets it has given SOTA performance when it has used as FC layer of many standard pre-trained networks. If it is used on dataset where no pre-trained network is used, the performance is either at par or better than the normal FC network. In different datasets, as per the size of classification labels the output size is increased or decreased as per the size of ProgressiveSpinalNet and tested for many configuration. Its performance was always better than normal FC network. For the performance comparison the SpinalNet is used as the reference because SpinalNet has SOTA on many data set [reference to paperwithcode.com] and baseline for this work. The performance of the ProgressiveSpinalNet is tested on various vanilla models along with the transfer learning models. The performance of the ProgressiveSpinalNet on both of these types is better than the SpinalNet or at par with SpinalNet. This ProgressiveSpinalNet has been tested on various datasets and the performance with different hyper parameters is as given in </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion:</head><p>In this paper an improved concept of DNN is presented with progressive computational network called ProgressiveSpinalNet for FC layers of deep-networks. This is a biologically inspired network design and proven its performance on various datasets with SOTA performance on many datasets. This network does not have problem of vanishing gradients with support of large depth of network. The structure of this network does not requires too many parameters, this leads to improvement in performance with less computations. This network concept can be easily expanded to wide range of real-world scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">References</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2</head><label>2</label><figDesc>FractalNet architecture</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>table below</head><label>below</label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell> No. of epochs = 100  StepLR</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell> CrossEntropy  Dropout =0.3</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell> ADAM</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell> Dropout = 0.2</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>3.</cell><cell cols="2">KMNITS  Learning rate = 0.0008</cell><cell></cell><cell>VGG-5</cell><cell></cell><cell>98.98</cell><cell>Performance</cell></row><row><cell></cell><cell></cell><cell> Batch size = 64</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>at par with</cell></row><row><cell></cell><cell></cell><cell> Hidden layer size = 64</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>reported</cell></row><row><cell></cell><cell></cell><cell> No. of epochs = 200</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>results</cell></row><row><cell></cell><cell></cell><cell> CrossEntropy</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell> ADAM</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell> Dropout = 0.2</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>4.</cell><cell cols="2">Bird225  Learningrate=0.0008, moment</cell><cell></cell><cell cols="2">Pre trained</cell><cell>99.55</cell><cell>SOTA</cell></row><row><cell></cell><cell></cell><cell>um=0.9</cell><cell></cell><cell cols="2">wide_resnet101</cell><cell></cell><cell>performance</cell></row><row><cell></cell><cell></cell><cell> Hidden layer size = 256  Batch size=16</cell><cell>:</cell><cell>_2 Model</cell><cell></cell><cell></cell></row><row><cell>S. No 1.</cell><cell>Dataset MNIST</cell><cell>Hyper parameters  No of epochs=10  CrossEntropyLoss  SGD  Learning rate=0.001, momentum=0.5  StepLR  Dropout =0.5</cell><cell></cell><cell cols="2">Base Model Vanilla FC layer only, no CNN</cell><cell>Accuracy (best of all epoch) in % 98.19</cell><cell>Remarks Performance at par with</cell></row><row><cell>5.</cell><cell>Fruits</cell><cell> Batch size=100  Learningrate=0.0008momentu</cell><cell></cell><cell>layers Pre</cell><cell>trained</cell><cell>99.97</cell><cell>reported Performance</cell></row><row><cell></cell><cell>360</cell><cell> HiddenLayer size = 128 m=0.9</cell><cell></cell><cell cols="2">wide_resnet101</cell><cell></cell><cell>results at par with</cell></row><row><cell></cell><cell></cell><cell> No. of epochs=50  Batch size=16</cell><cell></cell><cell>_2</cell><cell></cell><cell></cell><cell>reported</cell></row><row><cell></cell><cell></cell><cell> Negative Log-Likelihood Loss  Hidden layer size = 256</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>results</cell></row><row><cell></cell><cell></cell><cell> SGD with momentum = 0.9  No of epochs=10</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell> Dropout =0.2  CrossEntropyLoss</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell> No of Layers =6  SGD</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>2.</cell><cell>EMNIST digits</cell><cell> Learning rate=0.005  Batch size=50  StepLR  Dropout =0.5</cell><cell></cell><cell>VGG-5</cell><cell></cell><cell>99.82</cell><cell>SOTA performance</cell></row><row><cell>6.</cell><cell>STL-10</cell><cell> HiddenLayer size = 64  Learningrate=0.0008, moment</cell><cell></cell><cell cols="2">Pre trained</cell><cell>98.18</cell><cell>SOTA</cell></row><row><cell></cell><cell></cell><cell> No. of epochs=50 um=0.9</cell><cell></cell><cell cols="2">wide_resnet101</cell><cell></cell><cell>performance</cell></row><row><cell></cell><cell></cell><cell> CrossEntropy  Batch size=8</cell><cell></cell><cell>_2 Model</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell> SGD with momentum = 0.9  Hidden layer size = 256</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell> Dropout =0.2  No of epochs=50</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>1.</cell><cell>EMNIST Letters</cell><cell> Learning rate = 0.005  Batch size = 50  Hidden layer size = 128  No. of epochs = 100  CrossEntropyLoss  SGD  StepLR  Dropout =0.5</cell><cell></cell><cell>VGG-5</cell><cell></cell><cell>95.8605</cell><cell>Performance at par with reported results</cell></row><row><cell>7.</cell><cell>Caltech1</cell><cell> CrossEntropy  Learningrate=0.001,</cell><cell></cell><cell>Pre</cell><cell>trained</cell><cell>97.76</cell><cell>SOTA</cell></row><row><cell></cell><cell>01</cell><cell> ADAM momentum=0.9</cell><cell></cell><cell cols="2">wide_resnet101</cell><cell></cell><cell>performance</cell></row><row><cell></cell><cell></cell><cell> Dropout = 0.2  Batch size=16</cell><cell></cell><cell>_2</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell> HiddenLayer size = 200</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>2.</cell><cell cols="2">QMNITS  Learning rate = 0.0008  Batch size = 64  No of epochs=16  CrossEntropyLoss  Hiddenlayer size = 64  SGD</cell><cell></cell><cell>VGG-5</cell><cell></cell><cell>99.6867</cell><cell>SOTA performance</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Deep Neural Network with Gradual</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdar</forename><surname>Kabir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jalali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Spinalnet</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2007.03347" />
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Spinal cord mechanisms of pain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dickenson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">British journal of anaesthesia</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="8" to="16" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">A branching and merging convolutional network with homogeneous filter capsules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Byerly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kalganova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Dear</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.09136</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Multi-column deep neural networks for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ciregan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Meier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2012 IEEE conference on computer vision and pattern recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="3642" to="3649" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">FractalNet: Ultra-Deep Neural Networks without Residuals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maire</forename><surname>Larsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shakhnarovich</forename></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1605.07648" />
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Ikshana: A Theory of Human Scene Understanding Mechanism</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Daliparthi</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2101.10837" />
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Gist of the scene</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aude</forename><surname>Oliva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neurobiology of attention</title>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="251" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">What do we perceive in a glance of a real-world scene</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asha</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christof</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of vision</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="10" to="10" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
