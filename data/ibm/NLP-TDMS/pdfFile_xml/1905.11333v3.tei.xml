<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">MINA: Multilevel Knowledge-Guided Attention for Modeling Electrocardiography Signals</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shenda</forename><surname>Hong</surname></persName>
							<email>hongshenda@pku.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Electronics Engineering and Computer Science</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Key Laboratory of Machine Perception (Ministry of Education)</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="department">Department of Computational Science and Engineering</orgName>
								<orgName type="institution">Georgia Institute of Technology</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cao</forename><surname>Xiao</surname></persName>
							<email>cao.xiao@iqvia.com</email>
							<affiliation key="aff2">
								<orgName type="department">Analytics Center of Excellence</orgName>
								<orgName type="institution">IQVIA</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tengfei</forename><surname>Ma</surname></persName>
							<email>tengfei.ma1@ibm.com</email>
							<affiliation key="aff3">
								<orgName type="institution">IBM Research</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyan</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Electronics Engineering and Computer Science</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Key Laboratory of Machine Perception (Ministry of Education)</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimeng</forename><surname>Sun</surname></persName>
							<email>jsun@cc.gatech.edu</email>
							<affiliation key="aff4">
								<orgName type="department">Department of Computational Science and Engineering</orgName>
								<orgName type="institution">Georgia Institute of Technology</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">MINA: Multilevel Knowledge-Guided Attention for Modeling Electrocardiography Signals</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T20:51+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Electrocardiography (ECG) signals are commonly used to diagnose various cardiac abnormalities. Recently, deep learning models showed initial success on modeling ECG data, however they are mostly black-box, thus lack interpretability needed for clinical usage. In this work, we propose MultIlevel kNowledge-guided Attention networks (MINA) that predict heart diseases from ECG signals with intuitive explanation aligned with medical knowledge. By extracting multilevel (beat-, rhythm-and frequency-level) domain knowledge features separately, MINA combines the medical knowledge and ECG data via a multilevel attention model, making the learned models highly interpretable. Our experiments showed MINA achieved PR-AUC 0.9436 (outperforming the best baseline by 5.51%) in real world ECG dataset. Finally, MINA also demonstrated robust performance and strong interpretability against signal distortion and noise contamination.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Heart diseases are among the leading causes of death of the world <ref type="bibr" target="#b0">[Benjamin et al., 2018]</ref>. The routine monitoring of physiological signals is deemed important in heart disease prevention. Among existing monitoring technologies, electrocardiography (ECG) is a commonly used non-invasive and convenient diagnostic tool that records physiological activities of heart over a period of time. Deciphering ECG signals can help detect many heart diseases such as atrial fibrillation (AF), myocardial infarction (MI), and heart failure (HF) <ref type="bibr" target="#b11">[Turakhia, 2018;</ref><ref type="bibr" target="#b11">Yanowitz, 2012</ref>].</p><p>An example of real world ECG signal is shown in Figure1. ECG signals from cases and controls of heart diseases show different patterns at 1) beat level, 2) rhythm level, and 3) frequency level, each representing different anomalous activities of the heart. For example, beat level morphology such as P wave (atrial depolarization) and QRS complex (ventricular depolarization) can reflect conditions related to heart electric conduction. Rhythm level patterns capture rhythm features across beats and reflect cardiac arrhythmia conditions (abnormal heart rhythms). Frequency level is about frequency variations and sheds light on the diagnosis of ventricular flutter and ventricular fibrillation. Learning these patterns to support diagnoses has been an important research area in ECG analysis <ref type="bibr" target="#b10">[Roopa and Harish, 2017;</ref><ref type="bibr" target="#b9">Lake and Moorman, 2010;</ref><ref type="bibr" target="#b9">Linker, 2016;</ref><ref type="bibr" target="#b10">Tateno and Glass, 2001]</ref>.</p><p>In real clinical settings, in addition to the demand of an accurate classification, the interpretability of the results is equally important <ref type="bibr" target="#b10">[Tsai et al., 2003]</ref>. Cardiologists need to provide both diagnosis and detailed explanations to support diagnosis <ref type="bibr">[EC57, 2012]</ref>. Also, many heart diseases do not pose abnormal ECG diagram constantly <ref type="bibr" target="#b0">[Benjamin et al., 2018;</ref><ref type="bibr" target="#b11">Yanowitz, 2012]</ref>, especially during the early stage of the diseases. Therefore, interpretability of the results, particularly highlighting diagnosis related parts of the data, is crucial for early diagnosis and better clinical decisions.</p><p>Traditional machine learning methods either learn time domain patterns including beat level <ref type="bibr" target="#b8">[Ladavich and Ghoraani, 2015;</ref><ref type="bibr" target="#b10">Pürerfellner et al., 2014]</ref> and rhythm level <ref type="bibr" target="#b6">[Huang et al., 2011]</ref>, or extract frequency patterns using signal processing techniques such as discrete wavelet transform <ref type="bibr" target="#b3">[García et al., 2016]</ref>. However, time domain approaches are easily affected by noise or signal distortion <ref type="bibr" target="#b10">[Rodríguez et al., 2015]</ref>; while frequency domain methods cannot model rare events or some temporal dynamics that occur in time domain. Besides, they all require laborious feature engineering, and their performance also relies on the quality of the constructed features.</p><p>Recently, deep learning models showed initial success in modeling ECG data. Convolutional neural networks (CNN) were used to learn beat level patterns <ref type="bibr" target="#b7">[Kiranyaz et al., 2016;</ref><ref type="bibr" target="#b10">Rajpurkar et al., 2017;</ref><ref type="bibr" target="#b3">Hannun et al., 2019]</ref>. Recurrent neural networks (RNN) are suitable for capturing rhythm fea-tures <ref type="bibr">[Schwab et al., 2017;</ref><ref type="bibr" target="#b4">Hong et al., 2017;</ref><ref type="bibr" target="#b11">Zihlmann et al., 2017]</ref>. Moreover, attention mechanism is employed to extract interpretable rhythm features <ref type="bibr">[Schwab et al., 2017]</ref>. Despite their progress, these models were either black-box or only highlighted one aspect of patterns (such as rhythm features as in <ref type="bibr">[Schwab et al., 2017]</ref>), thus lack the comprehensive interpretability of the results for real clinical usage.</p><p>In this work, we propose MultIlevel kNowledge-guide Attention model (MINA) to learn and integrate different levels of features from ECG which are aligned with clinical knowledge. For each level MINA extracts level-specific domain knowledge features and uses them to guide the attention, including beat morphology knowledge that guides attentive CNN and rhythm knowledge that guides attentive RNN. MINA also performs attention fusion across time-and frequency domains. We proposed new evaluation approaches by interfering ECG signals with noise and signal distortion. We evaluated interpretability and robustness of the model by tracking intermediate reactions across layers from multilevel attentions to the final predictions.</p><p>Experimental results show MINA can correctly identify critical beat location, significant rhythm variation, important frequency component and remain robust in prediction under signal distortion or noise contamination. Tested on the atrial fibrillation prediction, MINA achieved PR-AUC 0.9436 (outperforming the best baseline by 5.51%). Finally, MINA also showed strong result interpretability and more robust performance than baselines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Traditional methods include time domain methods such as beat level methods <ref type="bibr" target="#b8">[Ladavich and Ghoraani, 2015;</ref><ref type="bibr" target="#b10">Pürerfellner et al., 2014]</ref> and rhythm level ones <ref type="bibr" target="#b10">[Tateno and Glass, 2001;</ref><ref type="bibr" target="#b6">Huang et al., 2011;</ref><ref type="bibr" target="#b10">Oster and Clifford, 2015]</ref>, both depending on segmentation by detecting QRS complex. However, time domain methods rely on the accuracy of QRS detection, thus are easily affected by noise or signal distortion. Frequency domain approaches, on the other hand, cannot model rare events and other time-domain patterns and thus lack interpretability. Moreover, both types of features are subjective.</p><p>Recently, deep neural networks (DNNs) have been used in ECG diagnosis <ref type="bibr" target="#b7">[Kiranyaz et al., 2016;</ref><ref type="bibr" target="#b10">Rajpurkar et al., 2017;</ref><ref type="bibr" target="#b3">Hannun et al., 2019;</ref><ref type="bibr" target="#b11">Zihlmann et al., 2017;</ref><ref type="bibr" target="#b4">Hong et al., 2017;</ref><ref type="bibr">Schwab et al., 2017]</ref>. Many of them have demonstrated stateof-the-art performance due to their ability in extracting effective features <ref type="bibr" target="#b10">[Rajpurkar et al., 2017;</ref><ref type="bibr" target="#b4">Hong et al., 2017]</ref>. Some of them build an end-to-end classifier <ref type="bibr" target="#b7">[Kiranyaz et al., 2016;</ref><ref type="bibr" target="#b10">Rajpurkar et al., 2017;</ref><ref type="bibr" target="#b11">Zihlmann et al., 2017]</ref>, others build a mixture model which combines traditional feature engineering methods and deep models <ref type="bibr" target="#b4">[Hong et al., 2017;</ref><ref type="bibr">Schwab et al., 2017;</ref><ref type="bibr" target="#b5">Hong et al., 2019]</ref>. However, existing deep models are insufficient in three aspects. First, they neglect the characteristics of ECG signals when design model architecture, namely, beat morphological, rhythm variations. Second, they only analyze ECG signals in time domain. Last, they are "black-box" and thus not interpretable. In real world medical applications, interpretability is critical for clinicians to accept machine recommendations and implement intervention. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head><p>In this section, we will introduce the model design of MINA. Section 3.1 provides an overview and introduces all notations. Section 3.2 describes the basic framework, including each layer of MINA. Section 3.3 proposes our new attention mechanism which is integrated in MINA. Section 3.4 describes how we evaluate interpretability and robustness. Figure2 depicts the architecture of MINA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Overview of MINA</head><p>Here we briefly describe the framework and introduce notations used in this paper. Assume we are given a single lead ECG signal x ∈ R n and use it to predict class probability. We firstly transform it into multi-channel signals with F channels across different frequency bands where ith signal is denoted as x (i) ∈ R n . We then split each x (i) into M segments s (k) . Next we apply CNN and RNN consecutively on s (k) to obtain beat level attention o (k) , 1 ≤ k ≤ M and rhythm level attention c (i) . This follows by a fully connected layer that transforms c (i) into q (i) . We then take weighted average to integrate Q = [q (1) , ..., q (F ) ] across all channels to output frequency attention d, which will be used in prediction. To improve model accuracy and interpretability, we propose a knowledge guided attention to learn attention vectors from beat-, rhythm-, and frequency levels, denoted as α, β, and γ respectively. More details will be described in Section 3.2. The notations are summarized in <ref type="table" target="#tab_0">Table 1</ref>. Detailed configurations of MINA are shown in the Experiments section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Description of MINA</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Signal Transformation and Segmentation</head><p>In order to utilize the frequency-domain information, we employ an efficient strategy by decomposing original ECG signals into different frequency bands (where each band is regarded as a channel). Then we can concurrently model signals of each channel.</p><p>Specifically, we propose a new time-frequency transformation layer to transform a single lead ECG signal into multichannel ones. Here we use Finite Impulse Response (FIR) Notation Definition C,F # of classes, # of frequency channels n,M ,T ECG length, # of segments, segment length</p><formula xml:id="formula_0">x ∈ R n Original ECG signal X ∈ R F ×n , x (i) ∈ R n Signals after transformation, ith signal s ∈ R T Segment of ECG with length T S ∈ R M ×T , s (k) ∈ R T M segments, kth segment L ∈ R K×N CNN layer output l (j) ∈ R K , L (k) ∈ R K×N jth column in L, kth segment output o ∈ R K Output of beat level attention O ∈ R K×M , o (k) ∈ R K Output of beat attention of M segments, kth output H ∈ R J×M , h (k) ∈ R J Bi-LSTM layer output, kth column in H c ∈ R J Output of rhythm level attention C ∈ R J×F , c (i) ∈ R J Output of rhythm attention of F channels, ith output W c ∈ R J×H , b c ∈ R H Weight and bias in fully connected layer Q ∈ R H×F , q (i) ∈ R H Fully connected layer output, ith column in Q d ∈ R H Output of freq. level attention W ∈ R H×C , b ∈ R C</formula><p>Weight matrix and bias vector in prediction layer</p><formula xml:id="formula_1">p, p c Predicted probability, cth value w, w c Class weight, cth value z, z c One-hot label, cth value α ∈ R N Beat attention weights α j ∈ R, α (k) ∈ R N jth value in α, segment k attention β ∈ R M , β k ∈ R Rhythm level attention weights, kth value in β γ ∈ R F , γ i ∈ R Frequency level attention weights, ith value in γ K * ∈ R E * ×N Knowledge feature ( * can be α, β or γ) W * ∈ R (K+E * )×D * 1st layer attention weights ( * can be α, β or γ) b * ∈ R D * 1st layer attention biases ( * can be α, β or γ) V * ∈ R D * ×1 2nd layer attention weights ( * can be α, β or γ) D Function of standard deviation F Function of power spectral density x , α , β , γ , p</formula><p>Interfered signals, attention weights and predictions </p><formula xml:id="formula_2">ECG signal x into F multi-channel ECG signals X = [x (1) , x (2) , ..., x (F ) ].</formula><p>Then for each channel, we split x (i) ∈ R n into a sequence of M equal length segments. Unlike previous deep models <ref type="bibr">[Schwab et al., 2017;</ref><ref type="bibr" target="#b7">Kiranyaz et al., 2016]</ref> that perform segmentation using QRS complex detection, which is easily affected by signal quality, we simply use sliding window segmentation. By cutting each of ith segment is indexed by (i − 1) × T and i × T − 1, we receive M equal length segments s ∈ R T (without the loss of generality, we assume that n = M * K, otherwise we can cut off last remain part which is shorter than T ). In general, segment length T needs to be shorter than the length of one heart beat, so that we can extract patterns in beat level. Detailed configurations can be found in Implementation Details section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Beat Level Attentive Convolutional Layer</head><p>For beat level patterns, we mainly consider the abnormal wave shapes or edges. To locate them from signals, we design an attentive convolutional layer. Formally, given M segments s ∈ R T , we perform 1-D convolution on each of them and output convolved features: L = Conv(s), L ∈ R K×N , K is the number of filters, N is the output length of segments after convolution, which is determined by hyperparameters like stride of CNN. Conv operations are shared weights of M segments. Then instead of traditional global average pooling which treats all features homogeneously, we propose a knowledge-guided attention to aggregate these features and get beat level attention o = N j=1 α j l (j) , where α j represents the weight for convolved features, l (j) ∈ R K is the jth column in L, 1 ≤ j ≤ N . Thus the model can focus more on significant signal locations and have better beat level interpretation. Details of knowledge-guided attention will be introduced in Section 3.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Rhythm Level Attentive Recurrent Layer</head><p>For rhythm level patterns, we mainly consider the abnormal rhythm variation. To capture them from beat sequences, RNNs are a natural choice due to their abilities to learn on data with temporal dependencies. Again to improve interpretability and accuracies, we use knowledge guided attention with rhythm knowledge.</p><p>Specifically, we use a bidirectional Long Short-Term Memory network <ref type="bibr">[Schuster and Paliwal, 1997</ref>] (Bi-LSTM) to get rhythm level annotations of segments. The bidirectional LSTM is denoted here as</p><formula xml:id="formula_3">h (k) = BiLST M (o (1) , ..., o (k) ).</formula><p>We concatenate the forward and backward outputs of Bi-LSTM and receive the rhythm level feature H ∈ R J×M ,</p><formula xml:id="formula_4">H = [h (1) , ..., h (M ) ], 1 ≤ k ≤ M .</formula><p>Here we use knowledgeguided attention with rhythm knowledge to output the rhythm level attention c = M k=1 β k h (k) , where β k represents the weight of kth rhythm level hidden state h (k) .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fusion and Prediction</head><p>At the beginning we decompose ECG signals into multiples channels (i.e., frequency bands) and learn rhythm level features {c (i) } from each channel i. Now we will perform attention fusion across all channels to have a more comprehensive view about the signal.</p><p>We first perform fully connected transformation:</p><formula xml:id="formula_5">Q = W T c C ⊕ b c , where C ∈ R J×F , C = [c (1) , ..., c (F ) ], W c ∈ R J×H , b c ∈ R H and Q ∈ R H×F . ⊕ means broadcast-</formula><p>ing b c to all N column vectors in W T c C and applies addition. Then, since the importance of these channels may not be homogeneous, we will take weighted average of q (i) to calculate frequency level attention</p><formula xml:id="formula_6">d = F i=1 γ i q (i) where γ i is the weight of q (i) , Q = [q (1) , ..., q (F ) ], 1 ≤ i ≤ F .</formula><p>We use frequency knowledge, signals with greater energy are more informative, to determine the weight γ. Here we use power spectral density to measure energy. Last, given integrated features d we make prediction using p = sof tmax(</p><formula xml:id="formula_7">W T d + b), where W ∈ R H×C , d ∈ R H , b ∈ R C ,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>and optimize the weighted cross entropy loss</head><formula xml:id="formula_8">CE(p) = − C c=1 I{z c = 1}w c log p c ,</formula><p>where C is the number of classes, z is the ground truth , w is the weight vector with the same shape as z, I is the indication function. w is adjusted to handle with class imbalance problem which is common in medical area.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Knowledge Guided Attention of MINA</head><p>We now describe how to compute multilevel attention weights α, β, γ. The attention mechanism can be regarded as a twolayer neural network: the 1st fully connected layer calculates the scores for computing weights; the 2nd fully connected layer computes the weights with via softmax activation.</p><p>In the first layer, the scores are computed based on the following features. (1) Multilevel outputs L ∈ R K×N , H ∈ R J×M , Q ∈ R H×F extracted by MINA.</p><p>(2) Domain knowledge features including beat level K α ∈ R Eα×N , rhythm level K β ∈ R E β ×M , and frequency level K γ ∈ R Eγ ×F . Concretely, three levels of domain knowledge features can be represented as below.</p><p>• Beat Level K α : For beat level knowledge we mainly consider the abnormal wave shapes or sharply changed points such as QRS complex <ref type="bibr" target="#b6">[Kashani and Barold, 2005]</ref>. To represent it we compute first-order difference ∆ and a convolutional operation Conv α on each segment s to extract the beat level knowledge feature </p><formula xml:id="formula_9">K α = Conv α (∆(s)), ∆(s) i = s i − s i−1 and ∆(s) 0 = s 0 , s i is the ith</formula><formula xml:id="formula_10">α = sof tmax(V T α (W T α L K α ⊕ b α )) β = sof tmax(V T β (W T β H K β ⊕ b β )) γ = sof tmax(V T γ (W T γ Q K γ ⊕ b γ )) where, W α ∈ R (K+Eα)×Dα , W β ∈ R (J+E β )×D β , W γ ∈ R (H+Eγ )×Dγ , b α ∈ R Dα , b β ∈ R D β , b γ ∈ R Dγ represent weights and biases in the first layer, V α ∈ R Dα×1 , V β ∈ R D β ×1 , V γ ∈ R Dγ ×1</formula><p>represent weights in the second layer. ⊕ is addition with broadcasting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Method for Evaluating Interpretability and Robustness</head><p>To evaluate the interpretability and robustness of MINA, we perturb the signals and observe attention weights and prediction results. The evaluation method is illustrated in <ref type="figure" target="#fig_2">Figure 3</ref>. Concretely, we add signal distortion (low frequency interferer) or noise (high frequency interferer) to the original ECG signal x and get x , here we choose baseline signal distortion and white noise. For the perturbed signals x , we applied MINA to generate prediction p and output multilevel attention weights α , β , γ . We compare them with the original results p and α, β, γ from unperturbed data.</p><p>To evaluate the interpretability of MINA, we visually check whether attention weights are in line with medical evidences. For beat level attention weights of M segments    . Then we visualize the values and verify whether high A j relates to beat level medical evidence. For rhythm level attention weight β and β , we align them to M segments S = [s (1) , ..., s (M ) ], where β k corresponds to s (k) . Then we verify whether high β k relates to rhythm level medical evidence. For frequency level attention weight γ and γ , we align them to F channels X = [x (1) , ..., x (F ) ], where γ i corresponds to x (i) . Likewise, we check whether high γ i relates to frequency level medical evidence.</p><p>We evaluate the robustness of MINA based on the two tasks: (1) we visually compare whether the new attention weights after perturbation are still in line with medical evidences, using the same way above, (2) we gradually change the interfered amplitude and evaluate the overall performance changes. The more robust model will be less impacted. Moreover, these results can also be used to evaluate interpretability, since interpretable model can highlight meaningful information, while also suppress unrelated parts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>In this section, we first describe the dataset used for the experiments, followed by the description of the baseline models. Then we discuss the model performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Source of Data</head><p>We conducted all experiments using real world ECG data from PhysioNet Challenge 2017 databases . The dataset contains 8,528 de-identified ECG recordings lasting from 9s to just over 60s and sampled at 300Hz by the AliveCor device, 738 from AF patients and 7790 from controls as predefined by the challenge. We first divided the data into a training set (75%), a validation set (10%) and a test set (15%) to train and evaluate in all tasks. Then, we preprocess them to get equal length data, where n = 3000. The summary statistics of the data is described in <ref type="table" target="#tab_3">Table 2</ref>. In this study, the objective is to discriminate records of AF patients from those of controls.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Baseline Models</head><p>We will compare MINA with the following models:</p><p>• </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Implementation Details</head><p>In convolutional layers of CNN, CRNN, ACRNN and MINA, we use one layer for each model. The number of filters is set to 64, the filter size is set to 32 and strider is set to 2. Pooling is replaced by attention mechanism. Conv α of K α has one filter with size set to 32, the strider is also 2. In recurrent layers of CRNN, ACRNN and MINA, we also use one single layer for each model, the number of hidden units in each LSTM is set to 32. The dropout rate in the fully connected prediction layer is set to 0.5. In sliding window segmentation, we use non-overlapping stride with T = 50. Deep models are trained with the mini-batch of 128 samples for 50 iterations, which was a sufficient number of iterations for achieving the best performance for the classification task. The final model was selected using early stopping criteria on validation set. We then tested each model for 5 times using different random seeds, and report their mean values with standard deviation. All models were implemented in PyTorch version 0.3.1, and trained with a system equipped with 64GB RAM, 12 Intel Core i7-6850K 3.60GHz CPUs and Nvidia GeForce GTX 1080. All models were optimized using Adam <ref type="bibr" target="#b6">[Kingma and Ba, 2014]</ref>, with the learning rate set to 0.003. Our code is publicly available at https://github.com/hsd1503/MINA. ROC-AUC PR-AUC F1 ExpertLR 0.9350 ± 0.0000 0.8730 ± 0.0000 0.8023 ± 0.0000 ExpertRF 0.9394 ± 0.0000 0.8816 ± 0.0000 0.8180 ± 0.0000 CNN 0.8711 ± 0.0036 0.8669 ± 0.0068 0.7914 ± 0.0090 CRNN 0.9040 ± 0.0115 0.8943 ± 0.0111 0.8262 ± 0.0215 ACRNN 0.9072 ± 0.0047 0.8935 ± 0.0087 0.8248 ± 0.0229 MINA 0.9488 ± 0.0081 0.9436 ± 0.0082 0.8342 ± 0.0352  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Performance Comparison</head><p>Performance was measured by the Area under the Receiver Operating Characteristic (ROC-AUC), Area under the Precision-Recall Curve (PR-AUC) and the F1 score. The PR-AUC is considered a better measure for imbalanced data like ours <ref type="bibr" target="#b1">[Davis and Goadrich, 2006]</ref>. <ref type="table" target="#tab_5">Table 3</ref> shows MINA outperforms all baselines, and shows 5.51% higher PR-AUC than the second best models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Interpretability and Robustness Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">MINA Automatically Extracts Clinically Meaningful Patterns</head><p>When reading an ECG record (upper left in <ref type="figure" target="#fig_4">Figure 4</ref>), cardiologists will make AF diagnosis based on following clinical evidences: 1) the absence of P wave: a small upward wave before QRS complex; 2) the irregular RR interval such as the much wider one between the 4th and the 5th QRS complex.</p><p>MINA learns these patterns automatically via beat-, rhythm-, and frequency level attention weights. From <ref type="figure" target="#fig_4">Figure 4</ref>, the beat level attentions point to where QRS complex or absent P waves occur. The rhythm level attentions indicate the location of abnormal RR interval, which precisely matches the clinical evidence. Besides, from the frequency level attentions, we notice channel 10Hz-50Hz receives the highest attention weight so MINA pays more attention to it. In fact, QRS complex, the most significant clinical evidence in ECG diagnosis, is known to be dominant in 10Hz-50Hz <ref type="bibr" target="#b10">[Tateno and Glass, 2001;</ref><ref type="bibr" target="#b9">Linker, 2016;</ref><ref type="bibr" target="#b9">Lake and Moorman, 2010]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">MINA Remains Interpretable and Robust Against Baseline Signal Distortion</head><p>The baseline wander distortion is a low frequency noise with slow but large changes of the signal offset. It is a common issue that drops ECG analysis performance. In this experiment, we mimic the real world setting by distorting data and observe whether MINA can still make robust and interpretable predictions.</p><p>For the experiment we interfered the signal in <ref type="figure" target="#fig_4">Figure 4</ref> with baseline wander distortion. The interfered signal is plotted in <ref type="figure" target="#fig_5">Figure 5</ref>(a). From the original frequency attention in <ref type="figure" target="#fig_4">Figure 4</ref>, it is easy to see Channel 1 (&lt;0.5Hz) has the lowest weights, while Channel 2 (0.5Hz-50Hz) weights much higher. Thus Channel 1 can be interpreted as baseline component while Channel 2 as clean signal component. MINA pays more attention to Channel 2 than Channel 1. After signal distortion, the importance of both channels remain the same, which is also reflected from their beat level and rhythm level attentions. Channel 1 shows no significant patterns, but the more informative Channel 2 have similar beat-and rhythm level patterns as unperturbed data, which indicates the interpretability of MINA will be less impacted by data distortion.</p><p>To evaluate model robustness, we compare the performance change along the increase of distortion amplitude on the entire test set. As shown in <ref type="figure" target="#fig_5">Figure 5(d)</ref>, MINA still has much lower performance drop even after distortion by large amplitude. While all baselines start to have large performance drop even with little distortion. This is mainly thanks to frequency attention fusion. In training process, the model already identified Channel 1 a baseline signal. Thus baseline distortion will have less impact on important signals in clean signal channel. Since baseline signal distortion occurs in real clinical setting, MINA will provide more accurate prediction in these scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">MINA Remains Interpretable and Robust in the Presence of Noise</head><p>The high frequency noise contamination is another common issues. For this experiment, we perturbed the signal in <ref type="figure" target="#fig_4">Figure 4</ref> with white noise. The perturbed signal is in <ref type="figure" target="#fig_6">Figure 6(a)</ref>. Similar to last experiment, from original frequency attentions we know Channel 3 (&gt;50Hz) has lower weights. It is a channel known for high noise. While Channel 2 (0.5Hz-50Hz) weights much higher and is known as a clean signal channel. After noise contamination, the noise impacts more to the noise Channel which is less important in the prediction of MINA, but the more informative Channel 2 have similar beat- and rhythm level patterns as unperturbed data, which indicates the interpretability of MINA will be less impacted by noise contamination. In <ref type="figure" target="#fig_6">Figure 6(d)</ref>, we compare the PR-AUC change along the increase of noise amplitude on the entire test set. MINA is less impacted by noise than other methods, demonstrating more robust performance in the presence of noise thanks to frequency attention fusion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion and Future Work</head><p>In this paper, we propose MINA, a deep multilevel knowledgeguided attention networks that interpretatively predict heart disease from ECG signals. MINA outperformed baselines in heart disease prediction task. Experimental results also showed robustness and strong interpretability against signal distortion and noise contamination. In future, we can extend to a broad range of disease where ECG signals can be treated as additional information in the diagnosis, on top of other health data such as electronic health records. Then we will need to investigate interpretable prediction based on multimodal data, which is a possibly rewarding avenue of future research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MINA: Multilevel Knowledge-Guided Attention for Modeling Electrocardiography Signals</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Background of Electrocardiography (ECG)</head><p>The Electrocardiography (ECG) is a test that measures the electrical activity of the heartbeat. With each beat, an electrical impulse travels through the heart and causes the muscle to squeeze and pump blood from the heart. Then ECG signals will record the timing of the top and lower chambers.</p><p>A normal heart beat in ECG is shown in <ref type="figure" target="#fig_7">Figure 7</ref>. Usually a "P wave" which is characterized by the right and left atria or upper chambers will arrive first, following by a flat line indicating when electrical impulse goes to the bottom chambers. Then next wave called ventricular depolarization (QRS complex) arrive. The next wave is called ventricular repolarization (ST segment, T wave), which represents electrical recovery or return to a resting state for the ventricles. Together we also have "U wave" that represents papillary muscle repolarization. ECG signals offer two types of information: 1) the time intervals measures how long the electrical wave needs to pass through the heart: normal or slow, fast or irregular; 2) the amount of electrical activity passing through the heart shows whether the size of parts of the heart become abnormal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>QRS P T U PR ST</head><p>The time domain features for heart disease diagnosis include beat level and rhythm level. However, many disease such as AF poses patterns in both beat level and rhythm level, so it is beneficial to combine them together for analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Frequency Band for ECG Signals</head><p>The ECG signal is a mixture of heart muscle's electrophysiologic activities including atrial, ventricular, papillary muscle and myocardium. Besides, it may also contain other electrical components from muscle, skin, respiration, body moving etc. The frequency bands listed below are commonly considered dominant components in ECG signal:</p><p>• &lt; 0.5 Hz: very low frequency component, mainly represent heart unrelated wandering.</p><p>• 0.12 Hz -0.5 Hz: respiration.</p><p>• 0.5 Hz -50 Hz: P wave, QRS complex and T wave.</p><p>• 0.67 Hz -5 Hz: P wave.</p><p>• 1 Hz -7 Hz: T wave.</p><p>• 5 Hz -50 Hz: muscle.</p><p>• 10 Hz -50 Hz: QRS complex is the most dominate component.</p><p>• &gt; 50 Hz: high frequency noise.</p><p>• All: raw signal.</p><p>Notice that these frequency bands are approximate, since they are hard to be divided entirely. Besides, their significance may also vary among people. However, it is beneficial to combine frequency domain features and time domain features together for disease diagnosis, since the transformation of frequency bands will divide time domain ECG signals into subspaces, thus helps classification tasks.</p><p>The illustration of frequency transformation is shown in <ref type="figure" target="#fig_8">Figure 8</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Interferer Simulation Details</head><p>We simulate baseline wander distortion signal using sine function and noise contamination signal using random normal distribution. Concretely, when interfere length n signal x:</p><p>x = x + amp * sin([ 1 * π n , 2 * π n , ..., π])</p><p>x = x + amp * random_normal([1, 2, ..., n])</p><p>where amp is amplitude of interfere, + represents elementwise addition. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D More Interpretability Evaluation Examples</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Normal ECG signal and Abnormal ECG signal show different patterns across different levels.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>MINA takes raw ECG signals as input and outputs probabilities of disease onset. MINA used knowledge-guided attention to learn informative beat-, rhythm-, and frequency level patterns, and then performs attentive signal fusion for improved prediction.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Analysis of multi-level attention change (Orange) and final prediction change (Blue).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>A</head><label></label><figDesc>= [α (1) , ..., α (M ) ] ∈ R M * N and A = [α (1) , ..., α (M ) ] ∈ R M * N , we align them to input ECG signals x ∈ R n , where the ith attention weight A j approximately corresponds from x n * j M * N to x n * (j+1) M * N</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>An ECG signal of AF patient (left top), MINA learns beat level attention which points to the position of significant QRS complexes and abnormal P waves. Rhythm level attention shows the abnormal RR interval. The frequency channel with highest attention correspond to the frequency bands where QRS complex is dominant.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>(a) Signal in Figure 4 interfered by baseline wander distortion. (b) Channel 1 (low attention weights) shows no significant patterns. (c) Channel 2 (higher attention weights) remains meaningful patterns similar to original data. (d) MINA has much lower PR-AUC drop % than baselines.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>(a) Signal in Figure 4 perturbed by noise. (b) Channel 3 (lower attention weights) shows no significant patterns. (c) Channel 2 (higher attention weights) remains meaningful patterns similar to original data. (d) MINA has much lower PR-AUC drop % than baselines.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 :</head><label>7</label><figDesc>A normal heart beat.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 8 :</head><label>8</label><figDesc>Finite impulse response bandpass filter in frequency transformation layer.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 9 :</head><label>9</label><figDesc>More examples of interpretability evaluations</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table /><note>Notations for MINA bandpass filter [Oppenheim et al., 1996] to transform sin- gle lead</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>value in s. Detailed configurations of Conv α are introduced in Implementation Details section. • Rhythm Level K β : Attention weights β focus on rhythm level variation, such as severe fluctuation in ventricular fibrillation disease [Yanowitz, 2012]. To characterize it we compute standard deviation on each segment in S to extract the rhythm level knowledge feature vector K β = D(S), where D calculate standard deviation of each s in S, D(s) = 1</figDesc><table /><note>T (s i −s) 2 • Frequency Level Kγ : On frequency level, signals with greater energy contain more information and thus need more attention [Yanowitz, 2012]. So we use power spectral density (PSD), a popular measure of energy, to extract the frequency level knowledge feature vector K γ = F(X), where F calculate PSD [Oppenheim et al., 1996] using a periodogram of each x (i) in X. Then, we concatenate model outputs and knowledge features to compute scores and attention weights.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Data profile of PhysioNet Challenge 2017 dataset</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>Expert: A combination of extracted features used in AF diagnosis including: rhythm features like sample entropy on QRS interval<ref type="bibr" target="#b9">[Lake and Moorman, 2010]</ref>; cumulative distribution functions<ref type="bibr" target="#b10">[Tateno and Glass, 2001]</ref>; thresholding on the median absolute deviation (MAD) of RR We used shared weights convolutional layers on ECG segments, and replaced the global average pooling with bi-directional LSTM. Then FC and softmax are applied to the top hidden layer. The architecture is modified based on<ref type="bibr" target="#b11">[Zihlmann et al., 2017]</ref>, but only keep one convolutional layer. Other hyper-parameters in CNN, RNN, FC and softmax are the same as MINA.• ACRNN: Based on CRNN, with additional beat level attentions and rhythm level attentions. Other hyperparameters are the same as MINA.</figDesc><table><row><cell>intervals [Linker, 2016]; heart rate variability in Poincare</cell></row><row><cell>plot [Park et al., 2009]; morphological features like lo-</cell></row><row><cell>cation, area, duration, interval, amplitude and slope of</cell></row><row><cell>related P wave, QRS complex, ST segment and T wave;</cell></row><row><cell>frequency features like frequency band power. We used</cell></row><row><cell>QRS segmentation method in [Pan and Tompkins, 1985]</cell></row><row><cell>and trained an LR classifier using these features. Then,</cell></row><row><cell>we build both logistic regression (ExpertLR) and ran-</cell></row><row><cell>dom forest (ExpertRF) on above extracted features.</cell></row><row><cell>• CNN: Convolutional layers are performed on ECG seg-</cell></row><row><cell>ments with shared weights. We use global average pool-</cell></row><row><cell>ing to combine features, and fully connect (FC) layer</cell></row><row><cell>and softmax layer for prediction. The model architecture</cell></row><row><cell>is modified based on [Kiranyaz et al., 2016] to handle</cell></row><row><cell>ECG segments. The hyper-parameters in CNN, FC and</cell></row><row><cell>softmax are the same as MINA to match the model com-</cell></row><row><cell>plexity.</cell></row><row><cell>• CRNN:</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>Performance Comparison on AF Prediction</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>•</head><label></label><figDesc>In beat level, an unusual p-wave may indicate disease such as atrial fibrillation (AF), ectopic atrial pacemaker, atrial enlargement et al. An unusual QRS complex may indicate disease such as left/right bundle branch block and ventricular tachycardia. An unusual ST segment and T wave may indicate myocardial infarction, ischemia, and left ventricular hypertrophy. • In rhythm level, the analysis is usually based on intervals between QRS complexes, which is called RR interval. Long RR interval may indicate sinus bradycardia, short RR interval may indicate sinus tachycardia or ventricular tachycardia, while irregular RR interval may indicate AF.</figDesc><table /><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work was supported by the National Science Foundation, award IIS-1418511, CCF-1533768 and IIS-1838042, the National Institute of Health award 1R01MD011682-01 and R56HL138415. We also thanks valuable discussions with Li Jiang from BOE.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">AF Classification from a short single lead ECG recording: the PhysioNet/Computing in Cardiology Challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>References</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Benjamin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Update: A Report from the American Heart Association. Circulation</title>
		<imprint>
			<biblScope unit="volume">137</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Computing in Cardiology</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The Relationship Between Precision-Recall and ROC Curves</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Goadrich ; Jesse</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Goadrich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML 2006</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="233" to="240" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Testing and Reporting Performance Results of Cardiac Rhythm and ST Segment Measurement Algorithms</title>
	</analytic>
	<monogr>
		<title level="m">Standard ANSI/AAMI EC57:2012, Association for the Advancement of Medical Instrumentation</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note>EC57, 2012</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Cardiologist-level Arrhythmia Detection and Classification in Ambulatory Electrocardiograms using a Deep Neural Network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>García</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">COMPUT METH PROG BIO</title>
		<imprint>
			<biblScope unit="volume">131</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">65</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>Nature medicine</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">ENCASE: an ENsemble ClASsifiEr for ECG Classification Using Expert Features and Deep Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Hong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computing in Cardiology</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Combining deep neural networks and engineered features for cardiac arrhythmia detection from ECG recordings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Hong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physiological Measurement</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">54009</biblScope>
			<date type="published" when="2019-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A Novel Method for Detection of the Transition Between Atrial Fibrillation and Sinus Rhythm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
	</analytic>
	<monogr>
		<title level="j">Adam: A Method for Stochastic Optimization</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
	<note>J AM COLL CARDIOL</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Real-Time Patient-Specific ECG Classification by 1-D Convolutional Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Kiranyaz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Rate-independent Detection of Atrial Fibrillation by Statistical Modeling of Atrial Activity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ghoraani ; Steven</forename><surname>Ladavich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Behnaz</forename><surname>Ladavich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ghoraani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biomedical Signal Processing and Control</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Accurate Estimation of Entropy in Very Short Physiological Time Series: the Problem of Atrial Fibrillation Detection in Implanted Ventricular Devices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Moorman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Douglas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J Randall Moorman ;</forename><surname>Lake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Linker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Accurate</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Oppenheim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Signals &amp;Amp; Systems</title>
		<imprint>
			<publisher>Prentice-Hall, Inc</publisher>
			<date type="published" when="1996" />
			<biblScope unit="volume">300</biblScope>
			<biblScope unit="page" from="182" to="189" />
		</imprint>
	</monogr>
	<note>CARDIOVASC ENG TECHN. 2Nd Ed</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Automatic Detection of Atrial Fibrillation using the Coefficient of Variation and Density Histograms of RR and ∆RR Intervals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clifford ; Julien</forename><surname>Oster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gari D Clifford ; Jiapu</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Willis J Tompkins ; Ieee T Bio-Med Eng ;</forename><surname>Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Beat by Beat: Classifying Cardiac Arrhythmias with Recurrent Neural Networks. Computing in Cardiology</title>
		<editor>Schwab et al., 2017] Patrick Schwab, Gaetano Scebba, Jia Zhang, Marco Delai, and Walter Karlen</editor>
		<meeting><address><addrLine>Douglas B Fridsma</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1985" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="478" to="483" />
		</imprint>
	</monogr>
	<note>Med Biol Eng Comput. and Guido Gatti. Computer Decision Support as a Source of Interpretation Error: the Case of Electrocardiograms. JAMIA</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Moving From Big Data to Deep Learning-The Case of Atrial Fibrillation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Turakhia ; Mintu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Turakhia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmytro</forename><surname>Yanowitz ; Martin Zihlmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Perekrestenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tschannen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Convolutional Recurrent Neural Networks for Electrocardiogram Classification. Computing in Cardiology</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="371" to="372" />
		</imprint>
	</monogr>
	<note>JAMA Cardiology</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
