<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Adapting Meta Knowledge Graph Information for Multi-Hop Reasoning over Few-Shot Relations</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Lv</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Institute for Artificial Intelligence</orgName>
								<orgName type="laboratory">KIRC</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Beijing National Research Center for Information Science and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxian</forename><surname>Gu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Han</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Institute for Artificial Intelligence</orgName>
								<orgName type="laboratory">KIRC</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Hou</surname></persName>
							<email>houlei@tsinghua.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Institute for Artificial Intelligence</orgName>
								<orgName type="laboratory">KIRC</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Beijing National Research Center for Information Science and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juanzi</forename><surname>Li</surname></persName>
							<email>lijuanzi@tsinghua.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Institute for Artificial Intelligence</orgName>
								<orgName type="laboratory">KIRC</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Beijing National Research Center for Information Science and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Institute for Artificial Intelligence</orgName>
								<orgName type="laboratory">KIRC</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Adapting Meta Knowledge Graph Information for Multi-Hop Reasoning over Few-Shot Relations</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T16:53+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Multi-hop knowledge graph (KG) reasoning is an effective and explainable method for predicting the target entity via reasoning paths in query answering (QA) task. Most previous methods assume that every relation in KGs has enough training triples, regardless of those few-shot relations which cannot provide sufficient triples for training robust reasoning models. In fact, the performance of existing multi-hop reasoning methods drops significantly on few-shot relations. In this paper, we propose a meta-based multi-hop reasoning method (Meta-KGR), which adopts meta-learning to learn effective meta parameters from high-frequency relations that could quickly adapt to few-shot relations. We evaluate Meta-KGR on two public datasets sampled from Freebase and NELL, and the experimental results show that Meta-KGR outperforms the current state-of-the-art methods in few-shot scenarios. Our code and datasets can be obtained from https://github.com/ THU-KEG/MetaKGR.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Recently, large-scale knowledge graphs <ref type="bibr">(KGs)</ref> have been demonstrated to be beneficial for many NLP tasks like query answering (QA). A triple query for QA is generally formalized as (e s , r q , ?), where e s is the source entity and r q is the query relation. For example, given a language query "What is the nationality of Mark Twain?", we can transform it into (Mark Twain, nationality, ?) and then search the target entity America from KGs as the answer. However, as many KGs are constructed automatically and face serious incompleteness problems <ref type="bibr" target="#b0">(Bordes et al., 2013)</ref>, it is often hard to directly get target entities for queries.</p><p>To alleviate this issue, some knowledge graph embedding methods <ref type="bibr" target="#b0">(Bordes et al., 2013</ref>; * Corresponding Author  <ref type="bibr" target="#b3">Dettmers et al., 2018)</ref> have been proposed to embed entities and relations into semantic spaces to capture inner connections, and then use the learned embeddings for final predictions. Although these embedding-based methods have shown strong abilities in predicting target entities for queries, they only give answers and lack interpretability for their decisions <ref type="bibr" target="#b9">(Lin et al., 2018)</ref>. In order to make models more intuitive, <ref type="bibr" target="#b2">Das et al. (2018)</ref> and <ref type="bibr" target="#b9">Lin et al. (2018)</ref> propose multi-hop reasoning methods, which leverage the symbolic compositionality of relations in KGs to achieve explainable reasoning results. For example, when queried with (Mark Twain, nationality, ?), multi-hop reasoning models can give not only the target entity America but also multi-hop explainable paths (Mark Twain, bornIn, Florida) ∧ (Florida, locatedIn, America) as well.</p><p>Most previous work assumes that there are enough triples to train an effective and robust reasoning models for each relation in KGs. However, as shown in <ref type="figure" target="#fig_0">Figure 1</ref>, a large portion of KG relations are actually long-tail <ref type="bibr" target="#b7">Han et al., 2018)</ref> and only contain few triples, which can be called few-shot relations. Some pilot experiments show that the performance of previous multi-hop reasoning models, e.g., MIN-ERVA <ref type="bibr" target="#b2">(Das et al., 2018)</ref> and <ref type="bibr">MultiHop (Lin et al., 2018)</ref>, on these few-shot relations will drop significantly. Note that, there are some knowledge graph embedding models <ref type="bibr" target="#b12">Shi and Weninger, 2018;</ref><ref type="bibr" target="#b15">Xie et al., 2016</ref>) that can deal with zero-shot or one-shot relations, but they still have two main drawbacks: (1) they are embedding-based models and lack interpretability;</p><p>(2) they focus on zero-shot or one-shot relations, which is a little far away from real-world scenes. In fact, even for people, it is hard to grasp new knowledge with almost no examples. Therefore, few-shot multi-hop reasoning is a quite important and practical problem that has not yet been fully resolved.</p><p>In this paper, we propose a meta-based algorithm for multi-hop reasoning (Meta-KGR) to address the above problems, which is explainable and effective for few-shot relations. Specifically, in Meta-KGR, we regard triple queries with the same relation r in KGs as a task. For each task, we adopt reinforcement learning (RL) to train an agent to search target entities and reasoning paths. Similar to previous meta-learning method MAML <ref type="bibr" target="#b5">(Finn et al., 2017)</ref>, we use tasks of highfrequency relations to capture meta information, which includes common features among different tasks. Then, the meta information can be rapidly adapted to the tasks of few-shot relations, by providing a good starting point to train their specific reasoning agents. In experiments, we evaluate Meta-KGR on two datasets sampled from Freebase and NELL, and the experimental results show that Meta-KGR outperforms the current state-ofthe-art multi-hop reasoning methods in few-shot scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Problem Formulation</head><p>We formally define a KG G = {E, R, F}, where E and R denote the entity and relation sets respectively. F = {(e s , r, e o )} ⊆ E × R × E is the triple set, where e s , e o ∈ E are entities and r ∈ R is a relation between them. In this paper, if the number of triples mentioning a relation r is smaller than the specific threshold K, r is considered as a fewshot relation, otherwise, it is a normal relation.</p><p>Given a query (e s , r q , ?), where e s is the source entity and r q is the few-shot relation, the goal of few-shot multi-hop reasoning is to predict the right entity e o for this query. Different from the previ-ous knowledge graph embedding work, multi-hop reasoning also gives a reasoning path from e s to e o over G to illustrate the whole reasoning process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Related Work</head><p>Knowledge Graph Embedding <ref type="bibr" target="#b0">(Bordes et al., 2013;</ref><ref type="bibr" target="#b18">Yang et al., 2015;</ref><ref type="bibr" target="#b3">Dettmers et al., 2018)</ref> aims to embed entities and relations into lowdimensional spaces, and then uses embeddings to define a score function f (e s , r, e o ) to evaluate the probability that a triple is true. Recently, several models <ref type="bibr" target="#b15">(Xie et al., 2016;</ref><ref type="bibr" target="#b12">Shi and Weninger, 2018)</ref> incorporate additional entity descriptions to learn embeddings for unseen entities, which can be seen as zero-shot scenarios.  predict new facts under a challenging setting where only one training triple for a given relation r is available, which can be seen as a one-shot scenario. Although these models are effective, they lack interpretability for their decisions.</p><p>Multi-Hop Reasoning over KGs aims to learn symbolic inference rules from relational paths in G and has been formulated as sequential decision problems in recent years. DeepPath <ref type="bibr" target="#b16">(Xiong et al., 2017)</ref> first applies RL to search reasoning paths in KGs for a given query, which inspires much later work (e.g., MINERVA <ref type="bibr" target="#b2">(Das et al., 2018)</ref> and DIVA ). Because it is hard to train an RL model, Reinforce-Walk <ref type="bibr" target="#b11">(Shen et al., 2018)</ref> proposes to solve the reward sparsity problem using off-policy learning. <ref type="bibr">MultiHop (Lin et al., 2018)</ref> further extends MIN-ERVA with reward shaping and action dropout, achieveing the state-of-the-art performance. These reasoning methods are intuitive and explainable. However, all of them have a weak performance in few-shot scenarios. In addition to multi-hop reasoning over KGs, there are also some multi-hop QA methods in recent years.  proposes a high quality dataset, which greatly promotes the development of this field. After that, many methods like CogQA <ref type="bibr" target="#b4">(Ding et al., 2019)</ref> and DFGN <ref type="bibr" target="#b14">(Xiao et al., 2019)</ref> are also proposed.</p><p>Meta-Learning tries to solve the problem of "fast adaptation on a new training task". It has been proved to be very successful on few-shot task <ref type="bibr" target="#b8">(Lake et al., 2015;</ref><ref type="bibr" target="#b6">Gu et al., 2018)</ref>. Previous metalearning models mainly focus on computer vision and imitation learning domains. In this paper, we propose a new model (Meta-KGR) using the metalearning algorithm MAML <ref type="bibr" target="#b5">(Finn et al., 2017)</ref> for</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Meta-Learning</head><p>Fast Adaptation rLr a &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; rLr b &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; rLr c &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; ✓ &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; ✓ ⇤ &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; ✓r 1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; ✓r 2 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; ✓r 3 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; <ref type="figure">Figure 2</ref>: Meta-learning. few-shot multi-hop reasoning. To the best of our knowledge, this work is the first research on fewshot learning for multi-hop reasoning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Model</head><p>The main idea of MAML is to use a set of tasks to learn well-initialized parameters θ * for a new task with few training examples. When applied to few-shot multi-hop reasoning, triple queries with the same relation r are considered as a task T r . We use triples with normal relations to find wellinitialized parameters θ * and train new models on triples with few-shot relations from the found initial parameters. As shown in <ref type="figure">Figure 2</ref>, we can easily fast adapt to new models with parameters θ r 1 , θ r 2 or θ r 3 for few-shot relation r 1 , r 2 or r 3 .</p><p>The learning framework of Meta-KGR can be divided into two parts: (1) relation-specific learning; (2) meta-learning. Relation-specific learning aims to learn a REINFORCE model with parameters θ r for a specific relation r (task) to search target entities and reasoning paths. Meta-learning is based on relation-specific learning and is used to learn a meta-model with parameters θ * . We will introduce these two parts in the following sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Relation-Specific Learning</head><p>For each query relation r q ∈ R, we learn a relation-specific multi-hop reasoning agent to search for reasoning paths and target entities over G, which is based on the on-policy RL approach proposed by <ref type="bibr" target="#b9">Lin et al. (2018)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Reinforcement Learning Formulation</head><p>The search process over G can be seen as a Markov Decision Process (MDP): We express G as a directed graph, with entities and relations as nodes and edges respectively. When given a query and its answer (e s , r q , e o ), we expect the agent for r q can start from the source entity e s and walk through several edges to reach the target entity e o . More specifically, the MDP is defined as follows.</p><p>States The state of the t-th time step is defined as a tuple s t = (r q , e s ,ê t ), where r q is the for all relation r do 5:</p><p>Sample supporting set DS and query set DQ for task Tr 6:</p><p>Evaluate</p><formula xml:id="formula_0">∇ θ L D S r (θ) in Eq. (3) 7:</formula><p>Compute adapted parameters: θ r = θ − α∇ θ L D S r (θ) 8: end for 9:</p><p>Update θ ← θ − β∇ θ Tr L D Q r (θ r ) 10: end while query relation, e s is the source entity andê t is the current entity over G.</p><p>Actions</p><p>The action space A t for a given state s t includes all outgoing edges and next entities ofê t . Formally, A t = {(r t+1 ,ê t+1 )| (ê t , r t+1 ,ê t+1 ) ∈ G}. We add a self-loop edge to every A t , which is similar to a "STOP" action.</p><p>Transition For the state s t , if the agent selects an action (r t+1 ,ê t+1 ) ∈ A t , the state will be changed to s t+1 = (r q , e s ,ê t+1 ). The transition function is defined as δ(s t , A t ) = (r q , e s ,ê t+1 ). In this paper, we unroll the search over G up to a fixed number of time steps T , and finally achieve the state s T = (r q , e s ,ê T ).</p><p>Rewards The reward R(s T |r q , e s ) will be 1 if the agent finally stops at the right entity, i.e., e T = e o , otherwise it will get an embeddingbased reward f (e s , r q ,ê T ), where f is a score function from knowledge graph embedding methods to measure the probability over (e s , r q ,ê t ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Policy Network</head><p>To solve the above MDP problem, we need a model which has policy to choose actions at each state. Specifically, different from normal RL problems, we apply a policy network considering the search history over G. Formally, after embedding all entities and relations in G as e ∈ R d and r ∈ R d respectively, each action a t = (r t+1 ,ê t+1 ) ∈ A t is represented as a t = [r t+1 ;ê t+1 ]. We use an LSTM to encode the search path, ht = LSTM(ht−1, at−1).</p><p>(1)</p><p>Then, we represent the action space by stacking all actions in A t as A t ∈ R |At|×2d . The parameterized policy network is defined as, π θ (at|st) = softmax(At(W2ReLU(W1[êt; ht; rq]))), where π θ (a t |s t ) is the probability distribution over all actions in A t .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3">Loss Function</head><p>Given a query relation r and a batch of triples set D with relation r, the overall loss for this relationspecific policy network is defined as:</p><formula xml:id="formula_2">L D r (θ) = −E (es,r,eo)∈D Ea 1 ,...,a T −1 ∈π θ [R(sT |es, r)].</formula><p>(3)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Meta-Learning</head><p>In meta-learning, we aim to learn well-initialized parameters θ * , such that small changes in the parameters will produce significant improvements on the loss function of any task <ref type="bibr" target="#b5">(Finn et al., 2017)</ref>. Formally, we consider a meta policy network with parameters θ. When adapting to a new task T r , the parameters of the model become θ r . Following MAML, the updated parameter θ r is computed using one or more gradient descent updates on task T r . For example, assuming a single gradient step is taken with the learning rate α</p><formula xml:id="formula_3">θ r = θ − α∇ θ L D S r (θ),<label>(4)</label></formula><p>where D S is a supporting set randomly sampled from the triples belonging to T r . After the relationspecific parameters θ r is learned, we evaluate θ r on the query set D Q belonging to T r , which is sampled like D S . The gradient computed from this evaluation can be used to update the meta policy network with parameters θ. Usually, we will go over many tasks in a batch and update θ as follows:</p><formula xml:id="formula_4">θ = θ − β∇ θ Tr L D Q r (θ r ),<label>(5)</label></formula><p>where β is the meta-learning rate. We detail the meta-learning algorithm in Algorithm 1. After previous meta-learning steps, Meta-KGR can fast adapt to a relation-specific policy network for every few-shot relation by using θ as wellinitialized parameters θ * .  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Datasets</head><p>We use two typical datasets FB15K-237 <ref type="bibr" target="#b13">(Toutanova et al., 2015)</ref> and NELL-995 <ref type="bibr" target="#b16">(Xiong et al., 2017)</ref> for training and evaluation. Specifically, we set K = 137 and K = 114 to select few-shot relations from FB15K-237 and NELL-995 respectively. Besides, we rebuild NELL-995 to generate few-shot relations in valid and test set. Statistics are given separately for normal relations and few-shot relations in <ref type="table" target="#tab_3">Table 2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Baselines</head><p>We compare with four multi-hop reasoning models in experiments: (1) Neural Logical Programming (NerualLP) ; (2) NTP-λ <ref type="bibr" target="#b10">(Rocktäschel and Riedel, 2017)</ref>; (3) MINERVA <ref type="bibr" target="#b2">(Das et al., 2018)</ref> and <ref type="formula" target="#formula_3">(4)</ref> MultiHop <ref type="bibr" target="#b9">(Lin et al., 2018)</ref>. For MultiHop and our model, we use both DistMult <ref type="bibr" target="#b18">(Yang et al., 2015)</ref> and ConvE <ref type="bibr" target="#b3">(Dettmers et al., 2018)</ref> as the reward function to create two different model variations, which are labeled in parentheses in <ref type="table">Table 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Link Prediction</head><p>Given a query (e s , r q , ?), link prediction for QA aims to give a ranking list of candidate entities from the KG. Following previous work <ref type="bibr" target="#b3">(Dettmers et al., 2018;</ref><ref type="bibr" target="#b9">Lin et al., 2018)</ref>, we use two evaluation metrics in this task: (1) the mean reciprocal rank of all correct entities (MRR) and (2) the proportion of correct entities that rank no larger than N (Hits@N).  Evaluation results on two datasets are shown in <ref type="table">Table 1</ref>. From the table, we can conclude that:</p><p>(1) Our models outperform previous work in most cases, which means meta parameters learned from high-frequency relations can adapt to few-shot relations well.</p><p>(2) ConvE is better than DistMult when used as the reward function in our models. This indicates that more effective knowledge graph embedding methods may provide finegrained rewards for training multi-hop reasoning models.</p><p>(3) Compared with NELL-995, FB15K-237 is denser. Our models perform well on both datasets, which demonstrates Meta-KGR can accommodate different types of KGs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Robustness Analysis</head><p>We can use different frequency thresholds K to select few-shot relations. In this section, we will study the impact of K on the performance of our model. In our experiments, some triples will be removed until every few-shot relation has only K triples. We do link prediction experiments on FB15K-237 and use ConvE as our reward function. The final results are shown in <ref type="table" target="#tab_5">Table 3</ref>. K = max means we use the whole datasets in <ref type="table" target="#tab_3">Table 2</ref> and do not remove any triples. From <ref type="table" target="#tab_5">Table 3</ref> we can see our model is robust to K and outperforms MultiHop in every case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we propose a meta-learning based model named Meta-KGR for multi-hop reasoning over few-shot relations of knowledge graphs. Meta-KGR uses training triples with highfrequency relations to find well-initialized parameters and fast adapt to few-shot relations. The meta information learned from high-frequency relations is helpful for few-shot relations. In experiments, our models achieve good performance on few-shot relations and outperform previous work in most cases. Some empirical analysis also demonstrates that our models are robust and generalized to different types of knowledge graphs.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>The histogram of relation frequency in the real-world knowledge graph Wikidata.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Algorithm 1 Meta-Learning for multi-hop reasoning over knowledge graphs</figDesc><table><row><cell cols="2">Require: p(R): distribution over relations</cell></row><row><cell cols="2">Require: α, β: learning rate hyperparameters</cell></row><row><cell cols="2">1: Randomly initialize θ for meta policy network</cell></row><row><cell cols="2">2: while not stop training do</cell></row><row><cell>3:</cell><cell>Sample batch of relations r ∼ p(R)</cell></row><row><cell>4:</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Statistics of datasets.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>Experimental results for robustness analysis.</figDesc><table /><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The work is supported by NSFC key projects (U1736204, 61533018, 61661146007), Ministry of Education and China Mobile Joint Fund (MCM20170301), and THUNUS NExT Co-Lab.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Translating embeddings for modeling multirelational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Garcia-Duran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oksana</forename><surname>Yakhnenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Variational knowledge graph reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xifeng</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">Yang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Go for a walk and arrive at the answer: Reasoning over paths in knowledge bases using reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajarshi</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shehzaad</forename><surname>Dhuliawala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manzil</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Vilnis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishan</forename><surname>Durugkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akshay</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Convolutional 2d knowledge graph embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Dettmers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pasquale</forename><surname>Minervini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pontus</forename><surname>Stenetorp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Cognitive graph for multi-hop reading comprehension at scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qibin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongxia</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Model-agnostic meta-learning for fast adaptation of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Meta-learning for lowresource neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiatao</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">K</forename><surname>Victor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Fewrel: A large-scale supervised few-shot relation classification dataset with state-of-the-art evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengfei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziyun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Human-level concept learning through probabilistic program induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Brenden M Lake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">350</biblScope>
			<biblScope unit="issue">6266</biblScope>
			<biblScope unit="page" from="1332" to="1338" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Multi-hop knowledge graph reasoning with reward shaping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Xi Victoria Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">End-toend differentiable proving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Rocktäschel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Reinforcewalk: Learning to walk in graph with monte carlo tree search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yelong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianshu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Po-Sen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuqing</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Open-world knowledge graph completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baoxu</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Weninger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Representing text for joint embedding of text and knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Pantel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hoifung</forename><surname>Poon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pallavi</forename><surname>Choudhury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Gamon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Dynamically fused graph network for multi-hop reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunxuan</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanru</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weinan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Representation learning of knowledge graphs with entity descriptions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruobing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huanbo</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Deeppath: A reinforcement learning method for knowledge graph reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thien</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">Yang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">One-shot relational learning for knowledge graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiyu</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxiao</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">Yang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Embedding entities and relations for learning and inference in knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bishan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Differentiable learning of logical rules for knowledge base reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Hotpotqa: A dataset for diverse, explainable multi-hop question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saizheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
