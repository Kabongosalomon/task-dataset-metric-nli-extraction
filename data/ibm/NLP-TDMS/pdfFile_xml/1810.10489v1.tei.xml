<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Forecasting Individualized Disease Trajectories using Interpretable Deep Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmed</forename><forename type="middle">M</forename><surname>Alaa</surname></persName>
							<email>ahmedmalaa@ucla.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Electrical and Computer Engineering Department</orgName>
								<orgName type="laboratory">Mihaela van der Schaar</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>90095-1594</postCode>
									<settlement>Los Angeles Los Angeles</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Electrical Engineering Department</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>90095-1594</postCode>
									<settlement>Los Angeles Los Angeles</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Forecasting Individualized Disease Trajectories using Interpretable Deep Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note type="submission">Editor: XXXXX</note>
					<note>FORECASTING INDIVIDUALIZED DISEASE TRAJECTORIES</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T12:24+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Disease progression modeling</term>
					<term>recurrent neural networks</term>
					<term>state-space models</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Disease progression models are instrumental in predicting individual-level health trajectories and understanding disease dynamics. Existing models are capable of providing either accurate predictions of patients' prognoses or clinically interpretable representations of disease pathophysiology, but not both. In this paper, we develop the phased attentive state space (PASS) model of disease progression, a deep probabilistic model that captures complex representations for disease progression while maintaining clinical interpretability. Unlike Markovian state space models which assume memoryless dynamics, PASS uses an attention mechanism to induce "memoryful" state transitions, whereby repeatedly updated attention weights are used to focus on past state realizations that best predict future states. This gives rise to complex, non-stationary state dynamics that remain interpretable through the generated attention weights, which designate the relationships between the realized state variables for individual patients. PASS uses phased LSTM units (with time gates controlled by parametrized oscillations) to generate the attention weights in continuous time, which enables handling irregularly-sampled and potentially missing medical observations. Experiments on data from a real-world cohort of patients show that PASS successfully balances the tradeoff between accuracy and interpretability: it demonstrates superior predictive accuracy and learns insightful individual-level representations of disease progression.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Chronic diseases -such as cardiovascular disease, cancer and diabetes -progress slowly throughout a patient's lifetime, causing increasing burden to the patients, their carers, and the healthcare delivery system <ref type="bibr" target="#b31">Sevick et al. (2007)</ref>. Modern electronic health records (EHR) keep track of individual patients' disease progression trajectories through follow-up data sequences of the form (X1, ..., Xt), where Xt is a set of clinical observations collected for the patient at time t. The advent of EHRs 1 provides an opportunity for building models of disease progression that can fulfill two central goals of healthcare delivery systems: Goal A entails the supervised problem of predicting future clinical observations (Xt+1, Xt+2, . . .) on the basis of past observations (X1, . . ., Xt). Goal B entails the unsupervised problem of discovering clinically-interpretable latent structures that explain the mechanisms underlying disease progression. Both goals A and B are entangled. This is because accurate predictions need to be transparent and interpretable in order to ensure their actionability, whereas interpretable representations explaining disease progression can only be trustworthy if they possess high predictive power.</p><p>Unfortunately, as a consequence of the inherent tension between model accuracy and interpretability Lipton (2016), most existing models of disease progression fulfill either Goal A or Goal b, but not both. State-of-the-art prediction performance is achieved by models based on recurrent neural networks (RNN) <ref type="bibr" target="#b19">Lim and van der Schaar (2018)</ref>; ; <ref type="bibr" target="#b9">Choi et al. (2016a)</ref>. RNN-based models are often used for sequence prediction (or sequence labeling), where they are trained to estimate the predictive distribution P (Xt | Xt−1, ..., X1) by propagating a sequence of hidden states (Z1, ..., Zt) through intermediate deterministic mappings <ref type="figure">(Figure 1a</ref>). Unfortunately, an RNN is of a "black-box" nature since its hidden states (Z1, ..., Zt) do not explicitly map to clinically meaningful states of disease progression. On the contrary, state space approaches based on Hidden Markov Models (HMM) provide a natural interpretation of a disease trajectory as a sequence of transitions between latent "progression stages" (Z1, ..., Zt) <ref type="figure">(Figure 1b)</ref>, each of which corresponds to a clinically distinguishable disease state Alaa and van der Schaar (2018); ; <ref type="bibr" target="#b37">Wang et al. (2014)</ref>. However, the interpretability of HMMs comes at a price. That is, while RNNs can in principle approximate any dynamical system, an HMM is limited to memoryless Markovian state dynamics, which greatly undermine its predictive performance.</p><p>Our Contribution In this paper, we develop a deep probabilistic model of disease progression that capitalizes on both the predictive power of RNNs and the interpretable nature of state space models to fulfill Goals A and B. Our model maintains the probabilistic structure of a state space representation, which decouples emission and transition distributions, but uses an RNN to model a flexible non-Markovian state transition dynamic P (Zt | Zt−1, ..., Z1) that allows future states to depend on all past states. To model state transitions, we use an attention mechanism whereby the RNN generates a (repeatedly updated) set of attention weights (α 1 , ..., α t ) that designate the (relative) influence that past state realizations (Z1, ..., Zt) have on the transition probabilities to the future state Zt+1. Our model for state transitions can be summarized as follows:</p><formula xml:id="formula_0">(α t 1 , ..., α t t ) = RNN(X 1 , ..., X t ), P (Z t+1 = z) = i≤t α t i × P (Z t = z | Z i = z ).</formula><p>The model described above, which we call an attentive state space model, uses a set of RNNgenerated attention weights to induce a time-varying Markov blanket for the state variable Zt. This Markov blanket changes for every new state transition, putting more or less attention on previous state realizations depending on the patient's clinical history. If we restrict the attention weights to be binary (α t i ∈ {0, 1}, ∀i ≤ t), the attentive state space becomes a variable-order Markov model that decides the extent of memory involved in state transitions in every time step depending on the patient's current context. This allows for realistic non-stationary and time-inhomogeneous dynamics that are implicitly captured by an RNN but could not be possibly modeled with an HMM. The attentive state representation is clinically interpretable because the complex state dynamics that it captures are fully explicable through the attention weights, which indicates the extent to which past clinical events contribute to future state realizations. <ref type="figure">Figure 1c</ref> provides a formal graphical model for our attentive state space representation. <ref type="figure">Figure 1d</ref> shows an unrolled graphical depiction of the model for a particular exemplary patient, highlighting the time-varying nature of the attention weights and their straightforward interpretational benefit.</p><p>Because EHR data comprises irregularly-sampled and asynchronous observations gathered only at the times when the patient visits a hospital, we use the phased LSTM units introduced in <ref type="bibr" target="#b27">Neil et al. (2016)</ref>, with time gates controlled by parametrized oscillations, in order to generate the attention weights at arbitrary time instances. Thus, we call our model a phased attentive state space (PASS) model. A detailed description of the construction of the PASS model is provided in Section 2. A detailed comparison between PASS and related models can be found in Section 4.</p><p>Indeed, state inference and parameter estimation of PASS is nontrivial since non-Markovianity hinders the application of conventional backward message passing algorithms Alaa and van der Schaar (2018); <ref type="bibr" target="#b13">Dai et al. (2016)</ref>. In Section 3, we show that PASS can be re-parameterized as a nonstationary dynamic Bayesian network, for which conventional forward message passing algorithms can be implemented with a complexity resembling that of the forward filtering algorithm used for HMMs. We conduct parameter estimation via a variant of the Expectation-Maximization algorithm. In Section 5, we conduct experiments on data from a real-world longitudinal cohort of more than 10,000 Cystic Fibrosis (CF) patients. Our experiments show that PASS successfully balances the tradeoff between accuracy and interpretability: it demonstrates superior predictive accuracy and learns insightful individual-level representations of disease progression. In particular, we show that PASS learns meaningful population-level CF progression stage, and that the attention weights can inform treatment decisions on the level of individual patients.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">A Phased Attentive State-space Model of Disease Progression</head><p>We model the progression of a target chronic disease using longitudinal EHR data for patients who have developed, or are at risk of developing such disease. We start by describing the model variables in Section 2.1, and then we develop the attentive state dynamics in Sections 2.2 and 2.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Model Variables and Notation</head><p>Structure of the EHR data A patient's EHR record, denoted as D, is a collection of timestamped follow-up data gathered during repeated, irregularly-spaced hospital visits, in addition to static features (e.g., genetic variables). We represent a given patient's EHR record as follows:</p><formula xml:id="formula_1">D = {Y } Static features ∪ {(X m , t m Visit times )} M m=1 ,<label>(1)</label></formula><p>where Y is the static features' vector, Xm is the follow-up data collected in the m th hospital visit, tm is the time of the m th visit, and M is the total number of hospital visits. (The time-horizon t is taken to be the patient's chronological age.) The follow-up data Xm comprises information on biomarkers and clinical events, such as treatments and diagnoses of comorbidities. (Refer to the Appendix for a more elaborate discussion on the type of follow-up data collected in EHRs.) An EHR dataset</p><formula xml:id="formula_2">{D (i) } N i=1</formula><p>is an assembly of records for N independent patients. Disease progression stages We assume that the target disease evolves through D different progression stages. Each stage corresponds to a distinct level of disease severity that manifests through the follow-up data. We model the evolution of progression stages via a (continuous-time) stochastic process Z(t) of the following form:</p><formula xml:id="formula_3">Z(t) = n∈N +Z n · 1 {Tn &lt; t ≤ T n+1 } ,Z n ∈ {1, . . ., D},</formula><p>where {Tn}n is the sequence of onsets for the realized progression stages, andZn is the progression stage occupying the interval <ref type="bibr">(Tn,</ref><ref type="bibr">Tn+1]</ref>. We assume that Z(0) = 1 (i.e.,Z1 = 1) almost surely, with stage 1 being the asymptomatic stage designating "healthy" patients. The sequence {Zm}m is the embedded discrete-time process induced by Z(t) at the hospital visit times {tm}m, i.e. Zm = Z(tm).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Attentive State Space Representation</head><p>We adopt a state space representation for the disease progression process, with the state space being the set of all stages of progression {1, . . . , D}. The states' sequence {Zm}m is hidden whereas the EHR data D is observed. We consider a graphical model that defines probabilistic dependencies between {Zm}m and D through the following factorization of emission and transition distributions:</p><formula xml:id="formula_4">P ({Z m } m , {X m } m | Y , {t m } m ) = m m =1 P (X m | Z m ) Emission · P (Z m | F t m −1 ) Transition ,<label>(2)</label></formula><p>where Ft m = {Y , (Z1, X1, t1), . . . , (Z m , X m , t m )} conveys all the information available in the model up to time t m . We model the emission distribution in (2) as a Gaussian distribution with state-specific parameters as follows:</p><formula xml:id="formula_5">P (X m | Z m = z) = N (µ z , Σ z ), z ∈ {1, . . . , D}.<label>(3)</label></formula><p>Binary variables are modeled with a Bernoulli state-specific distributions. The transition probability factor in (2) assumes that the realized state at time tm depends on the entire process history Ft m−1 . To model P (Z m | Ft m −1 ), we first define a D × D baseline Markov generator matrix Λ as follows:</p><formula xml:id="formula_6">Λ =        −λ 12 λ 12 0 . . . 0 0 −λ 23 λ 23 . . . 0 . . . . . . . . . . . . . . . 0 . . . 0 −λ D−1,D λ D−1,D 0 . . . 0 0 0        ,<label>(4)</label></formula><p>λij ≥ 0, ∀i, j ∈ {1, . . . , D}, where λij is a Markovian transition rate from state i to state j. Λ is the transition rate matrix of a continuous-time Markov chain model on the state space {1, . . . , D}; its bidiagonal structure forces transitions to be permissible only between adjacent states (in an ascending order), with the last state (state D) being an absorbing state. This enforces the states in the set {1, . . . , D} to map properly to the disease progression stages (state 1 is the least severe stage and state D is the terminal stage of illness). We model the state transition probability P (Zm = z | Ft m−1 ) by creating a "memoryful" version of the Markov chain model in (4) through the following parametrization:</p><formula xml:id="formula_7">P (Z m = z | {(Z k = z k , α m k , ∆ k )} m−1 k=1 Sufficient statistics ) = m−1 k=1 α m k Attention weights (e ∆ k Λ ) z,z k ,<label>(5)</label></formula><p>where ∆ k = tm − t k is the time interval between the k th and the m th hospital visits, α m k ∈ [0, 1] is an attention weight assigned to the k th visit, with m−1 k=1 α m k = 1, and (e ∆ k Λ )z,z k is entry (z, z k ) of the exponentiation of matrix Λ. The attention weights in (5) are generated via an attention function ϕ with parameter Θ as follows:</p><formula xml:id="formula_8">(α m 1 , . . . , α m m−1 ) = ϕ(Y , t m , {(X 1 , t 1 )} m−1 j=1 ; Θ).<label>(6)</label></formula><p>We call the representation in (5) an attentive state space representation. As shown in <ref type="formula" target="#formula_7">(5)</ref> Similar to an HMM model, the factorization in (2) decouples the transition and emission distributions by assuming that Zm d-separates Xm from all other variables. This decoupling ensures that the clinical interpretability of the hidden states is maintained since each state is associated with a distinct emission distribution for the observed follow-up data. Moreover, regardless of the choice of the attention function ϕ, the attentive state transition matrix m−1 k=1 α m k e ∆ k Λ will always be interpretable because the influence that a previous progression stage has on the future progression trajectory is encoded in its corresponding attention weight.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">The Phased Attention Mechanism</head><p>To implement the attentive state dynamics, the attention weights in (6) must be repeatedly updated (after each hospital visit) using variable-length sequences of data. Hence, we model the attention function ϕ as an RNN that maps a patient's history to attention weights as follows:</p><formula xml:id="formula_9">h m−1 , . . . , h 1 = pLSTM ({(X m−j , ∆ j,m )} m−1 j=1 ); Θ), e j = w T h j + b, ∀j ∈ {1, . . . , m − 1}, (α m 1 , . . . , α m m−1 ) = Softmax(e 1 , . . . , e m−1 ),<label>(7)</label></formula><p>where ∆j,m = tm−j+1 − tm−j, pLSTM is a phased LSTM network <ref type="bibr" target="#b27">Neil et al. (2016)</ref>, w and b are the output layer parameters, hj is the hidden layer, andXj = [Y , Xj, tj] is the input at time step j. Unlike traditional RNNs, a phased LSTM takes a timestamped sequence as an input, and performs updates at arbitrary points of time. Phased LSTMs can also handle asynchronously-sampled sequences, which is particularly important for EHR data as not all of the components of Xm are necessarily measured in each hospital visits. Through phased LSTMs, we can update the attention weights with whatever follow-up data available at arbitrary time instances without the need for explicitly imputing missing observations. We call the attention mechanism in (7) the phased attention mechanism. The PASS model is an attentive state space model that uses the phased attention mechanism.</p><p>In the m th time step, phased attention operates by feeding the phased LSTM with the sequence {Xj} m−1 j=1 in reversed order, with timestamps reversed and shifted by tm as shown in <ref type="figure" target="#fig_2">Figure 2</ref> (left). This allows all attention weights allocated to all previous state realizations (or equivalently, hospital visits) to be dynamically updated at every time step while preserving the relative time spacing between hospital visits. The phased attention mechanism in (7) can be thought of as a continuoustime analogue of the reverse-time attention mechanism in <ref type="bibr" target="#b10">Choi et al. (2016b)</ref>.</p><p>The main difference between the phased LSTM model and the conventional LSTM model is the addition of a time gate, g t , which controls the updates to the LSTM cell state ct (and consequently the hidden layer ht). The opening and closing of the time gate g t for every neuron is controlled through an independent (continuous-time) rhythmic oscillation specified by 3 parameters (an oscillation period, a phase shift, and the ratio of the duration of the "open" phase to the full period) that can be learned from the data <ref type="bibr" target="#b27">Neil et al. (2016)</ref>. With every neuron having its own oscillatory parameters, the phased LSTM generates a continuum of possible updates that can be probed at arbitrary time instances as illustrated in <ref type="figure" target="#fig_3">Figure 3</ref> (right). The updated equations of the phased LSTM can be found in <ref type="bibr" target="#b27">Neil et al. (2016)</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Learning and Inference</head><p>In this Section, we present the parameter learning and state inference algorithms for the PASS model. Throughout this Section, we continue with a single patient EHR record for the ease of notation.</p><p>Parameter learning Let Γ be the set of all PASS model parameters, i.e. Γ = {Λ, (µ, Σ), Θ}, where µ = {µ z } D z=1 and Σ = {Σz} D z=1 are the emission parameters. The complete data log-likelihood of an EHR record D and a state sequence realization {Zm = zm}m is given by:</p><formula xml:id="formula_10">log(P (D, {z m } M m=1 | Γ)) = M m=1 log m−1 k=1 α m k · exp(Λ (t m − t k )) z k ,zm .<label>(8)</label></formula><p>Because the state sequence {Zm}m is hidden, the complete data likelihood in <ref type="formula" target="#formula_10">(8)</ref> is inaccessible, and hence we resort to the Expectation-Maximization (EM) algorithm. The EM algorithm operates iteratively to update its guess of Γ, where the i th iteration implements 2 steps:</p><formula xml:id="formula_11">E-step: Q(Γ |Γ (i) ) = E [ log (P (D, {Z m } m )) ] , M-step:Γ (i+1) = argmax Γ Q(Γ |Γ (i) ).<label>(9)</label></formula><p>Algorithm 1 lists the steps involved in implementing the EM algorithm in (9). In Step 1, we first infer the hidden states via a message passing algorithm (described later) using the current guess of Γ. Next, in Steps 2 and 3, we compute the attention weights associated with all hospital visit times, and then compute the transition probabilities using the formula in (5). In Step 4, the phased LSTM parameters are updated by optimizing the cross-entropy loss of the estimated transition probabilities and the inferred states. Maximum-likelihood is used to update the emission and transition parameters using the complete data likelihood obtained by plugging the inferred states into the expression in (8).</p><p>To updated the Markov generator matrix Λ, we use the Expm method in .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 EM algorithm for learning the PASS model parameters</head><p>Input: EHR data D, initial guessΓ (0) , state space {1, . . ., D} and number of iterations R.</p><p>Output: </p><formula xml:id="formula_12">Parameter estimateΓ = {Λ, (μ,Σ),Θ} while i ≤ R do 1 • {ẑ m } m ← Forward-Backward(D |Γ (i) ) 2 • (α m 1 , . . . ,α m m−1 ) ← ϕ((X m−1 , t m − t m−1 ), . . . , (X 1 , t m − t 1 );Θ (i) ), m ∈ {1, . . ., M } 3 •p m ← m−1 k=1α m k (e ∆ kΛ (i) )ẑ ,ẑ k m ∈ {1, . . ., M } 4 •Θ (i+1) ← argmin (− mẑ m · log(p m )) 5 •Λ (i+1) ← argmax log(P (D | {ẑ m } M m=1 , Λ) 6 • (μ (i+1) ,Σ (i+1) ) ← argmax log(P ({X m } m | {ẑ m } M m=1 ) 7 • i ← i + 1 end while</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>State inference</head><p>One key advantage of the attentive state construction in <ref type="formula" target="#formula_10">(8)</ref> is that the attention weights explicitly quantify the importance of each past state to any given future state. Thus, efficient inference can be conducted by limiting the Markov blanket for every state variable to "important" past states with attention weights exceeding a certain threshold. Since attention weights already decline as we go back in time, we approximate the Markov blanket for every state Z m by only considering the Q most recent states (Z m−1 , . . ., Z m−Q ). The resulting graphical model can be rearrange by lumping together every Q consecutive states into one "super state" (as shown in <ref type="figure" target="#fig_3">Figure  3</ref>), we retrieve a first-order Markovian dynamic Bayesian network (or equivalently, a higher-order Markov model Murphy and <ref type="bibr" target="#b25">Russell (2002)</ref>), for which standard forward and backward message passing apply.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Related Works</head><p>Previous works related to PASS fall into three areas: state space models of disease progression, RNN-based predictive models for healthcare applications, and (general-purpose) deep probabilistic models. In what follows, we discuss previous works in these three areas, and then conclude the Section by demonstrating the generality of the PASS model.</p><p>State space models of disease progression Almost all existing models of disease progression are based on variants of the HMM model <ref type="bibr" target="#b37">Wang et al. (2014)</ref>; ; <ref type="bibr" target="#b2">Alaa et al. (2017)</ref>. Disease dynamics in such models are very easily interpretable as they can be perfectly summarized through a single matrix of probabilities that describes the transition rates among the different disease states. Markovian dynamics also greatly simplify inference because the model likelihood factorizes in a way that makes efficient forward and backward message passing possible Murphy and <ref type="bibr" target="#b25">Russell (2002)</ref>. However, memoryless Markov models assume that a patient's current state d-separates her future trajectory from her clinical history. This renders HMM-based models incapable of properly explaining the heterogeneity in the patients' progression trajectories, which often results from their varying clinical histories or the chronologies (timing and order) of their experienced clinical events <ref type="bibr" target="#b33">Valderas et al. (2009)</ref>. This limitation is particularly crucial in complex chronic diseases that are accompanied with multiple morbidities. As discussed earlier, PASS addresses this limitation by creating memoryful state transitions that depend on the patient's entire clinical history. (In the Appendix material, we provide a detailed discussion on how PASS can better explain patient heterogeneity compared to Markov models.)</p><p>RNN-based predictive modeling for healthcare Various RNN-based predictive models have been recently developed for healthcare settings; examples of such models include Doctor AI <ref type="bibr" target="#b9">Choi et al. (2016a)</ref>, L2D , and Disease-Atlas <ref type="bibr" target="#b19">Lim and van der Schaar (2018)</ref>. All those methods do not attempt to model a disease progression trajectory, but rather predict target clinical events on the basis of (discrete) sequential observations. Because of their black-box nature, none of these models can help understand the mechanisms underlying disease progression.</p><p>There have been various attempts to create interpretable RNN-based predictive models using attention. The models in <ref type="bibr" target="#b10">Choi et al. (2016b)</ref> and <ref type="bibr" target="#b23">Ma et al. (2017)</ref> use the reverse-time attention mechanism to learn visit-level and variable-level attention weights that explain the prediction of a target label through measures of variable importance. The phased attention mechanism proposed in Section 2.3 is a generalization of the reverse-time attention mechanism in <ref type="bibr" target="#b10">Choi et al. (2016b)</ref> that can operate in continuous-time, and update the attention weights at irregularly-spaced and potentially incomplete observations. The main difference between the way attention is used in PASS and the way it is used in models like <ref type="bibr">RETAIN</ref>  <ref type="bibr" target="#b10">Choi et al. (2016b)</ref> can be summarized as follows. PASS applies attention to the latent state space, whereas RETAIN applies attention to the observable sample space. Hence, the attention mechanism gives different types of explanations in the two models. In PASS, the phased attention mechanism interprets the hidden disease dynamics, and hence it provides an explanation for the mechanisms underlying disease progression. On the contrary, RETAIN uses attention to measure feature importance, and hence it only explains predictions, but does not explain the disease progression mechanisms.</p><p>Deep probabilistic models Most existing works on deep probabilistic models have focused on developed structured inference algorithms for deep Markov models and their variants Krishnan  <ref type="bibr" target="#b11">Chung et al. (2015)</ref>, <ref type="bibr">SRNN Fraccaro et al. (2016)</ref>, and STORN <ref type="bibr" target="#b4">Bayer and Osendorfer (2014)</ref>. All such models augment stochastic layers to an RNN in order to enrich its output distribution. However, the transition and emission distributions in all these models cannot be decoupled, and hence their latent state representations would not lead to clinically meaningful identification of disease states. To the best of our knowledge, PASS is the first deep probabilistic model that provides both a clinically interpretable latent representation, and interpretable non-Markovian state dynamics.</p><p>Generality of the attentive state space representation For particular choices of the attention function in <ref type="formula" target="#formula_8">(6)</ref>, the attentive state space representation in (5) reduces to various classical models of sequential data. For instance, if ϕ always sets α m m−1 to 1 and all other weights to 0, then we retrieve an HMM. If the attention weights are binarized, then we retrieve a variable-order HMM <ref type="bibr" target="#b38">Willems et al. (1995)</ref>; <ref type="bibr" target="#b5">Begleiter et al. (2004)</ref>. Furthermore, if the attention weights are fixed, then we recover an auto-regressive model. This is a powerful feature of our model as it implies that by learning the attention function ϕ, we are effectively testing the assumptions of various commonly-used time series models in a data-driven fashion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head><p>To validate the PASS model, we conducted a set of experiments using retrospective data for a longitudinal cohort of cystic fibrosis (CF) patients. CF is a life-shortening chronic condition that causes severe lung dysfunction, and is the most common genetic disease in Caucasian populations <ref type="bibr" target="#b32">Szczesniak et al. (2017)</ref>. All experimental details are listed hereunder.</p><p>Recall that, as stated in Section 1, the main purpose of the PASS model is to simultaneously fulfill Goal A (predicting individualized disease trajectories) and Goal B (understanding disease progression mechanisms). Thus, in Sections 5.1 and 5.2, we evaluate our model with respect to both goals.</p><p>Data description. The dataset involved in the experiments was extracted from the UK CF registry, a database maintained by the UK CF trust 2 . Data was gathered from hospitals all over the UK, with 99% of patients consenting to their data being submitted, and hence the cohort is representative of the UK CF population. The dataset comprises longitudinal follow-ups for 10,263 patients over the period spanning between 2008 and 2015, with a total of 60,218 hospital visits. Each patient is associated with 90 variables, including the intake of 36 possible treatments, diagnoses for 31 possible comorbidities and 16 possible infections, FEV1 biomarkers, gender, and CF genetic mutations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Goal A: Predicting individual-level CF progression trajectories</head><p>Baselines. We compared the predictive accuracy of PASS to the following models:</p><p>MLP: A multi-layer perceptron (MLP) classifier that is trained to sequentially predict the clinical events in 1 hospital visit given the observations in the prior visits. The MLP is trained on a static dataset that is created by unrolling the longitudinal follow-up data for all patients and treating every hospital visit as a separate data point. <ref type="bibr" target="#b37">Wang et al. (2014)</ref>;  trained with the Baum-Welch EM algorithm. The number of HMM states was set via the Akaike information criterion (AIC). Similar to the PASS model, the observations (X1, . . ., Xt) are modeled as Gaussian emission variables with state-specific mean and variance parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>HMM: A standard continuous-time HMM model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RNN:</head><p>A standard LSTM network with 2 hidden layers of size 200. The follow-up data (X1, . . ., Xt) was used as an input, and the output was defined as a set of (binary) labels designating the prediction targets at every hospital visit. A sigmoid transformation was applied to the top hidden layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RETAIN:</head><p>An RNN-based reverse-time attention model proposed in <ref type="bibr" target="#b10">Choi et al. (2016b)</ref>. To ensure a fair comparison with PASS and the standard RNN benchmark, we implemented the attention layer of RETAIN via an LSTM with 2 hidden layers of size 200, and restricted its architecture to generate only visit-level attention. (This is equivalent to the RNN-α M benchmark in <ref type="bibr" target="#b10">Choi et al. (2016b)</ref>.)</p><p>The baseline algorithms above are selected so as to highlight the added value of every modeling component in PASS. That is, an MLP only uses current information to predict the future clinical outcomes, whereas an HMM only looks 1 step back but provides a fully-fledged probabilistic model for disease progression. On the other hand an RNN capture more flexible dynamics (and is more memoryful) than an HMM but lacks interpretability, whereas RETAIN can provide explanations for its predictions, but does not explain the actual mechanisms of disease progression.</p><p>Implementation of PASS. We implemented the phased LSTM in Section 3 with 2 hidden layers of size 200 in order to match the model complexity of RETAIN and the standard RNN baseline. Hospital visits after which a death event happens within 3 years were explicitly labeled as the absorbing state D in our model. The number of states D was tuned via cross-validation to optimize the accuracy of predicting mortality events. PASS was implemented in Tensorflow <ref type="bibr" target="#b0">Abadi et al. (2016)</ref>, and the phased attention layer was implemented via tf.contrib.rnn.PhasedLSTMCell.</p><p>Prediction tasks and evaluation metric. All models were used to sequentially predict the 1-year risk for 6 prognostic tasks of predicting 3 comorbidities and 3 lung infections that are common in the CF population. The comorbidities are Allergic bronchopulmonary aspergillosis (ABPA), diabetes and intestinal obstruction. The lung infections are Klebsiella Pneumoniae, E. coli and Aspergillus. We used the area under the ROC curve (AUC-ROC) with 5-fold cross-validation for performance evaluation, where error counts are taken over all patients and all hospital visits.</p><p>Results. The AUC-ROC performance of all models on the 6 prognostic tasks under consideration is provided in <ref type="table" target="#tab_0">Table 1</ref>. We note that CF is a very complex disease, for which patients encounter various possible comorbidities and are prescribed a wide variety of possible treatments. This leads to each patient having a very rich clinical history that influence their outcomes. Because HMMs fail to properly integrate the patients' rich clinical histories into the state dynamics, they displayed modest predictive performance on the 6 prognostic tasks. As we can see in <ref type="table" target="#tab_0">Table 1</ref>, the HMM model did not provide any significant improvement over the static MLP model in any of the prognostic tasks. On the contrary, RNN-based model provided significant improvements over the static MLP model on all of the 6 tasks. The results in <ref type="table" target="#tab_0">Table 1</ref> show that the predictive accuracy of PASS is comparable to that of the RNN-based models. Note that the standard RNN model issue predictions without modeling disease progression, and hence it does not offer any interpretation benefit, whereas RETAIN provides explanations only in the form of measures of variable importance. PASS, however, explicitly models the CF physiology (in terms of its latent progression stages), and hence it ensures the interpretational and modeling benefits of an HMM while maintaining the predictive accuracy of an RNN-based predictive model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Goal B: Understanding disease progression mechanisms</head><p>In this Section, we show that the PASS model successfully extracts meaningful clinical knowledge about the CF progression mechanisms. We also show how the PASS model parameters can inform clinical practitioners about the progression mechanisms for individual patients.</p><p>CF progression stages. Unlike many other chronic diseases, current clinical guidelines do not provide classifications for the progression stages of CF <ref type="bibr" target="#b32">Szczesniak et al. (2017)</ref>. In a completely unsupervised fashion, the PASS model successfully learned D = 3 progression stages (Stages I, II and III) that corresponded to clinically distinguishable levels of CF severity. The learned baseline Markov generator matrix for the transition rates among the 3 stages is given by:</p><formula xml:id="formula_13">Λ =   −0.0578 0.0578 0 0 −0.0691 0.0691 0 0 0   .<label>(10)</label></formula><p>From the baseline transition rates in <ref type="formula" target="#formula_1">(10)</ref>, it follows that the average occupancy of a patient in Stage I is 1 0.0578 = 17.30 years, and the occupancy in Stage II is around 1 0.0691 = 14.47 years. That is, a typical patient who is born with CF progresses to Stage II by adulthood, before reaching the terminal stage by the age of 31. These figures match the survival rates in CF populations, where the median lifetime is known to be as low as 40 years of age <ref type="bibr" target="#b24">McCarthy et al. (2013)</ref>. Note that the baseline generator matrix in (10) only describes population-level rates of progression: individual variability among patients are captured via the patient-specific attention weights.</p><p>The FEV1 % biomarker is the main spirometric measure of lung function that is currently used to guide clinical and therapeutic decisions. In order to check that the learned progression stages correspond to different levels of disease severity, we plot the estimated emission distribution for the FEV1 % biomarker in Stages I, II and III in <ref type="figure" target="#fig_5">Figure 4</ref>. As we can see from the emission distributions in <ref type="figure" target="#fig_5">Figure 4</ref>, the mean values of the FEV1 biomarker in each stage were 87%, 65% and 36%, respectively. This coincided with the current practice guidelines for referring critically-ill patients to a lung transplant, which recommends a transplant for patients with FEV1 &lt; 30%, monitoring for a transplant for patients with FEV1 ranging from 30% to 80%, and no transplant for patients with FEV1 above 80% Braun and Merlo (2011). Thus, the learned progression stages can be translated into actionable information for clinical decision-making. We also plot the emission probabilities (parameter of the Bernoulli distribution) for the 3 comorbidities in <ref type="table" target="#tab_0">Table 1</ref> at every stage. We can also see that the incidences of comorbidities increase significantly in the more severe Stages II and III as compared to Stage I.</p><p>In <ref type="figure" target="#fig_5">Figure 4</ref>, we also obtain the maximum a posterior inferences for the progression stages of every individual patient as described in Section 3, and plot the average attention weights assigned to the patients' last 6 hospital visits in every progression stage. We found that the attentive dynamics tend to be less relevant for patients in Stage I, where most of the attention is allocated to the most recent visit. Memory starts getting more important in Stages II and III, where the attention weights allocated to older hospital visits gets higher. This can be explained by the fact that patients in Stages II and III are more likely to have been diagnosed with more comorbidities in the past, and hence more segments of their clinical history matters for predicting their outcomes.</p><p>Significance of attention weights for individual patients. How can clinicians interpret and make use of the generated attention weights for the patient at hand? One important way to utilize the attention weights is to reason about the effect of different treatment decisions and how their outcomes are impacted by the patient's history. For the sake of illustrating this point, in <ref type="figure" target="#fig_6">Figure 5</ref> we pick an out-of-sample patient who has repeatedly visited the hospital over the years 2012, 2013 and 2014. We see the attention weights generated by the PASS model can inform the clinician about the potential efficacy of the Ivacaftor treatment (a gene targeted therapy <ref type="bibr" target="#b35">Wainwright et al. (2015)</ref>) prescribed for this particular patient in the year 2014 by predicting the risk of progression to Stage III of lung function severity by the year 2015.</p><p>The inferred progression stage for the patient was Stage II for all of the 3 hospital visits. We toggle the patient's follow-up data vector X 3 (in year 2014) to let the variable indicating the prescription of the Ivacaftor drug be once set to 0 and once set to 1, and compute the probability of progressing to Stage III by the year 2015 in each case. We found that assigning Ivacaftor treatment to this patients is actually associated with an elevated risk of progressing to the severe Stage III within 1 year. By inspecting at the attention weights, we found that most attention is assigned to the most recent visit when Ivacaftor treatment is not prescribed, but the highest attention is paid to the follow-up data in 2012 when Ivacaftor is prescribed. The patient's follow-up data in year 2012 included a diagnosis with Liver disease. Hence, the elevated risk of progression upon taking the Ivacaftor treatment may be linked to its side effects concerning liver function complication, which may exacerbate the patient's liver disease. The PASS model altered the state dynamics to take into account the 2-year old follow-up data that is only important in determining the state dynamics conditional on prescription of an Ivacaftor treatment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Detailed structure of the EHR data</head><p>A patient's EHR record, denoted as E, is a collection of timestamped follow-up data gathered during repeated, irregularly-spaced hospital visits, in addition to static features of the patient (e.g., genetic variables). We represent a given patient's EHR record as follows:</p><formula xml:id="formula_14">E = {Y } Static features ∪ {(X m , t m Visit times )} M m=1 , Follow-up data =⇒ X m = u m Treatments , C m Anchors , O m Observations ,</formula><p>where Y is the static features' vector, Xm is the follow-up data collected in the m th hospital visit, tm is the time of the m th visit, and M is the total number of hospital visits. (The time-horizon t is taken to be the patient's chronological age.) The follow-up data vector Xm comprises three components:</p><p>Treatments indicator (um ∈ {0, 1} U ): A binary vector indicating the prescription of (a subset of) U possible treatments to the patient during the m th hospital visit.</p><p>Anchor findings (Cm ∈ {0, 1} K ): A binary vector indicating the presence of concrete diagnoses (i.e., ICD or HCPCS codes <ref type="bibr" target="#b6">Blumenthal and Tavenner (2010)</ref>) for K distinct comorbidities that may co-occur with the target disease.</p><p>Clinical observations (Om ∈ R O ): A set of laboratory-measured biomarkers that reflect the severity of the target disease.</p><p>An EHR dataset D is an assembly of records for N patients, i.e., D = {E (i) } N i=1 . <ref type="figure">Figure 6</ref> provides an illustration for the structure of the EHR data. E08.9 N18.9 Z94.2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stage I</head><p>Stage II <ref type="figure">Figure 6</ref>: Illustration for the structure of the EHR data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Comparison between Markovian and attentive state dynamics</head><p>Because Markovianity simplifies inference, most existing models of disease progression are based on HMMs (e.g., Alaa et al. <ref type="formula" target="#formula_1">(2017)</ref>, , and <ref type="bibr" target="#b37">Wang et al. (2014)</ref>). However, memoryless Markovian dynamics hinder a model's capacity for "explaining" individual-level progression trajectories. This is because under a Markov model, all patients at the same stage of progression would have the same expected future trajectory, irrespective of their potentially different individual clinical histories (i.e., the timing and order of treatments and comorbidities). That is, a Markov model captures the population-level transition rates among progression stages, but explains away individual-level variations in progression trajectories through the randomness of the transition probability P (Zm | Zm−1, tm − tm−1). This can render Markov models highly misleading since clinical actions are taken on an individual basis.</p><p>Interpreting the attentive state dynamics Now we use an illustrative example to show how a clinician can interpret the attentive state dynamics for individual patients, and highlight the information that is missed by Markovian dynamics but can be captured via attentive dynamics.</p><p>In <ref type="figure" target="#fig_8">Figure 7</ref>, we display exemplary progression trajectories for 2 chronic kidney disease (CKD) patients through the unrolled graphical model of the DBN in <ref type="formula" target="#formula_4">(2)</ref>. With a slight abuse of graphical model notation, we let the thickness of the arrows connecting states be proportional to the attention weights generated for predicting the state transition in the third hospital visit. Patients A and B have identical trajectories at the first 2 visits (both are diagnosed with hypertension and are in the same progression stages), with one exception being that Patient A is administered a medication for hypertension (ACE inhibitors) in the first visit. Patient B transits from stage 2 to stage 3 CKD because of hypertensive renal complications, whereas patient A stays in stage 2 thanks to the medication. The attentive model can capture the difference between the 2 trajectories by paying attention to the first visit for Patient A (when the medication was prescribed), and little attention to the same visit for Patient B. By visually inspecting the attention weights assigned to past states of each individual patient, clinicians can interpret the decreased risk for Patient A (compared to Patient B) to be a result of the clinical events that Patient A encountered in the first visit (i.e., administration of ACE inhibitors). On the contrary, a memoryless Markov model would not be able to distinguish the different trajectories that Patients A and B exhibit as both patients are in Stage 2 CKD during the second visit.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Unrolled graphical depiction for an attentive state space Figure 1: Depictions for different models of sequential data: (a) Graphical model for an RNN. ♦ denotes a deterministic intermediate representation, (b) Graphical model for an HMM. denotes probabilistic states, (c) Graphical model for the proposed attentive state space model. (c) Unrolled graphical depiction for an attentive state space. Thickness of the arrows reflect the attention weights. Goal A: Predicting individual-level disease trajectories. Goal B: Understanding disease progression mechanisms.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>, the attentive representation starts with a baseline Markov chain, and creates memory in state transitions by weighting the baseline Markovian transition probabilities from all previous states, i.e. {e ∆ k Q } m−1 k=1 , using a set of attention weights {α m k } m−1 k=1 . (The attention weights are generated on the basis of a patient's static features and follow-up data.) That is, instead of the memoryless Markovian dynamics in which a new state realization Zm+1 is fully determined by the current realization Zm, the attentive state dynamics pay attention to all previous realizations in proportion to their attention weights. This gives rise to "memoryful", non-stationary, and time-inhomogeneous state transitions, whereby the time-varying Markov blanket (sufficient statistic) {(Z k , α m k , ∆ k )} m−1 k=1 of every new state realization Zm determines which state realizations in the past matter most for the future.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Illustration of phased attention mechanism. Left: Architecture of the phased attention network. The follow-up data (augmented with the static features) are fed in a reversed order into the phased LSTM, with reversed and shifted timestamps for the hospital visits. Right: Illustration for the operation of the phased LSTM. The time gate g t of 4 neurons are depicted; each has different oscillatory parameters. The contents of the cell state ct decay as we go backwards in time, implying lesser attention for older hospital visits.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Rearranged super states for the attentive model in Figure 1c with truncated attention and Q = 1. The resulting graphical model (right) corresponds to a standard Hidden Markov model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>et al. (2017); Dai et al. (2016); Karl et al. (2016); Johnson et al. (2016). All such models use neural networks to model the transition and emission distributions, but are limited to Markovian dynamics. Other works develop stochastic versions of RNNs for the sake of generative modeling; examples include variational RNNs</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Depiction for the distributions of clinical observations and generated attention in the 3 learned progression stages.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 :</head><label>5</label><figDesc>Usage of the PASS attention weights to reason about treatment decisions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 7 :</head><label>7</label><figDesc>Depiction for the attentive state dynamics.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Performance of the different competing models for the 6 prognostic tasks under consideration.</figDesc><table><row><cell></cell><cell>ABPA</cell><cell>Diabetes</cell><cell>I. Obstruction</cell><cell>K. Pneumoniae</cell><cell>E. Coli</cell><cell>Aspergillus</cell></row><row><cell>Model</cell><cell>AUC-ROC</cell><cell>AUC-ROC</cell><cell>AUC-ROC</cell><cell>AUC-ROC</cell><cell>AUC-ROC</cell><cell>AUC-ROC</cell></row><row><cell>PASS</cell><cell>0.687 ± 0.022</cell><cell>0.771 ± 0.012</cell><cell>0.577 ± 0.018</cell><cell>0.718 ± 0.026</cell><cell>0.701 ± 0.019</cell><cell>0.640 ± 0.011</cell></row><row><cell>RETAIN</cell><cell>0.685 ± 0.026</cell><cell>0.764 ± 0.014</cell><cell>0.578 ± 0.014</cell><cell>0.715 ± 0.031</cell><cell>0.697 ± 0.015</cell><cell>0.641 ± 0.010</cell></row><row><cell>RNN</cell><cell>0.681 ± 0.016</cell><cell>0.762 ± 0.021</cell><cell>0.577 ± 0.010</cell><cell>0.719 ± 0.036</cell><cell>0.696 ± 0.014</cell><cell>0.641 ± 0.012</cell></row><row><cell>HMM</cell><cell>0.666 ± 0.021</cell><cell>0.755 ± 0.031</cell><cell>0.551 ± 0.014</cell><cell>0.689 ± 0.021</cell><cell>0.665 ± 0.013</cell><cell>0.620 ± 0.009</cell></row><row><cell>MLP</cell><cell>0.657 ± 0.036</cell><cell>0.751 ± 0.056</cell><cell>0.553 ± 0.024</cell><cell>0.685 ± 0.052</cell><cell>0.656 ± 0.018</cell><cell>0.601 ± 0.012</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">. https://www.cysticfibrosis.org.uk/the-work-we-do/uk-cf-registry/</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Tensorflow: a system for large-scale machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martín</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjay</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Isard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">OSDI</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="265" to="283" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A hidden absorbing semi-markov model for informatively censored temporal data: Learning and inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihaela</forename><surname>Alaa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Der Schaar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning from clinical judgments: Semimarkov-modulated marked hawkes processes for risk prognosis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Ahmed M Alaa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihaela</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Der Schaar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Black box variational inference for state space models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Archer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Memming</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><surname>Buesing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Cunningham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liam</forename><surname>Paninski</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.07367</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Learning stochastic recurrent networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Bayer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Osendorfer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1411.7610</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">On prediction using variable order markov models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ron</forename><surname>Begleiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ran</forename><surname>El-Yaniv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Golan</forename><surname>Yona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="385" to="421" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The &quot;meaningful use&quot; regulation for electronic health records</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Blumenthal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marilyn</forename><surname>Tavenner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">New England Journal of Medicine</title>
		<imprint>
			<biblScope unit="volume">363</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="501" to="504" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Cystic fibrosis lung transplantation. Current opinion in pulmonary medicine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><forename type="middle">A</forename><surname>Braun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Merlo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="467" to="472" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Deep computational phenotyping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengping</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Kale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenzhe</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><forename type="middle">Taha</forename><surname>Bahadori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="507" to="516" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Doctor ai: Predicting clinical events via recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><forename type="middle">Taha</forename><surname>Bahadori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Schuetz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Walter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimeng</forename><surname>Stewart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning for Healthcare Conference</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="301" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Retain: An interpretable predictive model for healthcare using reverse time attention mechanism</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><forename type="middle">Taha</forename><surname>Bahadori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimeng</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><surname>Kulas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Schuetz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Walter</forename><surname>Stewart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3504" to="3512" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A recurrent latent variable model for sequential data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyoung</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyle</forename><surname>Kastner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Dinh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kratarth</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Aaron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2980" to="2988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Management of chronic kidney disease comorbidities. CKD medscape CME expert column series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dw Coyne</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Recurrent hidden semi-markov model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanjun</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan-Ming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Sequential neural models with stochastic layers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Fraccaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Søren Kaae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulrich</forename><surname>Sønderby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ole</forename><surname>Paquet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Winther</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2199" to="2207" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Composing graphical models with neural networks for structured representations and fast inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Duvenaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wiltschko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ryan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandeep R</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Datta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2946" to="2954" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Deep variational bayes filters: Unsupervised learning of state space models from raw data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maximilian</forename><surname>Karl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maximilian</forename><surname>Soelch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Bayer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Van Der</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smagt</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.06432</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Foundations of the Theory of Probability: Second English Edition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><surname>Nikolaevich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kolmogorov</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>Courier Dover Publications</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Structured inference networks for nonlinear state space models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uri</forename><surname>Rahul G Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Shalit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sontag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2101" to="2109" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Disease-atlas: Navigating disease trajectories with deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihaela</forename><surname>Van Der Schaar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning for Healthcare Conference (MLHC)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zachary C Lipton</surname></persName>
		</author>
		<title level="m">The mythos of model interpretability. ICML Workshop on Human Interpretability of Machine Learning</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Learning to diagnose with lstm recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zachary C Lipton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Kale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Randall</forename><surname>Elkan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wetzel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Efficient learning of continuous-time hidden markov models for disease progression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Ying</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fuxin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">M</forename><surname>Rehg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3600" to="3608" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Dipole: Diagnosis prediction in healthcare via attention-based bidirectional recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fenglong</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radha</forename><surname>Chitta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quanzeng</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1903" to="1911" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The cf-able score: a novel clinical prediction rule for prognosis in patients with cystic fibrosis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cormac</forename><surname>Mccarthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Borislav</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dimitrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Imran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cedric</forename><surname>Meurling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noel</forename><forename type="middle">G</forename><surname>Gunaratnam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mcelvaney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Chest</title>
		<imprint>
			<biblScope unit="volume">143</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1358" to="1364" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Dynamic bayesian networks: representation, inference and learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><forename type="middle">Patrick</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Murphy</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stuart</forename><surname>Russell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Illness trajectories and palliative care</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Scott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marilyn</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kirsty</forename><surname>Kendall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aziz</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sheikh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMJ: British Medical Journal</title>
		<imprint>
			<biblScope unit="volume">330</biblScope>
			<biblScope unit="issue">7498</biblScope>
			<biblScope unit="page">1007</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Phased lstm: Accelerating recurrent network training for long or event-based sequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Neil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Pfeiffer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shih-Chii</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3882" to="3890" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A dual-stage attention-based recurrent neural network for time series prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yao</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongjin</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guofei</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Garrison</forename><surname>Cottrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Joint Conference on Artificial Intelligence (IJCAI&apos;17</title>
		<meeting>the 26th International Joint Conference on Artificial Intelligence (IJCAI&apos;17</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Global strategy for the diagnosis, management, and prevention of chronic obstructive pulmonary disease: Gold executive summary</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suzanne</forename><surname>Klaus F Rabe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Hurd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Anzueto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sonia</forename><forename type="middle">A</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Buist</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshinosuke</forename><surname>Calverley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christine</forename><surname>Fukuchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Jenkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Rodriguez-Roisin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Weel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American journal of respiratory and critical care medicine</title>
		<imprint>
			<biblScope unit="volume">176</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="532" to="555" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A framework for individualizing predictions of disease trajectories by exploiting multi-resolution structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Schulam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suchi</forename><surname>Saria</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="748" to="756" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Patients with complex chronic diseases: perspectives on supporting self-management</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mary</forename><forename type="middle">Ann</forename><surname>Sevick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeanette</forename><forename type="middle">M</forename><surname>Trauth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bruce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Roger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gretchen</forename><forename type="middle">A</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amy</forename><forename type="middle">M</forename><surname>Piatt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert M</forename><surname>Kilbourne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Goodman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of general internal medicine</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="438" to="444" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Phenotypes of rapid cystic fibrosis lung disease progression during adolescence and young adulthood</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rhonda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Szczesniak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiji</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cole</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Brokamp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Pestian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John P</forename><surname>Seid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Clancy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American journal of respiratory and critical care medicine</title>
		<imprint>
			<biblScope unit="volume">196</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="471" to="478" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Defining comorbidity: implications for understanding health and health services</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jose</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Valderas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonnie</forename><surname>Starfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Sibbald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Salisbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Roland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Family Medicine</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="357" to="363" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Łukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6000" to="6010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Lumacaftorivacaftor in patients with cystic fibrosis homozygous for phe508del cftr</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><forename type="middle">E</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonnie</forename><forename type="middle">W</forename><surname>Stuart Elborn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gautham</forename><surname>Ramsey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohong</forename><surname>Marigowda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carla</forename><surname>Cipolli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jane</forename><forename type="middle">C</forename><surname>Colombo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kris</forename><forename type="middle">De</forename><surname>Davies</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><forename type="middle">A</forename><surname>Boeck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Flume</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">New England Journal of Medicine</title>
		<imprint>
			<biblScope unit="volume">373</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="220" to="231" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Attention-based mixture density recurrent networks for historybased recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tian</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.07545</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Unsupervised learning of disease progression models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Sontag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 20th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="85" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">The context-tree weighting method: basic properties</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Frans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuri</forename><forename type="middle">M</forename><surname>Willems</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tjalling J</forename><surname>Shtarkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tjalkens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="653" to="664" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xun</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manzil</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amr</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.11179</idno>
		<title level="m">State space lstm models with particle mcmc inference</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
