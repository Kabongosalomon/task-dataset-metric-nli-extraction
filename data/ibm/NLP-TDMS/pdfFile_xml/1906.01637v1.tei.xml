<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Collaborative Translational Metric Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chanyoung</forename><surname>Park</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donghyun</forename><surname>Kim</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Xie</surname></persName>
							<email>xingx@microsoft.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwanjo</forename><surname>Yu</surname></persName>
							<email>hwanjoyu@postech.ac.kr</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">South</forename><surname>Korea</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Oath</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Usa</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Computer Science and Engineering</orgName>
								<address>
									<postBox>POSTECH</postBox>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft Research Asia</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Collaborative Translational Metric Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T09:40+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-Recommender system</term>
					<term>Metric learning</term>
					<term>Collab- orative filtering</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recently, matrix factorization-based recommendation methods have been criticized for the problem raised by the triangle inequality violation. Although several metric learningbased approaches have been proposed to overcome this issue, existing approaches typically project each user to a single point in the metric space, and thus do not suffice for properly modeling the intensity and the heterogeneity of user-item relationships in implicit feedback. In this paper, we propose TransCF to discover such latent user-item relationships embodied in implicit user-item interactions. Inspired by the translation mechanism popularized by knowledge graph embedding, we construct useritem specific translation vectors by employing the neighborhood information of users and items, and translate each user toward items according to the user's relationships with the items. Our proposed method outperforms several state-of-the-art methods for top-N recommendation on seven real-world data by up to 17% in terms of hit ratio. We also conduct extensive qualitative evaluations on the translation vectors learned by our proposed method to ascertain the benefit of adopting the translation mechanism for implicit feedback-based recommendations.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>The recent explosive growth of information on the Internet inundates users with choices, and recommender systems play a crucial role not only in helping users in their decision making, but also in increasing the revenues of e-commerce companies. Among various recommendation techniques, matrix factorization (MF)-based collaborative filtering (CF) <ref type="bibr" target="#b0">[1]</ref> has been shown to be the most successful; it assumes that users who have had similar interests in the past will tend to share similar interests in the future <ref type="bibr" target="#b1">[2]</ref>. More specifically, MF learns low-rank vector representations of users and items from their previous interaction history and models the similarity of user-item pairs using inner products. However, a critical yet not widely recognized flaw of employing the inner product as a similarity metric is that it violates the triangle inequality <ref type="bibr" target="#b2">[3]</ref>. As a concrete example, if user u 1 liked items v 1 and v 2 , MF will put both items close to u 1 , but will not necessarily place v 1 and v 2 close to each other. That is to say, the seemingly obvious item-item similarity (between v 1 and v 2 ) is not guaranteed to be learned when the triangle inequality is violated <ref type="bibr" target="#b3">[4]</ref>.</p><p>To address the above limitation of MF-based recommendation, several metric learning approaches have been proposed <ref type="bibr" target="#b3">[4]</ref>- <ref type="bibr" target="#b6">[7]</ref>. They commonly project entities (users and items) into a low-dimensional metric space, i.e., Euclidean space, where the similarity between points is inversely proportional to the *Corresponding Author Euclidean distance that satisfies the triangle inequality. Specifically, CML <ref type="bibr" target="#b3">[4]</ref> is the state-of-the-art metric learning-based recommendation method for implicit feedback (e.g., clicks or purchases); it minimizes the distances between embeddings of a user and items that the user has interacted with, under the assumption that a user should be closer to the items the user likes than to those that the user does not. In this way, these approaches not only expect to propagate positive user-item relationships to other unknown user-item pairs, but also to capture the similarity within user-user and item-item pairs by satisfying the triangle inequality.</p><p>Although existing metric learning approaches have shown their effectiveness by satisfying the triangle inequality, they suffer from an inherent limitation, which is that each user is projected to a single point in the metric space. Such a rigid restriction imposed on user embeddings makes it hard to properly model the intensity and the heterogeneity of user-item relationships in implicit feedback. More precisely, a user's implicit feedback on multiple items does not necessarily indicate that he holds an equal preference for these items; rather, some of the items are more relevant to the user than others. This implies that the intensity of the user-item relationships embodied in implicit user-item interactions differ from one another. Moreover, a user may have a wide variety of tastes in different item categories, implying that the type of user-item relationship is heterogeneous with regard to the user's tastes in various item categories <ref type="bibr" target="#b0">1</ref> . However, it is by no means an easy task to project each user to a single point such that his intense and heterogeneous relationships with items are fully considered, and this phenomenon compounds as the number of users and items increases. This paper presents a novel method called TransCF to overcome the above limitation of existing metric learning approaches. We achieve this by adopting the translation mechanism, which has been proven to be effective for knowledge graph embedding <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>, by which the relations between entities are interpreted as translation operations between them. In our work, we embed users and items as points in a low-dimensional metric space, and additionally introduce translation vectors to translate each user to multiple points. Equipped with the user-item specific translation vectors, a user is translated toward his relevant items by considering his relationships with the items, which facilitates the modeling of the intensity and the heterogeneity of user-item relationships in implicit feedback that were overlooked by the previous CML TransCF Translation User Relevant Item <ref type="figure">Fig. 1</ref>: Toy example illustrating the benefit of the user-item specific translation vectors. Items are assumed to be grouped according to their categories. metric learning approaches. A further appeal of our proposed method is the ability to handle the complex nature of CF where it is common for a user to interact with multiple items, i.e., one-to-many mapping. Whereas it is not feasible for the previous metric learning approaches to pull a user closer to all of the items (one-to-many mapping) because a user is projected to a single point, our proposed method alleviates this issue because once a user is translated to multiple points, a one-to-many mapping can be deemed as multiple one-toone mappings. As an illustration, consider the following toy example.</p><p>Toy Example. In <ref type="figure">Figure 1</ref>, whereas CML tries to find a single point for a user that minimizes the distances between the user and his relevant items, TransCF introduces useritem specific translation vectors to translate the user to multiple points according to the intensity and the heterogeneity of the user-item relationships. The more intense (thickness of the vectors) the user-item relationship, the closer the user is expected to be translated to the item. Besides, the direction of the vectors and the angles between them reflect the heterogeneity of the relationship with regard to the user's tastes in various item categories.</p><p>However, directly applying the translation mechanism into a general recommendation framework for implicit feedback is not viable because user-item interactions in the implicit feedback dataset are not labeled, unlike in knowledge graphs where each relation between entities is given a label, such as "was born in" or "performed in". Therefore, the key for successfully adopting the translation mechanism in our framework boils down to defining labels for implicit user-item interactions, and materializing them into the user-item specific translation vectors. Inspired by the highly effective neighborhoodbased CF algorithms <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b9">[10]</ref>- <ref type="bibr" target="#b13">[14]</ref>, whose assumptions are that similar users display similar item preferences and that similar items are consumed by similar users, we employ the neighborhood information of users and items to construct the translation vectors (Section III-C). Combined with a regularizer, specifically tailored to TransCF, that guides each user/item to its neighbors (Section III-D1), TransCF explicitly models the neighborhood information, in contrast to CML, which expects to achieve it implicitly by satisfying the triangle inequality. It is worth noting that the user-item specific translation vectors are constructed without introducing any new parameters, which prevents our proposed method from overfitting. Furthermore, we introduce a second regularizer to further improve the accuracy of TransCF in case the user-item relationships become more complex (Section III-D2). Our extensive experiments on seven real-world datasets (Section IV-A) show that TransCF considerably outperforms the state-ofthe-art recommendation methods for implicit feedback by up to 17% in terms of hit ratio. We also perform various experiments to qualitatively ascertain that TransCF indeed benefit from modeling the intensity and the heterogeneity of user-item relationships in implicit feedback as illustrated in <ref type="figure">Figure 1</ref> (Section IV-B). The source code is available at https://github.com/pcy1302/TransCF. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Amazon C&amp;A</head><p>Num. different ratings given by users Num. different ratings given by users (a) Distribution of the number of different ratings given by users.  <ref type="table">3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20  21  22  23</ref>   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. DATA ANALYSIS: INTENSITY AND HETEROGENEITY</head><p>In this section, we perform data analyses on Ciao <ref type="bibr" target="#b14">[15]</ref> and Amazon C&amp;A <ref type="bibr" target="#b15">[16]</ref> datasets to provide evidences of the existence of the intensity and the heterogeneity of user-item relationships in implicit feedback. The ratings in both datasets are integers from 1 to 5, and the numbers of unique item categories are 28 and 45, respectively. In our experiments, we regard every user-item interaction with a rating as an implicit feedback record 2 . <ref type="figure" target="#fig_2">Figure 2</ref> shows the distribution of the number of different ratings and different item categories given and observed by users. In <ref type="figure" target="#fig_2">Figure 2a</ref>, we observe that most users (95% in Ciao and 85% in Amazon C&amp;A) give two or more different ratings. This implies that implicit user-item interactions do indeed encode different intensities of useritem relationships, assuming that the rating is a proxy for the intensity; a higher rating implies higher intensity. Moreover, in <ref type="figure" target="#fig_2">Figure 2b</ref> we observe that only a few users (3% in Ciao and 6% in Amazon C&amp;A) interact with a single category, whereas the vast majority of users interact with two or more different item categories. This implies that users have diverse tastes in various item categories, and thus the type of useritem relationship is heterogeneous with regard to the users' tastes in various item categories.</p><p>In Section IV-B2, we show by our experiments that Tran-sCF can inversely infer knowledge regarding the intensity and the heterogeneity from the implicit user-item interactions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. PROPOSED METHOD: TRANSCF</head><p>In this section, we give details of our proposed method, which adopts the translation mechanism for modeling the intensity and the heterogeneity of user-item relationships in implicit feedback.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Problem Formulation</head><p>In this work, we focus on recommendations for implicit feedback. Let U and I denote a set of users and a set of items, respectively. N I u denotes the set of items that user u has previously interacted with. Given implicit user-item interactions (e.g., bookmarks and purchase history), our goal is to recommend items i ∈ I\N I u to each user u ∈ U. Note that we use neither the rating information nor any auxiliary information regarding users and items (e.g., user social network or item category).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Scoring Function</head><p>Recall that the objectives of this work are 1) to address the limitation of the inner product as a scoring function, which violates the triangle inequality, and 2) to model the intensity and the heterogeneity of user-item relationships in implicit feedback. To this end, we adopt Euclidean distance as our distance metric to satisfy the triangle inequality, and we introduce translation vectors to model the intensity and the heterogeneity of implicit user-item interactions. Given Kdimensional embedding vectors α u ∈ R K for user u, β i ∈ R K for item i, and r ui ∈ R K for the translation of user u with regard to item i, the similarity score s(u, i) between user u and item i is:</p><formula xml:id="formula_0">s(u, i) = − α u + r ui − β i 2 2 (1)</formula><p>where a higher similarity score s(u, i) implies a higher probability that user u will like item i. In other words, the similarity score between user u and item i is computed by the distance between the translated embedding vector of user u, given by (α u + r ui ), and the embedding vector β i of item i.</p><p>Optimization Objective. Given the scoring function s(u, i) as in Equation 1, we minimize a popular margin-based pairwise ranking criterion <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>, i.e., hinge loss, as follows:</p><formula xml:id="formula_1">L(Θ) = u∈U i∈N I u j / ∈N I u [γ − s(u, i) + s(u, j)] +<label>(2)</label></formula><p>where [x] + = max(x, 0), and γ is the margin. Our objective is to ensure that the similarity score of an observed (positive) user-item pair (u, i) is higher than that of an unobserved (negative) pair (u, j) by a margin of at least γ. By doing so, we aim to translate each user u closer to his relevant item i while translating him farther away from his non-relevant item j. One thing to note is that the translation vector r ui is user-item specific: it translates user u with respect to item i according to the user's specific relationship with the item i. This property enables TransCF not only to capture the intensity and the heterogeneity of user-item relationships in implicit feedback, but also to handle the complex nature of CF.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Modeling Relations: Neighborhood Information</head><p>As mentioned previously, the key for successfully adopting the translation mechanism in our framework is modeling the translation vectors so that they reflect the intensity and the heterogeneity of user-item relationships in implicit feedback. The translation vectors can be flexibly constructed as long as the user-item interactions are properly modeled. Although it is possible to introduce a new parameter for each translation vector corresponding to every user-item pair, we note that not only is this approach prone to overfitting owing to the large number of parameters, but also it does not allow the collaborative information to be explicitly modeled as no parameters are shared among users and among items. Therefore, in this work we employ the neighborhood information of users and items to construct the translation vectors without introducing any new parameters. Neighborhood information, which has been shown to be highly effective for recommendation <ref type="bibr" target="#b10">[11]</ref>- <ref type="bibr" target="#b13">[14]</ref>, implies that users are represented through the items that they prefer <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b9">[10]</ref>, and items are represented through the users that prefer them. More precisely, considering that user embedding vectors reveal users' tastes, each item can be regarded as the average tastes of the users that have interacted with that item:</p><formula xml:id="formula_2">β nbr i = 1 |N U i | k∈N U i α k<label>(3)</label></formula><p>where β nbr i ∈ R K denotes the neighborhood embedding of item i, and N U i denotes the set of users that have previously interacted with item i. Likewise, considering that item embedding vectors capture the prominent features of items, e.g., the item category, each user's taste can be represented by the average features of the items that the user has interacted with:</p><formula xml:id="formula_3">α nbr u = 1 |N I u | k∈N I u β k<label>(4)</label></formula><p>where α nbr u ∈ R K denotes the neighborhood embedding of user u, and N I u denotes the set of items that user u has previously interacted with. Given the respective representations of an item and a user from the neighborhood perspective as in Equations 3 and 4, we use them to model the user-item interactions as follows:</p><formula xml:id="formula_4">r ui = f (α nbr u , β nbr i ) where f (x, y)</formula><p>denotes a function to model the interaction between the two input vectors x and y. Note that although we could employ various functions such as a multi-layer perceptron, it turns out that a simple element-wise vector product provides the highest accuracy. <ref type="figure" target="#fig_3">Figure 3</ref> illustrates a working example of TransCF. Given that user 1 has interacted with items {2, 5, 8} and item 2 has been interacted with by users {1, 3, 6}, we obtain the neighborhood embedding vector α nbr 1 of user 1 from the set of items {2, 5, 8}, and the neighborhood embedding vector β nbr 2 of item 2 from the set of users {1, 3, 6}. Then, using these neighborhood embedding vectors α nbr 1 and β nbr 2 , we construct the translation embedding vector r 12 = f (α nbr 1 , β nbr 2 ), which is eventually used for computing the similarity score s(1, 2) = − α 1 + r 12 − β 2 2 2 . 1) Discussion: If users' social network information or auxiliary information related to items is given, it would be more intuitive to represent a user by his friends' tastes, and an item by its semantically related items, e.g., items that belong to the same category. However, such side information on users and items is not always provided in practice, and thus we do not consider any side information in our current work. Additionally, instead of simply averaging the embeddings of neighbors as in Equations 3 and 4, we could expect further improvements by applying the attention mechanism <ref type="bibr" target="#b16">[17]</ref>, whereby we give higher weights to more influential neighbors. Lastly, we could try swapping the role of users and items such that we conversely translate items towards users. However, since the above extensions are straightforward and our main focus is to incorporate the translation mechanism into recommender systems, we leave these for future studies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Model Regularization</head><p>In this section, we introduce two regularizers that are tailored to TransCF. We later show in our experiments (Section IV-A2) that these regularizers are indeed beneficial.</p><p>1) Regularizer 1 − Neighborhood Regularizer: In Section III-C, we explained how we reflect the neighborhood information of users and items into our translation vectors, under the assumption that users and items can be represented by their neighbors. In the case of users, we implicitly assumed that α u can be represented by α nbr u (Equation 4), and likewise for items, that β i can be represented by β nbr i (Equation 3). However, to ensure that the neighborhood information is explicitly incorporated into our model, we need to guide α u to be close to α nbr u , and β i to be close to β nbr i . To this end, we introduce a regularizer named reg nbr (Θ) that minimizes the distance between users/items and their neighbors:</p><formula xml:id="formula_5">reg nbr (Θ) = u∈U   αu − 1 |N I u | k∈N I u β k   2 + i∈I   βi − 1 |N U i | k∈N U i α k   2<label>(5)</label></formula><p>Through Equation 5, we aim to explicitly inject the neighborhood information into the users and items, leading to more robust representations of users/items and their neighbors.</p><p>2) Regularizer 2 − Distance Regularizer: The objective function shown in Equation 2 trains the user and item embeddings so that given a positive user-item interaction (u, i), the item embedding β i is the nearest neighbor of the user embedding α u translated by the translation vector r ui ; i.e., α u + r ui ≈ β i . In other words, the objective function (Equation 2) expects that the positive item i will be pulled toward user u by pushing the negative item j away from user u, which is in fact what is done in CML. However, the relations become more complex as the number of useritem interactions grows, and it is crucial to guarantee that the actual distance between them is small. Therefore, we introduce a second regularizer named reg dist (Θ) to explicitly pull the item embedding closer to the translated user embedding as follows:</p><formula xml:id="formula_6">reg dist (Θ) = u∈U i∈N I u −s(u, i) = u∈U i∈N I u αu + rui − βi 2 2 (6)</formula><p>Notably, reg dist (Θ) is equivalent to the loss L pull , which is introduced in the paper that proposed CML <ref type="bibr" target="#b3">[4]</ref>. However, CML does not employ L pull because "an item can be liked by many users and it is not feasible to pull it closer to all of them" as the authors mentioned in Section 3.1 of their paper <ref type="bibr" target="#b3">[4]</ref>. This infeasibility is essentially caused by the fact that each user is projected to a single point, and we argue that translating a user to multiple points by introducing the user-item specific translation vectors as in our method makes it feasible to pull the item closer to all of the translated users, allowing TransCF to employ reg dist (Θ).</p><p>Final Objective Function. Given the margin-based pairwise ranking function (Equation 2) and the two regularizers (Equations 5 and 6), our final objective function J (Θ) to minimize is as follows:</p><formula xml:id="formula_7">J (Θ) = (L(Θ) + λ nbr · reg nbr (Θ) + λ dist · reg dist (Θ))</formula><p>where λ nbr and λ dist are regularization coefficients for the neighborhood regularizer and the distance regularizer, respectively. We compute the gradient for parameters in Θ = {α u , β i }, and update them by using mini-batch stochastic gradient descent (SGD) with learning rate η as follows:</p><formula xml:id="formula_8">Θ ← Θ − η × ∂J (Θ)</formula><p>∂Θ . As our focus is to verify the benefit of translation mechanism for recommendation, we do not adopt advanced negative sampling techniques <ref type="bibr" target="#b17">[18]</ref>- <ref type="bibr" target="#b20">[21]</ref> for the model training. Instead, for each user u ∈ U, we randomly generate 100 samples of {(i, j)|i ∈ N I u ∩ j / ∈ N I u } in every epoch. Moreover, as done in CML, we apply regularizations on α * and β * after each epoch by bounding them within a unit sphere to mitigate 'curse of dimensionality' issue <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>: α * 2 ≤ 1 and β * 2 ≤ 1, which is achieved by</p><formula xml:id="formula_9">α * ← α * / max(1, α * 2 ) and β * ← β * / max(1, β * 2 ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTS</head><p>The experiments are designed to answer the following research questions (RQs):</p><p>• RQ 1 How does TransCF perform compared with other state-of-the-art competitors? • RQ 2 Are the newly introduced regularizers tailored to TransCF beneficial for the performance of TransCF? • RQ 3 Do the user-item specific translation vectors indeed translate the users close to their corresponding items (as illustrated in <ref type="figure">Figure 1</ref>)? • RQ 4 What is encoded in the translation vectors?</p><p>-Intensity / Heterogeneity of user-item relationships. Datasets. We evaluate our proposed method on seven realworld datasets: Delicious <ref type="bibr" target="#b21">[22]</ref>, Tradesy <ref type="bibr" target="#b22">[23]</ref>, Ciao <ref type="bibr" target="#b14">[15]</ref>, Amazon Cellphone and Accessories (Amazon C&amp;A) <ref type="bibr" target="#b15">[16]</ref>, Bookcrossing <ref type="bibr" target="#b23">[24]</ref>, Pinterest <ref type="bibr" target="#b24">[25]</ref>, and Flixster <ref type="bibr" target="#b25">[26]</ref>. Delicous, Tradesy and Pinterest datasets contain implicit feedback records, i.e., bookmark, purchased and pinning history. Ciao and Amazon C&amp;A datasets contain rating information of users given to items, and also contain item category information, which will later be used in our experiments pertaining to verifying the heterogeneity of user-item relationships. Bookcrossing dataset contains both the rating (from 1 to 10) information and the implicit feedback (denoted as 0) from users on items. Flixster dataset contains the rating (from 0.5 to 5.0 by an interval of 0.5) information. For datasets with rating information, we regard each observed rating as an implicit feedback record as done in previous research <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b26">[27]</ref>- <ref type="bibr" target="#b28">[29]</ref>. We use several explicit feedback datasets and convert them into implicit feedback to be able to experimentally ascertain that the translation vectors indeed encode the intensity of user-item relationships; this is not possible with pure implicit feedback datasets as the interactions are not labeled. We include Bookcrossing and Flixster datasets with 10-level ratings in addition to the 5-level ratings (Ciao and Amazon C&amp;A) to verify that TransCF can better infer knowledge regarding the intensity of user-item relationships when finer grained user preferences are given. We remove users and items having fewer than five ratings. The statistics of the preprocessed datasets used in our experiments are summarized in <ref type="table" target="#tab_1">Table I</ref>.</p><p>Evaluation Protocol and Metrics. We employ the widely used leave-one-out evaluation protocol <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b26">[27]</ref>- <ref type="bibr" target="#b29">[30]</ref>, whereby the last interacted item for each user is held out for testing, and the rest are used for training. Since it is time consuming to rank all the items in I, we sample 99 items for each user that the user had not interacted with, and compute the ranking scores for those items plus the user's test item (100 in total for each user) <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b29">[30]</ref>. For each user, we additionally hold out the last interacted item from the training data for validation set on which we tune the hyperparameters for all the methods. As we are focused on recommendations for implicit feedback, we employ two ranking metrics widely used for evaluating the performance of recommender systems <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b28">[29]</ref>: hit ratio (H@N) and normalized discounted cumulative gain (N@N). H@N measures whether the item is present in the top-N list, whereas N@N is a position-aware ranking metric that assigns higher scores to hits at upper ranks.</p><p>Methods Compared. As TransCF is a pair-wise 1) learningto-rank method based on 2) metric learning that employs 3) neighborhood information, we choose the following baselines.</p><p>1) Learning-to-rank baselines.</p><p>• Point-wise methods.</p><p>-eALS <ref type="bibr" target="#b17">[18]</ref>: The state-of-the-art MF-based method for implicit feedback that non-uniformly weights the unobserved interactions based on the item popularity. -NeuMF <ref type="bibr" target="#b27">[28]</ref>: A pointwise neural collaborative filtering framework for implicit feedback that combines MF and multi-layer perceptron (MLP). We report the best results from among MF, MLP, and NeuMF.</p><p>• Pairwise methods.</p><p>-BPR <ref type="bibr" target="#b26">[27]</ref>: A pairwise learning-to-rank method for implicit feedback in which observed items are assumed to be highly preferred by users to unobserved items. -AoBPR <ref type="bibr" target="#b19">[20]</ref>: An extension of BPR that samples popular items as negative feedback with a higher probability. 2) Neighborhood-based baselines.</p><p>• FISM [10]: A neighborhood-based recommendation method based on MF in which a user is represented by the items that the user has interacted with as in Eqn. 4. • CDAE <ref type="bibr" target="#b10">[11]</ref>: The state-of-the-art neighborhood-based method in which the user-item relationship is computed between a user and his neighbors, i.e., the items that the user has previously interacted with. i.e., we employ the current user and item embeddings for constructing r ui instead of their neighborhoods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Implementation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Details.</head><p>For each data, the hyperparameters are tuned on the validation set by grid searches with K ∈ {8, 16, 32, 64, 128}, η ∈ {0.0005, 0.001, 0.005, 0.01, 0.05, 0.1}, γ ∈ {0.0, 0.1, 0.5, 1.0 , 1.5, 2.0,2.5, 3.0}, λ, λ nbr , λ dist ∈ {0.0, 0.001, 0.01, 0.1}, where λ is the regularization coefficient for the baseline methods. We report the test performance measured using the hyperparameter values that give the best HR@10 on the validation set. For reliability, we repeat our evaluations five times with different random seeds for the model initialization, and we report mean test errors. We fix the number of samples in a mini-batch to 1000 for mini-batch SGD.</p><p>A. Performance Analysis 1) Recommendation performance (RQ 1): <ref type="table" target="#tab_1">Table II</ref> shows the performance of different methods in terms of various ranking metrics. We have the following observations from Table II. 1) We observe that CML outperforms the MF-based competitors (BPR, FISM, AoBPR, eALS, and NeuMF). This is consistent with the previous work <ref type="bibr" target="#b3">[4]</ref>, indicating that metric learning approaches overcome the inherent limitation of MF by learning a metric space wherein the triangle inequality is satisfied. 2) We observe that TransCF considerably outperforms the state-of-the-art competitor, namely CML, by up to 17.05% (achieved for HR@20 on Bookcrossing dataset). This verifies the benefit of the translation vectors that translate each user toward items according to the user's relationships with those items. 3) TransCF alt generally performs worse than CML, which implies that the translation vectors should be carefully designed, or else the performance will rather deteriorate. 4) The superior performance of TransCF over TransCF alt confirms that incorporating the neighborhood information is indeed crucial in collaborative filtering <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b10">[11]</ref>. 5) Tran-sCF dot generally performs worse than CML, which verifies that the inner product operation limits the performance despite the benefit of the translation mechanism adopted to Tran-sCF dot . 6) By further comparing HR@10 of TransCF alt on Delicious and Bookcrossing datasets (0.2174 and 0.2828 in <ref type="table" target="#tab_1">Table II</ref>) with HR@10 of TransCF without any regularization   <ref type="table" target="#tab_1">Table III</ref> when λ dist = λ nbr = 0.0), we observe that TransCF without the regularizers still outperforms TransCF alt . This again verifies that the neighborhood information itself is indeed beneficial even without the help of the neighborhood regularizer.</p><p>2) Benefit of regularizers (RQ 2): <ref type="table" target="#tab_1">Table III</ref> shows the effect of the regularization coefficients on the performance of TransCF on Delicious and Bookcrossing datasets, where λ nbr and λ dist denote the strengths of the neighborhood regularizer (reg nbr ) and of the distance regularizer (reg dist ), respectively. Larger values imply a stronger contribution of the regularizer to the model, and λ * = 0.0 indicates no regularization. We have the following observations: 1) Both regularizers are indeed beneficial for the model performance, and their impact varies across different datasets. 2) Although reg nbr is beneficial, its impact on the model performance decreases as the reg dist dominates the model; i.e., as λ dist increases. 3) reg dist is more helpful for the model performance compared with reg nbr ; the benefit of reg dist becomes more clear on Bookcrossing dataset in which the user-item relations are more complex compared with Delicious dataset. This confirms that explicitly pulling each translated user toward all of the positive items rather than merely pushing negative items away from each user helps to model the complex user-item interactions, which aligns with our motivation for the distance regularizer reg dist as mentioned in Section III-D2. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Qualitative Evaluations 1) Benefit of translation vectors (RQ 3):</head><p>In this section, we conduct experiments to verify whether the translation vectors learned by TransCF indeed translate each user closer to the observed (positive) items as in Toy example illustrated in <ref type="figure">Figure 1</ref>. To this end, for each user u and his observed item i, we check whether the following holds:</p><formula xml:id="formula_10">αu − βi 2 2 &gt; αu + rui − βi 2 2 (7)</formula><p>That is, we expect the distance between the item embedding vector β i of observed item i and the translated user embedding vector (α u + r ui ) to be smaller than the distance between the item embedding vector β i and the user embedding vector α u before translation. We calculate the percentage of observed/unobserved user-item interaction pairs that satisfy Equation 7 among all possible observed/unobserved pairs. We sample as many unobserved items as the number of observed items for each user for the comparisons. Here, we expect more observed pairs to satisfy Equation 7 than unobserved pairs. <ref type="table" target="#tab_1">Table IV</ref> shows the results on the seven datasets. We observe that users are generally translated closer toward their observed (positive) items, and at the same time translated farther away from the unobserved (negative) items. For instance, for Amazon C&amp;A dataset, 75.57% of the observed user-item interactions satisfy Equation 7, whereas only 31.96% of the unobserved interactions satisfy it, which conversely implies that users in 68% (≈ 100 − 31.96) of the unobserved interactions translate users farther away from the unobserved items. We also note that for Flixster dataset, although only 22.24% of the observed interactions satisfy Equation 7, the overwhelming majority of the unobserved interactions, i.e., 97% (≈ 100 − 2.88), violate it, which means that the effect of users being translated away from the unobserved items results in placing the translated users relatively closer toward their observed items. Hence, we argue that by simultaneously translating a user toward his relevant items and away from his irrelevant items, TransCF achieves superior recommendation performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2) What is encoded in the translation vectors? (RQ 4):</head><p>In this section, we investigate why TransCF outperforms the state-of-the-art methods. For this purpose, we conduct various experiments with the translation vectors to verify our claims that the translation vectors encode the i) intensity, and the ii) heterogeneity of user-item relationships in implicit feedback.</p><p>Intensity of user-item interactions. With regard to the first claim, i.e., intensity, we assume that the rating information is a proxy for the intensity of user-item relationships. In other words, the higher the rating of an item given by a user, the higher the intensity of the user-item relationship.</p><p>Since Ciao, Amazon C&amp;A, Bookcrossing and Flixster datasets contain rating information, we use them to study whether we can conversely infer some knowledge about ratings using the translation vectors even though the ratings are not utilized during the model training. To this end, we perform rating classification to predict the rating of user u on item i given the user-item specific translation vector r ui as input; for instance, there are five classes for datasets with ratings ranging from 1 to 5. Note that we perform classification instead of regression to clearly emphasize the difference between the numbers; the RMSE values of regression usually differ in the second decimal place <ref type="bibr" target="#b0">[1]</ref>. To ascertain the benefit of the translation vectors learned by TransCF, i.e., r TransCF ui , we compare the rating classification performance with that of CML. Since CML does not model the translation vectors <ref type="bibr" target="#b3">[4]</ref>, we alternatively define the translation vectors for CML, i.e., r CML ui := (α u − β i ), where α u and β i are both trained by CML. Likewise, we additionally define synthetic translation vectors r TransCF emb ui := (α u − β i ) for TransCF , where α u and β i are both trained by TransCF, and name this method TransCF emb . <ref type="table" target="#tab_5">Table V</ref> summarizes the classification results <ref type="bibr" target="#b3">4</ref> . We observe that the rating classification accuracy on translation vectors of TransCF outperforms that of CML and TransCF emb , and that the improvement is the greatest on Flixster dataset. This implies that the intensity of user-item relationships is encoded in the translation vectors learned by TransCF, which explains the superior performance of TransCF as shown in <ref type="table" target="#tab_1">Table II</ref>. However, we note that the improvements of classification accuracies compared with CML are not sufficiently large on Ciao and Amazon C&amp;A datasets, reaching only 5.3% and 1.5%, respectively. This motivates us to further investigate the translation vectors with regard to the intensity of user-item relationships.</p><p>To further study the translation vectors, we group the results of the observed user-item interactions from <ref type="table" target="#tab_1">Table IV</ref> according to their ground truth ratings, and calculate the percentage in higher rating groups. However, we observe that the results on Ciao and Amazon C&amp;A datasets do not agree with our expectation, which explains the relatively small improvements in <ref type="table" target="#tab_5">Table V</ref>. We conjecture that it is inherently challenging to infer users' fine-grained preferences from the user-item interactions of Ciao and Amazon C&amp;A datasets, because 1) the range of the ratings is relatively small (integers from 1 to 5), and more importantly, 2) the majority (over 75%) of interactions belong to ratings from 4 to 5. In contrast, for Bookcrossing <ref type="bibr" target="#b4">5</ref> and Flixster datasets whose ratings are in a wider range (from 1 to 10, and from 0.5 to 5.0, respectively), and relatively evenly distributed throughout the rating classes, the percentage of interactions satisfying Equation 7 increases as the ratings increase from 5 to 10 (for Flisxter, from 3.0 to 5.0). These results on Bookcrossing and Flixster datasets <ref type="table" target="#tab_1">(Table VI</ref>) are in line with the results in <ref type="table" target="#tab_5">Table V</ref>, where the relative improvement of the classification results of Tran-sCF is the highest for Bookcrossing and Flixster datasets. To summarize our findings from Tables V and VI, we conclude that the intensity of user-item relationships is indeed encoded in the translation vectors, and that it becomes clearer with datasets from which users' preferences can be more precisely inferred, e.g., Bookcrossing and Flisxter datasets. However, up to this point, it is still uncertain why the improvements of TransCF on Ciao and Amazon C&amp;A datasets are considerable in terms of the quantitative evaluation (Table II), even though the rating information (intensity) is not as clearly encoded in the translation vectors as in the case of Bookcrossing and Flixster dataset. Hence, in the following section, we study whether the translation vectors of Tran-sCF trained on Ciao and Amazon C&amp;A datasets encode meaningful information other than the rating information.</p><p>Heterogeneity of user-item interactions. In this section, we investigate the translation vectors from a different perspective, i.e., heterogeneity. Recall that TransCF aims to translate each user toward multiple items according to the user's heterogeneous tastes in various item categories, implying that the translation vectors encode information related to item categories. To verify this, we study whether we can conversely infer the categories of items using the translation vectors, even though the item category information is not utilized during the training of TransCF. To this end, we label each translation vector r ui with its corresponding category, and select vectors from the ten most frequently appearing categories to perform classification. <ref type="table" target="#tab_1">Table VIIa</ref> shows the item category classification accuracy on the translation vectors <ref type="bibr" target="#b3">4</ref> . We observe that TransCF considerably outperforms CML. This implies that the user-item specific translation vectors indeed encode the heterogeneity of the user-item relationships with regard to users' tastes in various item categories, which provides a justification for the superior performance of TransCF on Ciao and Amazon C&amp;A datasets. We further conduct another experiment on the item embedding vectors β i to ascertain that the considerable performance improvement with TransCF is indeed derived from the translation vectors; not from the high-quality item embedding vectors. This time, we select items whose categories belong to the ten most frequent appearing categories. <ref type="table" target="#tab_1">Table VIIb</ref> shows the classification accuracy on the item embedding vectors β i for all i ∈ I trained by CML and TransCF. We observe that CML and TransCF show comparable classification performance, implying that the superior performance of TransCF is derived not from the high-quality item embedding vectors, but from the translation vectors.</p><p>To provide a more intuitive understanding of the numerical results shown in <ref type="table" target="#tab_1">Table VIIa</ref>, we visualize in <ref type="figure">Figure 4</ref> the translation vectors learned by CML and TransCF on Ciao dataset by using t-distributed Stochastic Neighbor Embedding 6 (t-SNE) <ref type="bibr" target="#b32">[33]</ref> with perplexity 30. Each point represents a translation vector, and the color represents the item category. We can clearly see that the translation vectors of TransCF are generally grouped together according to their corresponding categories, unlike CML; this supports the superior classification results of TransCF over CML in <ref type="table" target="#tab_1">Table VIIa.</ref> Lastly, based on the above observation that similar translation vectors encode similar information with regard to item cat- <ref type="bibr" target="#b5">6</ref> We sample 200 samples from each category for visualization.  egories, we further investigate whether the translation vectors might even reveal the correlations among the item categories.</p><p>To this end, we compute the sum of the cosine similarity scores between all pairs of translation vectors from each category. We use the same sampled translation vectors that were used for the visualization in <ref type="figure">Figure 4</ref>. <ref type="figure" target="#fig_6">Figure 5</ref> shows the heat map of cosine similarity between translation vectors learned by TransCF on Ciao dataset with regard to the item categories.</p><p>The number in each cell denotes the average cosine similarity score normalized by the overall largest score. We observe that the similarity score is generally the highest within the same item category (the diagonal line). Moreover, interestingly, semantically related categories also show high correlations. For example, "Entertainment" is highly correlated with "Internet", "Games", "Music", and "Shopping" all of which are related to entertainment. From the above analyses, we can conclude that TransCF can even determine the correlations among the item categories by encoding the heterogeneity of user-item relationships into the translation vectors, which again helps explain the superior performance of TransCF. This experiment also verifies our assumption illustrated in <ref type="figure">Figure 1</ref> that the angles between the translation vectors reflect the heterogeneity of the user-item relationships regarding the user's tastes in various item categories. V. RELATED WORK Recommendations for Implicit Feedback. Although explicit feedback such as rating or review comment is a valuable source of information that reveals user preferences, in most cases it is difficult to obtain a large quantity of such data. Hence, the vast majority of past research has focused on recommendations for implicit feedback <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b33">[34]</ref>- <ref type="bibr" target="#b35">[36]</ref>. These methods generally adopt the matrix factorization (MF) technique, which uses the inner product to model the similarity of user-item pairs <ref type="bibr" target="#b0">[1]</ref>. However, the inner product violates the triangle inequality, and thus it may fail to capture fine-grained user preferences <ref type="bibr" target="#b3">[4]</ref>.</p><p>Incorporating the neighborhood information <ref type="bibr" target="#b12">[13]</ref> into CF has been shown to be effective for memory-based <ref type="bibr" target="#b13">[14]</ref> and model-based <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b9">[10]</ref>- <ref type="bibr" target="#b11">[12]</ref> CF. ItemCF <ref type="bibr" target="#b13">[14]</ref> computes the similarity scores, such as Pearson Correlation and Cosine Similarity, between users based on the items they interacted with in the past. SLIM <ref type="bibr" target="#b11">[12]</ref> and FISM <ref type="bibr" target="#b9">[10]</ref> improve ItemCF by learning the item-item similarity directly from the data through factorizing the item similarity matrix as a product of two latent factor matrices. CDAE <ref type="bibr" target="#b10">[11]</ref> is the state-ofthe-art neighborhood-based CF method implemented by using denoising auto-encoder. However, previously proposed neighborhood-based CF methods are generally based on MF, and thus suffer from the violation of triangle inequality.</p><p>In the following, we briefly introduce metric learning approaches that address this limitation of MF. Metric Learning. Metric learning <ref type="bibr" target="#b36">[37]</ref> learns a distance metric that preserves the distance relation among the training data; i.e., it assigns shorter distances to semantically similar pairs. It has been popularized in various domains such as computer vision <ref type="bibr" target="#b37">[38]</ref> and natural language processing <ref type="bibr" target="#b38">[39]</ref>. Recently, metric learning approaches have been adopted in collaborative filtering to address the limitation of MF. Khoshneshin and Street firstly introduced the Euclidean embedding scheme for explicit feedback-based CF, a scheme in which users and items are embedded according to their Euclidean similarity rather than their inner product <ref type="bibr" target="#b4">[5]</ref>. For music recommendation, Chen et al. represent songs as points in Euclidean space, and model the transition probability based on the Euclidean distance between songs <ref type="bibr" target="#b5">[6]</ref>. For point-of-interest (POI) recommendation, Feng et al. model personalized check-in sequences by projecting each POI into one object in Euclidean space <ref type="bibr" target="#b6">[7]</ref>. The above methods can be subsumed by the recently proposed CML <ref type="bibr" target="#b3">[4]</ref>, which is a general recommendation framework for implicit feedback. CML projects users and items into a common Euclidean space in which the similarity of a useritem pair is computed based on the Euclidean distance between the latent vectors of the user and of the item. Given user u and item i, the scoring function s(u, i) of CML is computed by: s(u, i) = − α u − β i 2 2 . In spite of its state-of-theart performance, CML projects each user to a single point, and thus it does not suffice for modeling the intensity and the heterogeneity of the user-item relationships in implicit feedback. Knowledge Graph Embedding. Knowledge graph embedding refers to the projection of entities and relations in knowledge graphs into low-dimensional vector spaces. Among various knowledge graph embedding methods, translationbased methods <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref> have shown state-of-the-art perfor-mance and scalability compared with traditional factorizationbased embedding methods <ref type="bibr" target="#b39">[40]</ref>, <ref type="bibr" target="#b40">[41]</ref>. Recently, the translation mechanism has been adopted for recommendation algorithms. Zhang et al. <ref type="bibr" target="#b41">[42]</ref> integrate collaborative filtering and a knowledge base for recommendation by adopting TransR <ref type="bibr" target="#b8">[9]</ref> to extract the structural knowledge of items from knowledge graphs. He et al. <ref type="bibr" target="#b28">[29]</ref> embed items into a transition space, where each user is modeled by a translation vector to model the transition from the previously consumed item to the next item. However, our work is distinguished from the above methods in that we adopt the translation mechanism to model the latent relationships of implicit user-item interactions rather than to extract some knowledge from knowledge graphs, and we do not model the temporal information. Hence, we do not compare them with TransCF in our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUSION</head><p>Each implicit user-item interaction encodes a different intensity of user-item relationship, and the relationship is heterogeneous regarding the user's taste in different item categories. In this paper, we propose a novel metric learning-based recommendation method called TransCF that captures not only the intensity and the heterogeneity of user-item relationships in implicit feedback, but also the complex nature of CF, all of which have been overlooked by previous metric learningbased recommendation approaches. TransCF employs the neighborhood information of users and items to construct translation vectors whereby a user is translated toward items according to his relationships with the items. Through extensive experiments, we demonstrate that TransCF considerably outperforms several state-of-the-art methods by generating meaningful translation vectors. Regarding possible directions for future studies, refer to Section III-C1.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 :</head><label>2</label><figDesc>Data analysis on Ciao and Amazon C&amp;A datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 :</head><label>3</label><figDesc>An overview of TransCF.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>3 ) 2 .</head><label>32</label><figDesc>Metric learning-based baselines &amp; Ablations of TransCF. • CML [4]: The state-of-the-art metric learning-based recommendation method for implicit feedback in which Euclidean distance is used for the scoring function. i.e., s(u, i) = − α u − β i 2 • TransCF dot : An ablation of TransCF in which instead of Euclidean distance, inner product is used for the scoring function. i.e., s(u, i) = (α u + r ui ) T β i . • TransCF alt : Another ablation of TransCF in which the translation vector is computed by r ui = f (α u , β i ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 5 :</head><label>5</label><figDesc>Heat map of cosine similarity between translation vectors of Ciao dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE I :</head><label>I</label><figDesc>Data Statistics. (Rat. denotes the range of ratings, and #Cat. denotes the number of unique item categories.)</figDesc><table><row><cell>Dataset</cell><cell cols="2">#Users #Items. #Inter.</cell><cell>Density</cell><cell>Rat.</cell><cell>#Cat.</cell></row><row><cell>Delicious</cell><cell>1,050 1,196</cell><cell>7,698</cell><cell>0.61%</cell><cell>-</cell><cell>-</cell></row><row><cell>Tradesy</cell><cell>3,352 5,547</cell><cell>32,710</cell><cell>0.13%</cell><cell>-</cell><cell>-</cell></row><row><cell>Ciao</cell><cell cols="2">6,760 11,166 146,996</cell><cell>0.19%</cell><cell>1-5</cell><cell>28</cell></row><row><cell>Amazon</cell><cell cols="2">59,089 17,969 332,236</cell><cell>0.03%</cell><cell>1-5</cell><cell>45</cell></row><row><cell>Bookcr</cell><cell cols="2">19,571 39,702 605,178</cell><cell>0.08%</cell><cell>1-10</cell><cell>-</cell></row><row><cell>Pinterest</cell><cell cols="2">55,187 9,329 1,462,895</cell><cell>0.28%</cell><cell>-</cell><cell>-</cell></row><row><cell>Flixster</cell><cell cols="2">69,482 25,687 8,000,690</cell><cell>0.45%</cell><cell>0.5-5.0</cell><cell>-</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE II :</head><label>II</label><figDesc>Test performance of different methods. Best results are in bold face. (Imp. denotes the improvement of TransCF over the best competitor, which is CML.)</figDesc><table><row><cell cols="3">Datasets Metrics</cell><cell>BPR</cell><cell>FISM</cell><cell>AoBPR</cell><cell>eALS</cell><cell>CDAE</cell><cell>NeuMF</cell><cell>CML</cell><cell cols="3">TransCF dot TransCF alt TransCF</cell><cell>Imp.</cell></row><row><cell cols="2">Delicious</cell><cell>H@10 H@20 N@10 N@20</cell><cell>0.1981 0.3177 0.1122 0.1418</cell><cell>0.2203 0.3391 0.1124 0.1424</cell><cell>0.2243 0.3602 0.1114 0.1452</cell><cell>0.1992 0.2942 0.1035 0.1271</cell><cell>0.1319 0.2414 0.0674 0.0949</cell><cell>0.1164 0.2171 0.0558 0.0789</cell><cell>0.2470 0.3649 0.1389 0.1678</cell><cell>0.2150 0.3377 0.1101 0.1412</cell><cell>0.2174 0.3084 0.1281 0.1494</cell><cell>0.2586 0.3786 0.1475 0.1781</cell><cell>4.70% 3.75% 6.19% 6.14%</cell></row><row><cell cols="2">Tradesy</cell><cell>H@10 H@20 N@10 N@20</cell><cell>0.2481 0.4174 0.1248 0.1673</cell><cell>0.2676 0.4109 0.1309 0.1670</cell><cell>0.2597 0.4256 0.1300 0.1715</cell><cell>0.2058 0.3314 0.1042 0.1356</cell><cell>0.1652 0.2867 0.0831 0.1136</cell><cell>0.1167 0.2290 0.0538 0.0817</cell><cell>0.3031 0.4413 0.1685 0.2031</cell><cell>0.2846 0.4266 0.1449 0.1806</cell><cell>0.2648 0.3823 0.1466 0.1760</cell><cell>0.3198 0.4505 0.1767 0.2095</cell><cell>5.51% 2.08% 4.87% 3.15%</cell></row><row><cell></cell><cell></cell><cell>H@10</cell><cell>0.1569</cell><cell>0.2100</cell><cell>0.1873</cell><cell>0.1419</cell><cell>0.1770</cell><cell>0.1535</cell><cell>0.2085</cell><cell>0.2011</cell><cell>0.1991</cell><cell>0.2292</cell><cell>9.93%</cell></row><row><cell cols="2">Ciao</cell><cell>H@20 N@10</cell><cell>0.2811 0.0751</cell><cell>0.3482 0.1027</cell><cell>0.3146 0.0891</cell><cell>0.2570 0.0670</cell><cell>0.3153 0.0862</cell><cell>0.2788 0.0741</cell><cell>0.3337 0.1053</cell><cell>0.3185 0.1017</cell><cell>0.3270 0.0989</cell><cell>0.3740 0.1167</cell><cell>12.08% 10.83%</cell></row><row><cell></cell><cell></cell><cell>N@20</cell><cell>0.1063</cell><cell>0.1374</cell><cell>0.1209</cell><cell>0.0957</cell><cell>0.1208</cell><cell>0.1040</cell><cell>0.1358</cell><cell>0.1311</cell><cell>0.1309</cell><cell>0.1525</cell><cell>12.30%</cell></row><row><cell>Book-</cell><cell>crossing</cell><cell>H@10 H@20 N@10 N@20</cell><cell>0.2425 0.3761 0.1250 0.1585</cell><cell>0.2178 0.3938 0.1002 0.1444</cell><cell>0.2563 0.3916 0.1338 0.1676</cell><cell>0.1655 0.2864 0.0791 0.1093</cell><cell>0.2244 0.3610 0.1164 0.1506</cell><cell>0.2286 0.3747 0.1158 0.1482</cell><cell>0.2885 0.4053 0.1663 0.1956</cell><cell>0.2802 0.3932 0.1618 0.1903</cell><cell>0.2828 0.4069 0.1578 0.1890</cell><cell>0.3329 0.4744 0.1865 0.2221</cell><cell>15.39% 17.05% 12.15% 13.55%</cell></row><row><cell>Amazon</cell><cell>C&amp;A</cell><cell>H@10 H@20 N@10 N@20</cell><cell>0.2489 0.3821 0.1276 0.1610</cell><cell>0.2470 0.3782 0.1247 0.1577</cell><cell>0.2646 0.3946 0.1391 0.1718</cell><cell>0.2161 0.3480 0.1064 0.0739</cell><cell>0.2817 0.4117 0.1613 0.1939</cell><cell>0.1317 0.2390 0.0613 0.0880</cell><cell>0.3011 0.4123 0.1752 0.2031</cell><cell>0.3003 0.4184 0.1648 0.1945</cell><cell>0.3184 0.4509 0.1766 0.2094</cell><cell>0.3436 0.4658 0.2019 0.2323</cell><cell>14.11% 12.98% 15.24% 14.38%</cell></row><row><cell cols="2">Pinterest</cell><cell>H@10 H@20 N@10 N@20</cell><cell>0.4759 0.7564 0.2034 0.2744</cell><cell>0.4444 0.6720 0.2048 0.2626</cell><cell>0.4921 0.7618 0.2143 0.2827</cell><cell>0.3301 0.5621 0.1373 0.1959</cell><cell>0.5244 0.7393 0.2644 0.3188</cell><cell>0.4546 0.6852 0.2165 0.2748</cell><cell>0.5378 0.7771 0.2558 0.3166</cell><cell>0.5485 0.7822 0.2549 0.3143</cell><cell>0.4899 0.7514 0.2259 0.2922</cell><cell>0.5504 0.8108 0.2580 0.3242</cell><cell>2.34% 4.34% 0.86% 2.40%</cell></row><row><cell cols="2">Flixster</cell><cell>H@10 H@20 N@10 N@20</cell><cell>0.6836 0.8087 0.3701 0.4020</cell><cell>0.5985 0.7597 0.2794 0.3206</cell><cell>0.6904 0.8124 0.3830 0.4140</cell><cell>0.6320 0.7359 0.3513 0.3778</cell><cell>0.6797 0.7973 0.4526 0.4824</cell><cell>0.6596 0.7816 0.4588 0.4895</cell><cell>0.7009 0.8081 0.4608 0.4881</cell><cell>0.6014 0.7147 0.3417 0.3705</cell><cell>0.7123 0.8163 0.4704 0.4969</cell><cell>0.7309 0.8374 0.4986 0.5257</cell><cell>4.28% 3.63% 8.20% 7.70%</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE III :</head><label>III</label><figDesc>Effect of the regularization coefficients.</figDesc><table><row><cell>Delicious</cell></row><row><cell>(HR@10)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE IV :</head><label>IV</label><figDesc>Analysis on the user-item specific translation vectors. (Obs./Unobs. denotes results on observed/unobserved user-item interactions.)</figDesc><table><row><cell>Dataset</cell><cell>Obs.</cell><cell>Unobs.</cell><cell>Dataset</cell><cell>Obs.</cell><cell>Unobs.</cell></row><row><cell>Delicious</cell><cell cols="2">64.63% 43.75%</cell><cell>Amazon</cell><cell cols="2">75.57% 31.96%</cell></row><row><cell>Tradesy</cell><cell cols="2">56.02% 43.01%</cell><cell>Pinterest</cell><cell cols="2">36.25% 33.08%</cell></row><row><cell>Ciao</cell><cell cols="2">54.63% 38.42%</cell><cell>Flixster</cell><cell>22.24%</cell><cell>2.88%</cell></row><row><cell>Bookcr.</cell><cell cols="2">55.42% 35.57%</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE V :</head><label>V</label><figDesc>Rating classification accuracy using translation vectors. (Rand denotes a random classifier, and RF denotes the random forest classifier<ref type="bibr" target="#b30">[31]</ref>.)</figDesc><table><row><cell>Acc.(%)</cell><cell cols="2">Ciao Rand RF</cell><cell cols="2">Amazon Rand RF</cell><cell cols="2">BookCr. 3 Rand RF</cell><cell cols="2">Flixster Rand RF</cell></row><row><cell>CML</cell><cell></cell><cell>50.3</cell><cell></cell><cell>50.1</cell><cell></cell><cell>39.1</cell><cell></cell><cell>20.5</cell></row><row><cell cols="2">TransCF emb 19.9</cell><cell cols="2">50.3 20.1</cell><cell cols="2">50.3 13.8</cell><cell cols="2">40.1 10.0</cell><cell>20.5</cell></row><row><cell>TransCF</cell><cell></cell><cell>53.0</cell><cell></cell><cell>50.8</cell><cell></cell><cell>43.7</cell><cell></cell><cell>23.4</cell></row><row><cell>vs. CML</cell><cell>-</cell><cell>5.3</cell><cell>-</cell><cell>1.5</cell><cell>-</cell><cell>11.7</cell><cell>-</cell><cell>14.2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE VI :</head><label>VI</label><figDesc>Analysis on the user-item specific translation vectors regarding the ratings. (Eqn 7. denotes the percentage of interactions that satisfyEquation 7, and Ptn. denotes the portion of each class.)</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>Rating</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Ciao</cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell></cell><cell></cell></row><row><cell>Eqn 7</cell><cell>61.5%</cell><cell cols="4">51.4% 55.4% 52.2% 55.4%</cell><cell></cell><cell></cell></row><row><cell>Ptn.</cell><cell>4.8%</cell><cell cols="4">5.1% 11.4% 29.0% 49.7%</cell><cell></cell><cell></cell></row><row><cell>Amazon</cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell></cell><cell></cell></row><row><cell>Eqn 7</cell><cell>76.7%</cell><cell cols="4">76.3% 75.7% 75.2% 75.4%</cell><cell></cell><cell></cell></row><row><cell>Ptn.</cell><cell>7.0%</cell><cell cols="4">5.7% 10.7% 20.1% 56.5%</cell><cell></cell><cell></cell></row><row><cell>BookCr.</cell><cell>1-4</cell><cell>5</cell><cell>6</cell><cell>7</cell><cell>8</cell><cell>9</cell><cell>10</cell></row><row><cell>Eqn 7</cell><cell>55.3%</cell><cell cols="4">52.7% 55.2% 56.1% 57.2%</cell><cell>58.4%</cell><cell>58.8%</cell></row><row><cell>Ptn.</cell><cell>3.8%</cell><cell cols="4">10.3% 7.9% 17.0% 24.5%</cell><cell>17.3%</cell><cell>19.2%</cell></row><row><cell cols="2">Flixster 0.5-2.5</cell><cell>3.0</cell><cell>3.5</cell><cell>4.0</cell><cell>4.5</cell><cell>5.0</cell><cell></cell></row><row><cell>Eqn 7</cell><cell>19.6%</cell><cell cols="4">19.9% 19.9% 22.2% 25.7%</cell><cell>27.2%</cell><cell></cell></row><row><cell>Ptn.</cell><cell>17.3%</cell><cell cols="4">17.0% 16.8% 19.6% 10.1%</cell><cell>19.2%</cell><cell></cell></row><row><cell cols="8">of interactions that satisfy Equation 7 in each rating group.</cell></row><row><cell cols="8">Table VI shows the results. Under the assumption that higher</cell></row><row><cell cols="8">ratings imply a higher intensity of user-item relationships,</cell></row><row><cell cols="8">we expect more observed interactions to satisfy Equation 7</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE VII :</head><label>VII</label><figDesc>Results of item category classification.</figDesc><table><row><cell>Dataset</cell><cell>Method</cell><cell>Rand.</cell><cell>Random Forest</cell></row><row><cell></cell><cell>CML</cell><cell></cell><cell>67.86±0.47%</cell></row><row><cell>Ciao</cell><cell>TransCF emb</cell><cell>10.01%</cell><cell>67.27±0.28%</cell></row><row><cell></cell><cell>TransCF</cell><cell></cell><cell>80.97±0.73%</cell></row><row><cell>Amazon C&amp;A</cell><cell>CML TransCF emb TransCF</cell><cell>10.40%</cell><cell>54.26±0.74% 54.85±0.51% 81.24±0.46%</cell></row><row><cell cols="4">(a) Classification on translation vectors (rui).</cell></row><row><cell>Dataset</cell><cell>Method</cell><cell>Rand.</cell><cell>Random Forest</cell></row><row><cell>Ciao</cell><cell>CML TransCF</cell><cell>10.92%</cell><cell>80.41±1.59% 81.61±1.54%</cell></row><row><cell>Amazon C&amp;A</cell><cell>CML TransCF</cell><cell>9.40%</cell><cell>47.94±3.34% 47.90±2.54%</cell></row><row><cell cols="4">(b) Classification on item embeddings (β i ).</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>.41 0.43 0.39 0.35 0.51 0.41 0.51 0.53 0.4 0.42 0.5 0.44 0.42 0.45 0.41 1 0.41 0.44 0.41 0.47 0.44 0.55 0.42 0.39 0.69 0.41 0.51 0.62 0.53 0.39 0.39 0.39 0.33 0.53 0.39 0.45 0.35 0.38 0.39 0.38 0.38 0.4 0.39 0.33 0.42 0.42 0.39 0.43 0.39 0.44 0.44 0.59 0.4 0.39 0.55 0.44 0.43 0.53 0.54</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">TransCF</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Method: CML, Dataset: ciao, Threshold: 0.5, Perplexity: 30 | numSamples: 200</cell><cell></cell><cell>Method: TransCF, Dataset: ciao, Threshold: 0.5, Perplexity: 30 | numSamples: 200</cell><cell>DVDs</cell><cell cols="10">0.65 0.42 0.44 0.38 0.39 0.47 0.42 0.41 0.44 0.44</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Shopping Ciao Cafe Entertainment Food &amp; Drink Travel Music Beauty</cell><cell cols="10">0.41 00.42 0.5 0.44 0.38 0.39 0.44 0.5 0.41 0.45 0.43</cell><cell>0.60 0.75 0.90</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Internet</cell><cell cols="10">0.44 0.45 0.53 0.43 0.38 0.62 0.44 0.53 0.64 0.51</cell><cell>0.45</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Games</cell><cell cols="10">0.44 0.43 0.54 0.39 0.39 0.53 0.41 0.4 0.51 0.6</cell></row><row><cell>DVDs Beauty (a) Visualization of r CM L Music Travel Food &amp; Drink Entertainment Ciao Cafe Shopping ui</cell><cell>Internet Games</cell><cell>DVDs Beauty (b) Visualization of r TransCF Music Travel Food &amp; Drink Entertainment Ciao Cafe Shopping ui</cell><cell>Internet Games</cell><cell>DVDs</cell><cell>Beauty</cell><cell>Music</cell><cell>Travel</cell><cell>Food &amp; Drink</cell><cell>Entertainment</cell><cell>Ciao Cafe</cell><cell>Shopping</cell><cell>Internet</cell><cell>Games</cell></row><row><cell cols="4">Fig. 4: t-SNE visualization of translation vectors of Ciao dataset regard-</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>ing the item categories.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">In Section II, we show the existence of the intensity and the heterogeneity of user-item relationships in implicit feedback.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">It is unavoidable to use explicit feedback datasets as it is not feasible to judge the intensity of user-item relationships from implicit feedback.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">We regard ratings of less than 4 as a single class as they account for only 3.86%.<ref type="bibr" target="#b3">4</ref> We balance the class distribution by randomly sampling a fixed number of samples (num. samples in the minority class) from each class. We then perform 5-fold cross validation. We use the default setting of the random forest classifier in Scikit-learn<ref type="bibr" target="#b31">[32]</ref>, but the accuracies could be further improved by tuning the classifier.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">Note that for Bookcrossing dataset, the number of observed interactions whose ratings are less than 4 account for a small proportion (3.86%), and are therefore negligible.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Factorization meets the neighborhood: a multifaceted collaborative filtering model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Koren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGKDD</title>
		<meeting>SIGKDD</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Recommender systems survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bobadilla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ortega</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hernando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gutiérrez</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>Knowledge-based systems</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Maximum inner-product search using cone trees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Gray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGKDD</title>
		<meeting>SIGKDD</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Collaborative metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-K</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Estrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of WWW</title>
		<meeting>WWW</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Collaborative filtering via euclidean embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Khoshneshin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">N</forename><surname>Street</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of RecSys</title>
		<meeting>RecSys</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Playlist prediction via metric embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Turnbull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGKDD</title>
		<meeting>SIGKDD</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Personalized ranking metric embedding for next new poi recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">M</forename><surname>Chee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Translating embeddings for modeling multi-relational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Garcia-Duran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Yakhnenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in NIPS</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning entity and relation embeddings for knowledge graph completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI. Citeseer</title>
		<meeting>AAAI. Citeseer</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Fism: factored item similarity models for top-n recommender systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kabbur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Karypis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGKDD</title>
		<meeting>SIGKDD</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Collaborative denoising auto-encoders for top-n recommender systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dubois</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">X</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ester</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of WSDM</title>
		<meeting>WSDM</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Slim: Sparse linear methods for top-n recommender systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Karypis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICDM. IEEE</title>
		<meeting>ICDM. IEEE</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A comprehensive survey of neighborhood-based recommendation methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Desrosiers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Karypis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Recommender systems handbook</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Item-based collaborative filtering recommendation algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sarwar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Karypis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Konstan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Riedl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of WWW</title>
		<meeting>WWW</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">mTrust: Discerning multi-faceted trust in a connected world</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of WSDM</title>
		<meeting>WSDM</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mcauley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of WWW. International World Wide Web Conferences Steering Committee</title>
		<meeting>WWW. International World Wide Web Conferences Steering Committee</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.0473</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Fast matrix factorization for online recommendation with implicit feedback</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-Y</forename><surname>Kan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-S</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGIR</title>
		<meeting>SIGIR</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">One-class collaborative filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">N</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Lukose</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Scholz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICDM</title>
		<meeting>ICDM</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Improving pairwise learning for item recommendation from implicit feedback</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rendle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Freudenthaler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of WSDM</title>
		<meeting>WSDM</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Wsabie: scaling up to large vocabulary image annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Usunier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IJCAI</title>
		<meeting>IJCAI</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">2nd workshop on information heterogeneity and fusion in recommender systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Cantador</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Brusilovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kuflik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of RecSys</title>
		<meeting>RecSys</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Vbpr: Visual bayesian personalized ranking from implicit feedback</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mcauley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Improving recommendation lists through topic diversification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-N</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Mcnee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Konstan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lausen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of WWW</title>
		<meeting>WWW</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Learning image and user features for recommendation in social networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-S</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A matrix factorization technique with trust propagation for recommendation in social networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jamali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ester</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of RecSys</title>
		<meeting>RecSys</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Bpr: Bayesian personalized ranking from implicit feedback</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rendle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Freudenthaler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Gantner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Schmidt-Thieme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of UAI</title>
		<meeting>UAI</meeting>
		<imprint>
			<publisher>AUAI Press</publisher>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Neural collaborative filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-S</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th WWW</title>
		<meeting>the 26th WWW</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Translation-based recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-C</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mcauley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of RecSys</title>
		<meeting>RecSys</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Deep matrix factorization models for recommender systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-J</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X.-Y</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Random forests</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Scikit-learn: Machine learning in Python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vanderplas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cournapeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brucher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Perrot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Duchesnay</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>JMLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Visualizing data using t-sne</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">V D</forename><surname>Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Gbpr: Group preference based bayesian personalized ranking for one-class collaborative filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Local collaborative ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lebanon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of WWW</title>
		<meeting>WWW</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Logistic matrix factorization for implicit feedback data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Distance metric learning: A comprehensive survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">A survey on metric learning for feature vectors and structured data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bellet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Habrard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sebban</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1306.6709</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Metric learning for text documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lebanon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A three-way model for collective learning on multi-relational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Tresp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-P</forename><surname>Kriegel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">A latent factor model for highly multi-relational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jenatton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">L</forename><surname>Roux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">R</forename><surname>Obozinski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in NIPS</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Collaborative knowledge base embedding for recommender systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">J</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGKDD</title>
		<meeting>SIGKDD</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
