<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Structure fusion based on graph convolutional networks for semi-supervised classification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="20192-07-08">July 8, 2019 2 Jul 2019</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangfeng</forename><surname>Lin</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Information Science Department</orgName>
								<orgName type="institution">Xi&apos;an University of Technology</orgName>
								<address>
									<addrLine>5 South Jinhua Road</addrLine>
									<postCode>710048</postCode>
									<settlement>Xi&apos;an</settlement>
									<region>Shaanxi Province</region>
									<country key="CN">PR China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Information Science Department</orgName>
								<orgName type="institution">Xi&apos;an University of Technology</orgName>
								<address>
									<addrLine>5 South Jinhua Road</addrLine>
									<postCode>710048</postCode>
									<settlement>Xi&apos;an</settlement>
									<region>Shaanxi Province</region>
									<country key="CN">PR China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiyang</forename><surname>Liao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Information Science Department</orgName>
								<orgName type="institution">Xi&apos;an University of Technology</orgName>
								<address>
									<addrLine>5 South Jinhua Road</addrLine>
									<postCode>710048</postCode>
									<settlement>Xi&apos;an</settlement>
									<region>Shaanxi Province</region>
									<country key="CN">PR China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fan</forename><surname>Zhao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Information Science Department</orgName>
								<orgName type="institution">Xi&apos;an University of Technology</orgName>
								<address>
									<addrLine>5 South Jinhua Road</addrLine>
									<postCode>710048</postCode>
									<settlement>Xi&apos;an</settlement>
									<region>Shaanxi Province</region>
									<country key="CN">PR China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanjun</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Information Science Department</orgName>
								<orgName type="institution">Xi&apos;an University of Technology</orgName>
								<address>
									<addrLine>5 South Jinhua Road</addrLine>
									<postCode>710048</postCode>
									<settlement>Xi&apos;an</settlement>
									<region>Shaanxi Province</region>
									<country key="CN">PR China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Structure fusion based on graph convolutional networks for semi-supervised classification</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="20192-07-08">July 8, 2019 2 Jul 2019</date>
						</imprint>
					</monogr>
					<note type="submission">Preprint submitted to Journal of L A T E X Templates</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T16:23+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>structure fusion</term>
					<term>graph convolutional networks</term>
					<term>semi-supervised classification</term>
					<term>citation networks * Corresponding author</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Suffering from the multi-view data diversity and complexity for semi-supervised classification, most of existing graph convolutional networks focus on the networks architecture construction or the salient graph structure preservation, and ignore the the complete graph structure for semi-supervised classification contribution. To mine the more complete distribution structure from multi-view data with the consideration of the specificity and the commonality, we propose structure fusion based on graph convolutional networks (SF-GCN) for improving the performance of semi-supervised classification. SF-GCN can not only retain the special characteristic of each view data by spectral embedding, but also capture the common style of multi-view data by distance metric between multi-graph structures. Suppose the linear relationship between multigraph structures, we can construct the optimization function of structure fusion model by balancing the specificity loss and the commonality loss. By solving this function, we can simultaneously obtain the fusion spectral embedding from the multi-view data and the fusion structure as adjacent matrix to input graph convolutional networks for semi-supervised classification. Experiments demonstrate that the performance of SF-GCN outperforms that of the state of the arts on three challenging datasets, which are Cora,Citeseer and Pubmed in citation networks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>As a efficient representation of data distribution, graph plays a important role for describing the intrinsic structure of data. Therefore, many existing works have constructed the significant theory and method depending on the graph structure of data in pattern recognition, such as graph cut building energy function for semantic segmentation task <ref type="bibr" target="#b0">[1]</ref>, graph-based learning system constructing the accurate recommendations for the interaction of the different objects <ref type="bibr" target="#b1">[2]</ref>  <ref type="bibr" target="#b2">[3]</ref>, graph modeling molecules bioactivity for drug discovery <ref type="bibr" target="#b3">[4]</ref>  <ref type="bibr" target="#b4">[5]</ref> and graph simulating the link connection of citation network for the different group classification <ref type="bibr" target="#b3">[4]</ref>[5] <ref type="bibr" target="#b5">[6]</ref>. In fact, we usually observe objects and their relationship (this relationship is defined as the objects of structure, which often can be described by graph.) from multiple views, which provide the more abundant and complete information for object recognition. Learning on multi-graph (multiple observation structure) can effectively mine multiple relationship to discriminate the different object. Existing learning methods on multi-graph trend to tow ways. One is structure fusion <ref type="bibr" target="#b6">[7]</ref> [8] <ref type="bibr" target="#b8">[9]</ref>[10] <ref type="bibr" target="#b10">[11]</ref> <ref type="bibr" target="#b11">[12]</ref>[13] <ref type="bibr" target="#b13">[14]</ref> [15] <ref type="bibr" target="#b15">[16]</ref> <ref type="bibr" target="#b16">[17]</ref> or diffusion on tensor product graph <ref type="bibr" target="#b17">[18]</ref> [19] <ref type="bibr" target="#b19">[20]</ref> [21] <ref type="bibr" target="#b21">[22]</ref> [23] based on the complete data, which include each view obser-vation data. Another is graph convolutional networks for the salient graph structure preservation <ref type="bibr" target="#b5">[6]</ref> based on the incomplete data, which lost some view observation data.</p><p>For example, link relationship can be extracted by application necessary in citation networks, but it can not be described by the corresponding observation data computation.</p><p>In other words, these link relationship exists, while the corresponding support data lost. Therefore, the method based on graph convolutional networks usually ignores the complete complementary of the different observation structure based on the incomplete multi-view data. To analysis this issue, we attempt to construct structure fusion based on graph convolutional networks for classification. <ref type="figure" target="#fig_0">Figure 1</ref> shows the overall flow diagram of structure fusion based on graph convolutional networks (SF-GCN).</p><p>The inspiration of SF-GCN comes from Multi-GCN in the literature <ref type="bibr" target="#b5">[6]</ref>, but there are tow points difference comparison with Multi-GCN. One is that SF-GCN considers the inequality of multiple structures, while Multi-GCN only equally deal with their relationship. The other is that SF-GCN focuses on the contributions of all nodes structure in the fusion structure, while Multi-GCN only emphasises on the salient structure of the part nodes. From the classification sense,the strong and weak links between nodes both considered for complementing structure can more fit to the intrinsic structure of the data for classification.</p><p>Our contributions can be summarized as following. (a)We present a novel structure fusion based on graph convolutional networks (SF-GCN) that discriminates the different classes by optimizing the linear relationship of multiple observation structure with balancing the specificity loss and the commonality loss. (b) In three citation datasets with document sparse feature and document link relationship, the proposed SF-GCN outperforms the state of the arts for semi-supervised classification. (c) Our model is generalized the different multi-graph fusion methods for evaluating the performance of the proposed SF-GCN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Works</head><p>In this section, we mainly review recent related works about structure fusion and graph neural network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Structure fusion</head><p>Structure fusion initially proposed in <ref type="bibr" target="#b6">[7]</ref>can merge multiple structures for shape classification. In the follow-up works, the extend methods can be divided into three categories according to the different fusion ways. The first kind of methods try to find the optimized linear relationship of multiple observation structure based on the different manifold learning method <ref type="bibr" target="#b7">[8]</ref> or statistics model analysis <ref type="bibr" target="#b8">[9]</ref>. The second kind of methods attempt to mine the nonlinear relationship of heterogeneous feature structure based on the global feature[10] <ref type="bibr" target="#b10">[11]</ref> or the local feature encoding <ref type="bibr" target="#b11">[12]</ref>. The third kind of methods can capture the dynamic changes of multiple structures for semi-supervised classification <ref type="bibr" target="#b12">[13]</ref>or the structure propagation way for zero-shot learning <ref type="bibr" target="#b13">[14]</ref> [15] <ref type="bibr" target="#b15">[16]</ref> <ref type="bibr" target="#b16">[17]</ref>.</p><p>From above mention, existing methods emphasis on the completeness of data and their relationship based on data project, while graph convolutional networks focus on the transformation and evolution of data structure by deep learning frameworks. Therefore, we expect to draw support from structure fusion based on structure metric and graph convolutional networks for processing the incomplete view data, and find evolution law of the the fusion structure with the consideration of their specificity and commonality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Graph neural network</head><p>Graph neural networks can discover the potential data relationship by the computation based on graph nodes and links. Especially, the computation is defined as convolution for graph data, and graph convolution networks (GCN) have become a promising direction in pattern recognition. In terms of the different node representation, graph convolution networks include spectral-based GCN and spatial-based GCN. Spectralbased GCN can define graph Fourier transform based on graph Laplacian matrix for projecting graph signal into the orthonormal space. The difference of these methods is the selection of the filter, which may be the learned parameters set <ref type="bibr" target="#b23">[24]</ref>, Chebyshev polynomial <ref type="bibr" target="#b3">[4]</ref>, or the first-order Chebyshev polynomial <ref type="bibr" target="#b24">[25]</ref>  <ref type="bibr" target="#b25">[26]</ref>. Spatial-based GCN regards images as a special graph with a pixel describing a node. To avoid the storage of all states, these methods have present the improved training strategies, such as subgraph training <ref type="bibr" target="#b26">[27]</ref>or stochastically asynchronous training <ref type="bibr" target="#b27">[28]</ref>. Furthermore, some complex networks architecture can utilize gating unite to control the selection of node neighborhood <ref type="bibr" target="#b28">[29]</ref>, or design two graph convolution networks with the consideration of the local and global consistency on graph <ref type="bibr" target="#b29">[30]</ref> , or adjust the receptive field of node on graph by hyper-parameters <ref type="bibr" target="#b30">[31]</ref>.</p><p>Because spectral-based GCN can explicitly construct the learning model on the graph structure,which can easily be separated from GCN architecture. Therefore, this point provides a way for processing multiple structures, which may be incremental. In this paper, we focus on the important role of graph (structure) from multi-view data, and attempt to mine the plentiful information from multiple structures for spectralbased GCN inputting. To the best of our knowledge,existing structure fusion methods usually construct the optimizing function for feature projection, in which feature data and the corresponding structure jointly participate in computation. Because of the possible loss and the structure preservation of multi-view data, we expect to build a novel structure fusion by structure metric, in which the optimizing function only involves multiple structures for avoiding the negative effect of the data lost. Simultaneously, multiple structures have each specificity and their commonality. Therefore,we also anticipate that a novel structure fusion can be constrained by these characteristics of multiple structures. <ref type="figure">Figure</ref> 2 demonstrates the internal mechanism of structure fusion in SF-GCN. First, we construct the specificity loss based on spectral embedding method with the consideration of multiple structure linear relationship. Second, we measure the commonality loss between multiple structures based on distance metric in Grassman manifold. Finally, we jointly exploit the structure fusion based on two losses, and input GCN for classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Structure fusion based on graph convolutional networks</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Specificity loss of multiple structures</head><p>Given an object set with m multi-view, we can use graph G i to describe the observation distribution of data on each view. Therefore, the graph G i is the representation of the observation structure and G = {G i |i = 1, 2, ..., m} can indicate multiple structures of data from multi-view observations. Because multiple structures detail the same object set, each G i includes the same vertex set V , or the possible different edges set E i . If W i is the adjacency matrix of G i and is the numerical expression of the structure in ith view. In terms of spectral embedding, we can obtain the following optimization function on the embedding matrix Y i ∈ R n×k (n is the number of samples, and k is the dimension of embedding space) of each view.</p><formula xml:id="formula_0">Y i = arg min tr(Y T i L i Y i ), s.t. Y T i Y i = 1 (1) Where, L i = D i − W i is Laplacian matrix of G i , D i is the degree matrix for G i .</formula><p>Therefore, L i can still describe the characteristic of structure on graph G i . We can compute the embedding matrix Y i by optimizing equation <ref type="formula">(1)</ref>, which is equivalent to a eigenvalue solution problem. When all eigenvalues are solved, eigenvectors corresponding to the smallest eigenvalues can build the embedding matrix Y i , which can project the original nodes into the low dimensional spectral space <ref type="bibr" target="#b31">[32]</ref>. We can regard</p><formula xml:id="formula_1">tr(Y T i L i Y i )</formula><p>as the specificity loss of structure on graph graph G i , and then we can reformulate the specificity loss of multiple structures as follow.</p><formula xml:id="formula_2">Loss s = tr(Y T LY )<label>(2)</label></formula><p>Where, Y is the embedding matrix of multiple structures in graph G and closely approximates Y i . Suppose fusion structure W is the linear combination of W i , then L and L i have the same linear relationship L = m i=1 β i L i , in which β i is the linear coefficient to encode the importance of multiple structures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Commonality loss of multiple structures</head><p>To measure the commonality loss of multiple structures, we need metric the distance between Laplacian matrix L i and L. According to the solvation of the equation <ref type="formula">(1)</ref>, we can obtain the equation <ref type="formula">(3)</ref> for describing the internal connection between embedding matrix Y i and the corresponding Laplacian matrix L i .</p><formula xml:id="formula_3">L i = Y i λ i Y T i (3)</formula><p>Where, λ i is diagonal matrix, in which diagonal values is the smallest eigenvalues of L i . Y i can be explained a subspace for preserving the smaller variance of the column in L i , that is for reserving the bigger variance of the column in the structure W i . In other words, Y i can keep the more discrimination of the data. Similarly, Y has the same sense in multiple observation structure. Therefore, we can replace the distance between Laplacian matrix L i and L by the distance between Y i and Y for indirectly computing the commonality loss of multiple structures. This point is consistent with the specificity loss of the assumption, which is that Y i approximates Y between each view and multi-view.</p><p>In terms of Grassmann manifold theory <ref type="bibr" target="#b32">[33]</ref>[34], the orthonormal matrix Y i ∈ R n×k can be regard as the column of Y i spanning an unique subspace, which can be project into an unique point on Grassmann manifold G(n, k). Similarly, Y also can be mapped into an unique point on this Grassmann manifold. Therefore, the principle angles {θ j } k j=1 between these subspaces can represent the distance between Y i and Y . Furthermore, this distance can be reformulate as following <ref type="bibr" target="#b34">[35]</ref>.</p><formula xml:id="formula_4">d 2 (Y, Y i ) = k j=1 sin 2 θ j = k − tr(Y Y T Y i Y T i )<label>(4)</label></formula><p>In multiple structures, we can define the commonality loss Loss c as the distance be-</p><formula xml:id="formula_5">tween Y and {Y i } m i=1 as following. Loss c = m i=1 d 2 (Y, Y i ) = km − m i=1 tr(Y Y T Y i Y T i )<label>(5)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Structure fusion by structure metric losses</head><p>As two structure metric losses, specificity loss can balance the contribution of the structure in each view, while commonality loss can consider the similarity of multiple structures in multi-view. These structure metric losses can both constrain the linear</p><formula xml:id="formula_6">relationship {β i } m i=1</formula><p>of multiple structures. Therefore, we combine these structure metric losses as a total loss for encoding the importance of multiple structures. The total loss can be reformulated as following.</p><formula xml:id="formula_7">Loss = loss s + αloss c<label>(6)</label></formula><p>Where, α is regularization parameter. From equation <ref type="formula" target="#formula_7">(6)</ref>, we can construct the object optimization function as following.</p><formula xml:id="formula_8">{Y, {β i } m i=1 } = arg min(loss s + αloss c ) = arg min tr(Y T LY ) + α(km − m i=1 tr(Y Y T Y i Y T i )) = arg min tr(Y T m i=1 β i L i Y ) + α(km − m i=1 tr(Y Y T Y i Y T i )) s.t. Y T Y = 1, m i=1 β i = 1, α &gt; 0<label>(7)</label></formula><p>In commonality loss, constant term km can not influence the loss trend change, so we may remove this term for conveniently computing. Equation <ref type="formula" target="#formula_8">(7)</ref> is reformulated as equation <ref type="formula" target="#formula_9">(8)</ref> for balancing parameter {β i } m i=1 between 0 and 1.</p><formula xml:id="formula_9">{Y, γ} = arg min(tr(Y T m i=1 β i L i Y ) − α m i=1 tr(Y Y T Y i Y T i ))) 2 = arg min(tr(Y T ( m i=1 β i L i − α m i=1 Y i Y T i )Y )) 2 s.t. Y T Y = 1, m i=1 β i = 1, α &gt; 0, γ = {{β i } m i=1 , α}<label>(8)</label></formula><p>Equation <ref type="formula" target="#formula_9">(8)</ref> is a nonconvex optimization problem, we can solve this problem by Y and γ alternated optimization. If γ is fixed, equation <ref type="formula" target="#formula_9">(8)</ref> can be transformed as a eigenvalue solving problem as following.</p><formula xml:id="formula_10">{Y } = arg min tr(Y T M Y ) s.t. Y T Y = 1, α &gt; 0, M = ( m i=1 β i L i − α m i=1 Y i Y T i ), γ = {{β i } m i=1 , α}<label>(9)</label></formula><p>Equation <ref type="formula" target="#formula_10">(9)</ref>is equivalent to a eigenvalue solution problem. When all eigenvalues of M are solved, eigenvectors corresponding to the smallest eigenvalues can build the fusion embedding matrix Y . If Y is fixed, equation <ref type="formula" target="#formula_9">(8)</ref> can be converted into a quadratic programming problem as following.</p><formula xml:id="formula_11">{γ} = arg min(tr(Y T ( m i=1 β i L i − α m i=1 Y i Y T i )Y )) 2 s.t. m i=1 β i = 1, α &gt; 0, γ = {{β i } m i=1 , α}<label>(10)</label></formula><p>By alternated solving between equation <ref type="formula" target="#formula_10">(9)</ref> and equation <ref type="formula" target="#formula_11">(10)</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Graph convolutional networks</head><p>In terms of the multiplication of convolution in the Fourier domain, graph convolution is defined as the the multiplication between the signal s ∈ R n and the filter g η <ref type="bibr" target="#b23">[24]</ref>.</p><p>Furtherly, graph convolution can also be approximated by 1 th -order Chebyshev polynomials <ref type="bibr" target="#b24">[25]</ref> as following. Computing the spectral embedding fusion Y of multiple structures in multi-view by equation <ref type="formula" target="#formula_10">(9)</ref> 6:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Fusion structure of multiple structures</head><formula xml:id="formula_12">Input: {W i } m i=1 : n × n adjacency matrices of graph {G i } m i=1 ; α:</formula><p>Updating the linear relationship γ of multiple structures by equation <ref type="formula" target="#formula_11">(10)</ref> 7: end for</p><formula xml:id="formula_13">8: Computing fusion structure by W = m i=1 β i W i g η * s = U g η U T s ≈ 1 k=0 η k T k (L)s ≈ η(I +D −1/2WD−1/2 )s<label>(11)</label></formula><p>Where, U is the eigen-decomposition of the normalized Laplacian L = I−D −1/2 W D −1/2 (I is the identity matrix; D is the degree matrix of graph G);L = I −D −1/2WD−1/2 (D andW respectively are the rescaled degree and adjacent matrix byW = W + I);</p><p>T k expresses the Chebyshev polynomials; η = η 0 = −η 1 .</p><p>Fusion structure W can directly be input into the above graph convolutional networks. The forward propagation based on two layers of graph convolutional networks can be indicated as following.</p><formula xml:id="formula_14">Z = sof tmax(W ReLU (W SΘ 0 )Θ 1 )<label>(12)</label></formula><p>Where, Z is the output of networks;S is the representation matrix of each nodes;Θ 0 and Θ 1 respectively are the 1 th and 2 th layer filter parameters; ReLU and sof tmax are the different type of activation function located in the various layers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>For evaluating the proposed SF-GCN, we carry out the experiments from four aspects. Firstly, we conduct the comparing experiment between the proposed SF-GCN and the baseline methods, which include graph convolutional networks (GCN) <ref type="bibr" target="#b24">[25]</ref> with the combination view and Multi-GCN <ref type="bibr" target="#b5">[6]</ref>. Secondly,we utilize the different multigraph fusion methods for analyzing the intrinsic mechanism of the proposed SF-GCN.</p><p>Thirdly, we show the experimental results between the proposed SF-GCN and the state of the art methods for the node classification in citation networks. Finally, we implement the proposed SF-GCN method of the lost structure for demonstrating the importance of the complete structure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Datasets</head><p>We use the paper-citation networks of the citation networks in experiments. The three popular datasets usually utilized in node classification respectively are Cora, Citeseer and Pubmed. Cora dataset has 7 classes that involve 2708 the grouped publication about machine learning and their undirected graph. Citeseer dataset includes 6 classes that have 3327 scientific papers and their undirected graph. In these datasets, each publication stands for a node of the related graph and is represented by one-hot vector, each element of which can indicate the presence and absence state of a word in the learned directory. Pubmed dataset has 3 classes that contain 19717 diabetes-related publications and their undirected graph. In this dataset, each paper (each node of the related graph) can be described by a term frequency-inverse document frequency (TF-IDF) <ref type="bibr" target="#b35">[36]</ref>. <ref type="table" target="#tab_0">Table 1</ref> shows the statistics of these datasets. To obtain the structure of the second view from publication description, we normalize the cosine similarity between these publication. If these similarity is greater than 0.8, we produce an edge for the corresponding to nodes in the citation network. This configuration is same in the literature <ref type="bibr" target="#b5">[6]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Experimental configuration</head><p>In experiments, we follow the configuration in GCN <ref type="bibr" target="#b24">[25]</ref>, in which we train a twolayer GCN for maximum of 200 epochs and test model in 1000 labeled samples. Moreover, we select the same validation set of 500 labeled sample for hyper-parameter optimization (dropout rate for all layers, number of hidden units and learning rate).</p><p>In proposed SF-GCN, we initially set the linear relationship {β i } m i=1 of multiple structures and regularization parameter α as 0.5, and then update these parameters in iteration optimization. The iteration time T of the algorithm is 5 according it's the convergence degree in fact.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Comparison with the base-line methods</head><p>The proposed method (SF-GCN) can be constructed based on GCN <ref type="bibr" target="#b24">[25]</ref>, and attempt to mine the different structure information for completing the intrinsic structure in multi-view data. Therefore, two base-line methods (GCN and Multi-GCN can find and capture the different structure information from the different consideration.) is involved for processing multi-view data based on GCN. GCN for multi-view <ref type="bibr" target="#b24">[25]</ref> can concatenate the different structure to build a sparse block-diagonal matrix where each block corresponding to the different structure (the adjacent matrix of different graph).</p><p>Multi-GCN <ref type="bibr" target="#b5">[6]</ref> can preserve the significant structure of the different structure by manifold ranking. In contrast with these base-line methods, the proposed method (SF-GCN) can not only enhance the common structure, but also retain the specific structure by structure fusion. <ref type="table" target="#tab_1">Table 2</ref> shows that the classification performance of SF-GCN outperforms that of the base-line methods and the least improvement of SF-GCN respectively is 0.7% for Cora, 2.1% for Citeseer and 0.6% for PubMed. However, GCN for multi-view is not superior to GCN for single-view, and it demonstrates that information mining of multiview data is a key point for node classification. Therefore, SF-GCN attempt to mine the structure information from multi-view data for this purpose and obtain the better performance.  <ref type="bibr" target="#b21">[22]</ref> and propagation <ref type="bibr" target="#b15">[16]</ref>  <ref type="bibr" target="#b13">[14]</ref> of the different structure can also describe the complex relationship of the various structure, and become the important part of structure fusion. Therefore, we can define fusion structure W by the propagation fusion (PF) of the different structure as follow.</p><formula xml:id="formula_15">W = m i W i<label>(13)</label></formula><p>The propagation fusion can exchange and interact the relationship information between the various structures, and mine the neighbour relationship of multiple structures. However,this propagation can effect on the clustering performance of the original structure by high-order iteration multiplication. Therefore, we only consider zero-order (for example SF) and first-order (for instance PF) multiplication, that is structure propagation fusion (SPF) as follow.</p><formula xml:id="formula_16">W = m i=1 β i W i + m i W i<label>(14)</label></formula><p>For evaluating structure fusion generalization, we compare structure fusion based graph convolutional networks (SF-GCN), propagation fusion based graph convolutional networks (PF-GCN) and structure propagation fusion based graph convolutional networks (SPF-GCN).In <ref type="table" target="#tab_2">Table 3</ref>, we observe that the performance of SPF-GCN is better than that of other method, and the least improvement of SPF-GCN respectively is 0.2% for Cora, 0.1% for Citeseer and 0.7% for PubMed, while the performance of SP is superior to that of PF-GCN, and the improvement of SF-GCN respectively is 0.6% for Cora, 0.9% for Citeseer and 0.2% for PubMed Therefore, PF and SF both are benefit for further mining the structure information and the role of SF is more important than that of PF. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Comparison with the state-of-the-arts</head><p>Because graph convolutional networks and structure fusion are basic ideas for constructing the proposed method SPF-GCN, we analyze six related state-of-the-arts methods for evaluating SPF-GCN. These methods include two categories. One is node neighbour information exploiting for GCN, and another is node information fusion based on GCN.</p><p>Node neighbour information exploiting attempts to capture the distribution structure of the node neighbour for obtain the stable graph structure representation. For example, graph attention networks(GAT) can specify different weights to different nodes in a neighborhood <ref type="bibr" target="#b36">[37]</ref>; stochastic training of graph convolutional networks (StoGCN) allows sampling an arbitrarily small neighbor size <ref type="bibr" target="#b37">[38]</ref>; deep graph infomax(DGI) can maximize mutual information between different level subgraph centered around nodes of interest (the different way for considering neighbour information) <ref type="bibr" target="#b38">[39]</ref>.</p><p>Node information fusion tries to mine the information from multi-view node description or multiple structures for complementing the difference of multi-view data.</p><p>For instance, large-scale learnable graph convolutional networks (LGCN) can fuse neighbouring nodes feature by ranking selection to transform graph data into grid-like structures in 1-D format <ref type="bibr" target="#b39">[40]</ref>; dual graph convolutional networks (DGCN) can consider local and global consistency for fusion different views graph of raw data <ref type="bibr" target="#b29">[30]</ref>;</p><p>Multi-GCN can extract and select the significant structure form multi-view structure by manifold ranking <ref type="bibr" target="#b5">[6]</ref>.</p><p>The proposed method SPF-GCN belongs to node information fusion method, and the difference compared with the above methods focuses on the complementary of multiple structures by mining their commonality, specificity and interactive propagation. <ref type="table" target="#tab_3">Table 4</ref> shows SPF-GCN outperforms other state-of-the-art methods except DGCN in Cora and PubMed datasets. Although SPF-GCN and DGCN reach to the same performance in Cora and PubMed datasets, SPF-GCN can preserve the higher computation efficient of the original GCN because of the separable computation between structure fusion and GCN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.">Incomplete structure influence</head><p>Structure fusion can capture the complementary information of multiple structures, and this complementary information can supply an efficient way for incomplete structure influence. The main reason of the incomplete structure may be because of noise and data loss in practical situation. For evaluating the performance of the proposed methods under the condition of the incomplete structure, we design a experiment in all datasets. In semi-supervised classification, the distribution structure of test datasets is more important than that of train datasets, and can assure the performance of classification because of the transfer relation of structure between train and test datasets.</p><p>Therefore, we delete the some structure of test datasets to destroy this transfer relation for simulating incomplete structure.</p><p>In the details, we proportionally set the adjacency matrix(graph structure from the original dataset) of elements (corresponding to test datasets) to zero from 10% to 60%, and then respectively implement GCN for multi-view <ref type="bibr" target="#b24">[25]</ref>, DGCN <ref type="bibr" target="#b29">[30]</ref>, SF-GCN and SPF-GACN methods in all dataset. In <ref type="figure" target="#fig_4">figure 3</ref>, we select structure loss degree from 10%,20%,30%,40%,50%,60% to construct the different classification model for evaluating the performance of the compared methods. Especially, there is the smaller descent of SPF-GCN classification accuracy with structure loss increasing from 10% to 60%, e.g. 83.3 to 82.5 on Cora, 73.4 to 73.0 on Citeseer and 79.8 to 79.4 on PubMed.</p><p>We can observe that the proposed SF-GCN and SPF-GACN is more stable and robust with incomplete degree increasing of structure than GCN for multi-view and DGCN.</p><p>In this situation, the performance of SPF-GACN is better than that of SF-GACN, while the performance of GCN outperforms that of DGCN in Cora datasets, and the performance of DGCN is superior to that of GCN in Citeseer and PubMed datasets. The details of this reason can be analyzed in section 4.7. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7.">Experimental results analysis</head><p>In our experiments, we compare the proposed method with eight methods, which contain two kinds of base-line methods (Multi-GCN <ref type="bibr" target="#b5">[6]</ref>, GCN <ref type="bibr" target="#b24">[25]</ref> for multi-view, GCN <ref type="bibr" target="#b24">[25]</ref> for view1 and view2 in section 4.3), two kinds of structure fusion generalization methods (PF-GCN and SF-GCN in section 4.4), and six kinds of the state-ofthe-art methods(GAT <ref type="bibr" target="#b36">[37]</ref>, StoGCN <ref type="bibr" target="#b37">[38]</ref>, DGI <ref type="bibr" target="#b38">[39]</ref>, LGCN <ref type="bibr" target="#b39">[40]</ref>, DGCN <ref type="bibr" target="#b29">[30]</ref> and Multi-GCN <ref type="bibr" target="#b5">[6]</ref> in section 4.5). These methods can utilize the graph structure mining based graph convolutional networks for semi-supervised classification by the different ways.</p><p>In contrast to other methods, the proposed SF-GCN and SPF-GCN methods focus on the complementary relationship of multiple structures by the consideration of their commonality and specificity. Moreover, the proposed SPF-GCN method not only cap-ture the optimization distribution of fusion structure, but also emphasize on the interactive propagation between the different structures. From the above experiments, we can observe several points as following.</p><p>• The performance of SF-GCN is superior to that of the base-line methods (Multi-GCN <ref type="bibr" target="#b5">[6]</ref>, GCN <ref type="bibr" target="#b24">[25]</ref> for multi-view, GCN <ref type="bibr" target="#b24">[25]</ref> for view1 and view2 in section 4.3). GCN <ref type="bibr" target="#b24">[25]</ref> constructs a general graph convolutional architecture by the first-order approximation of spectral graph convolutions for greatly improving the computation efficiency of graph convolutional networks, and also provides a feasible deep mining frameworks for effective semi-supervised classification.</p><p>For using multiple structures, GCN for multi-view can input a sparse blockdiagonal matrix, each block of which corresponding to the different structure.</p><p>Therefore, the relationship of each block (the different structure) is ignored for GCN, and this point leads to the poor performance (in some times, the performance of GCN for multi-view is worse than that of GCN for view1) of GCN for multi-view. In contrast, Multi-GCN <ref type="bibr" target="#b5">[6]</ref> can capture the relationship of the different structure to preserve the significant structure of merging subspace. However, Multi-GCN <ref type="bibr" target="#b5">[6]</ref> neglects the optimizing fusion relationship of the different structure, while the proposed SF-GCN focuses on finding these relationship by jointly considering the commonality and specificity loss of multiple structure for obtaining the better performance of semi-supervised classification.</p><p>• SPF-GCN shows the best performance in structure fusion generalization experiments, whereas the performance of SF-GCN is better than that of SP-GCN. The main reason is that SF-GCN emphasises on the complement information by the optimizing fusion relationship of the different structure, while SP-GCN trends to the interactive propagation by the diffusion influence between the different structures. The complement fusion play the more important role than the interactive propagation because of the specificity structure of individual view data, but both fusion and propagation can contribute the multiple structures mining for enhancing the the performance of semi-supervised classification.</p><p>• The performance improvement of SPF-GCN compared with six kinds of the commonality for complementing the different information, but also to preserve the structure specificity for mining the discriminative information. Therefore, the proposed SPF-GCN can improve the classification performance in the most experiments. In the least, the proposed SPF-GCN have the similar performance than the best performance of other method in all experiments. In addition, the proposed SPF-GCN is based on GCN frameworks, so it has the efficient implementation like GCN. In experiments, the computation efficiency of the proposed SPF-GCN is the highest than that of the state-of-the-art methods (the details of the computation efficiency in section 3.2).</p><p>• Structure shows the distribution of data, and is very important for learning GCN model. Incomplete structure can evaluate the robustness of the related GCN model. We select the classical GCN, the state-of-the-art DGCN, SF-GCN and SPF-GCN for the robust test. The proposed SPF-GCN shows the best performance in three datasets. In Cora, the performance of GCN is better than DGCN,while the performance of GCN is worse than DGCN in Citeseer and</p><p>PubMed. It shows that local and global consistency for fusing graph information in DGCN trend to the unstable characteristic because of the tight constraint of incomplete structure consistency. The loose constraint of GCN for incomplete structure correlation leads to the worse performance. The proposed SPF-GCN can compromise these constrains for balancing the incomplete structure information by optimizing the weight of multiple structures, and also connect the different structure for complementing the different information. Therefore, the proposed SPF-GCN obtains the best performance in experiments.</p><p>• The proposed SPF-GCN expect to mine the commonality and the specificity of multiple structures. The commonality describes the similarity characteristic of structures by Grassmann manifold metric, while the specificity narrates the difference characteristic of structures by spectral embedding. In the proposed method, the specificity is constructed based on the commonality. Therefore, we only execute the ablation experiment for preserving the commonality loss by deleting the specificity loss from the total loss. This experiment obtain the following performance, that is 82.6% in Cora, 71.5% in Citeseer and 78.9% in PubMed. These results obviously are worse than the performance of the proposed SF-GCN and SPF-GCN, which can balance the commonality and specificity for mining the suited weight of multiple structures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>We have proposed structure fusion based on graph convolutional networks (SF-GCN) to address the multi-view data diversity and complexity for semi-supervised classification. SF-GCN can not only adapt spectral embedding to preserve the specificity of structure, but also model the relationship of the different structure to find the commonality of multiple structures by manifold metric. Furthermore, the proposed structure propagation fusion based graph convolutional networks(SPF-GCN) can combine structure fusion framework with structure propagation to generating the completer structure graph for improving the performance of semi-supervised classification. At last, the optimization learning of the SF-GCN can obtain both the suitable weight for the different structure and the merge embedding space. For evaluating the proposed SF-GCN and SPF-GCN, we carry out the comparison experiments about the baseline methods, the different multi-graph fusion methods, the state of the art methods and the the lost structure analysis on Cora,Citeseer and Pubmed datasets. Experiment results demonstrate SF-GCN and SPF-GCN get the promising results in semi-supervised classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Acknowledgements</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>The diagram of structure fusion based on graph convolutional networks (SF-GCN), in which three graphs indicating the structure of the multi-view data and eight nodes (the different color connecting lines mean the various connecting weights) expressing the multi-node in these graphs;β = [β 1 β 2 β 3 ] showing the linear coefficient between multi-graph structure for complementary fusion.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>The mechanism of structure fusion in SF-GCN.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>, we can obtain fusion embedding matrix Y and the linear relationship γ of multiple structures. Furthermore, fusion structure (fusion adjacent matrix) can be computed by W = m i=1 β i W i . Algorithm 1 shows the pseudo code for fusion structure of multiple structures. In this algorithm, there are three steps. The first step (line 1) initializes the linear relationship of multiple structures. The second step(from line 2 to line 3) computes the Laplacian matrix and the spectral embedding in each view. The third step (from line 4 to line 6) alternately optimizes the spectral embedding fusion and the linear relationship of multiple structures. The last step (line 8) calculates fusion structure by the linear combination of each structure. Therefore, the complexity of this algorithm is O(mn 3 + mn 2 kT + k 3.5 l 2 T ), in which m represents multi-view; n is the sample number; k is the dimension of the selected eigenvectors; T is the iterative times of optimization; l is the number of bits in the input of algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>2 :</head><label>2</label><figDesc>regularization parameter of the total loss; T : the iteration times Output: W : fusion structure of multiple structures 1: Initializing the linear relationship {β i } m i=1 of multiple structures and regularization parameter α Computing Laplacian matrix L i of G i 3: Computing the spectral embedding Y i of structure in each view by equation (1) 4: for 1 &lt; t &lt; T do 5:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Impact of structure loss on classification accuracy for citation networks on (a) Cora,(b)Citeseer and (c)PubMed datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Three datasets statistics in citation networks.</figDesc><table><row><cell>Datasets</cell><cell>Nodes</cell><cell>Edges</cell><cell>Classes</cell><cell>Feature</cell><cell>Label</cell></row><row><cell></cell><cell>number</cell><cell>number</cell><cell>number</cell><cell>dimension</cell><cell>rate</cell></row><row><cell>Cora</cell><cell>2708</cell><cell>5429</cell><cell>7</cell><cell>1433</cell><cell>0.052</cell></row><row><cell>Citeseer</cell><cell>3327</cell><cell>4732</cell><cell>6</cell><cell>3703</cell><cell>0.036</cell></row><row><cell>Pubmed</cell><cell>19717</cell><cell>44338</cell><cell>3</cell><cell>500</cell><cell>0.003</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Accuracy comparison of SF-GCN method with the base-line methods for node classification in citation network. View1 stands for graph structure from the original dataset, while view2 indicates graph structure from the cosine similarity of node representation</figDesc><table><row><cell>Method</cell><cell>Cora</cell><cell cols="2">Citeseer PubMed</cell></row><row><cell>GCN [25] for view1</cell><cell>81.5</cell><cell>70.3</cell><cell>78.7</cell></row><row><cell>GCN [25] for veiw2</cell><cell>53.6</cell><cell>50.7</cell><cell>69.5</cell></row><row><cell cols="2">GCN [25] for multi-view 80.4</cell><cell>70.7</cell><cell>78.2</cell></row><row><cell>Multi-GCN [6]</cell><cell>82.5</cell><cell>71.3</cell><cell>NA</cell></row><row><cell>SF-GCN</cell><cell>83.3</cell><cell>73.4</cell><cell>79.3</cell></row><row><cell>4.4. structure fusion generalization</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">Structure fusion (SF) focuses on the complementation of the distribution structure</cell></row><row><cell>from the different view data, and W =</cell><cell cols="3">m i=1 β i W i can be defined in section 3.3.</cell></row><row><cell>However, the diffusion [19] [22]</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Structure fusion generalization classification accuracy in three methods, which are structure fusion based graph convolutional networks (SF-GCN), propagation fusion based graph convolutional networks (PF-GCN) and structure propagation fusion based graph convolutional networks (SPF-GCN)</figDesc><table><row><cell>Method</cell><cell>Cora</cell><cell cols="2">Citeseer PubMed</cell></row><row><cell>SF-GCN</cell><cell>83.3</cell><cell>73.4</cell><cell>79.3</cell></row><row><cell>PF-GCN</cell><cell>82.7</cell><cell>72.5</cell><cell>79.1</cell></row><row><cell cols="2">SPF-GCN 83.5</cell><cell>73.5</cell><cell>80.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Accuracy comparison of SF-GCN and SPF-GCN with state-of-the-art methods for node classification in citation network.</figDesc><table><row><cell>Method</cell><cell>Cora</cell><cell>Citeseer</cell><cell>PubMed</cell></row><row><cell>GAT[37]</cell><cell>83.0 ± 0.7</cell><cell>72.5 ± 0.7</cell><cell>79.3 ± 0.3</cell></row><row><cell>StoGCN[38]</cell><cell>82.0 ± 0.8</cell><cell>70.9 ± 0.2</cell><cell>78.7 ± 0.3</cell></row><row><cell>DGI[39]</cell><cell>82.3 ± 0.6</cell><cell>71.8 ± 0.7</cell><cell>76.8 ± 0.6</cell></row><row><cell>LGCN[40]</cell><cell>83.3 ± 0.5</cell><cell>73.0 ± 0.6</cell><cell>79.5 ± 0.2</cell></row><row><cell>DGCN[30]</cell><cell>83.5</cell><cell>72.6</cell><cell>80.0</cell></row><row><cell cols="2">Multi-GCN[6] 82.5</cell><cell>71.3</cell><cell>NA</cell></row><row><cell>SF-GCN</cell><cell>83.3</cell><cell>73.4</cell><cell>79.3</cell></row><row><cell>SPF-GCN</cell><cell>83.5</cell><cell>73.5</cell><cell>80.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>state-of-the-art methods is respectively different. The similar performance of SPF-GCN is shown in the comparison with LGCN and DGCN in Cora, DGCN in PubMed. Except these situation, the better improvement of SPF-GCN can be demonstrated in other methods. The main reason is that LGCN can emphasis on neighboring nodes feature fusion for the stable node representation and DGCN can correlate the local and global consistency for complementing the different structures. The proposed SPF-GCN expects not only to capture the structure</figDesc><table /><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The authors would like to thank the anonymous reviewers for their insightful comments that help improve the quality of this paper. This work was supported by NSFC </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>References</head></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Efficient graph cut optimization for full crfs with quantized edges</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Veksler</surname></persName>
		</author>
		<idno type="DOI">10.1109/TPAMI.2019.2906204</idno>
		<idno>10.1109/ TPAMI.2019.2906204</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Geometric matrix completion with recurrent multi-graph neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Monti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bresson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3697" to="3707" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Graph convolutional neural networks for web-scale recommender systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Eksombatchai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="974" to="983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Defferrard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bresson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vandergheynst</surname></persName>
		</author>
		<title level="m">Convolutional neural networks on graphs with fast localized spectral filtering</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3844" to="3852" />
		</imprint>
	</monogr>
	<note>Advances in neural information processing systems</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Neural message passing for quantum chemistry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gilmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Schoenholz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">F</forename><surname>Riley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Dahl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="1263" to="1272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Multi-gcn: Graph convolutional networks for multi-view networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Blumenstock</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.11213</idno>
	</analytic>
	<monogr>
		<title level="m">with applications to global poverty</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Multi-feature structure fusion of contours for unsupervised shape classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1286" to="1290" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Feature structure fusion and its application</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Fusion</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="146" to="154" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Feature structure fusion modelling for classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Miu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IET Image Processing</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="883" to="888" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Heterogeneous structure fusion for target recognition in infrared imagery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops</title>
		<imprint>
			<publisher>CVPRW</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="118" to="125" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Heterogeneous feature structure fusion for classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Visual feature coding based on heterogeneous structure fusion for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Miu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Kang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Fusion</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="275" to="283" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Dynamic graph fusion label propagation for semi-supervised multi-modality classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="14" to="23" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.09513</idno>
		<title level="m">Structure propagation for zero-shot learning</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.08301</idno>
		<title level="m">Class label autoencoder for zero-shot learning</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Structure fusion and propagation for zero-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Chinese Conference on Pattern Recognition and Computer Vision (PRCV)</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="465" to="477" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.02204</idno>
		<title level="m">Transfer feature generating networks with semantic classes structure for zero-shot learning</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Affinity learning on a tensor product graph with applications to shape and image retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Latecki</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="2369" to="2376" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Affinity learning with diffusion on tensor product graph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Prasad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Latecki</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="28" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Automatic ensemble diffusion for 3d shape and image retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Latecki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="88" to="101" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.06105</idno>
		<title level="m">Semi-supervised learning on graph with an alternating diffusion process</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Regularized diffusion process for visual retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Latecki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence</title>
		<meeting>the Thirty-First AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3967" to="3973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Ensemble diffusion for retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">Jan</forename><surname>Latecki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="774" to="783" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6203</idno>
		<title level="m">Spectral networks and locally connected networks on graphs</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.02907</idno>
		<title level="m">Semi-supervised classification with graph convolutional networks</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xiao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.10247</idno>
		<title level="m">Fastgcn: fast learning with graph convolutional networks via importance sampling</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Inductive representation learning on large graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1024" to="1034" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Learning steady-states of iterative algorithms over graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Kozareva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1114" to="1122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.00910</idno>
		<title level="m">Geniepath: Graph neural networks with adaptive receptive paths</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Dual graph convolutional networks for graph-based semisupervised classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 World Wide Web Conference on World Wide Web, International World Wide Web Conferences Steering Committee</title>
		<meeting>the 2018 World Wide Web Conference on World Wide Web, International World Wide Web Conferences Steering Committee</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="499" to="508" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Van Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Navarin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sperduti</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.10435</idno>
		<title level="m">On filter size in graph convolutional networks</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Multiview spectral embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man, and Cybernetics</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1438" to="1446" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
	<note>Part B (Cybernetics)</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Multi-cluster feature selection based on grassmann manifold</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-F</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-X</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E.-H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Jisuanji Gongcheng/ Computer Engineering</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">16</biblScope>
			<biblScope unit="page" from="178" to="181" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Statistical computations on grassmann and stiefel manifolds for image and video-based recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Turaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Veeraraghavan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2273" to="2286" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Clustering on multi-layer graphs via subspace analysis on grassmann manifolds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Frossard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vandergheynst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Nefedov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on signal processing</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="905" to="918" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.00596</idno>
		<title level="m">A comprehensive survey on graph neural networks</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Velikovi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.10903</idno>
		<title level="m">Graph attention networks</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Song</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.10568</idno>
		<title level="m">Stochastic training of graph convolutional networks with variance reduction</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Velikovi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Fedus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Hjelm</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.10341</idno>
		<title level="m">Deep graph infomax</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ji</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.03965</idno>
		<title level="m">Large-Scale Learnable Graph Convolutional Networks</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
