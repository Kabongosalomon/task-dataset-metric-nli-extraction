<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Understanding and Utilizing Deep Neural Networks Trained with Noisy Labels</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengfei</forename><surname>Chen</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benben</forename><surname>Liao</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangyong</forename><surname>Chen</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengyu</forename><surname>Zhang</surname></persName>
						</author>
						<title level="a" type="main">Understanding and Utilizing Deep Neural Networks Trained with Noisy Labels</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T21:47+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Noisy labels are ubiquitous in real-world datasets, which poses a challenge for robustly training deep neural networks (DNNs) as DNNs usually have the high capacity to memorize the noisy labels. In this paper, we find that the test accuracy can be quantitatively characterized in terms of the noise ratio in datasets. In particular, the test accuracy is a quadratic function of the noise ratio in the case of symmetric noise, which explains the experimental findings previously published. Based on our analysis, we apply cross-validation to randomly split noisy datasets, which identifies most samples that have correct labels. Then we adopt the Co-teaching strategy which takes full advantage of the identified samples to train DNNs robustly against noisy labels. Compared with extensive state-of-the-art methods, our strategy consistently improves the generalization performance of DNNs under both synthetic and real-world training noise.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The remarkable success of DNNs on supervised learning tasks heavily relies on a large number of training samples with accurate labels. Correctly labeling extensive data is too costly while alternating methods such as crowdsourcing <ref type="bibr">(Yan et al., 2014;</ref><ref type="bibr" target="#b5">Chen et al., 2017)</ref> and online queries <ref type="bibr" target="#b24">(Schroff et al., 2011;</ref><ref type="bibr" target="#b7">Divvala et al., 2014)</ref> inexpensively obtain data, but unavoidably yield noisy labels. Training with too many noisy labels reduces generalization performance of DNNs since the networks can easily overfit on corrupted labels <ref type="bibr" target="#b5">(Zhang et al., 2017;</ref><ref type="bibr" target="#b1">Arpit et al., 2017)</ref>. To utilize extensive noisy data, understanding how noisy labels affect training and generalization of DNNs is the very first step, 1 Department of Computer Science and Engineering, The Chinese University of Hong Kong 2 Tencent Technology. Correspondence to: Guangyong Chen &lt;gycchen@tencent.com&gt;.</p><p>Our code is available at https://github.com/ chenpf1025/noisy_label_understanding_ utilizing.</p><p>based on which we can design specific methods to train DNNs robustly in practical applications.</p><p>Numerous methods have been proposed to deal with noisy labels. Several methods focus on estimating the noise transition matrix and correcting the objective function accordingly, e.g., forward or backward correction <ref type="bibr" target="#b19">(Patrini et al., 2017</ref>), S-model <ref type="bibr" target="#b8">(Goldberger &amp; Ben-Reuven, 2017)</ref>. However, it is a challenge to estimate the noise transition matrix accurately. An alternative approach is training on selected or weighted samples, e.g., Decoupling <ref type="bibr" target="#b17">(Malach &amp; Shalev-Shwartz, 2017)</ref>, MentorNet <ref type="bibr" target="#b12">(Jiang et al., 2018)</ref>, gradientbased reweighting <ref type="bibr" target="#b23">(Ren et al., 2018)</ref> and Co-teaching <ref type="bibr" target="#b9">(Han et al., 2018)</ref>. A remaining issue is to design a reliable and convincing criteria of selecting or weighting samples. Another approach proposes to correct labels using the predictions of DNNs, e.g., Bootstrap <ref type="bibr" target="#b22">(Reed et al., 2015)</ref>, Joint Optimization <ref type="bibr" target="#b26">(Tanaka et al., 2018)</ref> and D2L <ref type="bibr" target="#b16">(Ma et al., 2018)</ref>, all of which are vulnerable to overfitting. To improve the robustness, Joint Optimization introduces regularization terms requiring a prior knowledge of how actual classes distribute among all training samples. However, the prior knowledge is usually unavailable in practice.</p><p>How noisy labels affect training and generalization of DNNs is not well understood, which deserves more attention since it may promote fundamental approaches of robustly training DNNs against noise. Without label corruption, the generalization error can be bounded by complexity measures such as VC dimension <ref type="bibr" target="#b28">(Vapnik, 1998)</ref>, Rademacher complexity <ref type="bibr" target="#b2">(Bartlett &amp; Mendelson, 2002)</ref> and uniform stability <ref type="bibr" target="#b18">(Mukherjee et al., 2002;</ref><ref type="bibr" target="#b4">Bousquet &amp; Elisseeff, 2002;</ref><ref type="bibr" target="#b20">Poggio et al., 2004)</ref>. But the bounds become trivial in the presence of noisy labels. <ref type="bibr" target="#b5">Zhang et al. (2017)</ref> demonstrated that DNNs have the high capacity to fit even random labels, but obtain a large generalization error. <ref type="bibr" target="#b5">Zhang et al. (2017)</ref> also showed a positive correlation between generalization error and noise ratio, which implies DNNs do capture some useful information out of the noisy data. <ref type="bibr" target="#b1">Arpit et al. (2017)</ref> showed that during training, DNNs tend to learn simple patterns first, then gradually memorize all samples, which justifies the widely used small-loss criteria: treating samples with small training loss as clean ones <ref type="bibr" target="#b9">(Han et al., 2018;</ref><ref type="bibr" target="#b12">Jiang et al., 2018)</ref>. <ref type="bibr" target="#b16">Ma et al. (2018)</ref> qualitatively attributed the poor generalization performance of DNNs to the increased dimensionality of the latent feature subspace. Through extensive experiments, these works gained empirical insight into the interesting behavior of DNNs trained with noisy labels, while a theoretical and quantitative explanation is yet to emerge.</p><p>In this paper, we can quantitatively clarify the generalization performance of DNNs normally trained with noisy labels. To verify our theoretical analysis, we apply cross-validation to randomly split a set of collected samples, whose labels may be polluted by some noise. DNNs can be trained on a subset, then evaluated on the remaining dataset to compare the theoretically and empirical results on the generalization performance. We find that DNNs can fit noisy training sets exactly and generalize in distribution (see Claim 1 for more details). Hence, we can quantitatively characterize the test accuracy in terms of noise ratio in datasets. In particular, the test accuracy is a quadratic function of the noise ratio in the case of symmetric noise. In <ref type="bibr" target="#b5">Zhang et al. (2017)</ref>, it has been empirically found that the generalization performance of DNNs is highly dependent on the noise ratio. One of our contributions is to provide a thorough explanation for their empirical findings.</p><p>Based on our analysis, we further develop a specific method to train DNNs against noisy labels. Our method is developed on top of the Co-teaching strategy, which is first presented in <ref type="bibr" target="#b3">Blum &amp; Mitchell (1998)</ref> and then modified to deal with noisy labels with impressive performance in <ref type="bibr" target="#b9">(Han et al., 2018)</ref>. In the Co-teaching strategy, one trains two networks simultaneously: mini-batches are drawn from the whole noisy training set, then each network selects a certain number of small-loss samples and feeds them to its peer network. However, the performance of the Co-teaching decays seriously when the noise ratio of the training set increases. Moreover, the number of small-loss samples selected in each mini-batch is set according to the noise ratio of the training set, which is unavailable in practice. Fortunately, we can address these issues based on our theoretical analysis on the generalization performance of DNNs. Specially, we present the Iterative Noisy Cross-Validation (INCV) method to select a subset of samples, which has much smaller noise ratio than the original dataset, resulting in a more stable training process of DNNs. Moreover, we can automatically estimate the noise ratio of the selected set, which makes our method more practical for industrial applications. Briefly speaking, our main contributions are • theoretically relating the generalization performance of DNNs to the label noise,</p><p>• practical algorithms of selecting clean labels and training noise-robust DNNs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiments on both synthetic and real-world noisy labels</head><p>show that compared with state-of-the-art methods <ref type="bibr" target="#b19">(Patrini et al., 2017;</ref><ref type="bibr" target="#b17">Malach &amp; Shalev-Shwartz, 2017;</ref><ref type="bibr" target="#b9">Han et al., 2018;</ref><ref type="bibr" target="#b12">Jiang et al., 2018;</ref><ref type="bibr" target="#b16">Ma et al., 2018)</ref>, DNNs trained using our strategy achieve the best test accuracy on the clean test set. In particular, our method is verified on (i) the CIFAR-10 dataset <ref type="bibr" target="#b14">(Krizhevsky &amp; Hinton, 2009</ref>) with synthetic noisy labels generated by randomly flipping the original ones, and (ii) the WebVision dataset <ref type="bibr" target="#b15">(Li et al., 2017)</ref>, which is a large benchmark consisting of 2.4 million images crawled from websites, containing real-world noisy labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Preliminaries</head><p>For a c-class classification, we collect a dataset D = {x t , y t } n t=1 , where x t is the t-th sample with its observed label as y t ∈ [c] := {1, . . . , c}. As discussed previously, the observed label y may be corrupted since the example x are often labeled by online queries or in crowdsourcing system. Letŷ denote the true label, we can describe the corruption process of the set D by introducing a noise transition matrix T ∈ R c×c , where T ij = P (y = j|ŷ = i) denotes the probability of labeling an i-th class example as j. In the cross-validation, we randomly split the collected samples D into two halves D 1 and D 2 . In this way, D 2 shares the same noise transition matrix T with D 1 . Let f (x; ω) denote a neural network parameterized by ω, and y f ∈ [c] denote the predicted label of x given by the network f (x; ω).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Understanding DNNs trained with noisy labels</head><p>Extensive experiments in <ref type="bibr" target="#b5">(Zhang et al., 2017)</ref> have shown that DNNs can fit the noisy, even random, labels contained in the training set, but the generalization error is large even on a test set with the same noise. In this section, we use the previously introduced noise transition matrix T to theoretically quantify the generalization performance of DNNs normally trained with noisy labels, which perfectly explains the empirical findings reported in <ref type="bibr" target="#b5">(Zhang et al., 2017)</ref>.</p><p>In the classical Probably Approximately Correct framework <ref type="bibr" target="#b27">(Valiant, 1984)</ref>, good generalization performance means that prediction y f and observed test label y are approximately identical as random variables, namely they should be equal for each testing sample x. Without label corruption, the generalization error can be bounded by VC dimension <ref type="bibr" target="#b28">(Vapnik, 1998)</ref>, Rademacher complexity <ref type="bibr" target="#b2">(Bartlett &amp; Mendelson, 2002)</ref>, etc. However, in dealing with DNNs trained with noisy labels, y f = y possibly does not hold when evaluated at each testing example x, resulting in a large generalization error <ref type="bibr" target="#b5">(Zhang et al., 2017)</ref>. Fortunately, we find that the generalization still occurs in the sense of distribution, namely generalization in distribution, as shown in the following Claim 1. Recall that in cross-validation, we randomly di-vide a noisy dataset D into two halves D 1 and D 2 .</p><p>Claim 1. (Generalization in distribution). Let f (x; ω) be the network trained on D 1 and tested on D 2 . If we assume (i) the observed input examples x are i.i.d. in the set D, (ii) f has a sufficiently high capacity, then on D 2 , the probability of predicting an truly i-th class test sample as j is</p><formula xml:id="formula_0">P (y f = j|ŷ = i) = T ij ,<label>(1)</label></formula><p>where T ij := P (y = j|ŷ = i) denotes the noise transition matrix shared by D 1 and D 2 .</p><p>Claim 1 reveals the fact that the prediction y f and the test label y have the same distribution. Actually, if the model trained on D 1 is tested on another clean test set with true labels, Eq. (1) still holds, while in this case it implies that the probability of predicting an i-th class test sample as j equals to the T ij of the training set D 1 . We will justify the Claim 1 through experiments in Sec. 5.1.</p><p>The Test Accuracy is a widely used metric, which is defined as the proportion of testing examples for which the prediction y f equals to the observed label y. In the following Prop. 1, we formulate the test accuracy on the test set D 2 .</p><p>Proposition 1. Let D 1 and D 2 be two datasets with the same noise transition matrix T , f (x; ω) be a network trained on D 1 and tested on D 2 . Following the assumptions in Claim 1, the test accuracy for any class i ∈ [c] is</p><formula xml:id="formula_1">P (y f = y|ŷ = i) = c j=1 T 2 ij .<label>(2)</label></formula><p>Proof. Based on Claim 1, y f and y have the same distribution characterized by T . Assume the label corruption process is independent, then on the test set, we have</p><formula xml:id="formula_2">P (y f = j, y = k|ŷ = i) =P (y f = j|ŷ = i)P (y = k|ŷ = i) = T ij T ik .<label>(3)</label></formula><p>Hence, Eq.</p><p>(2) follows from P (y f = y|ŷ = i) = c j=1 P (y f = j, y = j|ŷ = i).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Symmetric and Asymmetric Noise</head><p>Following previous literatures <ref type="bibr" target="#b23">(Ren et al., 2018;</ref><ref type="bibr" target="#b9">Han et al., 2018;</ref><ref type="bibr" target="#b12">Jiang et al., 2018;</ref><ref type="bibr" target="#b16">Ma et al., 2018)</ref>, in this subsection we focus on investigating two representative types of noise, symmetric and asymmetric noise, which can be defined as follows (see <ref type="figure" target="#fig_1">Fig. 1</ref> for examples), Definition 1. In the case of symmetric noise of ratio ε, ∀i ∈ [c], we define T ii = 1−ε, and T ij = ε/(c−1), ∀j = i.</p><p>In the case of asymmetric noise of ratio ε, ∀i ∈ [c], we </p><formula xml:id="formula_3">= {(x, y) ∈ D 1 : y f = y} 8: S = S 1 ∪ S 2 OUTPUT: the selected set S define T ii = 1 − ε, T ij = ε for some j = i, and T ij = 0 otherwise.</formula><p>In the cases of symmetric and asymmetric noise, we can use the noise ratio ε to quantify the test accuracy of DNNs, which are trained and tested on previously mentioned noisy datasets D 1 and D 2 , respectively.</p><p>Corollary 1.1. For symmetric noise of ratio ε, the test accuracy is</p><formula xml:id="formula_4">P (y f = y) = (1 − ε) 2 + ε 2 c − 1 .<label>(4)</label></formula><p>For asymmetric noise of ratio ε, the test accuracy is</p><formula xml:id="formula_5">P (y f = y) = (1 − ε) 2 + ε 2 .<label>(5)</label></formula><p>Proof. Following Prop. 1, we have</p><formula xml:id="formula_6">P (y f = y) = c i=1 P (ŷ = i)P (y f = y|ŷ = i) = c i=1 P (ŷ = i) c j=1 T 2 ij .</formula><p>Note that for the symmetric and asymmetric noise, ∀i ∈ [c], c j=1 T 2 ij is a constant given by ε. Therefore, the desired result follows by inserting ε into the equation.</p><p>Interestingly, Eq. (4) perfectly fits the experimental results of generalization accuracy shown in <ref type="figure" target="#fig_1">Fig. 1</ref>(c) of <ref type="bibr" target="#b5">(Zhang et al., 2017)</ref>, and enables us to estimate the noise ratio of a dataset from the experimental test accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Training DNNs against noisy labels</head><p>In this section, we present a method on top of the Coteaching strategy to train DNNs robustly against noisy labels. As introduced previously, the performance of the Co-teaching decays seriously and becomes unstable when the noise ratio of the training set increases, which is further demonstrated in our experiments. To address this issue, we propose to first select a subset of samples, which has much smaller noise ratio than the original dataset.</p><p>A sample (x, y) is clean, if its observed label y equals to its latent true classŷ. However,ŷ is unavailable in practice. We propose to identify a sample (x, y) as clean if its observed label y equals to its predicted label y f given by the network f (x; ω). If we aim to identify whether a sample (x, y) is clean or not, we should keep this sample out of the training set. An intuitive method can be found in Alg. 1, namely the Noisy Cross-Validation (NCV) method, whose validity will be justified through the following theoretical analysis and extensive experiments in the next section.</p><p>Following the standard metrics <ref type="bibr" target="#b21">(Powers, 2011)</ref>, we measure the identification performance in terms of Label Precision (LP ) <ref type="bibr" target="#b9">(Han et al., 2018)</ref> and Label Recall (LR),</p><formula xml:id="formula_7">LP := |{(x, y) ∈ S : y =ŷ}| |S| , LR := |{(x, y) ∈ S : y =ŷ}| |{(x, y) ∈ D : y =ŷ}| ,<label>(6)</label></formula><p>where S ⊂ D is the selected subset as given in Alg 1, and |·| denotes the number of samples in a set. In this way, LP represents the fraction of clean samples in S, and LR represents the fraction of clean samples in S over all clean samples in D. Note that the noise ratio of the selected set S is ε S = 1 − LP according to the above definition. We also have LP and LR for any class i ∈ [c]:</p><formula xml:id="formula_8">LP i := |{(x, y) ∈ S : y =ŷ = i}| |{(x, y) ∈ S :ŷ = i}| , LR i := |{(x, y) ∈ S : y =ŷ = i}| |{(x, y) ∈ D : y =ŷ = i}| .<label>(7)</label></formula><p>Based on the analysis presented in Sec. 3, we quantify the performance of Alg. 1 in the following Prop. 2.</p><p>Proposition 2. Using Alg. 1 to select clean samples, we have, ∀i ∈ [c]</p><formula xml:id="formula_9">LP i = T 2 ii c j=1 T 2 ij , LR i = T ii .<label>(8)</label></formula><p>Proof. According to Alg. 1, we can reformulate Eq. <ref type="formula" target="#formula_8">(7)</ref> as Initialize a network f (x; ω) 4:</p><formula xml:id="formula_10">LP i = P (y f = i, y = i|ŷ = i) P (y f = y|ŷ = i) , LR i = P (y f = i, y = i|ŷ = i) P (y = i|ŷ = i) .</formula><p>Randomly divide C into two halves C 1 and C 2 5:</p><formula xml:id="formula_11">Train f (x; ω) on S ∪ C 1 for E epochs 6: Select samples, S 1 = {(x, y) ∈ C 2 : y f = y} 7:</formula><p>Identify n = r|S 1 | samples that will be removed:</p><formula xml:id="formula_12">R 1 = {#n arg max C2 L(y, f (x; ω))} 8:</formula><p>if i = 1, estimate the noise ratio ε using Eq. (4) 9:</p><p>Reinitialize the network f (x; ω)</p><p>10:</p><formula xml:id="formula_13">Train f (x; ω) on S ∪ C 2 for E epochs 11: Select samples, S 2 = {(x, y) ∈ C 1 : y f = y} 12:</formula><p>Identify n = r|S 2 | samples that will be removed:</p><formula xml:id="formula_14">R 2 = {#n arg max C1 L(y, f (x; ω))} 13: S = S ∪ S 1 ∪ S 2 , C = C − S 1 ∪ S 2 ∪ R 1 ∪ R 2 14:</formula><p>end for OUTPUT: the selected set S, remaining candidate set C and estimated noise ratio ε</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Symmetric and Asymmetric Noise</head><p>Since ∀i,</p><formula xml:id="formula_15">c j=1 T ij = 1, Eq. (8) in general implies: Corollary 2.1. T 2 ii T 2 ii + (1 − T ii ) 2 ≤ LP i ≤ T 2 ii T 2 ii + (1−Tii) 2 c−1 .<label>(9)</label></formula><p>Interestingly, we can see that the upper bound of Eq. (9) is attained for the symmetric noise, and the lower bound is attained for the asymmetric noise. In the cases of symmetric and asymmetric noise, we further have LP = LP 1 = · · · = LP c , LR = LR 1 = · · · = LR c , so that we can reformulate the LP and LR in the following Cor. 2.2. Corollary 2.2. For the symmetric noise of ratio ε, we have</p><formula xml:id="formula_16">LP = (1 − ε) 2 (1 − ε) 2 + ε 2 /(c − 1) , LR = 1 − ε. (10)</formula><p>For the asymmetric noise of ratio ε, we have</p><formula xml:id="formula_17">LP = (1 − ε) 2 (1 − ε) 2 + ε 2 , LR = 1 − ε.<label>(11)</label></formula><p>Given the noise ratio ε of the original set D estimated by Eq. (4) or <ref type="formula" target="#formula_5">(5)</ref> Initialize two networks f 1 (x; ω 1 ) and f 2 (x; ω 2 ) 2: for e = 1, · · · , E max do 3:</p><formula xml:id="formula_18">for batches (B S , B C ) in (S, C) do 4: if t &gt; E 0 then B = B S ∪ B C , else B = B S 5: B 1 = {#n(e) arg min B L(y, f 1 (x; ω 1 ))} 6: B 2 = {#n(e) arg min B L(y, f 2 (x; ω 2 ))} 7:</formula><p>Update f 1 using B 2 8:</p><p>Update f 2 using B 1 9: end for 10: end for OUTPUT:</p><formula xml:id="formula_19">f 1 (x; ω 1 ), f 2 (x; ω 2 )</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Improving the Co-teaching with the INCV method</head><p>Although the subset selected by Alg. 1 usually has much smaller noise ratio than the original set, the robust training of DNNs may require larger number of training samples. To address this issue, we present the Iterative Noisy Cross-Validation (INCV) method to increase the number of selected samples by applying Alg. 1 iteratively. More details of the INCV can be found in Alg. 2. Apart from selecting clean samples, the INCV removes samples that have large categorical cross entropy loss at each iteration. The remove ratio r determines how many samples will be removed.</p><p>After a detailed dissection of the noisy dataset D by Alg. 2, we can further improve the Co-teaching to take full advantage of the selected set S and the candidate set C. Specifically, we let the two networks focus on the selected set S at the first E 0 epochs, then incorporate the candidate set C. Hence, both training stability and test accuracy are improved. More details of our method can be found in Alg. 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head><p>This section consists of three parts. Firstly, we experimentally verify the theoretical results presented in Sec. 3 &amp; 4. Then we demonstrate that the INCV method shown in Alg. 2 can identify more samples that have correct labels. Finally, we show that our proposed method outlined in Alg. 3 can train DNNs robustly against noisy labels, and outperforms state-of-the-art methods <ref type="bibr" target="#b19">(Patrini et al., 2017;</ref><ref type="bibr" target="#b17">Malach &amp; Shalev-Shwartz, 2017;</ref><ref type="bibr" target="#b9">Han et al., 2018;</ref><ref type="bibr" target="#b12">Jiang et al., 2018;</ref><ref type="bibr" target="#b16">Ma et al., 2018)</ref>. Our code is available at https://github.com/chenpf1025/ noisy_label_understanding_utilizing.</p><p>Experimental setup. To verify our theory and test the algorithm, we first conduct experiments on synthetic noisy labels generated by randomly corrupting the original la- bels in CIFAR-10 <ref type="bibr" target="#b14">(Krizhevsky &amp; Hinton, 2009</ref>). We focus on two representative types of noise: symmetric noise and asymmetric noise, as defined in Def. 1 and illustrated in <ref type="figure" target="#fig_1">Fig 1.</ref> To verify our method on real-world noisy labels, we use the WebVision dataset <ref type="bibr" target="#b15">(Li et al., 2017)</ref> which contains 2.4 million images crawled from websites using the 1,000 concepts in ImageNet ILSVRC12 <ref type="bibr" target="#b6">(Deng et al., 2009)</ref>. The training set of WebVision contains many real-world noisy labels without human annotation. More implementation details are presented in Supp. A. In the following subsections, we focus on experimental results and discussions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Behavior of DNNs trained with noisy labels</head><p>For DNNs normally trained with noisy labels, we have theoretically characterized their behavior with the following metrics (i) test accuracy given in Eq. (4) &amp; (5), (ii) LP given in Eq. (10) &amp; (11); (iii) LR given in Eq. (10) &amp; (11). In this subsection, we evaluate these three metrics in extensive experiments, and show that experimental results confirm our theoretical analysis. Given a noisy dataset D, we implement cross-validation to randomly split it into two halves D 1 , D 2 , then train the ResNet-110 <ref type="bibr" target="#b11">(He et al., 2016b)</ref> on D 1 and test on D 2 .</p><p>Experimental results confirm the theoretical analysis.</p><p>As shown in <ref type="figure" target="#fig_2">Fig. 2</ref>, the experimental results are consistent with theoretical estimations. In particular, <ref type="figure" target="#fig_2">Fig. 2 (a)</ref> reproduces the observation shown in <ref type="bibr" target="#b5">(Zhang et al., 2017)</ref> that the test accuracy is highly dependent of the noise ratio.</p><p>(Zhang et al., 2017) did not present any theoretical explanations while we explicitly formulate in Eq. (4) that the test accuracy is a quadratic function of the noise ratio. <ref type="figure" target="#fig_2">In Fig 2  (b)</ref> and (e), the experimental LP is precisely given by our formulas. It is observed that for some data points, the experimental test accuracy and LR are slightly smaller than our theoretical values. This is reasonable since the distribution of D 2 is not exactly the same as D 1 , and the generalization error would not become 0 even without noise.</p><p>To further investigate the prediction behavior of DNNs trained with noisy labels, we define a confusion matrix M , whose ij-th entry represents the probability of predicting an  </p><p>0.3 0.08 0.08 0.08 0.08 0.08 0.08 0.08 0.08 0.08 0.08 0.3 0.08 0.08 0.08 0.08 0.08 0.08 0.08 0.08 0.08 0.08 0.3 0.08 0.08 0.08 0.08 0.08 0.08 0.08 0.08 0.08 0.08 0.3 0.08 0.08 0.08 0.08 0.08 0.08 0.08 0.08 0.08 0.08 0.3 0.08 0.08 0.08 0.08 0.08 0.08 0.08 0.08 0.08 0.08 0.3 0.08 0.08 0.08 0.08 0.08 0.08 0.08 0.08 0.08 0.08 0.3 0.08 0.08 0.08 0.08 0.08 0.08 0.08 0.08 0.08 0.08 0.3 0.08 0.08 0.08 0.08 0.08 0.08 0.08 0.08 0.08 0.08 0.3 0.08 0.08 0.08 0.08 0.08 0.08 0.08 0.08 0.08 0.08 0.3</p><p>Noise Transition Matrix (T) <ref type="figure" target="#fig_4">Figure 3</ref>. Confusion matrix of the RseNet-110 which is normally trained on manually corrupted CIFAR-10 with noise transition matrix T . M ≈ T satisfies the statement presented in Claim 1.</p><p>i-th class test sample as j, s.t., Training accuracy converging to an extremely low value does not contradict our findings. We find that under large symmetric noise, training accuracy of the model always converges to an extremely low value. In the experiments, when trained with symmetric noise of ratio 0.7, 0.8, 0.9 and 1.0, the training accuracies are only 0.58, 0.40, 0.24 and 0.36, respectively. However, we show in <ref type="figure" target="#fig_2">Fig. 2 &amp; 3</ref>   <ref type="bibr" target="#b10">(He et al., 2016a)</ref> is used in our implementation, which makes it difficult to achieve a high training accuracy, especially under large symmetric noise. Intuitively, due to the existence of noisy labels, nearby samples from the same class may have different labels, requiring many small regions to be classified differently. Augmentation easily generates random samples violating the classifier regions learned previously, hence increases the training error. Even in this case, our theoretical formulas presented previously still hold, as shown in <ref type="figure" target="#fig_2">Fig. 2 &amp; 3</ref>. Here we conclude that as long as a sufficiently rich deep neural network is trained for sufficiently many steps till convergence, the network can fit the training set and generalize in distribution, even if there are noisy labels and the training accuracy is low. We call for more theoretical explanations on this interesting phenomena in future. <ref type="figure" target="#fig_2">Fig. 2 (b)</ref> and (e) verifies that the subset selected by Alg. 1 usually has much smaller noise ratio than the original set. Sometimes, training DNNs requires larger number of training samples. Here we demonstrate that Alg. 2 (INCV) can identify more clean samples through iteration. For efficiency, we use the ResNet-32 and set N = 4, E = 50 without fine tuning. ε is estimated automatically using Eq. <ref type="formula" target="#formula_4">(4)</ref> in all experiments.</p><formula xml:id="formula_21">M ij := P (y f = j|ŷ = i).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Identifying more clean samples by the INCV</head><p>The INCV identifies most clean samples accurately. <ref type="figure" target="#fig_5">Fig.  4</ref> illustrates the average LP and LR values of the Alg. 2, computed by repeating all experiments 5 times. As show in the figure, the LP and LR are better than the theoretical lower bound even after a single iteration. Compared with ResNet-110 used in Sec. 5.1, in this subsection we train the ResNet-32 for only 50 epochs at each iteration. A much simpler model naturally releases the overfitting problem, yielding better LP and LR. Besides, <ref type="figure" target="#fig_5">Fig. 4</ref> also demonstrates that the LR increases much with iteration, while the LP slightly decreases. After four iterations, the INCV accurately identifies most clean samples. For example, under symmetric noise of ratio 0.5, it selects about 90% (= LR) of the clean samples, and the noise ratio of the selected set is reduced to around 10% (= 1 − LP ).</p><p>Noisy labels exist even in the original CIFAR-10. We also run the INCV on the original CIFAR-10 for just 1 iteration and examine samples that are identified as corrupted ones. Interestingly, there are several confusing samples, as shown in <ref type="figure" target="#fig_6">Fig. 5</ref>. This indicates that noisy labels exist even in the original CIFAR-10. Although corrupted samples contained in CIFAR-10 are so rare, which have negligible influence on training, being capable of identifying them implies that the INCV is a powerful algorithm for cleaning noisy labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Training DNNs robustly against noisy labels</head><p>As outlined in Alg. 3, we reformulate the Co-teaching to take full advantage of our INCV method. The followings clarify some questions that are useful for practical implementations of Alg. 3.</p><p>• Q: How to set the size of mini-batches B C and B S drawn from C and S? A: In general, it is reasonable to draw mini-batches such that |B C |/|B S | = |C|/|S|. However, when C is large, it results in drawing too many samples from C, which harms the training process since C usually contains many corrupted samples. Therefore, we adjust the strategy slightly by setting |B C |/|B S | = min(0.5, |C|/|S|). In the experiments, we set the batch size |B S | to 128, then compute |B C | accordingly.</p><p>• Q: How many samples should we keep in each minibatch?</p><p>A: In each mini-batch, we update the network using #n(e) samples that have small training loss, where e is the current epoch. Following Co-teaching <ref type="bibr" target="#b9">(Han et al., 2018)</ref>, we set n(e) = |B S |(1−ε S min(e/10, 1)), which means we decrease n(e) from |B S | to |B S |(1 − ε S ) linearly at the first 10 epochs and fix it after that. Recall that ε S = 1 − LP denotes the noise ratio of S.</p><p>Comparable methods. We compare Alg. 3 with the following baselines (1) F-correction <ref type="bibr" target="#b19">(Patrini et al., 2017)</ref>. It first trains a network to estimate T , then corrects the loss function accordingly.</p><p>(2) Decoupling <ref type="bibr" target="#b17">(Malach &amp; Shalev-Shwartz, 2017)</ref>. It trains two networks on samples for which the predictions from the two networks are different.</p><p>(3) Coteaching <ref type="bibr" target="#b9">(Han et al., 2018)</ref>. It maintains two networks. Each network selects samples of small training loss from the minibatches and feeds them to the other network. (4) MentorNet <ref type="bibr" target="#b12">(Jiang et al., 2018)</ref>. A teacher network is pre-trained, which provides a sample weighting scheme to train the student network. (5) D2L <ref type="bibr" target="#b16">(Ma et al., 2018)</ref>. For each sample, it linearly combines the original label and the prediction of network as the new label. The combining weight depends on the dimensionality of the latent feature subspace <ref type="bibr" target="#b0">(Amsaleg et al., 2017)</ref>.</p><p>Experiments on manually corrupted CIFAR-10. We first evaluate all methods on the CIFAR-10 by manually corrupting the labels with different types of noise. For symmetric noise, we test noise ratio 0.2, 0.5 and 0.8. For asymmetric noise, we choose a non-trivial and challenging noise ratio 0.4, since asymmetric noise larger than 0.5 is trivial. Still, we use the ResNet-32 and repeat all experiments five times. As shown in <ref type="table" target="#tab_3">Table 1</ref>, our method always achieves the best test accuracy (marked in boldface) under all cases. Even for symmetric noise of ratio 0.8 which is challenging for most methods, we achieve a good test accuracy. <ref type="figure">Fig. 6</ref> illustrates the test accuracy of all methods on the clean test set after every training epoch. It can be found that our method impressively achieves the best test accuracy in all settings, while some baseline methods suffer from overfitting at the later stage of training, such as F-correction, Decoupling and MentorNet shown in <ref type="figure">Fig 6 (b) &amp; (d)</ref>, and D2L shown in all four sub-figures. In particular, compared with the Co-teaching <ref type="bibr" target="#b9">(Han et al., 2018)</ref>, our method further enjoys a more stable training process and obtains better test accuracy by training on a clean subset firstly.</p><p>Experiments on real-world noisy labels. To verify the practical usage of our method on real-world noisy labels, we use the WebVision dataset 1.0 <ref type="bibr" target="#b15">(Li et al., 2017)</ref>, whose training set contains many real-world noisy labels. Since the dataset is quite large, for quick experiments, we compare all methods on the first 50 classes of the Google image subset using the inception-resnet v2 <ref type="bibr" target="#b25">(Szegedy et al., 2017)</ref>. We test the trained model on the human-annotated WebVision validation set and the ILSVRC12 validation set. As shown in </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In this work, we initiate a formal study of noisy labels. We first formulate several findings towards the generalization of DNNs trained with noisy labels. Theoretical analysis and extensive experiments are presented to justify our statements. Based on our findings, we then propose the INCV method, which randomly divides noisy datasets, then utilizes cross-validation to identify clean samples. We provide theoretical guarantees for the INCV, and then demonstrate through experiments that it is capable of identifying most clean samples accurately. Finally, we adopt the Co-teaching strategy which takes full advantage of the identified samples to train DNNs robustly against noisy labels. By comparing with extensive baselines, we show that our method achieves state-of-the-art test accuracy on the clean test set. In future, our formulations on the generalization performance of DNNs trained with noisy labels may promote more fundamental approaches of dealing with label corruption. In all experiments, we set the batch size to 128, and implement (i) l 2 weight decay of 10 −4 and (ii) data augmentation of horizontal random flipping and 32 × 32 random cropping after padding 4 pixels around images. In Sec. 5.1, we aim to verify our theory by demonstrating the worst case, so we use the ResNet-110 <ref type="bibr" target="#b11">(He et al., 2016b</ref>) to ensure the model has the sufficiently high capacity to memorize all corrupted samples. While in Sec. 5.2 &amp; 5.3, we use the ResNet-32 <ref type="bibr" target="#b10">(He et al., 2016a)</ref> for the consideration of training efficiency.</p><p>In Sec. 5.2, we apply the Iterative Noisy Cross-Validation (INCV, Alg. 2) to select clean samples. For efficiency, we set the number of iterations to 4, and train the ResNet32 for 50 epochs at each iteration. We use the Adam optimizer with an initial learning rate 10 −3 , which is divided by 2 after 20 and 30 epochs, and finally takes the value 10 −4 after 40 epochs. In all other experiments, we train the networks for 200 epochs till convergence, using the Adam optimizer <ref type="bibr" target="#b13">(Kinga &amp; Adam, 2015)</ref> with an initial learning rate 10 −3 , which is divided by 10 after 80, 120 and 160 epochs, and further divided by 2 after 180 epochs.</p><p>After selecting clean samples, we train DNNs robustly using Alg. 3. We set the warm-up epochs E 0 to 40 or 80 (i.e., 20% or 40% of the total number of training epochs) without fine tuning. If the size of the candidate set C is large, considering it has much more noisy labels than the selected relatively clean set S, we set E 0 = 80 so that the network will focus on S until 80 epochs. Otherwise, we take E 0 = 40. In the INCV, we denote the proportion between the number of removed samples and selected samples as remove ratio r, which determines how many samples will be removed. We found that our algorithm is robust to r, which means slightly changing it does not affect the performance much. If we do not want to remove any samples, we set r = 0, otherwise we set r = ε 1−ε without fine tuning, where ε is the estimated noise ratio of the original training set given by Alg. 2, hence ε 1−ε is the proportion between the number of corrupted samples and the number of clean samples in the original training set.</p><p>For those baseline methods, there are many specific hyperparameters, and we set the value according to their original papers. We train the same ResNet-32 for 200 epochs using the Adam optimizer with the same learning rate scheduler.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2. WebVision</head><p>To verify the practical usage of our method on real-world noisy labels, we use the WebVision dataset 1.0 <ref type="bibr" target="#b15">(Li et al., 2017)</ref> which contains 2.4 million images crawled from the websites using the 1,000 concepts in ImageNet ILSVRC12 <ref type="bibr" target="#b6">(Deng et al., 2009)</ref>. The training set of the WebVision contains many real-world noisy labels. Since the dataset is quite large, for quick experiments, we use the first 50 classes of the Google image subset. We test the trained DNNs on the human-annotated WebVision validation set and the ILSVRC12 validation set.</p><p>We use the inception-resnet v2 <ref type="bibr" target="#b25">(Szegedy et al., 2017)</ref>. Following the standard training pipeline <ref type="bibr" target="#b15">(Li et al., 2017)</ref>, we first resize each image to make shorter size as 256. Then we implement standard data augmentation: randomly crop a patch of size 227 × 227 form each image, and horizontal random flipping is applied before feeding the patch to the network for training. The batch size is set to 128 for all experiments. We train the networks for 120 epochs using the SGD optimizer with an initial learning rate 0.1, which is divided by 10 after 40, and 80 epochs.</p><p>In our method, we first run the INCV to select clean samples. In the INCV, we set the number of iterations to 2, and train the model for simply 50 epochs at each iteration. We use the SGD optimizer with an initial learning rate 0.1, which is divided by 2 after 20 and 30 epochs, and finally takes the value 0.01 after 40 epochs. We set the remove ratio r to 0.1. After selecting clean samples, we train a model robustly using Alg. 3, where we set the warm-up epoch as E 0 = 20.  0.11 0.11 0.11 0.11 0.11 0.11 0.11 0.11 0.11 0.11 0 0.11 0.11 0.11 0.11 0.11 0.11 0.11 0.11 0.11 0.11 0 0.11 0.11 0.11 0.11 0.11 0.11 0.11 0.11 0.11 0.11 0 0.11 0.11 0.11 0.11 0.11 0.11 0.11 0.11 0.11 0.11 0 0.11 0.11 0.11 0.11 0.11 0.11 0.11 0.11 0.11 0.11 0 0.11 0.11 0.11 0.11 0.11 0.11 0.11 0.11 0.11 0.11 0 0.11 0.11 0.11 0.11 0.11 0.11 0.11 0.11 0.11 0.11 0 0.11 0.11 0.11 0.11 0.11 0.11 0.11 0.11 0.11 0.11 0 0.11 0.11 0.11 0.11 0.11 0.11 0.11 0.11 0.11 0.11 0 <ref type="figure">Figure 7</ref>. Confusion matrix (the first row) of ResNet-110 normally trained on corrupted CIFAR-10 with noise transition matrix T (the second row). We specifically examine the noise settings with low training accuracy. M ≈ T satisfies the statement presented in Claim 1. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. More plots of the confusion matrix</head><p>We have shown in the main paper that when a network is trained with noisy labels, its confusion matrix M on the test set equals to the noise transition matrix T . This directly verifies our statement presented in Claim 1, which implies that the DNNs are able to fit the noisy training set exactly and generalize in distribution. Due to lack of space, in the main paper, we simply show results for symmetric noise of ratio 0.7. Here in <ref type="figure">Fig. 7</ref>, we show that M ≈ T holds for different noise types and noise ratios. We present the results for asymmetric noise of ratio 0.4, and then specifically investigate the noise settings which result in a low training accuracy, i.e., symmetric noise of ratio 0.8, 0.9 and 1.0 where the training accuracies are 0.40, 0.24 and 0.36. In this way, we also verify that the training accuracy converging to a extremely low value does not contradict our formulations on the generalization performance of DNNs trained with noisy labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. The INCV automatically identifies many noisy labels in the WebVision dataset</head><p>In Sec. 5.3, we have demonstrated that on the WebVision dataset, compared with state-of-the-art methods, our training strategy is capable of training a model that achieves the best generalization performance on the clean validation set. In the experiments, we firstly select most clean samples out of the original training set use the Iterative Noisy Cross-Validation (INCV, Alg. 2). The INCV also identifies samples that are very likely to have a wrong label. In this Section, we demonstrate that the INCV does identify many noisy labels in the WebVision, as shown in <ref type="figure" target="#fig_8">Fig. 8</ref>. Since the images have different size with shorter size as 256, we crop each image from the center to form a square image. We first convert the observed label of each example to the correspond concept in the synsets, then annotate the concept on top of each image. In the WebVision, the 6 images are labeled as (a) brambling, Fringilla montifringilla; (b) green lizard, Lacerta viridis; (c) house finch, linnet, Carpodacus mexicanus; (d) box turtle, box tortoise; (e) terrapin; (f) European fire salamander, Salamandra salamandra; which are obviously unreasonable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. More discussions on Corollary 2.2</head><p>Without loss of generality, we assume ∀i, T ii being the largest among T ij , j ∈ [c] := {1, · · · , c}. Based on Corollary 2.2 presented in the main paper, we can prove that under the cases of symmetric and asymmetric noise, Alg. 1 always selects a subset with smaller noise ratio than the original dataset, i.e., ε S &lt; ε, where ε is the noise ratio of the original dataset D, and ε S is the noise ratio of the selected set S. Recall that ε S = 1 − LP according to the definition of LP .</p><p>For the symmetric noise, we have the definition ∀i ∈ [c], T ii = 1 − ε, and T ij = ε/(c − 1), ∀j = i. In this case, T ii being the largest number among T ij implies ε/(c − 1) &lt; 1 − ε. Using Eq. (10) in Corollary 2.2, we have 1 − ε S = LP = (1 − ε) 2 (1 − ε) 2 + ε 2 /(c − 1)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&gt;</head><p>(1 − ε) 2 (1 − ε) 2 + ε(1 − ε) = 1 − ε.</p><p>For the asymmetric noise, we have the definition ∀i ∈ [c], T ii = 1 − ε, T ij = ε for some j = i, and T ij = 0 otherwise. In this case, T ii being the largest number among T ij implies ε &lt; 1 − ε. Using Eq. (11) in Corollary 2.2, we have</p><formula xml:id="formula_22">1 − ε S = LP = (1 − ε) 2 (1 − ε) 2 + ε 2 &gt; (1 − ε) 2 (1 − ε) 2 + ε(1 − ε) = 1 − ε.</formula><p>Thus, we can conclude that ε S &lt; ε.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>The desired result follows by inserting Eq. (2) &amp; (3) into the above equations.Algorithm 2 Iterative Noisy Cross-Validation (INCV): selecting clean samples out of the noisy ones INPUT: the noisy set D, number of iterations N , epoch E, remove ratio r 1: selected set S = ∅, candidate set C = D 2: for i = 1, · · · , N do 3:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 .</head><label>1</label><figDesc>Examples of noise transition matrix T (taking 5 classes and noise ratio 0.4 as an example).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 .</head><label>2</label><figDesc>Test accuracy, label precision (LP ) and label recall (LR) w.r.t noise ratio on manually corrupted CIFAR-10. The first row corresponds to symmetric noise and the second row asymmetric. Following cross-validation, we train the ResNet-110 on half of the noisy dataset and test on the rest half. The experimental results are consistent with the theoretical curves.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 3</head><label>3</label><figDesc>illustrates the confusion matrix of DNNs trained on manually corrupted CIFAR-10 with symmetric noise of ratio 0.7, and we can find that M ≈ T , which satisfies the statement presented in Claim 1. More results can be found in Supp. B, where we show M ≈ T still holds.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 .</head><label>4</label><figDesc>LP and LR of the INCV on the manually corrupted CIFAR-10. In each figure, the four curves correspond to symmetric noise of ratio 0.2, 0.5, 0.8 and asymmetric noise of ratio 0.4.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 .</head><label>5</label><figDesc>Noisy labels contained in the CIFAR-10 and identified by the INCV. Original Labels are annotated under images. (a) Human labeled as truck. (b) Labeled as truck, actually an automobile? (c) A bird on a toy car. (d) Labeled as airplane. (e) An automobile beside a truck. (f) Labeled as cat. (g) Labeled as dog, actually a horse? (h) Labeled as ship.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 8 .</head><label>8</label><figDesc>Examples of automatically identified noisy labels in the WebVision dataset using the INCV. We annotate the labeled concepts on top of each image. The labels are obviously unreasonable.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>, the above Cor. 2.2 further enables us to estimate the metrics LP and LR. Recall that the noise ratio of the selected subset S is ε Training DNNs robustly against noisy labels INPUT: the selected set S, candidate set C and estimated noise ratio ε from Alg. 2, warm-up epoch E 0 , total epoch E</figDesc><table /><note>S = 1 − LP according to the definition of LP . In practical situations (∀i, T ii being the largest among T ij , j ∈ [c]), Alg. 1 always produces a subset with smaller noise ratio ε S &lt; ε. See Supp. D for more details. Algorithm 3max 1:</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1 .</head><label>1</label><figDesc>Average test accuracy (%, 5 runs) with standard deviation under different noise types and noise ratios. We train the RseNet-32 on manually corrupted CIFAR-10 and test on the clean test set. The best result is marked in bold face.</figDesc><table><row><cell>Method</cell><cell>0.2</cell><cell>Sym. 0.5</cell><cell>0.8</cell><cell>Asym. 0.4</cell></row><row><cell>F-correction</cell><cell cols="2">85.08 ±0.43 ±0.19 76.02</cell><cell cols="2">34.76 ±4.53 ±2.15 83.55</cell></row><row><cell>Decoupling</cell><cell cols="2">86.72 ±0.32 ±0.62 79.31</cell><cell cols="2">36.90 ±4.61 ±0.83 75.27</cell></row><row><cell>Co-teaching</cell><cell cols="2">89.05 ±0.32 ±0.59 82.12</cell><cell cols="2">16.21 ±3.02 ±2.81 84.55</cell></row><row><cell>MentorNet</cell><cell cols="2">88.36 ±0.46 ±0.44 77.10</cell><cell cols="2">28.89 ±2.29 ±0.79 77.33</cell></row><row><cell>D2L</cell><cell cols="4">86.12 ±0.43 ±13.62 ±0.04 ±1.21 67.39 10.02 85.57</cell></row><row><cell>Ours</cell><cell cols="2">89.71 ±0.18 ±0.33 84.78</cell><cell cols="2">52.27 ±3.50 ±0.54 86.04</cell></row><row><cell cols="5">Table 2. Validation accuracy (%) on the WebVision validation set</cell></row><row><cell cols="5">and ImageNet ILSVRC12 validation set. The number outside</cell></row><row><cell cols="5">(inside) the parentheses denotes Top-1 (Top-5) classification</cell></row><row><cell cols="5">accuracy. We train the inception-resnet v2 on the first 50 classes</cell></row><row><cell cols="5">of the WebVision training set, which contains real-world noisy</cell></row><row><cell cols="4">labels. The best result is marked in bold face.</cell><cell></cell></row><row><cell>Method</cell><cell cols="4">WebVision Val. ILSVRC2012 Val.</cell></row><row><cell>F-correction</cell><cell cols="2">61.12 (82.68)</cell><cell cols="2">57.36 (82.36)</cell></row><row><cell>Decoupling</cell><cell cols="2">62.54 (84.74)</cell><cell cols="2">58.26 (82.26)</cell></row><row><cell>Co-teaching</cell><cell cols="2">63.58 (85.20)</cell><cell cols="2">61.48 (84.70)</cell></row><row><cell>MentorNet</cell><cell cols="2">63.00 (81.40)</cell><cell cols="2">57.80 (79.92)</cell></row><row><cell>D2L</cell><cell cols="2">62.68 (84.00)</cell><cell cols="2">57.80 (81.36)</cell></row><row><cell>Ours</cell><cell cols="2">65.24 (85.34)</cell><cell cols="2">61.60 (84.98)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>table 2</head><label>2</label><figDesc></figDesc><table><row><cell>, our method consistently outperforms other state-</cell></row><row><cell>of-the-art ones in terms of test accuracy. Moreover, Supp. C,</cell></row><row><cell>contains some noisy examples identified automatically from</cell></row><row><cell>the WebVision dataset by our INCV method (Alg. 2), which</cell></row><row><cell>implies the INCV is reliable on datasets containing real-</cell></row><row><cell>world noisy labels.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>Yan, Y., Rosales, R., Fung, G., Subramanian, R., and Dy, J.Learning from multiple annotators with varying expertise. Machine learning, 95(3):291-327, 2014. Zhang, C., Bengio, S., Hardt, M., Recht, B., and Vinyals, O. Understanding deep learning requires rethinking generalization. ICLR, 2017.</figDesc><table><row><cell>Supplementary Materials:</cell></row><row><cell>Understanding and Utilizing Deep Neural Networks</cell></row><row><cell>Trained with Noisy Labels</cell></row><row><cell>A. Further details on experiments</cell></row><row><cell>A.1. CIFAR-10</cell></row><row><cell>CIFAR-10 (Krizhevsky &amp; Hinton, 2009) contains human-</cell></row><row><cell>annotated labels which can be treated as true labels. To</cell></row><row><cell>conduct experiments on the synthetic noisy labels, we ran-</cell></row><row><cell>domly corrupt the labels according to a noise transition</cell></row><row><cell>matrix T .</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The vulnerability of learning to adversarial perturbation increases with intrinsic dimensionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Amsaleg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bailey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Barbe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Erfani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Houle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Radovanović</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">WIFS</title>
		<imprint>
			<biblScope unit="page" from="1" to="6" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">A closer look at memorization in deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Arpit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jastrzębski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ballas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Kanwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Maharaj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Risk bounds and structural results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">L</forename><surname>Bartlett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mendelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rademacher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="463" to="482" />
			<date type="published" when="2002-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Combining labeled and unlabeled data with co-training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Blum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the eleventh annual conference on Computational learning theory</title>
		<meeting>the eleventh annual conference on Computational learning theory</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1998" />
			<biblScope unit="page" from="92" to="100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Stability and generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Bousquet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Elisseeff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="499" to="526" />
			<date type="published" when="2002-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Learning to aggregate ordinal labels by maximizing separating width</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Heng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Learning everything about anything: Webly-supervised visual concept learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Divvala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Guestrin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Training deep neuralnetworks using a noise adaptation layer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Goldberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ben-Reuven</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Co-teaching: robust training deep neural networks with extremely noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Identity mappings in deep residual networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="630" to="645" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mentornet</surname></persName>
		</author>
		<title level="m">Learning data-driven curriculum for very deep neural networks on corrupted labels. ICML</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kinga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Adam</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>Citeseer</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Agustsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.02862</idno>
		<title level="m">Webvision database: Visual learning and understanding from web data</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Houle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Erfani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-T</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wijewickrema</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bailey</surname></persName>
		</author>
		<title level="m">Dimensionalitydriven learning with noisy labels. ICML</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">when to update&quot; from&quot; how to update</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Malach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shalev-Shwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Decoupling</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Statistical learning: Stability is sufficient for generalization and necessary and sufficient for consistency of empirical risk minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Niyogi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Poggio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rifkin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Making deep neural networks robust to label noise: A loss correction approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Patrini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rozza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Menon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Nock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Qu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">General conditions for predictivity in learning theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Poggio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rifkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Niyogi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">428</biblScope>
			<biblScope unit="issue">6981</biblScope>
			<biblScope unit="page">419</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Evaluation: from precision, recall and fmeasure to roc, informedness, markedness and correlation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Powers</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rabinovich</forename></persName>
		</author>
		<title level="m">A. Training deep neural networks on noisy labels with bootstrapping. ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Learning to reweight examples for robust deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">ICML</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Harvesting image databases from the web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Criminisi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">TPAMI</biblScope>
			<biblScope unit="page" from="754" to="766" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Inception-v4, inception-resnet and the impact of residual connections on learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alemi</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Joint optimization framework for learning with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tanaka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ikami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Yamasaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Aizawa</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A theory of the learnable</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">G</forename><surname>Valiant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1134" to="1142" />
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Adaptive and learning systems for signal processing communications, and control. Statistical learning theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">N</forename><surname>Vapnik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
