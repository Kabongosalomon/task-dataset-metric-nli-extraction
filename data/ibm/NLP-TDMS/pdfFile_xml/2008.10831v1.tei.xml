<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">CDeC-Net: Composite Deformable Cascade Network for Table Detection in Document Images</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Madhav</forename><surname>Agarwal</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">CVIT</orgName>
								<orgName type="institution" key="instit2">IIIT</orgName>
								<address>
									<region>Hyderabad</region>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ajoy</forename><surname>Mondal</surname></persName>
							<email>ajoy.mondal@iiit.ac.in</email>
							<affiliation key="aff1">
								<orgName type="department">CVIT, IIIT</orgName>
								<address>
									<region>Hyderabad</region>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">V</forename><surname>Jawahar</surname></persName>
							<email>jawahar@iiit.ac.in</email>
							<affiliation key="aff2">
								<orgName type="department">CVIT, IIIT</orgName>
								<address>
									<region>Hyderabad</region>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">CDeC-Net: Composite Deformable Cascade Network for Table Detection in Document Images</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T19:36+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Page object</term>
					<term>table detection</term>
					<term>Cascade Mask R-CNN</term>
					<term>deformable convolution</term>
					<term>single model</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Localizing page elements/objects such as tables, figures, equations, etc. is the primary step in extracting information from document images. We propose a novel endto-end trainable deep network, (CDeC-Net) for detecting tables present in the documents. The proposed network consists of a multistage extension of Mask R-CNN with a dual backbone having deformable convolution for detecting tables varying in scale with high detection accuracy at higher IoU threshold. We empirically evaluate CDeC-Net on all the publicly available benchmark datasets -ICDAR-2013, ICDAR-2017, ICDAR-2019, UNLV, Marmot, PubLayNet, and TableBank -with extensive experiments.</p><p>Our solution has three important properties: (i) a single trained model CDeC-Net ‡ performs well across all the popular benchmark datasets; (ii) we report excellent performances across multiple, including higher, thresholds of IoU; (iii) by following the same protocol of the recent papers for each of the benchmarks, we consistently demonstrate the superior quantitative performance. Our code and models will be publicly released for enabling the reproducibility of the results.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Rapid growth in information technology has led to an exponential increase in the production and storage of digital documents over the last few decades. Extracting information from such a large corpus is impractical for human. Hence, useful information could be lost or not utilized over time. Digital documents have many other page objects (such as tables and figures) beyond text. These page objects also show wide variations in their appearance. Therefore any attempt to detect page objects such as tables need to be generic and applicable across wide variety of documents and use cases. In this paper, we are interested in detection of tables. It is well known <ref type="bibr" target="#b4">[1]</ref>- <ref type="bibr" target="#b14">[11]</ref> that the localisation of tables and other page element is challenging due to the high degree of intra-class variability (due to different layouts of the table, inconsistent use of ruling lines). The presence of interclass similarity (graphs, flowcharts, figures having a large number of horizontal and vertical lines which resembles to table) adds further challenges.</p><p>Table detection is still a challenging problem in the research community. This is an active area of research <ref type="bibr" target="#b6">[3]</ref>- <ref type="bibr" target="#b14">[11]</ref>. However, we observe that most of these attempts develop different table detection solutions for different datasets. We argue that this may be the time to consider the possibility of a single solution (say a trained model) that works across wide variety of documents. We provide a single model CDeC-Net ‡ trained with IIIT-AR-13K dataset <ref type="bibr" target="#b15">[12]</ref> and evaluate on popular benchmark datasets. <ref type="table">Table I</ref> shows the comparison with the state-of-the-art techniques for respective datasets. We observe from the table that our single model CDeC-Net ‡ performs better than stateof-the-art techniques for ICDAR-2019 (cTDaR) <ref type="bibr" target="#b16">[13]</ref>, <ref type="bibr">UNLV</ref>  <ref type="bibr" target="#b17">[14]</ref>, and PubLayNet <ref type="bibr" target="#b12">[9]</ref> dataset. In case of <ref type="bibr">ICDAR-2013</ref>  <ref type="bibr" target="#b18">[15]</ref>, ICDAR-POD-2017 <ref type="bibr" target="#b19">[16]</ref>, <ref type="bibr">Marmot</ref>  <ref type="bibr" target="#b20">[17]</ref>, and TableBank <ref type="bibr" target="#b10">[7]</ref>, single model CDeC-Net ‡ obtains comparable results to the state-of-the-art techniques. By following the same protocol of the state of the art papers, we also report superior performance consistently across all the datasets, as presented in <ref type="table">Table III</ref> and discussed later in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset</head><p>Method Score R↑ P↑ F1↑ mAP↑ ICDAR-2013 DeCNT <ref type="bibr" target="#b6">[3]</ref> 0.996 * 0.996 * 0.996 * -CDeC-Net ‡ (our) 0.942 0.993 0.968 0.942 ICADR-2017 YOLOv3 <ref type="bibr" target="#b21">[18]</ref> 0.968 0.975 0.971 -CDeC-Net ‡ (our) 0.899 0.969 0.934 0.880 ICADR-2019 TableRadar <ref type="bibr" target="#b16">[13]</ref> 0  Early attempts in localizing tables are based on meta-data extraction and exploitation of the semantic information present in the tables <ref type="bibr" target="#b22">[19]</ref>- <ref type="bibr" target="#b24">[21]</ref>. However, the absence of meta-data in the case of scanned documents makes these methods futile. In recent years, researchers employ deep neural networks [1]- <ref type="bibr" target="#b14">[11]</ref> in an attempt to provide a generic solution for localizing page objects, specifically tables from document images. Siddiqui et al. <ref type="bibr" target="#b6">[3]</ref> provide state-ofthe-art performance on many benchmark datasets by incorporating deformable convolutions <ref type="bibr" target="#b25">[22]</ref> in their network. However, even their work fails to provide a single model that achieves state-of-the-art performance on all the existing benchmark datasets. In general, the existing deep learning models are trained on a single IoU threshold, commonly 0.5, following the practice followed in computer vision literature. This leads to a noisy table detection at higher threshold value during evaluation. This is a drawback of the existing table detection techniques. Liu et al. discuss in <ref type="bibr" target="#b26">[23]</ref> that generally, a CNN based object detector uses a backbone network to extract features for detecting objects. These backbones are usually designed for the image classification task and are pre-trained on either ImageNet <ref type="bibr" target="#b27">[24]</ref> or MS-COCO <ref type="bibr" target="#b28">[25]</ref> datasets. Hence, directly employing them to extract features for table detection <ref type="bibr" target="#b4">[1]</ref>- <ref type="bibr" target="#b14">[11]</ref> may result in sub-optimal performance. Training a more powerful backbone is also expensive. This is a major bottleneck of these existing table detection techniques.</p><p>To address the issues mentioned above, we propose a composite deformable cascade network, called as CDeC-Net, to detect tables more accurately present in document images. The proposed CDeC-Net consists of a multi-stage object detection architecture, cascade Mask R-CNN <ref type="bibr" target="#b29">[26]</ref>. The cascade Mask R-CNN network is composed of a sequence of detectors trained with increasing IoU thresholds to address the problem of noisy detection at higher threshold. Inspired by <ref type="bibr" target="#b26">[23]</ref> we use composite backbone, which consists of multiple identical backbones having composite connections between neighbor backbones, in CDeC-Net to improve detection accuracy. We also incorporate deformable convolution <ref type="bibr" target="#b25">[22]</ref> in the backbones to model geometric transformations. We extensively evaluate CDeC-Net on publicly available benchmark datasets -ICDAR-2013, ICDAR-POD-2017, UNLV, Marmot, ICDAR-2019 (cTDaR), TableBank, and PubLayNet under various existing experimental environments. The extensive experiments show that CDeC-Net achieves state-of-the-art performance on all existing benchmark datasets except <ref type="bibr">ICDAR-2017.</ref> We also achieve high accuracy and more tight bounding box detection at higher IoU threshold than the previous benchmark results.</p><p>We summarise our main contributions as follows:</p><p>• We presents an end-to-end trainable deep architecture, CDeC-Net which consists of Cascade Mask R-CNN containing composite backbones with deformable convolution to detect tables more accurately in document images. <ref type="bibr">•</ref> We provide a single model trained on IIIT-AR-13K and achieve very close competitive results to the state-of-the-art techniques on all existing benchmark datasets (Refer <ref type="table">Table I</ref>). • We achieve state-of-the-art results on publicly available benchmark datasets except ICDAR-2017 (Refer <ref type="table">Table III</ref>). <ref type="table">Table detection</ref> is an essential step towards document analysis. Over the times, many researchers have contributed to the detection of tables in documents of varying layouts. Initially, the researchers have proposed several approaches based on heuristics or meta-data information to solve this particular problem <ref type="bibr" target="#b22">[19]</ref>, <ref type="bibr" target="#b24">[21]</ref>, <ref type="bibr" target="#b30">[27]</ref>- <ref type="bibr" target="#b35">[32]</ref>. Later, the researchers explore machine learning, more specifically deep learning, to make the solution generic [1]- <ref type="bibr" target="#b14">[11]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Rule Based Approaches</head><p>The research on table detection in document images was started in 1993. In the beginning, Itonori <ref type="bibr" target="#b22">[19]</ref> proposed a rule-based approach that led to the text-block arrangement and ruled line position to localize the table in the documents. At the same time, Chandran and Kasturi <ref type="bibr" target="#b30">[27]</ref> developed a table detection approach based on vertical and horizontal lines. Following these, several research works <ref type="bibr" target="#b24">[21]</ref>, <ref type="bibr" target="#b31">[28]</ref>- <ref type="bibr" target="#b35">[32]</ref> have been done for table detection using improved heuristic rules. Though these methods perform well on the documents having limited variation in layouts, they need more manual efforts to find a better heuristic rule. Moreover, rule-based approaches fail to obtain generic solutions. Therefore, it is necessary to employ machine learning approaches to solve the table detection problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Learning Based Approaches</head><p>Statistical learning approaches have been proposed to alleviate the problems mentioned earlier in table detection. Kieninger and Dengel <ref type="bibr" target="#b36">[33]</ref> applied an unsupervised learning approach for the table detection task. This method significantly differs from the previous rule-based approaches <ref type="bibr" target="#b24">[21]</ref>, <ref type="bibr" target="#b31">[28]</ref>- <ref type="bibr" target="#b35">[32]</ref> as it uses a clustering of given word segments. Cesarini et al. <ref type="bibr" target="#b37">[34]</ref> used a supervised learning approach using a hierarchical representation based on the MXY tree. This particular method detects the table with different features by maximizing the performance on a particular training set. Later, the solution of the table detection problem is formulated using various machine learning problems such as (i) sequence labeling <ref type="bibr" target="#b38">[35]</ref>, (ii) SVM with various hand-crafted features <ref type="bibr" target="#b39">[36]</ref>, and (iii) ensemble of various models <ref type="bibr" target="#b40">[37]</ref>. Learning methods improve The success of deep convolutional neural network (CNN) in the field of computer vision, motivates researchers to explore CNN for localizing tables in the documents. It is a data-driven method and has advantages -(i) it is robust to document types and layouts, and (ii) it reduces the efforts of hand-crafted feature engineering in CNN. Initially, Hao et al. <ref type="bibr" target="#b41">[38]</ref> used CNN to classify tables like structure regions extracted from PDFs using heuristic rule into two categories -table and non-table. The major drawbacks of this method are (i) use of the heuristic rule to extract table like region, and (ii) work on only non-raster PDF documents. The researchers explore various natural scene object detectors -Fast R-CNN <ref type="bibr" target="#b42">[39]</ref> in <ref type="bibr" target="#b8">[5]</ref>, Faster R-CNN <ref type="bibr" target="#b43">[40]</ref> in <ref type="bibr" target="#b4">[1]</ref>- <ref type="bibr" target="#b12">[9]</ref>, Mask R-CNN <ref type="bibr" target="#b44">[41]</ref> in <ref type="bibr" target="#b11">[8]</ref>- <ref type="bibr" target="#b14">[11]</ref>, <ref type="bibr">YOLO</ref>  <ref type="bibr" target="#b45">[42]</ref> in <ref type="bibr" target="#b14">[11]</ref> to localize page objects more specifically tables in the document images. All these methods are data-driven and do not require any heuristics or meta-data to extract table like region similar to <ref type="bibr" target="#b41">[38]</ref>.</p><p>Gilani et al. <ref type="bibr" target="#b4">[1]</ref> used Faster R-CNN to detect tables in the document images. Instead of the original document image, distance transformed image is taken as input to easily fine-tune the pretrained model to work on various types of document images. In the same direction, the transformed document image is taken as input to Faster R-CNN model for detecting tables <ref type="bibr" target="#b9">[6]</ref>; and figures and mathematical equations <ref type="bibr" target="#b11">[8]</ref> present in document images. Saha et al. <ref type="bibr" target="#b13">[10]</ref> experimentally established that Mask R-CNN performs better than Faster R-CNN for detecting graphical objects in the document images. Zhong et al. <ref type="bibr" target="#b12">[9]</ref> also experimentally established that Mask R-CNN performs better than Faster R-CNN for extracting semantic regions from the documents. The performance of Faster R-CNN is reduced when documents contain large scale variate tables. Siddiqui et al. <ref type="bibr" target="#b6">[3]</ref> incorporated deformable CNN in Faster R-CNN to adapt the different scales and transformations which allows the model to detect scale variate tables accurately. Sun et al. <ref type="bibr" target="#b7">[4]</ref> combined the corner information with the detected table region by Faster R-CNN to refine the boundaries of the detected tables to reduce false positives. It is observed that every detection method is sensitive to a certain type of object. Vo et al. <ref type="bibr" target="#b8">[5]</ref> combine outputs of two object detectors -Fast R-CNN and Faster R-CNN in order to exploit the advantages of the two models for page object detection. Due to the limited number of images in the existing training set, it is challenging to train such a detection model for table detection. Fine-tune is one solution to such a problem. In <ref type="bibr" target="#b14">[11]</ref>, the authors discuss the benefit of fine-tuning from a close domain on four different object detection models -Mask R-CNN <ref type="bibr" target="#b44">[41]</ref>, RetinaNet <ref type="bibr" target="#b46">[43]</ref>, SSD <ref type="bibr" target="#b47">[44]</ref> and YOLO <ref type="bibr" target="#b45">[42]</ref>. The experiments highlight that the close domain fine-tuning approach avoids over- fitting, solves the problem of having a small training set, and improves detection accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Related Datasets</head><p>Various benchmark datasets -ICDAR-2013 <ref type="bibr" target="#b18">[15]</ref>, ICDAR-POD-2017 <ref type="bibr" target="#b19">[16]</ref>, UNLV <ref type="bibr" target="#b17">[14]</ref>, Marmot <ref type="bibr" target="#b20">[17]</ref>, ICDAR-2019 (cTDaR) <ref type="bibr" target="#b16">[13]</ref>, TableBank <ref type="bibr" target="#b10">[7]</ref>, PubLayNet <ref type="bibr" target="#b12">[9]</ref>, and IIIT-AR-13K <ref type="bibr" target="#b15">[12]</ref> are publicly available for table detection tasks. <ref type="table">Table II</ref> shows the statistics of these datasets. Among them, ICDAR-2013, UNLV, Marmot, ICDAR-2019, TableBank are popularly used for table detection while ICDAR-POD-2017, PubLayNet, and IIIT-AR-13K datasets for various page object (including table) detection task. We use all datasets for our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. CDEC-NET: COMPOSITE DEFORMABLE CASCADE NETWORK</head><p>The success of deep convolution neural networks (CNN)s for solving various computer vision problems inspire researchers to explore and design models for detecting tables in document images [1]- <ref type="bibr" target="#b14">[11]</ref>. All these deep models provide high table detection accuracy. However, all these table detection models suffer from the following shortcomings -(i) all existing table detection networks use a backbone to extract features for detecting tables, which is usually designed for image classification tasks and pre-trained on ImageNet dataset. Since almost all of the existing backbone networks are originally designed for the image classification task, directly applying them to extract features for table detection may result in suboptimal performance. A more powerful backbone is needed to extract more representational features and improve the detection accuracy. However it is very expensive to train a deeper and powerful backbone on ImageNet and get better performance. (ii) CNNs have limitations to model large transformation due to the fixed geometric structures of CNN modules -a convolution filter samples the input feature map correspond to a fixed location, a pooling layer reduces the spatial resolution at a fixed ration and a RoI into a fixed spatial bin, etc. This leads to the lack of handling the geometric transformations. (iii) All these table detectors use the intersection over union (IoU) threshold to define positives, negatives, and finally, detection quality. They commonly use a threshold of 0.5, which leads to noisy (lowquality) detection and frequently degrades the performance for higher thresholds. The major hindrance in training a network at higher IoU threshold is the reduction of positive training samples with increasing IoU threshold. All these issues are also a bottleneck of CNNs based object detection techniques <ref type="bibr" target="#b42">[39]</ref>- <ref type="bibr" target="#b44">[41]</ref> in natural scene images.</p><p>Over the time, various solutions <ref type="bibr" target="#b25">[22]</ref>, <ref type="bibr" target="#b26">[23]</ref>, <ref type="bibr" target="#b29">[26]</ref> are proposed to handle the above stated problems for object detection in natural images. Lie et al. <ref type="bibr" target="#b26">[23]</ref> proposed CBNet which comprises of stacking multiple identical backbones by creating composite connections between them. It helps in creating a more powerful backbone for feature extraction without much additional computational cost. Dai et al. <ref type="bibr" target="#b25">[22]</ref> introduced deformable convolution in the object detection network to make it more scale-invariant. It captures the features using a variable receptive field and makes detection independent of the fixed geometric transforms. Cai and Vasconcelos <ref type="bibr" target="#b29">[26]</ref> proposed a multistage object detection architecture in which subsequent detectors are trained with increasing IoU thresholds to solve the last problem. The output of one detector is feed as an input to the subsequent detector, maintaining the number of positive samples at higher thresholds.</p><p>Inspired by the solutions provided by <ref type="bibr" target="#b25">[22]</ref>, <ref type="bibr" target="#b26">[23]</ref>, <ref type="bibr" target="#b29">[26]</ref> for issues discussed earlier in natural scene images, we propose a novel architecture CDeC-Net for detecting tables accurately in the document images. It is composed of Cascade Mask R-CNN with a composite backbone having deformable convolution filters instead of conventional convolution filters. <ref type="figure" target="#fig_1">Figure 1</ref> displays an overview of our proposed architecture for table localization in document images. We discuss each component of CDeC-Net in detail:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Cascade Mask R-CNN</head><p>Cai and Vasconcelos <ref type="bibr" target="#b29">[26]</ref> proposed Cascade R-CNN which is a multi-stage extension of Faster R-CNN <ref type="bibr" target="#b43">[40]</ref>. Cascade Mask R-CNN has a similar architecture as Cascade R-CNN, but along with an additional segmentation branch, denoted by 'S', for creating masks of the detected objects. CDeC-Net comprises of a sequence of three detectors trained with increasing IoU thresholds of 0.5, 0.6, and 0.7, respectively. The proposals generated by RPN network are passed through ROI pooling layer. The network head takes ROI features as input and makes two predictions -classification score (C) and bounding box regression (B). The output of one detector is used as a training set for the next detector. The deeper detector stages are more selective against close false positives. Each regressor is optimized for the bounding box distribution generated by the previous regressor, rather than the initial distribution. The bounding box regressor trained for a certain IoU threshold, tends to produce bounding boxes of higher IoU threshold. It helps in re-sampling an example distribution of higher IoU threshold and uses it to train the next stage. Hence, it results in a uniform distribution of training samples for each stage of detectors and enabling the network to train on higher IoU threshold values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Composite Backbone</head><p>We use a dual backbone based architecture <ref type="bibr" target="#b26">[23]</ref> which creates a composite connection between the parallel stages of two adjacent ResNeXt-101 backbones (one is called assistant backbone and other is called lead backbone). The assistant backbone's high-level output features are fed as an input to the corresponding lead backbone's stage. In a conventional network, the output (denoted by x l ) of previous l-1 stages is feed as input to the l-th stage, given by:</p><formula xml:id="formula_0">x l = F l (x l − 1), l ≥ 2.<label>(1)</label></formula><p>where F l (.) is a non-linear transformation operation of l-th stage. However, our network takes input from previous stages as well as parallel stage of assistant backbone. For a given stage l of lead backbone(bl), input is a combination of the output of previous l-1 stages of lead backbone and parallel l-th stage of assistant backbone(ba), given by:</p><formula xml:id="formula_1">x l bl = F l bl (x l−1 k + g(x l ba )), l ≥ 2,<label>(2)</label></formula><p>where g(.) represents composite connection. It helps the lead backbone to take advantage of the features learned by the assistant backbone. Finally, the output of the lead backbone is used for further processing in the subsequent network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Deformable Convolution</head><p>The commonly used backbone, ResNeXt architectures, have conventional convolution operation, in which the effective receptive field of all the neurons in a given layer is same. The grid points are generally confined to a fix 3×3 or 5×5 square receptive field. It performs well for layers at the lower hierarchy, but when the objects appear at the arbitrary scales and transformations, generally at the higher-level, the convolution operation does not perform well in capturing the features. We replace the fixed receptive field CNN with deformable CNN <ref type="bibr" target="#b25">[22]</ref> in each of our dual backbone architectures. The gird is deformable as each grid point can be moved by a learnable offset. In a conventional convolution, we sample over the input feature map x using a regular grid R, given by</p><formula xml:id="formula_2">y(p0) = pn∈R w(pn).x(p0 + pn).<label>(3)</label></formula><p>Whereas in a deformable convolution, for each location po on the output feature map y, we augment the regular grid using the offset ∆pn such that {∆pn|n = 1, ..., N }, where N = |R|, given by y(p0) = pn∈R w(pn).x(p0 + pn + ∆p).</p><p>Deformable convolution is operated on R but with each points augmented by a learnable offset ∆p. The offset value, ∆p is itself a trainable parameter. This helps in enabling each neuron to alter its receptive field based on the preceding feature map by creating an explicit offset. It makes the convolution operation agnostic for varying scales and transformations. The deformable convolution is shown in <ref type="figure" target="#fig_2">Figure 2</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Implementation Details</head><p>We implement CDeC-Net 2 in Pytorch using MMdetection toolbox <ref type="bibr" target="#b48">[45]</ref>. We use NVIDIA GeForce RTX 2080 Ti GPU with 12 GB memory for our experiments. We use pre-trained ResNeXt-101 (with blocks 3, 4, 23 and 3) on MS-COCO <ref type="bibr" target="#b28">[25]</ref> with FPN as the network head. We train CDeC-Net with document images scaled to 1200 × 800, while maintaining the original aspect ratio, as the input. We use 0.00125 as an initial learning rate with a learning rate decay at 25 epoch and 40 epoch. We use 0.0033 as warmup schedule for first 500 iterations. CDeC-Net is trained for 50 epochs. However, for the larger datasets such as PubLayNet and TableBank, the model is trained for 8 epochs in total with learning rate decay at 4 epoch and 6 epoch. In case of fine-tuning, we use 12 epochs in total. We use three IoU threshold values -0.5, 0.6, and 0.7 in our model. We use 0.5, 1.0 and 2.0 as anchor ratio with a single anchor scale of 8. The batch size of 1 is used for training our models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTS A. Evaluation Measures</head><p>Similar to the existing table localization tasks [1]- <ref type="bibr" target="#b14">[11]</ref> in document images, we also use recall, precision, F1, and mean average precision (mAP) to evaluate the performance of CDeC-Net. For fair comparison, we evaluate the proposed CDeC-Net on same IoU threshold values as mentioned in the respective existing papers. We perform multi-scale testing at 7 different scales (with 3 smaller scales, original scale, and 3 larger scales). We select detection output as final result if it presents in at least 4 test cases out of 7 scales. It helps in eliminating the false positives and provide consistent results. Comparison with current state-of-the-art techniques on various benchmark datasets is shown in <ref type="table">Table III</ref>. We observe from the table that CDeC-Net outperforms state-of-the-art techniques on ICADR-2013, UNLV, Marmot, TableBank, and PubLayNet datasets. For ICDAR-2019, CDeC-Net obtains very close performance to the stateof-the-art techniques. In case of ICDAR-2017 dataset, the performance of CDeC-Net is 2.4% lower than the state-of-the-art method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Comparison with State-of-the-Arts on Benchmark Datasets</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Thorough Comparison with State-of-the-Art Techniques</head><p>Tables IV-VII presents the comparative results between the proposed CDeC-Net and the existing techniques on various benchmark datasets under the existing experimental environments. In most of the cases, CDeC-Net performs better than the existing techniques. The    cascade Mask R-CNN in CDeC-Net leads to significant reduction in number of false positives, which is evident from the high precision values. <ref type="table">Table IV</ref> presents the obtained results under various experimental settings for <ref type="bibr">ICDAR-2013.</ref> We observe that for all experimental settings, CDeC-Net obtains the best results. In case of ICDAR-2019, CDeC-Net performs only 0.1% F1 score lower than state-of-the-art technique -TableRadar <ref type="bibr" target="#b16">[13]</ref> at IoU threshold 0.8. At higher threshold value 0.9, CDeC-Net performs significantly (1.8% greater F1 score) better than the state-of-the-art technique -TableRadar <ref type="bibr" target="#b16">[13]</ref>. For all other experimental settings, CDeC-Net also obtain the best results. For UNLV dataset, CDeC-Net performs (2.7% F1 score) better than the state-of-the-art method -DeCNT <ref type="bibr" target="#b6">[3]</ref>. For TableBank dataset, CDeC-Net performs significantly better that state-of-the-art technique -Li et al. <ref type="bibr" target="#b10">[7]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Effect of IoU Threshold on Table Detection</head><p>We evaluate the trained CDeC-Net on the existing benchmark datasets under varying IoU thresholds to test robustness of the proposed network. Our experiments on various benchmark datasets shows that CDeC-Net gives consistent results over varying IoU thresholds. <ref type="table">Table VIII</ref> highlights that in case of ICDAR-2019 datasets, the CDeC-Net consistently obtains high detection accuracy under varying thresholds (in range 0.5-0.9). Our model also obtains consistent results (in range of 0.5-0.8) on ICDAR-2013 and UNLV datasets. Only at threshold 0.9, there is a performance drop on ICDAR-2013 and UNLV datasets. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Qualitative Results</head><p>A visualization of detection results on ICDAR-2013, ICDAR-POD-2017, UNLV (first row, left to right), ICDAR-2019 (cTDaR), PubLayNet and TableBank (second row, left to right) obtained by CDeC-Net is shown in <ref type="figure">Figure 3</ref>. The figure highlights that the CDeC-Net properly detects complex table with high confidence score.</p><p>Third row of <ref type="figure">Figure 3</ref> shows some examples where CDeC-Net model fails to properly detect the tables. In the first image, it detects two false positives that are visually similar to tables. The second, and third images contain multiple closely spaced tables where CDeC-Net detects them as single table.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Results of Single Model</head><p>Tables IV-VII presents the comparative results between the proposed <ref type="bibr">CDeC</ref> to our best performing model CDeC-Net. <ref type="figure">Figure 4</ref> presents the visual results obtained using our single model CDeC-Net ‡ and our best model CDeC-Net. We select the best model under various existing experimental environments. First row of <ref type="figure">Figure 4</ref> shows examples where single model CDeC-Net ‡ performs better than the best model <ref type="bibr">CDeC-Net.</ref> In those examples, our best model CDeC-Net predicts single bounding box for multiple tables. While single model CDeC-Net ‡ accurately predicts bounding box corresponding to each table present in the document. The second row of <ref type="figure">Figure 4</ref> presents examples where our best model CDeC-Net accurately detects all tables present in the documents. While our single model CDeC-Net ‡ fails to predict bounding boxes corresponding to tables present in the documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G. Ablation Study</head><p>We perform a series of experiments to check the effectiveness of the proposed method. We train three models on Marmot dataset and evaluate on ICDAR-2013. Our baseline model -cascade Mask R-CNN achieves F1 score of 0.981 at IoU threshold 0.5. We incorporate the dual backbone in the baseline model and obtain F1 score of 0.984. Again we incorporate deformable convolution instead of convolution in the dual backbone and call it as CDeC-Net, which attains the best F1 score of 1.000. This particular experiment highlights the utility of incorporating the key components -dual backbone and deformable convolution into the baseline model Cascade Mask R-CNN. We finally select CDeC-Net as our final model for table detection task.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSION</head><p>We introduce a CDeC-Net, which consists of a cascade Mask R-CNN with a dual backbone having deformable convolution to detect tables present in documents with high accuracy at higher IoU threshold. The proposed CDeC-Net achieves state-of-the-art performance for most of the benchmark datasets under various existing experimental environments and significantly reduces the false positive detection even at the higher IoU threshold. We also provide a single model CDeC-Net ‡ for all benchmark datasets, which obtains very close performance to the state-of-the-art techniques. We expect that our single model sets a standard benchmark and improves the accuracy of table detection and other page objects-figures, logos, mathematical expressions, etc. For future work, the current framework can be extended to a more challenging table structure recognition task.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>AND STATE-OF-THE-ART TECHNIQUES ON EXISTING BENCHMARK DATASETS. WE CREATE THE SINGLE MODEL CDEC-NET ‡ BY TRAINING CDEC-NET WITH IIIT-AR-13K AND FINE-TUNING WITH TRAINING SET OF RESPECTIVE DATASETS. *: INDICATES THE AUTHORS REPORTED 0.996 IN TABLE HOWEVER IN DISCUSSION THEY MENTIONED 0.994.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Illustration of the proposed CDeC-Net which is compose of cascade Mask R-CNN with composite backbone having deformable convolution instead of conventional convolution.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Illustration of the deformable convolution.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>THE PROPOSED CDEC-NET AND STATE-OF-THE-ART TECHNIQUES ON ICDAR-2019 DATASET. CDEC-NET ‡ : INDICATES A SINGLE MODEL WHICH IS TRAINED WITH IIIT-AR-13K DATASET.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>CDeC-Net ‡ (our) IIIT-AR-13K 9K TableBank-LaTeX 1K 0.6 0.779 0.961 0.870 0.759 CDeC-Net ‡ (our) IIIT-AR-13K 9K TableBank-LaTeX 199K TableBank-LaTeX 1K 0.6 0.970 0.990 0.980 0.965 TABLE VII ILLUSTRATES COMPARISON BETWEEN THE PROPOSED CDEC-NET (OUR) AND STATE-OF-THE-ART TECHNIQUES ON TABLEBANK DATASET. CDEC-NET ‡ : INDICATES A SINGLE MODEL WHICH IS TRAINED WITH IIIT-AR-13K DATASET.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>X ILLUSTRATES COMPARISON BETWEEN THE PROPOSED CDEC-NET AND STATE-OF-THE-ART TECHNIQUES ON ICDAR-POD-2017. D2: INDICATES ICDAR-2013+ICDAR-POD-2017+UNLV+MARMOT. †: INDICATES MODEL TRAINED WITH MULTIPLE CATEGORIES. CDEC-NET ‡ : INDICATES A SINGLE MODEL WHICH IS TRAINED WITH IIIT-AR-13K DATASET. THE PROPOSED CDEC-NET AND STATE-OF-THE-ART TECHNIQUES ON PUBLAYNET DATASET. †: INDICATES MODEL TRAINED WITH MULTIPLE CATEGORIES. CDEC-NET ‡ : INDICATES A SINGLE MODEL WHICH IS TRAINED WITH IIIT-AR-13K DATASET.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>ILLUSTRATES COMPARISON BETWEEN OUR SINGLE MODEL CDEC-NET ‡</figDesc><table><row><cell></cell><cell></cell><cell>.940</cell><cell>0.950</cell><cell>0.945</cell><cell>-</cell></row><row><cell></cell><cell cols="2">CDeC-Net  ‡ (our) 0.930</cell><cell>0.971</cell><cell cols="2">0.950 0.913</cell></row><row><cell>UNLV</cell><cell>GOD [10]</cell><cell>0.910</cell><cell>0.946</cell><cell>0.928</cell><cell>-</cell></row><row><cell></cell><cell cols="2">CDeC-Net  ‡ (our) 0.915</cell><cell>0.970</cell><cell cols="2">0.943 0.912</cell></row><row><cell>Marmot</cell><cell>DeCNT [3]</cell><cell>0.946</cell><cell>0.849</cell><cell>0.895</cell><cell>-</cell></row><row><cell></cell><cell cols="2">CDeC-Net  ‡ (our) 0.779</cell><cell>0.943</cell><cell cols="2">0.861 0.756</cell></row><row><cell>TableBank</cell><cell>Li et al. [7]</cell><cell>0.975</cell><cell>0.987</cell><cell>0.981</cell><cell>-</cell></row><row><cell></cell><cell cols="2">CDeC-Net  ‡ (our) 0.970</cell><cell>0.990</cell><cell cols="2">0.980 0.965</cell></row><row><cell>PubLayNet</cell><cell>M-RCNN [9]</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>0.960</cell></row><row><cell></cell><cell cols="2">CDeC-Net  ‡ (our) 0.975</cell><cell>0.993</cell><cell cols="2">0.984 0.978</cell></row><row><cell></cell><cell></cell><cell>TABLE I</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>table detection accuracy significantly. INDICATES TABLE. F: INDICATES FIGURE. E: INDICATES EQUATION. NI: INDICATES NATURAL IMAGE. L: INDICATES LOGO. S: INDICATES SIGNATURE. TL: INDICATES TITLE. TT: INDICATES TEXT. LT: INDICATES LIST.</figDesc><table><row><cell>Dataset</cell><cell>Category Label</cell><cell cols="2">Training Validation Test</cell></row><row><cell></cell><cell></cell><cell>Set</cell><cell>Set Set</cell></row><row><cell>ICDAR-2013</cell><cell>1: T</cell><cell>170</cell><cell>238</cell></row><row><cell>ICDAR-POD-2017</cell><cell>3: T, F, and E</cell><cell>1600</cell><cell>817</cell></row><row><cell>UNLV</cell><cell>1: T</cell><cell></cell><cell>424</cell></row><row><cell>Marmot</cell><cell>1: T</cell><cell>2K</cell><cell></cell></row><row><cell cols="2">ICDAR-2019 (cTDaR) 1: T</cell><cell>1200</cell><cell>439</cell></row><row><cell>TableBank-word 1</cell><cell>1: T</cell><cell>163K</cell><cell>1K 1k</cell></row><row><cell>TableBank-LaTeX 1</cell><cell>1: T</cell><cell>253K</cell><cell>1K 1k</cell></row><row><cell>TableBank-both 1</cell><cell>1: T</cell><cell>417K</cell><cell>2K 2k</cell></row><row><cell>PubLayNet 1</cell><cell>5: T, F, TL, TT, and LT</cell><cell>340K</cell><cell>11K 11K</cell></row><row><cell>IIIT-AR-13K</cell><cell>5: T, F, NI, L, and S</cell><cell>9K</cell><cell>2K 2k</cell></row><row><cell></cell><cell>TABLE II</cell><cell></cell><cell></cell></row><row><cell cols="2">STATISTICS OF DATASETS. T:</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>BETWEEN THE PROPOSED CDEC-NET AND STATE-OF-THE-ART TECHNIQUES ON ICDAR-2013 DATASET. A: INDICATES ANCHOR OPTIMIZATION, PG: INDICATES POST-PROCESSING TECHNIQUE, SF: INDICATES SEMANTIC FEATURES, D1: INDICATES MARMOT+UNLV+ICDAR-2017, *: INDICATES THE AUTHORS REPORTED 0.996 IN TABLE HOWEVER IN DISCUSSION THEY MENTIONED 0.994.</figDesc><table><row><cell>Method</cell><cell></cell><cell>Training</cell><cell cols="2">Fine-tuning</cell><cell>Test</cell><cell>IoU</cell><cell></cell><cell cols="2">Score</cell></row><row><cell></cell><cell cols="2">Dataset</cell><cell>#Image Dataset</cell><cell>#Image Dataset</cell><cell></cell><cell>#Image</cell><cell>R↑</cell><cell>P↑</cell><cell>F1↑</cell><cell>mAP↑</cell></row><row><cell>DeCNT [3]</cell><cell>D1</cell><cell></cell><cell>4808 -</cell><cell cols="2">-ICDAR-2013</cell><cell cols="4">238 0.5 0.996  *  0.996  *  0.996  *</cell><cell>-</cell></row><row><cell>CDeC-Net (our)</cell><cell>D1</cell><cell></cell><cell>4808 -</cell><cell cols="2">-ICDAR-2013</cell><cell>238 0.5</cell><cell>1.000</cell><cell>1.000</cell><cell>1.000</cell><cell>1.000</cell></row><row><cell>GOD [10]</cell><cell cols="2">Marmot</cell><cell>2K -</cell><cell cols="2">-ICDAR-2013</cell><cell>238 0.5</cell><cell>1.000</cell><cell>0.982</cell><cell>0.991</cell><cell>-</cell></row><row><cell>CDeC-Net (our)</cell><cell cols="2">Marmot</cell><cell>2K -</cell><cell cols="2">-ICDAR-2013</cell><cell>238 0.5</cell><cell>1.000</cell><cell>0.981</cell><cell>0.991</cell><cell>0.995</cell></row><row><cell>F-RCNN [9]</cell><cell cols="2">PubLayNet</cell><cell>340K ICADR-2013</cell><cell cols="2">170 ICADR-2013</cell><cell>238 0.5</cell><cell>0.964</cell><cell>0.972</cell><cell>0.968</cell></row><row><cell>M-RCNN [9]</cell><cell cols="2">PubLayNet</cell><cell>340K ICADR-2013</cell><cell cols="2">170 ICADR-2013</cell><cell>238 0.5</cell><cell>0.955</cell><cell>0.940</cell><cell>0.947</cell><cell>-</cell></row><row><cell>CDeC-Net (our)</cell><cell cols="2">PubLayNet</cell><cell>340K ICADR-2013</cell><cell cols="2">170 ICADR-2013</cell><cell>238 0.5</cell><cell>0.968</cell><cell>0.987</cell><cell>0.977</cell><cell>0.959</cell></row><row><cell cols="3">YOLOv3+A+PG [18] ICDAR-2017</cell><cell>1.6K -</cell><cell cols="2">-ICADR-2013</cell><cell>238 0.5</cell><cell>0.949</cell><cell>1.000</cell><cell>0.973</cell><cell>-</cell></row><row><cell>CDeC-Net (our)</cell><cell cols="2">ICDAR-2017</cell><cell>1.6K -</cell><cell cols="2">-ICADR-2013</cell><cell>238 0.5</cell><cell>1.000</cell><cell>1.000</cell><cell>1.000</cell><cell>1.000</cell></row><row><cell>Khan et al. [46]</cell><cell cols="2">Marmot</cell><cell>2K ICDAR-2013</cell><cell cols="2">204 ICDAR-2013</cell><cell>34 0.5</cell><cell>0.901</cell><cell>0.969</cell><cell>0.934</cell><cell>-</cell></row><row><cell>TableNet+SF [47]</cell><cell cols="2">Marmot</cell><cell>2K ICDAR-2013</cell><cell cols="2">204 ICDAR-2013</cell><cell>34 0.5</cell><cell>0.963</cell><cell>0.970</cell><cell>0.966</cell><cell>-</cell></row><row><cell>DeepDeSRT [2]</cell><cell cols="2">Marmot</cell><cell>2K ICDAR-2013</cell><cell cols="2">204 ICDAR-2013</cell><cell>34 0.5</cell><cell>0.962</cell><cell>0.974</cell><cell>0.968</cell><cell>-</cell></row><row><cell>CDeC-Net (our)</cell><cell cols="2">Marmot</cell><cell>2K ICDAR-2013</cell><cell cols="2">204 ICDAR-2013</cell><cell>34 0.5</cell><cell>1.000</cell><cell>1.000</cell><cell>1.000</cell><cell>1.000</cell></row><row><cell>M-RCNN [11]</cell><cell cols="2">Pascel VOC</cell><cell>16K ICDAR-2013</cell><cell cols="2">178 ICDAR-2013</cell><cell>60 0.6</cell><cell>0.770</cell><cell>0.140</cell><cell>0.230</cell><cell>-</cell></row><row><cell>RetinaNet [11]</cell><cell cols="2">Pascel VOC</cell><cell>16K ICDAR-2013</cell><cell cols="2">178 ICDAR-2013</cell><cell>60 0.6</cell><cell>0.580</cell><cell>0.560</cell><cell>0.570</cell><cell>-</cell></row><row><cell>SSD [11]</cell><cell cols="2">Pascel VOC</cell><cell>16K ICDAR-2013</cell><cell cols="2">178 ICDAR-2013</cell><cell>60 0.6</cell><cell>0.680</cell><cell>0.540</cell><cell>0.600</cell><cell>-</cell></row><row><cell>YOLO [11]</cell><cell cols="2">Pascel VOC</cell><cell>16K ICDAR-2013</cell><cell cols="2">178 ICDAR-2013</cell><cell>60 0.6</cell><cell>0.580</cell><cell>0.920</cell><cell>0.750</cell><cell>-</cell></row><row><cell>CDeC-Net (our)</cell><cell cols="2">Pascel VOC</cell><cell>16K ICDAR-2013</cell><cell cols="2">178 ICDAR-2013</cell><cell>60 0.6</cell><cell>0.844</cell><cell>1.000</cell><cell>0.922</cell><cell>0.844</cell></row><row><cell>M-RCNN [11]</cell><cell cols="2">TableBank-LaTeX</cell><cell>199K ICDAR-2013</cell><cell cols="2">178 ICDAR-2013</cell><cell>60 0.6</cell><cell>0.970</cell><cell>0.700</cell><cell>0.810</cell><cell>-</cell></row><row><cell>RetinaNet [11]</cell><cell cols="2">TableBank-LaTeX</cell><cell>199K ICDAR-2013</cell><cell cols="2">178 ICDAR-2013</cell><cell>60 0.6</cell><cell>0.770</cell><cell>0.830</cell><cell>0.800</cell><cell>-</cell></row><row><cell>SSD [11]</cell><cell cols="2">TableBank-LaTeX</cell><cell>199K ICDAR-2013</cell><cell cols="2">178 ICDAR-2013</cell><cell>60 0.6</cell><cell>0.680</cell><cell>0.620</cell><cell>0.650</cell><cell>-</cell></row><row><cell>YOLO [11]</cell><cell cols="2">TableBank-LaTeX</cell><cell>199K ICDAR-2013</cell><cell cols="2">178 ICDAR-2013</cell><cell>60 0.6</cell><cell>0.650</cell><cell>1.000</cell><cell>0.780</cell><cell>-</cell></row><row><cell>CDeC-Net (our)</cell><cell cols="2">TableBank-LaTeX</cell><cell>199K ICDAR-2013</cell><cell cols="2">178 ICDAR-2013</cell><cell>60 0.6</cell><cell>0.933</cell><cell>1.000</cell><cell>0.967</cell><cell>0.933</cell></row><row><cell cols="3">Kavasidis et al. [48] Custom dataset</cell><cell>45K -</cell><cell cols="2">-ICDAR-2013</cell><cell>238 0.5</cell><cell>0.981</cell><cell>0.975</cell><cell>0.978</cell><cell>-</cell></row><row><cell>PFTD [49]</cell><cell>-</cell><cell></cell><cell>--</cell><cell cols="2">-ICADR-2013</cell><cell>238 0.5</cell><cell>0.915</cell><cell>0.939</cell><cell>0.926</cell><cell>-</cell></row><row><cell>Tran et al. [50]</cell><cell>-</cell><cell></cell><cell>--</cell><cell cols="2">-ICDAR-2013</cell><cell>238 0.5</cell><cell>0.964</cell><cell>0.952</cell><cell>0.958</cell><cell>-</cell></row><row><cell>CDeC-Net  ‡ (our)</cell><cell cols="2">IIIT-AR-13K</cell><cell>9K -</cell><cell cols="2">-ICDAR-2013</cell><cell>238 0.5</cell><cell>0.942</cell><cell>0.993</cell><cell>0.968</cell><cell>0.942</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>TABLE IV</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">ILLUSTRATES COMPARISON Method</cell><cell>Training</cell><cell cols="2">Fine-tuning</cell><cell></cell><cell>Test</cell><cell>IoU</cell><cell></cell><cell>Score</cell></row><row><cell></cell><cell>Dataset</cell><cell cols="2">#Image Dataset</cell><cell cols="2">#Image Dataset</cell><cell>#Image</cell><cell></cell><cell>R↑</cell><cell>P↑</cell><cell>F1↑ mAP↑</cell></row><row><cell>TableRadar [13]</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>CDEC-NET ‡ : INDICATES A SINGLE MODEL WHICH IS TRAINED WITH IIIT-AR-13K DATASET.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>NET AND STATE-OF-THE-ART TECHNIQUES ON UNLV DATASET. D4: INDICATES ICDAR-2013+ICDAR-2017+MARMOT. CDEC-NET ‡ : INDICATES A SINGLE MODEL WHICH IS TRAINED WITH IIIT-AR-13K DATASET.</figDesc><table><row><cell>Method</cell><cell></cell><cell cols="2">Training</cell><cell></cell><cell cols="2">Fine-tuning</cell><cell cols="2">Test</cell><cell>IoU</cell><cell></cell><cell></cell><cell>Score</cell></row><row><cell></cell><cell></cell><cell>Dataset</cell><cell></cell><cell>#Image</cell><cell>Dataset</cell><cell>#Image</cell><cell>Dataset</cell><cell>#Image</cell><cell></cell><cell>R↑</cell><cell>P↑</cell><cell>F1↑</cell><cell>mAP↑</cell></row><row><cell>GOD [10]</cell><cell></cell><cell>Marmot</cell><cell></cell><cell>2K</cell><cell>UNLV</cell><cell>340</cell><cell>UNLV</cell><cell>84</cell><cell>0.5</cell><cell cols="3">0.910 0.946 0.928</cell><cell>-</cell></row><row><cell>CDeC-Net (our)</cell><cell></cell><cell>Marmot</cell><cell></cell><cell>2K</cell><cell>UNLV</cell><cell>340</cell><cell>UNLV</cell><cell>84</cell><cell>0.5</cell><cell cols="3">0.925 0.952 0.938</cell><cell>0.912</cell></row><row><cell>Gilani et al. [1]</cell><cell></cell><cell>UNLV</cell><cell></cell><cell>340</cell><cell>-</cell><cell>-</cell><cell>UNLV</cell><cell>84</cell><cell>0.5</cell><cell>0.907</cell><cell cols="2">0.823 0.863</cell><cell>-</cell></row><row><cell>CDeC-Net (our)</cell><cell></cell><cell>UNLV</cell><cell></cell><cell>340</cell><cell>-</cell><cell>-</cell><cell>UNLV</cell><cell>84</cell><cell>0.5</cell><cell>0.906</cell><cell cols="2">0.914 0.910</cell><cell>0.861</cell></row><row><cell cols="2">Arif and Shafait [6]</cell><cell>private</cell><cell></cell><cell>1019</cell><cell>-</cell><cell>-</cell><cell>UNLV</cell><cell>427</cell><cell>0.5</cell><cell>0.932</cell><cell cols="2">0.863</cell><cell>0.896</cell><cell>-</cell></row><row><cell>CDeC-Net (our)</cell><cell></cell><cell>private</cell><cell></cell><cell>1019</cell><cell>-</cell><cell>-</cell><cell>UNLV</cell><cell>427</cell><cell>0.5</cell><cell>0.745</cell><cell cols="2">0.912</cell><cell>0.829</cell><cell>0.711</cell></row><row><cell>DeCNT [3]</cell><cell></cell><cell>D4</cell><cell></cell><cell>4622</cell><cell>-</cell><cell>-</cell><cell>UNLV</cell><cell>424</cell><cell>0.5</cell><cell>0.749</cell><cell cols="2">0.786 0.767</cell><cell>-</cell></row><row><cell>CDeC-Net (our)</cell><cell></cell><cell>D4</cell><cell></cell><cell>4622</cell><cell>-</cell><cell>-</cell><cell>UNLV</cell><cell>424</cell><cell>0.5</cell><cell>0.736</cell><cell cols="2">0.852 0.794</cell><cell>0.657</cell></row><row><cell>M-RCNN [11]</cell><cell></cell><cell>Pascel VOC</cell><cell></cell><cell>16K</cell><cell>UNLV</cell><cell>302</cell><cell>UNLV</cell><cell>101</cell><cell>0.6</cell><cell cols="3">0.580 0.290 0.390</cell><cell>-</cell></row><row><cell>RetinaNet [11]</cell><cell></cell><cell>Pascel VOC</cell><cell></cell><cell>16K</cell><cell>UNLV</cell><cell>302</cell><cell>UNLV</cell><cell>101</cell><cell>0.6</cell><cell cols="3">0.830 0.810 0.820</cell><cell>-</cell></row><row><cell>SSD [11]</cell><cell></cell><cell>Pascel VOC</cell><cell></cell><cell>16K</cell><cell>UNLV</cell><cell>302</cell><cell>UNLV</cell><cell>101</cell><cell>0.6</cell><cell cols="3">0.640 0.660 0.650</cell><cell>-</cell></row><row><cell>YOLO [11]</cell><cell></cell><cell>Pascel VOC</cell><cell></cell><cell>16K</cell><cell>UNLV</cell><cell>302</cell><cell>UNLV</cell><cell>101</cell><cell>0.6</cell><cell>0.950</cell><cell cols="2">0.910</cell><cell>0.930</cell><cell>-</cell></row><row><cell>CDeC-Net (our)</cell><cell></cell><cell>Pascel VOC</cell><cell></cell><cell>16K</cell><cell>UNLV</cell><cell>302</cell><cell>UNLV</cell><cell>101</cell><cell>0.6</cell><cell>0.805</cell><cell cols="2">0.961</cell><cell>0.883</cell><cell>0.788</cell></row><row><cell>M-RCNN [11]</cell><cell></cell><cell cols="2">TableBank-LaTeX</cell><cell>199K</cell><cell>UNLV</cell><cell>302</cell><cell>UNLV</cell><cell>101</cell><cell>0.6</cell><cell cols="3">0.830 0.660 0.740</cell><cell>-</cell></row><row><cell>RetinaNet [11]</cell><cell></cell><cell cols="2">TableBank-LaTeX</cell><cell>199K</cell><cell>UNLV</cell><cell>302</cell><cell>UNLV</cell><cell>101</cell><cell>0.6</cell><cell cols="3">0.830 0.810 0.820</cell><cell>-</cell></row><row><cell>SSD [11]</cell><cell></cell><cell cols="2">TableBank-LaTeX</cell><cell>199K</cell><cell>UNLV</cell><cell>302</cell><cell>UNLV</cell><cell>101</cell><cell>0.6</cell><cell cols="3">0.660 0.720 0.690</cell><cell>-</cell></row><row><cell>YOLO [11]</cell><cell></cell><cell cols="2">TableBank-LaTeX</cell><cell>199K</cell><cell>UNLV</cell><cell>302</cell><cell>UNLV</cell><cell>101</cell><cell>0.6</cell><cell>0.950</cell><cell cols="2">0.930 0.940</cell><cell>-</cell></row><row><cell>CDeC-Net (our)</cell><cell></cell><cell cols="2">TableBank-LaTeX</cell><cell>199K</cell><cell>UNLV</cell><cell>302</cell><cell>UNLV</cell><cell>101</cell><cell>0.6</cell><cell>0.894</cell><cell cols="2">0.991 0.943</cell><cell>0.889</cell></row><row><cell>CDeC-Net  ‡ (our)</cell><cell></cell><cell>IIIT-AR-13K</cell><cell></cell><cell>9K</cell><cell></cell><cell></cell><cell>UNLV</cell><cell>424</cell><cell>0.5</cell><cell>0.770</cell><cell>0.96</cell><cell>0.865</cell><cell>0.742</cell></row><row><cell>CDeC-Net  ‡ (our)</cell><cell></cell><cell>IIIT-AR-13K</cell><cell></cell><cell>9K</cell><cell>private</cell><cell>1019</cell><cell>UNLV</cell><cell>427</cell><cell>0.5</cell><cell cols="3">0.776 0.958 0.866</cell><cell>0.750</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>TABLE VI</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="7">ILLUSTRATES COMPARISON BETWEEN THE PROPOSED CDEC-Method Training Fine-tuning</cell><cell></cell><cell>Test</cell><cell></cell><cell>IoU</cell><cell></cell><cell>Score</cell></row><row><cell></cell><cell cols="2">Dataset</cell><cell cols="2">#Image Dataset</cell><cell></cell><cell cols="2">#Image Dataset</cell><cell cols="2">#Image</cell><cell></cell><cell>R↑</cell><cell>P↑</cell><cell>F1↑ mAP↑</cell></row><row><cell>Li et al. [7]</cell><cell cols="2">TableBank-LaTeX</cell><cell cols="2">253K -</cell><cell></cell><cell cols="3">-TableBank-Word</cell><cell cols="4">1K 0.5 0.956 0.826 0.886</cell><cell>-</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">TableBank-LaTeX</cell><cell cols="4">1K 0.5 0.975 0.987 0.981</cell><cell>-</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">TableBank-both</cell><cell cols="4">2K 0.5 0.962 0.872 0.915</cell><cell>-</cell></row><row><cell>CDeC-Net (our)</cell><cell cols="2">TableBank-LaTeX</cell><cell cols="2">253K -</cell><cell></cell><cell cols="3">-TableBank-Word</cell><cell cols="4">1K 0.5 0.868 0.873 0.871 0.762</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">TableBank-LaTeX</cell><cell cols="4">1K 0.5 0.979 0.995 0.987 0.976</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">TableBank-both</cell><cell cols="4">2K 0.5 0.924 0.934 0.929 0.898</cell></row><row><cell>M-RCNN [11]</cell><cell cols="2">TableBank-LaTeX</cell><cell cols="2">199K -</cell><cell></cell><cell cols="3">-TableBank-LaTeX</cell><cell cols="4">1K 0.6 0.980 0.960 0.940</cell><cell>-</cell></row><row><cell>RetinaNet [11]</cell><cell cols="2">TableBank-LaTeX</cell><cell cols="2">199K -</cell><cell></cell><cell cols="3">-TableBank-LaTeX</cell><cell cols="4">1K 0.6 0.860 0.980 0.920</cell><cell>-</cell></row><row><cell>SSD [11]</cell><cell cols="2">TableBank-LaTeX</cell><cell cols="2">199K -</cell><cell></cell><cell cols="3">-TableBank-LaTeX</cell><cell cols="4">1K 0.6 0.970 0.960 0.965</cell><cell>-</cell></row><row><cell>YOLO [11]</cell><cell cols="2">TableBank-LaTeX</cell><cell cols="2">199K -</cell><cell></cell><cell cols="3">-TableBank-LaTeX</cell><cell cols="4">1K 0.6 0.990 0.980 0.985</cell><cell>-</cell></row><row><cell>CDeC-Net (our)</cell><cell cols="2">TableBank-LaTeX</cell><cell cols="2">199K -</cell><cell></cell><cell cols="3">-TableBank-LaTeX</cell><cell cols="4">1K 0.6 0.978 0.995 0.986 0.974</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>Illustration of complex table detection results. Blue and Green colored rectangles correspond to ground truth and predicted bounding boxes using CDeC-Net. First and Second Rows: show examples where CDeC-Net accurately detects the tables. Third Row: shows examples where CDeC-Net fails to accurately detect the tables.</figDesc><table><row><cell>Fig. 3.</cell><cell></cell><cell></cell><cell></cell></row><row><cell>IoU</cell><cell></cell><cell cols="3">Performance on Various Benchmark Datasets</cell></row><row><cell>Threshold</cell><cell cols="2">ICDAR-2013</cell><cell cols="2">ICDAR-2019</cell><cell>UNLV</cell></row><row><cell></cell><cell>R↑</cell><cell cols="2">P↑ F1↑ R↑</cell><cell>P↑ F1↑ R↑</cell><cell>P↑ F1↑</cell></row><row><cell>0.5</cell><cell cols="4">1.000 1.000 1.000 0.946 0.987 0.966 0.770 0.960 0.865</cell></row><row><cell>0.6</cell><cell cols="4">1.000 1.000 1.000 0.939 0.980 0.959 0.758 0.944 0.851</cell></row><row><cell>0.7</cell><cell cols="4">0.987 0.987 0.987 0.936 0.977 0.956 0.734 0.915 0.825</cell></row><row><cell>0.8</cell><cell cols="4">0.942 0.942 0.942 0.930 0.971 0.950 0.663 0.826 0.744</cell></row><row><cell>0.9</cell><cell cols="4">0.660 0.660 0.660 0.895 0.934 0.915 0.496 0.618 0.557</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">TABLE VIII</cell></row><row><cell cols="5">ILLUSTRATES THE PERFORMANCE OF CDEC-NET UNDER VARYING IOU</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">THRESHOLDS.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>-</head><label></label><figDesc>Net and the existing techniques on various benchmark datasets under the existing experimental environments. The last row of each table presents obtained results using our single model CDeC-Net ‡ trained with IIIT-AR-13K dataset, fine-tuned with training images and evaluated on test images of the respective datasets. Table IV highlights that our single model CDeC-Net ‡ attains very close results to our best model CDeC-Net on ICDAR-2013 dataset. In case of ICDAR-2019, our single model CDeC-Net ‡ obtains the best performance at IoU threshold 0.8. In case of UNLV and TableBank datasets, the performance of single model CDeC-Net ‡ are very close Fig. 4. Illustration visual results of the state-of-the-art CDeC-Net model and single CDeC-Net ‡ model. Blue, Green, and Red colored rectangles correspond to ground truth and predicted bounding boxes using state-of-the-art CDeC-Net and single CDeC-Net ‡ model respectively. First Row: shows examples where CDeC-Net ‡ detects table accurately and CDeC-Net fails to detect table accurately. Second Row: shows examples where CDeC-Net detects table accurately and CDeC-Net ‡ fails to detect table accurately.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>TABLE IX ILLUSTRATES</head><label>IX</label><figDesc>THE PERFORMANCES OF VARIOUS MODELS. ALL MODELS ARE TESTED ON ICDAR-2013 DATASET WITH 0.5 AS IOU THRESHOLD. CASCADE MASK R-CNN WITH COMPOSITE RESNEXT-101 HAVING DEFORMABLE CONVOLUTION AS BACKBONE I.E., CDEC-NET OBTAINS BEST RESULTS AS COMPARED TO OTHER MODELS. WE SELECT CDEC-NET AS OUR FINAL MODEL.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>TABLE</head><label></label><figDesc></figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Ground truth bounding boxes are annotated automatically.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Our code is available publicly at https://github.com/mdv3101/CDeCNet</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>APPENDIX A: EXPERIMENTS Thorough Comparison with State-of-the-Art Techniques: We have done extensive experiments to check the performance of CDeC-Net. Our model is trained and evaluated on different experimental environments proposed by different researchers. The detailed results are shown in Tables X-XII. To provide a fair comparison, we have used two strategies while training-(i) Train a model on the same dataset as proposed by a given researcher. The best model among them is later called as state-of-the-art model. (ii) Train a model on IIIT-AR-13K dataset and then evaluate the model directly on the dataset. After that, we fine-tune it using the training split of the dataset used by the respective researcher. The model is again evaluated on the testing split. This model is called as single CDeC-Net ‡ . The results are shown in the last rows of <ref type="table">Tables X-XII.  It may be noted that for a given dataset, the single CDeC-Net  ‡ model  which is trained on IIIT-AR-13K dataset and fine tuned only on the  training split of the respective dataset (if available)</ref>.</p><p>CDeC-Net is trained and evaluated on ICDAR-2017 dataset (Table X). Our model does not achieve state-of-the-art performance. The main reason behind this is most of the methods used are quite focused on the ICDAR-2017 dataset, while CDeC-Net is generic in nature. We achieve the best result (F1 score of 0.959 at 0.6 IoU and 0.955 at 0.8 IoU) using the single CDeC-Net ‡ model which is trained on IIIT-AR-13K and fine-tuned using ICDAR-2017 training dataset.</p><p>CDeC-Net was evaluated on Marmot dataset under various experimental environments and it achieves state-of-the-art results ( <ref type="table">Table X</ref>). The best performance was observed by the single CDeC-Net ‡ model, which achieves an F1 score of 0.953.</p><p>Recently, two large datasets were released for table detection: TableBank and PubLayNet. We have evaluated the performance of CDeC-Net on them as well. CDeC-Net get an mAP of 0.967 when trained on PubLayNet dataset and hence getting better results than the current benchmark as shown in table XI. Our single model CDeC-Net ‡ gets even better mAP score of 0.978.   <ref type="table">TABLE XIII  ILLUSTRATES THE PERFORMANCE OF CDEC-NET UNDER VARYING IOU THRESHOLDS.</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Effect of IoU Threshold on</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<title level="m">Pascel VOC 16K ICDAR-2019 (archive)</title>
		<imprint>
			<biblScope unit="page" from="599" to="2019" />
		</imprint>
	</monogr>
	<note>archive</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<title level="m">Pascel VOC 16K ICDAR-2019 (archive)</title>
		<imprint>
			<biblScope unit="page" from="599" to="2019" />
		</imprint>
	</monogr>
	<note>archive</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<title level="m">Pascel VOC 16K ICDAR-2019 (archive)</title>
		<imprint>
			<biblScope unit="page" from="599" to="2019" />
		</imprint>
	</monogr>
	<note>archive</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<idno>Pascel VOC 16K ICDAR-2019 (archive) 599 ICDAR-2019 (archive) 198 0.6 0.910 0.950 0.930</idno>
		<title level="m">CDeC-Net (our) Pascel VOC 16K ICDAR-2019 (archive)</title>
		<imprint>
			<biblScope unit="page" from="599" to="2019" />
		</imprint>
	</monogr>
	<note>archive</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Table detection using deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gilani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Qasim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Shafait</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">DeepDeSRT: Deep learning for detection and structure recognition of tables in document images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Schreiber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Agne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dengel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ahmed</surname></persName>
		</author>
		<editor>ICDAR</editor>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">DeCNT: Deep deformable CNN for table detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Siddiqui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Agne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dengel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ahmed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Faster R-CNN based table detection combining corner locating</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
		<editor>ICDAR</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Ensemble of deep object detectors for page object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Vo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">V</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Nguyen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<pubPlace>UIMC</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Table detection in document images using foreground and background features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Arif</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Shafait</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">in DICTA</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<title level="m">TableBank: Table benchmark for image-based table detection and recognition</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">FFD: Figure and formula detection from document images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Younas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">T R</forename><surname>Rizvi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Shafait</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lukowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ahmed</surname></persName>
		</author>
		<editor>DICTA</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">PubLayNet: largest dataset ever for document layout analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Yepes</surname></persName>
		</author>
		<editor>ICDAR</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Graphical object detection in document images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mondal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">V</forename><surname>Jawahar</surname></persName>
		</author>
		<editor>ICDAR</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">The benefits of close-domain fine-tuning for table detection in document images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Á</forename><surname>Casado-García</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Domínguez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Mata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Pascual</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">IIIT-AR-13K: a new dataset for graphical object detection in documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mondal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lipps</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">V</forename><surname>Jawahar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>DAS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Déjean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-L</forename><surname>Meunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Kleber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Lang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>ICDAR 2019 competition on table detection and recognition (cTDaR),&quot; in ICDAR</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">An open approach towards the benchmarking of table structure recognition systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shahab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Shafait</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kieninger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dengel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>DAS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Göbel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Oro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Orsi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>ICDAR 2013 table competition,&quot; in ICDAR</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>2017 competition on page object detection,&quot; in ICDAR</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Dataset, ground-truth and performance metrics for table detection evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>DAS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">A YOLO-based table detection method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tang</surname></persName>
		</author>
		<editor>ICDAR</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Table structure recognition based on textblock arrangement and ruled line position</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Itonori</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDAR</title>
		<imprint>
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Table structure recognition based on robust block segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kieninger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Electronic Imaging</title>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Extracting tabular information from text files</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tupaj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">C H</forename><surname>Chang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
		<respStmt>
			<orgName>EECS Department, Tufts University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Deformable convolutional networks,&quot; in ICCV</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Cbnet: A novel composite backbone network architecture for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ling</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Microsoft COCO: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Cascade R-CNN: High quality object detection and instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Vasconcelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on PAMI</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Structural recognition of tabulated data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kasturi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDAR</title>
		<imprint>
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A method for table structure analysis using DP matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hirayama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDAR</title>
		<imprint>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Recognition of tables using table grammars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Krishnamoorthy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">DAIR</title>
		<imprint>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Mediumindependent table detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Kashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Lopresti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wilfong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Document Recognition and Retrieval VII</title>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Automatic table detection in document images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gatos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Danatsas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Pratikakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Perantonis</surname></persName>
		</author>
		<editor>IPRIA</editor>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Table detection in heterogeneous documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Shafait</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">DAS</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">The T-RECS table recognition and analysis system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kieninger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dengel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">DAS</title>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Trainable table location in document images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Cesarini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Marinai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sarti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Soda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Object recognition supported by user interaction for service robots</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Learning rich hidden Markov models in document analysis: Table location</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Silva</surname></persName>
		</author>
		<editor>ICDAR</editor>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Learning to detect tables in scanned document images using line information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kasar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Barlas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chatelain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Paquet</surname></persName>
		</author>
		<editor>ICDAR</editor>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Table region detection on large-scale PDF files without labeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Kim</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">A table detection method for PDF documents based on convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>DAS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Fast R-CNN</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Faster R-CNN: Towards realtime object detection with region proposal networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gkioxari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">You only look once: Unified, real-time object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Redmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Divvala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Farhadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Focal loss for dense object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">SSD: Single shot multibox detector</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-Y</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
		<title level="m">MMDetection: Open MMLab detection toolbox and benchmark</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Table structure extraction with bi-directional gated recurrent unit networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M D</forename><surname>Khalid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Shahzad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Shafait</surname></persName>
		</author>
		<editor>ICDAR</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">TableNet: Deep learning model for end-to-end table detection and tabular data extraction from scanned document images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Paliwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Vishwanath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rahul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Vig</surname></persName>
		</author>
		<editor>ICDAR</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">A saliency-based convolutional neural network for table and chart detection in digitized documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kavasidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Palazzo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Spampinato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Pino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Giordano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Giuffrida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Messina</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Parameter-free table detection method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Melinda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bhagvati</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDAR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Table detection from document image using vertical arrangement of text blocks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">N</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">A</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">S</forename><surname>Na</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Contents</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Page object detection from PDF document images by deep structured prediction and supervised clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X.-H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-L</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">A GAN-based feature generator for table detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<editor>ICDAR</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Multi-scale multi-task FCN for semantic page segmentation and table detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kifer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Giles</surname></persName>
		</author>
		<idno>2017. 1600 - -ICDAR-POD-2017</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">†</forename><surname>Yolov3</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>+a+p</surname></persName>
		</author>
		<idno>ICDAR-POD-2017 1600 - -ICDAR-POD-2017</idno>
		<imprint>
			<biblScope unit="volume">18</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">†</forename><surname>Fastdetectors</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">16</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">†</forename><surname>Yolov3</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>+a+p</surname></persName>
		</author>
		<idno>ICDAR-POD-2017 1600 - -ICDAR-POD-2017</idno>
		<imprint>
			<biblScope unit="volume">18</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M-Rcnn</forename></persName>
		</author>
		<imprint/>
	</monogr>
	<note>11</note>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M-Rcnn</forename></persName>
		</author>
		<idno>11] TableBank-LaTeX 199K ICDAR-POD-2017</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tablebank-Latex</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
				<title level="m">CDeC-Net ‡ † (our)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
				<title level="m">CDeC-Net ‡ † (our)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Iiit-Ar-13k</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
				<title level="m">CDeC-Net ‡ † (our)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
				<title level="m">CDeC-Net ‡ † (our)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Iiit-Ar-13k</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
				<title level="m">CDeC-Net ‡ (our)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
				<title level="m">CDeC-Net ‡ (our)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
				<title level="m">CDeC-Net ‡ (our)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
				<title level="m">CDeC-Net ‡ (our)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Iiit-Ar-13k</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
				<title level="m">CDeC-Net ‡ (our)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
				<title level="m">CDeC-Net ‡ (our)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Iiit-Ar-13k</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<monogr>
				<title level="m">CDeC-Net ‡ (our)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
				<title level="m">CDeC-Net ‡ (our)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Iiit-Ar-13k</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
