<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Published as a conference paper at ICLR 2021 WHEN OPTIMIZING f -DIVERGENCE IS ROBUST WITH LABEL NOISE</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaheng</forename><surname>Wei</surname></persName>
							<email>jiahengwei@ucsc.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>95060</postCode>
									<settlement>Santa Cruz Santa Cruz</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
							<email>yangliu@ucsc.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>95060</postCode>
									<settlement>Santa Cruz Santa Cruz</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Published as a conference paper at ICLR 2021 WHEN OPTIMIZING f -DIVERGENCE IS ROBUST WITH LABEL NOISE</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T20:01+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We show when maximizing a properly defined f -divergence measure with respect to a classifier's predictions and the supervised labels is robust with label noise. Leveraging its variational form, we derive a nice decoupling property for a family of f -divergence measures when label noise presents, where the divergence is shown to be a linear combination of the variational difference defined on the clean distribution and a bias term introduced due to the noise. The above derivation helps us analyze the robustness of different f -divergence functions. With established robustness, this family of f -divergence functions arises as useful metrics for the problem of learning with noisy labels, which do not require the specification of the labels' noise rate. When they are possibly not robust, we propose fixes to make them so. In addition to the analytical results, we present thorough experimental evidence. Our code is available at https:</p><p>Published as a conference paper at ICLR 2021 an addition of a bias term. Using this result, we analyze under which conditions maximizing an fdivergence measure would be robust to label noise. In particular, we demonstrate strong robustness results for Total Variation divergence, identify conditions under which several other divergences, including Jenson-Shannon divergence and Pearson X 2 divergence, are robust. The resultant fdivergence functions offer ways to learn with noisy labels, without estimating the noise parameters. As mentioned above, this distinguishes our solutions from a major line of previous studies that would require such estimates. When the f -divergence functions are possibly not robust with label noise, our analysis also offers a new way to perform "loss correction". We'd like to emphasize that instead of offering one method/loss/measure, our results effectively offer a family of functions that can be used to perform this noisy training task. Our contributions summarize as follows:</p><p>• We show a certain set of f -divergence measures that are robust with label noise (some under certain conditions). The corresponding f -divergence functions provide the community with robust learning measures that do not require the knowledge of the noise rates.</p><p>• When the f -divergence measures are possibly not robust with label noise, our analysis provides ways to correct the f -divergence functions to offer robustness. This process would require the estimation of the noise rates and our results contribute new ways to leverage existing estimation techniques to make the training more robust.</p><p>• We empirically verified the effectiveness of optimizing f -divergences when noisy labels present. We opensource our solutions at https://github.com/UCSC-REAL/ Robust-f-divergence-measures.</p><p>Joint distribution: P h×Y := P(h(X) = y, Y = y ), y, y ∈ Y.</p><p>And we use Q h×Y to denote the product (marginal) distribution of h(X) and Y :</p><p>Product distribution: Q h×Y := P(h(X) = y) · P(Y = y ), y, y ∈ Y.</p><p>When it is clear from context we will also shorthand the above two distributions as P and Q. We formulate the problem of learning using f -divergence as follows: the goal of the learner is to find a classifier h that maximizes the following divergence measure between P and Q:</p><p>Learning</p><p>Effectively the goal is to find a classifier that maximizes the divergence between the joint distribution and the product distribution. Define a f -mutual information based on f -divergence:</p><p>, equivalently the maximization in Eqn.</p><p>(3) tries to find the classifier that maximizes the f -mutual information between a classifier's output distribution and the true label distribution. A notable example is when f (v) = v log v, the corresponding D f and M f become the famous KL divergence and the mutual information. It is important to note in general maximizing (f -) mutual information between the classifier's predictions and labels does not promise the Bayes optimal classifier h * = argmax h P(h(X) = Y ). Nonetheless, maximizing it often returns a quality one. We provide further analysis in Section 2.2.</p><p>Variational representation As we mentioned earlier, f -divergence admits a variational form which further allows us to focus on maximizing the following variational difference: P(h * (X) = y, Y * = y) P(h * (X) = y) · P(Y * = y) − 1 &gt; P(h(X) = y , Y * = y) P(h(X) = y ) · P(Y * = y) − 1 , ∀h = h * This is because: P(h * (X) = y, Y * = y) P(h * (X) = y) · P(Y * = y) = P(h * (X) = y|Y * = y) P(h * (X) = y) = 1 P(Y * = y) On the other hand P(h(X) = y , Y * = y) P(h(X) = y ) · P(Y * = y) = P(h(X) = y |Y * = y) P(h(X) = y |Y * = y)P(Y * = y) + P(h(X) = y |Y * = −y)P(Y * = −y) = 1 P(Y * = y) + P(h(X)=y |Y * =−y) P(h(X)=y |Y * =y) P(Y * = −y)</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>A machine learning system continuously observes noisy training annotations and it remains a challenge to perform robust training in such scenarios. Earlier and classical approaches rely on estimation processes to understand the noise rate of the labels and then leverage this knowledge to perform label correction <ref type="bibr">(Patrini et al., 2017;</ref><ref type="bibr" target="#b18">Lukasik et al., 2020)</ref>, or loss correction <ref type="bibr">(Natarajan et al., 2013;</ref><ref type="bibr" target="#b15">Liu &amp; Tao, 2015;</ref><ref type="bibr">Patrini et al., 2017)</ref>, or both, among many other more carefully designed approaches (please refer to our related work section for more detailed coverage). Recent works have started to propose robust loss functions or metrics that do not require the above estimation <ref type="bibr" target="#b2">(Charoenphakdee et al., 2019;</ref><ref type="bibr">Xu et al., 2019;</ref><ref type="bibr">Liu &amp; Guo, 2020;</ref><ref type="bibr" target="#b3">Cheng et al., 2020)</ref>. Clear advantages of the latter approaches include their easiness in implementation, as well as their robustness to noisy estimates of the parameters. This work mainly contributes to the second line of studies and aimed to propose relevant loss functions and measures that are inherently robust with label noise.</p><p>We start with formulating the problem of maximizing an f -divergence defined between a classifier's prediction and the labels:</p><formula xml:id="formula_0">h * f = argmax h D f (P h×Y ||Q h×Y ) ,<label>(1)</label></formula><p>where in above D f is an f -divergence function, P and Q are the joint and product (marginal) distribution of the classifier h's predictions on a feature space X and label Y . Though optimizing the f -divergence measure is in general not the same as finding the Bayes optimal classifiers, we show these measures encourage a classifier that maximizes an extended definition of f -mutual information between the classifier's prediction and the true label distribution. We will also provide analysis for when the maximizer of this f -divergence coincides with the Bayes optimal classifier.</p><p>Building on a careful treatment of its variational form, we then reveal a nice property that helps establish the robustness of the f -divergence specified in Eqn. (1): the variational difference term defined with noisy labels is an affine transformation of the clean variational difference, subject to</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">RELATED WORKS</head><p>The now most popular approach of dealing with label noise is to first estimate the noise transition matrix and then use this knowledge to perform loss or sample correction <ref type="bibr">(Scott et al., 2013;</ref><ref type="bibr">Natarajan et al., 2013;</ref><ref type="bibr">Patrini et al., 2017;</ref><ref type="bibr" target="#b17">Lu et al., 2018;</ref><ref type="bibr" target="#b7">Han et al., 2018;</ref><ref type="bibr">Tanaka et al., 2018;</ref><ref type="bibr">Yao et al., 2020;</ref><ref type="bibr">Zhu et al., 2021)</ref>. In particular, the surrogate loss <ref type="bibr">(Scott et al., 2013;</ref><ref type="bibr">Natarajan et al., 2013;</ref><ref type="bibr">Scott, 2015;</ref><ref type="bibr">Van Rooyen et al., 2015;</ref><ref type="bibr">Menon et al., 2015)</ref> uses the transition matrix to define unbiased estimates of the true losses. Other works include <ref type="bibr">(Sukhbaatar &amp; Fergus, 2014;</ref><ref type="bibr">Xiao et al., 2015)</ref>, which consider building a neural network to facilitate the learning of noise rates or noise transition matrix. Symmetric loss has been studied and conditions have been identified for when there is no need to estimate noise rate <ref type="bibr">(Manwani &amp; Sastry, 2013;</ref><ref type="bibr" target="#b5">Ghosh et al., 2015;</ref><ref type="bibr" target="#b6">2017;</ref><ref type="bibr">Van Rooyen et al., 2015;</ref><ref type="bibr" target="#b2">Charoenphakdee et al., 2019)</ref>. Nonetheless, it remains a challenge to develop training approaches without requiring knowing the noise rates for more generic settings.</p><p>More recently, <ref type="bibr">(Zhang &amp; Sabuncu, 2018;</ref><ref type="bibr" target="#b0">Amid et al., 2019)</ref> proposed robust losses for neural networks. When noise rates are asymmetric (label class-dependent), <ref type="bibr">(Xu et al., 2019)</ref> proposed an information-theoretic loss that is also robust to asymmetric noise rates. There are also some trials on modifying the regularization term to improve generalization ability with the existence of label noise <ref type="bibr" target="#b10">(Jenni &amp; Favaro, 2018;</ref><ref type="bibr">Yi &amp; Wu, 2019)</ref>, and on providing complementary negative labels <ref type="bibr" target="#b11">(Kim et al., 2019)</ref>. Peer loss <ref type="bibr">(Liu &amp; Guo, 2020</ref>) is a recently proposed loss function that does not require knowing noise rates.</p><p>f -divergence is a popular information theoretical measure, and has been widely used and studied.</p><p>Most relevant to us, f -GAN was proposed in <ref type="bibr">(Nowozin et al., 2016)</ref> to study f -divergence in training generative neural samplers. To our best knowledge, ours is the first to study the robustness of fdivergence measures in the context of improving the robustness of training with noisy labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">LEARNING WITH NOISY LABELS USING f -DIVERGENCE</head><p>Our solution ties to the definition of f -divergence. The f -divergence between two distributions P and Q with probability density function p and q being measures for Z ∈ Z 1 is defined as:</p><formula xml:id="formula_1">D f (P Q) = Z q(Z)f p(Z) q(Z) dZ .</formula><p>(2) f (·) is a convex function such that f (1) = 0. Examples include KL-divergence when f (v) = v log v and Total Variation (TV) divergence with f (v) = 1 2 |v − 1|. Other examples can be found in <ref type="table" target="#tab_0">Table  1</ref>. Following from Fenchel's convex duality, f -divergence admits the following variational form:</p><formula xml:id="formula_2">D f (P Q) = sup g:Z→dom(f * ) E Z∼P [g(Z)] − E Z∼Q [f * (g(Z))] ,</formula><p>where f * is the Fenchel duality of the function f (·), which is defined as f * (u) = sup v∈R {uv − f (v)}. We use dom(f * ) to denote the domain of f * .</p><p>We consider the classification problem of learning a classifier h : X → Y that maps features X ∈ X to labels Y ∈ Y := {1, 2, ..., K}, where in above X × Y denote the random variables for features and labels. X × Y jointly draw from a distribution D. For a clear presentation, we will often focus on presenting the binary classification setting Y = {−1, +1}, but most of our core results extend to multi-class classification problems, and we shall provide corresponding justifications.</p><p>Instead of having access to sampled training data from X ×Y , we consider a setting with noisy labels where the noisy labelỸ generates according to a transition matrix T defined betweenỸ and the true label Y . The (i, j) element of T is defined as T i,j = P(Ỹ = j|Y = i) where i, j ∈ {1, ..., K}.</p><p>For the ease of presentation, when we present for the binary case, we adopt the following notation: e + := P(Ỹ = −1|Y = +1), e − := P(Ỹ = +1|Y = −1) , e + + e − &lt; 1. Suppose we have access to a noisy training dataset {x n ,ỹ n } N n=1 , whereỹ n generates according toỸ .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">LEARNING USING D f</head><p>We will start with presenting our idea of training a classifier using D f with the clean training data. Then we will proceed to the case with noisy labels. For an arbitrary classifier h, let's denote by P h×Y the joint distribution of h(X) and Y :</p><formula xml:id="formula_3">h * f = argmax h sup g E Z∼P h×Y [g(Z)] − E Z∼Q h×Y [f * (g(Z))] ,</formula><p>where we use Z to shorthand the tuple [h(X), Y ]. Denote the variational difference as follows:</p><formula xml:id="formula_4">VD f (h, g) := E Z∼P h×Y [g(Z)] − E Z∼Q h×Y [f * (g(Z))] .<label>(4)</label></formula><p>Let g * be the corresponding optimal variational function g for VD f (h, g). This variational form allows us to use a training dataset {(x n , y n )} N n=1 to perform the above maximization problem listed in Eqn. (3) <ref type="bibr">(Nowozin et al., 2016)</ref>. A list of f -divergence functions together with the optimal variational/conjugate functions g/f * is summarized in <ref type="table" target="#tab_0">Table 1</ref>. As we mentioned earlier, maximizing our defined f -divergence measures (or maximizing the fmutual information) between the classifier's predictions and labels is not always returning the Bayes optimal classifier. However, for a binary classification problem, we prove below that with balanced dataset, maximizing Total Variation (TV) divergence returns the Bayes optimal classifier: Theorem 1. For TV, when P(Y = +1) = P(Y = −1) (balanced), h * f is the Bayes optimal classifier. Remark 2. The above theorem extends to the multi-class setting when we restrict attentions to confident classifiers. See Appendix for details.</p><formula xml:id="formula_5">Name D f (P ||Q) g * dom f * f * (u) Total Variation 1 2 |p(z) − q(z)|dz 1 2 sign p(z) q(z) − 1 u ∈ [− 1 2 , 1 2 ] u Jenson-Shannon 1 2 p(z) log 2p(z) p(z) + q(z) + q(z) log 2q(z) p(z) + q(z) dz log 2p(z) p(z) + q(z) u &lt; log 2 − log (2 − e u ) Pearson X 2 (q(z) − p(z)) 2 p(z) dz 2 p(z) q(z) − 1 R 1 4 u 2 + u KL p(z) log p(z) q(z) dx 1 + log p(z) q(z) R e u−1</formula><p>The above observation is not easily true for other f -divergence. Nonetheless, denote by Y * (X = x) the Bayes optimal label for an instance x: Y * (X = x) = argmax y P(Y = y|X = x). Denote by P h×Y * , Q h×Y * the joint and product distribution P, Q defined w.r.t. h(X) and Y * . We prove:</p><formula xml:id="formula_6">Theorem 3. When P(Y * = +1) = P(Y * = −1) (balanced), maximizing D f (P h×Y * Q h×Y * ) returns the Bayes optimal classifier, if f (v) is monotonically increasing in |v − 1| on dom(f ).</formula><p>For example, Pearson X 2 (f (v) = (v − 1) 2 ) satisfies the monotonicity condition. In practice, when the label distribution P(Y |X = x) has small uncertainties, the ground truth labels are approximately equivalent to the Bayes optimal label. Therefore, the above theorem implies that maximizing D f (P h×Y Q h×Y ) is also likely to return a high-quality classifier for other f -divergences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">LEARNING WITH NOISY LABELS</head><p>Consider an arbitrary classifier h. Denote byP h×Ỹ the joint distribution of h(X) andỸ : Joint noisy distribution:P h×Ỹ := P(h(X) = y,Ỹ = y ), y, y ∈ Y.</p><p>Similarly, we useQ h×Ỹ to denote the product (marginal) distribution of h(X) andỸ :</p><p>Product noisy distribution:Q h×Ỹ := P(h(X) = y) · P(Ỹ = y ), y, y ∈ Y.</p><p>When it is clear from context, we shorthand usingP ,Q. We are interested in understanding the robustness in maximizing D f (P h×Ỹ ||Q h×Ỹ ). Using training samples {x n ,ỹ n } N n=1 , there exists algorithms to compute the gradient of D f leveraging its variational form <ref type="bibr">(Nowozin et al., 2016)</ref>, such that one can apply gradient descent or ascent to optimize it. We provide details in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">VARIATIONAL DIFFERENCE WITH NOISY LABELS</head><p>For an arbitrary g, we define the variational difference term w.r.t. the noisy label as follows:</p><formula xml:id="formula_7">VD f (h, g) := EZ ∼P h×Ỹ g(Z) − EZ ∼Q h×Ỹ f * (g(Z))<label>(5)</label></formula><p>where we useZ to denote [h(X),Ỹ ]. Denote byg * the corresponding optimal variational function g for VD f (h, g). In this section, we show that the variational difference term under noisy labels is closely related to the variational difference term defined on the clean distributions P, Q. Define the following quantity:</p><formula xml:id="formula_8">∆ y f (h, g) := E X [g(h(X), y)] − E X [f * (g(h(X), y))] , for example ∆ +1 f (h, g) := E X [g(h(X), +1)] − E X [f * (g(h(X), +1))]</formula><p>. For a binary classification problem, further denote by Bias f (h, g) := e + · ∆ −1 f (h, g) + e − · ∆ +1 f (h, g). We derive the following fact: Theorem 4. For binary classification, the variational difference between the noisy distributionsP andQ relates to the one defined on the clean distributions in the following way:</p><formula xml:id="formula_9">VD f (h, g) = (1 − e + − e − )VD f (h, g) + Bias f (h, g)<label>(6)</label></formula><p>The above decoupling result is inspiring: Bias f (h, g) can be viewed as the additional bias term introduced by label noise. If this term has negligible effect in the maximization problem, maximizing the noisy variational difference term will be equivalent to maximizing (1 − e + − e − ) · VD f (h, g), and therefore the clean variational difference term.</p><p>If the above is true, we have established the robustness of the corresponding f -divergence. This result also points out that when the effects from the bias term are non-negligible, finding ways to counter the additional bias term will help us retain the robustness of D f measures. Next we show that Theorem 4 extends to the multi-class setting under two broad families of noise rate models, both covering the binary setting as a special case.</p><p>Multi-class extension of Theorem 4: uniform off-diagonal case We first consider the following transition matrix: uniform off-diagonal transition matrix, where e j = T i,j , ∀i = j, that is any other classes i = j has the same chance of being flipped to class j. The diagonal entry T i,i (chance of a correct label) becomes 1 − j =i e j . We further require that j e j &lt; 1. Note that the binary noise rate model is easily a uniform off-diagonal transition matrix. Theorem 5.</p><p>[Multi-class] For uniform off-diagonal noise transition model, the noisy variational difference term relates to the clean one in the following way:</p><formula xml:id="formula_10">VD f (h, g) = (1 − K j=1 e j ) · VD f (h, g) + K j=1 e j · ∆ j f (h, g)<label>(7)</label></formula><p>If we define Bias f (h, g) := K j=1 e j · ∆ j f (h, g), we reproduced the results in Theorem 4: for binary case, relabel class 1 → +1, 2 → −1. Then e 1 := P(Ỹ = +1|Y = −1) = e − , e 2 := P(Ỹ = −1|Y = +1) = e + . Another case of noise model we consider is sparse noise. Mathematically, assume K is an even number, sparse noise model specifies K 2 disjoint pairs of classes (i c , j c ) where c ∈ [ K 2 ] and i c &lt; j c . The labels flip between each pair. We provide details in the Appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">WHEN D f IS ROBUST WITH LABEL NOISE</head><p>Denote by H an arbitrary hypothesis space for training a candidate classifier h. We will focus on H throughout this section, and with abusing notation a bit, let h * f = argmax h∈H D f (P h×Y ||Q h×Y ) . We first define formally what we mean by robustness of D f (P h×Y Q h×Y ).</p><formula xml:id="formula_11">Definition 1. D f (P h×Y Q h×Y ) is H-robust if h * f = argmax h∈H D f (P h×Ỹ ||Q h×Ỹ ).</formula><p>The above definition is stating that the label noise does not disrupt the optimality of h * f when maxi-</p><formula xml:id="formula_12">mizing D f (P h×Ỹ ||Q h×Ỹ ) instead of D f (P h×Y Q h×Y ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">IMPACT OF THE BIAS TERMS</head><p>In this section, we take a closer look at the Bias terms and argue that they have diminishing effects as compared to the VD terms when label noise increases. Recall g * ,g * are the corresponding optimal variational functions for VD f (h, g) and VD f (h, g).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Total variation (TV)</head><p>For TV, since f (v) = 1 2 |v − 1|, f * (u) = u, we immediately have ∀y g(h = y , y) − f * (g(h = y , y)) = 0 and therefore ∆ y f (h, g) = E X [g(h(X), y)] − E X [f * (g(h(X), y))] ≡ 0, ∀y, and further Bias f (h, g) ≡ 0. This fact helps establish the robustness of TV divergence measure (Theorem 7).</p><p>Other divergences The above nice property generally does not hold for other f -divergence functions. Next we focus on the binary classification setting and prove the following lemma: Lemma 1. For f -divergence listed in <ref type="table" target="#tab_7">Table 6</ref> </p><formula xml:id="formula_13">(Appendix), Bias f (h,g * ) = O (1 − e + − e − ) 2 .</formula><p>Note the variational form will be used when optimizing D f (P h×Ỹ ||Q h×Ỹ ) (and therefore we will be usingg * ). This lemma simplifies Eqn.</p><formula xml:id="formula_14">4 to VD f (h, g) ∝ VD f (h, g) + O(1 − e + − e − ).</formula><p>Since 0 &lt; 1 − e + − e − ≤ 1, when the noise rate e + + e − is high, the effect of Bias term diminishes. When the Bias term becomes negligible, we will have VD f (h, g) ∝ VD f (h, g) if e + + e − → 1, establishing the fact that optimizing VD f (h, g) is approximately the same as optimizing VD f (h, g).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">HOW ROBUST ARE D f S?</head><p>We first prove the following result: Theorem 6. D f is H-robust when Bias f (h, g) satisfies either of the following conditions:</p><formula xml:id="formula_15">(I) ∀h ∈ H, Bias f (h, g) ≡ const.; (II) ∀h ∈ H, h = h * f , Bias f (h,g * ) ≤ Bias f (h * f , g * ).</formula><p>Theorem 6 gives sufficient conditions when the Bias term does not get in the way of reaching the optimality h * f . Intuitively, when Bias f (h * f , g * ) is an upper bound of Bias f (h,g * ), the Bias term will not interfere with the convergence of the VD term. Next we provide specific examples of fdivergence functions that would satisfy these conditions. Total Variation (TV) is robust For TV, the fact that ∆ y f (h, g) ≡ 0 allows us to prove: Theorem 7. For TV divergence, Bias f (h, g) ≡ const. and D f (P h×Y Q h×Y ) is H-robust with label noise for any arbitrary hypothesis space H.</p><p>This result establishes TV as a strong measure that does not require specifying the noise rates.</p><p>Divergences that are conditionally robust Other divergences functions do not enjoy the above nice property as TV has. The robustness of these functions need more careful analysis. Define the following measures that capture the degree a classifier fits to a particular label distribution: .</p><p>FIT measures capture the degree of fit of the classifier to the corresponding label distribution. A high FIT(h = y,Ỹ = y) (same label) indicates a potential overfit to the noisy label. Denote by</p><formula xml:id="formula_16">H * :={h ∈ H : min y FIT(h = y,Ỹ = y) ≥ max y FIT(h * f = y, Y = y) ≥ 1} ∪ {h * f }</formula><p>The 1 in the "≥ 1" above corresponds to the FIT for a random classifier. H * contains the classifiers that are likely to overfit to the noisy labels. We argue, and also as observed in training, that H * is the set of classifiers the training should avoid converging to, especially when the training only sees noisy labels. Suppose P(Y = +1) = P(Y = −1) (balanced clean labels) and e + = e − (symmetric noise rate), we have the following theorem for binary classification:</p><p>Theorem 8. f -divergences listed in <ref type="table" target="#tab_7">Table 6</ref> (Appendix, except for Jeffrey) are H * -robust.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">MAKING D f MEASURES ROBUST TO LABEL NOISE</head><p>For the general case, to further improve robustness of D f measures, we will need to estimate the noise rates (e.g., e + , e − ) and then subtract Bias f (g, h) from the noisy variational difference term to correct the bias introduced by the noisy labels. As a corollary of Theorem 4 we have:</p><p>Corollary 1. Maximizing the following bias-corrected VD f (h, g) defined overP andQ leads to h *</p><formula xml:id="formula_17">f h * f = argmax h∈H sup g EZ ∼P h×Ỹ g(Z) − EZ ∼Q h×Ỹ f * (g(Z)) − Bias f (h, g) .</formula><p>By removing the Bias f term, maximizing EZ ∼P [g(Z)] − EZ ∼Q [f * (g(Z))] becomes the same with maximizing the divergence defined on the clean distribution (1 − K j=1 e j ) · VD f (h, g). The Corollary follows trivially from this fact. The calculation of the Bias terms will require the inputs of noise rates. Our work does not intend to particularly focus on noise rate estimation. But rather, we can leverage the existing results in performing efficient noise rate estimation. There are existing literature on estimating noise rates (noise transition matrix) which can be implemented without the need of ground truth labels. For interested readers, please refer to <ref type="bibr" target="#b15">(Liu &amp; Tao, 2015;</ref><ref type="bibr">Menon et al., 2015;</ref><ref type="bibr" target="#b8">Harish et al., 2016;</ref><ref type="bibr">Patrini et al., 2017;</ref><ref type="bibr" target="#b1">Arazo et al., 2019;</ref><ref type="bibr">Yao et al., 2020;</ref><ref type="bibr">Zhu et al., 2021)</ref>. We will test the effectiveness of this bias correction step in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTS</head><p>In this section, we validate our analysis of D f measures' robustness via a set of empirical evaluations on 5 datasets: <ref type="bibr">MNIST (LeCun et al. (1998)</ref>), Fashion-MNIST (Xiao et al. <ref type="formula" target="#formula_0">(2017)</ref>), CIFAR-10 and CIFAR-100 <ref type="bibr" target="#b13">(Krizhevsky et al. (2009)</ref>), and Clothing1M (Xiao et al. <ref type="formula" target="#formula_0">(2015)</ref>). Omitted experiment details are available in the appendix.</p><p>Baselines We compare our approach with five baseline methods: Cross-Entropy (CE), Backward (BLC) and Forward Loss Correction (FLC) methods as introduced in (Patrini et al., 2017), the determinant-based mutual information (DMI) method introduced in (Xu et al., 2019) and Peer-Loss (PL) functions in <ref type="bibr">(Liu &amp; Guo, 2020)</ref>. BLC and FLC methods require estimating the noise transition matrix. DMI and PL are approaches that do not require such estimation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Noise model</head><p>We test three types of noise transition models: uniform noise, sparse noise, and random noise. All details of the noise are in the Appendix. Here we briefly overview them. The uniform and sparse noise are as specified at the end of Section 3 for which our theoretical analyses mainly focus on. The noise rates of low-level uniform noise and sparse noise are both approximately 0.2 (the average probability of a label being wrong). The high-levels are about 0.55 and 0.4 respectively. In the random noise setting, each class randomly flips to one of 10 classes with probability p (Random p). For CIFAR-100, the noise rate of uniform noise is about 0.25. The sparse label noise is generated by randomly dividing 100 classes into 50 pairs, and the noise rate is about 0.4.</p><p>Optimizing D f (P h×Ỹ ||Q h×Ỹ ) using noisy samples With the noisy training dataset {x n ,ỹ n } N n=1 , we optimize D f (P h×Ỹ ||Q h×Ỹ ) using gradient ascent of its variational form. Sketch is given in Algorithm 1. For the bias correction version of our algorithm, the gradient will simply include the ∇Bias f (h, g). The variational functiong * can be updated progressively or can be fixed beforehand using an approximate activation function for each f (see e.g., <ref type="bibr">(Nowozin et al., 2016)</ref>).</p><p>Algorithm 1 Maximizing D f measures: one step gradient</p><formula xml:id="formula_18">1: Inputs: Training data {(x n ,ỹ n )} N n=1 , f , variational functiong * , conjugate f * , classifier h t . 2: Randomly sample three mini-batches {(x n ,ỹ n )} B n=1 , {(x † n ,ỹ † n )} B n=1 , {(x n ,ỹ n )} B n=1 from {(x n ,ỹ n )} N n=1 . {(x n ,ỹ n )} B n=1 : simulate samples ∼P ; {(x † n ,ỹ n )} B n=1 to simulateQ. 3: Use h t,xn [ỹ n ] to denote model prediction on x n for labelỹ n , E {(xn,ỹn)} B n=1 , E {(x † n ,ỹ n )} B n=1</formula><p>to denote the empirical sample mean calculated using the mini-batch data. 4: At step t, update h t by ascending its stochastic gradient with learning rate η t :</p><formula xml:id="formula_19">h t+1 := h t + η t · ∇ ht E {(xn,ỹn)} B n=1 [g * (h t,xn [ỹ n ])] − E {(x † n ,ỹ n )} B n=1 [f * g * (h t,x † n [ỹ n ]) ]</formula><p>. Tips: In practice, we suggest (also implemented in our experiments) using the fixed form ofg * which appears as g f (v) in Table 6 (appendix).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">HOW</head><formula xml:id="formula_20">GOOD IS h * f ON CLEAN DATA</formula><p>As a supplementary of Section 2.2, we validate the quality of h * f on clean dataset of MNIST, Fashion MNIST, CIFAR-10 and CIFAR-100. In experiments, since the estimation of product noisy distribution are unstable when trained on CIFAR-100 training dataset, we use CE as a warm-up (120 epochs) and then switch to train with D f measures. For other datasets, we train with D f measures without the warm-up stage. Results in <ref type="table">Table 2</ref>   <ref type="table">Table 2</ref>: Experiment results comparison on clean datasets: We report the maximum accuracy of CE and each D f measures along with (mean ± standard deviation); Gap: mean performance comparison w.r.t. CE. Numbers highlighted in blue indicate the gap is less than 1%. As a demonstration, we apply the uniform noise model to CIFAR-10 dataset to test the robustness of three D f measures: Total-Variation (TV), Jenson-Shannon (JS) and Pearson (PS). We trained models with D f measures using Algorithm 1 on 10 noise settings with an increasing noise rate from 0% to approximately 81%. The visualization of the D f values and accuracy w.r.t. noise rates are shown in <ref type="figure" target="#fig_1">Figure 1</ref>. Both the D f values and test accuracy are calculated on the reserved clean test data. We observe that almost all D f measures are robust to noisy labels, especially when the percentage of noisy labels is not overwhelmingly large, e.g., ≤ 70%. Note that the curves for other f -divergences are almost the same as the curve of total variation (TV), which is proved to be robust theoretically. This partially validates the analytical evidences we provided for the robustness of other f -divergences in Section 4.1 and 4.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">ROBUSTNESS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">PERFORMANCE EVALUATION AND COMPARISON</head><p>From <ref type="table" target="#tab_3">Table 3</ref>, several D f measures arise as competitive solutions in a variety of noise scenarios.</p><p>Among the proposed f -divergences, Total Variation (TV) has been consistently ranked as one of the top performing method. This aligns also with our analyses that TV is inherently robust. For most settings, the presented f -divergences outperformed the baselines we compare to, while they fell short to DMI (once) and Peer Loss (5 times) on several cases, particularly when the noise is sparse and high. The sparse high noise setting tends to be a challenging setting for all methods. We conjecture this is because sparse high noise setting creates a highly imbalanced dataset, model training is more likely to converge to a "sub-optimal" early in the training process. It is also possible that with sparse noise, the impact of Bias terms becomes non-negligible. We do observe better performances with very careful and intensive hyper-parameter tuning, but the results are not confident and we chose to not report it. Fully understanding the limitation of our approach in this setting remains an interesting on-going investigation.</p><p>In    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>In this paper, we explore the robustness of a properly defined f -divergence measure when used to train a classifier in the presence of label noise. We identified a set of nice robustness properties for a family of f -divergence functions. We also experimentally verified our findings. Our work primarily contributed to the problem of learning with noisy labels without requiring the knowledge of noise rate. Beyond this noisy learning problem, the derivation and analysis might be useful for understanding the robustness of f -divergences for other learning tasks. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A PROOF AND ADDITIONAL THEOREMS</head><p>A.1 SHORT NOTATIONS Throughout the appendix, we will denote by p := P(Y = +1) andp := P(Ỹ = +1) = p · (1 − e + ) + (1 − p) · e − . We will also shorthandP ,Q forP h×Ỹ ,Q h×Ỹ and P, Q for P h×Y , Q h×Y .</p><p>A <ref type="table" target="#tab_0">.2 FULL TABLES OF TABLE 1</ref> In experiments, we adopt the output activation function g f (v) instead of optimal activation functions g * by referring to the implementation of f- <ref type="bibr">GAN (Nowozin et al., 2016)</ref>. Proof. First note</p><formula xml:id="formula_21">Name g f (v) g * dom f * f * (u) Total Variation ( ) 1 2 tanh(v) 1 2 sign p(z) q(z) − 1 u ∈ [− 1 2 , 1 2 ] u Jenson-Shannon ( ) log 2 1 + e −v log 2p(z) p(z) + q(z) u &lt; log 2 − log (2 − e u ) Squared Hellinger () 1 − e v 1 − q(z) p(z) u &lt; 1 u 1 − u Pearson X 2 ( ) v 2 p(z) q(z) − 1 R 1 4 u 2 + u Neyman X 2 () 1 − e v 1 − q(z) p(z) 2 u &lt; 1 2 − 2 √ 1 − u KL ( ) v 1 + log p(z) q(z) R e u−1 Reverse KL () −e v − q(z) p(z) R− −1 − log (−u) Jeffrey ( ) v 1 + log p(z) q(z) − q(z) p(z) R W (e 1−u ) + 1 W (e 1−u ) + u − 2</formula><formula xml:id="formula_22">EZ ∼P g(Z) = p · EZ ∼P |Y =+1 g(Z) + (1 − p) · EZ ∼P |Y =−1 g(Z) = p · E X|Y =+1 [(1 − e + ) · g(h(X), +1) + e + · g(h(X), −1)] + (1 − p) · E X|Y =−1 [(1 − e − ) · g(h(X), −1) + e − · g(h(X), +1)] = p · E X|Y =+1 [(1 − e + − e − ) · g(h(X), +1) + e + · g(h(X), −1) + e − · g(h(X), +1)] + (1 − p) · E X|Y =−1 [(1 − e + − e − ) · g(h(X), −1) + e + · g(h(X), −1) + e − · g(h(X), +1)] = (1 − e + − e − ) · E Z∼P [g(Z)] + E X [e + · g(h(X), −1) + e − · g(h(X), +1)]</formula><p>The second term in the variational difference derives as:</p><formula xml:id="formula_23">EZ ∼Q f * (g(Z)) =p · E X [f * (g(h(X), +1))] + (1 −p) · E X [f * (g(h(X), −1))] = p · (1 − e + − e − ) · E X [f * (g(h(X), +1))] + e − · E X [f * (g(h(X), +1))] + (1 − p) · (1 − e + − e − ) · E X [f * (g(h(X), −1))] + e + · E X [f * (g(h(X), −1))] = (1 − e + − e − ) · E Z∼Q [f * (g(Z))] + E X [e − · f * (g(h(X), +1)) + e + · f * (g(h(X), −1))]</formula><p>Combining EZ ∼P g(Z) and EZ ∼Q f * (g(Z)) : the leading terms combine into</p><formula xml:id="formula_24">(1 − e + − e − ) · E Z∼P [g(Z)] − (1 − e + − e − ) · E Z∼Q [f * (g(Z))] = (1 − e + − e − ) · VD f (h, g)</formula><p>and the rest:</p><formula xml:id="formula_25">E X [e + · g(h(X), −1) + e − · g(h(X), +1)] − E X [e − · f * (g(h(X), +1)) + e + · f * (g(h(X), −1))] = e + · ∆ −1 f (h, g) + e − · ∆ +1 f (h, g) = Bias f (h, g)</formula><p>we proved the claim.</p><p>A.4 PROOF OF THEOREM 5: MULTI-CLASS EXTENSION I OF THEOREM 4</p><p>Proof. Denote p i = P(Y = i),p i := P(Ỹ = i),p i = (1 − j =i e j ) · p i + e i · j =i p j . We have:</p><formula xml:id="formula_26">EZ ∼P g(Z) = K i=1 p i · EZ ∼P |Y =i g(Z) = K i=1 p i · E X|Y =i   K j=1 T i,j · g(h(X),Ỹ = j)   = K i=1 p i · E X|Y =i   (1 − j =i e j ) · g(h(X),Ỹ = i) + j =i e j · g(h(X),Ỹ = j)   = K i=1 p i · E X|Y =i   (1 − K j=1 e j ) · g(h(X),Ỹ = i) + K j=1 e j · g(h(X),Ỹ = j)   = (1 − K j=1 e j ) · E Z∼P [g(Z)] + K j=1 e j · E X [g(h(X), j)] EZ ∼Q f * (g(Z)) = K i=1p i · E X f * (g(h(X),Ỹ = i)) = K i=1 [(1 − K j=1 e j ) · p i + e i · K j=1 p j ] · E X f * (g(h(X),Ỹ = i)) = (1 − K j=1 e j ) · E Z∼Q [f * (g(Z))] + K j=1 e j · E X [f * (g(h(X), j))]</formula><p>Similar to the binary case, combining EZ ∼P g(Z) and EZ ∼Q f * (g(Z)) we proved the claim.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.5 MULTI-CLASS EXTENSION II OF THEOREM 4: SPARSE CASE</head><p>For sparse transition matrix, assume K is an even number, sparse noise model specifies K 2 disjoint pairs of classes (i c , j c ) where c ∈ [ K 2 ] and i c &lt; j c . The diagonal entry T ic,ic becomes 1 − T ic,jc . Suppose ∀c ∈ [ K 2 ], T ic,jc = e p1 , T jc,ic = e p2 , e p1 + e p2 &lt; 1. Theorem 9. [Multi-class extension II] In the scenario of sparse noise transition model, the variational difference between the noisy distributionsP andQ relates to the one defined over the clean distributions in the following way:</p><formula xml:id="formula_27">VD f (h, g) =(1 − e p1 − e p2 ) · VD f (h, g) + (ic,jc) e p1 · ∆ jc f (g, h) + e p2 · ∆ ic f (g, h) .</formula><p>Proof.</p><formula xml:id="formula_28">EZ ∼P g(Z) = K i=1 p i · EZ ∼P |Y =i g(Z) = K i=1 p i · E X|Y =i   K j=1 T i,j · g(h(X),Ỹ = j)   = ic p ic · E X|Y =ic (1 − e p1 ) · g(h(X),Ỹ = i c ) + e p1 · g(h(X),Ỹ = j c ) + jc p jc · E X|Y =jc (1 − e p2 ) · g(h(X),Ỹ = j c ) + e p2 · g(h(X),Ỹ = i c ) = K i=1 p i · E X|Y =i (1 − e p1 − e p2 ) · g(h(X),Ỹ = i) + (ic,jc) (e p1 · g(h(X),Ỹ = j c ) + e p2 · g(h(X),Ỹ = i c )) = (1 − e p1 − e p2 ) · E Z∼P [g(Z)] + (ic,jc) E X e p1 · g(h(X),Ỹ = j c ) + e p2 · g(h(X),Ỹ = i c )</formula><p>Similarly, we have:</p><formula xml:id="formula_29">EZ ∼Q f * (g(Z)) = K i=1p i · E X f * (g(h(X),Ỹ = i)) = K i=1 (1 − K j=1 e j ) · p i + e i · K j=1 p j · E X f * (g(h(X),Ỹ = i)) = (1 − e p1 − e p2 ) · E Z∼Q [f * (g(Z))] + (ic,jc)</formula><p>E X e p1 · f * (g(h(X),Ỹ = j c )) + e p2 · f * (g(h(X),Ỹ = i c ))</p><p>Combining EZ ∼P g(Z) and EZ ∼Q f * (g(Z)) we proved the claim.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.6 PROOF OF THEOREM 1: TOTAL-VARIATION GENERATES BAYES OPTIMAL</head><p>Proof. For total variation, we have</p><formula xml:id="formula_30">D f (P h×Y Q h×Y ) = 1 2 y,y ∈{−1,+1} |P(h(X) = y, Y = y ) − P(h(X) = y) · P(Y = y )|</formula><p>We again present the main proof for the binary classification setting.</p><p>First note the following fact that Because of the above, there are four possible combinations of cases:</p><formula xml:id="formula_31">Case 1 P(h(X) = +1, Y = +1) − P(h(X) = +1) · P(Y = +1) &gt; 0, P(h(X) = −1, Y = −1) − P(h(X) = −1) · P(Y = −1) &gt; 0: y,y ∈{−1,+1} |P(h(X) = y, Y = y ) − P(h(X) = y) · P(Y = y )| = P(h(X) = +1, Y = +1) − P(h(X) = +1) · P(Y = +1) − P(h(X) = +1, Y = −1) + P(h(X) = +1) · P(Y = −1) + P(h(X) = −1, Y = −1) − P(h(X) = −1) · P(Y = −1) − P(h(X) = −1, Y = +1) − P(h(X) = −1) · P(Y = +1) = P(h(X) = Y ) − P(h(X) = Y ) = 2P(h(X) = Y ) − 1</formula><p>Therefore, maximizing D f total variation returns the Bayes optimal classifier h * , and the optimal value arrives at P(h * (X) = Y ) − 1 2 .</p><formula xml:id="formula_32">Case 2 P(h(X) = +1, Y = +1) − P(h(X) = +1) · P(Y = +1) &lt; 0, P(h(X) = −1, Y = −1) − P(h(X) = −1) · P(Y = −1) &gt; 0: y,y ∈{−1,+1} |P(h(X) = y, Y = y ) − P(h(X) = y) · P(Y = y )| = −P(h(X) = +1, Y = +1) + P(h(X) = +1) · P(Y = +1) + P(h(X) = +1, Y = −1) − P(h(X) = +1) · P(Y = −1) + P(h(X) = −1, Y = −1) − P(h(X) = −1) · P(Y = −1) − P(h(X) = −1, Y = +1) − P(h(X) = −1) · P(Y = +1) = P(Y = −1) − P(Y = +1) = 0</formula><p>Case 3 P(h(X) = +1, Y = +1) − P(h(X) = +1) · P(Y = +1) &gt; 0, P(h(X) = −1, Y = −1) − P(h(X) = −1) · P(Y = −1) &lt; 0: This case is symmetrical to Case 2.</p><p>Case 4 This is symmetrical to Case 1:</p><formula xml:id="formula_33">D f (P h×Y Q h×Y ) = P(h(X) = Y ) − 1 2</formula><p>The optimal classifier is then the opposite of h * , but</p><formula xml:id="formula_34">P(h * (X) = Y ) − 1 2</formula><p>&gt; P(h * (X) = Y ) − 1 2 so the maximizer returns a smaller value compared to Case 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multi-class extension</head><p>We provide arguments for the multi-class generalization. First note that Our following derivation focuses on confident classifiers:</p><p>Definition 3. We call a classifier confident if for each label class y, only one class y k ∈ Y returns positive correlation:</p><formula xml:id="formula_35">P(h(X) = y k , Y = k) − P(h(X) = y k ) · P(Y = k) ≥ 0 while for all other y = y k , we have P(h(X) = y , Y = k) − P(h(X) = y ) · P(Y = k) ≤ 0</formula><p>This above definition is saying the classifier h is "dominantly" confident in predicting one class for the each true label class.</p><p>For a given class k, if all other classes k = y k are negative in P(h(X) = k , Y = k) − P(h(X) = k ) · P(Y = k) , the total variation becomes:</p><formula xml:id="formula_36">k |P(h(X) = k , Y = k) − P(h(X) = k ) · P(Y = k)| =P(h(X) = y k , Y = k) − P(h(X) = y k ) · P(Y = k) + k =y k (P(h(X) = k ) · P(Y = k) − P(h(X) = k , Y = k)) =P(h(X) = y k , Y = k) − P(h(X) = y k ) · P(Y = k) + P(Y = k)(1 − P(h(X) = y k ) − (1 − P(h(X) = y k , Y = k)) =2(P(h(X) = y k , Y = k) − P(h(X) = y k ) · P(Y = k)).</formula><p>Summing up, for a confident classifier, the total variation becomes (ignoring constant 2):</p><formula xml:id="formula_37">k P(h(X) = y k , Y = k) − P(h(X) = y k ) · P(Y = k) = 1 K k P(h(X) = y k |Y = k) − P(h(X) = y k ) = 1 K k P(h(X) = y k |Y = k) − 1 = 1 K k P(Y = k|h(X) = y k )P(h(X) = y k ) P(Y = k) − 1 = k X f X (x) · P(Y = k|h(x) = y k )P(h(x) = y k ) dx − 1 = k X f X (x) · P(Y = k|X = x) · 1(h(x) = y k ) · P(h(x) = y k ) dx − 1 = X f X (x) · k P(Y = k|X = x) · 1(h(x) = y k ) · P(h(x) = y k ) dx − 1 ≤ X f X (x) · k P(Y = k|X = x) · 1(h * (X) = k) · P(h * (X) = k) dx − 1 = k P(h * (X) = k, Y = k) − P(h * (X) = k) · P(Y = k).</formula><p>where the last inequality is due to the fact that the Bayes optimal classifier selects the highest P(Y = k|X) for each x.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.7 PROOF OF THEOREM 3</head><p>Proof. By definition of D f :</p><formula xml:id="formula_38">D f (P h×Y * Q h×Y * ) = y,y P(h(X) = y, Y * = y ) · f P(h(X) = y, Y * = y ) P(h(X) = y) · P(Y * = y )</formula><p>A.8 PROOF OF THEOREM 6: H-ROBUST Proof. The proofs for the multi-class case under uniform diagonal and sparse noise setting are entirely symmetrical due to Theorem 5 and 9. We deliver the main idea for the binary case.</p><p>The proof for condition (I) is easy to see:</p><formula xml:id="formula_39">argmax h∈H D f (P h×Ỹ Q h×Ỹ ) = argmax h∈H sup g EZ ∼P g(Z) − EZ ∼Q f * (g(Z)) = argmax h∈H sup g (1 − e + − e − ) E Z∼P [g(Z)] − E Z∼Q [f * (g(Z)] + Bias f (h, g) = argmax h∈H sup g E Z∼P [g(Z)] − E Z∼Q [f * (g(Z)] = argmax h∈H D f (P h×Y Q h×Y ) =h * f .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Now we prove the robustness of D f under condition (II). Denote by h the classifier that maximizes</head><formula xml:id="formula_40">D f (P h ×Ỹ Q h ×Ỹ ) and D f (P h ×Ỹ Q h ×Ỹ ) &gt; D f (P h * f ×Ỹ Q h * f ×Ỹ ) But D f (P h ×Ỹ Q h ×Ỹ ) =(1 − e + − e − ) E Z∼P [g * ([h (X), Y ])] − E Z∼Q [f * (g * ([h (X), Y ])] + Bias f (h ,g * ) ≤ max h∈H (1 − e + − e − ) · sup g E Z∼P [g([h(X), Y ])] − E Z∼Q [f * (g([h(X), Y ])] + Bias f (h * f , g * ) (Bias f (h,g * ) ≤ Bias f (h * f , g * )) = max h∈H (1 − e + − e − ) · D f (P h×Y Q h×Y ) + Bias f (h * f , g * ) (variational form of D f ) =(1 − e + − e − ) · D f (P h * f ×Y Q h * f ×Y ) + Bias f (h * f , g * ) ≤ sup g E Z=[h * f (X),Y ]∼P [g(Z)] − E Z=[h * f (X),Y ]∼Q [f * (g(Z))] + Bias f (h * f , g) =D f (P h * f ×Ỹ Q h * f ×Ỹ ),</formula><p>which is a contradiction. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proof.</head><p>P (y, y )</p><formula xml:id="formula_41">Q(y, y ) − 1 = P(h(x) = y|Ỹ = y ) P(h(x) = y) − 1 = P(h(x) = y|Ỹ = y ) −p y P(h(x) = y|Ỹ = y ) − (1 −p y )P(h(x) = y|Ỹ = −y ) P(h(x) = y) = 1 −p y P(h(x) = y) · |P(h(x) = y|Ỹ = y ) − P(h(x) = y|Ỹ = −y )| |P(h(x) = y|Ỹ = y ) − P(h(x) = y|Ỹ = −y )| derives as |P(h(x) = y|Ỹ = y ) − P(h(x) = y|Ỹ = −y )| = p y P(h(x) = y|Y = y ) · P(Y = y |Ỹ = y ) + (1 − p y )P(h(x) = y|Y = −y ) · P(Y = −y |Ỹ = y ) − p y P(h(x) = y|Y = y) · P(Y = y |Ỹ = −y ) − (1 − p y )P(h(x) = y|Y = −y ) · P(Y = −y |Ỹ = −y ) = p y P(h(x) = y|Y = y ) · (P(Y = y |Ỹ = y ) − P(Y = y |Ỹ = −y )) + (1 − p y )P(h(x) = y|Y = −y ) · (P(Y = −y |Ỹ = y ) − P(Y = −y |Ỹ = −y )) = p y P(h(x) = y|Y = y ) − (1 − p y )P(h(x) = y|Y = −y )| · |P(Y = y |Ỹ = y ) − P(Y = y |Ỹ = −y )</formula><p>The last equation is satisfied because ∀y:   <ref type="figure">h(X), y)</ref>)], we analyze each of the term in expectation:g * (y, y ) − f * (g * <ref type="figure">(y, y )</ref>). Using Taylor expansion we know </p><formula xml:id="formula_42">P(Y = y|Ỹ = y) + P(Y = −y|Ỹ = y) = P(Y = −y|Ỹ = −y) + P(Y = y|Ỹ = −y) ⇐⇒P(Y = y|Ỹ = y) − P(Y = y|Ỹ = −y) = P(Y = −y|Ỹ = −y) − P(Y = −y|Ỹ = y)</formula><formula xml:id="formula_43">= p y p y · (1 −p y ) |(1 − e y ) · (1 −p y ) − e y ·p y | = p y p y · (1 −p y ) |(1 − e y ) · (1 − p y (1 − e y ) − (1 − p y )e −y ) − e y · (p y (1 − e y ) + (1 − p y )e −y )| = p y p y · (1 −p y ) |(1 − p y )(1 − e + − e − )| = p y · (1 − p y ) p y · (1 −p y ) |1 − e + − e</formula><formula xml:id="formula_44">) = O(x 2 ) for different f -divergences. Because Bias f (h,g * ) := K j=1 e j · ∆ j f (h,g * ) = K j=1 e j · E X [g * (h(X), y) − f * (g * (</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Jenson-Shannon</head><formula xml:id="formula_45">log 4 2 + x + 1 + 1 x+1 = 0 + x · − 4 · (1 − 1 (x+1) 2 ) 2 + x + 1 + 1 x+1 x=0 + O(x 2 ) = O(x 2 ).</formula><formula xml:id="formula_46">= √ 1 + x + 1 1 + x − 2. √ 1 + x + 1 1 + x − 2 = 1 + 1 2 · √ 1 + x + 1 − 1 2 (1 + x) −1.5 x=0 − 2 + O(x 2 ) = O(x 2 ).</formula><p>Pearson X 2g * (y, y ) − f * (g * (y, y )) =g * (y, y ) −g * (y, y ) − 1 4 (g * (y, y )) 2 = − P (y, y )</p><formula xml:id="formula_47">Q(y, y ) − 1 2 = −x 2 = O(x 2 ).</formula><p>Neyman X 2g * (y, y ) − f * (g * (y, y )) =g * (y, y ) − 2 − 2 1 −g * (y, y ) = − Q (y, y )</p><formula xml:id="formula_48">P (y, y ) − 1 2 = − 1 1 + x − 1 2 = O(x 2 ). KLg * (y, y ) − f * (g * (y, y )) =g * (y, y ) − eg * (y,y )−1 =1 + logP (h(x) = y,Ỹ = y ) Q(h(x) = y,Ỹ = y ) −P (h(x) = y,Ỹ = y ) Q(h(x) = y,Ỹ = y ) 1 + log (1 + x) − (1 + x) = ( 1 1 + x − 1) x=0 + O(x 2 ) = O(x 2 ).</formula><p>Reverse KLg * (y, y ) − f * (g * (y, y )) =g * (y, y ) + 1 + log (−g * (y, y ))</p><formula xml:id="formula_49">=1 −Q (h(x) = y,Ỹ = y ) P (h(x) = y,Ỹ = y ) + logQ (h(x) = y,Ỹ = y ) P (h(x) = y,Ỹ = y ) 1 + log (1 + x) −1 − (1 + x) −1 = 1 + − 1 1 + x − (1 − 1 (1 + x) 2 ) x=0 + O(x 2 ) = O(x 2 ) Jeffrey 1 −g * (y, y ) =Q (h(x) = y,Ỹ = y ) P (h(x) = y,Ỹ = y ) − logP (h(x) = y,Ỹ = y ) Q(h(x) = y,Ỹ = y ) = 1 1 + x − log (1 + x) Andg * (y, y ) = x 1 + x + log (1 + x)</formula><p>g * (y, y ) − f * (g * (y, y )) =g * (y, y ) − W (e 1−g * (y,y ) ) − 1 W (e 1−g * (y,y ) ) −g * (y, y ) + 2 =2 − W (e 1−g * (y,y ) ) − 1 W (e 1−g * (y,y ) ) =2 − W (e 1−g * (y,y ) ) x=0 − W (e 1−g * (y,y ) )</p><formula xml:id="formula_50">x=0 · x − 1 W (e 1−g * (y,y ) ) x=0 − 1 W (e 1−g * (y,y ) ) x=0 · x + O(x 2 ) = − W (e 1−g * (y,y ) ) x=0 · x − 1 W (e 1−g * (y,y ) ) x=0 · x + O(x 2 ) =O(x 2 )</formula><p>A.10 PROOF OF THEOREM 7: H-ROBUSTNESS OF TOTAL-VARIATION Proof. We present the binary derivation but it extends easily to the multi-class case.</p><p>For TV, since f (v) = 1 2 |v − 1|, f * (u) = u, we immediately have ∀y g * (h = y , y) − f * (g(h = y , y)) = 0 and therefore ∆ y f (h, g) = E X [g(h(X), y)] − E X [f * (g(h(X), y))] ≡ 0, ∀y and further for the binary case Bias f (h, g) := e + · ∆ −1 f (h, g) + e − · ∆ +1 f (h, g) = 0 and for the multi-class case</p><formula xml:id="formula_51">Bias f (h, g) = j e j ∆ j f (h, g) = 0.</formula><p>Therefore Bias f (h, g) ≡ 0. We then know TV is H-robust for an arbitrary H using Theorem 6.</p><p>TV's robustness can also be derived straightforwardly for binary classification:</p><formula xml:id="formula_52">sup g EZ ∼P g(Z) − EZ ∼Q f * (g(Z)) = sup |g|≤1/2 (1 − e + − e − ) [E Z∼P [g(Z)] − E Z∼Q [f * (g(Z))]] + E [e + · g(h(X), −1) + e − · g(h(X), +1)] − E [e + · f * (g(h(X), −1)) + e − · f * (g(h(X), +1))] = sup |g|≤1/2 (1 − e + − e − ) [E Z∼P [g(Z)] − E Z∼Q [f * (g(Z))]] + E [e + · g(h(X), −1) + e − · g(h(X), +1)] − E [e + · g(h(X), −1) + e − · g(h(X), +1)] = sup |g|≤1/2 (1 − e + − e − ) [E Z∼P [g(Z)] − E Z∼Q [f * (g(Z))]] = (1 − e + − e − )D f (P h×Y Q h×Y )</formula><p>That is for total variation, minimizing the f -divergence between h(X) andỸ is the same as minimizing the f -divergence between h(X) and the clean distribution Y . The above proof generalizes to multi-class easily. For example for the uniform diagonal noise, we have </p><formula xml:id="formula_53">≤ min y P(h * f (X) = −y|Y = y) P(h * f (X) = −y) ∪ {h * f } ⊆ h ∈ H : max y P(h(X) = y |Ỹ = −y ) P(h(X) = y ) ≤ min y P(h * f (X) = y|Y = −y) P(h * f (X) = y) ∪ {h * f } ⊆ h ∈ H : max y P(h(X) = y |Ỹ = −y ) − P(h(X) = y |Ỹ = y ) P(h(X) = y ) ≤ min y P(h * f (X) = y|Y = −y) − P(h * f (X) = y|Y = y) P(h * f (X) = y) ∪ {h * f } ⊆ h ∈ H : 1 − min y P(h(X) = y |Ỹ = y ) P(h(X) = y ) ≤ 1 − max y P(h * f (X) = y|Y = y) P(h * f (X) = y) ∪ {h * f } ⊆ h ∈ H : min y P(h(X) = y |Ỹ = y ) P(h(X) = y ) ≥ max y P(h * f (X) = y|Y = y) P(h * f (X) = y) ∪ {h * f } ⊆H * = h ∈ H : min y FIT(h(X) = y ,Ỹ = y ) ≥ max y FIT(h * f = y, Y = y) ∪ {h * f } Since t(x)</formula><p>is monotonically decreasing as a function of |x − 1|, for h ∈ H * , Thus, Bias f (h * f , g * ) ≥ max h∈H * Bias f (h,g * ). According to Theorem 6, the corresponding fdivergence measure is H * -robust.</p><formula xml:id="formula_54">Bias f (h * f ,g * ) = e + · y P(h * f (X) = y) · t(FIT(h * f (X) = y, Y = +1)) + e − · y P(h * f (X) = y) · t(FIT(h * f (X) = y, Y = −1)) =e + · y P(h * f (X) = y) · t(FIT(h * f (X) = y, Y = y)) · P(Y = +1) + e + · y P(h * f (X) = y) · t(FIT(h * f (X) = y, Y = −y)) · P(Y = −1) + e − · y P(h * f (X) = y) · t(FIT(h * f (X) = y, Y = y)) · P(Y = −1) + e − · y P(h * f (X) = y) · t(FIT(h * f (X) = y, Y = −y)) · P(Y = +1) = e + + e − 2 · y P(h * f (X) = y) · t(FIT(h * f (X) = y, Y = y)) + t(FIT(h * f (X) = y, Y = −y)) ≥ max h∈H * e + + e − 2 · t(max y FIT(h * f (X) = y, Y = y)) + t(min y FIT(h * f (X) = y, Y = −y)) max h∈H * Bias f (h,g * ) = max h∈H * e + ·</formula><p>A.12 PROOF OF THEOREM 8: ROBUSTNESS OF D f Proof. Earlier we proved Theorem 11, next we show presented conditions in Eqn. <ref type="formula">(8)</ref> and <ref type="formula">(9)</ref> and t(x) can be satisfied by the listed divergences:</p><p>The proof for ∆ y f (h * f , g * ) can be viewed as a special case of ∆ y f (h,g * ).</p><p>The following derivations will therefore focus on ∆ y f (h,g * ) and will not repeat for ∆ y f (h * f , g * ). Correspondingly t(x) = −(x − 1) 2 , which satisfies the requirement specified in Theorem 11. Clearly t(x) = 1 + log x − x satisfies the requirement specified in Theorem 11.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Jenson-Shannon</head><formula xml:id="formula_55">Neyman X 2 For Neyman X 2 we have f * (u) = 2 − 2 √ 1 − u, and ∆ y f (h,g * ) = E[g * (h(X), y) − f * (g * (h(X), y))] = E[g * (h(X), y) + 2 1 −g * (h(X), y) − 2] Sinceg * (y, y ) = 1 − Q(h(X) = y,Ỹ = y ) P (h(X) = y,Ỹ = y ) 2 = 1 − P(h(X) = y) P(h(X) = y|Ỹ = y )</formula><p>Reverse-KL For Reverse-KL, we have f * (u) = −1 − log (−u), and g * (y, y ) = − log P(h(X) = y) P(h(X) = y|Ỹ = y)</p><p>Therefore</p><formula xml:id="formula_56">∆ y f (h, g) =P(h(X) = −y) · 1 − log FIT(h(X) = −y,Ỹ = y) − 1 FIT(h(X) = −y,Ỹ = y) + P(h(X) = y) · 1 − log FIT(h(X) = y,Ỹ = y) − 1 FIT(h(X) = y,Ỹ = y) Clearly t(x) = 1 − log x − 1</formula><p>x satisfies the requirement specified in Theorem 11.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B SUPPLEMENTARY EXPERIMENT RESULTS</head><p>In our experiment settings, D f measures fail to work well on almost all sparse high noise setting. This is largely due to the super unbalanced noisy labels, e.g., for each pair, the ratio of samples between the two classes is in the range of [         For sparse noise matrix, we randomly divide 100 classes into 50 disjoint pairs, the flipping probability (T ji , T ij ) in each pair is randomly chosen from (0.05, 0.75), (0.1, 0.70), (0.15, 0.65), (0.2, 0.6).</p><formula xml:id="formula_57">               0.7 0.3 0. 0. 0. 0. 0. 0. 0. 0. 0.2 0.8 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.7 0.3 0. 0. 0. 0. 0. 0. 0. 0. 0.2 0.8 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.7 0.3 0. 0. 0. 0. 0. 0. 0. 0. 0.2 0.8 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.7 0.3 0. 0. 0. 0. 0. 0. 0. 0. 0.2 0.8 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.7 0.3 0. 0. 0. 0. 0. 0. 0. 0. 0.2 0.8                Sparse-high noise matrix:               </formula><formula xml:id="formula_58">                              0.</formula><formula xml:id="formula_59">               0.7 0.3 0. 0. 0. 0. 0. 0. 0. 0. 0.1 0.9 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.7 0.3 0. 0. 0. 0. 0. 0. 0. 0. 0.1 0.9 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.7 0.3 0. 0. 0. 0. 0. 0. 0. 0. 0.1 0.9 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.7 0.3 0. 0. 0. 0. 0. 0. 0. 0. 0.1 0.9 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.7 0.3 0. 0. 0. 0. 0. 0. 0. 0. 0.1 0.9                Sparse-high noise matrix:               </formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.5 PARAMETER SETTINGS ON NOISED DATASET</head><p>MNIST, Fashion MNIST, CIFAR-10 For experiments on MNIST and Fashion-MNIST datasets, we use the convolutional neural network used in DMI for DMI, PL and f -divergences. All the experiments are performed with batch size 128. PL and f -divergences adopt two kinds of learning rate setting and trained for 80 epochs, either with initial learning rate 5e-4 or 1e-3, then decay 0.2, 0.5, 0.2 every 20 epochs. We choose the default learning rate setting for DMI, BLC and FLC. For DMI's convolutional neural network, Adam( Kingma &amp; Ba (2014)) with default parameters is used as the optimizer, while for loss-correction's fully-connected neural network case we use AdaGrad <ref type="bibr" target="#b4">( Duchi et al. (2010)</ref>) in order to be consistent with their works.</p><p>CIFAR-10 and CIFAR-100 For all methods and both datasets, we unify the model to be an 18layer PreAct Resnet <ref type="bibr" target="#b9">(He et al. (2016)</ref>) and train it using SGD with a momentum of 0.9, a weight decay of 0.0005, and a batch size of 128. All methods firstly train with CE warm-up for 120 (CIFAR-10) or 240 (CIFAR-100) epochs on CIFAR-10 and CIFAR-100 respectively. For DMI, BLC and FLC, we use the default learning rate settings. For PL and f-divergences, we train 100 epochs after the warm-up with initial learning rate 0.01, and decays 0.1 every 30 epochs.</p><p>Clothing 1M For clothing 1M, we use pre-trained ResNet50, SGD optimizer with momentum 0.9 and weight decay 1e-3. The initial learning rate is 0.002. All mentioned f -divergences trained 40 epochs, after 10 epochs, the learning rate becomes 5e-5. Then it decays 0.2, 0.5 consequently for every 5 epochs. We compare with reported best result for all our baseline methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.6 PARAMETER SETTINGS ON CLEAN DATASET</head><p>We adopt the same setting (except for the number of epochs and the learning rate setting) as used in the noised dataset for each dataset.</p><p>MNIST, Fashion MNIST For CE, we trained the model for 40 epochs. The initial learning rate is 5e-4, and it decays 0.2 after 20 epochs. For D f measures, the learning rate setting is the same as that in the noised dataset.</p><p>CIFAR-10 For CE, we trained the model for 300 epochs. Learning rate is 0.1 for first 150 epochs. From 150-th epoch to 250-th epoch, the learning rate is 0.01. Then, 0.001 till the end. For D f measures, we trained the model for 240 epochs. The initial learning rate is 0.1, and it decays 0.1 for every 60 epochs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CIFAR-100</head><p>For CE, we trained the model for 200 epochs. Learning rate is 0.1 for first 60 epochs. From 61-th epoch to 120-th epoch, the learning rate is 0.02 (save the model at 120-th epoch as a warm-up model for D f measures). From 121-th epoch to 160-th epoch, the learning rate is 0.004. Then, 0.0008 till the end. For D f measures, we load pre-trained CE model and trained for another 100 epochs. The initial learning rate is 0.01, and it decays 0.1 for every 30 epochs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.7 COMPUTING INFRASTRUCTURE</head><p>In our experiments, we use a GPU cluster (8 TITAN V GPUs and 16 GeForce GTX 1080 GPUs) for training and evaluation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Definition 2 .</head><label>2</label><figDesc>The fitness of h to R ∈ {Y,Ỹ } is defined as FIT(h = y, R = y ) := P(h(X)=y|R=y ) P(h(X)=y)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Robustness of TV, JS, PS divergences.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>P</head><label></label><figDesc>(h(X) = y, Y = y) − P(h(X) = y) · P(Y = y) and P(h(X) = y, Y = −y) − P(h(X) = y) · P(Y = −y) have opposite signs. This is simply because P(h(X) = y, Y = y)−P(h(X) = y)·P(Y = y)+P(h(X) = y, Y = −y)−P(h(X) = y)·P(Y = −y) = 0</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>y,y ∈Y |P(h(X) = y, Y = y ) − P(h(X) = y) · P(Y = y )| = y,y ∈Y |P(h(X) = y|Y = y ) − P(h(X) = y)| · P(Y = y ) = y|Y = y ) − P(h(X) = y)| For any classifier h and for each y, one of the following terms P(h(X) = y, Y = 1)−P(h(X) = y)·P(Y = 1), ...., P(h(X) = y, Y = K)−P(h(X) = y)·P(Y = K) must be non-negative as: y P(h(X) = y, Y = y ) − P(h(X) = y) · P(Y = y ) = 0.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>A. 9</head><label>9</label><figDesc>PROOF OF LEMMA 1: IMPACT OF BIAS TERM FOR DIFFERENT f -DIVERGENCES Denote p y = P(Y = y),p y := P(Ỹ = y),P (y, y ) Q(y, y ) := P(h(x)=y,Ỹ =y ) P(h(x)=y)·P(Ỹ =y ) . We first prove that P (y, y ) Q(y, y ) − 1 approaches to 0 as a function of 1 − e + − e − : Proposition 10. When e + , e − &lt; 0.5, P (y, y ) Q(y, y ) − 1 = O ((1 − e + − e − )) .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>Now focus on |P(Y = y |Ỹ = y ) − P(Y = y |Ỹ = −y )|: |P(Y = y |Ỹ = y ) − P(Y = y |Ỹ = −y )| = P(Ỹ = y |Y = y ) · p y P(Ỹ = y ) − P(Ỹ = −y |Y = y ) · p y P(Ỹ = −y )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>p y (1 − p y ) (p y P(h(X) = y|Y = y ) − (1 − p y )P(h(X) = y|Y = −y )) |1 − e + − e − | p y When e + , e − &lt; 0.5, we havẽ p y = p y (1 − e y ) + p −y e −y ≥ 0.5 min{p, 1 − p}.Thereforep y (1 − p y ) (p y P(h(X) = y|Y = y ) − (1 − p y )P(h(X) = y|Y = −y )) |1 − e + − e − |py ≤ 2 max{p, 1 − p}(p y P(h(X) = y|Y = y ) − (1 − p y )P(h(X) = y|Y = −y )) · |1 − e + − e − | Next, we prove Lemma 1: Proof. ShorthandP (y, y ) := P(h(x) = y,Ỹ = y ),Q(y, y ) := P(h(x) = y) · P(Ỹ = y ). Denote x := P(h(x)=y,Ỹ =y ) P(h(x)=y)·P(Ỹ =y ) − 1 =P (y,y ) Q(y,y ) − 1. Next we prove Bias f (h,g *</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>For Jenson-Shannon divergence, we have: g * (y, y ) − f * (g * (y, y )) =g * (y, y ) + log(2 − eg * (y,y ) ) = log 2P (y, y ) P (y, y ) +Q(y, y ) + log 2 − e log 2P (y,y ) P (y,y )+Q(y,y ) = log 2P (y, y ) P (y, y ) +Q(y, y ) + log 2Q(y, y ) P (y, y ) +Q(y, y )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>y, y ) − f * (g * (y, y )) =g * (y, y ) −g * (y, y ) 1 −g * (y, y ) =g * 2 (y , y) 1 −g * (y, y ) = P (h(x) = y,Ỹ = y ) Q(h(x) = y,Ỹ = y ) + Q (h(x) = y,Ỹ = y ) P (h(x) = y,Ỹ = y ) − 2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>{h ∈ H : max y FIT(h(X) = −y ,Ỹ = y ) ≤ min y FIT(h * f = −y, Y = y)}, we first prove H * − ⊆ H * . It is equivalent to prove, ∀h ∈ H * − , h ∈ H * : H * − = {h ∈ H : max y FIT(h(X) = −y ,Ỹ = y ) ≤ min y FIT(h * f = −y, Y = y)} ⊆ h ∈ H : max y P(h(X) = −y |Ỹ = y ) P(h(X) = −y )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>yP</head><label></label><figDesc>(h(X) = y) · t(FIT(h(X) = y,Ỹ = +1))+ e − · y P(h(X) = y) · t(FIT(h(X) = y,Ỹ = −1)) = max h∈H * [e + · P(Ỹ = +1) + e − · P(Ỹ = −1)] · ỹ P(h(X) =ỹ) · t(FIT(h(X) =ỹ,Ỹ =ỹ)) + [e + · P(Ỹ = −1) + e − · P(Ỹ = +1)] · ỹ P(h(X) =ỹ) · t(FIT(h(X) =ỹ,Ỹ = −ỹ)) ≤ max h∈H * e + + e − 2 · t(max y FIT(h(X) = y,Ỹ = y)) + t(min y FIT(h(X) = y,Ỹ = −y))</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>FIT 2 − 2 =</head><label>22</label><figDesc>For Jenson-Shannon, we have f * (u) = − log (2 − e u ), and g * (y, y ) = log 2 · P(h(X) = y,Ỹ = y )P(h(X) = y,Ỹ = y ) + Q(h(X) = y,Ỹ = y ) = log 2 · P(h(X) = y|Ỹ = y ) P(h(X) = y|Ỹ = y ) + P(h(X) = y)Therefore,∆ y f (h, g) =P(h(X) = −y) · log 4 · FIT(h(X) = −y,Ỹ = y) (1 + FIT(h(X) = −y,Ỹ = y)) 2 + P(h(X) = y) · log 4 · FIT(h(X) = y,Ỹ = y) (1 + FIT(h(X) = y,Ỹ = y)) 2 t(x) = log 4x (1 + x) 2satisfies the requirement specified in Theorem 11. Squared-Hellinger For Squared-Hellinger, we have f * (u) = u 1 − u , and g * (y, y ) = 1 − P(h(X) = y) P(h(X) = y|Ỹ = y) Therefore ∆ y f (h, g) =P(h(X) = −y) · 2 − FIT(h(X) = −y,Ỹ = y) − 1 FIT(h(X) = −y,Ỹ = y) + P(h(X) = y) · 2 − FIT(h(X) = y,Ỹ = y) − 1 (h,g * ) = E[g * (h(X), y) − f * (g * (h(X), y))] = E[g * (h(X), y) −g * (h(X), y) − 1 4 (g * (h(X), y)) 2 ] = − 1 4 E[(g * (h(X), y)) 2 ] Published as a conference paper at ICLR 2021 ∆ y f (h,g * ) = − P(h(X) = y) · P(h(X) = y,Ỹ = y) P(h(X) = y) · P(Ỹ = y) − 1 P(h(X) = −y) · P(h(X) = −y,Ỹ = y) P(h(X) = −y) · P(Ỹ = y) − 1 − P(h(X) = y) · (FIT(h(X) = y,Ỹ = y) − 1) 2 − P(h(X) = −y) · (FIT(h(X) = −y,Ỹ = y) − 1) 2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>2 1 2 2 =</head><label>12</label><figDesc>Thereforẽ g * (h(X) = y, y ) + 2 1 −g * (h(X) = y, y ) − 2 = − P(h(X) = y) P(h(X) = y|Ỹ = y ) − And further we have∆ y f (h,g * ) = − P(h(X) = y) · P(h(X) = y) P(h(X) = y|Ỹ = y) − 1 2 − P(h(X) = −y) · P(h(X) = −y) P(h(X) = −y|Ỹ = y) − 1 − P(h(X) = y) · (FIT(h(X) = y,Ỹ = y) −1 − 1) 2 − P(h(X) = −y) · (FIT(h(X) = −y,Ỹ = y) −1 − 1) 2 t(x) = −(x −1 − 1) 2satisfies the requirement specified in Theorem 11. KL For KL, we have f * (u) = e u−1 , and g * (y, y ) = 1 + log P(h(X) = y|Ỹ = y ) P(h(X) = y ) Therefore ∆ y f (h, g) =P(h(X) = −y) · [1 + log FIT(h(X) = −y,Ỹ = y) − FIT(h(X) = −y,Ỹ = y)] + P(h(X) = y) · [1 + log FIT(h(X) = y,Ỹ = y) − FIT(h(X) = y,Ỹ = y)]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>D f s, optimal variational g (g * ), conjugate functions (f * ). A more complete table, including Jeffrey, Squared Hellinger, Neyman X 2 , Reverse KL, is provided in the Appendix.</figDesc><table><row><cell>2.2 HOW GOOD IS h  *  f ?</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>outperform CE on clean dataset, we do observe that the gap between CE and D f measures are negligible, for example, the largest gap of Total-Variation (TV) is only 0.81% among four datasets.</figDesc><table><row><cell>Dataset</cell><cell>CE</cell><cell>TV</cell><cell>Gap</cell><cell>J-S</cell><cell>Gap</cell><cell>KL</cell><cell>Gap</cell></row><row><cell>MNIST</cell><cell>99.39(99.38±0.01)</cell><cell>99.37(99.34±0.02)</cell><cell>-0.04</cell><cell>99.35(99.31±0.04)</cell><cell>-0.07</cell><cell>99.31(99.21±0.06)</cell><cell>-0.17</cell></row><row><cell>Fashion MNIST</cell><cell>90.44(90.34±0.12)</cell><cell>89.98(89.94±0.06)</cell><cell>-0.40</cell><cell>90.40(90.17±0.24)</cell><cell>-0.17</cell><cell>90.19(89.96±0.14)</cell><cell>-0.38</cell></row><row><cell>CIFAR-10</cell><cell>93.58(93.47±0.08)</cell><cell>92.80(92.66±0.13)</cell><cell>-0.81</cell><cell>92.35(92.23±0.07)</cell><cell>-1.24</cell><cell>90.55(90.38±0.15)</cell><cell>-3.09</cell></row><row><cell>CIFAR-100</cell><cell>73.47(73.39±0.05)</cell><cell>73.43(73.39±0.06)</cell><cell>0.00</cell><cell>73.47(73.26±0.17)</cell><cell>-0.13</cell><cell>73.33(73.16±0.10)</cell><cell>-0.23</cell></row></table><note>demonstrate that optimizing f −divergence on clean dataset returns a high-quality h * f by referring to the performance of CE. Even though D f measures can't</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 4</head><label>4</label><figDesc>(full details on MNIST and Fashion MNIST can be found in Appendix), we use noise transition estimation method in(Patrini et al. (2017)) to estimate the noise rate. The estimates help us define the bias term and perform bias correction for D f measures. We observe that while adding bias correction can further improve the performance of several divergence functions (Gap being positive), the improvement or difference is not significant. This partially justified our analysis of the bias term, especially when the noise is dense and high (uniform and random high).</figDesc><table><row><cell>Dataset</cell><cell>Noise</cell><cell>CE</cell><cell>BLC</cell><cell>FLC</cell><cell>DMI</cell><cell>PL</cell><cell>TV</cell><cell>J-S</cell><cell>KL</cell></row><row><cell></cell><cell>Sparse, Low</cell><cell>97.21</cell><cell>95.23</cell><cell>97.37</cell><cell>97.76</cell><cell>98.59</cell><cell>99.23(99.11±0.08)</cell><cell>99.15(99.03±0.09)</cell><cell>99.21(99.15±0.05)</cell></row><row><cell></cell><cell>Sparse, High</cell><cell>48.55</cell><cell>55.86</cell><cell>49.67</cell><cell>49.61</cell><cell>60.27</cell><cell>58.27(54.72±4.36)</cell><cell>58.93(55.80±1.93)</cell><cell>49.24(49.17±0.06)</cell></row><row><cell>MNIST</cell><cell>Uniform, Low</cell><cell>97.14</cell><cell>94.27</cell><cell>95.51</cell><cell>97.72</cell><cell>99.06</cell><cell>99.23(99.17±0.05)</cell><cell>99.1(99.08±0.04)</cell><cell>99.13(99.06±0.07)</cell></row><row><cell></cell><cell>Uniform, High</cell><cell>93.25</cell><cell>85.92</cell><cell>87.75</cell><cell>95.50</cell><cell>97.77</cell><cell>98.09(97.96±0.13)</cell><cell>97.86(97.71±0.10)</cell><cell>98.14(97.88±0.18)</cell></row><row><cell></cell><cell>Random (0.2)</cell><cell>98.26</cell><cell>97.46</cell><cell>97.61</cell><cell>98.82</cell><cell>99.25</cell><cell>99.26(99.19±0.05)</cell><cell>99.29(99.27±0.02)</cell><cell>99.26(99.19±0.06)</cell></row><row><cell></cell><cell>Random (0.7)</cell><cell>97.00</cell><cell>93.52</cell><cell>87.74</cell><cell>95.47</cell><cell>98.52</cell><cell>98.81(98.73±0.06)</cell><cell>98.72(98.63±0.08)</cell><cell>98.76(98.65±0.10)</cell></row><row><cell></cell><cell>Sparse, Low</cell><cell>84.36</cell><cell>86.02</cell><cell>88.15</cell><cell>85.65</cell><cell>88.32</cell><cell>89.74(89.34±0.33)</cell><cell>88.80(88.79±0.01)</cell><cell>89.77(89.42±0.34)</cell></row><row><cell>Fashion MNIST</cell><cell>Sparse, High Uniform, Low Uniform, High</cell><cell>43.33 82.98 79.52</cell><cell>46.97 84.48 78.10</cell><cell>47.63 86.58 82.41</cell><cell>47.16 83.69 77.94</cell><cell>51.92 89.31 84.69</cell><cell>45.66(45.22±0.26) 89.00(88.75±0.16) 85.58(85.07±0.31)</cell><cell>47.46(46.39±0.70) 88.58(88.46±0.18) 85.62(85.39± 0.33)</cell><cell>38.96(38.90±0.06) 88.32(88.16±0.11) 85.69(85.43±0.30)</cell></row><row><cell></cell><cell>Random (0.2)</cell><cell>85.47</cell><cell>83.40</cell><cell>77.61</cell><cell>86.21</cell><cell>89.78</cell><cell>90.22(90.09±0.19)</cell><cell>89.73(89.43±0.24)</cell><cell>89.24(89.05±0.14)</cell></row><row><cell></cell><cell>Random (0.7)</cell><cell>82.05</cell><cell>78.41</cell><cell>73.42</cell><cell>80.89</cell><cell>87.22</cell><cell>86.69(86.49±0.16)</cell><cell>87.79(87.33±0.29)</cell><cell>87.06(87.00±0.06)</cell></row><row><cell></cell><cell>Sparse, Low</cell><cell>87.20</cell><cell>72.96</cell><cell>76.17</cell><cell>92.32</cell><cell>91.35</cell><cell>91.81(91.56±0.16)</cell><cell>91.49 (91.43±0.08)</cell><cell>91.62(91.32±0.31)</cell></row><row><cell></cell><cell>Sparse, High</cell><cell>61.81</cell><cell>56.30</cell><cell>66.12</cell><cell>27.94</cell><cell>69.70</cell><cell>63.96(62.25±1.00)</cell><cell>67.33(65.27±1.34)</cell><cell>46.55(46.43±0.08)</cell></row><row><cell>CIFAR-10</cell><cell>Uniform, Low</cell><cell>85.68</cell><cell>72.73</cell><cell>77.12</cell><cell>90.39</cell><cell>91.70</cell><cell>92.10(92.01±0.09)</cell><cell>91.52(91.47±0.08)</cell><cell>92.26(92.08±0.12)</cell></row><row><cell></cell><cell>Uniform, High</cell><cell>71.38</cell><cell>54.41</cell><cell>64.22</cell><cell>82.68</cell><cell>83.42</cell><cell>85.56(85.44±0.08)</cell><cell>84.49(84.35±0.13)</cell><cell>84.36(84.19±0.13)</cell></row><row><cell></cell><cell>Random (0.5)</cell><cell>78.40</cell><cell>59.31</cell><cell>68.97</cell><cell>85.06</cell><cell>86.47</cell><cell>87.28(87.03±0.17)</cell><cell>86.92 (86.80±0.10)</cell><cell>86.93(86.85±0.11)</cell></row><row><cell></cell><cell>Random (0.7)</cell><cell>68.26</cell><cell>38.59</cell><cell>54.39</cell><cell>77.91</cell><cell>57.81</cell><cell>80.59(80.45±0.10)</cell><cell>80.50(80.27±0.15)</cell><cell>78.93(78.59±0.30)</cell></row><row><cell></cell><cell>Uniform</cell><cell>63.87</cell><cell>51.40</cell><cell>60.04</cell><cell>64.39</cell><cell>67.94</cell><cell>69.15(68.90±0.17)</cell><cell>69.13(68.80±0.21)</cell><cell>68.79(68.60±0.11)</cell></row><row><cell></cell><cell>Sparse</cell><cell>40.45</cell><cell>36.57</cell><cell>43.39</cell><cell>40.53</cell><cell>44.25</cell><cell>42.45(38.06±2.82)</cell><cell>38.09(38.00±0.08)</cell><cell>37.74(37.63±0.08)</cell></row><row><cell>CIFAR-100</cell><cell>Random (0.2)</cell><cell>65.84</cell><cell>61.21</cell><cell>61.52</cell><cell>66.23</cell><cell>62.92</cell><cell>70.43(70.22±0.13)</cell><cell>70.40(70.12±0.21)</cell><cell>70.28(70.06±0.14)</cell></row><row><cell></cell><cell>Random (0.5)</cell><cell>56.92</cell><cell>22.21</cell><cell>55.88</cell><cell>56.06</cell><cell>49.62</cell><cell>62.14(61.89±0.18)</cell><cell>61.58(61.15±0.27)</cell><cell>61.68(61.49±0.13)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Experiment results comparison (w/o bias correction): The best performance in each setting is highlighted in blue. We report the maximum accuracy of each D f measures along with (mean ± standard deviation). All f -divergences will be highlighted if their mean performances are better (or no worse) than all baselines we compare to. A supplementary table including Pearson X 2 and Jeffrey (JF) is attached inTable 7(Appendix).</figDesc><table><row><cell>Noise</cell><cell>J-S</cell><cell>Gap</cell><cell>PS</cell><cell>Gap</cell><cell>KL</cell><cell>Gap</cell><cell>JF</cell><cell>Gap</cell></row><row><cell>Sparse, Low</cell><cell>91.23(90.93±0.34)</cell><cell>-0.26</cell><cell>91.48(91.12±0.42)</cell><cell>+0.08</cell><cell>91.73(91.57±0.18)</cell><cell>+0.11</cell><cell>91.45(91.18±0.21)</cell><cell>-0.10</cell></row><row><cell>Sparse, High</cell><cell>46.45(46.31±0.14)</cell><cell>-20.88</cell><cell>46.31(45.90±0.44)</cell><cell>-0.05</cell><cell>46.59(46.52±0.05)</cell><cell>+0.04</cell><cell>46.25(45.77±0.50)</cell><cell>+0.04</cell></row><row><cell>Uniform, Low</cell><cell>92.16(92.09±0.09)</cell><cell>+0.64</cell><cell>92.25(92.13±0.09)</cell><cell>-0.12</cell><cell>90.92(90.84±0.10)</cell><cell>-1.34</cell><cell>92.19(92.10±0.08)</cell><cell>+0.02</cell></row><row><cell>Uniform, High</cell><cell>84.31(84.13±0.10)</cell><cell>-0.18</cell><cell>83.79(83.61±0.12)</cell><cell>+0.18</cell><cell>83.98(83.79±0.12)</cell><cell>-0.38</cell><cell>83.93(83.62±0.22)</cell><cell>+0.13</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>D f measures with bias correction on CIFAR-10: Numbers highlighted in blue indicate better than all baseline methods; Gap: relative performance w.r.t. their version w/o bias correction(Table 3); those in red indicate better than w/o bias correction.Clothing1MClothing1M is a large-scale clothes dataset with comprehensive annotations and can be categorized as a feature-dependent human-level noise dataset. Although this noise setting does not exactly follow our assumption, we are interested in testing the robustness of our f -divergence approaches. Experiment results inTable 5demonstrate the robustness of the D f measures. TV and KL divergences have outperformed other baseline methods.</figDesc><table><row><cell>Dataset</cell><cell>Noise</cell><cell>CE</cell><cell>BLC</cell><cell>FLC</cell><cell>DMI</cell><cell>PL</cell><cell>T-V</cell><cell>J-S</cell><cell>Pear</cell><cell>KL</cell><cell>Jeffrey</cell></row><row><cell>Clothing1M</cell><cell>Human Noise</cell><cell>68.94</cell><cell>69.13</cell><cell>69.84</cell><cell>72.46</cell><cell>72.60</cell><cell>73.09</cell><cell>72.32</cell><cell>72.22</cell><cell>72.65</cell><cell>72.46</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>Experiment results comparison on Clothing1M dataset.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>Naresh Manwani and PS Sastry. Noise tolerance under risk minimization. IEEE transactions on cybernetics, 43(3):1146-1151, 2013. Aditya Menon, Brendan Van Rooyen, Cheng Soon Ong, and Bob Williamson. Learning from corrupted binary labels via class-probability estimation. In International Conference on Machine Learning, pp. 125-134, 2015. Nagarajan Natarajan, Inderjit S Dhillon, Pradeep K Ravikumar, and Ambuj Tewari. Learning with noisy labels. In Advances in neural information processing systems, pp. 1196-1204, 2013. Sebastian Nowozin, Botond Cseke, and Ryota Tomioka. f-gan: Training generative neural samplers using variational divergence minimization. In Advances in neural information processing systems, pp. 271-279, 2016. Giorgio Patrini, Alessandro Rozza, Aditya Krishna Menon, Richard Nock, and Lizhen Qu. Making deep neural networks robust to label noise: A loss correction approach. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1944-1952, 2017. June 2019. Zhilu Zhang and Mert R. Sabuncu. Generalized cross entropy loss for training deep neural networks with noisy labels, 2018. Zhaowei Zhu, Yiwen Song, and Yang Liu. Clusterability as an alternative to anchor points when learning with noisy labels. arXiv preprint arXiv:2102.05291, 2021.</figDesc><table /><note>Clayton Scott. A rate of convergence for mixture proportion estimation, with application to learning from noisy labels. In AISTATS, 2015. Clayton Scott, Gilles Blanchard, Gregory Handy, Sara Pozzi, and Marek Flaska. Classification with asymmetric label noise: Consistency and maximal denoising. In COLT, pp. 489-511, 2013. Sainbayar Sukhbaatar and Rob Fergus. Learning from noisy labels with deep neural networks. arXiv preprint arXiv:1406.2080, 2(3):4, 2014. Daiki Tanaka, Daiki Ikami, Toshihiko Yamasaki, and Kiyoharu Aizawa. Joint optimization frame- work for learning with noisy labels. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 5552-5560, 2018. Brendan Van Rooyen, Aditya Menon, and Robert C Williamson. Learning with symmetric label noise: The importance of being unhinged. In Advances in Neural Information Processing Systems, pp. 10-18, 2015. Han Xiao, Kashif Rasul, and Roland Vollgraf. Fashion-mnist: a novel image dataset for benchmark- ing machine learning algorithms, 2017. Tong Xiao, Tian Xia, Yi Yang, Chang Huang, and Xiaogang Wang. Learning from massive noisy labeled data for image classification. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2691-2699, 2015. Yilun Xu, Peng Cao, Yuqing Kong, and Yizhou Wang. L_dmi: An information-theoretic noise- robust loss function. NeurIPS, arXiv:1909.03388, 2019. Yu Yao, Tongliang Liu, Bo Han, Mingming Gong, Jiankang Deng, Gang Niu, and Masashi Sugiyama. Dual t: Reducing estimation error for transition matrix in label-noise learning. arXiv preprint arXiv:2006.07805, 2020. Kun Yi and Jianxin Wu. Probabilistic end-to-end noise correction for learning with noisy labels. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR),</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table /><note>Exemplary output activation functions g f (used for approximating g, see e.g. (Nowozin et al., 2016)), optimal activation functions, optimal conjugate functions (full table). W is the Lambert−W product log function. ' ' indicates that the f −divergence function (in practice) is robust to label noise and '' means non-robust.A.3 MAIN RESULTS: PROOF OF THEOREM 4</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 7</head><label>7</label><figDesc>, the performance of Pearson X 2 , Jeffrey divergence on MNIST, Fashion MNIST, CIFAR-10 and CIFAR-100 are included inTable 7.</figDesc><table><row><cell>Dataset</cell><cell>Noise</cell><cell>CE</cell><cell>BLC</cell><cell>FLC</cell><cell>DMI</cell><cell>PL</cell><cell>Pearson</cell><cell>Jeffrey</cell></row><row><cell></cell><cell>Sparse, Low</cell><cell>97.21</cell><cell>95.23</cell><cell>97.37</cell><cell>97.76</cell><cell>98.59</cell><cell>99.24(99.07±0.16)</cell><cell>99.24(99.11±0.08)</cell></row><row><cell></cell><cell>Sparse, High</cell><cell>48.55</cell><cell>55.86</cell><cell>49.67</cell><cell>49.61</cell><cell>60.27</cell><cell>58.63(58.58±0.05)</cell><cell>49.21(49.17±0.04)</cell></row><row><cell>MNIST</cell><cell>Uniform, Low</cell><cell>97.14</cell><cell>94.27</cell><cell>95.51</cell><cell>97.72</cell><cell>99.06</cell><cell>99.13(99.03±0.09)</cell><cell>99.14(99.06±0.05)</cell></row><row><cell></cell><cell>Uniform, High</cell><cell>93.25</cell><cell>85.92</cell><cell>87.75</cell><cell>95.50</cell><cell>97.77</cell><cell>97.89(97.76±0.10)</cell><cell>97.94(97.80±0.12)</cell></row><row><cell></cell><cell>Random (0.2)</cell><cell>98.26</cell><cell>97.46</cell><cell>97.61</cell><cell>98.82</cell><cell>99.25</cell><cell>99.28(99.27±0.02)</cell><cell>99.29(99.22±0.11)</cell></row><row><cell></cell><cell>Random (0.7)</cell><cell>97.00</cell><cell>93.52</cell><cell>87.74</cell><cell>95.47</cell><cell>98.52</cell><cell>98.70(98.54±0.10)</cell><cell>98.67(98.53±0.15)</cell></row><row><cell></cell><cell>Sparse, Low</cell><cell>84.36</cell><cell>86.02</cell><cell>88.15</cell><cell>85.65</cell><cell>88.32</cell><cell>88.93(88.81±0.11)</cell><cell>88.96(88.68±0.21)</cell></row><row><cell>Fashion MNIST</cell><cell>Sparse, High Uniform, Low Uniform, High</cell><cell>43.33 82.98 79.52</cell><cell>46.97 84.48 78.10</cell><cell>47.63 86.58 82.41</cell><cell>47.16 83.69 77.94</cell><cell>51.92 89.31 84.69</cell><cell>44.62(44.36±0.21) 87.27(87.15±0.09) 85.30(85.26±0.06)</cell><cell>45.57(45.26± 0.28) 88.13(87.85±0.18) 84.92(84.63±0.26)</cell></row><row><cell></cell><cell>Random (0.2)</cell><cell>85.47</cell><cell>83.40</cell><cell>77.61</cell><cell>86.21</cell><cell>89.78</cell><cell>89.65(89.44±0.21)</cell><cell>89.74(89.33+0.29)</cell></row><row><cell></cell><cell>Random (0.7)</cell><cell>82.05</cell><cell>78.41</cell><cell>73.42</cell><cell>80.89</cell><cell>87.22</cell><cell>86.72(86.29±0.32)</cell><cell>87.21(87.19±0.04)</cell></row><row><cell></cell><cell>Sparse, Low</cell><cell>87.20</cell><cell>72.96</cell><cell>76.17</cell><cell>92.32</cell><cell>91.35</cell><cell>91.40(91.24±0.27)</cell><cell>91.55(91.24±0.15)</cell></row><row><cell></cell><cell>Sparse, High</cell><cell>61.81</cell><cell>56.30</cell><cell>66.12</cell><cell>27.94</cell><cell>69.70</cell><cell>46.36(46.27±0.07)</cell><cell>46.21(45.78±0.27)</cell></row><row><cell>CIFAR-10</cell><cell>Uniform, Low</cell><cell>85.68</cell><cell>72.73</cell><cell>77.12</cell><cell>90.39</cell><cell>91.70</cell><cell>92.37(92.27±0.07)</cell><cell>92.17(92.02±0.08)</cell></row><row><cell></cell><cell>Uniform, High</cell><cell>71.38</cell><cell>54.41</cell><cell>64.22</cell><cell>82.68</cell><cell>83.42</cell><cell>83.61(83.09±0.38)</cell><cell>83.80(83.73±0.05)</cell></row><row><cell></cell><cell>Random (0.5)</cell><cell>78.40</cell><cell>59.31</cell><cell>68.97</cell><cell>85.06</cell><cell>86.47</cell><cell>86.03(85.56±0.32)</cell><cell>86.04(85.75±0.19)</cell></row><row><cell></cell><cell>Random (0.7)</cell><cell>68.26</cell><cell>38.59</cell><cell>54.39</cell><cell>77.91</cell><cell>57.81</cell><cell>76.92 (76.82±0.07)</cell><cell>79.46(79.08±0.25)</cell></row><row><cell></cell><cell>Uniform</cell><cell>63.87</cell><cell>51.40</cell><cell>60.04</cell><cell>64.39</cell><cell>67.94</cell><cell>68.42(68.16±0.16)</cell><cell>68.86(68.63±0.18)</cell></row><row><cell></cell><cell>Sparse</cell><cell>40.45</cell><cell>36.57</cell><cell>43.39</cell><cell>40.53</cell><cell>44.25</cell><cell>37.54(37.50±0.07)</cell><cell>37.43(37.06±0.25)</cell></row><row><cell>CIFAR-100</cell><cell>Random (0.2)</cell><cell>65.84</cell><cell>61.21</cell><cell>61.52</cell><cell>66.23</cell><cell>62.92</cell><cell>69.90(69.72±0.15)</cell><cell>69.56(69.42±0.14)</cell></row><row><cell></cell><cell>Random (0.5)</cell><cell>56.92</cell><cell>22.21</cell><cell>55.88</cell><cell>56.06</cell><cell>49.62</cell><cell>60.81(60.36±0.26)</cell><cell>60.95(60.73±0.15)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 7 :</head><label>7</label><figDesc>Experiment results comparison (w/o bias correction): The best performance in each setting (row) is highlighted in blue. All f -divergences will be highlighted if they are better than the baselines we compare to. We report the maximum accuracy of each D f measures along with (mean ± standard deviation).B.2 D f MEASURES WITH BIAS CORRECTION ON MNISTInTable 8, we test the impact of bias correction on MNIST with 4 noise settings. Except for the spare high noise setting which is a huge challenge for all implemented methods, experiment results of other 3 noise settings further demonstrate the negligible effect of bias term in the optimization of D f measures.</figDesc><table><row><cell>Noise</cell><cell>J-S</cell><cell>Gap</cell><cell>PS</cell><cell>Gap</cell><cell>KL</cell><cell>Gap</cell><cell>Jeffrey</cell><cell>Gap</cell></row><row><cell>Sparse, Low</cell><cell>98.88(98.82±0.06)</cell><cell>-0.27</cell><cell>99.05(98.98±0.05)</cell><cell>-0.19</cell><cell>99.29(99.19±0.09)</cell><cell>+0.08</cell><cell>99.13(99.06±0.06)</cell><cell>-0.11</cell></row><row><cell>Sparse, High</cell><cell>21.39(21.36±0.03)</cell><cell>-37.54</cell><cell>49.22(49.17±0.05)</cell><cell>-9.41</cell><cell>49.07(49.05±0.02)</cell><cell>-0.07</cell><cell>49.14(49.06±0.09)</cell><cell>-0.07</cell></row><row><cell>Uniform, Low</cell><cell>99.18(99.10±0.05)</cell><cell>+0.05</cell><cell>99.13(99.01±0.10)</cell><cell>+0.00</cell><cell>99.30(99.24±0.08)</cell><cell>+0.20</cell><cell>99.20(99.12±0.09)</cell><cell>+0.06</cell></row><row><cell>Uniform, High</cell><cell>97.76(97.68±0.07)</cell><cell>-0.10</cell><cell>97.72(97.65±0.06)</cell><cell>-0.17</cell><cell>97.91(97.74±0.14)</cell><cell>-0.23</cell><cell>98.16(97.98±0.14)</cell><cell>+0.22</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 8 :</head><label>8</label><figDesc>D f measures with bias correction on MNIST: Digits highlighted in blue means better than baseline methods, in red means better than without bias correction. PS: Pearson. B.3 D f MEASURES WITH BIAS CORRECTION ON FASHION MNIST InTable 9, we test the impact of bias correction on Fashion MNIST with 4 noise settings. We can reach the same conclusion on bias correction as MNIST.</figDesc><table><row><cell>Noise</cell><cell>J-S</cell><cell>Gap</cell><cell>PS</cell><cell>Gap</cell><cell>KL</cell><cell>Gap</cell><cell>Jeffrey</cell><cell>Gap</cell></row><row><cell>Sparse, Low</cell><cell>89.37(88.83±0.34)</cell><cell>+0.57</cell><cell>87.99(87.90±0.13)</cell><cell>-0.94</cell><cell>82.29(82.03±0.22)</cell><cell>-7.48</cell><cell>82.04(81.65±0.26)</cell><cell>-6.92</cell></row><row><cell>Sparse, High</cell><cell></cell><cell></cell><cell>39.02(38.85±0.10)</cell><cell>-5.60</cell><cell>46.98(46.23±0.62)</cell><cell>+8.02</cell><cell>38.94(38.75±0.15)</cell><cell>-6.63</cell></row><row><cell>Uniform, Low</cell><cell>88.98(88.61±0.26)</cell><cell>+0.40</cell><cell>87.72(87.66±0.06)</cell><cell>+0.45</cell><cell>89.04(88.78±0.18)</cell><cell>+0.72</cell><cell>89.05(88.87±0.15)</cell><cell>+0.92</cell></row><row><cell>Uniform, High</cell><cell>85.56(85.33± 0.19)</cell><cell>-0.06</cell><cell>85.57(85.03±0.37)</cell><cell>+0.27</cell><cell>85.15(84.94±0.15)</cell><cell>-0.54</cell><cell>84.76(84.48±0.31)</cell><cell>-0.16</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 9 :</head><label>9</label><figDesc>D f measures with bias correction on Fashion MNIST: Digits highlighted in blue means better than baseline methods, in red means better than without bias correction. ×: experiment failed to stablize. PS: Pearson. NOISE TRANSITION MATRIX FOR SECTION 5.2: ROBUSTNESS OF D f MEASURESWe use CIFAR-10 dataset together with the uniform noise transition matrix to flip the noisy labels. In the following noise transition matrix, e is in [0.00, 0.01, 0.02, ..., 0.09] and the noise rate of each set of noisy labels is 9 * e.</figDesc><table><row><cell>C EXPERIMENT DETAILS</cell></row><row><cell>C.1 </cell></row><row><cell>             </cell></row><row><cell>C.2 NOISE TRANSITION MATRIX FOR MNIST AND FASHION MNIST DATASET</cell></row><row><cell>Sparse-low noise matrix:</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">We use Z instead of X as conventionally done for a good reason -we will be reserving X to explicitly denote the features.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>K j=1 e j · E X [g(h(X),Ỹ = j)] − E X f * (g(h(X),Ỹ = j)) = 0.</p><p>Similar argument holds for sparse noise too.</p><p>A.11 WHEN f -DIVERGENCE MEASURE IS H * -ROBUST?</p><p>Theorem 11. For binary classification, suppose ∆ y f (h, g) has the following form:</p><p>is monotonically decreasing as a function of |x − 1| on both sides of [1, ∞] and (−∞, 1), then Bias f (h * f , g * ) ≥ max h∈H * Bias f (h,g * ). Further, according to Theorem 6, the corresponding f -divergence measure is H * -robust.</p><p>Proof. For binary case, when P(Y = +1) = P(Y = −1) and e + = e − , we have P(Ỹ = +1) = P(Ỹ = −1). </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Robust bi-tempered logistic loss based on bregman divergences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehsan</forename><surname>Amid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">K</forename><surname>Manfred</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rohan</forename><surname>Warmuth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomer</forename><surname>Anil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Koren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="14987" to="14996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Unsupervised label noise modeling and loss correction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Arazo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diego</forename><surname>Ortego</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Albert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noel</forename><forename type="middle">E</forename><surname>O&amp;apos;connor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Mcguinness</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.11238</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">On symmetric losses for learning from corrupted labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nontawat</forename><surname>Charoenphakdee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jongyeong</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masashi</forename><surname>Sugiyama</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.09314</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Learning with instancedependent label noise: A sample sieve approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaowei</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifei</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.02347</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Adaptive subgradient methods for online learning and stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elad</forename><surname>Hazan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoram</forename><surname>Singer</surname></persName>
		</author>
		<idno>15324435</idno>
	</analytic>
	<monogr>
		<title level="m">COLT 2010 -The 23rd Conference on Learning Theory</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="257" to="269" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Making risk minimization tolerant to label noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aritra</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naresh</forename><surname>Manwani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">S</forename><surname>Sastry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">160</biblScope>
			<biblScope unit="page" from="93" to="107" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Robust loss functions under label noise for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aritra</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Himanshu</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">S</forename><surname>Sastry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-First AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Co-teaching: Robust training of deep neural networks with extremely noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quanming</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingrui</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weihua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivor</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masashi</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8527" to="8537" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Mixture proportion estimation via kernel embeddings of distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramaswamy</forename><surname>Harish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clayton</forename><surname>Scott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ambuj</forename><surname>Tewari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2052" to="2060" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Identity mappings in deep residual networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="630" to="645" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Deep bilevel learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Jenni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Favaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="618" to="633" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Nlnl: Negative learning for noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youngdong</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junho</forename><surname>Yim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juseung</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junmo</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="101" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<idno>abs/1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>Citeseer</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Classification with noisy labels by importance reweighting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tongliang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dacheng</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="447" to="461" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Peer loss functions: Learning from noisy labels without knowing noise rates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyi</forename><surname>Guo</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">On the minimal supervision for training any binary classifier from only unlabeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><forename type="middle">K</forename><surname>Menon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masashi</forename><surname>Sugiyama</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.10585</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Lukasik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srinadh</forename><surname>Bhojanapalli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><forename type="middle">Krishna</forename><surname>Menon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjiv</forename><surname>Kumar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.02819</idno>
		<title level="m">Does label smoothing mitigate label noise</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
