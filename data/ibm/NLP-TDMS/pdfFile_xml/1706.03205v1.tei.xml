<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Item Silk Road: Recommending Items from Information Domains to Social Users</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>August 7-11, 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Wang</surname></persName>
							<email>xiangwang@u.nus.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangnan</forename><surname>He</surname></persName>
							<email>xiangnanhe@gmail.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liqiang</forename><surname>Nie</surname></persName>
							<email>nieliqiang@gmail.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">National University of Singapore</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">National University of Singapore</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">ShanDong University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">National University of Singapore</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Item Silk Road: Recommending Items from Information Domains to Social Users</title>
					</analytic>
					<monogr>
						<title level="m">SIGIR 17</title>
						<meeting> <address><addrLine>Shinjuku, Tokyo, Japan</addrLine></address>
						</meeting>
						<imprint>
							<date type="published">August 7-11, 2017</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3077136.3080771</idno>
					<note>Cross-domain Recommendation, Deep Collaborative Filtering, Neural Network, Deep Learning * Xiangnan He is the corresponding author. 978-1-4503-5022-8/17/08. . . $15.00 DOI: h p://dx.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T16:49+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>CCS CONCEPTS •Information systems → Social recommendation</term>
					<term>Retrieval models and ranking</term>
					<term>Recommender systems</term>
					<term>KEYWORDS</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Online platforms can be divided into information-oriented and social-oriented domains. e former refers to forums or Ecommerce sites that emphasize user-item interactions, like Trip.com and Amazon; whereas the la er refers to social networking services (SNSs) that have rich user-user connections, such as Facebook and Twi er. Despite their heterogeneity, these two domains can be bridged by a few overlapping users, dubbed as bridge users. In this work, we address the problem of cross-domain social recommendation, i.e., recommending relevant items of information domains to potential users of social networks. To our knowledge, this is a new problem that has rarely been studied before.</p><p>Existing cross-domain recommender systems are unsuitable for this task since they have either focused on homogeneous information domains or assumed that users are fully overlapped. Towards this end, we present a novel Neural Social Collaborative Ranking (NSCR) approach, which seamlessly sews up the user-item interactions in information domains and user-user connections in SNSs. In the information domain part, the a ributes of users and items are leveraged to strengthen the embedding learning of users and items. In the SNS part, the embeddings of bridge users are propagated to learn the embeddings of other non-bridge users. Extensive experiments on two real-world datasets demonstrate the e ectiveness and rationality of our NSCR method.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Nowadays online platforms play a pivotal role in our daily life and encourage people to share experiences, exchange thoughts, and enjoy online services. Regardless of applications, we can roughly divide the existing platforms into information-oriented and social-oriented domains. e former typically refers to forums or E-Commerce sites that have thorough knowledge on items, such as point-of-interests in Trip.com, movies in IMDb, and products in Amazon. ese sites have ample user-item interactions available in the form of users' reviews, ratings, along with various kinds of implicit feedback like views and clicks <ref type="bibr" target="#b0">[1]</ref>. On the other hand, the social-oriented domains are mainly social network sites, which emphasize the social connections among users <ref type="bibr" target="#b14">[15]</ref>.</p><p>When adopting an item, besides consulting the information sites, a user usually gathers more detailed information from her experienced friends. is refers to word-of-mouth marketing, which is widely recognized as the most e ective strategy for producing recommendation. As reported by Cognizant 1 , more than 45% of travelers rely on social networks to seek advice from friends for travel. However, most existing SNSs, like Facebook and Twi er, are designed mainly for users to rebuild their real-world connections, rather than for seeking options regarding items. ough some item cues implying users' preference can be found in SNSs, they typically contain item names only with limited details. e sparse and weak user-item interactions greatly hinder the ability of SNSs to o er item recommendation services.</p><p>Fortunately, some users may be simultaneously involved in both SNSs and information-domain sites, who can act as a bridge to propagate user-item interactions across domains. For example, it is not unusual for a user to share her travel experiences in Trip.com; and if the user also holds a Facebook account, we can recommend her friends in Facebook with her liked items from Trip.com. In social circles, these bridge users are like the silk road to route relevant items from information domains to (non-bridge) users of social networks. As such, we formulate the task of cross-domain social recommendation, which aims to recommend relevant items of information domains to the users of social domains. Apparently, this task is related to the recently emerging topic -cross-domain recommendation <ref type="bibr" target="#b12">[13]</ref>. However, we argue that existing e orts have either focused on homogeneous domains (i.e., multiple sites of the information domain) <ref type="bibr" target="#b4">[5]</ref>, or unrealistically assumed that the users are fully overlapped <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b29">30]</ref>. Our task to address is particularly challenging due to the following two practical considerations.</p><p>• Insu cient bridge users. To gain a deep insight, we analyzed the overlapped users between Trip.com and Facebook/Twi er, nding that only 10.5% of <ref type="bibr" target="#b7">8,</ref><ref type="bibr">196</ref> Facebook users and 6.9% of 7, 233 Twi er users have public accounts in Trip.com. It is highly challenging to leverage history of such limited number of bridge users to provide quality recommendation for non-bridge users.</p><p>• Rich a ributes. e users and items of an information domain are usually associated with rich a ributes. For instance, Trip.com enables users to indicate their travel preference explicitly, and associates travel spots (i.e., items) with speci c travel modes, among other information. However, li le a ention has been paid to leverage these a ributes to boost the performance of cross-domain recommendation. In this work, we propose a novel solution named Neural Social Collaborative Ranking (NSCR) for the new task of cross-domain social recommendation. It is developed based on the recent advance of neural collaborative ltering (NCF) <ref type="bibr" target="#b10">[11]</ref>, which is further extended to model the cross-domain social relations by combining with the graph regularization technique <ref type="bibr" target="#b8">[9]</ref>. We entail two key technical components of our NSCR as follows.</p><p>• For the modelling of information domain, we build an a ributeaware recommender based on the NCF framework. To fully exploit the interactions among a user, an item, and their a ributes, we enhance NCF by plugging a pairwise pooling operation above the embedding vectors of user (item) ID and a ributes. In contrast to the default average pooling used by NCF <ref type="bibr" target="#b10">[11]</ref> and other recent neural recommenders <ref type="bibr" target="#b3">[4]</ref>, our use of pairwise pooling be er captures feature interactions in the low level <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b20">21]</ref>, greatly facilitating the following deep layers to learn higher-order interactions among users, items and a ributes. • For the modelling of social domain, it is natural to guide the embedding learning of social users by using the embeddings of bridge users. As the embeddings of bridge users are optimized to predict user-item interactions (e.g., ratings and purchases), propagating their embeddings to social users helps to bridge the heterogeneity gap between information domain and social domain. To implement such propagation e ect, we employ the smoothness constraint (i.e., graph Laplacian) on the social network, which enforces close friends to have similar embedding so as to re ect their similar preferences.</p><p>To sum up, the key contributions of this work are three-fold:</p><p>(1) To our knowledge, we are the rst to introduce the task of crossdomain social recommendation, which recommends relevant items of information domains to target users of social domains. (2) We propose a novel solution that uni es the strengths of deep neural networks in modelling a ributed user-item interactions and graph Laplacian in modelling user-user social relations. (3) We construct two real-world benchmark datasets for exploring the new task of cross-domain social recommendation and extensively evaluate our proposed solution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PRELIMINARY</head><p>We rst formulate the task of cross-domain social recommendation, and then shortly recapitulate the matrix factorization model, highlighting its limitations for addressing the task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 1:</head><p>Illustration of the cross-domain social recommendation task. <ref type="figure">Figure 1</ref> illustrates the task of cross-domain social recommendation. In the information domain, we have the interaction data between users and items. Let u and U 1 = {u t } M 1 t =1 denote a user and the whole user set of the information domain, respectively; similarly, we use i and I = {i t } N t =1 to denote an item and the whole item set, respectively. e edges between users and items denote their interactions, Y = { ui }, which can be real-valued explicit ratings or binary 0/1 implicit feedback. Traditional collaborative ltering algorithms can then be performed on the user-item interaction data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Problem Formulation</head><p>In addition to the ID that distinguishes a user or an item, most information-domain sites also associate them with abundant side information, which can help to capture users' preferences and item properties be er. For example, in Trip.com, the user may choose the travel tastes of {luxury travel, art lover} in her pro le; while, the item Marina Bay Sands is tagged most with travel modes {luxury travel, family travel, nightlife}. We term these associated information as a ributes, most of which are discrete categorical variables for the web domain <ref type="bibr" target="#b9">[10]</ref>. Formally, we denote and G = { t } V t =1 as an a ribute and the whole a ribute set, respectively; for a user u and an item i, we can then construct the associated a ribute set as</p><formula xml:id="formula_0">G u = { u 1 , · · · , u V u } ⊂ G and G i = { i 1 , · · · , i V i } ⊂ G, respectively.</formula><p>In the social domain, we have social connections between users, such as the undirected friendship or directed follower/followee relations. We denote a social user as u , all users of the social domain as U 2 = {u t } M 2 t =1 , and all social connections as S = {s u u }. We de ne the bridge users as the overlapping users between the information domain and social domain. ese bridge users can be expressed as U = U 1 ∩ U 2 . In a social network, a user's behaviours and preferences can be propagated along the social connections to in uence her friends. As such, these bridge users play a pivotal role in addressing the cross-domain social recommendation problem, which is formally de ned as:</p><p>Input: An information domain with {U 1 , I, Y, G u , G i }; a social domain with {U 2 , S}; and U 1 ∩ U 2 is nonempty. Output: A personalized ranking function for each user u of the social domain f u : I → R, which maps each item of the information domain to a real number.</p><p>It is noted that there indeed exist sparse and weak user-item interactions in SNSs as aforementioned. However, we simplify this scenario of cross-domain social recommendation by only </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Factorization Model</head><p>Collaborative ltering (CF) is the key technique for personalized recommendation systems. It exploits user-item interactions by assuming that similar users would have similar preference on items.</p><p>Model-based CF approaches <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b32">33]</ref> achieve this goal by describing the interaction data with an underlying model, for which the holistic goal is to build:</p><formula xml:id="formula_1">ui = f Θ (u, i),<label>(1)</label></formula><p>where f denotes the underlying model with parameters Θ, and ui denotes the predicted score for a user-item interaction ui . Matrix factorization (MF) is one of the simplest yet e ective models for the recommendation task, which characterizes a user or an item with a latent vector, modelling a user-item interaction as the inner product of their latent vectors:</p><formula xml:id="formula_2">f M F (u, i |p u , q i ) = p u q i = K k =1 p uk q ik ,<label>(2)</label></formula><p>where p u ∈ R K and q i ∈ R K are model parameters denoting the latent vector (aka. representation) for user u and item i, respectively. Despite its e ectiveness, we note that MF's expressiveness can be limited by the use of the inner product operation to model a user-item interaction. To illustrate this, we present a neural network view of the MF model. As shown in <ref type="figure" target="#fig_0">Figure 2</ref>, we feed the one-hot representation of user/item ID into the architecture, and project them with a fully connected embedding layer. By feeding the user/item embedding vectors into the element-wise product layer, we obtain a hidden vector h = {p uk q ik }. If we directly project h into the output score, we can exactly recover the MF model. As such, MF can be deemed as a shallow neural network with one hidden layer only. Based on this connection, we argue that there are two key limitations of MF-based approaches for cross-domain social recommendation:</p><p>• First, MF only considers the simple two-way interaction between a user and an item, by assuming that their cross latent factors (i.e., p u and q i ) are independent of each other. However, such an independence assumption can be insu cient to model real-world data, which usually have complex and non-linear underlying structures <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b14">15]</ref>.</p><p>• e case can be even worse if we take the a ributes into account. A typical way to extend MF with side a ributes is SVDfeature, i.e., by summing a ribute embedding vectors with user/item embedding vector. As a result, the rich correlations among users, items, and a ributes are unintentionally ignored.</p><p>Our proposed NSCR solution addresses the above limitations of MF by 1) using a deep learning scheme to capture the higher-order correlations between user and item latent factors, and 2) devising a pairwise pooling operation to e ciently model the pair-wise correlations among users, items, and a ributes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">OUR NSCR SOLUTION</head><p>e goal of cross-domain social recommendation is to select relevant items from the information domain for social users. Under the paradigm of embedding-based methods (aka. representation learning), the key for addressing the task is on how to project items (of the information domain) and users (of the social domain) into the same embedding space. A generic solution is the factorization machine (FM) <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b20">21]</ref>, which merges the data from the two domains by an early fusion; that is, constructing the predictive model by incorporating social users as the input features. While the solution sounds reasonable conceptually, the problem is that the training instances which can incorporate social users are only applicable to the bridge users, which can be very few for real-world applications. As such, the generic recommender solution FM can su er severely from the problem of insu cient bridge users.</p><p>To address the challenge of insu cient bridge users, we propose a new framework that separates the embedding learning process of each domain. By enforcing the two learning processes to share the same embeddings for bridge users, we can ensure that items and social users are in the same embedding space. Formally, we devise the optimization framework as:</p><formula xml:id="formula_3">L = L I (Θ I ) + L S (Θ S ),<label>(3)</label></formula><p>where L I (or L S ) denotes the objective function of the information domain (or social domain) learning with parameters Θ I (or Θ S ), and most importantly, Θ I ∩ Θ S are nonempty denoting the shared embeddings of bridge users. By separating the learning process for two domains, we allow the design of each component to be more exible. Specially, we can apply any collaborative ltering solution for L I to learn from user-item interactions, and utilize any semi-supervised learning technique for L S to propagate the embeddings of bridge users to non-bridge users. In the remainder of this section, we rst present our novel neural collaborative ranking solution for L I , followed by the design of social learning component L S . Lastly, we discuss how to optimize the joint objective function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Learning of Information Domain</head><p>To estimate the parameters for a CF model from user-item interaction data, two types of objective functions -point-wise <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b10">11]</ref> and pair-wise <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b25">26]</ref> -are most commonly used. e pointwise objective functions aim to minimize the loss between the predicted score and its target value. Here, to tailor our solution for both implicit feedback and the personalized ranking task, we adopt the pair-wise ranking objective functions. Formally, we denote an observed user-item interaction as ui = 1, otherwise ui = 0. Instead of forcing the prediction scoreˆ ui to be close to ui , ranking-ware objective functions concern the relative order between the pairs of observed and unobserved interactions:</p><formula xml:id="formula_4">L I = (u,i, j)∈ O L( ui j ,ˆ ui j ),<label>(4)</label></formula><p>where ui j = ui − u j andˆ ui j =ˆ ui −ˆ u j ; O denotes the set of training triplets, each of which comprises of a user u, an item i of observed interactions (i.e., ui = 1), and an item j of unobserved interactions (i.e., ui = 0). An ideal model should rank all (i, j) item pairs correctly for every user. To implement the ranking hypotheses, we adopt the regression-based loss <ref type="bibr" target="#b25">[26]</ref>:</p><formula xml:id="formula_5">L I = (u,i, j)∈ O ( ui j −ˆ ui j ) 2 = (u,i, j)∈ O (ˆ ui −ˆ u j − 1) 2 . (5)</formula><p>Note that other pair-wise ranking functions can also be applied, such as the bayesian personalized ranking (BPR) <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b20">21]</ref> and contrastive max-margin loss <ref type="bibr" target="#b22">[23]</ref>. In this work, we use the regression-based ranking loss as a demonstration for our NSCR, and leave the exploration of other choices as the future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">A ribute-aware Deep CF Model.</head><p>Having established the optimization function for learning from information domain, we now present our a ribute-aware deep collaborative ltering model to estimate a user-item interactionˆ ui . <ref type="figure" target="#fig_1">Figure 3</ref> illustrates its architecture, which is a multi-layered feed-forward neural network. We elaborate its design layer by layer.</p><p>Input Layer. e input to the model is a user u, an item i, and their associated a ributes G u and G i . We transform them into barbarized sparse vectors with one-hot encoding, where only the non-zero binary features are recorded.</p><p>Embedding Layer. e embedding layer maps each non-zero feature into a dense vector representation. As we have four types of features here, we di erentiate them with di erent symbols: u, i, g u t , and g i t denote the K-dimensional embedding vector for user u, item i, user a ribute u t , and item a ribute i t , respectively. Pooling Layer. e output of the embedding layer is a set of embedding vectors to describe user u and item i, respectively. As di erent users (items) may have di erent number of a ributes, the size of the embedding vector set may vary for di erent inputs. To train a neural network of xed structure, it is essential to convert the set of variable-length vectors to a xed-length vector, i.e., the pooling operation. e most commonly used pooling operations in neural network modelling are average pooling and max pooling. However, we argue that such simple operations are insu cient to capture the interaction between users/items and a ributes. For example, the average pooling assumes a user and her a ributes are linearly independent, which fails to encode any correlation between them in the embedding space. To tackle the problem, we consider to model the pairwise correlation between a user and her a ributes, and all nested correlations among her a ributes: where denotes the element-wise product of two vectors. We term it as pairwise pooling, which is originally inspired from the design of factorization machines <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b18">19]</ref>. By applying pairwise pooling on the item counterpart, we can similarly model the pair-wise correlation between an item and its a ributes:</p><formula xml:id="formula_6">p u = φ pair wise (u, {g u t }) = V u t =1 u g u t + V u t =1 V u t =t +1 g u t g u t ,<label>(6)</label></formula><formula xml:id="formula_7">q i = φ pair wise (i, {g i t }) = V i t =1 i g i t + V i t =1 V i t =t +1 g i t g i t .<label>(7)</label></formula><p>It is worth pointing out that although pairwise pooling models the correlation between each pair of features, it can be e ciently computed in linear time -the same time complexity with average/max pooling. To show the linear time complexity of evaluating pairwise pooling, we reformulate Eqn.(6) as,</p><formula xml:id="formula_8">p u = 1 2 (u + V u t =1 g u t ) (u + V u t =1 g u t ) − u u − V u t =1 g u t g u t ,<label>(8)</label></formula><p>which can be computed in O(KV u ) time. is is a very appealing property, meaning that the bene t of pairwise pooling in modelling all pair-wise correlations does not involve any additional cost, as compared to the average pooling that does not model any correlation between input features. Hidden Layers: Above the pairwise pooling is a stack of full connected layers, which enable us to capture the nonlinear and higher-order correlations among users, items, and a ributes. Inspired by the neural network view of matrix factorization (cf. <ref type="figure" target="#fig_0">Figure 2</ref>), we rst merge user representation p u and item representation q i with an element-wise product, which models the two-way interaction between u and i. We then place a multilayer perceptron (MLP) above the element-wise product. Formally, the hidden layers are de ned as:</p><formula xml:id="formula_9">             e 1 = σ 1 (W 1 (p u q i ) + b 1 ) e 2 = σ 2 (W 2 e 1 + b 2 ) · · · · · · e L = σ L (W L e L−1 + b L ) ,<label>(9)</label></formula><p>where W l , b l , σ l , and e l denote the weight matrix, bias vector, activation function, and output vector of the l-th hidden layers, respectively. As for the activation function in each hidden layer, we opt for Recti er (ReLU) unit, which is more biologically plausible and proven to be non-saturated. Regarding the structure of hidden layers, common choices include the tower <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b10">11]</ref>, constant, and diamond, among others. In this work, we simply set all hidden layers have the same size, leaving the further tuning of the deep structure as the future work. Prediction Layer: At last, the output vector of the last hidden layer e L is transformed to the prediction score:</p><formula xml:id="formula_10">ui = w e L ,<label>(10)</label></formula><p>where w represents the weight vector of the prediction layer. Note that we have recently proposed a neural factorization machine (NFM) model <ref type="bibr" target="#b9">[10]</ref>, which similarly uses a pairwise pooling operation to model the interaction among features. We point out that the main architecture di erence is in our separated treatment of the user and item channel, where each channel can essentially be seen as an application of NFM on the user/item ID and a ributes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Learning of Social Domain</head><p>With the above neural collaborative ranking solution, we obtain an a ribute-aware representation p u and q i for each user and item, respectively. To predict the a nity score of a social user to an item of the information domain, we need to also learn an representation for the social user in the same latent space of the information domain. We achieve this goal by propagating p u from bridge users to representations for non-bridge users of the social domain. e intuition for such representation propagation is that, if two users are strongly connected (e.g., close friends with frequent interactions), it is likely that they have the similar preference on items; as such, they should have similar representations in the latent space. is suits well the paradigm of graph regularization <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b28">29]</ref> (aka. semi-supervised learning on graph), which has two components:</p><p>Smoothness: e smoothness constraint implies the structural consistency -the nearby vertices of a graph should not vary much in their representations. Enforcing smoothness constraint in our context of social domain learning will propagate a user's representation to her neighbors, such that when a steady state reaches, all vertices should have been placed in the same latent space. e objective function for smoothness constraint is de ned as:</p><formula xml:id="formula_11">θ (U 2 ) = 1 2 u ,u ∈U 2 s u u p u √ d u − p u √ d u 2 ,<label>(11)</label></formula><p>where s u u denotes the strength of social connection between u and u , and d u (or d u ) denotes the outdegree of u (or u ) for normalization purpose. It is worth noting that the use of normalization is the key di erence with the social regularization used by <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b35">36]</ref>, which does not apply any normalization on the smoothness constraint. As pointed out by He et al. <ref type="bibr" target="#b8">[9]</ref>, the use of normalization helps to suppress the impact of popular vertices, which can lead to more e ective propagation. We empirically verify this point in Section 4.3.</p><p>Fitting: e ing constraint implies the latent space consistency across two domains -the bridge users' representations should be invariant and act as the anchors across domains. Towards this end, we encourage the two representations of the same bridge users to be close to each other. e objective function for ing constraint is de ned as,</p><formula xml:id="formula_12">θ (U) = 1 2 u ∈U p u − p (0) u 2 ,<label>(12)</label></formula><p>where for each bridge user u , p u (or p (0) u ) is her representation of the SNS (or information domain). As such, the ing constraint essentially acts as the bridges connecting the two latent spaces.</p><p>Lastly, we combine the smoothness constraint with the ing constraint and obtain the objective function of the social domain learning as,</p><formula xml:id="formula_13">L S = θ (U 2 ) + µθ (U),<label>(13)</label></formula><p>where µ is a positive parameter to control the tradeo between two constraints.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.2.1</head><p>Prediction for Social Users. With the representations of social users and items (i.e., p u and q i ) at hand, we can feed them into the fully connected layers as Eqn. <ref type="bibr" target="#b8">(9)</ref> shows and utilize the prediction layer as Eqn. <ref type="formula" target="#formula_1">(10)</ref> displays. At last, we can obtain the predicted preference u i , as follows,</p><formula xml:id="formula_14">             e 1 = σ 1 (W 1 (p u q i ) + b 1 ) · · · · · · e L = σ L (W L e L−1 + b L ) u i = w e L .<label>(14)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Training</head><p>We adopt the alternative optimization strategy on Eqn.(3) since it can emphasize exclusive characteristics within individual domains. In the information domain, we employ stochastic gradient descent SGD) to train the a ribute-aware NSCR in the mini-batch mode and update the corresponding model parameters. In particular, we rst sample a batch of observed user-item interactions (u, i) and adopt negative sampling <ref type="bibr" target="#b10">[11]</ref> to randomly select an unobserved item j for each (u, i). We then generate a triplet (u, i, j). Following that, we take a gradient step to optimize the loss function L I in Eqn. <ref type="bibr" target="#b4">(5)</ref>. As such, we obtain the enhanced representations of users. In the SNS, we feed the enhanced representations of bridge users into our graph Laplacian to update all representations of social users. Towards this end , we can simplify the derivative of L S regarding user representation P and then obtain the close-form solution as,</p><formula xml:id="formula_15">P = µ 1 + µ I − 1 1 + µ D − 1 2 SD − 1 2 −1 P (0) ,<label>(15)</label></formula><p>where P (0) is the embedding of social users, which includes the updated representations of bridge users from NSCR part; S and D are the similarity matrix and diagonal degree matrix of social users, respectively, whereinto S u u = s u u and D u u = d u . erea er, we view the newly updated representations of bridge users as the next initialization for the bridge users in NSCR. We repeat the above procedures to approximate the model parameter set Θ. As for the regularization term in Eqn.(3), we omit it since we utilize dropout technique in neural network modeling to avoid over ing. Dropout: Dropout is an e ective solution to prevent deep neural networks from over ing. e idea is to randomly drop part of neurons during training. As such, only part of the model parameters, which contribute to the nal ranking, will be updated. In our neural CR model, we propose to adopt dropout on the pairwise pooling layer. In particular, we randomly drop ρ of p u and q i , whereinto ρ is the dropout ratio. Analogous to the pooling layer, we also conduct dropout on each hidden layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTS</head><p>To comprehensively evaluate our proposed method, we conducted experiments to answer the following research questions:</p><p>• RQ1: Can our NSCR approach outperform the state-of-theart recommendation methods for the new cross-domain social recommendation task? • RQ2: How do di erent hyper-parameter se ings (e.g., the dropout ratio and tradeo parameters) a ect NSCR? • RQ3: Are deeper hidden layers helpful for learning from useritem interaction data and improving the performance of NSCR?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data Description</head><p>To the best of our knowledge, there is no available public benchmark dataset that ts the task of cross-domain social recommendation.</p><p>As such, we constructed the datasets by ourselves. We treated Trip.com as the information domain, Facebook and Twi er as the social domains. In Trip.com, we initially compiled 6, 532 active users, who had at least 5 ratings over 2, 952 items (e.g., gardens by the bay in Singapore and ei el tower in Pairs). We transformed their 93, 998 ratings into binary implicit feedback as ground truth, indicating whether the user has rated the item. Moreover, we collected 19 general categories regarding the travel mode (e.g., adventure travel, business travel, and nightlife) and used them as the a ributes of users and items. Subsequently, we parsed the users' pro les to identify their aligned accounts in Facebook and Twi er, inspired by the methods in <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b23">24]</ref>. We obtained 858 and 502 bridge users for Facebook and Twi er, respectively. erea er, we crawled the public friends or followers of each bridge user to reconstruct the social networks, resulting in 177, 042 Facebook users and 106, 049 Twi er users. However, the original social data are highly sparse, where most non-bridge users have only one friend, making it ine ective to propagate users' preferences. To ensure the quality of the social data, we performed a modest ltering on the data, retraining users with at least two friends. is results in a subset of the social data that contains 7, 233 Twi er users with 42, 494 social connections and <ref type="bibr" target="#b7">8,</ref><ref type="bibr">196</ref> Facebook users with 49, 156 social connections. e statistics of the datasets are summarized in <ref type="table" target="#tab_0">Table 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experimental Settings</head><p>Evaluation Protocols: Given a social user, each method generates an item ranking list for the user. To assess the ranking list, we adopted two popular IR metrics, AUC and recall, to measure the quality of preference ranking and top-N recommendation.</p><p>• AUC: Area under the curve (AUC) <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b20">21]</ref> measures the probability that a recommender system ranks a positive useritem interaction higher than negative ones: where I + u = {i | ui = 1} and I − u = {j | u j = 0} denote the sets of relevant (observed) item i and irrelevant (unobserved) item j for user u, respectively; and δ is the count function returning 1 if ui j &gt; 0 and 0 otherwise. Below we report the averaged AUC for all testing users.</p><formula xml:id="formula_16">AU C = i ∈I + u j ∈I − u δ ( ui j &gt; 0) |I + u ||I − u | ,<label>(16)</label></formula><p>• R@K: Recall@K considers the relevant items within the top K positions of the ranking list. A higher recall with lower K indicates a be er recommender system, which can be de ned as,</p><formula xml:id="formula_17">R@K = |I + u ∩ R u | |I + u | ,<label>(17)</label></formula><p>where R u denotes the set of the top-K ranked items for the given user u. Analogous to AUC, we report the average R@5 for all testing users.</p><p>By learning representations for social users and informationdomain items together, our NSCR is capable of recommending items for both bridge and non-bridge users. However, due to the limitation of our static datasets, it is di cult for us to evaluate the recommendation quality for non-bridge users, since they have no interaction on the information-domain items. As such, we rely on the bridge users for evaluating the performance. Following the common practice in evaluating a recommender algorithm <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b20">21]</ref>, we holdout the latest 20% interactions of a bridge user as the test set. To tune hyper-parameters, we further randomly holdout 20% interactions from a bridge user's training data as the validation set. We feed the remaining bridge users, all the non-bridge users in SNSs, and the remaining user-item interactions in the information domains into our framework for training. Baselines: To justify the e ectiveness of our proposal, we study the performance of the following methods:</p><p>• ItemPop: is method ranks items base on their popularity, as judged by the number of interactions. It is a non-personalized method that benchmarks the performance of a personalized system <ref type="bibr" target="#b20">[21]</ref>.</p><formula xml:id="formula_18">• MF:</formula><p>is is the standard matrix factorization model that leverages only user-item interactions of the information domain for recommendation (cf. Eqn. <ref type="formula" target="#formula_2">(2)</ref>).</p><p>• SFM: Factorization machine <ref type="bibr" target="#b18">[19]</ref> is a generic factorization model that is designed for recommendation with side information. We construct the input feature vector by using one-hot encoding on the ID and a ributes of users and items. To adjust FM for modelling social relations, we further plug a (bridge) user's friends into the input feature vector, dubbed this enhanced model as Social-aware FM (SFM). • SR: is <ref type="bibr" target="#b15">[16]</ref> is a state-of-the-art factorization method for social recommendation. It leverages social relations to regularize the latent vectors of friends to be similar. To incorporate a ributes into their method, we adjust the similarity of two users based on their a ribute sets, which leads to be er performance. Note that for all model-based methods, we optimize them with the same pair-wise ranking function of Eqn.(5) for a fair comparison on the model's expressiveness. To explore the e cacy of a ributes, we further explore variants that remove a ribute modelling from SFM, SR, and NSCR, named as SFM-a, SR-a, and NSCR-a, respectively. Parameter Settings: We implemented our proposed framework on the basis of Tensor ow 2 , which will be made publicly available, as well as our datasets. For all the neural methods, we randomly initialized model parameters with a Gaussian distribution, whereinto the mean and standard deviation is 0 and 0.1, respectively. e mini-batch size and learning rate for all methods was searched in [128, 256, 512, 1024] and [0.0001, 0.0005, 0.001, 0.05, 0.1], respectively. We selected Adagrad as the optimizer. Moreover, we empirically set the size of hidden layer same as the embedding size (the dimension of the latent factor) and the activation function as ReLU. Without special mention, we employed two hidden layers for all the neural methods, including SFM, SR, and NSCR. We randomly generated ten di erent initializations and feed them into our NSCR. For other competitors, the initialization procedure is analogous to ensure the fair comparison. erea er, we performed paired t-test between our model and each of baselines over 10-round results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Performance Comparison (RQ1)</head><p>We rst compare the recommendation performance of all the methods. We then purpose to justify how the social modelling and the a ribute modelling a ect the recommendation performance.</p><p>Overall Comparison: <ref type="table" target="#tab_1">Table 2</ref> displays the performance comparison w.r.t. AUC and R@5 among the recommendation methods on Twi er-Trip and Facebook-Trip datasets, where the embedding size is 64 for all the methods. We have the following ndings:</p><p>• ItemPop achieves the worst performance, indicating the necessity of modelling users' personalized preferences, rather than just recommending popular items to users. As for MF, its unsatis ed performance re ects that the independence assumption is insu cient to capture the complex and non-linear structure of user-item interactions. • NSCR substantially outperforms the state-of-the-art methods, SFM and SR. We further conduct one-sample t-tests, verifying that all improvements are statistically signi cant with p-value &lt; 0.05. It justi es the e ectiveness of our proposed framework. • e performance on Twi er-Trip clearly underperforms that of Facebook-Trip. It is reasonable since more bridge users are 2 h ps://www.tensor ow.org. available in Facebook, which can lead to be er embedding learning in SNSs. It again veri es the signi cance of the bridge users.</p><p>E ect of Social Modelling: To analyze the e ect of social modelling, we only consider the variants, SFM-a, SR-a, and NSCR-a. <ref type="figure">Figure 4</ref> presents the performance comparison w.r.t. the number of latent factors on two datasets. We have the following observations. • ItemPop and MF perform worst since neither of them considers the social connections from SNSs. It highlights the necessity of social modelling in cross-domain social recommendation. • Clearly, NSCR-a signi cantly outperforms SFM-a and SR-a by a large margin. Formally, in terms of AUC, the relative improvement over SFM-a and SR-a, on average, is 3.19% and 1.01% respectively. While SFM-a considers modelling the social connections, it treats these connections as ordinary features, overlooking the exclusive characteristics of social networks. is leads to the poor expressiveness of the social users' embedding.</p><p>On the contrary, SR-a and NSCR-a emphasizes the social modelling via the e ective social regularization. • Lastly, NSCR-a shows consistent improvements over SR-a, admi ing the importance of the normalized graph Laplacian. It again veri es that the normalized graph Laplacian can suppress the popularity of friends and further prevent the social modelling from being dominated by popular social users.</p><p>E ect of Attribute Modelling: As <ref type="figure">Figure 5</ref> demonstrates, we verify the substantial in uence of a ribute modelling and the e ectiveness of our pairwise pooling operation. Due to the poor performance of ItemPop and MF, they are omi ed. Jointly analyzing the performance of all the methods and their variants, we nd that, • For all methods, modelling user/item a ributes can achieve signi cant improvements. By leveraging the similarity of users' a ributes, SR enriches the pairwise similarity of any two users and strengthens their connections; meanwhile, SFM can model the correlations of user-a ribute, item-a ribute, and a ributea ribute, and accordingly enhances the user-item interactions. Bene ting from the pairwise pooling operation, NSCR can encode the second-order interactions between user/item and a ributes and boost the representation learning. e signi cance of a ribute is consistent with <ref type="bibr" target="#b33">[34]</ref>. • Varying the embedding size, we can see that large embedding may cause over ing and degrade the performance. In particular, the optimal embedding size is 64 and 32 for AUC and R@5, respectively. It indicates that the se ing of embedding size can e ect the expressiveness of our model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Study of NSCR (RQ2)</head><p>In this subsection, we empirically study the convergence of NSCR and then purpose to analyse the in uences of several factors, such as dropout ratio and tradeo parameter, on our framework. Convergence: We separately present the training loss and the performance w.r.t. AUC and R@5 of each iteration in  indicates that e ectiveness of our learning framework. As <ref type="figure">Figure 6</ref>(c) shows, the performance regarding R@5 uctuates markedly over the iteration times, while that regarding AUC is quite stable. It is reasonable since R@5 only considers the top-5 results rather than the relative order as AUC de ned. Impact of Dropout: We employ the dropout technique in NSCR to prevent our model from over ing, instead of regularizing model parameters. <ref type="figure" target="#fig_3">Figures 7(a)</ref> and 7(b) present the performance w.r.t. AUC and R@5 of NSCR-0 by varying the dropout ratio ρ on the pairwise pooling layer, respectively. As we can see, when dropout ratio equals to 0, NSCR-0 su ers severely from over ing. Moreover, using a dropout ratio of 0.3 and 0.2 leads to the best performance on Twi er-Trip and Facebook-Trip datasets, respectively. However, when the optimal dropout ratio exceeds the optimal se ings, the performance of NSCR-0 greatly decreases, which su ers from insu cient information. is highlights the signi cance of using dropout, which can be seen as ensembling multiple sub-models <ref type="bibr" target="#b24">[25]</ref>.</p><p>Impact of Tradeo Parameter: ere is one positive parameter µ in the social modelling, which can capture the tradeo between the ing regularizer and the normalized graph Laplacian, as Eqn. <ref type="formula" target="#formula_1">(15)</ref> shows. Figures 7(c) and 7(d) present the performance w.r.t. . AUC and R@5, respectively. As we can see, se ing µ of 0.8 and 0.7 can lead to the optimal performance on Twi er-Trip and Facebook-Trip datasets, respectively. And the performance of NSCR-0 changes within small ranges nearby the optimal se ings. It justi es that our model is relatively insensitive to the parameter around its optimal con guration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Impact of Hidden Layer (RQ3)</head><p>To capture the complex and non-linear inherent structure of useritem interactions, we employ the a deep neural network for our task. It is curious whether NSCR can bene t from the deep architecture. Towards this end, we further investigate NSCR with di erent number of hidden layers. As it is computationally expensive to tune the dropout ratio ρ for each hidden layer, we simply apply the same se ings for all layers. e empirical results on two datasets are summarized in <ref type="table" target="#tab_2">Table 3</ref> whereinto NSCR-2 indicates the NSCR method with two hidden layers (besides the embedding layer and prediction layer), and similar notations for others. We have the following observations:</p><p>• In most cases, stacking more hidden layers is helpful for the recommendation performance. NSCR-2 and NSCR-1 achieve consistent improvement over NSCR-0, which has no hidden layers and directly projects the embedding to the prediction layer. We a ributed the improvement to the high nonlinearity achieved by stacking more hidden layers. Our nding is consistent with <ref type="bibr" target="#b7">[8]</ref> and again veri es the deep neural networks have strong generalization ability. However, it is worth mentioning that such a deep architecture needs more time to optimize our framework and easily leads to the over ing due to the limited training data in our datasets. • Increasing the width of hidden layers (i.e., the embedding size) from 8 to 64 can improve the performance signi cantly, as that of increasing their depth. However, with the embedding size of 128, NSCR degrades the performance. It again veri es that using a large number of the embedding size has powerful representation ability <ref type="bibr" target="#b7">[8]</ref>, but may adversely hurt the generalization of the model (e.g., over ing the data) <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b10">11]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">RELATED WORK 5.1 Social Recommendation</head><p>Social recommendation aims to leverage users' social connections to enhance a recommender system <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b31">32]</ref>. It works by modelling social in uence, which refers to the fact that a user's decision can be a ected by her friends' opinions and behaviours. Ma et al. <ref type="bibr" target="#b15">[16]</ref> propose a social regularization term to enforce social constraints on traditional recommender systems. Based on a generative in uence model, the work <ref type="bibr" target="#b30">[31]</ref> exploits social in uence from friends for item recommendation by leveraging information embedded in the user social network. e authors in <ref type="bibr" target="#b34">[35]</ref> utilize social links as complementary data source to mine topic domains and employed domain-speci c collaborative ltering to formulate users' interests. More recently, <ref type="bibr" target="#b12">[13]</ref> represents a star-structured hybrid graph centered at a user domain, which connects with other item domains, and transfers knowledge on social networks. It is worth noting that the aforementioned studies are all based on social network relations of an information domain. While in this work, we focus on how to distill useful signal from an external social network (e.g., Facebook and Twi er), so as to improve the recommendation service of any information domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Cross-Domain Recommendation</head><p>Distinct from the traditional recommendation methods that focus on data within a single domain, cross-domain recommendation concerns data from multiple domains. A common se ing is leveraging the user-item interaction of a related auxiliary domain to improve the recommendation of the target domain. However, existing cross-domain recommendation work has an underlying assumption that the target and auxiliary domains are homogeneous. Depending on <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b12">13]</ref>, they can be divided into two directions. One is assuming that di erent domains share overlapped user or item sets. e work <ref type="bibr" target="#b21">[22]</ref> augments ratings of movies and books for the shared users and accordingly conducts CF. Based on the shared users' latent space, the authors in <ref type="bibr" target="#b2">[3]</ref> leveraged cluster-level tensor sharing as a social regularization to bridge the domains. One more step, the authors in <ref type="bibr" target="#b11">[12]</ref> formulated a generalized triadic user-itemdomain relation over the common users and accordingly to capture domain-speci c user factors and item factors. More recently, the authors <ref type="bibr" target="#b4">[5]</ref> proposed a multi-view deep learning recommendation system by using auxiliary rich features to represent users from di erent domains. Without aligned user or item, the other direction is on homogeneous data with the same rating scale. Codebook Transfer <ref type="bibr" target="#b13">[14]</ref> represents cluster-level rating pa erns between two rating matrices in two related domains. <ref type="bibr" target="#b26">[27]</ref> introduces a topic model to recommend authors to collaborate from di erent research elds.</p><p>Despite the compelling success achieved by previous work, li le a ention has been paid to recommendation across heterogeneous domains. In our se ings, the source domain is a social network with user-user relations only, while the target domain is an information domain with user-item interactions. Hence, the auxiliary information is the social friendship, rather than the conventional interaction data. As a result, existing approaches can be hardly applied to this new research problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>In this work, we systematically investigated cross-domain social recommendation, a practical task that has rarely been studied previously. Towards this end, we proposed a generic neural social collaborative ranking (NSCR) solution, which seamlessly integrates user-item interactions of the information domain and user-user social relations of the social domain. To validate our solution, we constructed two real-world benchmarks of the travel domain, performing extensive experiments to demonstrate the e ectiveness and rationality of our NSCR solution. e key nding of the work is that social signals contain useful cues about users' preference, even if the social signals are from social networks in a di erent domain. We achieved the goal by leveraging bridge users to unify the relevance signals from the two heterogeneous domains.</p><p>Due to our restricted resources in collecting cross-domain data, the result is preliminary. Here we discuss several limitations of the current work, and our plans to address them in future. First, in this work, we studied the recommendation performance of a travel-based information domain only, which is mainly for the ease of accessing the users' account on Facebook/Twi er.</p><p>is results in a relatively small number of bridge users of our crossdomain datasets. As a future work, we will collect a larger-scale set of data from the more popular information domains, such as E-commence sites, to explore the generalization ability of our solution to other information domains. Second, due to the small number of bridge users, we forwent the study of user cold-start problem, as further holding out bridge users to simulate the coldstart scenario will pose challenge to the stability of evaluation. With a larger-scale cross-domain data, we will study the e ectiveness of our solution for cold-start users, as well as the in uence of the bridge users' percentage. Moreover, we restricted the SNSs by emphasizing only the social connections and omi ing the weak user-item interactions in user-generated-contents. We will consider the weak user-item interaction in both domains to improve the recommendation performance.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>MF as a shallow neural network model. emphasizing the social connections in SNSs and leaving the exploration of weak interactions as the future work.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Illustration of our Attributed-aware Deep CF model for estimating an user-item interaction.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figures 6 (Figure 4 :Figure 5 :Figure 6 :</head><label>6456</label><figDesc>a), 6(b), and 6(c). Jointly observing these Figures, we can see that training loss of NSCR gradually decreases with more iterations, whereas the performance is generally improved. is indicates the rationality of our learning framework. Moreover, the most e ective updates occurs in the rst 20 iterations, which(a) AUC on Twi er-Trip (b) R@5 on Twi er-Trip (c) AUC on Facebook-Trip (d) R@5 on Facebook-Trip Performance comparison of AUC and R@5 w.r.t. the embedding size on Twitter-Trip and Facebook-Trip datasets. (a) AUC on Twi er-Trip (b) R@5 on Twi er-Trip (c) AUC on Facebook-Trip (d) R@5 on Facebook-Trip Performance comparison of AUC and R@5 w.r.t. the embedding size on Twitter-Trip and Facebook-Trip datasets. Training loss and recommendation performance regarding AUC and R@5 w.r.t. the number of iterations. (a) AUC vs. dropout ratio ρ (b) R@5 vs. dropout ratio ρ (c) AUC vs. tradeo parameter µ (d) R@5 vs. tradeo parameter µ</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 7 :</head><label>7</label><figDesc>Performance comparison of AUC and R@5 w.r.t. the dropout ratio ρ and tradeo parameter µ on Twitter-Trip and Facebook-Trip datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Statistics of the complied datasets. e social user set includes the bridge users.</figDesc><table><row><cell>Information Domain</cell><cell>User#</cell><cell>Item#</cell><cell>Interaction#</cell></row><row><cell>Trip.com</cell><cell>6, 532</cell><cell>2, 952</cell><cell>93, 998</cell></row><row><cell>SNSs</cell><cell cols="3">Bridge User# Social User# Social Connection#</cell></row><row><cell>Twi er</cell><cell>502</cell><cell>7, 233</cell><cell>42, 494</cell></row><row><cell>Facebook</cell><cell>858</cell><cell>8, 196</cell><cell>49, 156</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Performance comparison between all the methods, when the embedding size= 64 and signi cance test is based on AUC.</figDesc><table><row><cell>Datasets</cell><cell></cell><cell>Twitter-Trip</cell><cell></cell><cell cols="2">Facebook-Trip</cell></row><row><cell cols="2">Methods AUC</cell><cell cols="3">R@5 p-value AUC</cell><cell>R@5 p-value</cell></row><row><cell cols="3">ItemPop 0.7193 0.0164</cell><cell>3e-5</cell><cell cols="2">0.7439 0.0249</cell><cell>8e-6</cell></row><row><cell>MF</cell><cell cols="2">0.8285 0.0375</cell><cell>3e-4</cell><cell cols="2">0.8596 0.0821</cell><cell>1e-4</cell></row><row><cell>SFM</cell><cell cols="2">0.8832 0.0492</cell><cell>2e-3</cell><cell cols="2">0.8908 0.0856</cell><cell>1e-3</cell></row><row><cell>SR</cell><cell cols="2">0.9013 0.0747</cell><cell>9e-3</cell><cell cols="2">0.9267 0.1433</cell><cell>4e-2</cell></row><row><cell>NSCR</cell><cell cols="2">0.9222 0.0807</cell><cell>-</cell><cell cols="2">0.9390 0.1466</cell><cell>-</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Recommendation performance of NSCR with di erent hidden layers.</figDesc><table><row><cell>Metrics</cell><cell></cell><cell>AUC</cell><cell></cell><cell></cell><cell>R@5</cell><cell></cell></row><row><cell cols="7">Factors NSCR-0 NSCR-1 NSCR-2 NSCR-0 NSCR-1 NSCR-2</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Twitter-Trip</cell><cell></cell><cell></cell><cell></cell></row><row><cell>8</cell><cell>0.8598</cell><cell>0.8630</cell><cell>0.8704</cell><cell>0.0585</cell><cell>0.0604</cell><cell>0.0628</cell></row><row><cell>16</cell><cell>0.8883</cell><cell>0.8984</cell><cell>0.9026</cell><cell>0.0738</cell><cell>0.0672</cell><cell>0.0812</cell></row><row><cell>32</cell><cell>0.9018</cell><cell>0.9056</cell><cell>0.9109</cell><cell>0.0723</cell><cell>0.0742</cell><cell>0.0843</cell></row><row><cell>64</cell><cell>0.9138</cell><cell>0.9175</cell><cell>0.9222</cell><cell>0.0717</cell><cell>0.0697</cell><cell>0.0725</cell></row><row><cell>128</cell><cell>0.9003</cell><cell>0.9034</cell><cell>0.9125</cell><cell>0.0519</cell><cell>0.0653</cell><cell>0.0688</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Facebook-Trip</cell><cell></cell><cell></cell><cell></cell></row><row><cell>8</cell><cell>0.8978</cell><cell>0.8922</cell><cell>0.9034</cell><cell>0.0860</cell><cell>0.0872</cell><cell>0.0986</cell></row><row><cell>16</cell><cell>0.9165</cell><cell>0.9197</cell><cell>0.9265</cell><cell>0.1048</cell><cell>0.1388</cell><cell>0.1419</cell></row><row><cell>32</cell><cell>0.9303</cell><cell>0.9322</cell><cell>0.9335</cell><cell>0.1441</cell><cell>0.1486</cell><cell>0.1465</cell></row><row><cell>64</cell><cell>0.9337</cell><cell>0.9376</cell><cell>0.9390</cell><cell>0.1353</cell><cell>0.1359</cell><cell>0.1466</cell></row><row><cell>128</cell><cell>0.9270</cell><cell>0.9310</cell><cell>0.9332</cell><cell>0.1168</cell><cell>0.1304</cell><cell>0.1373</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgement We would like to thank the anonymous reviewers for their valuable comments. NExT research is supported by the National Research Foundation, Prime Minister's O ce, Singapore under its IRC@SG Funding Initiative.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A generic coordinate descent framework for learning from implicit feedback</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Bayer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kanagal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rendle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1341" to="1350" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A entive collaborative ltering: Multimedia recommendation with item-and component-level a ention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">N</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Making recommendations from multiple domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="892" to="900" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Deep neural networks for youtube recommendations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Covington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Sargin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">RecSys</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="191" to="198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A multi-view deep learning approach for cross domain user modeling in recommendation systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Elkahky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="278" to="288" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Cross-domain recommendation via clustering on multi-layer graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Farseev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Samborskii</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Filchenkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-S</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Computational social indicators: a case study of chinese university ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-S</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Trirank: Review-aware explainable recommendation by modeling aspects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1661" to="1670" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Neural factorization machines for sparse predictive analytics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-S</forename><surname>Chua</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Neural collaborative ltering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-S</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="173" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Personalized recommendation via cross-domain triadic factorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="595" to="606" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Social recommendation with cross-domain transferable knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TKDE</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="3084" to="3097" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Can movies and books collaborate? cross-domain collaborative ltering for sparsity reduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="2052" to="2057" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">A ributed social network embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-S</forename><surname>Chua</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.04969</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Recommender systems with social regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>King</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="287" to="296" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Learning from Multiple Social Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Synthesis Lectures on Information Concepts, Retrieval, and Services</title>
		<imprint>
			<date type="published" when="2016" />
			<publisher>Morgan &amp; Claypool Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Social collaborative viewpoint regression with explainable recommendations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="485" to="494" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Factorization machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rendle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="995" to="1000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Factorization machines with libfm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rendle</surname></persName>
		</author>
		<idno>57:1-57:22</idno>
	</analytic>
	<monogr>
		<title level="j">TIST</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">BPR: bayesian personalized ranking from implicit feedback</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rendle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Freudenthaler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Gantner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Schmidt-Ieme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">UAI</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="452" to="461" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Cross-domain collaborative recommendation in a cold-start context: e impact of user pro le size on the quality of recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sahebi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Brusilovsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">UMAP</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="289" to="295" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Reasoning with neural tensor networks for knowledge base completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="926" to="934" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Multiple social network learning and its application in volunteerism tendency prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Akbari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="213" to="222" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Dropout: a simple way to prevent neural networks from over ing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Alternating least squares for personalized ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Takács</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tikk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">RecSys</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="83" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Cross-domain collaboration recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1285" to="1293" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Learning on big graph: Label inference and regularization with anchor hierarchy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TKDE</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1101" to="1114" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Scalable semi-supervised learning by e cient anchor graph regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TKDE</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1864" to="1877" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Unifying virtual and physical worlds: Learning toward local and global consistency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-S</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TOIS</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Exploring social in uence for recommendation: a generative model approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="671" to="680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Gmove: Grouplevel mobility modeling using geo-tagged social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hanra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1305" to="1314" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Discrete collaborative ltering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-S</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="325" to="334" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A ribute-augmented semantic hierarchy: towards bridging semantic gap and intention gap in image retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MM</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="33" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Toprec: domain-speci c recommendation through community topic mining in social network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1501" to="1510" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">User preference learning for online social recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhuang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TKDE</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2522" to="2534" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
