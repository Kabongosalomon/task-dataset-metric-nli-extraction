<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Puzzle Mix: Exploiting Saliency and Local Statistics for Optimal Mixup</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jang-Hyun</forename><surname>Kim</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wonho</forename><surname>Choo</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyun</forename><forename type="middle">Oh</forename><surname>Song</surname></persName>
						</author>
						<title level="a" type="main">Puzzle Mix: Exploiting Saliency and Local Statistics for Optimal Mixup</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T05:43+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>While deep neural networks achieve great performance on fitting the training distribution, the learned networks are prone to overfitting and are susceptible to adversarial attacks. In this regard, a number of mixup based augmentation methods have been recently proposed. However, these approaches mainly focus on creating previously unseen virtual examples and can sometimes provide misleading supervisory signal to the network. To this end, we propose Puzzle Mix, a mixup method for explicitly utilizing the saliency information and the underlying statistics of the natural examples. This leads to an interesting optimization problem alternating between the multi-label objective for optimal mixing mask and saliency discounted optimal transport objective. Our experiments show Puzzle Mix achieves the state of the art generalization and the adversarial robustness results compared to other mixup methods on CIFAR-100, Tiny-ImageNet, and ImageNet datasets. The source code is available at https: //github.com/snu-mllab/PuzzleMix.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Deep neural network models are the bedrock of modern AI tasks such as object recognition, speech, natural language processing, and reinforcement learning. However, these models are known to memorize the training data and make overconfident predictions often resulting in degraded generalization performance on test examples <ref type="bibr" target="#b29">(Srivastava et al., 2014;</ref><ref type="bibr" target="#b37">Zhang et al., 2016)</ref>. Furthermore, the problem is exacerbated when the models are evaluated on examples under slight distribution shift <ref type="bibr" target="#b0">(Ben-David et al., 2010)</ref>.</p><p>To this end, data augmentation approaches aim to alleviate some of these issues by improving the model generalization  <ref type="table" target="#tab_1">001  002  003  004  005  006  007  008  009  010  011  012  013  014  015  016  017  018  019  020  021  022  023  024  025  026  027  028  029  030  031  032  033  034  035  036  037  038  039  040  041  042  043  044  045  046  047  048  049  050  051  052  053   Input1</ref> Input Mixup Puzzle Mix (z only)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Input2</head><p>CutMix Puzzle Mix (full) <ref type="figure" target="#fig_0">Figure 1</ref>. A visual comparison of the mixup methods. Puzzle Mix ensures to contain sufficient target class information while preserving the local statistics of each input.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Saliency</head><p>Before Transport After Transport Input Before Transport After Transport <ref type="figure" target="#fig_1">Figure 2</ref>. Illustration of our transport process. After the transport, the salient regions (green) replace the other regions within the positive mask, so that the salient information still remains after mixup. The first row represents the saliency information after downsampling, i.e., s(r x`( x)), the masked saliency (z s(r x`( x))), and the masked saliency after transport (z ⇧ | 1 s(r x`( x))). The second row represents the corresponding data. performance <ref type="bibr" target="#b10">(He et al., 2015;</ref><ref type="bibr" target="#b7">DeVries &amp; Taylor, 2017)</ref>. Recently, a line of research called mixup has been proposed. These methods mainly focus on creating previously unseen virtual mixup examples via convex combination or local replacement of data for training <ref type="bibr" target="#b38">(Zhang et al., 2018;</ref><ref type="bibr" target="#b30">Verma et al., 2019;</ref><ref type="bibr" target="#b35">Yun et al., 2019;</ref><ref type="bibr" target="#b9">Guo et al., 2019)</ref>.</p><p>However, the underlying data domains contain rich regional saliency information (i.e. foreground objects in vision, prominent syllables in speech, informative textual units in language) <ref type="bibr" target="#b27">(Simonyan et al., 2013;</ref><ref type="bibr" target="#b16">Kalinli &amp; Narayanan, 2007;</ref><ref type="bibr" target="#b8">Erkan &amp; Radev, 2004)</ref> and exhibit local regularity structure far from random matrices of numbers <ref type="bibr" target="#b14">(Huang &amp; Mumford, 1999;</ref><ref type="bibr" target="#b39">Zhang et al., 2017;</ref><ref type="bibr">Smith, 2003)</ref>. Thus, completely disregarding these aspects of data could lead to creating mixup examples which could misguide the training model and undermine the generalization performance.</p><p>Motivated by this intuition, we propose Puzzle Mix, a mixup method for explicitly leveraging the saliency information and the underlying local statistics of natural examples. Our proposed method jointly seek to find (1) the optimal mask for deciding how much of the two inputs to reveal versus conceal in the given region and for (2) the transport for finding the optimal moves in order to maximize the exposed saliency under the mask. The optimization process is reminiscent of the sliding block puzzle and thus the name Puzzle arXiv:2009.06962v2 <ref type="bibr">[cs.</ref>LG] 30 Dec 2020</p><p>Mix. Additionally, we impose the objective to respect the various underlying local statistics encouraging the optimization to preserve the structural integrity of each data. The proposed method alternates between finding the optimal mask and optimizing the transport plans, and efficiently generates the mixup examples in a mini-batch stochastic gradient descent setting.</p><p>Furthermore, our method allows us to incorporate adversarial training without any computation overhead. Adversarial training is a method for training a robust model resistant to adversarial attacks via optimization <ref type="bibr" target="#b20">(Madry et al., 2017)</ref>. We adapt the fast adversarial training method from <ref type="bibr">Wong et al. (2020)</ref> and stochastically include the adversarially perturbed examples with random restarts for robustness.</p><p>Our results on CIFAR-100, Tiny-ImageNet, and ImageNet datasets show significant improvement both in the generalization task and in the adversarial robustness over existing mixup methods by a large margin.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Works</head><p>Data augmentation Methods that implement data augmentation aim to regularize the models from overfitting to the training distribution and improve the generalization performance by generating virtual training examples in the vicinity of the given training dataset <ref type="bibr" target="#b2">(Bishop, 2006)</ref>. Some of the most commonly used data augmentation techniques are random cropping, horizontal flipping <ref type="bibr" target="#b19">(Krizhevsky et al., 2012)</ref>, and adding random noise <ref type="bibr" target="#b1">(Bishop, 1995)</ref>. Recently, a data augmentation method called AugMix is proposed to improve both the generalization performance and the corruption robustness <ref type="bibr" target="#b13">(Hendrycks et al., 2020)</ref>. Our method is complementary to these techniques and could be used in conjunction in order to further increase the generalization and robustness performance.</p><p>Mixup Input mixup creates virtual training examples by linearly interpolating two input data and corresponding onehot labels <ref type="bibr" target="#b38">(Zhang et al., 2018)</ref>. The method induces models to have smoother decision boundaries and reduces overfitting to the training data. Manifold mixup extends this concept from input space to feature space <ref type="bibr" target="#b30">(Verma et al., 2019)</ref>. Also, <ref type="bibr" target="#b9">Guo et al. (2019)</ref> proposed an adaptive mixup method, which improves Input mixup by preventing the generation of improper mixup data. <ref type="bibr" target="#b35">Yun et al. (2019)</ref> proposed CutMix which implants a random rectangular region of the input into another. However, these methods can generate improper examples by randomly removing important regions of the data, which may mislead the neural network (see <ref type="figure" target="#fig_0">Figure 1</ref>). Our mixup method aims to prevent these issues by utilizing the saliency signal while preserving the local properties of the input data.</p><p>Saliency <ref type="bibr" target="#b27">Simonyan et al. (2013)</ref> detects object saliency by computing gradients of a pre-trained deep neural network. Subsequently, other methods were introduced to obtain more precise saliency <ref type="bibr" target="#b40">(Zhao et al., 2015;</ref><ref type="bibr" target="#b32">Wang et al., 2015)</ref>. However, these methods require modifying the pre-trained network or training new models to compute the saliency. <ref type="bibr">Zhou et al. (2016)</ref> and <ref type="bibr" target="#b26">Selvaraju et al. (2017)</ref> proposed methods with the reduced computation cost but at the cost of saliency resolution. We follow the method from <ref type="bibr" target="#b27">Simonyan et al. (2013)</ref>, which does not require any modification to the model, to compute the saliency map. The saliency information has been used in various fields of machine learning <ref type="bibr" target="#b24">(Ren et al., 2013;</ref><ref type="bibr" target="#b33">Wei et al., 2017)</ref>.</p><p>Optimal transport A transport plan that moves a given distribution to another at the minimal cost is called the optimal transport <ref type="bibr" target="#b31">(Villani, 2008)</ref>. Also, the optimal transport with discrete domain can be represented as a linear program or an assignment problem <ref type="bibr" target="#b21">(Munkres, 1957;</ref><ref type="bibr" target="#b31">Villani, 2008)</ref>. The optimal transport problem is widely applied in various applications areas such as color transfer <ref type="bibr" target="#b23">(Rabin et al., 2014)</ref> and domain adaptation <ref type="bibr" target="#b5">(Courty et al., 2016)</ref>. We formulate a binary transport problem for the optimal move, which maximizes the exposed saliency under the mask.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Preliminaries</head><p>Let us define x ∈ X to be an input data and y ∈ Y be its output label. Let D be the distribution over X ×Y. In mixup based data augmentation method, the goal is to optimize the model's loss : X × Y × Θ → R given the data mixup function h(·) and the mixing distribution q as below.</p><formula xml:id="formula_0">minimize θ E (x 0 ,y 0 ),(x 1 ,y 1 )∈D E λ∼q (h(x0, x1), g(y0, y1); θ), (1)</formula><p>where the label mixup function is g(y 0 , y 1 ) = (1 − λ)y 0 + λy 1 . Input mixup uses h(x 0 ,</p><formula xml:id="formula_1">x 1 ) = (1 − λ)x 0 + λx 1 . Mani- fold mixup employs h(x 0 , x 1 ) = (1−λ)f (x 0 )+λf (x 1 ) for some hidden representation f . CutMix defines h(x 0 , x 1 ) = (1 − 1 B ) x 0 + 1 B x 1 for a binary rectangular mask 1 B , where B = [r x , r x + r w ] × [r y , r y + r h ] with λ = rwr h</formula><p>W H and represents the element-wise product. In other words, B is a randomly chosen rectangle covering λ proportion of the input. We propose the following mixup function,</p><formula xml:id="formula_2">h(x0, x1) = (1 − z) Π 0 x0 + z Π 1 x1,<label>(2)</label></formula><p>where z i represents a mask in [0, 1] with mixing ratio λ = 1 n i z i . Π 0 and Π 1 represent n × n transportation plans of the corresponding data with n dimensions. Π ij encodes how much mass moves from location i to j after the transport. From now on, we omit the dependence of y and θ from the loss function for clarity. <ref type="table" target="#tab_1">Table 1</ref> summarizes various mixup functions described above. We begin Section 4 with the formal desiderata for our mixup function and the corresponding optimization objective. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Mixup function h(x0, x1) </p><formula xml:id="formula_3">Input mixup (1 − λ)x0 + λx1 Manifold mixup (1 − λ)f (x0) + λf (x1) CutMix (1 − 1B) x0 + 1B x1 Puzzle Mix (1 − z) Π 0 x0 + z Π 1 x1</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Methods</head><p>Our goal is to maximally utilize the saliency information of each input while respecting the underlying local statistics of the data. First, in order to maximally utilize the saliency information, we seek to find the optimal mixing mask z and the optimal transport plans Π under the following criteria.</p><p>• Given a pair of transported data and a specific region, the mask z should optimally reveal more salient data of the two while masking the less salient one in the given region.</p><p>• Given a data x and the mask z, the transport Π should find the optimal moves that would maximize the saliency of the revealed portion of the data.</p><p>The criteria above motivates us to maximize for (1 − z) Π 0 s(x 0 )+z Π 1 s(x 1 ). Note, we denote the saliency of the input x as s(x) which is computed by taking 2 norm of the gradient values across input channels. <ref type="figure" target="#fig_1">Figure 2</ref> (a) shows the proposed mixup function well preserves the saliency information after mixup. Second, in order to respect the underlying local statistics of the data <ref type="bibr" target="#b14">(Huang &amp; Mumford, 1999;</ref><ref type="bibr" target="#b39">Zhang et al., 2017;</ref><ref type="bibr">Smith, 2003)</ref>, we consider the following criteria.</p><p>• The saliency information can be noisy, which could lead to a suboptimal solution. Therefore, we add spatial regularization terms ψ and φ i,j to control the smoothness of the mask and regional smoothness of the result-ing mixed example. <ref type="figure" target="#fig_1">Figure 2</ref> (b) compares the local smoothness measured in total variation.</p><p>• We ensure the structural integrity within each data is generally preserved by considering the transport cost C ij (defined as the distance between the locations i and j). Also, to further ensure the local salient structure of the data is preserved without being dispersed across after the transport, we optimize for the binary transport plans as opposed to continuous plans.</p><p>Evaluation results on the pretrained vanilla classifier in <ref type="figure">Figure</ref> 2 (c), (d), (e) show our mixup examples have the smallest loss and the highest accuracy compared to other methods, verifying our intuitions above. Moreover, we optimize the main objective after down-sampling the saliency information s(x) with average pooling to support multi-scale transport and masking. From now on, we denote n as the down-sampled dimension. In practice, we select the downsampling resolution randomly per each mini-batch.</p><p>To optimize the mask z, we first discretize the range of the mask value. Let L denote the discretized range { t m | t = 0, 1, . . . , m}. In addition, to control the mixing ratio of given inputs, we add a prior term p(z i ), which follows a binomial distribution. We now formalize the complete objective in Equation <ref type="formula">(3)</ref>.</p><formula xml:id="formula_4">minimize z∈L n Π 0 ,Π 1 ∈{0,1} n×n − (1 − z) Π 0 s(x0) 1 (3) − z Π 1 s(x1) 1 + β (i,j)∈N ψ(zi, zj) + γ (i,j)∈N φi,j(zi, zj) − η i log p(zi) + ξ k=0,1 Π k , C</formula><p>subject to Π k 1n = 1n, Π k 1n = 1n for k = 0, 1. <ref type="table" target="#tab_1">023  024  025  026  027  028  029  030  031  032  033  034  035  036  037  038  039  040  041  042  043  044  045  046  047  048  049  050  051  052  053  054</ref> Saliency Before Transport After Transport Input Before Transport After Transport <ref type="figure" target="#fig_1">Figure 2</ref>. Illustration of our transport process. After the transport, the salient regions (green) replace the other regions within the positive mask, so that the salient information still remains after mixup. The first row represents the saliency information after downsampling, i.e., s(rx`(x)), the masked saliency (z s(rx`(x))), and the masked saliency after transport (z ⇧ | 1 s(rx`(x))). The second row represents the corresponding data. <ref type="figure">Figure 3</ref>. Illustration of Puzzle Mix process. After the transport, the salient regions (highlighted in green) replace the other regions, so that the salient information still remains after the mixup. The first row represents the saliency information after down-sampling, i.e., s(x), the masked saliency (z s(x)), and the masked saliency after transport (z Π s(x)) respectively. The second row shows the corresponding data.</p><p>After solving the optimization problem in Equation <ref type="formula">(3)</ref>, we obtain the mixed example h(x 0 ,</p><formula xml:id="formula_5">x 1 ) = (1 − z * ) Π * 0 x 0 + z * Π * 1</formula><p>x 1 which is then used for the model training as in Equation <ref type="formula" target="#formula_22">(1)</ref>. <ref type="figure">Figure 3</ref> illustrates the mask z and the transport plan Π optimized with Equation <ref type="formula">(3)</ref>.</p><p>We solve this optimization problem via alternating minimization through iterating first over z and then simultaneously over Π 0 and Π 1 . In mixup augmentation, however, one needs to be able to efficiently generate the mixed examples as the generation process takes place per each mini-batch. Therefore, we optimize for one complete cycle of the alternating minimization, as repeated cycles require additional network evaluations, for efficiency. As for the initialization, we optimize the mask z with Π k initialized as identity transport, and then optimize each Π k with the previously solved z. We now formally discuss individual optimization problems in Section 4.1 and Section 4.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Optimizing Mask</head><p>Given Π 0 and Π 1 , we seek to solve the following discrete optimization problem over z in Equation (4). The objective is to decide how to best mix the two transported inputs jointly based on the region saliency measure (unary), the label and data local smoothness (pairwise), and the mixing weight log prior (mix prior) criteria.  where the unary term</p><formula xml:id="formula_6">minimize z∈L n i ui(zi) + β (i,j)∈N ψ(zi, zj) (4) + γ (i,j)∈N φi,j(zi, zj) − η i log p(zi), ψ(0, 1) u j (1) u j (0) φ i,j (0, 1) i j i j x 0 x 1 h(x 0 , x 1 ) φ i,j (0, 0) φ i,j (1, 1)</formula><formula xml:id="formula_7">u i (z i ) is defined as z i (Π 0 s(x 0 )) i + (1 − z i )(Π 1 s(x 1 )) i .</formula><p>We define the neighborhood N as a set of adjacent regions, and use the following pairwise terms and the prior term. <ref type="figure" target="#fig_2">Figure 4</ref> visualizes different components in Equation <ref type="formula">(4)</ref>.</p><formula xml:id="formula_8">Definition 1. (Label smoothness) ψ(z i , z j ) := (z i − z j ) 2 .</formula><p>For data local smoothness, we measure the distance between input regions. Let d p denote the distance function. First, we define pairwise terms under the binary case, L = {0, 1}, and then extend them to the multi-label case.</p><p>Definition 2. (Data local smoothness for binary labels) Let x k,i represent the i th region of data x k . Then, <ref type="formula">(4)</ref> is a type of multi-label energy minimization problem and can be efficiently solved via α-β swap algorithm <ref type="bibr" target="#b3">(Boykov et al., 2001)</ref>, which is based on the graph-cuts. In the binary label case, finding the minimum s-t cut in the graph returns an equivalent optimal solution if the pairwise term satisfies the submodularity condition <ref type="bibr" target="#b17">(Kolmogorov &amp; Zabih, 2004)</ref>. In our problem, the pairwise term is</p><formula xml:id="formula_9">φ b i,j (z i , z j ) := d p (x zi,i , x zj ,j ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The discrete optimization problem in Equation</head><formula xml:id="formula_10">e i,j (z i , z j ) = βψ(z i , z j )+ γφ i,j (z i , z j )</formula><p>. We now assume that the function values of d p are bounded in [0,1], which is generally satisfied when data values are bounded in [0,1].</p><formula xml:id="formula_11">Proposition 1. Suppose d p function is bounded in [0,1] and φ = φ b . If γ ≤ β, then e i,j (z i , z j ) satisfies submodularity for z i , z j ∈ {0, 1}.</formula><p>Proof. e(0, 0)+e(1, 1) = γφ i,j (0, 0)+γφ i,j (1, 1) ≤ 2γ ≤ 2β = βψ(0, 1) + βψ(1, 0) ≤ e(0, 1) + e(1, 0).</p><p>For multi-label case, the α-β swap algorithm iteratively applies graph-cut as a sub-routine and converges to a local-minimum if the pairwise term satisfies pairwisesubmodularity <ref type="bibr" target="#b25">(Schmidt &amp; Alahari, 2011)</ref>. We can guarantee pairwise-submodularity by slightly modifying</p><formula xml:id="formula_12">φ b i,j as φ b i,j (0, 0) = φ b i,j (0, 0) + (φ b i,j (0, 1) + φ b i,j (1, 0))/2 φ b i,j (0, 1) = φ b i,j (0, 1) + (φ b i,j (0, 0) + φ b i,j (1, 1))/2 φ b i,j (1, 0) = φ b i,j (1, 0) + (φ b i,j (0, 0) + φ b i,j (1, 1))/2 φ b i,j (1, 1) = φ b i,j (1, 1) + (φ b i,j (0, 1) + φ b i,j (1, 0))/2. It is important to note that, φ b i,j (1, 0) + φ b i,j (0, 1) − φ b i,j (0, 0) − φ b i,j (1, 1) = 0. Definition 3. (Data local smoothness for the multi labels) φ i,j (z i , z j ) := z i z j φ b i,j (1, 1) + z i (1 − z j )φ b i,j (1, 0) + (1 − z i )z j φ b i,j (0, 1) + (1 − z i )(1 − z j )φ b i,j (0, 0), ∀ z i , z j ∈ L.</formula><p>Proposition 2. With φ i,j defined as Definition 3, e i,j satisfies pairwise submodularity.</p><p>Proof. We can represent φ i,j as follows:</p><formula xml:id="formula_13">φi,j(zi, zj) = f (zi, zj) φ b i,j (1, 0) + φ b i,j (0, 1) − φ b i,j (0, 0) − φ b i,j (1, 1) 2 + zi φ b i,j (1, 0) + φ b i,j (1, 1) − φ b i,j (0, 0) − φ b i,j (0, 1) 2 + zj φ b i,j (0, 1) + φ b i,j (1, 1) − φ b i,j (0, 0) − φ b i,j (1, 0) 2 + φ b i,j (0, 0), where f (z i , z j ) = (1 − z i )z j + z i (1 − z j ). By definition φ b i,j (1, 0) + φ b i,j (0, 1) − φ b i,j (0, 0) − φ b i,j (1, 1) = 0, and thus, φ i,j (z i , z j ) can be represented as the form of z i φ b 1 i,j + z j φ b 2 i,j + c. Thus, ∀ x, y ∈ L, φ i,j (x, y) + φ i,j (y, x) = xφ b 1 i,j +yφ b 2 i,j +c+yφ b 1 i,j +xφ b 2 i,j +c = φ i,j (x, x)+φ i,j (y, y), which means φ i,j satisfies pairwise submodularity.</formula><p>By definition ψ satisfies pairwise submodularity, and by Lemma 1, e i,j satisfies pairwise submodularity.</p><p>Lemma 1. If ψ, φ satisfies pairwise submodularity and β, γ ∈ R + , then βψ + γφ satisfies pairwise submodularity. Proof. See Supplementary A.1. Finally, we use the prior term to control the ratio of inputs in the mixed output. For the given mixing weight λ, which represents the ratio of x 1 with respect to x 0 , we define the prior term p to satisfy E zi∼p [z i ] = λ, ∀i. Specifically, for the label space L = { t m | t = 0, ..., m}, we define the prior term as p(z i = t m ) = m t λ t (1−λ) m−t for t = 0, 1, ..., m. In other words, z i ∼ 1 m B(m, λ). In <ref type="figure" target="#fig_4">Figure 5</ref>, we provide the resulted mixup images using the optimal mask from Equation <ref type="formula">(4)</ref>. Specifically, we visualize how the Puzzle Mix images change by increasing the mixing weight λ and the coefficients of the smoothness terms, β and γ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Optimizing Transport</head><p>After optimizing the mask z, we optimize the transportation plans for the input data under the optimal mask z * . Our objective with respect to transportation plans is the following.</p><formula xml:id="formula_14">minimize Π 0 ,Π 1 ∈{0,1} n×n − (1 − z * ) Π 0 s(x0) 1 − (z * Π 1 s(x1) 1 + ξ k=0,1 Π k , C</formula><p>subject to Π k 1n = 1n, Π k 1n = 1n for k = 0, 1.</p><p>Note the problem is completely separable as two independent optimization problems of each Π k . Let s(x 1 ) i Algorithm 1 Masked Transport</p><formula xml:id="formula_15">Input: mask z * , cost C , large value v Initialize C (0) = C , t = 0 repeat target = argmin(C (t) , dim = 1) Π = 0 n×n for i = 0 to n − 1 do Π[i, target[i]] = 1 end for C conf lict = C (t) Π + v(1 − Π) source = argmin(C conf lict , dim = 0) Π win = 0 n×n for j = 0 to n − 1 do Π win [source[j], j] = 1 end for Π win = Π win Π Π lose = (1 − Π win ) Π C (t+1) = C (t) + vΠ lose t = t + 1 until convergence Return: Π win denote the i th entry of the n-dimensional column vector s(x 1 ). The term z * Π 1 s(x 1 ) 1 can be represented as i,j z * j s(x 1 ) i Π 1i,j = Π 1 , s(x 1 )z * . Finally, the trans- port optimization problem of Π 1 becomes minimize Π 1 ∈{0,1} n×n Π1, C<label>(5)</label></formula><p>subject to Π11n = 1n, Π 1 1n = 1n,</p><p>where C = ξC − s(x 1 )z * . C ij is the cost of moving the i th region to the j th position, which consists of two components. The first component is the distance ξC ij , which is defined as a distance from i to j. The second component is the saliency term, which discounts the transport cost with the saliency value of the i th region if the mask of j th position is non-zero. Briefly speaking, the larger the saliency value, the more the discount in the transport cost.</p><p>The optimization problem in Equation <ref type="formula" target="#formula_15">(5)</ref> can be solved exactly by using the Hungarian algorithm and its variants with time complexity of O(n 3 ) <ref type="bibr" target="#b21">(Munkres, 1957;</ref><ref type="bibr" target="#b15">Jonker &amp; Volgenant, 1987)</ref>. As we need to efficiently generate mixup examples per each mini-batch, this can be a computational bottleneck as n increases. Thus, we propose an approximate algorithm that can be parallelized on GPUs and efficiently computed in batches. The proposed algorithm can quickly decrease the objective Π, C and converges to a localminimum within n(n − 1)/2 + 1 steps. Experimental results comparing the wall clock execution time and the relative error are in Supplementary B.</p><p>Algorithm 1 progressively alternates between row-wise and column-wise optimizations. The algorithm first minimizes Π, C only with the Π1 n = 1 n constraint. However, since the optimization is done without the column constraint, there can be multiple 1 values in a column of Π. In the following step, the column with multiple 1 values leaves only one 1 in the row with the smallest cost. We denote the result as Π win in Algorithm 1. The corresponding cost entries for the rows that do not remain in Π win are penalized with a large additive value, and the 1 values are moved to the other columns in the next iteration.</p><p>Our algorithm can also take advantage of intermediate Π win as a solution, supported by the following two properties. We suppose that transport cost matrix C has zeros in diagonal entries and positive values in others. In addition, let Π (t) and Π</p><p>win denote Π and Π win at the end of t th step in Algorithm 1.</p><formula xml:id="formula_17">Proposition 3. Suppose z * has values in {0, 1}. Then for j s.t. z * j = 1, j th column of Π (t)</formula><p>win has exactly one 1.</p><p>Proof. By the definition of C (0) = ξC − s(x 0 )z * , for j s.t. z * j = 1, j th row of C (0) has a minimum at j th entry. Thus, j th column of Π (0) win has exactly one 1 and others are 0. Suppose that, the claim is satisfied for Π</p><formula xml:id="formula_18">(t) win and Π (t) win [i(j), j] is 1 for j s.t. z * j = 1. Then, by the definition of Π (t) win , C (t) win [i(j)</formula><p>, j] is the minimum of i(j) th row of C (t) and the row will not be updated in C (t+1) . Thus, i(j) th row of C (t+1) has a minimum at j th entry and j th column of Π (t+1) win has exactly one 1. By induction, the claim holds.</p><p>Proposition 4. Under the assumption of Proposition 3, the partial objective &lt; Π (t) win , C z * &gt; decreases as t increases.</p><p>Proof. By Proposition 3, for j s.t. z * j = 1, j th column of Π (t) win has exactly one 1. Let i(j; t) denote the corresponding row index with the entry 1. Then, it is enough to prove that C [i(j; t + 1), j] ≤ C [i(j; t), j]. However, in the last part of the proof of Proposition 3, we showed that i(j; t) th row of C (t+1) has a minimum at j th entry, and thus Π (t+1) [i(j; t), j] = 1. By Algorithm 1, index</p><formula xml:id="formula_19">i(j; t + 1) satisfies C (t+1) [i(j; t + 1), j] ≤ C (t+1) [i, j], ∀i s.t. Π (t+1) [i, j] = 1. Thus, C (t+1) [i(j; t + 1), j] ≤ C (t+1) [i(j; t), j]. Finally, Π (t+1) [i, j] = 1 means that cost from i to j is not updated, i.e., C (t+1) [i, j] = C [i, j].</formula><p>Finally, we introduce the convergence property of Algorithm 1.</p><p>Proposition 5. Algorithm 1 converges to a local-minimum with respect to the update rule at most n(n − 1)/2 + 1 steps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proof. See Supplementary A.2.</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 2 Stochastic Adversarial Puzzle Mix</head><p>Input: data x 0 , x 1 , attack ball , step τ , probability p x i,clean = x i for i = 0, 1 Sample ν i ∼ B(1, p) for i = 0, 1</p><formula xml:id="formula_20">for i = 1, 2 do if ν i == 1 then κ i ∼ U nif orm(− , ) x i ← x i + κ i end if end for Calculate gradient ∇ x l(x i ) for i = 0, 1 Optimize z * and Π * i in Equation (3) Sample δ ∼ U nif orm(0, 1) for i = 0, 1 do if ν i == 1 then κ i ← κ i + τ sign(∇ x l(x i )) κ i ← clip(κ i , − , ) x i ← x i,clean + δ κ i end if end for Return: (1 − z * ) Π * 0 x 0 + z * Π * 1 x 1</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Adversarial Training</head><p>Since our mix-up strategy utilizes the gradients of the loss function with respect to the given inputs for saliency computation, we can incorporate adversarial training in our mix-up method without any additional computation cost.</p><p>For adversarial training on mixup data, we adapt the fast adversarial training method of <ref type="bibr">Wong et al. (2020)</ref>, which adds a uniform noise before creating an adversarial perturbation. As shown in Algorithm 2, we add the adversarial perturbation to the proper location of the mixed output, i.e., adding an adversarial signal to the corresponding input and location specified by z. Note that the adversarial perturbation is added to each data probabilistically to prevent possible degradation in the generalization performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Implementation Details</head><p>First, to solve the discrete optimization problem with respect to the mask z, we use α-β swap algorithm from the pyGCO python wrapper 1 . Although the minimization is performed example-wise in CPUs, the α-β swap algorithm converges quickly, since we restrict the size of the graph with downsampling. Note that, in our experiments, the computational bottleneck of the method is in the forward-backward passes of the neural network. In our experiments, we use label space L = {0, 1 2 , 1}. In addition, we randomly sample the size of the graph, i.e., size of mask z, from {2 × 2, 4 × 4, 8 × 8, 16 × 16}, and down-sample the given mini-batch 1 https://github.com/Borda/pyGCO for all experiments.</p><p>We normalize the down-sampled saliency map, which is used as the unary term, to sum up to 1. This allows us to use consistent hyperparameters across all the models and datasets. To measure the distance between the two adjacent data regions, we compute the mean of the absolute values of differences on the boundaries. For the mixing ratio λ, we randomly sample λ from Beta(α, α) at each mini-batch. All of the computations in our algorithm except α-β swap are done in mini-batch and can be performed in parallel in GPUs. Note that for-loops in Algorithm 1 can be done in parallel by using the scatter function of PyTorch <ref type="bibr" target="#b22">(Paszke et al., 2017)</ref>.</p><p>Since we calculate the saliency information by backpropagating the gradient of loss function through the model, we can utilize this gradient information without any computational overhead. We regularize the gradient of the model with mixup data as ∇ θ (h(x 0 , x 1 ), g(y 0 , y 1 ); θ) + 1 2 λ clean (∇ θ (x 0 , y 0 ; θ) + ∇ θ (x 1 , y 1 ; θ)). This additional regularization helps us to improve generalization performance on Tiny-ImageNet and ImageNet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Experiments</head><p>We train and evaluate classifiers on CIFAR-100 <ref type="bibr" target="#b18">(Krizhevsky &amp; Geoffrey, 2009</ref>), Tiny-ImageNet <ref type="bibr" target="#b4">(Chrabaszcz et al., 2017)</ref>, and ImageNet <ref type="bibr" target="#b6">(Deng et al., 2009)</ref> datasets. We first study the generalization performance and adversarial robustness of our method (Section 6.1). Next, we show that our method can be used in conjunction with the existing augmentation method (AugMix) to simultaneously improve the corruption robustness and generalization performance (Section 6.2). Finally, we perform ablation studies for our method (Section 6.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Generalization Performance and Adversarial Robustness</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.1.">CIFAR-100</head><p>We train two residual neural networks <ref type="bibr" target="#b10">(He et al., 2015)</ref>: WRN28-10 (Zagoruyko &amp; Komodakis, 2016) and PreAc-tResNet18 <ref type="bibr" target="#b11">(He et al., 2016)</ref>. We follow the training protocol of <ref type="bibr" target="#b30">Verma et al. (2019)</ref>, which trains WRN28-10 for 400 epochs and PreActResNet18 for 1200 epochs. Hyperparameter settings are available in Supplementary C.1. We reproduce the mixup baselines <ref type="bibr" target="#b38">(Zhang et al., 2018;</ref><ref type="bibr" target="#b30">Verma et al., 2019;</ref><ref type="bibr" target="#b35">Yun et al., 2019;</ref><ref type="bibr" target="#b13">Hendrycks et al., 2020)</ref> and compare the baselines with our method under the same experimental settings described above. We denote the experiments as Vanilla, Input, Manifold, CutMix, AugMix, Puzzle Mix in the experiment tables.</p><p>Note however, our mixup method requires an additional forward-backward evaluation of the network per mini-batch to calculate the saliency signal. For some practitioners, a fairer comparison would be to compare the performances at a fixed number of network evaluations (i.e. for power conservation). In order to compare our method in this condition, we also test our method trained for half the epochs and with twice the initial learning rate. We denote this experiment as Puzzle Mix (half) in the experiment tables.</p><p>In addition, we report experiments with the adversarial training described in Algorithm 2 with p = 0.1. We denote this experiment as Puzzle Mix (adv) in the tables. We assess the adversarial robustness against FGSM attack of 8/255 ∞ epsilon ball following the evaluation protocol of <ref type="bibr" target="#b38">Zhang et al. (2018)</ref>; <ref type="bibr" target="#b30">Verma et al. (2019)</ref>; <ref type="bibr" target="#b35">Yun et al. (2019)</ref> for fair comparison. The results are summarized in <ref type="table" target="#tab_2">Table 2</ref> and <ref type="table">Table 3</ref>, and adversarial robustness results against the PGD attack <ref type="bibr" target="#b20">(Madry et al., 2017)</ref> are in Supplementary D.2.</p><p>We observe that Puzzle Mix outperforms other mixup baselines in generalization and adversarial robustness with WRN28-10 ( </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Robustness Against Corruption</head><p>Hendrycks et al. <ref type="formula" target="#formula_2">(2020)</ref> proposed AugMix which performs Input mixup between clean and augmented images to improve robustness against corrupted datasets as well as the generalization performance. AugMix uses Jensen-Shannon divergence (JSD) between network outputs of a clean image and two AugMix images as a consistency loss. However, computing the JSD term requires triple the network evaluations compared to other mixup methods to train the network.</p><p>We found that simply using our mixup algorithm between two AugMix images, improves both the generalization and corruption robustness over the training strategy with the JSD objective. Note that our method requires only one additional (versus two) network evaluation per each mini-batch. We denote this experiment setting as Puzzle Mix (aug).</p><p>We use CIFAR-100-C dataset <ref type="bibr" target="#b12">(Hendrycks &amp; Dietterich, 2019)</ref> to evaluate the corruption robustness. The dataset consists of 19 types of corruption, including noise, blur, weather, and digital corruption types. In <ref type="table">Table 7</ref>, we report average test errors on CIFAR-100-C dataset as well as test errors on the clean CIFAR-100 test dataset. <ref type="table">Table 7</ref> demonstrates that our method using AugMix images improves both the generalization performance and the corruption accuracy by 3.95% and 2.31% each over AugMix baseline.  <ref type="table">Table 7</ref>. Top-1 / Corruption error rates on CIFAR-100 and CIFAR-100-C on WRN28-10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.">Ablation Study</head><p>The generalization performance of Puzzle Mix stems from saliency-based multi-label masking and transport. We verified the effectiveness of these two factors in comparative experiments on CIFAR-100 with WRN28-10.  <ref type="table" target="#tab_4">Table 8</ref>. Top-1 / Top-5 rates on CIFAR-100 dataset of WRN28-10 trained with our mixup methods.</p><p>We also verify the effects of different factors in stochastic adversarial training. In Algorithm 2, we add an adversarial perturbation to each data based on each Bernoulli sample ν i and apply linear decay with δ sampled from the uniform distribution. From <ref type="table">Table 9</ref>, we observe that using two independent random variables ν 0 and ν 1 (adv) has significant improvement in adversarial robustness over using one variable (ν 0 = ν 1 ). In the absence of linear decaying (fgsm), there is improvement in the FGSM error rate of 4.02%, but the Top-1 error increases by 0.41%. In all experiments, p is set to 0.1. We use FGSM attack of 8/255 ∞ epsilon-ball and 7-step PGD attack with a 2/255 step size. Additional experiments regarding the effect of p value in adversarial training are available in Supplementary D.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusion</head><p>We have presented Puzzle Mix, a mixup augmentation method for optimally leveraging the saliency information  A.2. Proof of Proposition 5</p><p>Proposition 5. Algorithm 1 converges to a local-minimum with respect to the update rule at most n(n − 1)/2 + 1 steps.</p><p>Proof. Let C (0) has a minimum at (i 1 , j 1 ). Then, ∀t = 0, 1, ..., Π</p><p>win [i 1 , j 1 ] = 1. Next, let's define I 2 = {(i, j)|i = i 1 , j = j 1 } and (i 2 , j 2 ) = argmin (i,j)∈I2 C (1) <ref type="bibr">[i, j]</ref>. If Π (0) [i 2 , j 1 ] = 1, C (0) [i 2 , j 1 ] will be added by the large value, and thus, Π</p><formula xml:id="formula_22">win [i 2 , j 2 ] = 1. Otherwise, if Π (0) [i 2 , j 1 ] = 0, then C (0) [i 2 , j 2 ] ≤ C (0) [i 2 , j 1 ] and Π (0)<label>(1)</label></formula><p>win [i 2 , j 2 ] = 1. By the definition of (i 2 , j 2 ), ∀t ≥ 1, Π (t) win [i 2 , j 2 ] = 1. To use induction, let's define I k = {(i, j)|i / ∈ {i 1 , ..., i k−1 }, j / ∈ {j 1 , ..., j k−1 }} and let a k−1 denote a minimal step number at which Π (t)</p><formula xml:id="formula_23">win [i k−1 , j k−1 ] = 1, ∀t ≥ a k−1 . Let's define (i k , j k ) = argmin (i,j)∈I k C (a k−1 +1) [i, j]. If ∃j ∈ {j 1 , ..., j k−1 }, Π (a k−1 ) win [i k , j] = 1, then ∀t ≥ a k−1 + k − 1, Π (t) win [i k , j k ] = 1. If not, Π (a k−1 ) win [i k , j k ] = 1, and ∀t ≥ a k−1 , Π (t) win [i k , j k ] = 1. Thus, a k ≤ a k−1 + k − 1.</formula><p>Finally, by induction, a n ≤ n(n − 1)/2 which means there are no more updates of Π win after n(n−1)/2+1 steps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Analysis of Algorithms</head><p>B.1. Comparison Experiments for Algorithm 1 <ref type="figure" target="#fig_6">Figure 6</ref> and <ref type="figure" target="#fig_7">Figure 7</ref> show the comparison results of Algorithm 1 with the exact Hungarian algorithm on 100 random samples per each vertex size n. Note that, the size of a transport plan is n × n. In the simulation, we generate a random cost matrix C = C − s(x)z , where s(x) is sampled from a uniform distribution and the mask z is sampled from a bernoulli distribution with probability p = 0.5. In the case of n = 1024, Algorithm 1 is about 8.6 times faster than the exact algorithm, with relative error of 0.0005. For comparison, we use lapjv solver from library 2 as the exact optimizer, which to the best of our knowledge is the fastest solver. In addition to the simulation test, we train classifiers with ten different random seeds to compare the Top-1 accuracy between using the Hungarian algorithm and Algorithm 1. In this experiment, we train WRN28-10 on CIFAR100 for 400 epochs. In summary, the mean difference of the Top-1 accuracy is −0.025, with a standard deviation of 0.239. Besides, we perform a two-sided paired t-test to check the statistical insignificance. As a result, T-statistics is -0.105 with a P-value of 0.919, which means there is no evidence for a statistical difference between the two methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2. Convergence of Alternating Minimization</head><p>We solve the optimization problem of a mask and transport plans via alternating minimization for one-cycle for computational efficiency. In this subsection, we analyze the convergence property of the alternating algorithm by optimizing 1,000 CIFAR100 image pairs with various numbers of regions. As a result, we observe that the most of optimal masks of the images are not changed after the first cycle (i.e., comparison between one-cycle and multi-cycle), and hence the optimal transport plans are not changed. For transport cost coefficient ξ in [0.5, 0.8], which shows the best performance, less than 0.2% of the final mixed images change after the first cycle. Also, the ratio of pixels changed after the first cycle is less than 0.001%.</p><p>We believe that this result is due to the mutual complement of the optimal mask and the optimal transport. That is, the optimal mask assigns the output regions so that the remained saliency of each input is maximized, and the transport enhances the assignment. Therefore, after a cycle, there is little room for a change of the optimal mask when the optimization is performed again.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Hyperparameter Settings</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.1. CIFAR-100</head><p>We train models via stochastic gradient descent (SGD) with initial learning of 0.1 decayed by factor 0.1 at epochs 200 and 300 for WRN28-10 and epochs 400 and 800 for PreAc-tResNet18. We set the momentum as 0.9 and add a weight decay of 0.0001. Mixing weight λ is randomly sampled from <ref type="figure" target="#fig_0">Beta(1, 1)</ref> for all experiments except Manifold mixup, which uses Beta(2, 2) in the original paper. Puzzle Mix has hyperparameters of β for the label smoothness term, γ for the data smoothness term, η for the prior term, and ξ for the transport cost. In the CIFAR-100 experiment, we use (β, γ, η, ξ) = (1.2, 0.5, 0.2, 0.8). For adversarial training, we use 10/255 epsilon-ball with the step size τ of 12/255 according to the step size protocol of <ref type="bibr">Wong et al. (2020)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2. Tiny-ImageNet</head><p>We follow the training protocol of <ref type="bibr" target="#b30">Verma et al. (2019)</ref> except for the learning schedule. <ref type="bibr" target="#b30">Verma et al. (2019)</ref> train Tiny-ImageNet for 2000 epochs with an initial learning rate of 0.1, but we train models for 1200 epochs with an initial learning rate of 0.2. As in the CIFAR-100 experiment, we use SGD and decay learning rate by factor 0.1 at epochs 600 and 900. We set momentum as 0.9 and weight decay as 0.0001. In case of mixing weight λ, for Input mixup and Manifold mixup, we follow the setting α = 0.2 as described in Manifold mixup <ref type="bibr" target="#b30">(Verma et al., 2019)</ref>. For CutMix, we choose α = 0.2, which showed the best performance among [0.2, 0.5, 1.0], and for Puzzle Mix, we use α = 1.0. In the Tiny-ImageNet experiment, we use (β, γ, η, ξ) = (1.2, 0.5, 0.2, 0.8), which is the same with the CIFAR-100 experiment. However, we apply regularization using clean input with λ clean = 1 for all experiments regarding Puzzle Mix, and use the same initial learning rate of 0.2 for Puzzle Mix (half).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.3. ImageNet</head><p>For ImageNet, we modify the training protocol in <ref type="bibr">Wong et al. (2020)</ref> and train models for 100 epochs. The learning rate starts from 0.5, linearly increases to 1.0 for 8 epochs, and linearly decreases to 0.125 until 15 th epoch. Then, the learning rate jumps to 0.2 and linearly decreases to 0.02 until 40 th epoch, 0.002 until 65 th epoch, 0.0002 until 90 th epoch, and 0.00002 until 100 th epoch. In addition, we resize images to 160×160 for the first 15 epochs, and use images pre-resized to 352×352 for the next 85 epochs following the prescription in <ref type="bibr">Wong et al. (2020)</ref>. Mixing distribution parameter α is 0.2, 0.2, 1.0, 1.0 each for Input mixup, Manifold mixup, CutMix, Puzzle Mix, which follows the settings of the original papers. In the case of Manifold mixup, there is no experiments on ImageNet, and thus, we tune α in [0.2, 1.0] and report the best result. In the case of ImageNet, we use hyperparameter (β, γ, η, ξ) = (1.5, 0.5, 0.2, 0.8) and apply clean input regularization of λ clean = 1 for the first 40 epochs. For the experiment following the experimental setting of CutMix <ref type="bibr" target="#b35">(Yun et al., 2019)</ref>, we use the same hyperparameter without the clean input regularization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.4. Hyperparameter Sensitivity</head><p>We analyze the sensitivity of the hyperparameters with WRN28-10 on CIFAR100 trained for 400 epochs. In detail, we sweep hyperparameters one by one while others being fixed, and calculate the mean and standard deviation of Top-1 accuracy. Note that, the hyperparameter setting (β, γ, η, ξ) of the main experiment is (1.2, 0.5, 0.2, 0.8) which achieves 15.95% Top-1 test error. <ref type="table" target="#tab_1">Table 10</ref> shows the mean Top-1 error rates and standard deviations of various hyperparameter settings. From the table, we can find that there exists a well of hyperparameters of which performance is superior to that of baselines (manifold mixup: 17.40%).  <ref type="table" target="#tab_1">Table 10</ref>. Mean Top-1 error rates and standard deviations (SD) for various hyperparameter settings on CIFAR 100 with WRN28-10. For β, γ, and ξ, we sweep the range with 0.1 step size, and for η, we sweep the range with 0.05 step size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Effect of Adversarial Training</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.1. Trade-off between Generalization and Adversarial Robustness</head><p>Since adversarial training increases the adversarial robustness at the expense of clean accuracy <ref type="bibr" target="#b20">(Madry et al., 2017)</ref>, we introduced adversarial probability p, a probability of whether to add adversarial perturbation or not, to control the intensity of adversarial training. <ref type="table" target="#tab_1">Table 11</ref> shows the inverse relationship between clean error and FGSM error.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2. Robustness against PGD Attack</head><p>We test the adversarial robustness of various mixup methods against the PGD attack <ref type="bibr" target="#b20">(Madry et al., 2017)</ref>. In this experiment, we train PreActResNet18 on CIFAR-100 with each mixup method and test with PGD attack of 4/255 l ∞ epsilon-ball with 2/255 step size. For comparison, we test Puzzle Mix with stochastic adversarial training of p = 0.1, which outperforms other baselines at Top-1 Accuracy given a clean test dataset. <ref type="figure" target="#fig_8">Figure 8</ref> demonstrates that Puzzle Mix is more robust against the PGD attack than the existing mixup methods. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Puzzle Mix Qualitative Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.1. Effect of Prior and Smoothness Term</head><p>In this section, we provide Puzzle Mix results while adjusting the hyperparameters associated with the optimal mask. In <ref type="figure">Figure 9</ref>, we visualize how the Puzzle Mix images change by increasing the mixing weight λ, and in <ref type="figure" target="#fig_0">Figure 10</ref>, we visualize how the results change as we increase the coefficients of the smoothness terms, β and γ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.2. More Samples</head><p>In this section, we provide Puzzle Mix results with various resolutions of the optimal mask and transport. <ref type="figure" target="#fig_0">Figure 11</ref> visualizes the Puzzle Mix results along with the given inputs.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>A visual comparison of the mixup methods. Puzzle Mix ensures to contain sufficient saliency information while preserving the local statistics of each input.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>(a) Mixed saliency ||h(s(x0), s(x1))||1. Note the saliency map of each input s(x k ) is normalized to sum up to 1. (b) Total variation of mixed data. (c) Cross entropy loss of mixup data and the corresponding soft-label evaluated by the vanilla classifier (ResNet18). (d) Top-1 prediction accuracy of mixed data. Prediction is counted as correct if the Top-1 prediction belongs to {y0, y1}. (e) Top-2 prediction accuracy of mixed data. Prediction is counted as correct if the Top-2 predictions are equal to {y0, y1}. Manifold mixup is omitted in (a) and (b) as manifold mixup generates mixup examples in the hidden space not in the input space.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 .</head><label>4</label><figDesc>Visualization of different components in the mask optimization. Two rectangles in the top show the two inputs x0 and x1, and the rectangle in the bottom show the mixed output h(x0, x1).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Figure reproducedwith permission from Julien Mairal.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 .</head><label>5</label><figDesc>(Top row) Puzzle Mix images with increasing mixing weight λ. (Bottom row) Puzzle Mix images with increasing smoothness coefficients, β and γ. Note that the results are obtained without transport.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>If ψ, φ satisfy pairwise submodularity and β, γ ∈ R + , then βψ + γφ satisfies pairwise submodularity. Proof. By the assumption, β, γ ∈ R + , and by using pairwise submodularity of ψ and φ, ∀x, y ∈ L, (βψ + γφ)(x, x) + (βψ + γφ)(y, y) = β(ψ(x, x) + ψ(y, y)) + γ(φ(x, x) + φ(y, y)) ≤ β(ψ(x, y) + ψ(y, x)) + γ(φ(x, y) + φ(y, x)) = (βψ + γφ)(x, y) + (βψ + γφ)(y, x).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 .</head><label>6</label><figDesc>Comparison of average execution time (log-log scale) to solve Equation (5) between the exact solver (black) and Algorithm 1 (blue). Execution times are mean of 100 trials.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 .</head><label>7</label><figDesc>Relative errors of objective function value f between Algorithm 1 (alg) and random assignment (random). Relative error is calculated as ea/(ea + er), where ea = f alg − fexact, er = f random − fexact.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 8 .</head><label>8</label><figDesc>Adversarial robustness of various mixup methods against the PGD attack.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Department of Computer Science and Engineering, Seoul National University, Seoul, Korea 2 Neural Processing Research Center. Correspondence to: Hyun Oh Song &lt;hyunoh@snu.ac.kr&gt;. Proceedings of the 37 th International Conference on Machine Learning, Online, PMLR 119, 2020. Copyright 2020 by the author(s).</figDesc><table><row><cell>000</cell></row></table><note>1</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>Summary of various mixup functions.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2</head><label>2</label><figDesc>Puzzle Mix improves Top-1 test error over the best performing baseline by 1.45%, and Puzzle Mix (half) outperforms by 1.17%. Puzzle Mix (adv) improves FGSM error rate over 8.41% than AugMix while achieving 1.39% lower Top-1 error rate than Manifold mixup, which had the best Top-1 score among baselines. We observe similar results with PreActResNet18. Puzzle Mix (adv) reduces the Top-1 error rate by 1.14% and the FGSM error rate by 12.98% over baselines.Puzzle Mix shows the best performance in both Top-1 / Top-5 error rate, achieving 0.43%, 0.24% improvement each, compared to the best baseline(Table 5).</figDesc><table><row><cell>WRN28-10, Method</cell><cell cols="4">) and PreActResNet18 (Table 3). With Top-1 Top-5 FGSM Error(%) Error(%) Error(%)</cell></row><row><cell>Vanilla Input Manifold Manifold † CutMix AugMix</cell><cell></cell><cell>21.14 18.27 17.40 18.04 17.50 20.44</cell><cell>6.33 4.98 4.37 -4.69 5.74</cell><cell>63.92 56.60 60.70 -79.34 55.59</cell></row><row><cell>Puzzle Mix Puzzle Mix (half)</cell><cell></cell><cell>15.95 16.23</cell><cell>3.92 3.90</cell><cell>63.71 66.74</cell></row><row><cell cols="2">Puzzle Mix (adv) Puzzle Mix (half, adv)</cell><cell>16.01 16.39</cell><cell>3.91 3.94</cell><cell>47.18 46.95</cell></row><row><cell cols="5">Table 2. Top-1 / Top-5 / FGSM error rates on CIFAR-100 dataset</cell></row><row><cell cols="5">of WRN28-10 trained with various mixup methods (400 epochs).</cell></row><row><cell cols="5">† denotes the result reported in the original paper. Top-1 and Top-5 results are median test errors of models in the last 10 epochs.</cell></row><row><cell cols="2">6.1.2. TINY-IMAGENET</cell><cell></cell><cell></cell></row><row><cell cols="5">We train PreActResNet18 network on Tiny-ImageNet dataset, which contains 200 classes with 500 training im-ages and 50 test images per class with 64 × 64 resolution (Chrabaszcz et al., 2017). Training settings are described in</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 8</head><label>8</label><figDesc></figDesc><table><row><cell cols="3">shows that Puzzle Mix with the binary label space (binary) has 1.44% higher Top-1 error rate than multi-label case, and Puzzle Mix without transport (mask only) has 0.43% higher Top-1 error rate than Puzzle Mix with transport.</cell></row><row><cell>Method</cell><cell>Top-1 Error(%)</cell><cell>Top-5 Error(%)</cell></row><row><cell>Vanilla</cell><cell>21.14</cell><cell>6.33</cell></row><row><cell>Puzzle Mix Puzzle Mix (binary) Puzzle Mix (mask only)</cell><cell>15.95 17.39 16.38</cell><cell>3.92 4.34 3.78</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://github.com/berhane/LAP-solvers</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This research was supported in part by Samsung Electronics and Institute of Information &amp; communications Technology Planning &amp; Evaluation (IITP) grant funded by the Korea government (MSIT) (No. 2020-0-00882, (SW STAR LAB) Development of deployable learning intelligence via selfsustainable and trustworthy machine learning). Hyun Oh Song is the corresponding author.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A theory of learning from different domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ben-David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kulesza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Vaughan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="151" to="175" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Training with noise is equivalent to tikhonov regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Bishop</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="108" to="116" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Pattern recognition and machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Bishop</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Fast approximate energy minimization via graph cuts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Boykov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Veksler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zabih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1222" to="1239" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">A downsampled variant of imagenet as an alternative to the cifar datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chrabaszcz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.08819</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Optimal transport for domain adaptation. IEEE transactions on pattern analysis and machine intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Courty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Flamary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tuia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rakotomamonjy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Imagenet: a large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">F</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Improved regularization of convolutional neural networks with cutout</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Devries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">W</forename><surname>Taylor</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.04552</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Graph-based lexical centrality as salience in text summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Erkan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Radev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lexrank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of artificial intelligence research</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="457" to="479" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Mixup as locally linear out-of-manifold regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<title level="m">Identity mappings in deep residual networks. ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Benchmarking neural network robustness to common corruptions and perturbations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Dietterich</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">AugMix: A simple data processing method to improve robustness and uncertainty</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gilmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lakshminarayanan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Statistics of natural images and models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mumford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149)</title>
		<meeting>1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1999" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="541" to="547" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A shortest augmenting path algorithm for dense and sparse linear assignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jonker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Volgenant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computing</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="325" to="340" />
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A saliency-based auditory attention model with applications to unsupervised prominent syllable detection in speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Kalinli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Narayanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eighth Annual Conference of the International Speech Communication Association</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">What energy functions can be minimizedvia graph cuts?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kolmogorov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zabih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis &amp; Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="147" to="159" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Geoffrey</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
		<respStmt>
			<orgName>University of Toronto</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurlPS</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Towards deep learning models resistant to adversarial attacks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Madry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Makelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tsipras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vladu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.06083</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Algorithms for the assignment and transportation problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Munkres</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Society for Industrial and Applied Mathematics</title>
		<imprint>
			<date type="published" when="1957" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Automatic differentiation in pytorch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lerer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Adaptive color transfer with relaxed optimal transport</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rabin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ferradans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Papadakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2014 IEEE International Conference on Image Processing (ICIP)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Regionbased saliency detection and its application in object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-T</forename><surname>Chia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">W</forename><surname>Tsang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Circuits and Systems for Video Technology</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="769" to="779" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Generalized fast approximate energy minimization via graph cuts: Alpha-expansion beta-shrink moves</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Alahari</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1108.5710</idno>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Grad-cam: Visual explanations from deep networks via gradient-based localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">R</forename><surname>Selvaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cogswell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vedantam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Batra</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6034</idno>
		<title level="m">Deep inside convolutional networks: Visualising image classification models and saliency maps</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Exploiting Saliency and Local Statistics for Optimal Mixup Smith, C. S. Modes of discourse: The local structure of texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Puzzle</forename><surname>Mix</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<publisher>Cambridge University Press</publisher>
			<biblScope unit="volume">103</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Dropout: a simple way to prevent neural networks from overfitting. The journal of machine learning research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lamb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Beckham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Najafi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Mitliagkas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manifold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mixup</surname></persName>
		</author>
		<title level="m">Better representations by interpolating hidden states. ICML</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Optimal transport: old and new</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Villani</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>Springer Science &amp; Business Media</publisher>
			<biblScope unit="volume">338</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Deep networks for saliency detection via local estimation and global search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ruan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Object region mining with adversarial erasing: A simple classification to semantic segmentation approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-M</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Fast is better than free: Revisiting adversarial training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Rice</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Z</forename><surname>Kolter</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Choe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yoo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cutmix</surname></persName>
		</author>
		<title level="m">Regularization strategy to train strong classifiers with localizable features. ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zagoruyko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.07146</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">Wide residual networks. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Understanding deep learning requires rethinking generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Recht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.03530</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<title level="m">mixup: Beyond empirical risk minimization. ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Towards end-to-end speech recognition with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pezeshki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Brakel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.02720</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Saliency detection by multi-context deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lapedriza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Torralba</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
