<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Domain Adaptation for Structured Output via Discriminative Patch Representations</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Hsuan</forename><surname>Tsai</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">NEC Laboratories America</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">NEC Laboratories America</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Schulter</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">NEC Laboratories America</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manmohan</forename><surname>Chandraker</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">NEC Laboratories America</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>San Diego</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Domain Adaptation for Structured Output via Discriminative Patch Representations</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T17:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Predicting structured outputs such as semantic segmentation relies on expensive per-pixel annotations to learn supervised models like convolutional neural networks. However, models trained on one data domain may not generalize well to other domains without annotations for model finetuning. To avoid the labor-intensive process of annotation, we develop a domain adaptation method to adapt the source data to the unlabeled target domain. We propose to learn discriminative feature representations of patches in the source domain by discovering multiple modes of patch-wise output distribution through the construction of a clustered space. With such representations as guidance, we use an adversarial learning scheme to push the feature representations of target patches in the clustered space closer to the distributions of source patches. In addition, we show that our framework is complementary to existing domain adaptation techniques and achieves consistent improvements on semantic segmentation. Extensive ablations and results are demonstrated on numerous benchmark datasets with various settings, such as synthetic-to-real and cross-city scenarios.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>With the availability of large-scale annotated datasets <ref type="bibr" target="#b7">[8]</ref>, deep learning has made a significant impact on many computer vision tasks, such as object recognition <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b21">22]</ref>, detection <ref type="bibr" target="#b10">[11]</ref>, or semantic segmentation <ref type="bibr" target="#b2">[3]</ref>. Unfortunately, learned models may not generalize when evaluated on a test domain different from the labeled training data <ref type="bibr" target="#b45">[46]</ref>. Unsupervised domain adaptation (UDA) <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b32">33]</ref> has been proposed to close the performance gap introduced by the mismatch between the source domain, where labeled data is available, and the target domain. UDA circumvents an expensive data annotation process by utilizing only unlabeled data from the target domain. Along this line, numerous UDA methods have been developed and successfully applied for classification tasks <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b41">42]</ref>. * Now at Google Cloud AI. <ref type="figure">Figure 1</ref>. Our method aims at improving output distribution alignment via: 1) patch mode discovery from the source patch annotations to construct a clustered space and project to a feature space, and 2) patch alignment from the target patch representation (unfilled symbol) to the source distribution (solid symbols).</p><p>UDA is even more crucial for pixel-level prediction tasks such as semantic segmentation as annotation is prohibitively expensive. A prominent approach towards domain adaptation for semantic segmentation is distribution alignment by adversarial learning <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b9">10]</ref>, where the alignment may happen at different representation layers, such as pixellevel <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b48">49]</ref>, feature-level <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b17">18]</ref> or output-level <ref type="bibr" target="#b39">[40]</ref>. Despite these efforts, discovering all modes of the data distribution is a key challenge for domain adaptation <ref type="bibr" target="#b38">[39]</ref>, akin to difficulties also faced by generative tasks <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b26">27]</ref>.</p><p>A critical step during adversarial training is the use of a convolutional discriminator <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b39">40]</ref> that classifies patches into source or target domains. However, the discriminator is not supervised to capture several modes in the data distribution and it may end up learning only low-level differences such as tone or texture across domains. In addition, for the task of semantic segmentation, it is important to capture and adapt high-level patterns given the highly structured output space.</p><p>In this work, we propose an unsupervised domain adap-tation method that explicitly discovers many modes in the structured output space of semantic segmentation to learn a better discriminator between the two domains, ultimately leading to a better domain alignment. We leverage the pixellevel semantic annotations available in the source domain, but instead of directly working on the output space <ref type="bibr" target="#b39">[40]</ref>, our adaptation happens in two stages. First, we extract patches from the source domain, represent them using their annotation maps and discover major modes by applying K-means clustering, which groups patches into K clusters (Step A in <ref type="figure">Figure 1</ref>). Each patch in the source domain can now be assigned to a ground truth cluster/mode index. We then introduce a K-way classifier that predicts the cluster/mode index of each patch, which can be supervised in the source domain but not in the target domain. Second, different from the output space alignment <ref type="bibr" target="#b39">[40]</ref>, our method, referred as patch-level alignment (Step B in <ref type="figure">Figure 1</ref>) operates on the K-dimensional probability vector space after projecting to the clustered space that already discovers various patch modes. This is in contrast to prior art that operates on either pixel- <ref type="bibr" target="#b48">[49]</ref>, feature- <ref type="bibr" target="#b16">[17]</ref> or outputlevel <ref type="bibr" target="#b39">[40]</ref>. The learned discriminator on the clustered space can back-propagate the gradient through the cluster/mode index classifier to the semantic segmentation network.</p><p>In experiments, we follow the setting of <ref type="bibr" target="#b16">[17]</ref> and perform pixel-level road-scene semantic segmentation. We experiment under various settings, including synthetic-to-real (GTA5 <ref type="bibr" target="#b30">[31]</ref>, SYNTHIA <ref type="bibr" target="#b31">[32]</ref> to Cityscapes <ref type="bibr" target="#b6">[7]</ref>) and crosscity (Cityscapes to Oxford RobotCar <ref type="bibr" target="#b25">[26]</ref>) adaptation. We provide an extensive ablation study to validate each component in the proposed framework. Our approach is also complementary to existing domain adaptation techniques, which we demonstrate by combining with output space adaptation <ref type="bibr" target="#b39">[40]</ref>, pixel-level adaptation <ref type="bibr" target="#b15">[16]</ref> and pseudo label retraining <ref type="bibr" target="#b50">[51]</ref>. Our results show that the learned representations improve segmentation results consistently and achieve state-of-the-art performance.</p><p>Our contributions are summarized as follows. First, we propose an adversarial adaptation framework for structured prediction that explicitly tries to discover and predict modes of the output patches. Second, we demonstrate the complementary nature of our approach by integration into three existing domain adaptation methods, which can all benefit from it. Third, we extensively analyze our approach and show state-of-the-art results on various domain adaptation benchmarks for semantic segmentation. <ref type="bibr" target="#b0">1</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>We discuss unsupervised domain adaptation methods for image classification and pixel-level structured prediction tasks, and works on learning disentangled representations. <ref type="bibr" target="#b0">1</ref> The project page is at https://www.nec-labs.com/˜mas/ adapt-seg/adapt-seg.html.</p><p>UDA for Image Classification. UDA methods have been developed for classification by aligning the feature distributions between the source and the target domains. Conventional methods use hand-crafted features <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b11">12]</ref> to minimize the discrepancy across domains, while recent algorithms utilize deep architectures <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b40">41]</ref> to learn domaininvariant features. One common practice is to adopt adversarial learning <ref type="bibr" target="#b9">[10]</ref> or to minimize the Maximum Mean Discrepancy <ref type="bibr" target="#b23">[24]</ref>. Several variants have been developed by designing different classifiers <ref type="bibr" target="#b24">[25]</ref> and loss functions <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b41">42]</ref>, and for distance metric learning <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b37">38]</ref>. In addition, other recent work aims to enhance feature representations by pixellevel transfer <ref type="bibr" target="#b0">[1]</ref> and maximum classifier discrepancy <ref type="bibr" target="#b33">[34]</ref>.</p><p>UDA for Semantic Segmentation. Following the practice in image classification, domain adaptation for pixel-level predictions has been studied. <ref type="bibr" target="#b16">[17]</ref> introduces to tackle the semantic segmentation problem for road-scene images by adapting from synthetic images via aligning global feature representations. In addition, a category-specific prior, e.g., object size and class distribution is extracted from the source domain and is transferred to the target distribution as a constraint. Instead of designing such constraints, <ref type="bibr" target="#b46">[47]</ref> applies the SVM classifier to capture label distributions on superpixels as the property to train the adapted model. Similarly, <ref type="bibr" target="#b5">[6]</ref> proposes a class-wise domain adversarial alignment by assigning pseudo labels to the target data.</p><p>More recently, numerous approaches are proposed to improve the adapted segmentation and can be categorized as follows: 1) output space <ref type="bibr" target="#b39">[40]</ref> and spatial-aware <ref type="bibr" target="#b4">[5]</ref> adaptations aim to align the global structure (e.g., scene layout) across domains; 2) pixel-level adaptation synthesizes target samples <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b47">48]</ref> to reduce the domain gap during training the segmentation model; 3) pseudo label re-training <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b50">51]</ref> generates pseudo ground truth of target images to finetune the model trained on the source domain. While the most relevant approaches to ours are from the first category, they do not handle the intrinsic domain gap such as camera poses. In contrast, the proposed patch-level alignment is able to match patches at various image locations across domains. We also note that, the other two categories or other techniques such as robust loss function design <ref type="bibr" target="#b49">[50]</ref> are orthogonal to the contribution of this work. In Section 4.3, we show that our patch-level representations can be integrated with other domain adaptation methods to further enhance the performance.</p><p>Learning Disentangled Representations. Learning a latent disentangled space has led to a better understanding for numerous tasks such as facial recognition <ref type="bibr" target="#b29">[30]</ref>, image generation <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b28">29]</ref>, and view synthesis <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b44">45]</ref>. These approaches use predefined factors to learn interpretable representations of the image. <ref type="bibr" target="#b22">[23]</ref> propose to learn graphic codes that are disentangled with respect to various image transformations, e.g., <ref type="figure">Figure 2</ref>. An overview of our patch-level alignment. For our method, the category distribution is projected to the patch distribution via a clustered space that is constructed by discovering K patch modes in the source domain. For the target data, we then align patch distributions across domains via adversarial learning in this K-dimensional space. Note that, compared to the output space adaptation methods, they only have a step that directly aligns category distributions without consider multiple modes in the source data. pose and lighting, for rendering 3D images. Similarly, <ref type="bibr" target="#b44">[45]</ref> synthesize 3D objects from a single image via an encoderdecoder architecture that learns latent representations based on the rotation factor. Recently, AC-GAN <ref type="bibr" target="#b28">[29]</ref> develops a generative adversarial network (GAN) with an auxiliary classifier conditioned on the given factors such as image labels and attributes.</p><p>Although these methods present promising results on using the specified factors and learning a disentangled space to help the target task, they focus on handling the data in a single domain. Motivated by this line of research, we propose to learn discriminative representations for patches to help the domain adaptation task. To this end, we take advantage of the available label distributions and naturally utilize them as a disentangled factor, in which our framework does not require to predefine any factors like conventional methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Domain Adaptation for Structured Output</head><p>In this section, we describe our framework for predicting structured outputs: an adversarial learning scheme to align distributions across domains by using discriminative output representations of patches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Algorithm Overview</head><p>Given the source and target images I s , I t ∈ R H×W ×3 , where only the source data is annotated with per-pixel semantic categories Y s , we seek to learn a semantic segmentation model G that works on both domains. Since the target domain is unlabeled, our goal is to align the predicted output distribution O t of the target data with the source distribution O s , which is similar to <ref type="bibr" target="#b39">[40]</ref>. However, such distribution is not aware of the local difference in patches and thus is not able to discover a diverse set of modes during adversarial learning. To tackle this issue, and in contrast to <ref type="bibr" target="#b39">[40]</ref>, we project the category distribution of patches to the clustered space that already discovers various patch modes (i.e., K clusters) based on the annotations in the source domain. For target data, we then employ adversarial learning to align the patch-level distributions across domains in the K-dimensional space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Patch-level Alignment</head><p>As in <ref type="figure">Figure 2</ref>, we seek for ways to align patches in a clustered space that provides a diverse set of patch modes. One can also treat this procedure as learning prototypical output representations of patches by clustering ground truth segmentation annotations from the source domain. In what follows, we introduce how we construct the clustered space and learn discriminative patch representations. Then we describe adversarial alignment using the learned patch representation. The detailed architecture is shown in <ref type="figure">Figure 3</ref>.</p><p>Patch Mode Discovery. To discover modes and learn a discriminative feature space, class labels <ref type="bibr" target="#b35">[36]</ref> or predefined factors <ref type="bibr" target="#b28">[29]</ref> are usually provided as supervisory signals. <ref type="figure">Figure 3</ref>. The proposed network architecture that consists of a generator G and a categorization module H for learning discriminative patch representations via 1) patch mode discovery supervised by the patch classification loss L d , and 2) patch-level alignment via the adversarial loss L adv . In the projected space, solid symbols denote source representations and unfilled ones are target representations pulled to the source distribution.</p><p>However, it is non-trivial to assign a class membership to individual patches of an image. One may apply unsupervised clustering of image patches, but it is unclear whether the constructed clustering would separate patches in a semantically meaningful way. In this work, we make use of per-pixel annotations available in the source domain to construct a space of semantic patch representation. To achieve this, we use label histograms for patches. We first randomly sample patches from source images, use a 2-by-2 grid on patches to extract spatial label histograms, and concatenate them to obtain a 2 × 2 × C dimensional vector. Second, we apply K-means clustering on these histograms, thereby assigning each ground truth label patch a unique cluster index. We define the process of finding the cluster membership for each patch in a ground truth label map Y s as Γ(Y s ).</p><p>To incorporate this clustered space for training the segmentation network G on source data, we add a classification module H on top of the predicted output O s , which tries to predict the cluster membership Γ(Y s ) for all locations. We denote the learned representation as F s = H(G(I s )) ∈ (0, 1) U ×V ×K through the softmax function, where K is the number of clusters. Here, each data point on the spatial map F s corresponds to a patch of the input image, and we obtain the group label for each patch via Γ(Y s ). Then the learning process to construct the clustered space can be formulated as a cross-entropy loss:</p><formula xml:id="formula_0">L d (F s , Γ(Y s ); G, H) = − u,v k∈K CE (u,v,k) ,<label>(1)</label></formula><p>where</p><formula xml:id="formula_1">CE (u,v,k) = Γ(Y s ) (u,v,k) log(F (u,v,k) s</formula><p>).</p><p>Adversarial Alignment. The ensuing task is to align the representations of target patches to the clustered space con-structed in the source domain, ideally aligned to one of the K modes. To this end, we utilize an adversarial loss between F s and F t , where F t is generated in the same way as described above. Note that, the patch-level feature F is now transformed from the category distribution O to the clustered space defined by K-dimensional vectors. We then formulate the patch distribution alignment in an adversarial objective:</p><formula xml:id="formula_2">L adv (F s , F t ; G, H, D) = u,v E[log D(F s ) (u,v,1) ] (2) +E[log(1 − D(F t ) (u,v,1) )],</formula><p>where D is the discriminator to classify whether the feature representation F is from the source or the target domain.</p><p>Learning Objective. We integrate <ref type="formula" target="#formula_0">(1)</ref> and <ref type="formula">(2)</ref> into the minmax problem (for clarity, we drop all arguments to losses except the optimization variables):</p><formula xml:id="formula_3">min G,H max D L s (G) + λ d L d (G, H) (3) +λ adv L adv (G, H, D),</formula><p>where L s is the supervised cross-entropy loss for learning the structured prediction (e.g., semantic segmentation) on source data, and λ's are the weights for different losses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Network Optimization</head><p>To solve the optimization problem in Eq. (3), we follow the procedure of training GANs <ref type="bibr" target="#b12">[13]</ref> and alternate two steps: 1) update the discriminator D, and 2) update the networks G and H while fixing the discriminator.</p><p>Update the Discriminator D. We train the discriminator D to classify whether the feature representation F is from the source (labeled as 1) or the target domain (labeled as 0). The maximization problem wrt. D in <ref type="formula">(3)</ref> is equivalent to minimizing the binary cross-entropy loss:</p><formula xml:id="formula_4">L D (F s , F t ; D) = − u,v log(D(F s ) (u,v,1) ) (4) + log(1 − D(F t ) (u,v,1) ).</formula><p>Update the Networks G and H. The goal of this step is to push the target distribution closer to the source distribution using the optimized D, while maintaining good performance on the main tasks using G and H. As a result, the minimization problem in <ref type="formula">(3)</ref> is the combination of two supervised loss functions with the adversarial loss, which can be expressed as a binary cross-entropy function that assigns the source label to the target distribution:</p><formula xml:id="formula_5">L G,H = L s + λ d L d − λ adv u,v log(D(F t ) (u,v,1) ). (5)</formula><p>We note that updating H also influences G through backpropagation, and thus the feature representations are enhanced in G. In addition, we only require H during the training phase, so that runtime for inference is unaffected compared to the output space adaptation approach <ref type="bibr" target="#b39">[40]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Implementation Details</head><p>Network Architectures. The generator consists of the network G with a categorization module H. For a fair comparison, we follow the framework used in <ref type="bibr" target="#b39">[40]</ref> that adopts DeepLab-v2 <ref type="bibr" target="#b2">[3]</ref> with the ResNet-101 architecture <ref type="bibr" target="#b14">[15]</ref> as our baseline network G. To add the module H on the output prediction O, we first use an adaptive average pooling layer to generate a spatial map, where each data point on the map has a desired receptive field corresponding to the size of extracted patches. Then this pooled map is fed into two convolution layers and a feature map F is produced with the channel number K. <ref type="figure">Figure 3</ref> illustrates the main components of the proposed architecture. For the discriminator D, input data is a K-dimensional vector and we utilize 3 fully-connected layers similar to <ref type="bibr" target="#b41">[42]</ref>, with leaky ReLU activation and channel numbers {256, 512, 1}.</p><p>Implementation Details. We implement the proposed framework using the PyTorch toolbox on a single Titan X GPU with 12 GB memory. To train the discriminators, we use the Adam optimizer <ref type="bibr" target="#b20">[21]</ref> with initial learning rate of 10 −4 and momentums set as 0.9 and 0.99. For learning the generator, we use the Stochastic Gradient Descent (SGD) solver where the momentum is 0.9, the weight decay is 5 × 10 −4 and the initial learning rate is 2.5 × 10 −4 . For all the networks, we decrease the learning rates using the polynomial decay with a power of 0.9, as described in <ref type="bibr" target="#b2">[3]</ref>.</p><p>During training, we select λ d = 0.01, λ adv = 0.0005 and K = 50 fixed for all the experiments. Note that we first train the model only using the loss L s for 10K iterations to avoid initially noisy predictions and then train the network using all the loss functions. More details of the hyper-parameters such as image and patch sizes are provided in the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental Results</head><p>We evaluate the proposed framework for domain adaptation on semantic segmentation. We first conduct an extensive ablation study to validate key components of our algorithm. Second, we show that the proposed method can be integrated with various domain adaptation techniques, including output space adaptation <ref type="bibr" target="#b39">[40]</ref>, pixel-level adaptation <ref type="bibr" target="#b15">[16]</ref>, and pseudo label re-training <ref type="bibr" target="#b50">[51]</ref>. This demonstrates that our learned patch-level representations are complementary to a wide range of domain adaptation strategies and provide additional benefits. Finally, we present a hybrid model that performs favorably against state-of-the-art approaches on numerous benchmark datasets and settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Evaluated Datasets and Metric</head><p>We evaluate our domain adaptation method on semantic segmentation under various settings, including synthetic-toreal and cross-city. First, we adapt the synthetic GTA5 <ref type="bibr" target="#b30">[31]</ref> dataset to the Cityscapes <ref type="bibr" target="#b6">[7]</ref> dataset that contains real roadscene images. Similarly, we use the SYNTHIA <ref type="bibr" target="#b31">[32]</ref> dataset, which has a larger domain gap to Cityscapes images. For these experiments, we follow <ref type="bibr" target="#b16">[17]</ref> to split data into training and test sets. As another example with high practical impact, we apply our method on data captured in different cities and weather conditions by adapting Cityscapes with sunny images to the Oxford RobotCar <ref type="bibr" target="#b25">[26]</ref> dataset containing rainy scenes. We manually select 10 sequences in the Oxford RobotCar dataset tagged as "rainy" and randomly split them into 7 sequences for training and 3 for testing. We sequentially sample 895 images for training and annotate 271 images with per-pixel semantic segmentation ground truth as the test set for evaluation. The annotated ground truths are made publicly available at the project page. For all experiments, Intersection-over-Union (IoU) ratio is used as the evaluation metric.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Ablation Study and Analysis</head><p>In <ref type="table" target="#tab_0">Table 1</ref>, we conduct the ablation study and analysis of the proposed patch-level alignment on the GTA5-to-Cityscapes scenario to understand the impact of different loss functions and design choices in our framework. <ref type="table" target="#tab_0">Table 1</ref>, we show different steps of the proposed method, including the model without adaptation, using discriminative patch features and the final patch-level  alignment. Interestingly, we find that adding discriminative patch representations without any alignments (L s + L d ) already improves the performance (from 36.6% to 38.8%), which demonstrates that the learned feature representation enhances the discrimination and generalization ability. Finally, the proposed patch-level adversarial alignment improves the mIoU by 4.7%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Loss Functions. In</head><p>Impact of Learning Clustered Space. K-means provides an additional signal to separate different patch patterns, while performing alignment in this clustered space. Without the clustered loss L d , it would be difficult to align patch modes across two domains. To validate it, we run an experiment by only using L s and L adv but removing L d , and the performance is reduced by 1.9% compared to our method (41.3%). This shows the importance of learning the clustered space supervised by the K-means process.</p><p>Impact of Cluster Number K. In <ref type="figure">Figure 5</ref>, we study the impact of the cluster number K used to construct the patch representation, showing that the performance is robust to K. However, when K is too large, e.g., larger than 300, it would cause confusion between patch modes and increases the training difficulty. To keep both efficiency and accuracy, we use K = 50 throughout the experiments.</p><p>Visualization of Feature Representations. In <ref type="figure" target="#fig_0">Figure 4</ref>, we show the t-SNE visualization <ref type="bibr" target="#b42">[43]</ref> of the patch-level features in the clustered space of our method and compare with the one without patch-level adaptation. The result shows <ref type="figure">Figure 5</ref>. The performance of our method with respect to different numbers of clusters K on GTA5-to-Cityscapes.</p><p>that with adaptation in the clustered space, the features are embedded into groups and the source/target representations overlap well. In addition, we present example source/target patches with high similarity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Improvement on Domain Adaptation Methods</head><p>The learned patch representation via the proposed patch alignment enhances feature representations and is complementary to various DA methods, which we demonstrate by combining with output-space adaptation (Ou), pixel-level adaptation (Pi) and pseudo label re-training (Ps). Our results show consistent improvement in all cases, e.g., 1.8% to 2.7% on GTA5-to-Cityscapes, as shown in <ref type="table" target="#tab_1">Table 2</ref>.</p><p>Output Space Adaptation. We first consider methods that align the global layout across domains as in <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b39">40]</ref>. Our proposed cluster prediction network H and the corresponding loss L adv can be simply added into <ref type="bibr" target="#b39">[40]</ref>. Since these methods only align the global structure, adding our method helps figuring out local details better and improves the segmentation quality.</p><p>Pixel-level Adaptation. We utilize CyCADA <ref type="bibr" target="#b15">[16]</ref> as the pixel-level adaptation algorithm and produce synthesized images in the target domain from source images. To train our model, we add synthesized samples into the labeled training set with the proposed patch-level alignment. Note that, since synthesized samples share the same pixel-level Target Image</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ground Truth</head><p>Before Adaptation Output Alignment Patch Alignment <ref type="figure">Figure 6</ref>. Example results for GTA5-to-Cityscapes. Our method often generates the segmentation with more details (e.g., sidewalk and pole) while producing less noisy regions compared to the output space adaptation approach <ref type="bibr" target="#b39">[40]</ref>. annotations as the source data, they can be also considered in our clustering process and the optimization in <ref type="formula">(3)</ref>.</p><p>Pseudo Label Re-training. Pseudo label re-training is a natural way to improve the segmentation quality in domain adaptation <ref type="bibr" target="#b50">[51]</ref> or semi-supervised learning <ref type="bibr" target="#b18">[19]</ref>. The endto-end trainable framework <ref type="bibr" target="#b18">[19]</ref> uses an adversarial scheme to identify self-learnable regions, which makes it an ideal candidate to integrate our patch-level adversarial loss.</p><p>Results and Discussions. The results for combining the proposed patch-level alignment with the three above mentioned DA methods are shown in <ref type="table" target="#tab_1">Tables 2 and 3</ref> for GTA5-to-Cityscapes and SYNTHIA-to-Cityscapes, respectively. We can observe that adding patch-level alignment improves in all cases. For reference, we also show the gain from adding patch-level alignment to the plain segmentation network (without adaptation). Even when combining all three DA methods, i.e., Fusion (Fu), the proposed patch-alignment further improves the results significantly (≥ 2.0%). Note that, the combination of all DA methods including patch alignment, i.e., Fu + Patch-Alignment, achieves the best performance in both cases. As a comparison point, we also try to combine pixellevel adaptation with output space alignment (Pi + Ou), but the performance is 0.7% worse than ours, i.e., Pi + Patch-Alignment, showing the advantages of adopting patch-level alignment. On SYNTHIA-to-Cityscapes in <ref type="table" target="#tab_2">Table 3</ref>, we find that Pi and Ps are less effective than Ou, likely due to the poor quality of the input data in the source domain, which also explains the lower performance of the combined model (Fu). This also indicates that directly combining different DA methods may not improve the performance incrementally. However, adding the proposed patch-alignment improves the results consistently in all settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Comparisons with State-of-the-art Methods</head><p>We have validated that the proposed patch-level alignment is complementary to existing domain adaptation methods on semantic segmentation. In the following, we compare our final model (Fu + Patch-Alignment) with state-of-the-art algorithms under various scenarios, including synthetic-toreal and cross-city cases.</p><p>Synthetic-to-real Case. We first present experimental results for adapting GTA5 to Cityscapes in <ref type="table" target="#tab_3">Table 4</ref>. We utilize two different architectures, i.e., VGG-16 and ResNet-101, and compare with state-of-the-art approaches via feature adaptation <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b46">47]</ref>, pixel-level adaptation <ref type="bibr" target="#b15">[16]</ref>, pseudo label re-training <ref type="bibr" target="#b50">[51]</ref> and output space alignment <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b39">40]</ref>. We show that the proposed framework improves over existing methods by 2.5% and 5.1% in mean IoU for two architectures, respectively. In <ref type="table" target="#tab_4">Table 5</ref>, we present results for adapting SYN-THIA to Cityscapes and similar improvements are observed compared to state-of-the-arts. In addition, we shows visual comparisons in <ref type="figure">Figure 6</ref> and more results are presented in the supplementary material.</p><p>Cross-city Case. Adapting between real images across different cities and conditions is an important scenario for   <ref type="bibr" target="#b39">[40]</ref>, we run the authors' released code and obtain a mean IoU of 69.5%, which is 2.5% lower than the proposed method. Further results and comparisons are provided in the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions</head><p>In this paper, we present a domain adaptation method for structured output via patch-level alignment. We propose to learn discriminative representations of patches by construct-ing a clustered space of the source patches and adopt an adversarial learning scheme to push the target patch distributions closer to the source ones. With patch-level alignment, our method is complementary to various domain adaptation approaches and provides additional improvement. We conduct extensive ablation studies and experiments to validate the effectiveness of the proposed method under numerous challenges on semantic segmentation, including syntheticto-real and cross-city scenarios, and show that our approach performs favorably against existing algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Training Details</head><p>To train the model in an end-to-end manner, we randomly sample one image from each of the source and target domain (i.e., batch size as 1) in a training iteration. Then we follow the optimization strategy as described in Section 3.3 of the main paper. <ref type="table">Table 6</ref> shows the image and patch sizes during training and testing. Note that, the aspect ratio of the image is always maintained (i.e., no cropping) and then the image is down-sampled to the size as in the table.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Relation to Entropy Minimization</head><p>Entropy minimization <ref type="bibr" target="#b13">[14]</ref> can be used as a loss in our model to push the target feature representation F t to one of the source clusters. To add this regularization, we replace the adversarial loss on the patch level with an entropy loss as in <ref type="bibr" target="#b24">[25]</ref>, where the entropy loss L en = u,v k H(σ(F t /τ )) <ref type="bibr">(u,v,k)</ref> , H is the information entropy function, σ is the softmax function, and τ is the temperature of the softmax. The model with adding this entropy regularization achieves the IoU as 41.9%, that is lower than the proposed patch-level adversarial alignment as 43.2%. The reason is that, different from the entropy minimization approach that does not use the source distribution as the guidance, our model learns discriminative representations for the target patches by pushing them closer to the source distribution in the clustered space guided by the annotated labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. More Ablation Study on Clustered Space</head><p>To validate the effectiveness of the H module, we conduct an experiment on GTA5-to-Cityscapes that directly computes category histograms from the segmentation output and then perform alignment. This implementation achieves an IoU 0.7% lower than our method as 41.3%. A possible reason is that we use the H module that involves learnable parameters to estimate K-means memberships, whereas directly computing category histograms would solely rely on updating the segmentation network G, which causes more training difficulty.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. More Details on Pseudo Label Re-training</head><p>We use the official implementation of <ref type="bibr" target="#b18">[19]</ref> provided by the authors. In this case, we consider our target samples as unlabeled data used in <ref type="bibr" target="#b18">[19]</ref> under the semi-supervised setting. The same discriminator in the output space and the loss function are then adopted as in <ref type="bibr" target="#b18">[19]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Result of Cityscapes-to-Oxford</head><p>In <ref type="table">Table 7</ref>, we present the complete result for adapting Cityscapes (sunny condition) to Oxford RobotCar (rainy scene). We compare the proposed method with the model without adaptation and the output space adaptation approach <ref type="bibr" target="#b39">[40]</ref>. More qualitative results are provided in <ref type="figure">Figure 7</ref> and 8.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Qualitative Comparisons</head><p>We provide more visual comparisons for GTA5-to-Cityscapes and SYNTHIA-to-Cityscapes scenarios from <ref type="figure">Figure 9</ref> to <ref type="figure" target="#fig_2">Figure 11</ref>. In each row, we present the results of the model without adaptation, output space adaptation <ref type="bibr" target="#b39">[40]</ref>, and the proposed method. We show that our approach often yields better segmentation outputs with more details and produces less noisy regions.  <ref type="figure">Figure 7</ref>. Example results of adapted segmentation for the Cityscapes-to-OxfordRobotCar setting. We sequentially show images in a video and their adapted segmentations generated by our method. <ref type="figure">Figure 8</ref>. Example results of adapted segmentation for the Cityscapes-to-OxfordRobotCar setting. We sequentially show images in a video and their adapted segmentations generated by our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Target Image</head><p>Ground Truth Before Adaptation Global Alignment Ours <ref type="figure">Figure 8</ref>: Example results of adapted segmentation for the GTA5-to-Cityscapes setting. For each target image, we show results before adaptation, output space adaptation , and the proposed method. <ref type="figure">Figure 9</ref>. Example results of adapted segmentation for the GTA5-to-Cityscapes setting. For each target image, we show results before adaptation, output space adaptation <ref type="bibr" target="#b39">[40]</ref>, and the proposed method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Target Image</head><p>Ground Truth Before Adaptation Global Alignment Ours <ref type="figure">Figure 9</ref>: Example results of adapted segmentation for the GTA5-to-Cityscapes setting. For each target image, we show results before adaptation, output space adaptation , and the proposed method. <ref type="figure" target="#fig_1">Figure 10</ref>. Example results of adapted segmentation for the GTA5-to-Cityscapes setting. For each target image, we show results before adaptation, output space adaptation <ref type="bibr" target="#b39">[40]</ref>, and the proposed method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Target Image</head><p>Ground Truth Before Adaptation Global Alignment Ours  . Example results of adapted segmentation for the SYNTHIA-to-Cityscapes setting. For each target image, we show results before adaptation, output space adaptation <ref type="bibr" target="#b39">[40]</ref>, and the proposed method.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 4 .</head><label>4</label><figDesc>Visualization of patch-level representations. We first show feature representations via t-SNE of our method and compare to the baseline without the proposed patch-level alignment. In addition, we show patch examples in the clustered space. In each group, patches are similar in appearance (i.e., each color represents a semantic label) between the source and target domains.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 10 :</head><label>10</label><figDesc>Example results of adapted segmentation for the SYNTHIA-to-Cityscapes setting. For each target image, we show results before adaptation, output space adaptation, and the proposed method.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 11</head><label>11</label><figDesc>Figure 11. Example results of adapted segmentation for the SYNTHIA-to-Cityscapes setting. For each target image, we show results before adaptation, output space adaptation [40], and the proposed method.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Ablation study of the proposed loss functions on GTA5to-Cityscapes using the ResNet-101 network.</figDesc><table><row><cell cols="2">GTA5 → Cityscapes</cell><cell></cell></row><row><cell>Method</cell><cell>Loss Func.</cell><cell>mIoU</cell></row><row><cell>Without Adaptation</cell><cell>Ls</cell><cell>36.6</cell></row><row><cell cols="2">Discriminative Feature Ls + L d</cell><cell>38.8</cell></row><row><cell>Patch-level Alignment</cell><cell>Ls + L</cell><cell></cell></row></table><note>d + L adv 41.3</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc></figDesc><table><row><cell cols="4">Performance improvements in mIoU of integrating our</cell></row><row><cell cols="4">patch-level alignment with existing domain adaptation approaches</cell></row><row><cell cols="3">on GTA5-to-Cityscapes using the ResNet-101 network.</cell><cell></cell></row><row><cell cols="3">GTA5 → Cityscapes (19 Categories)</cell><cell></cell></row><row><cell>Methods</cell><cell cols="2">Base + Patch-Alignment</cell><cell>∆</cell></row><row><cell>Without Adaptation</cell><cell>36.6</cell><cell>41.3</cell><cell>+4.7</cell></row><row><cell cols="2">(Ou)tput Space Ada. 41.4</cell><cell>43.2</cell><cell>+1.8</cell></row><row><cell>(Pi)xel-level Ada.</cell><cell>42.2</cell><cell>44.9</cell><cell>+2.7</cell></row><row><cell>(Ps)eudo-GT</cell><cell>41.8</cell><cell>44.2</cell><cell>+2.4</cell></row><row><cell>(Fu)sion</cell><cell>44.5</cell><cell>46.5</cell><cell>+2.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc></figDesc><table><row><cell cols="4">Performance improvements in mIoU of integrating our</cell></row><row><cell cols="4">patch-level alignment with existing domain adaptation approaches</cell></row><row><cell cols="4">on SYNTHIA-to-Cityscapes using the ResNet-101 network.</cell></row><row><cell cols="3">SYNTHIA → Cityscapes (16 Categories)</cell><cell></cell></row><row><cell>Methods</cell><cell cols="2">Base + Patch-Alignment</cell><cell>∆</cell></row><row><cell>Without Adaptation</cell><cell>33.5</cell><cell>37.0</cell><cell>+3.5</cell></row><row><cell cols="2">(Ou)tput Space Ada. 39.5</cell><cell>39.9</cell><cell>+0.4</cell></row><row><cell>(Pi)xel-level Ada.</cell><cell>35.8</cell><cell>37.0</cell><cell>+1.2</cell></row><row><cell>(Ps)eudo-GT</cell><cell>37.4</cell><cell>38.9</cell><cell>+1.5</cell></row><row><cell>(Fu)sion</cell><cell>37.9</cell><cell>40.0</cell><cell>+2.1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 .</head><label>4</label><figDesc>Results of adapting GTA5 to Cityscapes. The first and second groups adopt VGG-16 and ResNet-101 networks, respectively.</figDesc><table><row><cell>GTA5 → Cityscapes</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 .</head><label>5</label><figDesc>Results of adapting SYNTHIA to Cityscapes. The first and second groups adopt VGG-16 and ResNet-101 networks, respectively. mIoU and mIoU * are averaged over 16 and 13 categories, respectively.</figDesc><table><row><cell>SYNTHIA → Cityscapes</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 .Table 7 .</head><label>67</label><figDesc>Image and patch sizes for training and testing. Results of adapting Cityscapes to Oxford RobotCar.</figDesc><table><row><cell>Dataset</cell><cell></cell><cell cols="2">Cityscapes</cell><cell>GTA5</cell><cell></cell><cell cols="5">SYNTHIA Oxford RobotCar</cell></row><row><cell cols="2">Patch size for training</cell><cell cols="2">32 × 64</cell><cell cols="2">36 × 64</cell><cell cols="2">38 × 64</cell><cell>-</cell><cell></cell><cell></cell></row><row><cell cols="8">Image size for training 512 × 1024 720 × 1280 760 × 1280</cell><cell cols="2">960 × 1280</cell><cell></cell></row><row><cell cols="2">Image size for testing</cell><cell cols="2">512 × 1024</cell><cell>-</cell><cell></cell><cell>-</cell><cell></cell><cell cols="2">960 × 1280</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="5">Cityscapes → Oxford RobotCar</cell><cell></cell><cell></cell></row><row><cell>Method</cell><cell>road</cell><cell>sidewalk</cell><cell>building</cell><cell>light</cell><cell>sign</cell><cell>sky</cell><cell>person</cell><cell>automobile</cell><cell>two-wheel</cell><cell>mIoU</cell></row><row><cell cols="11">Without Adaptation 79.2 49.3 73.1 55.6 37.3 36.1 54.0 81.3 49.7 61.9</cell></row><row><cell>Output Space [40]</cell><cell cols="10">95.1 64.0 75.7 61.3 35.5 63.9 58.1 84.6 57.0 69.5</cell></row><row><cell>Ours</cell><cell cols="10">94.4 63.5 82.0 61.3 36.0 76.4 61.0 86.5 58.6 72.0</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Unsupervised pixel-level domain adaptation with generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantinos</forename><surname>Bousmalis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Silberman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Dohan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilip</forename><surname>Krishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Mode regularized generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanran</forename><surname>Tong Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Jacob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjie</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iasonas</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<idno>abs/1606.00915</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Infogan: Interpretable representation learning by information maximizing generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rein</forename><surname>Houthooft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Road: Reality oriented adaptation for semantic segmentation of urban scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhua</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">No more discrimination: Cross city adaptation of road scene segmenters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Hsin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Yu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo-Cheng</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Chiang Frank</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Sun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The cityscapes dataset for semantic urban scene understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>Cordts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Omran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Ramos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Rehfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Enzweiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>Benenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uwe</forename><surname>Franke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Unsupervised visual domain adaptation using subspace alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Basura</forename><surname>Fernando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amaury</forename><surname>Habrard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Sebban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tinne</forename><surname>Tuytelaars</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Domain-adversarial training of neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaroslav</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniya</forename><surname>Ustinova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hana</forename><surname>Ajakan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Germain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">François</forename><surname>Laviolette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Marchand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">JMLR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Fast r-cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Geodesic flow kernel for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boqing</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Sha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristen</forename><surname>Grauman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Semi-supervised learning by entropy minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Grandvalet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Cycada: Cycle-consistent adversarial domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judy</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taesung</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Yan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Fcns in the wild: Pixel-level adversarial and constraint-based adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judy</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dequan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fisher</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<idno>abs/1612.02649</idno>
		<imprint>
			<date type="published" when="2008" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Domain transfer through deep activation matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoshuo</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qixing</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Krahenbuhl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Adversarial learning for semisupervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Chih</forename><surname>Hung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Hsuan</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan-Ting</forename><surname>Liou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yen-Yu</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Image-to-image translation with conditional adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Yan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tinghui</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Deep convolutional inverse graphics network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tejas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pushmeet</forename><surname>Whitney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Kohli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Learning transferable features with deep adaptation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingsheng</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation with residual transfer networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingsheng</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael I Jordan</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">1 year, 1000km: The oxford robotcar dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Maddern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Pascoe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Linegar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Newman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The International Journal of Robotics Research (IJRR)</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Unrolled generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Pfau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jascha</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Image to image translation for domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zak</forename><surname>Murez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soheil</forename><surname>Kolouri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Kriegman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ravi</forename><surname>Ramamoorthi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyungnam</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In CVPR</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Conditional image synthesis with auxiliary classifier gans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Augustus</forename><surname>Odena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Olah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Learning to disentangle factors of variation with manifold interaction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuting</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Playing for data: Ground truth from computer games</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><forename type="middle">R</forename><surname>Richter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vibhav</forename><surname>Vineet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The SYNTHIA Dataset: A large collection of synthetic images for semantic segmentation of urban scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">German</forename><surname>Ros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Sellart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joanna</forename><surname>Materzynska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Vazquez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><forename type="middle">M</forename><surname>Lopez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Adapting visual category models to new domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Kulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Fritz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Maximum classifier discrepancy for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuniaki</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kohei</forename><surname>Watanabe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshitaka</forename><surname>Ushiku</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tatsuya</forename><surname>Harada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Effective use of synthetic data for urban scene semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fatemeh Sadat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Saleh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathieu</forename><surname>Sadegh Aliakbarian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jose</forename><forename type="middle">M</forename><surname>Petersson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Alvarez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ECCV</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Improved techniques for training gans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vicki</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation for face recognition in unlabeled videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sifei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangyu</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manmohan</forename><surname>Chandraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation for distance metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenling</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manmohan</forename><surname>Chandraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Gotta adapt em all: Joint pixel and feature-level domain adaptation for recognition in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luan</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoming</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manmohan</forename><surname>Chandraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Learning to adapt structured output space for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Hsuan</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Chih</forename><surname>Hung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Schulter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manmohan</forename><surname>Chandraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page">16</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Simultaneous deep transfer across domains and tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judy</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Adversarial discriminative domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judy</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Visualizing high-dimensional data using t-sne</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Dcan: Dual channel-wise alignment networks for unsupervised scene adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zuxuan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xintong</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yen-Liang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mustafa</forename><forename type="middle">Gkhan</forename><surname>Uzunbas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Goldstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nam</forename><surname>Ser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry</forename><forename type="middle">S</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ECCV</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Weakly-supervised disentangling with recurrent transformations for 3d view synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Understanding deep learning requires rethinking generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chiyuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moritz</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Recht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Curriculum domain adaptation for semantic segmentation of urban scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boqing</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Fully convolutional adaptation networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaofan</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Unpaired image-to-image translation using cycle-consistent adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Yan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taesung</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Penalizing top performers: Conservative loss for semantic segmentation adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinge</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ceyuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dahua</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ECCV</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Domain adaptation for semantic segmentation via class-balanced self-training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiding</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">V K</forename><surname>Vijaya Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinsong</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
