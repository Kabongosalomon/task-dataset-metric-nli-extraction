<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Building Sequential Inference Models for End-to-End Response Selection</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia-Chen</forename><surname>Gu</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">National Engineering Laboratory for Speech and Language Information Processing</orgName>
								<orgName type="institution">University of Science and Technology of China</orgName>
								<address>
									<settlement>Hefei</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen-Hua</forename><surname>Ling</surname></persName>
							<email>zhling@ustc.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="laboratory">National Engineering Laboratory for Speech and Language Information Processing</orgName>
								<orgName type="institution">University of Science and Technology of China</orgName>
								<address>
									<settlement>Hefei</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Ping</forename><surname>Ruan</surname></persName>
							<email>ypruan@mail.ustc.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="laboratory">National Engineering Laboratory for Speech and Language Information Processing</orgName>
								<orgName type="institution">University of Science and Technology of China</orgName>
								<address>
									<settlement>Hefei</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quan</forename><surname>Liu</surname></persName>
							<email>quanliu@ustc.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="laboratory">National Engineering Laboratory for Speech and Language Information Processing</orgName>
								<orgName type="institution">University of Science and Technology of China</orgName>
								<address>
									<settlement>Hefei</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">iFLYTEK Research</orgName>
								<address>
									<settlement>Hefei</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Building Sequential Inference Models for End-to-End Response Selection</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T21:46+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents an end-to-end response selection model for Track 1 of the 7th Dialogue System Technology Challenges (DSTC7). This task focuses on selecting the correct next utterance from a set of candidates given a partial conversation. We propose an end-to-end neural network based on enhanced sequential inference model (ESIM) for this task. Our proposed model differs from the original ESIM model in the following four aspects. First, a new word representation method which combines the general pre-trained word embeddings with those estimated on the task-specific training set is adopted in order to address the challenge of out-ofvocabulary (OOV) words. Second, an attentive hierarchical recurrent encoder (AHRE) is designed which is capable to encode sentences hierarchically and generate more descriptive representations by aggregation. Third, a new pooling method which combines multi-dimensional pooling and laststate pooling is used instead of the simple combination of max pooling and average pooling in the original ESIM. Last, a modification layer is added before the softmax layer to emphasize the importance of the last utterance in the context for response selection. In the released evaluation results of DSTC7, our proposed method ranked second on the Ubuntu dataset and third on the Advising dataset in subtask 1 of Track 1.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Building dialogue systems that can converse naturally with humans is a challenging yet intriguing problem of artificial intelligence. Recently, human-computer conversation has attracted increasing attention due to its promising potentials and alluring commercial values. According to the applications, dialogue systems can be roughly divided into two categories : (1) task-oriented systems and (2) non-taskoriented systems (also known as chatbots). Task-oriented systems aim to assist the user to complete certain tasks (e.g. booking accommodations and restaurants). Non-taskoriented systems aim to engage users in human-computer conversations in the open domain and attract lots of research attentions because they target on unstructured dialogues without a priori logical representation for the information exchanging during the conversation.</p><p>Copyright c 2019, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.</p><p>Existing approaches to dialogue response generation includes generation-based methods <ref type="bibr" target="#b6">(Shang, Lu, and Li 2015;</ref><ref type="bibr" target="#b5">Serban et al. 2016</ref>) and retrieval-based methods <ref type="bibr" target="#b9">(Zhou et al. 2016;</ref><ref type="bibr" target="#b8">Wu et al. 2017)</ref>. Generation-based models maximize the probability of generating a response given the previous dialogue. This approach enables the incorporation of rich context when mapping between consecutive dialogue turns. Retrieval-based methods select a proper response for the current conversation from a repository with response selection algorithms, and have the advantage of producing informative and fluent responses. Track 1 of the 7th Dialogue System Technology Challenges (DSTC7) is a kind of retrieval-based task which selects the correct response from a large set of candidates. The set used in this track contains more candidates than many other datasets. Some candidates are also similar which increases the difficulty of making right decisions.</p><p>The techniques of word embeddings and sentence embeddings are important to response selection as well as many other natural language processing (NLP) tasks. The context and the response must be projected to a vector space appropriately in order to capture the relationships between them, which are essential for following procedures. Recently there has been a growing interest in models for word-level <ref type="bibr" target="#b3">(Mikolov et al. 2013;</ref><ref type="bibr" target="#b4">Pennington, Socher, and Manning 2014;</ref><ref type="bibr" target="#b1">Dong and Huang 2018)</ref> and sentence-level <ref type="bibr" target="#b8">(Wang, Hamza, and Florian 2017;</ref><ref type="bibr" target="#b1">Chen et al. 2017</ref>) representations using neural networks, which helped classification or inference algorithms to achieve better performance in many NLP tasks.</p><p>Another key technique to the response selection task lies in context-response matching. Modeling the semantic matching degree between two sentences is challenging. The enhanced sequential inference model (ESIM) <ref type="bibr" target="#b1">(Chen et al. 2017</ref>) was proposed to measure the relationship between a pair of sentences in natural language inference (NLI) tasks. This model described the interactions between two sentences by sequential encoding and attention-based alignment. Considering the good performance and decomposable implementation of ESIM, it is adopted as our baseline model for response selection.</p><p>This paper introduces the end-to-end response selection method developed by us for subtask 1 of Track 1 in DSTC7. We propose to improve the original ESIM model for re-  sponse selection from the following four aspects.</p><p>• A new word representation method which combines the general pre-trained word embeddings with those estimated on the task-specific training set is adopted in order to address the challenge of out-of-vocabulary (OOV) words. • An attentive hierarchical recurrent encoder (AHRE) is designed which encodes sentences hierarchically and generates sentence representations by aggregation. • A new pooling method which combines multidimensional pooling and last-state pooling is used instead of the simple combination of max pooling and average pooling in the original ESIM. • A modification layer is added before the softmax layer to emphasize the importance of the last utterance in the context for response selection.</p><p>As shown in the released challenge results, our proposed model ranked second on the Ubuntu dataset and ranked third on the Advising dataset in subtask 1 of Track 1. In the following sections, we first introduce the task descriptions of Track 1 in DSTC7, and present the details of our proposed model. Then the model configurations, training settings and evaluation results are shown. Furthermore, the experimental results are analyzed by ablation tests. Finally we draw conclusions and give an overview of our future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Task Description</head><p>The DSTC7 Track 1 organizers provided two datasets <ref type="bibr" target="#b2">(Kummerfeld et al. 2018)</ref>. One is Ubuntu Dialogue Corpus which contains dialogues between Ubuntu users for the purpose of solving an Ubuntu users posted problem and the other is Advising Data which consists of dialogues between a student and a advisor for the purpose of guiding the student to pick courses. The task is divided into 5 subtasks and a participant may participate in one, several, or all the subtasks. Participants are required to meet different goals for different subtasks such as selecting the next utterance from the given 100   candidates or 120k candidates, selecting the next utterance with the set of paraphrases, selecting the next utterance with a candidate pool which might not include the correct next utterance, and selecting the next utterance with a model incorporating external knowledge. Each subtask has its corresponding dataset and each dialogue in it has its corresponding response candidates together with the correct answer. Due to limited time and manpower, we only participate subtask 1 of this track, which aims to select the next utterance from a candidate set of 100 utterances. An example dialogue and its candidates is shown in <ref type="table" target="#tab_1">Table 1</ref>.</p><formula xml:id="formula_0">...</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>BiLSTM Layer L</head><formula xml:id="formula_1">1 A 2 A L A 1 B 2 B L B att A att B Pre-trained</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Description</head><p>Our proposed model is composed of five components: Word Representation Layer, Encoding Layer, Matching Layer, Prediction Layer and Modification Layer. <ref type="figure" target="#fig_1">Figure 1</ref> shows the diagram of the model architecture. Details about each layer are described in this section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Word Representation Layer</head><p>One challenge of modeling dialogue is the large number of out-of-vocabulary words. To address this issue, we adopt an algorithm (Dong and Huang 2018) which combines the general pre-trained word embedding vectors with those generated on the task-specific training set to enhance word representations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Encoding Layer</head><p>Recurrent neural networks (RNN) <ref type="bibr" target="#b2">(Mikolov et al. 2010)</ref> have been proven to be good at modeling chronological relationship in language sequences and multi-layer RNNs have achieved good performance in many NLP tasks such as neural machine translation (NMT) (Bahdanau, Cho, and Bengio 2014) and natural language inference (NLI) <ref type="bibr" target="#b1">(Chen et al. 2017)</ref>. Encoding the sequences with deep neural networks can help capture deeper and more useful information. Typically, the outputs of the top RNN layer are regarded as the final sentence representations and the other layers are neglected. However, the lower layers can also provide useful sentence descriptions, such as part-of-speech tagging and syntax-related ones <ref type="bibr" target="#b1">(Hashimoto et al. 2017</ref>).</p><p>To make full use of the representations at all hidden layers, we propose a new sentence encoder called attentive hierarchical recurrent encoder (AHRE). This encoder is motivated by the method of embeddings from language models (ELMo) <ref type="bibr" target="#b5">(Peters et al. 2018</ref>) which combines the internal states of multi-layer RNNs. More specifically, an AHRE learns a linear combination of the vectors stacked above each input word, which improves the performance of just using the top RNN layer in our experiments.</p><p>Let</p><formula xml:id="formula_2">A 0 = [a 0 1 , ..., a 0 la ] and B 0 = [b 0 1 , ..., b 0 l b</formula><p>] denote sequences of word representations of context and response respectively. l a and l b are token numbers in these two sequences. Both a 0 i ∈ R l and b 0 j ∈ R l are l-dimentional embedding vectors given by the word representation layer mentioned above. Furthermore, bidirectional LSTMs (BiL-STM) <ref type="bibr" target="#b2">(Hochreiter and Schmidhuber 1997)</ref> are employed as our basic building blocks. In an L-layer RNN, the l th layer takes the output of the l − 1 th layer as its input. We denote the calculations as the follows,</p><formula xml:id="formula_3">a l i = BiLSTM(a l−1 , i), i ∈ {1, ..., l a }, l ∈ {1, .., L}, (1) b l j = BiLSTM(b l−1 , j), j ∈ {1, ..., l b }, l ∈ {1, .., L}.</formula><p>(2) The weights for these two BiLSTMs are shared in our implementation. Due to limit space, we skip the descriptions on the basic chain LSTMs and readers can refer to <ref type="bibr" target="#b2">(Hochreiter and Schmidhuber 1997)</ref> for details.</p><p>Finally we get a set of L representations {a 1 , ..., a L } and {b 1 , ..., b L } through the L-layer RNNs. Typically a L or b L , i.e. the outputs of the top layer, are used as the final encoded vectors. Here, we propose to combine the set of representations to get enhanced representations a att i and b att j by learning attention weights of all layers. Mathematically, we have</p><formula xml:id="formula_4">a att i = L l=1 w l a l i , i ∈ {1, ..., l a },<label>(3)</label></formula><formula xml:id="formula_5">b att j = L l=1 w l b l j , j ∈ {1, ..., l b },<label>(4)</label></formula><p>where w l are softmax-normalized weights shared between context and response which need to be estimated during the training process. Our representations differ from those of traditional encoder in that ours not only considers the top layer representations but also takes the lower layer representations which may be informative into account. As a result, the representations given by our encoder are expected to capture and fuse multi-level characteristics of sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Matching Layer</head><p>Interactions between context and response is important to provide information for deciding the matching degree between them. Our model follows the matching part of ESIM <ref type="bibr" target="#b1">(Chen et al. 2017)</ref> which collects local information between two sentences by attention-based alignment and is fully computationally decomposable. First, a soft alignment is conducted by computing the attention weight between each representation tuple</p><formula xml:id="formula_6">{a att i , b att j } as e ij = (a att i ) T · b att j .<label>(5)</label></formula><p>Then, local inference is determined by the attention weights e ij computed above to obtain the local relevance between a context and a response. For a word in the context, its relevant representation carried by the response is identified and composed using e ij as</p><formula xml:id="formula_7">a att i = l b j=1 exp(e ij ) l b k=1 exp(e ik ) b att j , i ∈ {1, ..., l a },<label>(6)</label></formula><p>whereā att i is a weighted summation of {b att j } l b j=1 . Intuitively, the contents in {b att j } l b j=1 that are relevant to a att i are selected to formā att i . The same calculation is performed for each word in the response as To further enhance the collected information, we compute the differences and the element-wise products between {A att ,Ā att } and between {B att ,B att }. The difference and element-wise product are then concatenated with the original vectors to get the enhanced representations as follows,</p><formula xml:id="formula_8">M a = [A att ;Ā att ; A att −Ā att ; A att Ā att ],<label>(8)</label></formula><formula xml:id="formula_9">M b = [B att ;B att ; B att −B att ; B att B att ].<label>(9)</label></formula><p>Then, BiLSTMs are employed to compose the enhanced local matching information M a and M b as</p><formula xml:id="formula_10">v a i = BiLSTM(M a , i), i ∈ [1, ..., l a ],<label>(10)</label></formula><formula xml:id="formula_11">v b j = BiLSTM(M b , j), j ∈ [1, ..., l b ].<label>(11)</label></formula><p>where BiLSTMs have d hidden units along each direction and {v a i , v b i } ∈ R 1×2d . Instead of using max pooling and average pooling in the original ESIM model, we combine multi-dimensional pooling <ref type="bibr" target="#b7">(Shen et al. 2017</ref>) and last-state pooling to derive the final matching feature vectors from the sequences of v a i and v b i .</p><p>Multi-dimensional attention differs from general attention in that the logit for an input vector is not a scalar but a vector with dimensions equal to the dimensions of the input vector. This allows each dimension of the input vector to have a scalar logit, and we can perform attention in each dimension separately. In our model, for v a i , its logit l(v a i ) is calculated by two linear transformations with an exponential linear units (ELU) activation function in between, i.e.,</p><formula xml:id="formula_12">l(v a i ) = ELU(v a i W M 1 + b M 1 )W M 2 + b M 2 ,<label>(12)</label></formula><p>where</p><formula xml:id="formula_13">{W M 1 , W M 2 } ∈ R 2d×2d and {b M 1 , b M 2 } ∈ R 1×2d . Further, we have d a i = sof tmax(l(v a i )) v a i ,<label>(13)</label></formula><formula xml:id="formula_14">d a = la i=1 d a i .<label>(14)</label></formula><p>The calculations of Eq. (12)- <ref type="formula" target="#formula_5">(14)</ref> are also applied to v b j to get d b . Finally, we combine the multi-dimentional pooling introduced above and last-state pooling to form the matching feature vector as</p><formula xml:id="formula_15">f = [d a ; d b ; v a la ; v b l b ].<label>(15)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Prediction Layer</head><p>The matching feature vector f is fed into a multi-layer perception (MLP) classifier. An MLP is a feedforward neural network estimated in a supervised way using examples of features together with known labels. Here, the MLP is designed to predict whether a pair of context and response match appropriately through the matching feature f. Finally, the MLP returns a score s 1 before softmax to denote the degree of matching.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Modification Layer</head><p>At this layer, the matching score given by the prediction layer is further modified to emphasize the effect of the last utterance in the context. We denote the length of the last utterance u as l u and its output after AHRE as u att . A laststate pooling is employed over it to get its representation u att lu . A transform matrix is applied to compute another matching score s 2 and the final score s is the combination of s 1 and s 2 with a scalar weight</p><formula xml:id="formula_16">s 2 = (u att lu ) T · M · b att l b ,<label>(16)</label></formula><formula xml:id="formula_17">s = s 1 + w · s 2 ,<label>(17)</label></formula><p>where M and w are both parameters need to be estimated during training. Finally, a softmax layer is applied to the score s to predict the correct answer among all candidates. All model parameters are estimated in an end-to-end way by minimizing the multi-class cross-entropy loss on training set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiments Dataset</head><p>There were two datasets provided by the subtask 1. Both of them provided 100k training dialogues and each was equipped with 100 candidates. They are different in the development dataset size, test dataset size and vocabulary size. Specifically, the Ubuntu dialogue has 5k development dialogues and the vocabulary size is 113k, while the Advising dialogue has only 0.5k development dialogues and the vocabulary size is only 5k.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Training details</head><p>Adam method (Kingma and Ba 2014) was employed for optimization with a minibatch size of 2. The initial learning rate was 0.001 and was exponentially decayed by 0.96 every 5000 steps. The word embeddings were concatenations of 300-dimensional fixed GloVe embeddings (Pennington, Socher, and Manning 2014) and 100-dimensional embeddings estimated on the training set using Word2Vec <ref type="bibr" target="#b3">(Mikolov et al. 2013)</ref> algorithm. The word embeddings were not updated during training. All hidden states of LSTM had 200 dimensions. The number of BiLSTM layers in AHRE was 3. The MLP at the prediction layer had a hidden unit size of 256 with ReLU (Nair and Hinton 2010) activation. We set the maximum context length as 160. Zeros were padded if the length was less than 160, otherwise the last 160 words were kept. We used the development dataset to select the best model for testing. All codes were implemented using TensorFlow framework (Abadi et al. 2016) and were released to help replicate our results 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evaluation metrics</head><p>Both datasets in the task were designed for selecting the best answer among a set of candidates for each given conversation. Recalls of the selected top-k responses from 100 available candidates for each conversation (i.e., R 100 @k) were employed as metrics to evaluate our model performance.</p><p>We also used mean reciprocal rank (MRR) to evaluate our model performance, which is a statistic measure for evaluating any process that produces a list of possible responses to a sample of queries, ordered by probability of correctness. The reciprocal rank of a query response is the multiplicative inverse of the rank of the first correct answer, and MRR is the average of the reciprocal ranks of results for a query set Q. It can be formulated as</p><formula xml:id="formula_18">M RR = 1 |Q| |Q| i=1 1 rank i ,<label>(18)</label></formula><p>where rank i refers to the rank position of the first relevant document for the i-th query.</p><p>The average of R 100 @10 and MRR was adopted by the challenge organizers to get the ranks of all participants.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>The results of our model on Ubuntu dataset and Advising dataset are summarized in <ref type="table" target="#tab_4">Table 2</ref>. We tuned our single models on the development datasets and submitted the final results for subtask 1 of the track using ensemble models. The ensemble models were built by averaging the outputs of three single models with identical architectures and different random initializations. It should be noticed that the test set originally released for the Advising dataset had some dependency with the training set which we denoted as Advising-Case 1 in <ref type="table" target="#tab_4">Table 2</ref>. The Advising-Case 2 test set was further released to better evaluate model performance for unseen conversations and was used for system ranking.</p><p>According to the evaluation results released by challenge organizers, our proposed method ranked second on the Ubuntu dataset and third on the Advising dataset in subtask 1 of Track 1 among all 20 participants.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset comparison</head><p>From the evaluation results on the two different datasets shown in <ref type="table" target="#tab_4">Table 2</ref>, we can see that there were significant recall and MRR differences between the two datasets although the same model architectures were shared. We have mentioned above that these two datasets were different in the sizes of development set, test set and vocabulary. Although the Ubuntu dataset had a much larger vocabulary, its development/test set performances were better than the Advising dataset. Meanwhile, our model showed a good generalization ability on the Ubuntu dataset because the evaluation results on test set were better than that on development set, showing its less dependency on the training set. However, the response selection performance on the Advising dataset was much worse. One possible reason is  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ablation tests</head><p>We further investigated the effects of different parts in our proposed model by removing them one by one. A single model built on the Ubutu dataset was adopted for this investigation and the development set performances are as shown in <ref type="table" target="#tab_5">Table 3</ref>. First, we can see that removing the modification layer degrades the recalls and MRR. This confirmed the positive effect of emphasizing the last utterance in the context for response selection. Second, we replaced the proposed AHRE with a simple single-layer BiLSTM at the encoding layer of our model and we can also see the performance degradation. Meanwhile, we also reported the learned weights of each layer in AHRE as shown in <ref type="table" target="#tab_6">Table 4</ref>. Furthermore, we replaced the multidimensional pooling and last-state pooling at the matching layer with max pooling and average pooling employed in original ESIM. The results shown that our proposed pooling strategy was more appropriate for the response selection task. Finally, the word embedding were updated instead of being fixed during the training process, which also led to a performance degradation. Actually, the model described by the last row in <ref type="table" target="#tab_5">Table 3</ref> was the original ESIM. Comparing the first row and the last row in this table, we can see that significant performance improvement has been achieved by applying all our proposed techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>In this paper, we have introduced our end-to-end model proposed for the response selection task in DSTC7. This model improves the original ESIM model from several aspects, including concatenated and fixed word representations, AHRE for sentence encoding, multi-dimentional and last-state pooling for context-response matching, and score calculation with emphasis on the last utterance in the context. In the released evaluation results of DSTC7, our proposed method ranked second on the Ubuntu dataset and third on the Advising dataset in subtask 1 of Track 1 among all 20 participants. Ablation tests also confirm the effectiveness of our proposed methods. Our future work includes to explore the methods for other subtasks and to design a more domain-general framework that can alleviate domain-dependency of models.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Diagram of our proposed model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>∈ {1, ..., l b }. (7)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Dialogue example of subtask 1.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 :</head><label>2</label><figDesc>Evaluation results on Ubuntu dataset and Advising dataset of subtask 1.R 100 @1 R 100 @10 R 100 @50 MRR</figDesc><table><row><cell>Our model (single)</cell><cell>0.521</cell><cell>0.817</cell><cell>0.982</cell><cell>0.616</cell></row><row><cell>-Modification layer</cell><cell>0.514</cell><cell>0.804</cell><cell>0.981</cell><cell>0.611</cell></row><row><cell>-Attentive hierarchical recurrent encoder</cell><cell>0.506</cell><cell>0.799</cell><cell>0.977</cell><cell>0.602</cell></row><row><cell>-Multi-dimensional and last-state pooling</cell><cell>0.5</cell><cell>0.791</cell><cell>0.974</cell><cell>0.598</cell></row><row><cell>-Fixed word embedding</cell><cell>0.488</cell><cell>0.776</cell><cell>0.969</cell><cell>0.591</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>Results of ablation tests using our single model on the Ubuntu development set of subtask 1.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>Weights of each layer in AHRE that the Advising dataset had a much small development set for model selection. Another reason is that there were some symbols such as EECS 351 and Classes 280 which increased the difficulty of representation and modeling.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/JasonForJoy/DSTC7-ResponseSelection</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Tensorflow: a system for largescale machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>References</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Abadi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.0473</idno>
	</analytic>
	<monogr>
		<title level="m">Neural machine translation by jointly learning to align and translate</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="265" to="283" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>OSDI</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A joint many-task model: Growing a neural network for multiple nlp tasks</title>
		<idno type="arXiv">arXiv:1802.02614</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1923" to="1933" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Recurrent neural network based language model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">K</forename><surname>Kummerfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Gouravajhala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Athreya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gunasekara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ganhotra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Polymenakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lasecki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>S ; Mikolov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<idno>arXiv:1810.11118</idno>
	</analytic>
	<monogr>
		<title level="m">Analyzing assumptions in conversation disentanglement research through the lens of a new dataset and model</title>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Eleventh Annual Conference of the International Speech Communication Association</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Rectified linear units improve restricted boltzmann machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 conference on empirical methods in natural language processing</title>
		<meeting>the 2014 conference on empirical methods in natural language processing<address><addrLine>Hinton</addrLine></address></meeting>
		<imprint>
			<publisher>EMNLP</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
	<note>Proceedings of the 27th international conference on machine learning (ICML-10)</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Building end-toend dialogue systems using generative hierarchical neural network models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Peters</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2227" to="2237" />
		</imprint>
	</monogr>
	<note>Deep contextualized word representations</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Neural responding machine for short-text conversation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li ;</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1577" to="1586" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Disan: Directional selfattention network for rnn/cnn-free language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Shen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.04696</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Sequential matching network: A new architecture for multi-turn response selection in retrievalbased chatbots</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hamza</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><forename type="middle">;</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Hamza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Florian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="496" to="505" />
		</imprint>
	</monogr>
	<note>Proceedings of the 26th International Joint Conference on Artificial Intelligence</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Multi-view response selection for human-computer conversation</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="372" to="381" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
