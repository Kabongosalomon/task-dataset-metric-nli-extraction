<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/yhou/git/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2019-02-07T08:45+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">UWaterloo at SemEval-2017 Task 8: Detecting Stance towards Rumours with Topic Independent Features</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>August 3 -4, 2017. 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hareesh</forename><surname>Bahuleyan</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Waterloo</orgName>
								<address>
									<region>ON</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Vechtomova</surname></persName>
							<email>ovechtomova@uwaterloo.ca</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Waterloo</orgName>
								<address>
									<region>ON</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">UWaterloo at SemEval-2017 Task 8: Detecting Stance towards Rumours with Topic Independent Features</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 11th International Workshop on Semantic Evaluations (SemEval-2017)</title>
						<meeting>the 11th International Workshop on Semantic Evaluations (SemEval-2017) <address><addrLine>Vancouver, Canada</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="461" to="464"/>
							<date type="published">August 3 -4, 2017. 2017</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>This paper describes our system for subtask-A: SDQC for RumourEval, task-8 of SemEval 2017. Identifying rumours, especially for breaking news events as they unfold, is a challenging task due to the absence of sufficient information about the exact rumour stories circulating on social media. Determining the stance of Twitter users towards rumourous messages could provide an indirect way of identifying potential rumours. The proposed approach makes use of topic independent features from two categories, namely cue features and message specific features to fit a gradient boosting classifier. With an accuracy of 0.78, our system achieved the second best performance on subtask-A of Ru-mourEval.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In the recent years, with the increasing popularity of smartphones, social media has become one of the top sources of news. However, because all the content is user-generated, the truth behind such news stories may become difficult to verify. Spread of misinformation during the event of an emergency can potentially have negative impacts. Although a few studies in the literature have developed rumour classification algorithms for Twitter <ref type="bibr" target="#b4">(Qazvinian et al., 2011</ref>), these studies assume that the circulating stories about a topic or an event are known a priori (Eg: Is Barack Obama muslim ?). On the other hand, identifying rumour stories for breaking news events, as they unfold, is even more challenging ( <ref type="bibr" target="#b8">Zubiaga et al., 2016b</ref>). This is because during these early stages, the exact rumour stories propagating about the event are still unknown.</p><p>In such a scenario, studying the conversation between users discussing the event on Twitter can possibly give insights about the veracity of a circulating rumour story ( <ref type="bibr" target="#b9">Zubiaga et al., 2016c</ref>). By making use of the so-called 'wisdom of the crowd', the idea here is to understand how other users respond to rumourous tweets. It would be useful to identify if users may reply with an intent to support the story, deny the rumour by providing counter evidence or pose questions about the information stated <ref type="bibr" target="#b7">(Zubiaga et al., 2016a</ref>). Collating the stance of other users could indirectly help in resolving the veracity of a rumour.</p><p>The rest of this paper is organized as follows. Section 2 is a brief overview of the task. The features used and the modeling technique are described in section 3. The results are analyzed in section 4 and the conclusions from the study are provided in section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Task Description</head><p>The objective of subtask-A of RumourEval was to identify the stance of Twitter users towards rumour tweets. Given a rumourous tweet (source) and its conversation thread, the participants were required to classify the stance of each tweet (including the source tweet) with respect to the underlying rumour ( <ref type="bibr" target="#b1">Derczynski et al., 2017)</ref>. The type of interaction could be one of the following:</p><p>1. Support(S): responding user supports the veracity of the rumour 2. Deny(D): responding user denies the veracity of the rumour 3. Query(Q): responding user demands additional evidence 4. Comment(C): responding user's tweet is not useful in determining the veracity of the rumour</p><p>The training dataset consisted of 4519 tweets from eight breaking news stories. The test set had 1049 tweets corresponding to a mix of topics from different events.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">System Description</head><p>Breaking news events, as they unfold on social media, may not have sufficient topic-specific information that could assist in rumour identification. For this reason, we chose to design topic independent features for the task of rumour stance classification. Our hypothesis was that the presence of specific words in the reply tweets could potentially be indicative of reply type.</p><p>Prior to feature extraction, the following data pre-processing steps were carried out: (1) removal of quoted text (reply tweets at times quote the source tweet), (2) discarding URLs, unicode characters, HTML tags, and <ref type="formula">(3)</ref> stripping out the extra whitespaces and carriage returns in the text.</p><p>We began by manually inspecting tweet messages in the training dataset to come up with an initial hand-curated list of word features. On further analyzing these features, it was found that these words could be categorized into meaningful groups. Such 'cue words' have previously been reported to be useful in identifying an author's certainty in journalism ( <ref type="bibr" target="#b6">Soni et al., 2014</ref>), determining veracity of rumours ( <ref type="bibr" target="#b5">Reichel and Lendvai, 2016)</ref> and detecting disagreement in online dialogue ( <ref type="bibr" target="#b3">Misra and Walker, 2013)</ref>. As listed in Table 1, the first five categories of the cue features are Belief, Report, Doubt, Knowledge, Denial. The presence of belief or knowledge words could be indicative of a reply where the author expresses his support. As for doubt or denial word cues, they are more likely to be used when the replying author wishes to convey his disagreement. On the other hand, report cue words could be present in either a supporting tweet or a denying tweet. Table 2 provides example tweet messages containing different cue words and their corresponding true class-labels from the original dataset .</p><p>Internet slang and curse words are more likely to be present in reply tweets which are of type 'comment'. While negation words were useful in identifying denying replies, the occurrence of question words in the text were very informative in capturing query type replies. We have a list of certain other cue words, which could not be fit into any particular category, but were useful in this 4-class classification problem. The cue word feature categories along with examples are shown in <ref type="table" target="#tab_1">Table  1</ref>. In total, there were 153 such features. <ref type="bibr">1</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Feature</head><p>Example Words   Apart from the cue word features discussed earlier, certain other tweet specific features were also used as part of our model. These message level features provide information about the writing style, such as the presence of punctuation marks, Twitter-specific characters (such as #, @) and number of words/characters in the message. The entire list of features under this category have been summarized in <ref type="table" target="#tab_4">Table 3</ref>. For calculating the sentiment polarity score, the lexicon based social media sentiment calculator, VADER, developed by <ref type="bibr" target="#b2">Hutto and Gilbert (2014)</ref>, was used. <ref type="bibr">1</ref> The cue word feature list used in this study is available at https://github.com/HareeshBahuleyan/ rumour-eval/blob/master/cue_word_list. txt It is to be noted that all of the features discussed in this section (except for similarity) were extracted from the reply tweets in the dataset. The task also required the source tweet to be classified as one of the four reply types. Since there wasn't enough data to train a separate model for predicting the label of source tweets, we made an assumption that all source tweets were 'supporting' the rumour, which was the majority class in the training set.  The numeric features, most of which were counts of specific characters or words, were used for training a supervised classification algorithm, specifically Gradient Boosting. Boosting is an additive and iterative tree-based supervised machine learning approach where a strong classifier is sequentially constructed from multiple weak learners. The XGBoost implementation of the gradient boosting algorithm was utilized in this study <ref type="bibr" target="#b0">(Chen and Guestrin, 2016)</ref>. The hyperparameters were tuned and set to be as follows:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Feature</head><p>1. n estimators = 100: Refers to the number of trees to be grown to fit the model. 2. max depth = 9: Number of splits for each of the weak learner trees. 3. sub sample = 0.8; Each tree uses a random subset of size 80% of the original training set size. Baseline: We also construct a unigram model as a baseline, which is compared against the proposed model that uses topic independent features. Because the unigram terms are unfiltered, the baseline model uses topic specific features as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>In this section, we discuss the performance of the model with topic independent features. We also compare it against the unigram baseline. Classification accuracy was the evaluation metric for this RumourEval subtask. However, since a majority of the tweets (about 70%) in the dataset belonged to the class label 'comment', we also report the macro-averaged F-score here.</p><p>The development set provided by the organizers was the set of tweets corresponding to the topic germanwings-crash. This was used for validating the model and determining the best combination of features from among the ones listed in the previous section. The results of the proposed model, in terms of accuracy and F-score, on the development set are shown in <ref type="table" target="#tab_6">Table 4</ref>. The model with the proposed set of features is observed to have a reasonable accuracy and F-score for all class labels, except for the 'deny' label, which it found difficult to identify.</p><p>The results on the actual test set, which was a mix of all topics, are summarized in <ref type="table">Table 5</ref>. All models performed similarly in terms of accuracy because a large proportion of the predicted labels belong to 'comment' class. However, the models with the topic independent features outperformed the baseline unigram model in terms of F-score. While the baseline model had an F-score of 0.31, the best combination of the proposed features resulted in an F-score of 0.45. The features were chosen by running validations with different feature combinations on the development dataset. The highest accuracy and F-score was obtained when the following features were discarded from the model: @user, hashtag, similarity, sentiment, characters. The submission with this model made our system the one with the second best performance for subtask A of RumourEval.</p><p>We also tried out models with features only from one category. When the cue features alone were used, the F-score was 0.34. On the other hand, the model with only the message specific features provided a higher F-score of 0.42. When all the proposed features were used for the classification task, it resulted in an accuracy of 0.77 with an F-score of 0.44, suggesting that, when used in tandem, the features yield a better result than using only a single category of features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>This paper provides a description of our submission for subtask A of RumourEval in which the participants were required to classify the stance of tweets towards rumours. The proposed model used topic independent features from two categories: cue features and message specific features.    <ref type="table">Table 5</ref>: Results for different feature combinations on the Test Set -Accuracy and F-score (macroaveraged and per class)</p><p>A gradient boosting classifier was implemented for this 4-class classification problem. Our system ranked second in terms of accuracy. For future work, we plan to investigate if the tree structure of the conversation could provide insights about the reply type.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Features</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><head>Table 1 : Set of cue features and examples</head><label>1</label><figDesc></figDesc><table>Example Tweet 
Cue 
Word 
Type 

Reply 
Type 

@TroyBramston Source from Ray 
Hadley shows confirmed same re-
port of gunman claiming there are 
four packages around Sydney 

Knowle-
dge/ 
Report 
Support 

@PhilSerrin Me thinks you like to 
emote in suppositions. Truth is, 
you don't know what happened, 
but want to speculate. 

Doubt 
Deny 

@DaveBeninger 
@SheilaGun-
nReid Canadian news contradicts 
this 
Denial 
Deny 

@Manning Eli 1 @TheAnonMes-
sage2 I thought the same thing 
Belief 
Support 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 2 : Example tweets with cue words</head><label>2</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 : Set of tweet features and description</head><label>3</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table>Results for different feature combinations on the Development Set -Accuracy and F-score 
(macro-averaged and per class) 

Features 
Accuracy F-score Comment 
Deny 
Query 
Support 
Unigrams (Baseline) 
0.750 
0.31 
0.856 
0.000 
0.000 
0.386 
Only Cue Features 
0.757 
0.34 
0.860 
0.000 
0.085 
0.406 
Only Message Specific Features 
0.763 
0.42 
0.858 
0.000 
0.432 
0.400 
All Proposed Features 
0.770 
0.44 
0.867 
0.027 
0.473 
0.388 
All Features -{@user, hashtag, similar-
ity, sentiment, characters} 
0.780 
0.45 
0.869 
0.052 
0.494 
0.397 

</table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Guestrin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.02754</idno>
		<title level="m">Xgboost: A scalable tree boosting system</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">RumourEval: Determining rumour veracity and support for rumours</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leon</forename><surname>Derczynski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kalina</forename><surname>Bontcheva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Liakata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Procter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SemEval. ACL</title>
		<meeting>SemEval. ACL</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">8</biblScope>
		</imprint>
	</monogr>
	<note>Geraldine Wong Sak Hoi, and Arkaitz Zubiaga</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Vader: A parsimonious rule-based model for sentiment analysis of social media text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Clayton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Hutto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gilbert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eighth International AAAI Conference on Weblogs and Social Media</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Topic independent identification of agreement and disagreement in social media dialogue</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amita</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marilyn A</forename><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference of the Special Interest Group on Discourse and Dialogue</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">920</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Rumor has it: Identifying misinformation in microblogs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><surname>Vahed Qazvinian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rosengren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiaozhu</forename><surname>Dragomir R Radev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1589" to="1599" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Veracity computing from lexical cues and perceived certainty trends</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Uwe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piroska</forename><surname>Reichel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lendvai</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.02590</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Modeling factuality judgments in social media text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandeep</forename><surname>Soni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tanushree</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Gilbert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Eisenstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL (2)</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="415" to="420" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Stance classification in rumours as a sequential task exploiting the tree structure of social media conversations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arkaitz</forename><surname>Zubiaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elena</forename><surname>Kochkina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Liakata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Procter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Lukasik</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.09028</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Learning reporting dynamics during breaking news for rumour detection in social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arkaitz</forename><surname>Zubiaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Liakata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Procter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.07363</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Analysing how people orient to and spread rumours in social media by looking at conversational threads</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arkaitz</forename><surname>Zubiaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Liakata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Procter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PloS one</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">150989</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>Geraldine Wong Sak Hoi, and Peter Tolmie</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
