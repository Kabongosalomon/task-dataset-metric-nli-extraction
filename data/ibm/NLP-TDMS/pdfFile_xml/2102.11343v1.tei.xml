<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Understanding Catastrophic Forgetting and Remembering in Continual Learning with Optimal Relevance Mapping</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prakhar</forename><surname>Kaushik</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Gain</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Kortylewski</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Yuille</surname></persName>
						</author>
						<title level="a" type="main">Understanding Catastrophic Forgetting and Remembering in Continual Learning with Optimal Relevance Mapping</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T17:35+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Catastrophic forgetting in neural networks is a significant problem for continual learning. A majority of the current methods replay previous data during training, which violates the constraints of an ideal continual learning system. Additionally, current approaches that deal with forgetting ignore the problem of catastrophic remembering, i.e. the worsening ability to discriminate between data from different tasks. In our work, we introduce Relevance Mapping Networks (RMNs) which are inspired by the Optimal Overlap Hypothesis. The mappings reflects the relevance of the weights for the task at hand by assigning large weights to essential parameters. We show that RMNs learn an optimized representational overlap that overcomes the twin problem of catastrophic forgetting and remembering. Our approach achieves state-ofthe-art performance across all common continual learning datasets, even significantly outperforming data replay methods while not violating the constraints for an ideal continual learning system. Moreover, RMNs retain the ability to detect data from new tasks in an unsupervised manner, thus proving their resilience against catastrophic remembering.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Continual learning refers to a learning paradigm where different data and tasks are presented to the model in a sequential manner, akin to what humans usually encounter. But, unlike humans or animal learning, which is largely incremental and sequential in nature, artificial neural networks (ANNs) prefer learning in a more concurrent way and have been shown to forget catastrophically. The term catastrophic forgetting (CF) in neural networks is usually used to define the inability of ANNs to retain old information in the presence of new one. Continual Learning (CL) in Neural Networks. The widely understood formulation of continual learning refers to a learning paradigm where ANNs are trained strictly sequentially on different data and tasks <ref type="bibr" target="#b4">(Chen &amp; Liu, 2018;</ref><ref type="bibr" target="#b29">Mundt et al., 2020)</ref>. The important conditions of the training paradigm are:</p><p>1. Sequential Training i.e. for a single neural network f with parameters θ trained at time T with sequentially available data D 1...N ,</p><formula xml:id="formula_0">T 1 [f θ (D 1 )] &lt; T 2 [f θ * (D 2 )] &lt; ... &lt; T N [f θ * * (D N )] 2.</formula><p>No negative exemplars, examples or feedback i.e. future (or past) data samples cannot be provided to the network with the current data/task.</p><formula xml:id="formula_1">(D 1 ∩ D T ) ∪ ... ∪ (D T −1 ∩ D T ) ∪ (D T ∩ D T +1 ) ∪ (D T ∩ D T +2 )... ∪ (D T ∩ D T +N ) = ∅</formula><p>Despite this formulation, since  showed the promise of memory replay methods in dealing with CF and the prevalence of cognitive/neuro science inspired theories regarding memory, it is of no surprise that rehearsal/replay buffer/generative replay methods dominate the current state of the art (SOTA) benchmarks . However, they clearly violate the conditions of the CL paradigm. Additionally, some most prominent current CL methods  change the ANN altogether by adding new convolutional/linear layers for each task (for e.g. using multi heads -different last linear layer for each task-has become a common practice) or using a mixture of ANNs which violates the above conditions as well since we are not training the same ANN f θ anymore. In contrast, we aim to develop a learning paradigm that strictly obeys the formulation of CL without applying data replay or introducing new sets of additional ANN models or convolutional/linear layers during training and inference.</p><p>Catastrophic Forgetting is a direct implication of continual learning in ANNs and is largely considered a direct consequence of the overlap of distributed representations in the network.Most prior works deal with CF by either completely removing the representational overlap <ref type="bibr" target="#b8">(French, 1991;</ref> or more frequently, by replaying data from previous tasks. Data replay methods can deal arXiv:2102.11343v1 <ref type="bibr">[cs.</ref>LG] 22 Feb 2021 with CF but, in turn, lead to a reduced capability of the network to discriminate between old and new inputs <ref type="bibr" target="#b38">(Sharkey &amp; Sharkey, 1995b)</ref>. This is referred to as Catastrophic Remembering (CR) (Refer to Section 3.1 for a detailed discussion) and has been shown to be a significant limitation of replay methods <ref type="bibr" target="#b38">Sharkey &amp; Sharkey, 1995b)</ref>.</p><p>The goal of this work is that we attempt to develop a method for continual learning for deep neural networks which can alleviate the twin problem of Catastrophic Forgetting and Catastrophic Remembering at the same time, without violating or relaxing the conditions of a strict continual learning framework.</p><p>Our proposed approach builds on the following Optimal Overlap Hypothesis: For a strictly continually trained deep neural network, catastrophic forgetting and remembering can be minimized, without additional memory or data, by learning optimal representational overlap, such that the representational overlap is reduced for unrelated tasks and increased for tasks that are similar.</p><p>More formally, for an ANN f Θ (D) with parameter Θ and sequentially available data D i over number of tasks/data i ∈ [1, T] instead of trying to enforce over-generalization which is to learn a superset parameter space which encompasses the sequential tasks {θ i | ∪θ 1...T = Θ ∧ ∩θ 1...T = ∅} or complete separation of weight space {θ i | ∪θ i Θ} , we try and learn optimal overlaps amongst the sequentially learned parameter sets. That means {∀i, j ∈ T i = j | θ i ∩ θ j = A ∧ ∪θ i = Θ} where A ∈ [∅, θ i/j ]. Inspired by this hypothesis, we propose Relevance Mapping for continual learning to alleviate CF and CR. During the continual learning process, our method learns the neural network parameters and a task-based relevance mask on the hidden layer representation concurrently. The almost-binary relevance mask keeps a portion of the neural network weights static and hence is able to maintain the knowledge acquired from previous tasks, while the rest of the network adapts to the new task. Our experiments demonstrate that Relevance Mapping Networks outperform all related works by a wide margin on many popular continual learning benchmarks (Permuted MNIST, Split MNIST, Split Omniglot, Split CIFAR-100), hence alleviating catastrophic forgetting without relaxing or violating the conditions of a strict continual learning framework. Moreover, we demonstrate that Relevance Mapping Networks are able to detect new sequential tasks in an unsupervised manner with high accuracy, hence alleviating catastrophic remembering.</p><p>In summary, our contributions are:</p><p>• We introduce Relevance Mapping Networks which learns binary relevance mappings on the weights of the neural network concurrently to every task. We demonstrate that our model efficiently deal with the twin problem of catastrophic forgetting and remembering.</p><p>• Our method achieves SOTA results on all popular continual learning benchmarks without relaxing the conditions of a strict continual learning framework.</p><p>• We re-introduce the concept of Catastrophic Remembering for deep neural networks and show that our method is capable of dealing with the same (becoming the first modern methodology to elevate catastrophic forgetting and remembering concurrently).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Continual Learning. Current continual learning mechanisms dealing with CF are broadly classified into regularization approaches, dynamic architecture, complementary learning systems and replay architectures <ref type="bibr" target="#b33">(Parisi et al., 2018)</ref>. Primarily based on the Stability-Plasticity Dilemma <ref type="bibr" target="#b28">(Mermillod et al., 2013)</ref> concept, regularization approaches impose constraints on weight updates to alleviate catastrophic forgetting like Elastic Weight Consolidation (EWC)  and Learning Without Forgetting <ref type="bibr" target="#b26">(Li &amp; Hoiem, 2018)</ref>. These methods do not ordinarily violate the conditions of the CL framework but have been shown to suffer from brittleness due to representational drift  and thus are usually combined with other methods. Rehearsal/replay buffer methods, like  which are the state-ofthe-art methods, use a memory store of past observations to remember previous tasks in order to alleviate the brittleness problem. However, these are not representative of strict sequential learning insofar that they still require re-learning of old data to some extent and perform significantly worse the less samples are replayed, and they may struggle to represent uncertainty about unknown functions.</p><p>There are no known methods which deal with CR in continual learning framework, with our method being the first of its kind to be able to combat catastrophic forgetting and remembering in a strict continual learning framework.</p><p>Catastrophic Remembering refers to the tendency of artificial neural networks to abruptly lose the ability to discriminate between old and new data/task during sequential learning. It is an important problem and inherently attached to the problem of catastrophic forgetting. But, unlike the problem of catastrophic forgetting, which has a rich literature of research, catastrophic remembering has not been explored outside of minor discussions in early works <ref type="bibr" target="#b37">(Sharkey &amp; Sharkey, 1995a;</ref><ref type="bibr" target="#b25">Lewandowsky &amp; Li, 1995;</ref><ref type="bibr" target="#b8">French, 1991)</ref>. In this work, we discuss CR from a probabilistic perspective (Section 3.1) and demonstrate that related work suffers from CR in our experiments in Section 5.2. Finally, we demonstrate that our proposed Relevance Masking Networks are much more resilient to catastrophic remembering.</p><p>Similar Methods. The idea of using soft-masking in networks (usually on non-linear activations) has been utilized before in novel ways for solving different problems. However, few of them, if any, ground these methods in some underlying concept (Optimal Overlap in our case) and often these methods include masks which are mutually exclusive, for example, for sparsity learning <ref type="bibr" target="#b44">(Zhu &amp; Gupta, 2017)</ref>, joint learning <ref type="bibr" target="#b27">(Mallya et al., 2018)</ref> where piggyback a pretrained network by using a non-differentiable mask thresholding function and value, etc. In contrast, we don't require our models to be pretrained or be thresholded. In CL, the following methods appear to be closest to our Relevance Mapping Networks (RMNs):  proposes hard attention (HAT), a task based attention mechanism which can be considered the most similar to our RMN. It differs from RMN due to following reasons-(i) They utilize task embeddings and a positive scaling parameter -and a gated product of these two is used to produce a non-binary mask -unlike our RMNs which don't use either a task embedding or a scaling parameter and is necessarily binary. (ii) Unlike RMNs, the attention on the last layer in HAT is manually hard-coded for every task. (iii) A recursive cumulative attention mechanism is employed to deal with multiple non binary mask values over tasks in HAT. RMNs however have no need for such a mechanism. (iv) HAT cannot be used in a unsupervised CL setup or to deal with CR and has not been implemented with more complex network architectures like Residual Networks.  uses proximal gradient descent algorithm to progressively freeze nodes in an ANN. (i) Unlike RMNs, this method employs selective regularization to signify node importance (which is calculated by lasso regularization).</p><p>(ii) This method progressively uses up the parameter set of the ANN and it is unclear whether it can be used for an arbitrary large number of sequential tasks. (iii) This method is also unable to deal with unsupervised learning scenario or CR. (iv) This method uses a different classification layer for each task -relaxing the core constraints of the problem altogether.</p><p>(Aljundi et al., 2018) (i) calculates the parameter importance by calculating sensitivity of the squared l2 norm of the function output to their changes and then uses regularization (similar to  to enforce in sequential learning, unlike RMNs. (ii) The method enforces fixed synaptic importance between tasks irrespective to their similarity and unlike our work, doesn't seem to be capable of working under Unsupervised Learning scenarios.  propose SNOW and (i) uses a unique channel pooling scheme to evaluate the channel relevance for each specific task which differs from RMN's individual node relevance mapping strategy. (ii) Importantly, this work, unlike RMNs, employs a pre-trained model which is frozen source model which already overgeneralizes to the CL problem at hand and thus makes this method inapplicable for dealing with CR. (iii) It also doesn't seem to be capable of handling unsupervised learning/testing scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Strict Continual Learning and a Catastrophic Memory</head><p>Continual learning has been an important topic since the onset of Machine Learning and the fact that ANNs are incapable of learning continually due to Catastrophic Forgetting has been a significant drawback. CF has been strongly identified with overlap of distributed representations <ref type="bibr" target="#b8">(French, 1991)</ref>.</p><p>Catastrophic forgetting from a probabilistic view. Intuitively, given a learnt initial set of parameters θ i for a neural network f and a task i with data D i , the network's parameters get overwritten when it learns a new set of network parameters θ i+1 from new data D i+1 for the (i + 1) th task. To facilitate the conceptual understanding of CF, we consider continual learning from a probabilistic perspective, where optimizing the parameters Θ of f is tantamount to finding their most probable values given some data D | D ⊃ D 1 , ..., D n . We can compute the conditional probability of the first task P(θ 1 |D 1 ) from the prior probability of the parameters P(θ 1 ) and the probability of the data P(D 1 |θ 1 ) by using Bayes' rule. Hence, for the first task, log P(θ 1 |D 1 )= log P(D 1 |θ 1 )+ log P(θ 1 )− log P(D 1 ).</p><p>(1)</p><p>Note that the likelihood term log P(D 1 |θ 1 ) simply represents the negative of the loss function for the problem at hand . Additionally, the posterior term is usually intractable and only approximated for ANNs  and we are just considering it here without change for analysis purposes only. If we were to now train the same network for a second task, the posterior from (1) now becomes a prior for the new posterior. If no regularization or method is included to preserve the prior information, we'd optimize for the second task, log P(θ 1:2 |D 1:2 )= log P(D 2 |θ 2 )+ log P(θ 1 |D 1 )</p><p>− log P(D 2 ) = log P(D 2 |θ 2 )+ log P(D 1 |θ 1 )</p><p>+ log P(θ 1 )− log P(D 1 )− log P(D 2 ).</p><p>If the likelihood term is not optimised over both θ 1 and θ 2 , as would happen normally in a ordinary ANN training setup, the prior information can be overwritten, leading to the condition commonly referred to as catastrophic forgetting.</p><p>Overcoming catastrophic forgetting. We can clearly see from Eq. 3, if we had access to the previous data D 1 or if both θ 1 and θ 2 were independent of one another, we could approximate a well optimized posterior. However, in a typical continual learning setting we do not have access to the previous data and cannot ordinarily make independence assumptions on the sequentially learnt parameters. However, this provides us a with a crucial conceptual understanding of how to deal with CF and an insight towards understanding the mechanisms of current popular CL methods, which aim to overcome either of the two mentioned restrictions. In particular, some recent works <ref type="bibr" target="#b27">(Mallya et al., 2018;</ref> try to effectively separate the model parameters θ i for different tasks, as initially proposed by <ref type="bibr" target="#b7">(French, 1994)</ref>. The most successful recent works  involve data replay methods, which relax the previous data availability restriction and have been shown to be effective initially by . Despite its success in dealing with CF to an extent, data replay drastically diminishes the discriminative ability of the ANN, which is referred to as Catastrophic Remembering . This usually happens when the ANN learns a more general function f (Θ) than necessary, generalizing not only to the individual tasks, but to the entire sequential set of tasks {θ | ∀θ i Θ} which we has been referred to as overgeneralization . The network can then experience a sense of extreme deja vu <ref type="bibr" target="#b38">(Sharkey &amp; Sharkey, 1995b)</ref> and is unable to differ the old from new data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Catastrophic Remembering</head><p>For a better understanding of CR and why CF alleviation aggravates it, we calculate the posterior after the n th task learnt continually using Eq. <ref type="formula" target="#formula_3">(3)</ref>,</p><formula xml:id="formula_4">log P(θ 1:n |D 1:n ) = log P(D n |θ n ) + n−1 i=1 log P(D i |θ i ) + log P(θ 1 ) − C<label>(4)</label></formula><p>where C is a constant representing the sum of the normalization constants n i=1 log P(D i ). As discussed earlier, the information of from the previous tasks is passed to the next sequential task as a prior (</p><formula xml:id="formula_5">n−1 i=1 log P(D i |θ i )).</formula><p>The problem of loss of discriminative ability arises when for an arbitrary large n when the prior term far exceeds the currently optimized likelihood. For Eq. (4), that means</p><formula xml:id="formula_6">log P(D n |θ n ) &lt;&lt; n−1 i=1 log P(D i |θ i ).<label>(5)</label></formula><p>In the context of data replay methods this intuitively means that if the number of data from the previous tasks {D 1 , . . . , D n−1 } is far bigger than the data in the current task D n the contribution of the present likelihood to the posterior is negligible and no new features are learnt by the ANN to account for the new dataset/task. This, in turn, gives the model a sense of false familiarity with a new input and the model is no longer able to discriminate between old and new inputs. The above explanation, though not exhaustive, provides a initial understanding from a Bayesian viewpoint.</p><p>One may argue against the necessity of the discriminative property that CR attacks in ANNs. While, it is true that just concentrating on generalization may allow us to ignore the problems of CR, but novel input and task detection are important problems in Artificial Intelligence, Computer Vision and Robotics. It can be necessary to detect new inputs to learn more robust features for the current data, e.g. a self driving network may need to identify whether it is familiar with a current set of input data. Additionally, Recognition and discrimination memory are important aspects of human memory and learning -concepts which artificial networks have been trying to replicate.</p><p>Balancing Forgetting and Remembering Having gained a basic understanding about CF and CR, an astute reader realizes the crux of the problem that we are dealing with. Alleviating CF appears to aggravate CR. While current literature focuses on alleviating CF, the problem of CR does not receive much attention. One aim of this work is to shed light on the twin problem of catastrophic forgetting and remembering and to introduce a method which can balance alleviating both problems concurrently.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Relevance Mapping for Continual Learning</head><p>We introduce Relevance Mapping, which is a method inspired by the Optimal Overlap Hypothesis, that aims to learn an optimal representational overlap, such that unrelated tasks use different network parameters, while allowing similar tasks to have a representational overlap. Note that our method avoids data replay and instead aims to achieve independence between network weights that are used for different sequential tasks.</p><p>Algorithmic implementation of Relevance Mapping. To illustrate and motivate Relevance Mapping Networks (RMNs) using a simple example, we consider a multilayer perceptron (MLP) with two layers f defined as</p><formula xml:id="formula_7">f (x) σ(W 2 σ(W 1 x)),<label>(6)</label></formula><p>where x ∈ R d1 , W 1 ∈ R d2×d1 , and W 2 ∈ R d3×d2 , and σ denotes a nonlinear activation function. We denote the set of weights as W {W 1 , W 2 }. Although it may depend on the dimensionality of the task, overparameterization occurs even in these simple MLP settings. For a sufficiently simple task, only a subset of the parameters in W are often required . For example, if the optimization task has ground truth outputs specified as f * (x) = σ(W * 2 σ(W * 1 x)) for optimized weights {W * 1 , W * 2 }, and ||W * 1 || 0 + ||W * 2 || 0 d 3 d 2 + d 2 d 1 (i.e. the number of non-zero weights needed for the ground-truth function is much less than the number of total weight parameters) then only ||W * 1 || 0 + ||W * 2 || 0 weight parameters are necessary to be learned in network f . In theory, if we could learn the importance or relevance of each weight node, we could apply a zero-mask to the non-essential parameters without pruning or modifying them and still successfully learn the ground-truth. A set of mappings can be denoted as</p><formula xml:id="formula_8">M P = {M P1 , M P2 }, where M P1 ∈ {0, 1} d2×d1 and M P2 ∈ {0, 1} d3×d2</formula><p>, explicitly representing the neuron-toneuron connections of the network. The initialized relevance mappings of an ANN can be approximated by a logit-normal distribution mixture which is rounded during inference.</p><formula xml:id="formula_9">M Pk ≈ k L R N (µ k , σ 2 k )</formula><p>where µ, σ are the initializing distribution parameters and L R sigmoidal pseudo-round function:</p><formula xml:id="formula_10">L R (x k ; β) = 1 1 + exp(−(β(x k − 0.5)))<label>(7)</label></formula><p>This is done in order to make the mappings differentiable and the individual mixture components are jointly optimized for the task with the network parameters.</p><p>In theory, any network f with weight tensors W can have such corresponding sets of neuron connection representations M P1 , M P2 , . . . M PT for T tasks/mappings, where each set M Pi activates a subnetwork mapping in f that could be used for various purposes for a task i.</p><p>Note that lim β→∞ (L R (x, β)) for x ∈ [0, 1] is equivalent to the rounding function. Here, β is a learnable, layer-wise parameter (i.e., in our implementation, there is one specific β for every layer of a given network) that controls the "tightness" of R. To achieve an approximate neuron-connection representation, we defineM P = L R (M P ; β) where M P is initialized from some distribution with support [0, 1] (in experiments, we initializeM P with a clipped, skewed normal distribution).</p><p>In our presented work, we can think of the RMNs as replacing the weights of a network with the product of the weights and a binary relevance mixture. In this work, we introduce two algorithms, Algorithm 1 and 2 (Supplementary Sec. 2) which make use of Relevance Mapping. The former is used for traditional Supervised CL experiments which used to evaluate CF alleviation. The latter is used for the Unsupervised scenario (new task detection and unsupervised task inference) concerning evaluation of CR alleviation. Importantly, neither of the algorithms relax the conditions of a strict CL framework (Section 1). 1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Probabilistic interpretation of Relevance Mapping.</head><p>French introduced the method of context-biasing in <ref type="formula" target="#formula_4">(1994)</ref> which produces internal representations which are both well distributed and well separated to deal with CF. RMN preserves a similar idea of distribution and separability without constraining for an explicit representation separation amongst posteriors learnt for the sequential tasks. The separation, in turn, is provided by the relevance mappings.</p><formula xml:id="formula_11">P(θ 1 , M P1 |D 1 ) ∝ P(D 1 |θ M P1 )P(θ M P 1 )<label>(8)</label></formula><p>The 1st task of the CL problem presented in Eq. <ref type="formula" target="#formula_11">(8)</ref> is similar to Eq. (1) with relevance mappings introduced under the conditions of the algorithm presented. θ M Pi represents only a subset of θ for which M Pi = 1. For learning the second task we optimize</p><formula xml:id="formula_12">P(θ 1:2 , M P2 |D 1:2 ) ∝ P(D 2 |θ M P 2 )P(θ 1 , M P1 |D 1 ).<label>(9)</label></formula><p>In Eq. <ref type="formula" target="#formula_12">(9)</ref>, the second term on the right doesn't contribute anything to the optimization over the second task due to the presence of independent relevance mappings which effectively disengages θ M P1 from further tampering and the next task receives a slightly constrained prior distribution that we can refer to as θ 2 . The θ M P1 parameter set is however still available to the second task. Eq. (9) now becomes</p><formula xml:id="formula_13">P(θ 1:2 , M P2 |D 1:2 ) ∝ P(D 2 |θ M P2 )P(θ 2 )<label>(10)</label></formula><p>which is effectively now a problem of just jointly optimizing an ANN's parameters (Θ, M P2 ) without any dependence on the previous task's posterior. We have effectively decomposed the sequential task parameters. There are three scenarios that may occur w.r.t the optimised parameters i.e. (k represents the individual elements) (i)</p><formula xml:id="formula_14">M P k 2 = M P k 1 ⇒ θ k M P1 = θ k M P2 (i) M P k 2 = 1 &amp; M P k 1 = 0 ⇒ {θ k M P 1 ∩ θ k M P2 = ∅}(iii) M P k 2 = 0 &amp; M P k 1 = 1.</formula><p>All of these scenarios can be handled by RMNs thanks to the O 2 hypothesis.</p><p>For n tasks, (10) becomes,</p><formula xml:id="formula_15">P(Θ, M P |D 1:n ) ∝ n i=1 P(D i |θ M Pi )P(θ i )<label>(11)</label></formula><p>Looking at (11) which is a basic Bayesian expression for a normal ANN, we can now understand that O 2 hypothesis inspired RMN algorithm is capable of learning well separated and well distributed internal representations thanks to the posterior decomposition induced by our method. This takes care of the problem of CF and since the parameters of the model are jointly optimized over both the RMN parameters Θ and the relevance mappings M P , the network cannot The focus in RMNs is not to force a zero representational overlap or just generalize to all the sequential tasks altogether but rather to utilize the over-parameterization property of ANNs  and learn an optimal representational overlap for all tasks in the weight spacecorroborating the Optimal Overlap Hypothesis. Therefore, there's no constraint on the maps M P to minimize the overlap with each other or a global loss function which takes in account of the loss of individual tasks.The map M P for each task helps define a subset of the final weight mapping of the ANNs. This subset may be disjoint or overlapping with other M P defined weight subsets. Since, all the sequential tasks' parameter mappings are subsets of the final weight mapping (with M P defining the set relationship), we are able to alleviate both CF (the final mappings generalizes well for all the tasks) and CR (the M P preserve the relationship between the global and individual parametric mappings).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Supervised CL (Testing Catastrophic Forgetting)</head><p>We evaluate RMNs on supervised sequential learning tasks, which enables us to measure their ability to alleviate CF. In this setup, the network is given data for learning one task followed by another. The challenge lies in retaining the performance on previous tasks even as new tasks are learned, hence alleviating catastrophic forgetting. This experimental framework is commonly used in CL literature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Setup. We use standard baseline architectures, including</head><p>CNNs (LeCun et al.), Siamese Networks <ref type="bibr" target="#b17">(Koch et al., 2015)</ref>, and Residual Networks  and apply Relevance Mapping to them (denoted as CNN-RMN, Siamese-RMN. Resnet18-RMN, etc.). For task-wise classification, we let the classification output f (x; W, M P1 , . . . M PT ) argmax i∈{1...T } ({f (x; W, M Pi )} so that no task-specific information is utilized at inference time. We also augment the loss function with L1-norm penalty on M P masks and sum of overlap of M P1 , . . . M PT ) to reward sparsity and optimal separation of weight spaces, respectively. We adhere to the strict CL(Section 1) framework in RMN experiments.</p><p>Models. As is common in related work , we evaluate RMNs on five benchmarks: Permuted-MNIST (Kirkpatrick et al., 2017)(P-MNIST), Split-MNIST(S-MNIST), Sequential Omniglot(S-OMNIGLOT) <ref type="bibr" target="#b35">(Schwarz et al., 2018)</ref>, 10 task Split-Cifar100 (Zenke et al., 2017)(S-CIFAR100) and 20 task Split-Cifar100 (RES-CIFAR). To validate the efficacy of RMNs on complex architectures, the RES-CIFAR model is trained on a Resnet18. For 10 task S-Cifar100, we used 6 convolution layers followed by 2 fully connected layers (with ReLU activations). S-MNIST, P-MNIST and S-Omniglot architectures are same as in .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results and Discussion</head><p>As seen in <ref type="table" target="#tab_1">Table 1</ref>, our RMNs set the new state of the art across all continual learning benchmarks presented, with improvements of 2.8% (P-MNIST), 0.5% (S-MNIST), 3.9% (S-Omnliglot), 8.7% (S-Cifar100) and 13.9% (RES-CIFAR) over the previous SOTA. RMNs show their versatility in both simple (MLP) and complex (ResNet) architectures over both long (S-Omniglot, RES-CIFAR) and short continual learning, demonstrating their versatility. <ref type="figure" target="#fig_0">Figure 1</ref> shows an example of the effectiveness of RMNs as compared to other methods when dealing with CF.</p><p>To keep comparisons fair amongst methods, <ref type="table" target="#tab_1">Table 1</ref> is divided into two parts by a 2-line separator. The above part includes all the methods which do not obey the conditions of a strict CL framework. Some compared methods  employ data replay buffers while others cannot work efficiently without one or more multi-headed layers  or a version of it -for e.g.  use manual hard coding of layers per task. The lower part of <ref type="table" target="#tab_1">Table 1</ref> consists of methods which are implemented in a strict sequential learning setup. Unlike most of the compared methods, RMNs do not require any replay buffers, ensemble networks, meta networks, multi-headed layers or pretrained models and yet are able to outperform methods which do use such methods. We also compare RMNs with similar methods as mentioned in Section 2 and see that RMNs substantially outperforms every one of them as seen in <ref type="table" target="#tab_1">Table 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Unsupervised CL (Testing Catastrophic Remembering)</head><p>Measuring Catastrophic Remembering For a good measure of CR, we need to evaluate how well a sequentially trained ANN discriminates between old and new data as well as how well does it discriminate between all the tasks/data after it has been trained on all of them. To that end, we propose two tests: (1) (Unsupervised) New Task/Data De-  <ref type="formula" target="#formula_2">(2)</ref> Unsupervised Task Inference. In the new task detection setup, the ANN is given no supervision with respect to the new data or task and has to detect this change. The model's performance (for e.g., the accuracy for each task in case of classification) is compared with the supervised continual learning version. In the second test, a trained model has to detect which specific task does the test input data belongs to. A point to be noted is that the preconditions of the sequential training paradigm mentioned in Section 1 are to be strictly observed. The tests are mutually inclusive in terms of representing effectiveness w.r.t CR alleviation i.e. a method should perform well on both tasks to be good candidate for fixing Catastrophic Remembering (while still being able to alleviate Catastrophic Forgetting).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1.">NEW TASK/DATA DETECTION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Setup.</head><p>The model is given no information about the tasks during training (and inference) time. The results are then compared with the full supervised version <ref type="table" target="#tab_1">(Table 1)</ref>. The performance degradation from the supervised learning results allow us to evaluate how well the model can alleviate CR. Here, we assume that no information of task labels is given, including the number of disparate tasks. RMN Methodology. In this case, we initialize f with only a single M P , i.e. only a single forward inference path can be learned at initialization, as seen in Line 2 of Algorithm 2 (Suppl. Sec. 2). We set the current task indicator as est j =0. Then, for each minibatch x encountered, we run a task-switch-detection (T SD) method, denoted as T SD(x) which returns a boolean value. If T SD(x) returns True, then est j is incremented and another set of M P is added to f . We use a Relevance modified Welsh's t-test on the KL divergence between prior and posterior distributions of the model to determine a task switch <ref type="bibr" target="#b11">Hendrycks &amp; Gimpel, 2016;</ref><ref type="bibr" target="#b24">Lee et al., 2018)</ref>.</p><p>Results and Discussion. Few methods  have tried to effectively deal with the harder problem of learning continually without task labels and none of these follow a strict CL framework.  and  both employ a data replay buffer whereas  uses generative replay and a mixture of expert models (which leads to a large increase in computational and memory requirements). The usual methodology that is followed in an Unsupervised CL learning setup involves boundary detection between current and new tasks. <ref type="table" target="#tab_2">Table 2</ref> shows the results of this setup amongst all the relevant methods. RMNs achieve the state of the art for Unsupervised CL Learning without the usage of data replay buffer, mixture of expert models or any kind of generative replay, unlike . Ordinarily, these task detection methods employ statistical tests like Welch's Ttest over clean batches of data (the entire batch data belongs to either the current or the next task). This methodology fails when the incoming previous and the incoming batch are noisy with the incoming batch consisting of the new task data as well as old data. RMNs however can easily deal with this by filtering the incoming batch via final layer activations -only if RMNs have seen the data do they have high and confident activations before calculating the KL divergence test between the prior and posterior to detect the presence of a new set of data. However, none of the methods  mentioned are capable of deploying over such a noisy data setup and are unable to learn continually.  does employ a Fuzzy Testing scenario for Split-MNIST in which there are transition phases between tasks where the amount of new data increases linearly in each batch. Comparison on the same experiment is presented in <ref type="table" target="#tab_3">Table 3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2.">UNSUPERVISED TASK INFERENCE</head><p>Under this novel setup, the algorithm has to identify at inference time which task a data input belongs to amongst all the tasks it has learned. From a practical point of view, knowing which task in the sequential task list does the current inference data element belongs to, without human intervention opens up huge opportunities for automation and analysis.</p><p>Setup. After the ANN has been trained, the test data is randomized and provided to the model for inference without its task identity (something which would happen in real world CL scenario). The model identifies the task to which the data belongs to and then the test accuracy is calculated from the correctly identified task over the entire task set. For RMNs, as task j is not given at inference time, thus max k f (x, k; W ) is returned, as seen in Algorithm 2 (Suppl. Sec. 2). Our experimental results show that for any ground-truth task label j, indeed the desired result is f (x, j; W ) ≈ max k f (x, k; W ), which allows for unsupervised CL inference, as the pathways of different tasks don't overlap unless the tasks are the same. Results and Discussion. Unfortunately, we couldn't find any SOTA CL method which can be used for this experiment, or can be used with trivial modifications. It should be possible for  to possibly be able to extend the method to do unsupervised task inference. However since the method employs a mixture of expert models for every task as well as generative replay which in turn rapidly drives up computational and storage memory requirements for even small ANNs, it cannot be considered a strict CL setup or even a slightly relaxed version of the same. In <ref type="figure" target="#fig_1">Figure 2</ref>, we show how our algorithm is able to detect the right task -we see that the relevance-weight combination achieves the correct maximum activation in the final layer only when the correct relevance is used. We also display the percentage of correct activations for other relevance values even if they are not maximum activations. According to our knowledge, our method is the only known continual learning method under strict CL setup constraints capable of successfully accomplishing unsupervised task inference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In this work, we study the twin problem of catastrophic forgetting and remembering in continual learning. To resolve them, we introduce Relevance Mapping for continual learning, which applies a relevance map on the parameters of a neural network that is learned concurrently to every task. In particular, Relevance Mapping learns an optimal overlap of network parameters between sequentially learned tasks, reducing the representational overlap for dissimilar tasks, while allowing for overlap in the network parameters for related tasks. We demonstrate that our model efficiently deals with catastrophic forgetting and remembering, and achieves SOTA performance across a wide range of popular benchmarks without relaxing the conditions of a strict continual learning framework.</p><p>In Section 1 of the main paper, the concept of Continual Learning is defined and it is noted that most of the current state of the art Continual Learning methods relax the constraints of a strict continually learning framework. In <ref type="table" target="#tab_1">Table 1</ref>, we quote some of the major violations of a strict continual learning framework with reference to the state of the art methods compared in the main paper.</p><p>Data Replay refers to the usage of old or future task data in any way to train the neural network. Methods like , etc. all employ this tactic in unique ways to learn continually. It often involves saving old task data in memory modules and been originally inspired from  who was among the first researchers to show that data replay helps in alleviating catastrophic forgetting in artificial neural networks, albeit at an expense of relaxing the constraints of a strict continual learning setup.</p><p>Multihead usually refers to the usage of different last (usually linear) layer for each task. This has become particularly common in continual learning benchmarks with many methods  dissuading the usage of single heads for a continually learning neural network. There are a few methods which also employ similar but unique methodology. For e.g.  uses a binary hard coded final layer per task.</p><p>Pretrained refers to using a pretrained model (usually trained on a more complex dataset like ImageNet <ref type="bibr" target="#b47">(Deng et al., 2009)</ref>) for training on a simpler problem or dataset (e.g. CIFAR ). Having used data outside of the continual learning problem setup and since the model has now probably over-generalized to entire sequel data/task set, using a pretrained model relaxes the constraints of a strict continual learning.</p><p>Generative Replay ordinarily refers to the usage of generative modelling for the dataset or task at hand and using these generated samples for some form of data replay. The usage of additional generative model (even for simple classification models and tasks), saving old data points, etc. all violate the conditions of a strict continual setup.</p><p>Multi-Models refers to the usage of a neural model other than the original model to help with the continual learning problem. This can reflect in using meta networks, or in strategies similar to the one presented in  where separate delta models are used per task to help the original neural network learn continually.</p><p>The aforementioned concepts are not mutually exclusive and clearly do not present an exhaustive list of methods employed to relax a strict continual learning framework, however they do provide us a reference among-st the compared SOTA methods to ascertain which method displays the best results with least amount of constraint relaxation. <ref type="table" target="#tab_1">Table 1</ref> show that our method, RMNs, do not need to use any of the aforementioned methods to violate strict continual learning constraints and still produces the state of the art results in common Continual Learning benchmarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.">Catastrophic Remembering</head><p>A common solution for the problem of Catastrophic Forgetting is to overgeneralize to the entire set of sequential data/tasks. For example, methods which employ data replay, pre-training and knowledge distillation directly employ over-generalization for CF alleviation.</p><p>Over-generalization The concept of over-generalization (in the case of back propagated artificial neural networks) refers to the learning of parameter set by the neural network tries to or has already learned a much more general function than what is required.</p><p>A simple example to understand Catastrophic Remembering was provided in the work by <ref type="bibr" target="#b49">French (1999)</ref> where a network has a task of reproducing an input as output. A new input is detected if output diverges by a large margin. If the network learns too well and learns the identity function, then it has overgeneralized and hence loses the ability to detect new input. This trivial example presents one aspect of Catastrophic Remembering. However, there is no guarantee that the loss of discrimination always leads to correct generalization -the network just becomes too familiar with the input irrespective of whether the output is correct. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1.">SUPERVISED</head><p>In the supervised continual learning setup, task labels are available both during training and inference (though RMNs do not requires task labels as such). This kind of experimental setup is currently the most common form of evaluation used for Continual Learning methods. A point to note that adding regularization to induce sparsity in RMNs is optional and is not required to obtain an optimally trained model (as shown in Section 2.3). Additionally, model weights are never pruned in RMN methodology. The pruning mentioned in Algorithm 1 and 2 refers to zeroing out of relevance mappings which have not tightened towards value of 1. The prune parameter µ may also refer to the combination of weight and M P . This usually involves task boundary detection during training which often involves statistical tests like Welch's T-test or KL-Divergence on the model's loss . However, this setup often assumes clean sequential data over the entire training set as well as in a mini-batch. New Task/Data detection also involves learning in an unsupervised way when the incoming mini-batch is noisy i.e. a mix of old and new task data. The Fuzzy Unsupervised Learning experiment done on Sequential-MNIST follows the procedure laid out in .</p><p>The Randomized Unsupervised Task Inference experiment also capitalizes on the aforementioned weakness of the former test. Under this, a continually trained model has to identify the task ID during inference under circumstances where the inference input is task randomized. However, since RMNs form unique subnetworks in the original neural network, they are capable of trivially identifying the task ID as well as filtering out the noisy training data for new tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">β parameter</head><p>As presented in the main text, we used a sigmoidal pseudoround function during training which is completely rounded during inference:</p><formula xml:id="formula_16">L R (x k ; β) = 1 1 + exp(−(β(x k − 0.5)))<label>(1)</label></formula><p>We also noted that lim β−→∞ (L R (x, β)) for x ∈ [0, 1] is equivalent to the rounding function. Here, β is a learnable, layer-wise parameter (i.e., in our implementation, there is one specific β for every layer of a given network) that controls the "tightness" of L R . We experimented with different values of β and noted that for an arbitrary high value of β (≥ 80), there's not any visible difference in results and that the β value doesn't require any tuning. If we tried and learn the β parameter instead of fixing its value, we noted that the β value tightened over time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Sparsity Analysis</head><p>Sparsity(S) in a RMN f (W, M P ) is calculated according to the following formula S = n i=1 ∩M P = 0 num(W)</p><p>(2) <ref type="figure" target="#fig_0">Figure 1</ref> shows the model sparsity and usage for Resnet-18 model trained on Cifar-100  dataset over 20 tasks. For this experiment, there are no loss functions, regularization or any method employed to constrain the model parameters or M P for sparsity. If we do however constrain for sparsity using L 1 or L 0 regularization, we can observe much higher sparsity levels. We can observe that the model capacity usage evens out over time which can be explained due to subsequent tasks finding overlap amongst old task parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Model Computational Complexity w.r.t number of Tasks</head><p>RMNs require only the learned weights of the continually learning network, though this is achieved through creating distinct sub-network mappings in each network. This does increase the number of parameters, but ultimately reduces the effective model size because all additional parameters can be converted to binary tensors. Thus, the memory complexity can be written as O(tk) where t is an integer and equal to the number of tasks and k is a constant. Thus, for a finite and constrained value of t, the memory complexity of RMNs is O(1) i.e. constant. The value of k depends on the amount of overlap in our model as well as the method used to save binary parameters. For e.g. For the model in <ref type="table" target="#tab_2">Table 2</ref>, the theoretical worst case scenario (a model with no overlap amongst the relevance mappings) results in 12kb of memory. Practically, as noticed in the RMN sparsity discussion, the model has not been observed to fully utilize its weights over the period of sequential tasks and unused parameters can be effectively removed post training. Additionally, we do not implement bias parameters in our RMN. Thus, effectively, the final model memory footprint is actually negative as compared with even the baseline model for all the experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.">The Lottery Ticket Hypothesis and Relevance Mapping</head><p>A question arises as to whether the slight constraints introduced in the weight space by our algorithm worsen the per-formance of the sequential tasks. The Lottery ticket Hypothesis introduced in a seminal work  states that -A randomly-initialized, dense neural network contains a subnetwork that is initialized such that-when trained in isolation-it can match the test accuracy of the original network after training for at most the same number of iterations. Additionally, our method doesn't remove the previous tasks parameters and subsequent methods can choose to use their predecessors parameters optimally. Therefore, no performance drop is expected in our method and results from our experiments prove the same.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Experimental Details</head><p>The experimental implementation for most comparative methods mentioned in <ref type="table" target="#tab_1">Table 1</ref> have been taken from official implementations of , ,  and .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Architectural Details</head><p>In this section, we provide detailed descriptions of the architectures used for our experiments. We denote 2D convolutional layers as Conv2D, linear layers as Linear, Rectified Linear Unit as ReLU, and Batch Normalization as BN. For RMN versions of each layer with included Relevance Mapping M P , we add an "M-" prefix, e.g. M-Conv is the RMN version of Conv.</p><p>For fair comparison purposes, for all architectures, we attempt to keep architectural representational capacity and module sequences as similar as possible to referenced methods.  .</p><p>INPUT:  <ref type="table" target="#tab_3">Table 3</ref>. Details of the convolutional network used for the Sequential Omniglot task. This architecture is of similar or equivalent representational capacity to the network used in , cited as "Baseline" in their results sections. For the sequential Cifar-100 (10 tasks)  benchmark, we follow the experimental and architectural details from . For the RMN, however, we do not use bias parameters and dropout layers. <ref type="table">Table 4</ref> shows the architecture details for the RMN used in the experiment.</p><formula xml:id="formula_17">INPUT: x ∈ R 1×105×105 RESIZE −→ x ∈ R 1×28×28 M-CONV2D 1ch −→ 250ch M-BN (250) RELU MAXPOOLING (2 X 2), stride = 2 M-CONV2D 250ch −→ 250ch M-BN (250) RELU MAXPOOLING (2 X 2), stride = 2 M-CONV2D 250ch −→ 250ch M-BN (250) RELU MAXPOOLING (2 X 2), stride = 2 M-CONV2D 250ch −→</formula><p>For the RES-CIFAR experiment which uses a Resnet-18  1 trained over Sequential Cifar-100 (20 tasks), we use the original Resnet-18 architecture for all experiments with modifications as required by a specific method 2 . For the RMN-Resnet-18, we do not make use of bias parameters and dropout layers. <ref type="table">Table 4</ref>. Details of the convolutional network used for the Sequential Cifar 100 (10 tasks) task. This architecture is of similar or equivalent representational capacity to the network used in  INPUT: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Hyperparameter Details</head><p>In this section, we provide detailed descriptions of training, optimization, and hyperparameter details.</p><p>In  and , they select experiment with a range of hyperparameters, choose the values that return the highest validation accuracy and then retrain on the union of the train and validation set. When applicable, we select hyperparameter values similar or equivalent to those arrived at in  for MNIST and Omnliglot experiments and  for Cifar-100 experiments. For all continual learning tasks, we make use of the Adam optimizer and have separate learning rates for weights and M P parameters. Subsets of weights are frozen via gradient masking as tasks increase, where T t M P≈ = 1 is the mask applied to the weights at task T + 1.</p><p>For the Permuted-MNIST and Split-MNIST tasks, we use a 90-10 train-test split, 0.002 learning rate for all parameters, and batch size of 128. For all tasks, the network is trained for 250 epochs. For the Sequential Omniglot task, we use an 80-20 train-test split, 0.0002 learning rate for all parameters, except M P parameters, a learning rate of 0.0001 for M P parameters, a batch size of 16. For the first task, the network is trained for 150 epochs, for subsequent tasks the network trained for 200 epochs.</p><p>In S-CIFAR-100 and RES-CIFAR, we train all comparative methods with mini-batch size of 256 for 100 epochs using Adam optimizer <ref type="bibr" target="#b54">(Kingma &amp; Ba, 2014)</ref> with initial learning rate 0.001 and decaying it by a factor of 3 if there is no improvement in the validation loss for 5 consecutive epochs, similarly as in .</p><p>For our method (RMNs), we keep the same mini batch size, training epochs and optimizer as mentioned in . For Split Cifar-100 (10 tasks) and RES-CIFAR (Split Cifar100-20 tasks with Resnet-18), the model weight parameters initial learning rate is .001 and for M P the learning rate is .01. The prune parameter value is .05 and .01 respectively which is used to prune the relevance mappings. The pruning is done whenever the model's task loss converges which varies from epoch 20 − 80 for different tasks.  proposes hard attention (HAT), a task based attention mechanism which can be considered the most similar to our RMN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Similar Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Differences with Relevance Mapping Method</head><p>It differs from RMN due to following reasons-1. They utilize task embeddings and a positive scaling parameter -and a gated product of these two is used to produce a non-binary mask -unlike our RMNs which don't use either a task embedding or a scaling parameter and is necessarily binary.</p><p>2. Unlike RMNs, the attention on the last layer in HAT is manually hard-coded for every task.</p><p>3. A recursive cumulative attention mechanism is employed to deal with multiple non binary mask values over tasks in HAT. RMNs however have no need for such a mechanism.</p><p>4. HAT cannot be used in a unsupervised CL setup or to deal with CR and has not been implemented with more complex network architectures like Residual Networks.  uses proximal gradient descent algorithm to progressively freeze nodes in an ANN.</p><p>1. Unlike RMNs, this method employs selective regularization to signify node importance (which is calculated by lasso regularization).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Average accuracy results on CIFAR-100 (10 tasks)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>P-MNIST Randomized Unsupervised Task Inference</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 1 .</head><label>1</label><figDesc>Model Sparsity for AMN-Resnet-18 trained on CIFAR-100 (20 tasks)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>(100) −→ 10 SOFTMAX</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>3 provide the main architecture details of the continual learning experiments dealing with Sequential MNIST, Permuted MNIST and Sequential Omniglot benchmarks.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Department of Computer Science, Johns Hopkins University, USA. Correspondence to: Prakhar Kaushik &lt;pkaushi1@jh.edu&gt;.</figDesc><table /><note>1Preprint. Do not Distribute.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>Results on sequential learning tasks for the Split-MNIST (S-MNIST), Permuted-MNIST (P-MNIST), Sequential Omniglot (S-Omniglot), Split Cifar-100(20 tasks) with Resnet18 (RES-CIFAR) and Split Cifar-100(5 tasks) (S-CIFAR100) tasks. Mean test accuracy results with standard deviation over five trials are shown where applicable.</figDesc><table><row><cell>ALGORITHM</cell><cell></cell><cell>P-MNIST</cell><cell>S-MNIST</cell><cell>S-OMNIGLOT</cell><cell>RES-CIFAR</cell><cell>S-CIFAR100</cell></row><row><cell cols="2">VCL((NGUYEN ET AL., 2017)) R,H HAT((SERR ET AL., 2018))  † H RWALK((CHAUDHRY ET AL., 2018)) R,H AGS-CL((JUNG ET AL., 2020))  † H FRCL((TITSIAS ET AL., 2020)) R MEGA-II((GUO ET AL., 2020)) R,** SNOW((YOO ET AL., 2020))  † A FROMP((PAN ET AL., 2021)) R</cell><cell>90 (200 pts/task) 91.6 − − 94.3 ± 0.2 (200 pts/task) 91.21 (256 pts/task) − 94.9 ± 0.1 (40 pts/task)</cell><cell cols="2">97 (40 pts/task) (3 pts/character) 53.86 ± 2.3 99 5.5 ± 11.1 82.5 71.0 ± 5.6 − 82.8 ± 1.8 97.8 ± 0.7 81.47 ± 1.6 (40 pts/task) (3 pts/character) − − − 82.8 ± 1.8 99.0 ± 0.1 − (40 pts/task)</cell><cell>− 23.6 ± 8.8 70.1 (5000 samples) 27.6 ± 3.6 − 66.12 ± 1.94 M (1300 pts/task) − −</cell><cell>− 59.2 ± 0.7 58.1 ± 1.7 64.1 ± 1.7 − − − −</cell></row><row><cell>DLP((SMOLA ET AL., 2003)) EWC((KIRKPATRICK ET AL., 2017)) SI((ZENKE ET AL., 2017)) MAS((ALJUNDI ET AL., 2018))  † H RMN (OURS)</cell><cell cols="2">82 84 − − 97.727 ± 0.07</cell><cell>61.2 63.1 57.6 − 99.5 ± 0.2</cell><cell>− 67.43 ± 4.7 H 54.9 ± 16.2 81.4 ± 1.8 85.33 ± 1.7</cell><cell>− 42.67 ± 4.24 H 45.49 ± 0.2 H 42 ± 1.9 80.01 ± 0.9</cell><cell>− 60.2 ± 1.1 H 60.3 ± 1.3 H 61.5 ± 0.9 70.02 ± 2.5</cell></row></table><note>† SIMILAR METHODS(SECTION 2)√ USES PRETRAINED NETWORKR USES DATA REPLAY BUFFERH MULTIHEADED LAYER IMPLEMENTATION** NOT TRAINED OVER ALL TASKSA ADDITIONAL MODEL IS USED overgeneralize to a specific task given only Θ which, in turn takes care of CR.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Continual Learning without Task Labels.</figDesc><table><row><cell>ALGORITHM</cell><cell>P-MNIST</cell><cell>S-MNIST</cell><cell>S-OMNIGLOT</cell></row><row><cell cols="4">FRCL R FROMP R CN-DPM C, R RMN (OURS) 97.73 ± 0.1 94.3 ± 0.2 94.9 ± 0.1 − C (LEE ET AL., 2020) R USES DATA REPLAY BUFFER 97.8 ± 0.7 81.47 ± 1.6 99.0 ± 0.1 − 97.53 ± 0.3 − 99.5 ± 0.2 85.33 ± 1.7</cell></row><row><cell>tection and</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 .</head><label>3</label><figDesc>Fuzzy Unsupervised Learning.</figDesc><table><row><cell>ALGORITHM</cell><cell>S-MNIST</cell></row><row><cell>CN-DPM RMN (OURS)</cell><cell>93.22 ± 0.07 99.1 ± 0.5</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 1 .</head><label>1</label><figDesc>Common Methods used in Continual Learning which relax a strict CL framework</figDesc><table><row><cell>ALGORITHM</cell><cell cols="2">DATA REPLAY MULTIHEAD PRETRAINED GENERATIVE REPLAY MULTI-MODELS</cell></row><row><cell cols="2">VCL HAT RWALK AGS-CL FRCL MEGA-II  RMN (OURS)  *</cell><cell>*</cell></row><row><cell cols="2">EXCEPTIONS EXIST</cell></row><row><cell cols="2">2. Relevance Mapping Method</cell></row><row><cell>2.1. Algorithms</cell><cell></cell></row></table><note>* SNOW FROMP* DLP EWC* SI* MAS**</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 2 .</head><label>2</label><figDesc>Details of the Multi-layer Perceptron network used for the Permuted-MNIST and Split-MNIST tasks. This architecture is of equivalent representational capacity to the network used in</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Refer to Supplementary for further method details</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">HAT authors mentioned that there is no official implementation for Residual Networks 2 AGS-CL authors did not reply to our query concerning official Residual network implementation.</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Input: data x, ground truth y for n tasks, prune parameter µ, corresponding task labels i paired with all x 2: Given: parameters W &amp; initilaized relevance mappings M P 3: for each task i do 4:</p><p>Optional: Add Sparsity Loss : L(ŷ i , y i ) + (M Pi ) l0</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>7:</head><p>Backpropagate and optimize 8:</p><p>Prune M P ≤ µ only.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>9:</head><p>Stabilize (fix) parameters in f where M P = 1 10: end for 11: Inference: For data x and ground-truth task label i: 12: Output: f (x, i; W )</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2.">UNSUPERVISED</head><p>For Unsupervised learning setup (which is used as a measure of Catastrophic Remembering in our work), we introduce two sub tests -new task/data detection and unsupervised/randomized task inference.</p><p>In New Task/Data Detection, task label information is unavailable during both training and inference time and the model has to detect the new task in a unsupervised manner.</p><p>Algorithm 2 RMN Unsupervised Continual Learning 1: Input: data x, ground truth y, prune parameter µ 2: Given: parameters W, M Pest j with est j = 0, Task Switch Detection Method TSD 3: for each task j do 4:</p><p>Filter input x on f (x; W, M P0...j−1 ) 2. This method progressively uses up the parameter set of the ANN and it is unclear whether it can be used for an arbitrary large number of sequential tasks.</p><p>3. This method employs two group sparsity-based penalties in order to regularize important nodes, however AMN do not require usage such kind of sparse based penalty.</p><p>4. This method is also unable to deal with unsupervised learning scenario or CR. (iv) This method uses a different classification layer for each task -relaxing the core constraints of the problem altogether.  1. Calculates the parameter importance by calculating sensitivity of the squared l2 norm of the function output to their changes and then uses regularization (similar to  to enforce in sequential learning, unlike RMNs.</p><p>2. The method enforces fixed synaptic importance between tasks irrespective to their similarity and unlike our work, doesn't seem to be capable of working under Unsupervised Learning scenarios.  propose SNOW and 1. Uses a unique channel pooling scheme to evaluate the channel relevance for each specific task which differs from RMN's individual node relevance mapping strategy.</p><p>2. Importantly, this work, unlike RMNs, employs a pretrained model which is frozen source model which already overgeneralizes to the CL problem at hand and thus makes this method inapplicable for dealing with CR.</p><p>3. It also doesn't seem to be capable of handling unsupervised learning/testing scenarios.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Uncertainty-based Continual Learning with Adaptive Regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Moon</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Memory Aware Synapses: Learning What (not) to Forget</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Aljundi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Babiloni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Elhoseiny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tuytelaars</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ferrari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hebert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sminchisescu</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-01219-9</idno>
		<idno>1007/ 978-3-030-01219-9_9</idno>
		<ptr target="http://link.springer.com/10" />
	</analytic>
	<monogr>
		<title level="m">Series Title: Lecture Notes in Computer Science</title>
		<editor>Weiss, Y.</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">11207</biblScope>
			<biblScope unit="page" from="144" to="161" />
		</imprint>
	</monogr>
	<note>Computer Vision -ECCV 2018</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A framework for learning predictive structures from multiple tasks and unlabeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">K</forename><surname>Ando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<idno>1532-4435</idno>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="1817" to="1853" />
			<date type="published" when="2005-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Riemannian walk for incremental learning: Understanding forgetting and intransigence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chaudhry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">K</forename><surname>Dokania</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ajanthan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Torr</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Lifelong machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Synthesis Lectures on Artificial Intelligence and Machine Learning</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="207" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Uncertainty-guided Continual Learning with Bayesian Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ebrahimi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Elhoseiny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rohrbach</surname></persName>
		</author>
		<ptr target="https://iclr.cc/virtual_2020/poster_HklUCCVKDB.html" />
		<imprint>
			<date type="published" when="2020-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">The lottery ticket hypothesis: Finding sparse, trainable neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Frankle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Carbin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Dynamically constraining connectionist networks to produce distributed, orthogonal representations to reduce catastrophic interference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>French</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Using semi-distributed representations to overcome catastrophic forgetting in connectionist networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>French</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Improved schemes for episodic memory-based lifelong learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Rosing</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">A baseline for detecting misclassified and out-of-distribution examples in neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gimpel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Continual learning with node-importance based adaptive group sparse regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Moon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Fearnet: Brain-inspired model for incremental learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kemker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kanan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Measuring catastrophic forgetting in neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kemker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mcclure</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Abitino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hayes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kanan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Overcoming catastrophic forgetting in neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Rabinowitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Veness</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Desjardins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Milan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Quan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ramalho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Grabska-Barwinska</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the national academy of sciences</title>
		<meeting>the national academy of sciences</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="page" from="3521" to="3526" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Optimal Continual Learning has Perfect Memory and is NPhard</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Knoblauch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Husain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Diethe</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.05188</idno>
		<idno>arXiv: 2006.05188</idno>
		<ptr target="http://arxiv.org/abs/2006.05188" />
		<imprint>
			<date type="published" when="2020-06" />
		</imprint>
	</monogr>
	<note>cs, stat</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Siamese neural networks for one-shot image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML deep learning workshop</title>
		<meeting><address><addrLine>Lille</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012-05" />
		</imprint>
		<respStmt>
			<orgName>University of Toronto</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Continual Learning with Bayesian Neural Networks for Non-Stationary Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kurle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Cseke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Klushyn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Smagt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Günnemann</surname></persName>
		</author>
		<ptr target="https://iclr.cc/virtual_2020/poster_SJlsFpVtDB.html" />
		<imprint>
			<date type="published" when="2020-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Human-level concept learning through probabilistic program induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">M</forename><surname>Lake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<idno type="DOI">10.1126/science.aab3050</idno>
		<ptr target="https://science.sciencemag" />
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">350</biblScope>
			<biblScope unit="issue">6266</biblScope>
			<biblScope unit="page" from="1332" to="1338" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">The mnist database of handwritten digits</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<ptr target="http://yann.lecun.com/exdb/mnist/.URLhttps://ci.nii.ac.jp/naid/10027939599/en/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Convolutional networks for images, speech, and time series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Continual Learning With Extended Kronecker-Factored Approximate Curvature</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">G</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Joo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR42600.2020.00902</idno>
		<ptr target="https://ieeexplore.ieee.org/document/9157569/" />
	</analytic>
	<monogr>
		<title level="m">2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting><address><addrLine>Seattle, WA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020-06" />
			<biblScope unit="page" from="8998" to="9007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">A simple unified framework for detecting out-of-distribution samples and adversarial attacks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">10 -catastrophic interference in neural networks: Causes, solutions, and data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lewandowsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-C</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.1016/B978-012208930-5/50011-8.URLhttp:/www.sciencedirect.com/science/article/pii/B9780122089305500118</idno>
		<idno>978-0-12-208930-5. doi</idno>
		<ptr target="https://doi.org/10.1016/B978-012208930-5/50011-8.URLhttp://www.sciencedirect.com/science/article/pii/B9780122089305500118" />
		<editor>Dempster, F. N., Brainerd, C. J., and Brainerd, C. J.</editor>
		<imprint>
			<date type="published" when="1995" />
			<publisher>Academic Press</publisher>
			<biblScope unit="page" from="329" to="361" />
			<pubPlace>San Diego</pubPlace>
		</imprint>
	</monogr>
	<note>Interference and Inhibition in Cognition</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Learning without forgetting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hoiem</surname></persName>
		</author>
		<idno type="DOI">10.1109/tpami.2017.2773081</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2935" to="2947" />
			<date type="published" when="2018-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Adapting a single network to multiple tasks by learning to mask weights</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mallya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lazebnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Piggyback ; Ferrari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sminchisescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-01225-05.15th</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings, Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)</title>
		<editor>Hebert, M.</editor>
		<meeting>Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)<address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2018-01" />
			<biblScope unit="page" from="8" to="09" />
		</imprint>
	</monogr>
	<note>Computer Vision -ECCV 2018 -15th European Conference. Conference date</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">The stabilityplasticity dilemma: investigating the continuum from catastrophic forgetting to age-limited learning effects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mermillod</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bugaiska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonin</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2013.00504</idno>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">504</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">A wholistic view of continual learning with deep neural networks: Forgotten lessons and the bridge to active and open world learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mundt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">W</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Pliushch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramesh</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">V</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">D</forename><surname>Bui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Turner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Varia</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>tional continual learning</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Continual learning with hypernetworks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">V</forename><surname>Oswald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Henning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sacramento</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">F</forename><surname>Grewe</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=SJgwNerKvB" />
		<imprint>
			<date type="published" when="2019-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Continual deep learning by functional regularisation of memorable past</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Swaroop</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Immer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Eschenhagen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Turner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Khan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">I</forename><surname>Parisi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kemker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Part</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wermter</surname></persName>
		</author>
		<title level="m">Continual lifelong learning with neural networks: A review</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Catastrophic forgetting in neural networks: the role of rehearsal mechanisms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Robins</surname></persName>
		</author>
		<idno>doi: 10.1109/ ANNES.1993.323080</idno>
		<ptr target="http://ieeexplore.ieee.org/document/323080/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings 1993 The First New Zealand International Two-Stream Conference on Artificial Neural Networks and Expert Systems</title>
		<meeting>1993 The First New Zealand International Two-Stream Conference on Artificial Neural Networks and Expert Systems<address><addrLine>Dunedin, New Zealand</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Comput. Soc. Press</publisher>
			<date type="published" when="1993" />
			<biblScope unit="page" from="65" to="68" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schwarz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Luketina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">M</forename><surname>Czarnecki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Grabska-Barwinska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">W</forename><surname>Teh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.06370</idno>
		<title level="m">Progress &amp; compress: A scalable framework for continual learning</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Overcoming catastrophic forgetting with hard attention to the task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Serr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miron</forename><surname>Suris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karatzoglou</forename></persName>
		</author>
		<idno>abs/1801.01423</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">An analysis of catastrophic interference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sharkey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sharkey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Connect. Sci</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="301" to="330" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Backpropagation discrimination geometric analysis interference memory modelling neural nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">E</forename><surname>Sharkey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Sharkey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Connection Science</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="301" to="330" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Laplace propagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vishwanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Eskin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">01</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Gaussian process multi-task learning using joint feature selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">K</forename><surname>Srijith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shevade</surname></persName>
		</author>
		<idno>Hei- delberg. ISBN 978-3-662-44845-8</idno>
	</analytic>
	<monogr>
		<title level="m">Machine Learning and Knowledge Discovery in Databases</title>
		<editor>Calders, T., Esposito, F., Hüllermeier, E., and Meo, R.</editor>
		<meeting><address><addrLine>Berlin, Heidelberg; Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="98" to="113" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Functional Regularisation for Continual Learning with Gaussian Processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">K</forename><surname>Titsias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schwarz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G D G</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">W</forename><surname>Teh</surname></persName>
		</author>
		<ptr target="https://iclr.cc/virtual_2020/poster_HkxCzeHFDB.html" />
		<imprint>
			<date type="published" when="2020-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Subscribing to Knowledge via Channel Pooling for Transfer &amp; Lifelong Learning of Convolutional Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yoo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Snow</surname></persName>
		</author>
		<ptr target="https://iclr.cc/virtual_2020/poster_rJxtgJBKDr.html" />
		<imprint>
			<date type="published" when="2020-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Continual learning through synaptic intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zenke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ganguli</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">To prune, or not to prune: exploring the efficacy of pruning for model compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gupta</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.01878</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Memory Aware Synapses: Learning What (not) to Forget</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Aljundi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Babiloni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Elhoseiny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tuytelaars</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ferrari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hebert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sminchisescu</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-01219-9</idno>
		<idno>1007/ 978-3-030-01219-9_9</idno>
		<ptr target="http://link.springer.com/10" />
	</analytic>
	<monogr>
		<title level="m">Series Title: Lecture Notes in Computer Science</title>
		<editor>Weiss, Y.</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">11207</biblScope>
			<biblScope unit="page" from="144" to="161" />
		</imprint>
	</monogr>
	<note>Computer Vision -ECCV 2018</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Riemannian walk for incremental learning: Understanding forgetting and intransigence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chaudhry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">K</forename><surname>Dokania</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ajanthan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Torr</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">ImageNet: A Large-Scale Hierarchical Image Database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">09</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">The lottery ticket hypothesis: Finding sparse, trainable neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Frankle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Carbin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Catastrophic forgetting in connectionist networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>French</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in cognitive sciences</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="128" to="135" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Improved schemes for episodic memory-based lifelong learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Rosing</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Continual learning with node-importance based adaptive group sparse regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Moon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Fearnet: Brain-inspired model for incremental learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kemker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kanan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adam</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Overcoming catastrophic forgetting in neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Rabinowitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Veness</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Desjardins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Milan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Quan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ramalho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Grabska-Barwinska</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the national academy of sciences</title>
		<meeting>the national academy of sciences</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="page" from="3521" to="3526" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012-05" />
		</imprint>
		<respStmt>
			<orgName>University of Toronto</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Continual Learning With Extended Kronecker-Factored Approximate Curvature</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">G</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Joo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR42600.2020.00902</idno>
		<ptr target="https://ieeexplore.ieee.org/document/9157569/" />
	</analytic>
	<monogr>
		<title level="m">2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting><address><addrLine>Seattle, WA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020-06" />
			<biblScope unit="page" from="8998" to="9007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">V</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">D</forename><surname>Bui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Turner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Varia</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>tional continual learning</note>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Continual deep learning by functional regularisation of memorable past</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Swaroop</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Immer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Eschenhagen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Turner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Khan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Catastrophic forgetting in neural networks: the role of rehearsal mechanisms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Robins</surname></persName>
		</author>
		<idno>doi: 10.1109/ ANNES.1993.323080</idno>
		<ptr target="http://ieeexplore.ieee.org/document/323080/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings 1993 The First New Zealand International Two-Stream Conference on Artificial Neural Networks and Expert Systems</title>
		<meeting>1993 The First New Zealand International Two-Stream Conference on Artificial Neural Networks and Expert Systems<address><addrLine>Dunedin, New Zealand</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Comput. Soc. Press</publisher>
			<date type="published" when="1993" />
			<biblScope unit="page" from="65" to="68" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Overcoming catastrophic forgetting with hard attention to the task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Serr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miron</forename><surname>Suris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karatzoglou</forename></persName>
		</author>
		<idno>abs/1801.01423</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">Functional Regularisation for Continual Learning with Gaussian Processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">K</forename><surname>Titsias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schwarz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G D G</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">W</forename><surname>Teh</surname></persName>
		</author>
		<ptr target="https://iclr.cc/virtual_2020/poster_HkxCzeHFDB.html" />
		<imprint>
			<date type="published" when="2020-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">Subscribing to Knowledge via Channel Pooling for Transfer &amp; Lifelong Learning of Convolutional Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yoo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Snow</surname></persName>
		</author>
		<ptr target="https://iclr.cc/virtual_2020/poster_rJxtgJBKDr.html" />
		<imprint>
			<date type="published" when="2020-04" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
