<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Lifted Disjoint Paths with Application in Multiple Object Tracking</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Hornakova</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Henschel</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bodo</forename><surname>Rosenhahn</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Swoboda</surname></persName>
						</author>
						<title level="a" type="main">Lifted Disjoint Paths with Application in Multiple Object Tracking</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T22:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present an extension to the disjoint paths problem in which additional lifted edges are introduced to provide path connectivity priors. We call the resulting optimization problem the lifted disjoint paths problem. We show that this problem is NP-hard by reduction from integer multicommodity flow and 3-SAT. To enable practical global optimization, we propose several classes of linear inequalities that produce a high-quality LPrelaxation. Additionally, we propose efficient cutting plane algorithms for separating the proposed linear inequalities. The lifted disjoint path problem is a natural model for multiple object tracking and allows an elegant mathematical formulation for long range temporal interactions. Lifted edges help to prevent id switches and to re-identify persons. Our lifted disjoint paths tracker achieves nearly optimal assignments with respect to input detections. As a consequence, it leads on all three main benchmarks of the MOT challenge, improving significantly over state-of-the-art.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>* Equal contribution 1 Computer Vision and Machine Learning,</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>This appendix supplements our work by presenting missing proofs regarding the solver and details about our tracker.</p><p>Sections 10.1 up to Section 10.4 provide proofs used in Sections 4 and 6.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The disjoint paths problem, a special case of the network flow problem with flows constrained to be binary, is a classical combinatorial optimization problem for which fast combinatorial solvers exist. It is a natural model for the multiple object tracking problem (MOT) in computer vision <ref type="bibr">(Zhang et al., 2008)</ref>. In the form of the tracking-bydetection paradigm, MOT consists of two steps: First, an object detector is applied to each frame of a video sequence to find the putative locations of all objects appearing in the video. Then, in the data association step, false positive de-tections are removed while correct detections are associated to the corresponding identities, thereby forming trajectories. In this work, we concentrate on the latter task.</p><p>While for MOT even very large data association instances can be solved using the disjoint paths formulation, it has been shown that the basic disjoint paths problem alone is not sufficient to provide trajectories of high accuracy. The main limitation for MOT is the implicit assumption of a first-order Markov chain. In particular, costs only indicate whether two detections directly follow each other in a track.</p><p>Our contribution is three-fold: First, to overcome the limited expressiveness of disjoint paths, we propose to augment it with lifted edges which take into account long range interactions. We call the resulting problem the lifted disjoint paths problem, see Section 3. We prove the problem to be NP-hard in Section 6. Second, we study the optimization problem from a polyhedral perspective, proposing a high-quality linear programming relaxation, see Section 4. Separation routines for the proposed constraints are described in Section 5. Third, we apply the lifted disjoint paths problem to MOT and show that our solver significantly outperforms state-of-the-art trackers on the popular MOT challenge, see Section 7.</p><p>We argue that our model has advantages from the modelling and optimization point of view. From the modelling standpoint, the lifted disjoint paths problem does not change the set of feasible solutions, but adds more expressive power to it. For MOT, this means that the set of feasible solutions, which naturally represent trajectories of objects, is preserved. The additional lifted edges represent connectivity priors. A lifted edge is active if and only if there is an active trajectory between its endpoints in the flow graph. For MOT, lifted edges take (dis-)similarity of object detection pairs represented by its endpoints into account. This allows to encourage or penalize an active path between the detections with possibly larger temporal distance. This helps to reidentify the same object and to prevent id-switches between distinct objects within long trajectories.</p><p>From the optimization point of view, we study several nontrivial classes of linear inequalities that result in a highquality relaxation. The proposed inequalities depend nontrivially on the constraint structure of the underlying disjoint paths problem, see Section 4. We show that the polyhe-arXiv:2006.14550v1 [cs.CV] 25 Jun 2020 dral relaxation we consider is tighter than naively applying known inequalities. The proposed relaxation enables us to solve MOT problems via a global approach, in contrast to established approaches, which either use heuristics on complex models or global optimization on simpler models that do not exploit long range interaction. We present, to our knowledge, the first global optimization approach that incorporates long range interaction for MOT. This has several advantages: First, our optimization is not trapped in poor local optima or affected by initialization choices and is hence potentially more robust. Second, improvements in the discriminative power of features used to compute costs for the lifted disjoint paths problem directly correlate to better tracking performance, since no errors are introduced by suboptimal choices during optimization.</p><p>Finally, we note that the proposed lifted disjoint path formulation is not inherently tied to MOT and can potentially be applied to further problems not related to MOT.</p><p>Our code is available at https://github.com/ AndreaHor/LifT_Solver.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Disjoint paths problem. The disjoint paths problem can be solved with fast combinatorial solvers <ref type="bibr" target="#b5">(Kov√°cs, 2015)</ref>. The shortest paths method for network flow specialized for the disjoint paths problem <ref type="bibr">(Wang et al., 2019a)</ref> performs extremely well in practice. For the case of the two disjoint paths problem the specialized combinatorial algorithm by <ref type="bibr" target="#b20">Suurballe's (Suurballe, 1974)</ref> can be used.</p><p>There exist several NP-complete extensions to the disjoint paths problem. The shortest disjoint paths problem with multiple source-sink pairs <ref type="bibr">(Eilam-Tzoreff, 1998)</ref> is NPcomplete, as is the more general integer multicommodity flow problem <ref type="bibr">(Even et al., 1976)</ref>. The special case of the disjoint paths problem with two distinct source/sink pairs can be solved in polynomial time, however <ref type="bibr">(Tholey, 2012)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Connectivity priors &amp; lifted edges.</head><p>For several combinatorial problems, special connectivity inducing edges, which we will call lifted edges for our problem, have been introduced to improve expressiveness of the base problem.</p><p>In the Markov Random Field literature, special connectivity inducing edges were studied from a polyhedral point of view in <ref type="bibr" target="#b13">(Nowozin &amp; Lampert, 2010)</ref>. They were used in image analysis to indicate that two non-adjacent pixels come from the same object and hence they must be part of a contiguously labeled component of the underlying graph.</p><p>For multicut (a.k.a. correlation clustering), a classical graph decomposition problem, lifted edges have been introduced in <ref type="bibr" target="#b1">(Keuper et al., 2015)</ref> to model connectivity priors. A lifted edge expresses affinity of two nodes to be in the same/different connected component of the graph partition. Lifted multicut has been used for image and mesh segmentation <ref type="bibr" target="#b1">(Keuper et al., 2015)</ref>, connectomics <ref type="bibr">(Beier et al., 2017)</ref> and cell tracking <ref type="bibr" target="#b14">(Rempfler et al., 2017)</ref>. A combination of the lifted multicut problem and Markov Random Fields has been proposed in  with applications in instance-separating semantic segmentation . A polyhedral study of lifted multicut was presented in <ref type="bibr">(Hor≈à√°kov√° et al., 2017</ref>).</p><p>Yet, for the above problems, global optimization has only been reported for small instances.</p><p>Disjoint paths for MOT. The data association step of MOT has been approached using the disjoint path setup <ref type="bibr">(Berclaz et al., 2011;</ref><ref type="bibr">Zhang et al., 2008)</ref>, since disjoint paths through a graph naturally model trajectories of multiple objects. Extension of the plain disjoint paths problem that disallow certain pairs of detections to occur simultaneously have been used to fuse different object detectors <ref type="bibr">(Chari et al., 2015)</ref> and for multi-camera <ref type="bibr">MOT (Hofmann et al., 2013;</ref><ref type="bibr" target="#b7">Leal-Taix√© et al., 2012)</ref>. The drawback of these approaches is that they cannot integrate long range information, in contrast to our proposed formulation.</p><p>Other combinatorial approaches to MOT. The minimum cost arborescence problem, an extension of minimum spanning tree to directed graphs, has been used for MOT in <ref type="bibr">(Henschel et al., 2014)</ref>. In <ref type="bibr" target="#b2">(Keuper et al., 2016;</ref><ref type="bibr" target="#b6">Kumar et al., 2014;</ref><ref type="bibr" target="#b15">Ristani &amp; Tomasi, 2014;</ref><ref type="bibr" target="#b21">Tang et al., 2015;</ref> the multicut problem has been used for <ref type="bibr">MOT and in (Babaee et al., 2018;</ref><ref type="bibr" target="#b9">Tang et al., 2017)</ref> additionally lifted edges have been used to better model long range temporal interactions. The maximum clique problem, which corresponds to multicut with complete graphs has been applied for MOT in <ref type="bibr">(Zamir et al., 2012;</ref><ref type="bibr">Dehghan et al., 2015)</ref>. Maximum independent set, which corresponds to maximum clique on the complement graph, has been used for MOT in <ref type="bibr">(Brendel et al., 2011)</ref>. The multigraph-matching problem, a generalization of the graph matching problem, has been applied to <ref type="bibr">MOT in (Hu et al., 2019)</ref>. Consistency of individual matched detections is ensured by cycle-consistency constraints coming from the multi-graph matching. The works <ref type="bibr">(Henschel et al., 2018;</ref> reformulate tracking multiple objects with long temporal interactions as a binary quadratic program. If the problem size is small, the optimization problem can be solved optimally by reformulating it to an equivalent binary linear program <ref type="bibr">(Henschel et al., 2019a;</ref><ref type="bibr">von Marcard et al., 2018)</ref>. For large instances, an approximation is necessary. To this end, a specialized nonconvex Frank-Wolfe method can be used <ref type="bibr">(Henschel et al., 2018)</ref>. Common to the above state of the art trackers is that they either employ heuristic solvers or are limited in the integration of long range information, in contrast to our work.</p><p>Contribution w.r.t. existing combinatorial approaches. It is widely acknowledged that one crucial ingredient for obtaining high-quality MOT results is to incorporate long range temporal information to re-identify detections and prevent id-switches. However, from a theoretical perspective, we believe that long range information has not yet been incorporated satisfactorily in optimization formulations for the data association step in MOT.</p><p>In comparison to lifted multicut for MOT, we argue that from the modelling point of view, network flow has advantages. In multicut, clusters can be arbitrary, while in MOT, tracks are clusters that may not contain multiple detection hypotheses of distinct objects at the same time point. This exclusion constraint must be enforced in multicut explicitly via soft constraints, while the disjoint paths substructure automatically takes care of it. On the other hand, the lifted multicut approach <ref type="bibr" target="#b9">(Tang et al., 2017)</ref> has used the possibility to cluster multiple detections in one time frame. This directly incorporates non-maxima suppression in the optimization, which however increases computational complexity.</p><p>From a mathematical perspective, naively using polyhedral results from multicut is also not satisfactory. Specifically, one could naively obtain a polyhedral relaxation for the lifted disjoint paths problem by reusing the known polyhedral structure of lifted multicut <ref type="bibr">(Hor≈à√°kov√° et al., 2017)</ref> and additionally adding network flow constraints for the disjoint paths substructure. However, this would give a suboptimal polyhedral relaxation. We show in Section 4 that the underlying structure of the disjoint paths problem can be used to derive new and tighter constraints for lifted edges. This enables us to use a global optimization approach for MOT. To our knowledge, our work is the first one to combine global optimization with long range interactions for MOT.</p><p>In comparison to works that propose non-convex algorithms or other heuristics for incorporating long range temporal edges <ref type="bibr">(Henschel et al., 2018;</ref><ref type="bibr">Hu et al., 2019;</ref><ref type="bibr">Zamir et al., 2012;</ref><ref type="bibr">Dehghan et al., 2015)</ref> our approach yields a more principled approach and globally optimal optimization solutions via LP-based branch and bound algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Problem Formulation</head><p>Below we recapitulate the disjoint paths problem and extend it by defining lifted edges. We discuss how the lifted disjoint paths problem can naturally model MOT. Proofs for statements in all subsequent sections can be found in the Appendix, Section ??.</p><p>Flow network and lifted graph. Consider two directed acyclic graphs G = (V, E) and G = (V , E ) where V = V \{s, t}. The graph G = (V, E) represents the flow network and we denote by G the lifted graph. The two special nodes s and t of G denote source and sink node respectively. We further assume that every node in V is reachable from s, and t can be reached from it.</p><p>We define the set of paths starting at v and ending in w as</p><formula xml:id="formula_0">vw-paths(G) = (v 1 v 2 , . . . , v l‚àí1 v l ) : v i v i+1 ‚àà E, v 1 = v, v l = w .</formula><p>(1) For a vw-path P we denote its edge set as P E and its node set as P V .</p><p>The flow variables in G are denoted by y ‚àà {0, 1} E for edges and x ‚àà {0, 1} V for nodes. Allowing only 0/1 values of vertex variables reflects the requirement of vertex disjoint paths. Variables on the lifted edges E are denoted by y ‚àà {0, 1} E . Here, y vw = 1 means that nodes v and w are connected via the flow y in G. Formally,</p><formula xml:id="formula_1">y vw = 1 ‚áî ‚àÉP ‚àà vw-paths(G) s.t. ‚àÄij ‚àà P E : y ij = 1 .</formula><p>(2) </p><p>In Section 4, we present an ILP formulation of (3) by proposing several linear inequalities that lead to a high-quality linear relaxation.</p><p>Graph construction for multiple object tracking. We argue that the lifted disjoint paths problem is an appropriate way of modelling the data association problem for MOT. In MOT, an unknown number of objects needs to be tracked across a video sequence. This problem can be naturally formalized by a graph G = (V, E) where its node set V represents either object detections or tracklets of objects. If V represents object detections, we can express it as follows:</p><formula xml:id="formula_3">V = s ‚à™ V 1 ‚à™ . . . ‚à™ V T ‚à™ t,</formula><p>where T is the number of frames and V i denotes the object detections in time i. We introduce edges between adjacent time frames. An active flow on such an edge denotes correspondences of the same object. We also introduce skip edges between time frames that are farther apart. An active flow on a skip edge also denotes correspondences between the same object that, in contrast, may have been been occluded or not detected in intermediate time frames. This classical network flow formulation has been commonly used for MOT <ref type="bibr">(Zhang et al., 2008)</ref>.</p><p>On top of the underlying flow formulation for MOT, we usually want to express that two detections belong to the same object connected by a possibly longer track with multiple detections in between. For that purpose, lifted edges with negative costs can be used. We say in such a case that an active lifted edge re-identifies two detections <ref type="bibr" target="#b9">(Tang et al., 2017)</ref>. If two detections with larger temporal distance should not be part of the same track, a positive valued lifted edge can be used. In this case the lifted edge is used to prevent id-switches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Constraints</head><p>Below, we will first introduce constraints that give an integer linear program (ILP) of the lifted disjoint paths problem (3). The corresponding linear programming (LP) relaxation can be strenghtened by additional constraints that we present subsequently.</p><p>Many constraints considered below will rely on whether a node w is reachable from another node v in the flow network. We define to this end the reachability relation</p><formula xml:id="formula_4">R ‚äÇ V 2 via vw ‚àà R ‚áî vw-paths(G) = ‚àÖ .<label>(4)</label></formula><p>In the special case of v = w, we also allow empty paths, which means ‚àÄv ‚àà V : vv ‚àà R. This makes relation R reflexive.</p><p>Flow conservation constraints. The flow variables y obey, as in classical network flow problems <ref type="bibr" target="#b0">(Ahuja et al., 1988)</ref>, the flow conservation constraints ‚àÄv ‚àà V \ {s, t} :</p><formula xml:id="formula_5">u:uv‚ààE y uv = w:vw‚ààE y vw = x v . (5)</formula><p>Constraining lifted edges. All the following constraints restrict values of lifted edge variables y vw in order to ensure that they satisfy (2). Despite their sometimes complex form, they always obey the two basic principles:</p><p>‚Ä¢ If there is flow in G going from vertex v to vertex w, then y vw = 1. The constraints of this form are (8), (10).</p><p>‚Ä¢ If there is a vw-cut in G with all edges labeled by zero (i.e. no flow passes through this cut), then y vw = 0. We will mainly look at cuts that are induced by paths, i.e. edges that separate a path from the rest of the graph. The paths of interest will either originate at v or end at w. The constraints of this form are (6), (7), (9), (11), (12).</p><p>Single node cut inequalities. Given a lifted edge vw ‚àà E , if there is no flow going from vertex v which can potentially go to vertex w, then y vw = 0. Formally,</p><formula xml:id="formula_6">y vw ‚â§ u: vu‚ààE, uw‚ààR y vu .<label>(6)</label></formula><p>Similarly, if there is no flow going to w that can originate from vertex v, then y vw = 0. Formally,</p><formula xml:id="formula_7">y vw ‚â§ u:uw‚ààE, vu‚ààR y uw .<label>(7)</label></formula><p>The number of constraints of the above type (5) is linear in the number of vertices, while (6) and <ref type="formula" target="#formula_7">(7)</ref> are linear in the number of lifted edges. Hence we add them into our initial constraint set during optimization.</p><p>Path inequalities. For lifted edge y vw it holds that if there is a flow in G going from v to w along a path P , then y vw = 1. This constraint can be expressed by the following set of inequalities:</p><p>‚àÄvw ‚àà E ‚àÄP ‚àà vw-paths(G) :</p><formula xml:id="formula_8">y vw ‚â• vj:j‚ààP V y vj ‚àí i‚ààP V \{v,w} k / ‚ààP V y ik (8)</formula><p>Here the first sum expresses the flow going from v to any vertex of path P . The second sum is the flow leaving path vertices P V before reaching w. In other words, if flow does not leave P V , edge y vw must be active. Note that inequality (8) implicitly enforces y vw to be active if any path vw-pathP withP V ‚äÇ P V is active.</p><p>Remark 1. For the multicut problem, there exist path inequalities that enforce path properties in an analogous way. While the multicut path inequalities would yield the same set of feasible integral points, the resulting polyhedral relaxation would be weaker, see Proposition 3 in the Appendix.</p><p>Path-induced cut inequalities. The path-induced cut inequalities generalize the single node cut inequalities (6) and (7) by allowing cuts induced by paths.</p><p>Let a lifted edge vw ‚àà E , a node u from which w is reachable and a vu-path P be given. Consider the cut given by edges ik with i ‚àà P V and k / ‚àà P V but such that w is reachable from k. If the flow does not take any edge of this cut, then y vw = 0. Formally,</p><formula xml:id="formula_9">‚àÄvw ‚àà E ‚àÄP ‚àà vu-paths(G) s.t. uw ‚àà R ‚àß u = w : y vw ‚â§ i‚ààP V k / ‚ààP V , kw‚ààR y ik .<label>(9)</label></formula><p>Lifted inequalities. The path inequalities (8) and the pathinduced cut inequalities (9) only consider base edges on their right hand sides. We can generalize both (8) and (9) by including lifted edges in the paths as well. Conceptually, using lifted edges allows to represent all possible paths between their endpoints, which enables to formulate tighter inequalities, see Propositions 1 and 2.</p><p>To that end consider the multigraph G ‚à™ G := (V, E ‚à™ E ).</p><p>For any edge ij ‚àà E ‚à© E we always distinguish whether ij ‚àà E or ij ‚àà E . For P ‚àà vw-paths(G ‚à™ G ), we denote by P E and P E edges of the path P in E and E respectively. We require P E ‚à© P E = ‚àÖ.</p><p>Lifted path inequalities. We generalize the path inequalities (8). Now the vw-path P may contain both edges in E and E . Whenever a lifted edge y ij in the third sum in (10) is one, two cases can occur: (i) Flow goes out of P (uses vertices not in P V ) but reenters it again later. Then a base edge variable y ik will be one in the second sum in (10) and the values of y ij and y ik cancel out. (ii) A base edge ij ‚àà E ‚à© E parallel to the lifted edge is active. Then the variable y ij in the fourth sum in (10) cancels out y ij . The lifted path inequality becomes</p><formula xml:id="formula_10">‚àÄvw ‚àà E ‚àÄP ‚àà vw-paths(G ‚à™ G ) : y vw ‚â• j‚ààP V y vj ‚àí i‚ààP V \{v,w} k / ‚ààP V y ik + ij‚ààP E y ij ‚àí ij‚ààP E ‚à©E y ij .<label>(10)</label></formula><p>Whenever the path in (10) consists only of base edges P E , the resulting inequality becomes a path inequality (8).</p><p>Proposition 1. The lifted path inequalities (10) provide a strictly better relaxation than the path inequalities (8).</p><p>Lifted path-induced cut inequalities. We generalize the path-induced cut inequalities (9). Let a lifted edge vw ‚àà E and a vu-path P in G ‚à™ G be given. In contrast to the basic version (9), a lifted edge ij ‚àà P E can be taken. This can occur in two cases: Either the flow leaves P V via a base edge ik, k / ‚àà P V or a base edge ij ‚àà E ‚à© E parallel to the lifted edge is taken. Both cases are accounted for by terms in the first and the third sum in (11) below.</p><formula xml:id="formula_11">‚àÄvw ‚àà E ‚àÄP ‚àà vu-paths(G ‚à™ G ) s.t. uw ‚àà R ‚àß u = w : y vw ‚â§ i‚ààP V k / ‚ààP V , kw‚ààR y ik ‚àí ij‚ààP E y ij + ij‚ààP E ‚à©E y ij (11)</formula><p>Assume that the last node u of path P is connected via a lifted edge with w. Then we can strengthen (11) by replac-ing the sum of base edges outgoing from u by y uw .</p><formula xml:id="formula_12">‚àÄvw ‚àà E ‚àÄP ‚àà vu-paths (G ‚à™ G ) s.t. uw ‚àà E : y vw ‚â§ i‚ààP V \u k / ‚ààP V , kw‚ààR y ik ‚àí ij‚ààP E y ij + ij‚ààP E ‚à©E y ij + y uw<label>(12)</label></formula><p>Proposition 2. The lifted path-induced cut inequalities (11) define a strictly tighter relaxation than the path-induced cut inequalities (9).</p><p>Furthermore the lifted path-induced cut inequalities <ref type="formula">(11)</ref> and (12) define a strictly better relaxation than (11) alone.</p><p>Symmetric cut inequalities. Inequalities <ref type="formula" target="#formula_7">(7)</ref> provide a symmetric counterpart to inequalities (6). We can also formulate symmetric counterparts to inequalities <ref type="formula" target="#formula_9">(9)</ref>, <ref type="formula">(11)</ref> and <ref type="formula" target="#formula_12">(12)</ref> by swapping the role of v and w. All constraints <ref type="formula" target="#formula_9">(9)</ref>, <ref type="formula">(11)</ref> and <ref type="formula" target="#formula_12">(12)</ref> concentrate on paths originating in v. The symmetric inequalities are obtained by studying all paths ending in w. These symmetric inequalities are described in Appendix Section 10.2. Relations analogous to those described in Proposition 2 hold for the symmetric counterparts as well. The symmetric inequalities also strengthen the relaxation strictly. For the exact statements, see propositions in Appendix Section 10.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Separation</head><p>We solve the lifted disjoint paths problem (3) with the state of the art integer linear program solver Gurobi (Gurobi Optimization, 2019). Since there are exponentially many constraints of the form (8), (9), (10), <ref type="formula">(11)</ref> and <ref type="formula" target="#formula_12">(12)</ref>, we do not add them initially. Instead, we start with constraints <ref type="formula">(5)</ref>, <ref type="formula" target="#formula_6">(6)</ref> and <ref type="formula" target="#formula_7">(7)</ref> and find the optimal integer solution. In the separation procedures described below we check if any of the advanced constraints are violated and add those that are to the active constraint set. We resolve the tightened problem and iterate until we have found a feasible solution to the overall problem (3).</p><p>Algorithms 1 and 2 describe the separation procedures for adding lifted path constraints (10), and lifted path-induced cut constraints <ref type="formula">(11)</ref> and <ref type="formula" target="#formula_12">(12)</ref>. Since path constraints (8) and path-induced cut inequalities (9) are special cases of those above, they are also accounted for.</p><p>Separation for path inequalities. Algorithm 1 iterates over all active st-paths. For every path P 1 , labels of all lifted edges connecting two vertices in P 1 V are inspected. If the lifted edge variable is zero, Algorithm 1 will extract a path in G ‚à™ G connecting the endpoints and add the resulting lifted path inequality (10) to the active constraint set.</p><p>Algorithm 1 Separation for lifted path inequalities (10)</p><formula xml:id="formula_13">Define E 1 = {e ‚àà E : y e = 1}, G 1 = (V, E 1 ) for all P 1 ‚àà st-paths (G 1 ) do for all y vw = 0 : v ‚àà P 1 V ‚àß w ‚àà P 1 V do P := Extract_path(P 1 , v, w)</formula><p>Add constr. (10) for y vw with P . end for end for Separation for path-induced cut inequalities. Algorithm 2 iterates over all active st-paths. For every path P 1 , lifted edges that start in P 1 V but do not end in P 1 V are inspected. If their label is one, Algorithm 2 will extract a subpath of P 1 for either (12) or (11) and add the respective inequality to the active constraint set.</p><p>Algorithm 2 Separation for lifted path-induced cut inequalities <ref type="formula">(11)</ref> and <ref type="formula" target="#formula_12">(12)</ref> Define</p><formula xml:id="formula_14">E 1 = {e ‚àà E : y e = 1}, G 1 = (V, E 1 ) for all P 1 ‚àà st-paths (G 1 ) do for all y vw = 1 : v ‚àà P 1 V ‚àß w / ‚àà P 1 V do if ‚àÉu ‚àà P 1 V : y uw = 0 ‚àß vu ‚àà R then P := Extract_path(P 1 , v, u) Add constr. (12) for y vw with P . else u := last vertex of P 1 such that uw ‚àà R P := Extract_path (P 1 , v, u)</formula><p>Add constr. (11) for y vw with P . end if end for end for Complexity of separation. Both Algorithms 1 and 2 can be implemented efficiently such that they are linear in |E 1 | (i.e. in the number of active edges of graph G). In our implementation, we traverse all active st-paths from the end to the beginning and directly store correctly labelled lifted edges that originate on the already processed subpaths. These lifted edges can be used later as edges in P E in (10)-(12) or as y uw = 0 in (12).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Complexity</head><p>Below, we show that the lifted disjoint paths problem <ref type="formula" target="#formula_2">(3)</ref> is NP-hard. The following Theorems state that even its restricted versions using only negative or only positive lifted edges are NP-hard. The proofs use reductions from two known NP-complete problems. Theorem 1 is proven by reduction from integer multicommodity flow <ref type="bibr">(Even et al., 1976)</ref> and Theorem 2 by reduction from 3-SAT <ref type="bibr">(Cook, 1971)</ref>.</p><formula xml:id="formula_15">Algorithm 3 Extract_path(P 1 , v, w) P := vw-subpath of P 1 , P := ‚àÖ for j ‚àà P V from end of path to beginning do if ‚àÉ edge ij ‚àà E , i ‚àà P V , y ij = 1 then Add ij to P E , skip to node i ‚àà P V else Add ij from P to P E end if end for output P = P E ‚à™ P E Theorem 1. Lifted disjoint paths problem (3) with negative lifted edges only is NP-hard.</formula><p>Theorem 2. Lifted disjoint paths problem (3) with positive lifted edges only is NP-hard.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Experiments</head><p>We conduct several experiments on MOT showing the merit of using lifted disjoint paths for the tracking problem. Below, we describe our problem construction, cost learning for base and lifted edges, preprocessing and post-processing steps and report resulting performance. More details about our experiments are provided in Appendix, Section ??.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1.">Graph Construction.</head><p>Two-step procedure. Due to the computational complexity of the problem, we cannot solve entire video sequences straightforwardly. In order to make the problem tractable, we apply the following two-step procedure. In the first step, the solver is applied on graphs over person detections but only for small time intervals consisting of a few dozen video frames. The tracks resulting from the first step are used for extracting tracklets. In the second step, the solver is applied on newly created graphs G and G where vertices correspond to the obtained tracklets. Edges and edge costs between tracklets are obtained by aggregating original edges resp. edge costs between person detections. The tracks resulting from the second step may be suboptimal with respect to the original objective function defined over person detections. Therefore, we identify points where splitting a track leads to an improvement of the original objective value and extract new tracklets from the divided tracks. Multiple iterations of the second step are performed until no improving split points are found in the output tracks. This two-step procedure improves the objective w.r.t. the original objective (3) in every iteration. Since there are only finitely many trackings, the procedure terminates finitely. In practice, only a few iterations are necessary.</p><p>Graph sparsification. For our experiments, we use edges between detections up to 2sec temporal distance. These long range edges cause high computational complexity for the first step. In order to reduce it, we apply sparsification on both base and lifted graphs. For the base edges, we select for every v ‚àà V its K nearest (lowest-cost) neighbors from every subsequent time frame within an allowed time gap. Lifted edges with costs close to zero are not included, since they are not discriminative. Lifted edges connecting detections with high time gap are included more sparsely than lifted edges having lower time gaps. We use dense graphs in the second step.</p><p>Costs. Initially, in the first step, we set œâ v = 0 for all vertices v ‚àà V . For the second step, where V represents tracklets, œâ v is set to the cost of outputting tracklet v as a final trajectory. Specifically, œâ v is the sum of costs of base edges between consecutive detections in the tracklet and the cost of lifted edges between all pairs of detections contained in the tracklet. The cost of a base edge between two tracklets is given by the cost of the original base edge connecting the last detection in the first tracklet with the first detection in the subsequent tracklet. The cost of a lifted edge between two tracklets is obtained by summing up the costs of original lifted edges between detections contained in the tracklets. This ensures that the costs of the tracklet solution corresponds to the costs of the original problem. We set cost of all edges from the source node s and to the sink node t to zero. Setting of detection costs and in/out costs to zero reduces the number of hyperparameters that usually needs to be incorporated by other methods. Moreover, our method does not include temporal decay of edge costs since the formulation directly prefers short range base edges over the long range ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.">Preprocessing and Post-processing</head><p>As is common for tracking by detection, we perform preand postprecessing to compensate for detector inaccuracies.</p><p>Input filtering. Given a set of input detections derived from a detector, we follow the approach of (Bergmann et al., 2019), a leading tracker for the MOT challenge, to reject false positive detections and to correct misaligned ones. For this, each input detection is send through the regression and classification part of their detector. In more detail, all tracking parts involved in the tracker Tracktor <ref type="bibr">(Bergmann et al., 2019)</ref> are deactivated, such that it only reshapes and eventually rejects input detections, without assigning labels to them. Input detections are rejected if Tracktor's detector outputs a confidence score œÉ active ‚â§ 0.5.</p><p>Tracktor also applies a non-maxima-surpression on the reshaped input detections, where we use the threshold Œª new = 0.6.</p><p>Inter-and extrapolation. Even if all input detections have been assigned to the correct identities by our solver, there might still be missing detections in case that a person has not been detected in some frames. We recover missing detections within the time range of a trajectory, which we denote as interpolation. Further, we extend a trajectory in forward and backward directions, which we denote as extrapolation. To this end, we follow <ref type="bibr">(Bergmann et al., 2019)</ref> and apply their object detector to recover missing positions based on the visual information at the last known position. Finally, for sequences filmed from a static camera, we perform linear interpolation on the remaining gaps. These sequences can be automatically detected using DeepMatching on the regions outside detection boxes.</p><p>To demonstrate the performance using traditional postprocessing, we also evaluate our tracker using only linear interpolation as post-processing in all sequences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3.">Cost Learning</head><p>Costs for base edges E and lifted edges E are computed equally, since they both indicate whether two detections are from the same object or not. For an edge e = vw, we denote with d wi (v) the detection width corresponding to node v.</p><p>Visual cues. We exploit two different appearance features: Given two detections, the re-identification descriptor utilizes global appearance statistics, while the deep-matching descriptor relies on fine-grained pixel-wise correspondences.</p><p>We employ the state-of-the-art re-identification network <ref type="bibr">(Zheng et al., 2019)</ref> and train it on MOT17 train set <ref type="bibr" target="#b12">(Milan et al., 2016)</ref> together with additional reidentification datasets <ref type="bibr">(Zheng et al., 2015;</ref><ref type="bibr">Wei et al., 2018;</ref><ref type="bibr" target="#b17">Ristani et al., 2016)</ref>. The obtained feature value f re-id (e) ‚àà [‚àí1, 1] is modified in order to better reflect the uncertainty of a connection. We truncate values smaller 0 (corresponding to improbable connections) and re-scale the rest. First, we normalize scores between each detection v and all detections in every time frame V j through the score of the most probable connecting edge vw. Second, all other connections than vw are downscaled.</p><p>Our second visual cue utilizes DeepMatching (DM) <ref type="bibr">(Weinzaepfel et al., 2013)</ref> to establishes pixelwise correspondences between two images. It thus serves as a reliable tracking feature <ref type="bibr">Henschel et al., 2018;</ref><ref type="bibr">2019b)</ref>.</p><p>We apply DM between boxes in two images and compute the DM intersection over union <ref type="bibr">Henschel et al., 2018)</ref> w.r.t. the whole detection boxes and on five subboxes (left/right, upper/middle/lower part). In addition, we measure for all points in a given subbox whether their matched endpoints are in the corresponding subbox again or not. This gives two additional error measures for deviation in x and y-directions. Thus, in total we obtain a feature vector f DM (e) ‚àà [0, 1] 8 . In order to assess the reliability of DM features, density of matching points is computed in each box and its subboxes. The smaller value is chosen for each box pair. This results in feature œÅ ‚àà [0, 1] 6 .</p><p>Motion constraints. We penalize for improbable motions by comparing the maximal displacement of DM endpoints within the sequence with the displacements of detection boxes. Assignment hypotheses of pairs of boxes representing improbable motions are penalized with a large cost.</p><p>Spatio-temporal cues. Our spatio-temporal cues utilize a simple motion compensation by computing the median DM displacement between correspondences of the background.</p><p>We assume a linear motion model, similar to <ref type="bibr" target="#b16">(Ristani &amp; Tomasi, 2018)</ref> and penalize deviations of detections from the estimated motion trajectory. This enforces spatio-temporally consistency of detections within one trajectory. Furthermore, we penalize improbable large person movements by relating velocities (in pixels per seconds) in horizontal direction to box width:</p><formula xml:id="formula_16">f trans (e) = log(v x (e)/ min{d wi (v), d wi (w)}).</formula><p>Fusion of input features. We construct a neural network consisting of fully connected layers, batch normalization and relu units taking the above described features and time differences as input and outputting scores for assignment hypotheses. The final layer uses a sigmoid activation function for producing a score in [0, 1]. We refer to the supplemental material for the exact structure of the neural network and details about the training procedure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4.">Experiment Setup</head><p>In order to assess the suitability of the proposed lifted disjoint paths formulation for MOT, we conduct extensive experiments on three challenging benchmarks: MOT15 <ref type="bibr" target="#b8">(Leal-Taix√© et al., 2015)</ref>, MOT16 and MOT17 <ref type="bibr" target="#b12">(Milan et al., 2016)</ref>, resulting in 39 test sequences. The sequences are filmed from static and moving cameras. While MOT16 and MOT17 share the same sequences, MOT17 provides three different detectors in order to study the dependence of the tracking quality on the input detections. We perform analysis and parameter tuning for our tracker on the MOT17 train set, even when our tracker is applied to the MOT15 sequences to ensure that our tracker is not prone to overfitting. We follow the MOT challenge protocol and use the detections provided by the respective benchmarks. All experiments on the training set are evaluated using a leave-one-out crossvalidation. This includes all of our training procedures, in particular also the training of the re-identification network.</p><p>To measure the tracking quality, the multiple object tracking accuracy (MOTA) <ref type="bibr">(Bernardin &amp; Stiefelhagen, 2008)</ref> and the IDF1 metric <ref type="bibr" target="#b17">(Ristani et al., 2016)</ref> are regarded as the most meaningful ones. The first incorporates the number of false negatives (FN), false positives (FP) and identity switches (IDS), thereby focusing on the coverage of persons. The latter assesses the consistency w.r.t. identities. Further tracking metrics (MT, ML) are defined in <ref type="bibr" target="#b10">(Li et al., 2009)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.5.">Benefit of Long Range Edges</head><p>We investigate the importance of using long range information for MOT. To this end, we apply our proposed tracker on the MOT17 training sequence with varying maximal time gap, for which base and lifted edges are created between nodes. In order to assess the influence of the time gap on the tracking quality, we measure the assignment quality in terms of the MOTA and IDF1 metrics, without performing any inter-or extrapolation. To assess how well the assignment part is solved by our tracker, we compute the maximum achievable metrics given the filtered input detections and admissible assignment hypotheses within maximal time gaps. A detailed description of how we obtain the optimal assignments are given in the appendix in Section 10.6. From the result in <ref type="table">Table 1</ref>, we see essentialy constant MOTA scores. This is due the fact that selecting correct connections does not change MOTA significantly except after inter-and extrapolation (which we have excluded in <ref type="table">Table 1</ref>). However, we see a significant improvement in the IDF1 score, which directly penalizes wrong connections. Here, long range edges help greatly. Moreover, both metrics, ID precision and ID recall, clearly increase with increasing time gap. This shows that improvements by incorporating more temporal information come from using longer skip edges (impact on IDR) but most importantly, precision increases greatly. This means that ID switches are avoided thanks to lifted edges. Furthermore, the experiment shows that our designed features together with the lifted disjoint paths formulation <ref type="formula" target="#formula_2">(3)</ref>   <ref type="bibr" target="#b18">(Sadeghian et al., 2017)</ref>. In addition, we compare the results to our tracker Lif_TsimInt that uses only a simple interpolation method (linear interpolation) as post-processing in all sequences. We outperform competing solvers on most metrics on all three MOT Challenge benchmarks, using Lif_T and Lif_TsimInt. Arrows indicate whether low or high metric values are better.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.6.">Benchmark Evaluations</head><p>Finally, we compare our tracking performance on the MOT15, MOT16 and MOT17 benchmarks with all trackers listed on the MOTChallenge which have been peer-reviewed and correspond to published work. The three benchmark datasets consist of 11/7/7 training and test sequences for MOT15/16/17 respectively. They are the standard benchmark datasets for MOT. The results in <ref type="table" target="#tab_1">Table 2</ref> show the tracking performance of our tracker together with the best 5 performing trackers, accumulated over all sequences of the respective benchmarks. The evaluations show that we outperform all tracking systems by a large margin on all considered benchmarks. On MOT17, we improve the MOTA score from 53.5 to 60.5 and the IDF1 score from 52.3 to 65.6, which corresponds to an improvement of 13% in terms of MOTA and almost 25% in terms of the IDF1 score, indicating the effectiveness of the lifted edges. We observe similar improvements across all three benchmarks. These results reflect the near-optimal assignment performance observed on the MOT17 train set in Sect. 7.5. Finally, using only simple linear interpolation as post-processing (Lif_TsimInt), our tracker achieves 58.2 MOTA and 65.2 IDF1. Even then, our system clearly outperforms existing tracking systems. On average, the ILP solver needs 26.6 min. per sequence. Detailed runtimes are available in <ref type="table">Table 5</ref> in Appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Conclusion</head><p>We have shown that for the MOT challenge datasets we reach nearly optimal data association performance. We conjecture that further improvements would have to come from better detectors, better inter-and extrapolation and more powerful solvers for our formulation to take into account even longer time-gaps. Our polyhedral work offers the basis for writing such more powerful solvers. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.">Acknowledgement</head><formula xml:id="formula_17">y vw ‚â• ij‚ààP E (y ij ‚àí 1) + 1 .<label>(13)</label></formula><p>Proof. Let us define the following sets: Let us rewrite the right hand side of (8) for a path P ‚àà vw-paths(G):</p><formula xml:id="formula_18">S B = {(y, y ) ‚àà [0, 1] E √ó [0, 1] E |(y, y ) satisfy (8)} , S M = {(y, y ) ‚àà [0, 1] E √ó [0, 1] E |(y,</formula><formula xml:id="formula_19">y vw ‚â• vj:j‚ààP V y vj ‚àí i‚ààP V \{v,w} k / ‚ààP V y ik = = vj:j‚ààP V y vj ‚àí i‚ààP V \{v,w} (x i ‚àí j‚ààP V y ij ) = = i‚ààP V \w j‚ààP V y ij ‚àí i‚ààP V \{v,w} x i ‚â• ‚â• ij‚ààP E y ij ‚àí i‚ààP V \{v,w} 1 = = ij‚ààP E (y ij ‚àí 1) + 1 .<label>(14)</label></formula><p>‚Ä¢ Let us prove that S B S M We prove that there exists (y, y ) ‚àà [0, 1] E √ó[0, 1] E such that (y, y ) satisfies (13) and does not satisfy (8). An example is given in <ref type="figure">Figure 1</ref>. There are four possible paths from v to w. If we use Constraints (13), the highest lower bound on y vw is given by path P = (vv 2 , v 2 v 4 , v 4 w) and it is as follows:</p><p>y vw ‚â• (0.5 ‚àí 1) + (0.5 ‚àí 1) + (1 ‚àí 1) + 1 = 0 .</p><p>Let us apply Constraint (8) using path P = (vv 1 , v 1 v 2 , v 2 v 3 , v 3 v 4 , v 4 w). We obtain the following threshold on y vw y vw ‚â• 0.5 + 0.5 ‚àí 0 ‚àí 0 = 1 .</p><p>Proposition 1. The lifted path inequalities (10) provide a strictly better relaxation than the path inequalities (8).</p><p>Proof. Let us define the following sets ‚Ä¢ Let us prove that S L ‚äÇ S B : Note that every path P ‚àà vw-paths(G) belongs to the set of vw-paths(G ‚à™ G ) too. It just holds that</p><formula xml:id="formula_20">P E = ‚àÖ. Let v v 1 v 2 v 3 v 4 w v 5 v 6</formula><p>0.5 0.5 0.5 0.5 1 0 0 0.5 0.5</p><p>? <ref type="figure">Figure 1</ref>. Failure case for lifted multicut path inequality (13). The path inequality <ref type="formula">(8)</ref> gives the correct lower bound for lifted edge y vw in this case. Example for Proposition 3.</p><p>us rewrite the right hands side of the inequality from <ref type="formula" target="#formula_10">(10)</ref> for such P ‚àà vw-path(G ‚à™ G ) where P E = ‚àÖ.</p><formula xml:id="formula_21">y vw ‚â• vj:j‚ààP V y vj ‚àí i‚ààP V \{v,w} k / ‚ààP V y ik + ij‚ààP E y ij ‚àí ij‚ààP E ‚à©E y ij = = vj:j‚ààP V y vj ‚àí i‚ààP V \{v,w} k / ‚ààP V y ik .</formula><p>Which is exactly the right hand side of (8). Therefore, any pair of real vectors (y, y ) ‚àà [0, 1] E √ó [0, 1] E that satisfies (10) must satisfy (8) as well.</p><p>‚Ä¢ Let us prove that S L S B :</p><p>We prove that there exists (y, y ) ‚àà [0, 1] E √ó [0, 1] E such that (y, y ) satisfies (8) and does not satisfy (10). See the graph in <ref type="figure" target="#fig_1">Figure 2</ref>. There are four possible paths from v to w in G. If we use Constraints (8), all the paths give us the same lower bound on y vw y vw ‚â• 1 ‚àí 0.5 ‚àí 0.5 = 0 .</p><p>If we use Constraints (10) with path P = (vv 1 , v 1 v 4 , v 4 w) where P E = {v 1 v 4 , v 4 w}, we obtain y vw ‚â• 1 ‚àí 0.5 ‚àí 0.5 ‚àí 0.5 ‚àí 0.5 + 1 + 1 = 1 .</p><p>Proposition 2. The lifted path-induced cut inequalities (11) define a strictly tighter relaxation than the path-induced cut inequalities (9).</p><p>Furthermore the lifted path-induced cut inequalities (11) and (12) define a strictly better relaxation than (11) alone.</p><p>Proof. Let us define the following sets ‚Ä¢ First, we prove S L1 ‚äÇ S B :</p><p>We use the same argument as in the proof of Proposition 1. Every path P ‚àà vw-paths(G) belongs to the set of vw-paths(G ‚à™ G ) and it holds that P E = ‚àÖ. Let us rewrite the right hands side of the inequality from <ref type="formula">(11)</ref> for</p><formula xml:id="formula_22">such P ‚àà vw-path(G ‚à™ G ) where P E = ‚àÖ. y vw ‚â§ i‚ààP V k / ‚ààP V kw‚ààR y ik ‚àí ij‚ààP E y ij + ij‚ààP E ‚à©E y ij = = i‚ààP V k / ‚ààP V kw‚ààR y ik .</formula><p>Which is exactly the right hand side of (9). Therefore, any pair of real vectors (y, y ) ‚àà [0, 1] E √ó [0, 1] E that satisfies (11) must satisfy (9).</p><p>‚Ä¢ Let us prove S L1 S B :</p><p>We prove that there exists (y, y ) ‚àà [0, 1] E √ó [0, 1] E such that (y, y ) satisfies (9) and does not satisfy (11). See the example in <ref type="figure" target="#fig_2">Figure 3</ref>. There are four possible paths in G from v to either u 1 or u 2 . They are P 1 = (vv 3 , v 3 u 1 ), P 2 = (vv 2 , v 2 u 1 ), P 3 = (vv 3 , v 3 u 2 ), P 4 = (vv 2 , v 2 u 2 ). Using (11), all of them give us the same threshold on y vw : y vw ‚â§ 0.5 + 0.5 + 0 = 1 .</p><p>If we use Constraint (11) with path P = (vu 1 ), we obtain the following threshold:</p><p>y vw ‚â§ 0.5 + 0.5 + 0 ‚àí 1 = 0 .</p><p>‚Ä¢ Let us prove that S L1 ‚à© S L2 S L1 It holds trivially that S L1 ‚à© S L2 ‚äÇ S L1 . Let us prove that there exists (y, y ) ‚àà [0, 1] E √ó [0, 1] E such that    <ref type="formula" target="#formula_12">(12)</ref> give the correct upper bound for lifted edge y vw . Example for Proposition 2. than the following:</p><formula xml:id="formula_23">y vw ‚â§ 1 .</formula><p>However, if we use Constraints (12) with path P = (vv 3 ) and y v3w = 0, we obtain y vw ‚â§ 0 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10.2.">Symmetric Form of Cut Inequalities</head><p>Inequalities symmetric to <ref type="formula" target="#formula_9">(9)</ref>:</p><formula xml:id="formula_24">‚àÄvw ‚àà E ‚àÄP ‚àà uw-paths(G) s.t. vu ‚àà R ‚àß u = v : y vw ‚â§ i‚ààP V k / ‚ààP V , vk‚ààR y ki .<label>(15)</label></formula><p>Inequalities symmetric to (11)</p><formula xml:id="formula_25">‚àÄvw ‚àà E ‚àÄP ‚àà uw-paths(G ‚à™ G ) s.t. vu ‚àà R ‚àß u = v : y vw ‚â§ i‚ààP V k / ‚ààP V , vk‚ààR y ki ‚àí ij‚ààP E y ij + ij‚ààP E ‚à©E y ij .<label>(16)</label></formula><p>Inequalities symmetric to <ref type="formula" target="#formula_12">(12)</ref> ‚àÄvw ‚àà E ‚àÄP ‚àà uw-paths (G ‚à™ G ) s.t. vu ‚àà E :</p><formula xml:id="formula_26">y vw ‚â§ i‚ààP V \u k / ‚ààP V , vk‚ààR y ki ‚àí ij‚ààP E y ij + ij‚ààP E ‚à©E y ij + y vu .<label>(17)</label></formula><p>Proposition 4. The lifted path-induced cut inequalities (16) define a strictly tighter relaxation than the path-induced cut inequalities (15).</p><p>The lifted path-induced cut inequalities <ref type="formula" target="#formula_6">(16)</ref> and <ref type="formula" target="#formula_7">(17)</ref>  Proposition 5. 1. The path-induced cut inequalities (9) together with their symmetric counterpart (15) define a strictly tighter relaxation than inequalities (9) alone.</p><p>2. The path-induced cut inequalities (11) together with their symmetric counterpart (16) define a strictly tighter relaxation than inequalities (11) alone.</p><p>3. Using path-induced cut inequalities (17) together with (11), (12) and (16) strictly improves the relaxation.</p><p>Proof. 1. See the example in <ref type="figure" target="#fig_8">Figure 7</ref>. Upper bound on y vw by (9): y vw ‚â§ 0.5 + 0.5 = 1.</p><p>Upper bound on y vw by (15): y vw ‚â§ 0.</p><p>2. See the example in <ref type="figure" target="#fig_6">Figure 5</ref>. Upper bound on y vw by (11): y vw ‚â§ 0.5 + 0.5 = 1.</p><p>Upper bound on y vw by (16) using path P = (u 2 w): y vw ‚â§ 0 + 0.5 + 0.5 ‚àí 1 = 0.</p><p>3. See the example in <ref type="figure" target="#fig_7">Figure 6</ref>. Upper bounds on y vw by (11), (12), (16): y vw ‚â§ 1.</p><p>Upper bound on y vw by (17) using path P = (uw) and y vu = 0: y vw ‚â§ 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10.3.">Other Valid Inequalities</head><p>Basic flow constraints (5) together with the advanced constrains on lifted edges (6)-(12) are sufficient for defining the set of feasible solutions of the lifted disjoint paths problem (3). Moreover, they define an efficient LP relaxation (Section 4) and enable efficient separation procedures (Section 5). Below, we present lifted flow inequalities specific to the lifted disjoint paths problem applied to MOT that help   to improve the speed of our ILP solver. The inequalities depend on the fact that every node can be connected to maximally one node in each time frame. Therefore the number of lifted edges originating (or ending) in a given point and ending (resp. originating) in a specific time frame is at most one.</p><formula xml:id="formula_27">‚àÄk, l ‚àà {1, . . . , T } : k &gt; l, ‚àÄv ‚àà V l : vu‚ààE :u‚ààV k y vu ‚â§ x v ,<label>(18)</label></formula><p>‚àÄk, l ‚àà {1, . . . , T } : k &lt; l, ‚àÄw ‚àà V l :</p><formula xml:id="formula_28">uw‚ààE :u‚ààV k y uw ‚â§ x w .<label>(19)</label></formula><p>The number of constraints <ref type="formula" target="#formula_27">(18)</ref> and <ref type="formula" target="#formula_9">(19)</ref> is linear in the number of vertices. Therefore, we add them to our initial constraint set. This enables to reduce the search space for the branch and bound method in the early solver stages when only few constraints of type (8)-(12) have been added.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10.4.">Proofs for Section 6 Complexity</head><p>We define Y GG to be the set of all (y, y ) ‚àà {0, 1} E √ó {0, 1} E such that (y, y ) are feasible solutions of the lifted disjoint path problem <ref type="formula" target="#formula_2">(3)</ref>.</p><p>Integer multicommodity flow. The integer multicommodity flow problem is defined on a directed graph G = (V, E) with edge capacities c ‚àà N E and source/sink pairs s i t i and edge flows f i ‚àà N E and demands R i , i = 1, . . . , k.</p><p>The aim is to send k flows from their sources to their sinks such that the flows obey the edge capacities. Formally,</p><formula xml:id="formula_29">k i=1 f i e ‚â§ c e ‚àÄe ‚àà E (20) u:uv‚ààE f i uv = w:vw‚ààE f i vw ‚àÄi ‚àà [k] ‚àÄv / ‚àà {s i , t i } (21) v:siv‚ààE f i siv ‚â• R i ‚àÄi ‚àà [k] (22)</formula><p>where [k] denotes the set {1, . . . , k}. Even has shown in <ref type="bibr">(Even et al., 1976</ref>) that the integer multicommodity flow problem is NP-complete also in the case of unit capacity edges and two source sink pairs. Below we detail a construction that gives us a correspondence between edge-disjoint paths in G and node-disjoint paths in the transformed graph G. This construction is similar to transforming a graph into its line graph. The lifted edges in the transformed graph will count how many units of flow go from sources to sinks.</p><p>Lemma 1. There exists a polynomial transformation from any graph G with source/sink pairs s i , t i , i = 1, . . . , k with demands R i to a pair of graphs G and G with edge costs c and c respectively such that there exists a feasible integer multicommodity flow in G if and only if the lifted disjoint paths problem for G, G has objective min (y,y )</p><formula xml:id="formula_30">‚ààY GG c, y + c , y ‚â§ ‚àí k i=1 R i .</formula><p>Proof. Without loss of generality, we consider these feasible flow sets f 1 , . . . , f k where it holds ‚àÄi ‚àà [k] :</p><formula xml:id="formula_31">siv‚ààE f i siv = R i .</formula><p>Note that if the flow of commodity i is higher than its demand R i , we can reduce it to R i by removing the flow across one or more s i t i -paths in G without violating other constraints. We first detail the graph transformation (see <ref type="figure" target="#fig_9">Figures 8 and  9</ref>).</p><p>‚Ä¢ For all edges ij ‚àà E add a vertex v ij to V .</p><p>‚Ä¢ For each pair of vertices v ij , v jk ‚àà V add an edge (v ij , v jk ) to E.</p><p>‚Ä¢ Add vertices s and t to V .</p><p>‚Ä¢ Add to V vertices s 1 i , s 2 i , . . . , s Ri i representing requirements of each commodity i.</p><p>‚Ä¢ For each vertex s r i add an edge (s,</p><formula xml:id="formula_32">s r i ) to E. ‚Ä¢ For each pair of vertices s r i , v sij add edge (s r i , v sij ) to E.</formula><p>‚Ä¢ For all v kti ‚àà V (representing and edge from k to t i in G) add an edge (v kti , t) to E.</p><p>‚Ä¢ For all pairs of vertices v sij v kti ‚àà V add an edge (v sij , v kti ) to E . That is, the lifted edges connect all vertices representing edges from s i in G with vertices representing the edges to t i in G.</p><p>‚Ä¢ Cost function on base edges ‚àÄe ‚àà E : c e = 0.</p><p>‚Ä¢ Cost function on lifted edges ‚àÄe ‚àà E : c e = ‚àí1.</p><p>An illustration of this construction can be seen in <ref type="figure" target="#fig_9">Figures 8  and 9</ref>. Note that the construction of G in <ref type="bibr">(Even et al., 1976)</ref> allows s i = s j for i = j. In this case, we still construct separate vertices for their incident edges in G.</p><formula xml:id="formula_33">Every path P = (s i k 1 , k 1 k 2 , . . . , k n t i ) in G can be assigned to a path P = (ss r i , s r i v sik1 , v sik1 v k1k2 , . . . , v knti t) in G where r ‚àà [R i ]</formula><p>can be chosen arbitrarily and vice versa. Note that such a path P saturates exactly one lifted edge (v sik1 , v knti ). Moreover, every feasible set of flow functions f 1 , . . . , f k satisfying for all i ‚àà [k] : siv‚ààE f i siv = R i defines a set of edge-disjoint paths from s 1 , . . . , s k to t 1 , . . . , t k in G. This set corresponds to a set of k i=1 R i st-paths in G whose edges and vertices are disjoint and where every path saturates exactly one lifted edge v sij v kti . Every lifted edge contributes with ‚àí1 to the total cost. So, this set of disjoint st-paths has total cost ‚àí k i=1 R i . Reversely, let us have a set of vertex-and edge-disjoint Proof. The NP-complete integer multicommodity flow problem with unit edge capacities can be reduced in polynomial time to the lifted disjoint paths problem (3) with negative lifted edges only. The transformation is described in Lemma 1.</p><p>3-SAT. The boolean satisfiability problem (SAT) is a classical NP-complete problem <ref type="bibr">(Cook, 1971)</ref>. from its NP-complete special version 3-SAT is commonly used for proving than a problem is NP-hard or NP-complete. Theorem 2. Lifted disjoint paths problem (3) with positive lifted edges only is NP-hard.</p><formula xml:id="formula_34">A transformation cd eƒì b c c c a aƒÅƒÅ s t -1 -1 4 4 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1</formula><p>Proof. Below, we detail a transformation from 3-SAT to the lifted disjoint paths problem with positive lifted edges only. For the transformation, it holds that a 3-SAT formula consisting of k clauses has a true assignment iff min</p><formula xml:id="formula_35">(y,y )‚ààY GG Œ≥(y, y ) ‚â§ ‚àí(k ‚àí 1).</formula><p>Let a 3-SAT problem containing k ordered clauses C 1 . . . C k be given. Each clause C i consists of a conjunction of literals, which is either a variable a or its complement a. We construct graphs G = (V, E) and G = (V , E ) as follows.</p><p>‚Ä¢ The graph G has k layers. Every layer corresponds to one clause. Each layer contains 3 vertices labeled with the literals in the corresponding clause. Specifically, for a variable a in clause C i we associate node v ia , analoguously for a complemented variable b in clause C i we associate node v ib .</p><p>‚Ä¢ For every pair of vertices</p><formula xml:id="formula_36">v il1 ‚àà V and v i+1l2 ‚àà V where l 1 =l 2 add an edge (v il1 , v i+1l2 ) to E and set c (v il 1 ,v i+1l 2 ) = ‚àí1.</formula><p>‚Ä¢ For every variable a and every pair of vertices v ia , v jƒÅ ‚àà V where j &gt; i + 1 add an edge (v ia , v jƒÅ ) to E and set c (via,vjƒÅ) = k. Do so analoguously for every pair of variables v iƒÅ and v ja .</p><p>‚Ä¢ Add an edge from s to all vertices corresponding to the first clause. And an edge to t from all vertices corresponding to the last clause.</p><p>An illustration of this construction can be found in <ref type="figure" target="#fig_10">Figure 10</ref>.</p><p>Every path P ‚àà st-paths(G) that has cost ‚àí(k ‚àí 1) saturates vertices labelled by non-contradicting literals. We can obtain a 3-SAT solution from P as follows. If v ia ‚àà P V , set variable a := true. If v jb ‚àà P , set variable b := f alse.</p><p>Variables not contained as labels of vertices in P V can have arbitrary values. Similarly, every solution of 3-SAT problem defines at least one path P ‚àà st-paths(G) that has cost ‚àí(k ‚àí 1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10.5.">Implementation Details on the Lifted Disjoint Paths Solver</head><p>The solver for the lifted disjoint paths problem is implemented in C++ and builds upon Gurobi 7.5. All experiments were conducted on a machine with a 6-Core Intel 2.00GHz CPU and 128 GB RAM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10.6.">Optimal data association</head><p>The experiment of Section 7.5 compares the assignments of our tracking system with the optimal assignments. We elaborate on the details to obtain the optimal assignments. We start with the pre-processed input detections, according to Section 7.2. For each frame, we compute the intersection over union between the detections and ground-truth boxes of the respective frame, which forms a weighted bipartite graph. Edges with a corresponding intersection over union below 0.5 are removed. Then, we use Hungarian matching to find a maximum-weight matching. Unmatched detections are considered as false positives, while matched detections are assigned the corresponding ground-truth label. Thus, we obtain the trajectories on the input detections using the optimal assignment. Finally, depending on the time threshold of <ref type="table">Table 1</ref>, trajectories are synthetically splitted at skip-edges longer than the specified threshold.</p><p>10.7. Ablation study on post-processing methods.</p><p>Solving the proposed lifted disjoint paths problem establishes the assignment of input detections to object identities very close to the best possible assignment (Section 7.5).</p><p>To localize tracked objects also in the frames in which the object detector failed to detect them, some trackers apply an additional object detector on these frames based on the available input detections. This can be seen as performing interpolation and extrapolation, if viewed from the perspective of data association in a tracking-by-detection framework, e.g. see <ref type="bibr">(Bergmann et al., 2019)</ref>. As a result, improvements can be achieved from extending trajectories to image areas without input detections by applying of a very accurate object detector.</p><p>In order to make our tracking performance comparable with other trackers, we follow this strategy and employ an interand extrapolation based on <ref type="bibr">(Bergmann et al., 2019)</ref>.  <ref type="table">Table 3</ref>. Ablation study on inter-and extrapolation, evaluated on the MOT17 train set. SI = spatial interpolation only on sequences filmed from a static camera, SI * = spatial interpolation on all sequences, VI = visual interpolation, VE = visual extrapolation. Assignment and assignment (optimal) denote the results of the lifted disjoint paths problem and the optimal assignment, as reported in Section 7.5 given 2s time gap. Note that Tracktor's object detector is fine-tuned on MOT17Det. In our experiments, this resulted in bigger improvements on the MOT17 training set than on the test set, compare <ref type="table" target="#tab_1">Table 2</ref>. <ref type="table">Table 3</ref> reports the influence of employing inter-and extrapolation. The first two rows repeat values from <ref type="table">Table 1</ref> given the maximal 2s time gap. Since our solver produces nearly optimal data assignemt with respect to the used input detections, further improvements can only be achieved by applying interpolation and extrapolation on the tracks obtained by the solver.</p><p>We compare the visual interpolation (VI) as well as visual extrapolation (VE), both using the method of (Bergmann et al., 2019) with spatial interpolation (SI). For SI, we employ linear interpolation based solely on the geometric bounding box information.</p><p>The interpolation SI is applied only to sequences with a fixed camera in order to guarantee robust approximations. Still, the improvements by Assignment+SI over the baseline is evident. Especially the MOTA metric, which measures mainly the coverage of objects by detections, improves by about 10%. We also evaluate spatial interpolation for all sequences (SI * ), which improves the tracker further to 59.5 MOTA and 68.9 IDF1. However, performing spatial interpolation on sequences with moving cameras can lead to error propagation. Thus, our final tracker Lif_T relies on the more robust visual interpolation and employs spatial interpolation only on sequences filmed from a static camera.</p><p>On the contrary, the visual interpolation based on <ref type="bibr">(Bergmann et al., 2019)</ref> can be applied robustly to all sequences, but only in situations where the object is visible. Accordingly, the method Assignment+VI further improves over the baseline, as it is applied to more frames.</p><p>Recovering the position of tracked objects also outside of the time range of its computed trajectory (Assignment+VI+VE) further helps to improve the tracking accuracy, enhancing MOTA by about 20% and IDF1 by about 10% IDF1, as VE extends computed trajectory thereby achieving longer identity consistencies.</p><p>Finally, we employ spatial interpolation on the remaining cases where detections are missing and the objects are fully occluded (Assignment+VI+VE+SI) resulting in a slight improvement over Assignment+VI+VE.</p><p>Note that we use the method Assignment+VI+VE+SI to evaluate our tracker on the MOT15, MOT16 and MOT17 test set, as reported in <ref type="table" target="#tab_1">Table 2</ref>. The impact of the postprocessing on the training set using Tracktor seems to be very high. We conjectured this might be due to the fact that Tracktor's object detector is trained on MOT17Det (which are the detections of MOT17), leading to some degree of overfitting. Note that Tracktor is not trained the MOT17 tracking ground truth, so that it is still regarded as a meaningful validation procedure <ref type="bibr">(Bergmann et al., 2019)</ref>. Therefore, we created another tracker Lif_TsimInt that uses a simple interpolation, namely only linear interpolation between detections of a trajectory, for all sequences. The tracker thus corresponds to Assignment+SI * . Comparing <ref type="table">Table 3</ref> with <ref type="table" target="#tab_1">Table 2</ref>, we see that indeed, the impact of the post-processing on the test set is significantly lower. We conclude that while the post-processing improves the tracking performance, the main performance of our tracker is due to our contributions.</p><p>Recall that most offline tracking systems obtain trajectories by solving a data association problem, e.g. <ref type="bibr">(Henschel et al., 2018;</ref><ref type="bibr" target="#b9">Tang et al., 2017;</ref><ref type="bibr" target="#b16">Ristani &amp; Tomasi, 2018</ref>). Our proposed tracker is able to achieve near-optimal results with respect to the input detections. Applying interpolation and extrapolation further improves the results, and makes it conceptually comparable to Tracktor. Still, with postprocessing on our computed data-association, we improve over Tracktor by 25%. We argue that solving the data association accurately is important to obtain a final high-quality result after post-processing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10.8.">Further Details on the Feature Fusion Network.</head><p>We discuss in detail the neural network which fuses the input features, thereby extending Section 7.3.</p><p>Architecture of the fusion network. Considering one assignment hypothesis represented by an edge e = vw, the DeepMatching densities œÅ ‚àà [0, 1] 6 as well the temporal distance t between the corresponding detections v and w serve as a confidence score for the remaining input features. They describe which of the input features is a reliable metric for a given assignment hypothesis, but they are not giving any information about the correctness of the assignment hypothesis. We transform the density features non-linearly and denote them together with the temporal distance as control features C(e) := (log(œÅ), t) ‚àà R 6 √ó [0, 2]. The remaining features described in Section 7.3 are denoted as F(e) ‚àà [0, 1] n .</p><p>One plausible architecture is to use a convex combination of the input features, such that the coefficients depend on the control features. To this end, let Œ± i (C(e), W Œ±i ) for i = 1, ¬∑ ¬∑ ¬∑ , n denote a neural network with the control features as input and W Œ±i as learnable weights. Further, let Œ≤ i (F(e) i , W Œ≤i ) for i = 1, ¬∑ ¬∑ ¬∑ , n be a neural network applied to i-th feature of F(e), with learnable weights W Œ≤i .</p><p>The input features and control features can then be fused via n i=1 Œ± i (C(e), W Œ±i )Œ≤ i (F(e) i , W Œ≤i ),</p><p>such that n i=1 Œ± i (C(e), W Œ±i ) = 1.</p><p>To ensure stable training, (23) should be applied to a sigmoid function and trained using binary cross-entropy loss.</p><p>Nonetheless, our tracker implementation employs neural network based mainly on a combination of relu units and fully connected layers, which performed slightly better, still sharing the idea of seperating the input into control features and input features. The detailed architecture is depicted in <ref type="figure" target="#fig_11">Figure 11</ref>.</p><p>Training details. Training of the neural network is performed directly on the (preprocessed) input detections. Labels are retrieved by assigning each detection to the best fitting ground-truth bounding box. Detections with ambiguous assignments are ignored within the training phase.</p><p>In order to train the edge classifier, special care has to be taken as the training set is highly imbalanced. The number of edges which correspond to true negatives (pairs of detections which do not belong to the same person) clearly dominates the number of true positive edges (pairs of detections belonging to the same person).</p><p>To address this issue, the network is trained on a randomly sampled subset of all possible edges, such that the ratio of true positive edges and true negative edges per time distance between the end nodes of the edges remains fixed. The maximal temporal distance of an edge is set to 2 seconds, allowing to recover persons even after long occlusions.</p><p>The weights of the fusion network are optimized according to the binary cross-entropy loss. We employ stochastic gradient descent with the learning rate set to 10 ‚àí2 and Nesterov momentum set to 0.9, for a total of 10 epochs. Training and inference is performed using Pytorch 1.3 on a Nvidia RTX 2080 Ti.</p><p>Accuracy of the fusion network. The performance of a tracking system depends highly on the accuracy of the edge classifier (and the corresponding edge weights).</p><p>Therefore, we report our evaluation of the edge classifier on all training sequences of the filtered MOT17 train set in <ref type="table">Table 4</ref>. Together with <ref type="table">Table 5</ref> and <ref type="table" target="#tab_1">Table 2</ref>, it shows that improvements in the tracking features directly correlate to high quality tracking results thanks to the proposed solver. While <ref type="table">Table 4</ref> shows very good performance of the edge classifier, a powerful graph model and solver is still crucial to obtain high quality tracking results. Even small errors (we observed 5% maximal error) in the edge classifier can cause many errors in the tracking results if an unsuitable procedure is used. Also note that for training the edge classifier, detections with ambiguous assignment to the ground truth boxes were ignored. So, these potentially difficult cases are excluded int the evaluation of the edge classifier. Especially the interpolation and extrapolation is prone to error propagation, once a single identity switch has been created, which heavily affects, among others, the IDF1 score.  <ref type="table">Table 4</ref>. Performance metrics on the edge classifier. The performance is measured in terms of the accuracy (Acc), precision (Prec), true positive rate (TPR) and true negative rate (TNR). The arrows indicate that higher metric values are better. disjoint paths formulation can be advantageous, since lifted edges aggregate multiple edge classifiers which can correct individual wrong classifications of single edges.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10.9.">Extended Quantitative Results</head><p>We provide additional evaluations on our tracking system as well as on the lifted disjoint paths solver.</p><p>Detailed tracking evaluations. We provide the evaluations of the MOT15, MOT16, MOT17 test sets as well as the MOT17 train set per sequence in <ref type="table">Table 5</ref>. In addition, the table contains the solver time (STime) in seconds, needed to solve the corresponding lifted disjoint paths problem.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>S</head><label></label><figDesc>B = {(y, y ) ‚àà [0, 1] E √ó [0, 1] E |(y, y ) satisfy (8)} , S L = {(y, y ) ‚àà [0, 1] E √ó [0, 1] E |(y, y ) satisfy (10)} .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>SFigure 2 .</head><label>2</label><figDesc>B = {(y, y ) ‚àà [0, 1] E √ó [0, 1] E |(y, y ) satisfy (9)} , S L1 = {(y, y ) ‚àà [0, 1] E √ó [0, 1] E |(y, y ) satisfy (11)} , S L2 = {(y, y ) ‚àà [0, 1] E √ó [0, 1] E |(y, y ) satisfy (12)} . Exemplary case where the path inequalities (8) give a trivial lower bound on lifted edge y vw . The lifted path inequality (10) gives the correct lower bound. Example for Proposition 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>(y, y ) ‚àà S L1 and (y, y ) / ‚àà S L1 ‚à© S L2 . See the example graph in Figure 4. Similarly as in Figure 3, there are four possible paths from v to either u 1 or u 2 in G. There are no active lifted edges that would enable us to obtain a better upper bound on y vw using (11) Exemplary case where the path-induced cut inequalities (9) fail to give non-trivial upper bounds for lifted edge y vw . The lifted path-induced cut-inequalities (11) give the correct upper bound in this case. Example for Proposition 2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 .</head><label>4</label><figDesc>Exemplary failure case for the lifted path-induced cut inequalities (11). The lifted path-induced cut inequalities</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>define a strictly better relaxation than (16) alone. Proof. Analogical to the proof of Proposition 2. See Figure 5 for example analogical to the one in Figure 3 and Figure 6 for example analogical to the one in Figure 4.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 .</head><label>5</label><figDesc>The best upper bound on y vw is provided by inequalities (16). Example for Proposition 4 and Proposition 5.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 .</head><label>6</label><figDesc>The best upper bound on y vw is provided by inequalities (17). Example for Proposition 4 and Proposition 5.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 7 .</head><label>7</label><figDesc>The best upper bound on y vw is provided by inequalities (15). Example for Proposition 5.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 9 .</head><label>9</label><figDesc>Integer multicommodity flow network transformation. Transformed graph from Figure 8 for flow demands R1 = 2, R2 = 2. Edges without label have cost 0. st-paths in G of size k i=1 R i where every path contains some v sij v kti -path as its subpath and therefore its cost is ‚àí k i=1 R i . This set defines uniquely a set of feasible flow functions f 1 , . . . , f k . So, there exist feasible functions f 1 , . . . , f k satisfyingf i = R i for all i ‚àà [k] iff min (y,y )‚ààY GG Œ≥(y, y ) ‚â§ ‚àí k i=1 R i .Theorem 1. Lifted disjoint paths problem (3) with negative lifted edges only is NP-hard.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 10 .</head><label>10</label><figDesc>Reduction to lifted disjoint paths problem for 3-SAT formula (a ‚à® b ‚à®c) ‚àß (a ‚à® c ‚à®d) ‚àß (ƒÅ ‚à® c ‚à® e) ‚àß (ƒÅ ‚à® c ‚à®ƒì).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 11 .</head><label>11</label><figDesc>The architecture of the edge classifier used in Lif_T. FC-i denotes a fully-connected layer with i nodes in as outputs. Using a concatenation with subsequent fully connected layer, m control features and n input features are fused.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc>are well-suited for the MOT problem delivering nearly optimal assignments.</figDesc><table><row><cell></cell><cell>0.3s 0.5s 1s 1.5s 2s</cell><cell>‚àû</cell></row><row><cell>MOTA (ours)‚Üë</cell><cell>52.6 52.7 52.8 52.8 52.8</cell><cell>-</cell></row><row><cell cols="3">MOTA (optimal)‚Üë 53.0 53.1 53.3 53.3 53.4 53.4</cell></row><row><cell>IDF1 (ours) ‚Üë</cell><cell>55.7 57.8 61.8 63.8 64.3</cell><cell>-</cell></row><row><cell cols="3">IDF1 (optimal)‚Üë 56.0 58.6 63.2 65.7 66.8 69.9</cell></row><row><cell>IDP (ours) ‚Üë</cell><cell>79.8 82.9 88.5 91.4 92.1</cell><cell>-</cell></row><row><cell>IDP (optimal)‚Üë</cell><cell cols="2">80.4 84.2 90.8 94.3 95.9 100.0</cell></row><row><cell>IDR (ours) ‚Üë</cell><cell>42.7 44.5 47.4 49.0 49.4</cell><cell>-</cell></row><row><cell>IDR (optimal)‚Üë</cell><cell cols="2">42.9 45.0 48.5 50.4 51.3 53.4</cell></row></table><note>Table 1. Assignment quality of our solver without interpolation or extrapolation on the MOT17 train set with different maximal time gaps in seconds. Rows 1,3,5 and 7 show the results by our solver, rows 2,4,6 and 8 show the maximally achievable bounds with admissible assignment hypotheses up to the specified time gap. Bold numbers represent the best values per row.. We compare our tracker Lif_T with the five best performing competing solvers w.r.t. MOTA from the MOT challenge. Track- tor (Bergmann et al., 2019), JBNOT (Henschel et al., 2019b), FAMNet (Chu &amp; Ling, 2019), eTC (Wang et al., 2019b), eHAF (Sheng et al., 2018), NOTA (Chen et al., 2019), HCC (Ma et al., 2018), KCF (Chu et al., 2019), AP_HWDPL_p (Chen et al., 2017), STRN (Xu et al., 2019) and AMIR15</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Cook, S. A. The complexity of theorem-proving procedures. In Proceedings of the third annual ACM symposium on Theory of computing, pp. 151-158. ACM, 1971. International Journal Tang, S., Andriluka, M., Andres, B., and Schiele, B. Multiple people tracking by lifted multicut and person reidentification. In IEEE Conference on Computer Vision and Pattern Recognition, 2017. Tholey, T. Linear time algorithms for two disjoint paths problems on directed acyclic graphs. Joint discriminative and generative learning for person re-identification. In IEEE Conference on Computer Vision and Pattern Recognition, 2019.</figDesc><table><row><cell></cell><cell>Dehghan, A., Modiri Assari, S., and Shah, M. GMMCP</cell></row><row><cell>Babaee, M., Athar, A., and Rigoll, G. Multiple people Theoretical Com-tracking using hierarchical deep tracklet re-identification. puter Science, 465:35-48, 2012. arXiv preprint arXiv:1811.04091, 2018. von Marcard, T., Henschel, R., Black, M. J., Rosenhahn, Beier, T., Pape, C., Rahaman, N., Prange, T., Berg, S., Bock, B., and Pons-Moll, G. Recovering accurate 3d human D. D., Cardona, A., Knott, G. W., Plaza, S. M., Scheffer, pose in the wild using imus and a moving camera. In L. K., et al. Multicut brings automated neurite segmenta-Proceedings of the European Conference on Computer tion closer to human performance. Nature Methods, 14 (2):101, 2017. Vision (ECCV), pp. 601-617, 2018.</cell><cell>tracker: Globally optimal generalized maximum multi clique problem for multiple object tracking. In IEEE Conference on Computer Vision and Pattern Recognition, pp. 4091-4099, 2015. Eilam-Tzoreff, T. The disjoint shortest paths problem. Dis-crete Applied Mathematics, 85(2):113-138, 1998. timetable and multicommodity flow problems. SIAM J. Even, S., Itai, A., and Shamir, A. On the complexity of</cell></row><row><cell>Wang, C., Wang, Y., Wang, Y., Wu, C.-T., and Yu, G. mussp: Berclaz, J., Fleuret, F., Turetken, E., and Fua, P. Multiple Efficient min-cost flow algorithm for multi-object track-object tracking using k-shortest paths optimization. IEEE ing. In Advances in Neural Information Processing Sys-Transactions on Pattern Analysis and Machine Intelli-gence, 33(9):1806-1819, 2011. tems, pp. 423-432, 2019a. Section 10.6 provides further information how</cell><cell>Comput., 5:691-703, 12 1976. doi: 10.1137/0205048. Gurobi Optimization, L. Gurobi optimizer reference manual, 2019. URL http://www.gurobi.com.</cell></row><row><cell>the optimal assignments used in Section 7.5 were Wang, G., Wang, Y., Zhang, H., Gu, R., and Hwang, J.-N. Bergmann, P., Meinhardt, T., and Leal-Taix√©, L. Track-obtained. The impact of the employed post-Exploit the connectivity: Multi-object tracking with track-ing without bells and whistles. In IEEE International processing used in our tracker is analyzed in Sec-letnet. In ACM International Conference on Multimedia, Conference on Computer Vision, pp. 941-951, 2019. pp. 482-490, 2019b. tion 10.7. Details about the used fusion network</cell><cell>Henschel, R., Leal-Taix√©, L., and Rosenhahn, B. Efficient multiple people tracking using minimum cost arbores-cences. In German Conference on Pattern Recognition, pp. 265-276. Springer, 2014.</cell></row><row><cell>Bernardin, K. and Stiefelhagen, R. Evaluating multi-ple object tracking performance: the clear mot metrics. EURASIP Journal on Image and Video Processing, 2008: are given in Section 10.8. Finally, evaluation met-Wei, L., Zhang, S., Gao, W., and Tian, Q. Person transfer rics for all tracked sequences are provided in Sec-In IEEE Conference on Computer Vision and Pattern gan to bridge domain gap for person re-identification. tion 10.9.</cell><cell>Henschel, R., Leal-Taix√©, L., Rosenhahn, B., and Schindler, K. Tracking with multi-level features. arXiv preprint arXiv:1607.07304, 2016.</cell></row><row><cell>1-10, 2008. Brendel, W., Amer, M., and Todorovic, S. Multiobject Recognition, pp. 79-88, 2018. Weinzaepfel, P., Revaud, J., Harchaoui, Z., and Schmid, C. 10. Appendix</cell><cell>Henschel, R., Leal-Taix√©, L., Cremers, D., and Rosenhahn, B. Fusion of head and full-body detectors for multi-object</cell></row><row><cell>tracking as maximum weight independent set. In IEEE Conference on Computer Vision and Pattern Recognition, Deepflow: Large displacement optical flow with deep matching. In IEEE Intenational Conference on Computer 10.1. Proofs for Section 4</cell><cell>tracking. In IEEE Conference on Computer Vision and Pattern Recognition Workshops, June 2018.</cell></row><row><cell>pp. 1273-1280. IEEE, 2011. Chari, V., Lacoste-Julien, S., Laptev, I., and Sivic, J. On pairwise costs for network flow multi-object tracking. Vision, Sydney, Australia, December 2013. URL http: Proposition 3. Path inequalities (8) define a strictly tighter relaxation of the lifted disjoint path problem than the lifted //hal.inria.fr/hal-00873592. Xu, J., Cao, Y., Zhang, Z., and Hu, H. Spatial-temporal multicut path inequalities</cell><cell>Henschel, R., von Marcard, T., and Rosenhahn, B. Simulta-neous identification and tracking of multiple people using video and imus. In Proceedings of the IEEE Conference</cell></row><row><cell>In IEEE Conference on Computer Vision and Pattern relation networks for multi-object tracking. In IEEE ‚àÄvw ‚àà E ‚àÄP ‚ààvw-paths(G) :</cell><cell>on Computer Vision and Pattern Recognition Workshops,</cell></row><row><cell>Recognition, pp. 5537-5545, 2015. International Conference on Computer Vision, pp. 3988-</cell><cell>pp. 0-0, 2019a.</cell></row><row><cell>Chen, L., Ai, H., Shang, C., Zhuang, Z., and Bai, B. Online 3998, 2019.</cell><cell>Henschel, R., Zou, Y., and Rosenhahn, B. Multiple peo-</cell></row><row><cell>multi-object tracking with convolutional neural networks. Zamir, A. R., Dehghan, A., and Shah, M. GMCP-tracker: In IEEE International Conference on Image Processing, Global multi-object tracking using generalized minimum pp. 645-649. IEEE, 2017. clique graphs. In European Conference on Computer Chen, L., Ai, H., Chen, R., and Zhuang, Z. Aggregate track-Vision, pp. 343-356. Springer, 2012.</cell><cell>ple tracking using body and joint detections. In IEEE This work was funded by the Deutsche Forschungsgemein-Conference on Computer Vision and Pattern Recognition schaft (DFG, German Research Foundation) under Ger-Workshops, pp. 0-0, 2019b. many's Excellence Strategy within the Cluster of Excellence PhoenixD (EXC 2122). We thank Laura Leal-Taix√© for ini-Hofmann, M., Wolf, D., and Rigoll, G. Hypergraphs for</cell></row><row><cell>let appearance features for multi-object tracking. IEEE Zhang, L., Li, Y., and Nevatia, R. Global data association</cell><cell>tiating the collaboration. We thank all reviewers for their joint multi-view reconstruction and multi-object tracking.</cell></row><row><cell>Signal Processing Letters, 26(11):1613-1617, 2019. for multi-object tracking using network flows. In IEEE</cell><cell>valuable comments. In IEEE Conference on Computer Vision and Pattern</cell></row><row><cell>Conference on Computer Vision and Pattern Recognition, Chu, P. and Ling, H. Famnet: Joint learning of feature, affin-ity and multi-dimensional assignment for online multiple pp. 1-8. IEEE, 2008.</cell><cell>Recognition, pp. 3650-3657, 2013. Hor≈à√°kov√°, A., Lange, J.-H., and Andres, B. Analysis and</cell></row><row><cell>object tracking. In IEEE International Conference on Zheng, L., Shen, L., Tian, L., Wang, S., Wang, J., and Tian,</cell><cell>optimization of graph decompositions by lifted multicuts.</cell></row><row><cell>Computer Vision, pp. 6172-6181, 2019. Q. Scalable person re-identification: A benchmark. In</cell><cell>In International Conference on Machine Learning, 2017.</cell></row><row><cell>IEEE International Conference on Computer Vision, pp.</cell><cell></cell></row><row><cell>1116-1124, 2015.</cell><cell></cell></row></table><note>Chu, P., Fan, H., Tan, C. C., and Ling, H. Online multi- object tracking with instance-aware tracker and dynamic model refreshment. In IEEE Winter Conference on Appli- cations of Computer Vision, pp. 161-170. IEEE, 2019.Hu, W., Shi, X., Zhou, Z., Xing, J., Ling, H., and May- bank, S. Dual L1-normalized context aware tensor power iteration and its applications to multi-object track- ing and multi-graph matching.Zheng, Z., Yang, X., Yu, Z., Zheng, L., Yang, Y., and Kautz, J.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>Computer Vision and Machine Learning, Max Planck Institute for Informatics, Saarbr√ºcken, Saarland, Germany 2 Institut for Image Processing, Leibniz University Hannover, Hannover, Niedersachsen, Germany. Correspondence to: Andrea Hornakova &lt;andrea.hornakova@mpi-inf.mpg.de&gt;, Roberto Henschel &lt;henschel@tnt.uni-hannover.de&gt;. Proceedings of the 37 th International Conference on Machine Learning, Vienna, Austria, PMLR 119, 2020. Copyright 2020 by the author(s).</figDesc><table /><note>y ) satisfy (13)} .‚Ä¢ Let us prove that S B ‚äÇ S M* Equal contribution 1</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>During the inter-and extrapolation, output detections (coming from the lifted disjoint paths solver) are preserved. In particular, the detections are not rejected, reshaped, neither are their labels changed by Tracktor. Instead, we apply Tracktor to recover further locations of an object in the frames where detections of the object were missing. The procedure is based on its trajectory obtained from the lifted disjoint paths solver. Note that our adaption ignores additional, unassigned input detections, whereas the original implementation(Bergmann et al., 2019)  of Tracktor fuses the detections coming from Tracktor's detector with detections provided by the dataset.</figDesc><table><row><cell>Method</cell><cell cols="2">MOTA IDF1</cell></row><row><cell>Assignment</cell><cell>52.8</cell><cell>64.3</cell></row><row><cell>Assignment (optimal)</cell><cell>53.4</cell><cell>66.8</cell></row><row><cell>Assignment+SI</cell><cell>57.8</cell><cell>67.6</cell></row><row><cell>Assignment+SI  *</cell><cell>59.5</cell><cell>68.9</cell></row><row><cell>Assignment+VI</cell><cell>59.6</cell><cell>68.5</cell></row><row><cell>Assignment+VI+VE</cell><cell>65.7</cell><cell>71.5</cell></row><row><cell>Assignment+VI+VE+SI</cell><cell>67.0</cell><cell>72.4</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>Our liftedSequenceAcc ‚Üë Prec ‚Üë TPR ‚Üë TNR ‚Üë</figDesc><table><row><cell>MOT17-02-DPM</cell><cell>1.00</cell><cell>0.99</cell><cell>1.00</cell><cell>1.00</cell></row><row><cell>MOT17-04-DPM</cell><cell>1.00</cell><cell>0.98</cell><cell>0.99</cell><cell>1.00</cell></row><row><cell>MOT17-05-DPM</cell><cell>0.95</cell><cell>0.95</cell><cell>1.00</cell><cell>0.99</cell></row><row><cell>MOT17-09-DPM</cell><cell>1.00</cell><cell>0.98</cell><cell>0.98</cell><cell>1.00</cell></row><row><cell>MOT17-10-DPM</cell><cell>1.00</cell><cell>0.99</cell><cell>0.99</cell><cell>1.00</cell></row><row><cell>MOT17-11-DPM</cell><cell>1.00</cell><cell>1.00</cell><cell>0.99</cell><cell>1.00</cell></row><row><cell>MOT17-13-DPM</cell><cell>0.99</cell><cell>0.97</cell><cell>0.96</cell><cell>1.00</cell></row><row><cell>MOT17-02-SDP</cell><cell>1.00</cell><cell>0.96</cell><cell>1.00</cell><cell>1.00</cell></row><row><cell>MOT17-04-SDP</cell><cell>1.00</cell><cell>0.98</cell><cell>0.98</cell><cell>1.00</cell></row><row><cell>MOT17-05-SDP</cell><cell>0.99</cell><cell>0.92</cell><cell>1.00</cell><cell>0.98</cell></row><row><cell>MOT17-09-SDP</cell><cell>0.97</cell><cell>0.81</cell><cell>0.99</cell><cell>0.97</cell></row><row><cell>MOT17-10-SDP</cell><cell>0.99</cell><cell>0.94</cell><cell>0.97</cell><cell>1.00</cell></row><row><cell>MOT17-11-SDP</cell><cell>1.00</cell><cell>0.99</cell><cell>0.99</cell><cell>1.00</cell></row><row><cell>MOT17-13-SDP</cell><cell>0.99</cell><cell>0.90</cell><cell>0.96</cell><cell>0.99</cell></row><row><cell cols="2">MOT17-02-FRCNN 1.00</cell><cell>0.98</cell><cell>1.00</cell><cell>1.00</cell></row><row><cell cols="2">MOT17-04-FRCNN 1.00</cell><cell>0.97</cell><cell>0.99</cell><cell>1.00</cell></row><row><cell cols="2">MOT17-05-FRCNN 0.99</cell><cell>0.94</cell><cell>1.00</cell><cell>1.00</cell></row><row><cell cols="2">MOT17-09-FRCNN 0.99</cell><cell>0.97</cell><cell>0.98</cell><cell>1.00</cell></row><row><cell cols="2">MOT17-10-FRCNN 0.99</cell><cell>0.95</cell><cell>0.98</cell><cell>1.00</cell></row><row><cell cols="2">MOT17-11-FRCNN 1.00</cell><cell>0.99</cell><cell>0.99</cell><cell>1.00</cell></row><row><cell cols="2">MOT17-13-FRCNN 0.99</cell><cell>0.90</cell><cell>0.95</cell><cell>0.99</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"> <ref type="table">Table 5</ref><p>. We provide the results of our tracker Lif_T, evaluated per sequence. In addition, we provide the time necessary to solve the corresponding lifted disjoint path problem instance (STime), in seconds. Arrows indicate whether low or high metric values are better.</p><p>Tracking results on the test sets were evaluated by the MOTChallenge server https://www.motchallenge.net</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">of Computer Vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">K</forename><surname>Ahuja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Magnanti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Orlin</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11263-019-01231-y</idno>
		<ptr target="https://doi.org/10.1007/s11263-019-01231-y" />
		<editor>Alfred P. Sloan School of Management</editor>
		<imprint>
			<date type="published" when="1988-10" />
			<pubPlace>Cambridge, Mass; Massachusetts</pubPlace>
		</imprint>
	</monogr>
	<note>Network flows</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Efficient decomposition of image and mesh graphs by lifted multicuts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Keuper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Levinkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Bonneel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lavou√©</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andres</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename></persName>
		</author>
		<idno>doi: 10.1109/ ICCV.2015.204</idno>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">A multi-cut formulation for joint segmentation and tracking of multiple objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Keuper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhongjie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Andres</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.06317</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Motion segmentation &amp; multiple object tracking by correlation co-clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Keuper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Andres</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="140" to="153" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Instancecut: from edges to instances with multicut</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kirillov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Levinkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Andres</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Savchynskyy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rother</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5008" to="5017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Minimum-cost flow algorithms: an experimental evaluation. Optimization Methods and Software</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kov√°cs</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="94" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Multiple object tracking by efficient graph partitioning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Charpiat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Thonnat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asian Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="445" to="460" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Branchand-price global optimization for multi-view multi-target tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Leal-Taix√©</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Pons-Moll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Rosenhahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1987" to="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Leal-Taix√©</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Milan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Schindler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Motchallenge</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1504.01942</idno>
		<idno>arXiv: 1504.01942</idno>
		<ptr target="http://arxiv.org/abs/1504.01942" />
		<title level="m">Towards a benchmark for multitarget tracking</title>
		<imprint>
			<date type="published" when="2015-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Joint graph decomposition &amp; node labeling: Problem, algorithms, applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Levinkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uhrig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Omran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Insafutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kirillov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rother</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andres</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6012" to="6020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Learning to associate: Hybridboosted multi-target tracker for crowded scene</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Nevatia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="2953" to="2960" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Customized multi-person tracker</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asian Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="612" to="628" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Milan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Leal-Taix√©</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Schindler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mot16</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.00831</idno>
		<idno>arXiv: 1603.00831</idno>
		<ptr target="http://arxiv.org/abs/1603.00831" />
		<title level="m">A benchmark for multi-object tracking</title>
		<imprint>
			<date type="published" when="2016-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Global interactions in random field models: A potential function ensuring connectedness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nowozin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Lampert</surname></persName>
		</author>
		<idno type="DOI">10.1137/090752614</idno>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Imaging Sciences</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1048" to="1074" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Efficient algorithms for moral lineage tracing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rempfler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-H</forename><surname>Lange</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Jug</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Blasse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">W</forename><surname>Myers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">H</forename><surname>Menze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andres</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4695" to="4704" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Tracking multiple people online and in real time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ristani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tomasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asian Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="444" to="459" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Features for multi-target multicamera tracking and re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ristani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tomasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="6036" to="6046" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Performance measures and a data set for multi-target, multi-camera tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ristani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Solera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cucchiara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tomasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision Workshop on Benchmarking Multi-Target Tracking</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Tracking the untrackable: Learning to track multiple cues with longterm dependencies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Alahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="300" to="311" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Heterogeneous association graph fusion for target association in multiple object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Circuits and Systems for Video Technology</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="3269" to="3280" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Disjoint paths in a network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Suurballe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Networks</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="125" to="145" />
			<date type="published" when="1974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Subgraph decomposition for multi-target tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Andres</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Andriluka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="5033" to="5041" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Multiperson tracking by multicut and deep matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Andres</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Andriluka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="100" to="111" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
