<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Joint Object Detection and Multi-Object Tracking with Graph Neural Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kris</forename><surname>Kitani</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinshuo</forename><surname>Weng</surname></persName>
						</author>
						<title level="a" type="main">Joint Object Detection and Multi-Object Tracking with Graph Neural Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T07:02+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Object detection and data association are critical components in multi-object tracking (MOT) systems. Despite the fact that the two components are dependent on each other, prior works often design detection and data association modules separately which are trained with separate objectives. As a result, one cannot back-propagate the gradients and optimize the entire MOT system, which leads to sub-optimal performance. To address this issue, recent works simultaneously optimize detection and data association modules under a joint MOT framework, which has shown improved performance in both modules. In this work, we propose a new instance of joint MOT approach based on Graph Neural Networks (GNNs). The key idea is that GNNs can model relations between variablesized objects in both the spatial and temporal domains, which is essential for learning discriminative features for detection and data association. Through extensive experiments on the MOT15/16/17/20 datasets, we demonstrate the effectiveness of our GNN-based joint MOT approach and show state-of-the-art performance for both detection and MOT tasks. Our code is available at: https://github.com/yongxinw/GSDT.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Object detection <ref type="bibr" target="#b0">[1]</ref>- <ref type="bibr" target="#b7">[8]</ref> and data association <ref type="bibr" target="#b8">[9]</ref>- <ref type="bibr" target="#b15">[16]</ref> are two components of multi-object tracking (MOT), which is essential to perception in robotic systems such as autonomous driving <ref type="bibr" target="#b16">[17]</ref>- <ref type="bibr" target="#b20">[21]</ref>. Prior work <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b13">[14]</ref> often approaches MOT in an online fashion using a tracking-by-detection pipeline, where a detector outputs detections followed by a data association module matching the detections with past tracklets to form new tracklets up to the current frame. Oftentimes, the detector and data association modules are trained separately in prior work. However, with this separate optimization procedure, we cannot back-propagate errors through the entire MOT system. In other words, each module is optimized only towards its own local optimum, but not towards the objective of MOT. As a result, this separate optimization procedure used in prior work often yields suboptimal performance.</p><p>To improve performance, we investigate 1) joint optimization of object detection and data association, which we refer to as the joint MOT framework; 2) within the joint MOT framework, how to learn more discriminative features. First, to address the joint MOT problem, prior work <ref type="bibr" target="#b21">[22]</ref>- <ref type="bibr" target="#b30">[31]</ref> has explored different directions. <ref type="bibr" target="#b21">[22]</ref>- <ref type="bibr" target="#b24">[25]</ref> proposed to unify object detector with a model-free single-object tracker, where the tracker directly regresses the location of each object detected in the previous frame to the current frame. As each object is tracked independently, the data association problem is naturally resolved. <ref type="bibr" target="#b25">[26]</ref>- <ref type="bibr" target="#b28">[29]</ref> proposed to extend an object detector by adding a re-identification (Re-ID) <ref type="bibr" target="#b31">[32]</ref>  Prior work leverages object-object relations but only adopts it for data association. By using off-the-shelf detections that cannot be optimized jointly, such disjoint MOT paradigm can lead to sub-optimal MOT performance. (Bottom): Our method leverages spatial-temporal object relations for both detection and data association under a joint MOT framework. or ID verification branch which extracts features of objects for matching across frames. Also, <ref type="bibr" target="#b29">[30]</ref>, <ref type="bibr" target="#b30">[31]</ref> proposed an anchor tube. Different from anchor box used in anchor-based detectors, anchor tube represents a sequence of bounding boxes in a list of frames (one box per frame). Given video clips as inputs, true positive tubes can be found and used as tracklet outputs, which solves the joint MOT problem in a single shot.</p><p>Although prior joint MOT methods achieved impressive performance, we observed that the feature extracted for individual object/tracklet/tube is independent of one another and object-object relations are ignored. We argue that such object relations are useful to both object detection and data association. For example, for object detection in MOT, if related objects (e.g., two pedestrians that walk together) cooccur in the last frame, it is likely that they will also co-occur in the current frame at a nearby location. For data association, if the similarity score of two objects across frames increases with a high confidence (i.e., it is likely that these two objects have the same identity), then the similarity score between any of these two objects and other objects should be suppressed to avoid confusion in data association. As a result, to achieve better performance for the joint MOT framework, we should design our method to leverage object-object relations. While recent works <ref type="bibr" target="#b32">[33]</ref>- <ref type="bibr" target="#b34">[35]</ref> have exploited object-object relations in data association, they are limited to disjoint MOT where the detector is optimized separately. Therefore, the object relations are not used for the detector which is sub-optimal.</p><p>To deal with the above issue, we propose a new instance of joint MOT approach that can model object-object relations for both object detection and data association. Specifically, to obtain more discriminative features, we use Graph Neural Networks (GNNs) to exploit object-object relations. Then, the obtained features that consider object relations are used for both tasks of detection and data association. With GNNs, the feature extracted for each object is not isolated anymore, but instead can be adapted via features of its related objects in both spatial and temporal domains. To the best of our knowledge, our work is the first to model object relations via GNNs in the joint MOT framework. Our work overcomes the limit of prior work that 1) can perform joint MOT while ignoring object relations, or 2) can model object relations in association but cannot address joint MOT and use object relations to improve detection. Through experiments on MOTChallenges, we show S.O.T.A. performance on MOT15/20 and competitive performance on MOT16/17 datasets. Our contributions are summarized as follows.</p><p>1) A joint MOT approach that models object relations via GNNs to improve both detection and data association; 2) Strong empirical performance on <ref type="bibr">MOT 15/16/17/20</ref> datasets for both detection and MOT tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORKS</head><p>Object Detection. There have been tremendous advancements in image-based detection since large datasets such as COCO <ref type="bibr" target="#b35">[36]</ref> have been introduced. In past few years, anchorbased object detectors <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b36">[37]</ref>, <ref type="bibr" target="#b37">[38]</ref> have been dominant in the field of object detection. Recently, a new type of detector that models objects as points has been proposed <ref type="bibr" target="#b38">[39]</ref>, <ref type="bibr" target="#b39">[40]</ref> and achieved impressive performance. However, image-based methods suffer from unstable detections across frames as they use a single image as input. To deal with the issue, video detection <ref type="bibr" target="#b40">[41]</ref>- <ref type="bibr" target="#b42">[43]</ref> has been investigated which uses multiple frames as inputs. Although producing more temporally-consistent detections than image-based methods, existing video-based methods cannot model object relations. Similar to video-based detection methods, our joint MOT method also takes multiple frames as inputs to obtain detections. However, our difference is that, in additional to leveraging multiple frames of input, we also model object relations via GNNs, which can further improve detection performance when the objects across consecutive frames are highly related to one another. (e.g., object co-occurring.</p><p>Multi-Object Tracking. Recent MOT work primarily focuses on data association component in the tracking-bydetection pipeline, which can be split into online and batch methods. Online methods <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b43">[44]</ref>, <ref type="bibr" target="#b44">[45]</ref> only require information up to the current frame for data association and can be useful to online applications. On the other hand, batch methods <ref type="bibr" target="#b45">[46]</ref>- <ref type="bibr" target="#b50">[51]</ref> need to have access to global information (i.e., information up to the current frame plus information from future frames), which can theoretically achieve higher accuracy than online methods but are not applicable to online scenarios. We restrict the scope of this paper to online methods. Different from prior online methods that use offthe-shelf detections and only focus on the data association component, our method jointly optimizes detection and data association with an additional GNN module for object-object relation modeling which improves performance in both tasks.</p><p>Joint Detection and Data Association. To enable gradient back-propagation in the joint MOT framework and improve overall performance, <ref type="bibr" target="#b21">[22]</ref>- <ref type="bibr" target="#b30">[31]</ref> attempted to jointly optimize detection and data association for MOT. As introduced before, prior joint MOT methods can be mostly split into three categories: 1) unify a single-object tracker with an object detector; 2) add a Re-ID branch to object detection network; 3) use anchor tube representation for one-shot joint MOT. For example, <ref type="bibr" target="#b23">[24]</ref> builds on top of Faster-RCNN <ref type="bibr" target="#b1">[2]</ref> and makes its bounding box regression head multi-purpose, i.e., not only to refine the detected bounding boxes but also to serve as a single object tracker that regresses the object location from the previous frame to the current frame. Our method shares a similar spirit with prior joint MOT methods but goes beyond them by modeling spatial-temporal object relations. We show that our method can improve performance for both object detection and data association tasks in MOT.</p><p>Graph Neural Networks for Relation Modeling. GNNs were first introduced by <ref type="bibr" target="#b51">[52]</ref> to process data with a graph structure using neural networks. The key idea is to construct a graph with nodes and edges relating each other and update node/edge features based on relations, i.e., a process called node feature aggregation. In recent years, different GNNs (e.g., GraphConv <ref type="bibr" target="#b52">[53]</ref>, GCN <ref type="bibr" target="#b53">[54]</ref>, GAT <ref type="bibr" target="#b54">[55]</ref>, etc) have been proposed each with a unique feature aggregation rule which are shown to be effective on various tasks. Specifically for MOT, recent work <ref type="bibr" target="#b32">[33]</ref>- <ref type="bibr" target="#b34">[35]</ref>, <ref type="bibr" target="#b55">[56]</ref> formulates data association as an edge classification problem using GNNs, where each node represents an object and each edge relating two nodes denotes the similarity between detection and tracklets.</p><p>These approaches use GNNs to update node features via object relation modeling and have shown improved MOT performance. As opposed to these methods that focus only on using GNNs to improve data association, our work uses GNNs for joint detection and association, where the detection branch also benefits from the GNN relation modeling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. APPROACH</head><p>We follow online MOT methodology. Given images F t−1 , F t at frame t-1, t and tracklets at frame t-1, denoted as</p><formula xml:id="formula_0">T t−1 ={T 1 t−1 , T 2 t−1 , ..., T Pt−1 t−1 } as inputs, we aim to detect objects D t = {D 1 t , D 2 t , ..., D Kt t } in F t ,</formula><p>and associate them to tracklets T t−1 , where K t and P t−1 are number of detections and tracklets which can vary across frames. By associating detections to past tracklets, we can determine whether to extend or terminate an existing tracklet or to initiate a new tracklet at frame t. We perform this process iteratively at every frame to obtain the tracklets of the entire video.</p><p>To simultaneously detect and associate objects for MOT, we integrate a detector and a Re-ID module in our model. However, doing so alone does not leverage spatial-temporal object relations. Therefore, we use GNNs to extract relations between objects and learn better features to improve both detection and data association. For illustration, we show the  We first extract featuresM 0 t−1 ,M 0 t from images Ft and F t−1 using a shared backbone. To obtain feature of each tracklet in T t−1 , we use RoIAlign to crop feature from the image featureM 0 t−1 given the tracklets' boxes (red boxes inM 0 t−1 ). To obtain features of potential detections, we use feature of every pixel inM 0 t . To construct a graph with manageable number of edges, we only define edges between features of potential detections to tracklets if their spatial distances are within a window (grey boxes inM 0 t ). With the constructed graph, we use 3-layer GNNs to update features of tracklets and potential detections via node feature aggregation. A detection and data association head is applied to every layer of GNNs to obtain final detections and matching. proposed network architecture in <ref type="figure" target="#fig_2">Fig. 2</ref>, which contains four modules: feature extraction (Sec. III-A), node feature aggregation (Sec. III-C), detection (Sec. III-A) and association (Sec. III-B). As we use GNNs for Simultaneous Detection and Tracking, we abbreviate our method as GSDT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Feature Extraction and Object Detection</head><p>Given two input images F t−1 and F t , we first use a shared DLA-34 backbone <ref type="bibr" target="#b56">[57]</ref> to extract feature maps at two frameŝ <ref type="figure" target="#fig_2">Fig. 2</ref> (a) left, where r is the downsample ratio, W /H are width and heights of the images, and C is the number of channels. Both image featuresM 0 t−1 ,M 0 t will be used in the following relation modeling, object detection and data association modules. Also, for the image feature at frame t, we will update it at the lth layer of GNNs to obtainM l t (Sec. III-C). For object detection, we follow CenterNet <ref type="bibr" target="#b57">[58]</ref> and detect each object by finding its center coordinate (x, y) and width/height (w, h). As we only perform detection in the frame t, we feedM l t to three heads (location, box size and refinement heads) as shown in <ref type="figure" target="#fig_2">Fig. 2 (b)</ref>, which provides three maps, i.e., a location mapM l L ∈ R Training. To train three detection heads and back-propagate the gradients through the entire network, we need to construct ground truth (GT) for each map and apply loss functions. For GT location map M l L ∈ R W r × H r , we use a Gaussian heatmap where the peaks occupy the locations of GT objects. Specifically, the value at the location (i, j) is: <ref type="bibr" target="#b0">(1)</ref> where N is number of GT objects and (x k , y k ) is the center coordinate of GT object k, and · is a floor function. The standard deviation σ k scales with the GT box size (w k , h k ) <ref type="bibr" target="#b39">[40]</ref>. For GT box size and refinement maps M l S , M l R , if there exists a GT object center at location (i, j), then:</p><formula xml:id="formula_1">M 0 t−1 ,M 0 t ∈ R W r × H r ×C as shown in</formula><formula xml:id="formula_2">M l L (i, j) = N k=1 exp (− (i− x k r ) 2 +(j− y k r ) 2 2σ 2 k ),</formula><formula xml:id="formula_3">M l S (i, j, :) = (w, h),<label>(2)</label></formula><formula xml:id="formula_4">M l R (i, j, :) = ( x r − x r , y r − y r ).<label>(3)</label></formula><p>After we construct the GT for three maps, we use focal loss for the location map L l loc , and L1 loss for the size map L l size and refinement map L l ref .</p><p>Note that for size/refinement maps, their losses are only applied to locations with GT objects. The overall loss for detection is then:</p><formula xml:id="formula_5">L l det = λ 1 L l loc + λ 2 L l size + λ 3 L l ref ,<label>(4)</label></formula><p>where we empirically found λ 1 = λ 3 = 1, λ 2 = 0.1 could achieve a well balance between each individual loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Data Association</head><p>To match detections with tracklets, we add an additional embedding head as shown in <ref type="figure" target="#fig_2">Fig. 2 (b)</ref> to learn an identity embedding for each potential detection, i.e., every pixel in M l t . These identity embeddings are used to compute similarity between every pair of tracklet and potential detection during testing, where the identity embeddings of tracklets are cached when they are detected in the previous frame. Specifically, givenM l t as inputs, our embedding head outputs an embedding mapM l E ∈ R W r × H r ×D , where D denotes the embedding dimension and each pixel inM l E has an embedding for a potential detection centered at this pixel. Training. To optimize our embedding head, we further use embedding at each pixel of the embedding mapM l E as input, and predict its identity vectorp, the ith entry of which represents the probability of this pixel has an object identity of i. Also, we will need the GT identity vector p for training, which is a one-hot vector of length M (M is the number of object identities in the target dataset). Note that in the GT identity vector p, only the GT identity index is filled with 1 while all other indexes are 0s. Similar as before, we only supervise our embedding mapM l E at pixels where there exists a GT object using a cross-entropy loss as follows:</p><formula xml:id="formula_6">L l emb = 1 N N k=1 M m=1 p k (m)log(p k (m)). (5)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Graph Neural Networks for Relation Modeling</head><p>As detection and data association modules alone overlook spatial-temporal relations between tracklets and detections, we use GNNs to further leverage such relation information and obtain better features for joint MOT. Graph Construction. To perform graph feature learning, we need to construct a graph G(V, E) with nodes V being features of detections and tracklets. For features of tracklets, we can easily obtain them as tracklets' boxes are given as inputs. Specifically, we crop tracklet features from the image featureM 0 t−1 using the RoIAlign <ref type="bibr" target="#b37">[38]</ref> operator. However, it is relatively non-trivial to obtain features of detections. This is because objects have not been detected inM l t so we do not have their locations to crop features fromM l t . To overcome this issue, we use feature at every pixel ofM l t to represent a potential detection, resulting in W r × H r detection nodes. This design choice is made because we believe thatM l t contains enough information about detections, as all three detection heads are branched fromM l t . In addition to node construction, we also need the set of edges E. A simple solution is to define an edge between every pair of nodes, resulting in a fully-connected graph. However, such a graph with massive number of edges can be computationally expensive and sometimes impractical when the number of tracklets and potential detections (i.e., number of pixels inM l t ) are too large. Instead, we take advantage of domain knowledge in MOT: (a) data association only happens across frames (not in the same frame); (b) displacement of the same object is often small across frames. According to (a), we only define edges between tracklet nodes and detection nodes. Based on (b), for every tracklet node, we only connect it to detection nodes that are in nearby locations, i.e., within a s × s spatial window centered at the tracklet location in F t−1 . We use s = 15 in our model which balances computation and performance. We illustrate the idea of edge construction in <ref type="figure" target="#fig_2">Fig. 2</ref>, where grey boxes onM l t enclose the pixels (detection nodes) that have edges with tracklets. Node Feature Aggregation. The key idea of our method is using GNNs to model object-object relations and improve feature learning for both detection and data association. To that end, we iteratively update node features by aggregating features from its neighborhood nodes connected with edges. In this way, information can propagate through the graph and nodes are allowed to interact. So the question is how exactly we should perform the node feature aggregation?</p><p>Recently, there are many GNNs proposed, e.g., GraphConv <ref type="bibr" target="#b52">[53]</ref>, AGNNConv <ref type="bibr" target="#b58">[59]</ref>, EdgeConv <ref type="bibr" target="#b59">[60]</ref>, each with a different node aggregation rule. To explore how different GNNs affect our joint MOT method, we try five popular GNNs in our model in the ablation study and compare their performance. Our final model uses GraphConv as it provides the best empirical performance. Specifically, GraphConv updates node features using the following rule:</p><formula xml:id="formula_7">h i l = ρ 1 (h i l−1 ) + j∈N (i) ρ 2 (h j l−1 ),<label>(6)</label></formula><p>where h i l represents the feature of node i at GNN layer l, N (i) defines neighborhood of node i, and ρ 1 , ρ 2 are linear layers. Note that, for detection nodes that have no edge to any tracklets, the second term in Eq. 6 disappears, and these potential detection nodes are only used for discovering new objects in frame t (not having corresponding tracklet in frame t-1). Also, one might argue that, as our edges are only defined across frames, object-object relations are only modeled in the temporal domain for data association but not in the spatial domain for object detection, i.e., nodes within the same frame cannot interact. This is true if we only have a single layer of GNNs. In the case we use more than one layer, the information can be propagated back and forth, enabling spatial-temporal object relation modeling. For example, in the first layer, the feature of a detection node i 1 is aggregated to a tracklet node j. Then in the second layer, the feature of the tracklet node j is propagated to a different detection node i 2 , i.e., part of the node feature i 1 is propagated to the detection node i 2 which enables spatial relation modeling in the same frame. In ablation study, we will explore how the number of GNN layers will affect performance of our model. In our best model, we use three layers of GNNs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Joint Detection and Association with GNNs</head><p>Although the detection and association heads introduced in Sec. III-A and III-B can solve joint detection and data association problem by training two modules together, they do not leverage object relations if they only use features from M 0 t−1 ,M 0 t . As shown in <ref type="figure" target="#fig_2">Fig. 2</ref>, to leverage GNNs, we apply the detection and association head also to features obtained in GNN layer 1, 2, etc, which have better features after node feature aggregation by encoding relations. To summarize, the overall loss of our network is a summation of detection and data association losses over all layers of GNNs:</p><formula xml:id="formula_8">L total = l η 1 L l det + η 2 L l emb ,<label>(7)</label></formula><p>where l is the index of GNN layers and η 1 , η 2 denote weights of each loss. We adopt an automatic loss weighting scheme as in <ref type="bibr" target="#b60">[61]</ref> to balance η 1 and η 2 . We refer our readers to <ref type="bibr" target="#b60">[61]</ref> for details about this automatic loss weighting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Inference and Tracking Management</head><p>At test time, we iteratively detect objects and associate them to existing tracklets. At every frame, we first obtain estimated detections D t in F t by post processingM l L ,M l S , andM l R followed by non-maximal suppression. Also, we obtain identity embeddings fromM l E at pixels where objects are detected, which provides us identity embeddings of detections D t . The identity embeddings for T t−1 are cached when they are detected in the previous frame so they are also available. We use these embeddings to compute affinity matrixŜ where each entry represents the similarity between every pair of tracklet and detection. We then feedŜ to the Hungarian Algorithm <ref type="bibr" target="#b61">[62]</ref> to find the best matches between D t and T t−1 . For each detection that is not matched to any tracklets, we use it to initialize a new tracklet if its detection confidence score is higher than 0.4. For unmatched tracklets, they might either exit the scene or be still in the scene but not detected. To avoid terminating tracklets that are still in the scene, we use the Kalman filter <ref type="bibr" target="#b62">[63]</ref> to extend the unmatched tracklets for τ term frames, while keep trying to match these tracklets with detections in following frames. If after τ term frames an unmatched tracklet still cannot be matched to any new detection, we terminate this tracklet. Empirically, we found τ term = 30 works well in our model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTS</head><p>Datasets. We evaluate our method on MOTChallenges <ref type="bibr" target="#b63">[64]</ref>- <ref type="bibr" target="#b66">[67]</ref>, including the 2DMOT15/MOT16/MOT17/MOT20 benchmarks. These datasets have two tracks: public and private, where the public track asks methods to use off-theshelf detections provided by the datasets while methods in the private track can use their own detections. As we jointly detect and track objects (not using off-the-shelf detections for disjoint MOT), it is straightforward to evaluate our method in private track. For a fair comparison with prior work, we evaluate on the test set by submitting our results to the MOT test server. Evaluation Metrics. For MOT, we use standard CLEAR MOT metrics <ref type="bibr" target="#b67">[68]</ref> and IDF1 metric <ref type="bibr" target="#b68">[69]</ref>. For object detection, we report the Average Precision (AP) using official MOT17Det and MOT20Det evaluation protocol. Implementation Details. We use an Adam optimizer with an initial learning rate of 1e −4 decaying by a factor of 0.1 at epoch 20 and 27. We train the network for a total of 30 epochs with a batch size of 16. Following TR-MOT <ref type="bibr" target="#b26">[27]</ref>, we use a mix of six pedestrian detection datasets for pre-training, including CalTech <ref type="bibr" target="#b69">[70]</ref>, MOT17 <ref type="bibr" target="#b64">[65]</ref>, CUHK-SYSU <ref type="bibr" target="#b31">[32]</ref>, ETH <ref type="bibr" target="#b70">[71]</ref>, PRW <ref type="bibr" target="#b71">[72]</ref>, and CityPersons <ref type="bibr" target="#b72">[73]</ref>. Same as <ref type="bibr" target="#b26">[27]</ref>, we removed a few sequences in the above six datasets which overlap with MOT test set to avoid training with test data, for the sake of fair comparison.</p><p>Evaluating Multi-Object Tracking. We summarize results on the MOTChallenges for ours and published methods in <ref type="table" target="#tab_1">Table I</ref>, marking the best, second best, and third best. Across most metrics (e.g., primary metrics MOTA and IDF1), we achieve the best performance on all 2DMOT2015/MOT16/MOT17/MOT20 datasets among published methods. As the MOTA metric emphasizes more on detection side, we believe our strong MOTA performance shows that our detector is stronger than prior methods. Also, our strong IDF1 performance suggests that our method is able to produce temporally-consistent tracklets due to the spatial-temporal relation modeling via GNNs. Moreover, when comparing with prior joint MOT methods without modeling object relations such as <ref type="bibr" target="#b21">[22]</ref>, [30], our method achieves better performance as shown in 2DMOT15/MOT16/MOT17 benchmarks, suggesting that adding object relation modeling is useful in joint MOT. When comparing with prior disjoint MOT methods with relation modeling for data association such as <ref type="bibr" target="#b33">[34]</ref>, our method also performs better across all benchmarks, suggesting that only modeling object relations in data association is not enough, and that it is useful to model object relations in object detection as well. All these results confirm our hypothesis that modeling object relations in the joint MOT framework can lead to better performance. Note that all numbers in <ref type="table" target="#tab_1">Table I</ref> are updated from the official leaderboard by 2021/03/22. To visually verify our results, we also provide qualitative results  of our method in <ref type="figure" target="#fig_4">Fig. 3</ref> Evaluating Object Detection. We compare our method with published methods in <ref type="table" target="#tab_1">Table II</ref>. We observed that our detector outperforms prior methods in most of the metrics. We highlight that we achieve a higher Average Precision than most of the prior methods, which could be attributed to our use of GNNs that makes it easier to find existing objects and harder to generate false positives by exploiting object relation information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. ABLATION STUDY</head><p>We conduct ablation study on the 2DMOT2015 validation set, removing sequences overlapping with our training set. Effect of GNNs. To answer the question on whether adding a GNN module is useful, we train our model with {1,2,3}layer/no GNNs. The results are shown in <ref type="table" target="#tab_1">Table III</ref>. When comparing 1-layer/no GNNs model, we see clear improvements in primary metrics MOTA and IDF1, which shows the usefulness of GNNs in the task of MOT. Also, with GNNs, we see a clear decrease in IDS comparing to the no-GNN model, which suggests that GNNs help learn more discriminative features and reduce confusion in data association. Moreover, when comparing {1,2,3}-layer GNNs model, we see further improvements in MOTA but lower numbers in IDF1, especially 2-layer model. We hypothesize that adding more layers might have made our model emphasize more on detection but less on temporally-consistent tracking. How to balance the task of detection and data association during the joint MOT learning can be a very interesting research topic in the future. Note that we use AGNNConv <ref type="bibr" target="#b58">[59]</ref> in this ablation study and we do not explore more than 3 GNN layers as GPU memory is not enough to fit our model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUSIONS</head><p>We proposed a new instance of joint MOT approach that simultaneously optimizes object detection and data association modules. Moreover, to model spatial-temporal object relations, we used GNNs to learn more discriminative features that benefit both detection and data association. Through extensive experiments, we showed effectiveness of GNNs under the joint MOT framework and achieved stateof-the-art performance on the MOT challenges. Our code will be released so that future follow-up work can easily build on top of our method to advance the state-of-the-art.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>(Top left): Although jointly training detection and data association, prior work does not take into account object-object relations. (Top right):</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>(a) Overview of the Proposed Network.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>(b) Detection and Data Association: The location, box size, and refinement heads generatê M l L ,M l S , andM l R which are used to obtain detections. The embedding head generatesM l E to compute identity embedding for data association. (c) Node Feature Aggregation. The mixed color illustrates that features from tracklets and potential detections affect each other via relation modeling.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 3 .</head><label>3</label><figDesc>Visualization of our detection and tracking results on two sequences of the MOT17 test set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>refines rough coordinates to be precise. Note that these three detection heads can operate on any GNN layer l.</figDesc><table><row><cell>W r × H r , a size map</cell></row><row><cell>M l S ∈ R As the names suggest,M l W r × H r ×2 , and a refinement mapM l R ∈ R L provides rough estimates of object W r × H r ×2 . center coordinates,M l S gives estimated widths and heights, andM l R</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE I MOT</head><label>I</label><figDesc>EVALUATION ON 2DMOT2015/MOT16/MOT17/MOT20 TEST SETS AS OF 2021/03/22 (PUBLISHED METHODS ONLY).</figDesc><table><row><cell></cell><cell>Method</cell><cell cols="5">MOTA(%)↑ IDF1(%)↑ MT(%)↑ ML(%)↓ IDS↓</cell></row><row><cell></cell><cell>DMT [22]</cell><cell></cell><cell>44.5</cell><cell>49.2</cell><cell>34.7</cell><cell>22.1 684</cell></row><row><cell></cell><cell>Tracktor++V2 [24]</cell><cell></cell><cell>46.6</cell><cell>47.6</cell><cell>18.2</cell><cell>27.9 1,290</cell></row><row><cell>2DMOT2015</cell><cell>MDP SubCNN [9] CDA DDAL [74] MPNTrack [34] Lif T [75] EAMTT [76] AP HWDPL [77]</cell><cell></cell><cell>47.5 51.3 51.5 52.5 53.0 53.0</cell><cell>55.7 54.1 58.6 60.0 54.0 52.0</cell><cell>30.0 36.3 31.2 33.8 35.9 29.1</cell><cell>18.6 628 22.2 544 25.9 375 25.8 1,047 19.6 776 20.2 708</cell></row><row><cell></cell><cell>NOMTwSDP [78]</cell><cell></cell><cell>55.5</cell><cell>59.1</cell><cell>39.0</cell><cell>25.8 427</cell></row><row><cell></cell><cell>RAR15 [79]</cell><cell></cell><cell>56.5</cell><cell>61.3</cell><cell>45.1</cell><cell>14.6 428</cell></row><row><cell></cell><cell>Tube TK [30]</cell><cell></cell><cell>58.4</cell><cell>53.1</cell><cell>39.3</cell><cell>18.0 854</cell></row><row><cell></cell><cell>GSDT (Ours)</cell><cell></cell><cell>60.7</cell><cell>64.6</cell><cell>47.0</cell><cell>10.5 480</cell></row><row><cell></cell><cell>MPNTrack [34]</cell><cell></cell><cell>58.6</cell><cell>61.7</cell><cell>27.3</cell><cell>34.0 354</cell></row><row><cell></cell><cell>Lif T [75]</cell><cell></cell><cell>61.3</cell><cell>64.7</cell><cell>27.0</cell><cell>34.0 389</cell></row><row><cell></cell><cell>DeepSORT 2 [11]</cell><cell></cell><cell>61.4</cell><cell>62.2</cell><cell>32.8</cell><cell>18.2 1,423</cell></row><row><cell>MOT16</cell><cell cols="2">NOMTwSDP16 [78] VMaxx [80] RAR16wVGG [79] TAP [81]</cell><cell>62.2 62.6 63.0 64.8</cell><cell>62.6 49.2 63.8 73.5</cell><cell>32.5 32.7 39.9 38.5</cell><cell>31.1 406 21.1 1,389 22.1 482 21.6 571</cell></row><row><cell></cell><cell>CNNMTT [82]</cell><cell></cell><cell>65.2</cell><cell>62.2</cell><cell>32.5</cell><cell>21.3 946</cell></row><row><cell></cell><cell>POI [83]</cell><cell></cell><cell>66.1</cell><cell>65.1</cell><cell>34.0</cell><cell>20.8 3,093</cell></row><row><cell></cell><cell>Tube TK POI [30]</cell><cell></cell><cell>66.9</cell><cell>62.2</cell><cell>39.0</cell><cell>16.1 1,236</cell></row><row><cell></cell><cell>CTracker V1 [29]</cell><cell></cell><cell>67.6</cell><cell>57.2</cell><cell>32.9</cell><cell>23.1 1,897</cell></row><row><cell></cell><cell>GSDT (Ours)</cell><cell></cell><cell>74.5</cell><cell>68.1</cell><cell>41.2</cell><cell>17.3 1,229</cell></row><row><cell>MOT17</cell><cell>MPNTrack [34] Lif T [75] Tube TK [30] CTrackerV1 [29]</cell><cell></cell><cell>58.8 60.5 63.0 66.6</cell><cell>61.7 65.6 58.6 57.4</cell><cell>28.8 27.0 31.2 32.2</cell><cell>33.5 1,185 33.6 1,189 19.9 4,137 24.2 5,529</cell></row><row><cell></cell><cell>CTTrack17 [25]</cell><cell></cell><cell>67.8</cell><cell>64.7</cell><cell>34.6</cell><cell>24.6 3,039</cell></row><row><cell></cell><cell>GSDT (Ours)</cell><cell></cell><cell>73.2</cell><cell>66.5</cell><cell>41.7</cell><cell>17.5 3,891</cell></row><row><cell>MOT20</cell><cell>SORT20 [10] Tracktor++V2 [24] MPNTrack [34]</cell><cell></cell><cell>42.7 52.6 57.6</cell><cell>45.1 52.7 59.1</cell><cell>16.7 29.4 38.2</cell><cell>26.2 4,334 26.7 1,648 22.5 1,210</cell></row><row><cell></cell><cell>GSDT (Ours)</cell><cell></cell><cell>67.1</cell><cell>67.5</cell><cell>53.1</cell><cell>13.2 3,133</cell></row><row><cell></cell><cell></cell><cell></cell><cell>TABLE II</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="6">DETECTION EVALUATION ON MOT17DET/MOT20DET TEST SET.</cell></row><row><cell></cell><cell>Method</cell><cell cols="5">AP(%)↑ MODA(%)↑ Recall(%)↑ Precision(%)↑</cell></row><row><cell></cell><cell>DPM [84]</cell><cell>0.61</cell><cell cols="2">31.2</cell><cell>68.1</cell><cell>64.8</cell></row><row><cell>MOT17</cell><cell>FRCNN [2] ZIZOM [85] SDP [86] F ViPeD B [87]</cell><cell>0.72 0.81 0.81 0.89</cell><cell cols="2">68.5 72.0 76.9 -14.4</cell><cell>77.3 83.3 83.5 93.2</cell><cell>89.8 88.0 92.6 46.4</cell></row><row><cell></cell><cell>GSDT (Ours)</cell><cell>0.89</cell><cell cols="2">78.1</cell><cell>90.7</cell><cell>87.8</cell></row><row><cell>MOT20</cell><cell>ViPeD20 [87] GSDT (Ours)</cell><cell>0.80 0.81</cell><cell cols="2">46.0 79.3</cell><cell>86.5 88.6</cell><cell>68.1 90.6</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE III ABLATION</head><label>III</label><figDesc>STUDY ON EFFECTIVENESS OF GNNS.</figDesc><table><row><cell>Method</cell><cell cols="5">MOTA(%)↑ IDF1(%)↑ MT(%)↑ ML(%)↓ FP↓ FN↓ IDS↓</cell></row><row><cell>No GNNs</cell><cell>79.5</cell><cell>73.8</cell><cell>71.8</cell><cell cols="2">8.8 1,948 1,487 139</cell></row><row><cell>1-layer GNNs</cell><cell>81.6</cell><cell>77.4</cell><cell>66.3</cell><cell>13.5 1,394 1,733</cell><cell>68</cell></row><row><cell>2-layer GNNs</cell><cell>81.9</cell><cell>75.0</cell><cell>65.7</cell><cell>13.5 1,234 1,866</cell><cell>54</cell></row><row><cell>3-layer GNNs</cell><cell>82.1</cell><cell>76.4</cell><cell>65.4</cell><cell>12.6 1,281 1,793</cell><cell>71</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Fast R-CNN</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">ICCV</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">A MultiPath Network for Object Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zagoruyko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">O</forename><surname>Pinheiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">BMVC</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">You Only Look Once: Unified, Real-Time Object Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Redmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Divvala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Farhadi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Focal Loss for Dense Object Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Doll</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">R-FCN-3000 at 30fps: Decoupling Detection and Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Monocular 3D Object Detection with Pseudo-LiDAR Point Cloud</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kitani</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ICCVW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Bounding Box Regression with Uncertainty for Accurate Object Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Savvides</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Learning to Track: Online Multi-Object Tracking by Decision Making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Alahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">ICCV</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Simple Online and Realtime Tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bewley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ramos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Upcroft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICIP</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Simple Online and Realtime Tracking with a Deep Association Metric</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Wojke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bewley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Paulus</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Deep Network Flow for Multi-Object Tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Schulter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vernaza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chandraker</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Non-Markovian Globally Consistent Multi-Object Tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Maksai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Fleuret</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fua</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">3D Multi-Object Tracking: A Baseline and New Evaluation Metrics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Held</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kitani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IROS</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Multiple Object Tracking with Attention to Appearance, Structure, Motion and Size</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Karunasekera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">muSSP: Efficient Min-cost Flow Algorithm for Multi-object Tracking</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Fast and Furious: Real Time Endto-End 3D Detection, Tracking and Motion Forecasting with a Single Convolutional Net</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Deep Reinforcement Learning for Autonomous Driving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Weng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.11329</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">A Survey of Autonomous Driving: Common Practices and Emerging Technologies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yurtsever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lambert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Carballo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Takeda</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.05113</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Badue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Guidolini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">V</forename><surname>Carneiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Azevedo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">B</forename><surname>Cardoso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Forechi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jesus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Berriel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Paixão</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Mutz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Veronese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Oliveira-Santos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">F</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Souza</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.04407</idno>
		<title level="m">Self-Driving Cars: A Survey</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Inverting the Forecasting Pipeline with SPF2: Sequential Pointcloud Forecasting for Sequential Pose Forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kitani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Nick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CoRL</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">CDT: Cooperative Detection and Tracking for Tracing Multiple Objects in Video Sequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-U</forename><forename type="middle">K</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-S</forename><surname>Kim</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Detect to Track and Track to Detect</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Feichtenhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pinz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bergmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Meinhardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Leal-Taixe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Tracking without Bells and Whistles</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Tracking Objects as Points</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Koltun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Krähenbühl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">MOTS: Multi-Object Tracking and Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Voigtlaender</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Osep</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Luiten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">B G</forename><surname>Sekar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Leibe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Towards Real-Time Multi-Object Tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">FairMOT: On the Fairness of Detection and Re-Identification in Multiple Object Tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.01888</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Chained-Tracker: Chaining Paired Attentive Regression Results for End-to-End Joint Multiple-Object Detection and Tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">TubeTK: Adopting Tubes to Track Multi-Object in a One-Step Training Model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Simultaneous Detection and Tracking with Motion Modelling for Multiple Object Tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Akhtar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shah</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Joint Detection and Identification Feature Learning for Person Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Man</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kitani</surname></persName>
		</author>
		<title level="m">GNN3DMOT: Graph Neural Network for 3D Multi-Object Tracking with 2D-3D Multi-Feature Learning</title>
		<imprint>
			<publisher>CVPR</publisher>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Learning a Neural Solver for Multiple Object Tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Brasó</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Leal-Taixé</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Graph Networks for Multiple Object Tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Jiang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>WACV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Microsoft COCO: Common Objects in Context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">SSD: Single Shot MultiBox Detector</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gkioxari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Doll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mask R-CNN</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Objects as Points</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Krähenbühl</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.07850</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">CornerNet: Detecting Objects as Paired Keypoints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Law</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Towards High Performance Video Object Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">RST-MODNet: Real-time Spatio-temporal Moving Object Detection for Autonomous Driving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ramzy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Rashed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Sallab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yogamani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Video Object Detection with an Aligned Spatial-Temporal Memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">J</forename><surname>Lee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Frame-Wise Motion and Appearance for Real-time Multiple Object Tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Huang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">BMVC</note>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Online Multi-Object Tracking with Dual Matching Attention Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">H</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Continuous Energy Minimization for Multitarget Tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Milan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Schindler</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>TPAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Globally-Optimal Greedy Algorithms for Tracking a Variable Number of Objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pirsiavash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Fowlkes</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Multi-Person Tracking by Multicut and Deep Matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Andres</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Andriluka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>ECCVW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Multiobject Tracking as Maximum Weight Independent Set</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Brendel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Amer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Todorovic</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">GMMCP Tracker: Globally Optimal Generalized Maximum Multi Clique Problem for Multiple Object Tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dehghan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Assari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shah</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">GMCP-Tracker: Global Multi-Object Tracking Using Generalized Minimum Clique Graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zamir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dehghan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shah</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">A New Model for Learning in Graph Domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Monfardini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Scarselli</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
	<note type="report_type">IJCNN</note>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Weisfeiler and Leman Go Neural: Higher-Order Graph Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ritzert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Lenssen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Rattan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Grohe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>AAAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Semi-Supervised Classification with Graph Convolutional Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Graph Attention Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Veličković</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liò</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">ICLR</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">PTP: Parallelized Tracking and Prediction with Graph Neural Networks and Diversity Sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kitani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Robotics and Automation Letters</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Deep Layer Aggregation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">CenterNet: Keypoint Triplets for Object Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">ICCV</note>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Attention-based Graph Neural Network for Semi-supervised Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">K</forename><surname>Thekumparampil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<idno>1803.03735</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Dynamic Graph CNN for Learning on Point Clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">E</forename><surname>Sarma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Solomon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Multi-Task Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cipolla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kendall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">The Hungarian Method for the Assignment Problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kuhn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Naval Research Logistics Quarterly</title>
		<imprint>
			<date type="published" when="1955" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">A New Approach to Linear Filtering and Prediction Problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kalman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Basic Engineering</title>
		<imprint>
			<date type="published" when="1960" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Leal-Taixé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Milan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Schindler</surname></persName>
		</author>
		<title level="m">MOTChallenge 2015: Towards a Benchmark for Multi-Target Tracking</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">TPAMI</note>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">MOT16: A Benchmark for Multi-Object Tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Milan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Leal-Taixe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Schindler</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>TPAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dendorfer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Rezatofighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Milan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cremers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Schindler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Leal-Taixe</surname></persName>
		</author>
		<title level="m">CVPR19 Tracking and Detection Challenge: How crowded can it get?&quot; TPAMI</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">MOT20: A benchmark for multi object tracking in crowded scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dendorfer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Rezatofighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Milan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cremers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Schindler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Leal-Taixé</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.09003</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Evaluating Multiple Object Tracking Performance: The CLEAR MOT Metrics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bernardin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Stiefelhagen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Journal on Image and Video Processing</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">Performance Measures and a Data Set for Multi-Target, Multi-Camera Tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ristani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Solera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cucchiara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tomasi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>ECCVW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">Pedestrian detection: A benchmark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Doll Ar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wojek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<title level="m" type="main">A Mobile Vision System for Robust Multi-Person Tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Leibe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Schindler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<title level="m" type="main">Person Re-identification in the Wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chandraker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">CityPersons: A Diverse Dataset for Pedestrian Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Benenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title level="m" type="main">Confidence-based data association and discriminative deep appearance learning for robust online multi-object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yoon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>TPAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<title level="m" type="main">Lifted Disjoint Paths with Application in Multiple Object Tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hornakova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Henschel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Rosenhahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Swoboda</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">ICML</note>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<title level="m" type="main">Online Multi-Target Tracking with Strong and Weak Detections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sanchez-Matilla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Poiesi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cavallaro</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>ECCVW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<title level="m" type="main">Online multi-object tracking with convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bai</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Near-Online Multi-Target Tracking with Aggregated Local Flow Descriptor</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
		<title level="m" type="main">Recurrent Autoregressive Networks for Online Multi-Object Tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>WACV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Multi-Object Tracking Using Online Metric Learning with Long Short-Term Memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICIP</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<title level="m" type="main">Online Multi-Target Tracking with Tensor-Based High-Order Graph Matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">ICPR</note>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Mahmoudi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Ahadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename></persName>
		</author>
		<title level="m">Multi-Target Tracking Using CNN-Based Features: CNNMTT,&quot; Multimedia Tools and Applications</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<monogr>
		<title level="m" type="main">POI: Multiple Object Tracking with High Performance Detection and Appearance Feature</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>ECCVW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<monogr>
		<title level="m" type="main">Object Detection with Discriminatively Trained Part Based Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">F</forename><surname>Felzenszwalb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mcallester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>TPAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<monogr>
		<title level="m" type="main">Graininess-Aware Deep Feature Learning for Pedestrian Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<monogr>
		<title level="m" type="main">Exploit All the Layers: Fast and Accurate CNN Object Detector with Scale Dependent Pooling and Cascaded Rejection Classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Virtual to Real Adaptation of Pedestrian Detectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ciampi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Messina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Falchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gennaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Amato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
