<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Multiple Instance Active Learning for Object Detection</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianning</forename><surname>Yuan</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Fang Wan † *</roleName><forename type="first">Mengying</forename><surname>Fu</surname></persName>
							<email>fumengying19@mails.ucas.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianzhuang</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Noah&apos;s Ark Lab</orgName>
								<orgName type="institution">Huawei Technologies</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Songcen</forename><surname>Xu</surname></persName>
							<email>xusongcen@huawei.com</email>
							<affiliation key="aff1">
								<orgName type="laboratory">Noah&apos;s Ark Lab</orgName>
								<orgName type="institution">Huawei Technologies</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyang</forename><surname>Ji</surname></persName>
							<email>xyji@tsinghua.edu.cn</email>
							<affiliation key="aff2">
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qixiang</forename><surname>Ye</surname></persName>
							<email>qxye@ucas.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Multiple Instance Active Learning for Object Detection</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T17:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Despite the substantial progress of active learning for image recognition, there still lacks an instance-level active learning method specified for object detection. In this paper, we propose Multiple Instance Active Object Detection (MI-AOD), to select the most informative images for detector training by observing instance-level uncertainty. MI-AOD defines an instance uncertainty learning module, which leverages the discrepancy of two adversarial instance classifiers trained on the labeled set to predict instance uncertainty of the unlabeled set. MI-AOD treats unlabeled images as instance bags and feature anchors in images as instances, and estimates the image uncertainty by re-weighting instances in a multiple instance learning (MIL) fashion. Iterative instance uncertainty learning and re-weighting facilitate suppressing noisy instances, toward bridging the gap between instance uncertainty and imagelevel uncertainty. Experiments validate that MI-AOD sets a solid baseline for instance-level active learning. On commonly used object detection datasets, MI-AOD outperforms state-of-the-art methods with significant margins, particularly when the labeled sets are small. Code is available at https://github.com/yuantn/MI-AOD.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The key idea of active learning is that a machine learning algorithm can achieve better performance with fewer training samples if it is allowed to select which to learn. Despite the rapid progress of the methods with less supervision <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b19">20]</ref>, e.g., weak supervision and semi-supervision, * Corresponding Authors.  active learning remains the cornerstone of many practical applications for its simplicity and higher performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Image Uncertainty</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reweighting</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MI-AOD Detector</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Instances with Re-weighted Uncertainty</head><p>In the computer vision area, active learning has been widely explored for image classification (active image classification) by empirically generalizing the model trained on the labeled set to the unlabeled set <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b33">34]</ref>. Uncertainty-based methods define various metrics for selecting informative images and adapting trained models to the unlabeled set <ref type="bibr" target="#b8">[9]</ref>. Distribution-based approaches <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b0">1]</ref> aim at estimating the layout of unlabeled images to select samples of large diversity. Expected model change methods <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b14">15]</ref> find out samples that can cause the greatest change of model parameters or the largest loss <ref type="bibr" target="#b41">[42]</ref>.</p><p>Despite the substantial progress, there still lacks an instance-level active learning method specified for object detection (i.e., active object detection <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b1">2]</ref>), where the instance denotes the object proposal in an image. The objective goal of active object detection is to select the most informative images for detector training. However, the recent methods tackled it by simply summarizing/averaging instance/pixel uncertainty as image uncertainty and unfortunately ignored the large imbalance of negative instances in object detection, which causes significant noisy instances in the background and interferes with the learning of image uncertainty, <ref type="figure" target="#fig_1">Fig. 1(a)</ref>. The noisy instances also cause the inconsistency between image and instance uncertainty, which hinders selecting informative images.</p><p>In this paper, we propose a Multiple Instance Active Object Detection (MI-AOD) approach, <ref type="figure" target="#fig_1">Fig. 1(b)</ref>, and target at selecting informative images from the unlabeled set by learning and re-weighting instance uncertainty with discrepancy learning and multiple instance learning (MIL). To learn the instance-level uncertainty, MI-AOD first defines an instance uncertainty learning (IUL) module, which leverages two adversarial instance classifiers plugged atop the detection network (e.g., a feature pyramid network) to learn the uncertainty of unlabeled instances. Maximizing the prediction discrepancy of two instance classifiers predicts instance uncertainty while minimizing classifiers' discrepancy drives learning features to reduce the distribution bias between the labeled and unlabeled instances.</p><p>To establish the relationship between instance uncertainty and image uncertainty, MI-AOD incorporates a MIL module, which is in parallel with the instance classifiers. MIL treats each unlabeled image as an instance bag and performs instance uncertainty re-weighting (IUR) by evaluating instance appearance consistency across images. During MIL, the instance uncertainty and image uncertainty are forced to be consistently driven by a classification loss defined on image class labels (or pseudo-labels). Optimizing the image-level classification loss facilitates suppressing the noisy instances while highlighting truly representative ones. Iterative instance uncertainty learning and instance uncertainty re-weighting bridge the gap between instance-level observation and image-level evaluation, towards selecting the most informative images for detector training.</p><p>The contributions of this paper include:</p><p>(1) We propose Multiple Instance Active Object Detection (MI-AOD), establishing a solid baseline to model the relationship between the instance uncertainty and image uncertainty for informative image selection.</p><p>(2) We design instance uncertainty learning (IUL) and instance uncertainty re-weighting (IUR) modules, providing effective approaches to highlight informative instances while filtering out noisy ones in object detection.</p><p>(3) We apply MI-AOD to object detection on commonly used datasets, improving state-of-the-art methods with significant margins.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Active Learning</head><p>Uncertainty-based Methods. Uncertainty is the most popular metric to select samples for active learning <ref type="bibr" target="#b30">[31]</ref>, which can be defined as the posterior probability of a predicted class <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b15">16]</ref>, or the margin between the posterior probabilities of the first and the second predicted class <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b27">28]</ref>. It can also be defined upon entropy <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b13">14]</ref> to measure the variance of unlabeled samples. The expected model change methods <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b32">33]</ref> utilized the present model to estimate the expected gradient or prediction changes <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b14">15]</ref> for sample selection. MIL-based methods <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b5">6]</ref> selected informative images by discovering representative instances. However, they are designed for image classification and not applicable to object detection due to the challenging aspect of crowded and noisy instances <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b36">37]</ref>.</p><p>Distribution-based Methods. These methods select diverse samples by estimating the distribution of unlabeled samples. Clusters <ref type="bibr" target="#b26">[27]</ref> were applied to build the unlabeled sample distribution while discrete optimization methods <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b40">41]</ref> were employed to perform sample selection. Considering the distances to the surrounding samples, the context-aware methods <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b2">3]</ref> selected the samples that can represent the global sample distribution. Core-set <ref type="bibr" target="#b29">[30]</ref> defined active learning as core-set selection, i.e., choosing a set of points such that a model learned on the labeled set can capture the diversity of the unlabeled samples.</p><p>In the deep learning era, active learning methods remain falling into the uncertainty-based or distribution-based routines <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b3">4]</ref>. Sophisticated methods extended active learning to the open sets <ref type="bibr" target="#b23">[24]</ref>, or combined it with selfpaced learning <ref type="bibr" target="#b35">[36]</ref>. Nevertheless, it remains questionable whether the intermediate feature representation is effective for sample selection. The learning loss method <ref type="bibr" target="#b41">[42]</ref> can be categorized as either uncertainty-based or distributionbased. By introducing a module to predict the "loss" of the unlabeled samples, it estimates sample uncertainty and selects samples with large "loss" like hard negative mining.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Active Learning for Object Detection</head><p>Despite the substantial progress of active learning, few methods are specified for active object detection, which  faces complex instance distributions in the same images and are more challenging than active image classification. By simply sorting the loss predictions of instances to evaluate the image uncertainty, the learning loss method <ref type="bibr" target="#b41">[42]</ref> specified for image classification was directly applied to object detection. The image-level uncertainty can also be estimated by the uncertainty of a lot of background pixels <ref type="bibr" target="#b1">[2]</ref>. CDAL <ref type="bibr" target="#b0">[1]</ref> introduced spatial context to active detection and selected diverse samples according to the distances to the labeled set. Existing approaches simply used instance-/pixellevel observations to represent the image-level uncertainty. There still lacks a systematic method to learn the image uncertainty by leveraging instance-level models <ref type="bibr" target="#b43">[44,</ref><ref type="bibr" target="#b44">45]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">The Proposed Approach</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Overview</head><p>For active object detection, a small set of images X 0 L (the labeled set) with instance labels Y 0 L and a large set of images X 0 U (the unlabeled set) without labels are given. For each image, the label consists of bounding boxes (y loc x ) and categories (y cls x ) for objects of interest. A detection model M 0 is firstly initialized by using the labeled set {X 0 L , Y 0 L }. With the initialized model M 0 , active learning targets at selecting a set of images X 0 S from X 0 U to be manually labeled and merging them with X 0 L for a new labeled set X 1 L , i.e.,</p><formula xml:id="formula_0">X 1 L = X 0 L ∪ X 0 S .</formula><p>The selected image set X 0 S should be the most informative, i.e., can improve the detection performance as much as possible. Based on the updated labeled set X 1 L , the task model is retrained and updated to M 1 . The model training and sample selection repeat some cycles until the size of labeled set reaches the annotation budget.</p><p>Considering the large number 1 of instances in each image, there are two key problems for active object detection: (1) how to evaluate the uncertainty of the unlabeled instances using the detector trained on the labeled set; (2) how to precisely estimate the image uncertainty while filtering out noisy instances. MI-AOD handles these two problems by introducing two learning modules respectively. For the first problem, MI-AOD incorporates instance uncertainty learning, with the aim of highlighting informative instances in the unlabeled set, as well as aligning the distributions of the labeled and unlabeled set, <ref type="figure" target="#fig_2">Fig. 2</ref>(a). It is motivated by the fact that most active learning methods remain simply generalizing the models trained on the labeled set to the unlabeled set. This is problematic when there is a distribution bias between the two sets <ref type="bibr" target="#b9">[10]</ref>. For the second problem, MI-AOD introduces MIL to both the labeled and unlabeled set to estimate the image uncertainty by re-weighting the instance uncertainty. This is done by treating each image as an instance bag while re-weighting the instance uncertainty under the supervision of the image classification loss. Optimizing the image classification loss facilitates highlighting truly representative instances belonging to the same object classes while suppressing the noisy ones, <ref type="figure" target="#fig_2">Fig. 2</ref> </p><formula xml:id="formula_1">(b). Fixed g (a) (b) f r f 1 f 2 g f r f 1 f 2 Fixed (c) g f r f 1 f 2</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Labeled Data Flow Labeled and Unlabeled Data Flow Unlabeled Data Flow</head><formula xml:id="formula_2">l det -l dis l dis l det l det</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Instance Uncertainty Learning</head><p>Label Set Training. Using the RetinaNet as the baseline <ref type="bibr" target="#b18">[19]</ref>, we construct a detector with two discrepant instance classifiers (f 1 and f 2 ) and a bounding box regressor (f r ), <ref type="figure" target="#fig_3">Fig. 3(a)</ref>. We utilize the prediction discrepancy between the two instance classifiers to learn the instance uncertainty on the unlabeled set. Let g denote the feature extractor parameterized by θ g . The discrepant classifiers are parameterized by θ f1 and θ f2 and the regressor by θ fr . Θ = {θ f1 , θ f2 , θ fr , θ g } denotes the set of all parameters, where θ f1 and θ f2 are independently initialized.</p><p>In object detection, each image x can be represented by multiple instances {x i , i = 1, ..., N } corresponding to the feature anchors on the feature map <ref type="bibr" target="#b18">[19]</ref>. N is the number of the instances in image x. {y i , i = 1, ..., N } denote the labels for the instances. Given the labeled set, a detection model is trained by optimizing the detection loss, as</p><formula xml:id="formula_3">argmin Θ l det (x) = i FL(ŷ f1 i , y cls i ) + FL(ŷ f2 i , y cls i ) + SmoothL1(ŷ fr i , y loc i ) ,<label>(1)</label></formula><p>where FL(·) is the focal loss function for instance classification and SmoothL1(·) is the smooth L1 loss function for bounding box regression <ref type="bibr" target="#b18">[19]</ref>.ŷ f1 Maximizing Instance Uncertainty. Before the labeled set can precisely represent the unlabeled set, there exists a distribution bias between the labeled and unlabeled set, especially when the labeled set is small. The informative instances are in the biased distribution area. To find them out, f 1 and f 2 are designed as the adversarial instance classifiers with larger prediction discrepancy on the instances close to the boundary, <ref type="figure" target="#fig_2">Fig. 2(a)</ref>. The instance uncertainty is defined as the prediction discrepancy of f 1 and f 2 .</p><formula xml:id="formula_4">i = f 1 (g(x i )), y f2 i = f 2 (g(x i )) andŷ fr i = f r (g(x i )) denote</formula><p>To find out the most informative instances, it requires to fine-tune the network and maximize the prediction discrep-ancy of the adversarial classifiers, <ref type="figure" target="#fig_3">Fig. 3(b)</ref>. In this procedure, θ g is fixed so that the distributions of both the labeled and unlabeled instances are fixed. θ f1 and θ f2 are fine-tuned on the unlabeled set to maximize the prediction discrepancies for all instances. At the same time, it requires to preserve the detection performance on the labeled set. This is fulfilled by optimizing the following loss function, as</p><formula xml:id="formula_5">argmin Θ\θg L max = x∈X L l det (x) − x∈X U λ · l dis (x), (2) where l dis (x) = i |ŷ f1 i −ŷ f2 i |<label>(3)</label></formula><p>denotes the prediction discrepancy loss.ŷ f1 i ,ŷ f2 i ∈ R 1×C are the instance classification predictions of the two classifiers for the i-th instance in image x, where C is the number of object classes in the dataset, and λ is a regularization hyper-parameter determined by experiment. As shown in <ref type="figure" target="#fig_2">Fig. 2(a)</ref>, the informative instances with different predictions by the adversarial classifiers tend to have larger prediction discrepancy and larger uncertainty.</p><p>Minimizing Instance Uncertainty. After maximizing the prediction discrepancy, we further propose to minimize the prediction discrepancy to align the distributions of the labeled and unlabeled instances, <ref type="figure" target="#fig_3">Fig. 3(c)</ref>. In this procedure, the classifier parameters θ f1 and θ f2 are fixed, while the parameters θ g of the feature extractor are optimized by minimizing the prediction discrepancy loss, as</p><formula xml:id="formula_6">argmin θg L min = x∈X L l det (x) + x∈X U λ · l dis (x). (4)</formula><p>By minimizing the prediction discrepancy, the distribution bias between the labeled set and the unlabeled set is minimized and their features are aligned as much as possible.</p><p>In each active learning cycle, the max-min prediction discrepancy procedures repeat several times so that the instance uncertainty is learned and the instance distributions of the labeled and unlabeled set are progressively aligned. This actually defines an unsupervised learning procedure, which leverages the information (i.e., prediction discrepancy) of the unlabeled set to improve the detection model.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Instance Uncertainty Re-weighting</head><p>With instance uncertainty learning, the informative instances are highlighted. However, as there is a lot of instances (∼100k) in each image, the instance uncertainty may be not consistent with the image uncertainty. Some instances of high uncertainty are simply background noise or hard negatives for the detector. We thereby introduce an MIL procedure to bridge the gap between the instance-level and image-level uncertainty by filtering out noisy instances.</p><p>Multiple Instance Learning. MIL treats each image as an instance bag and utilizes the instance classification predictions to estimate the bag labels. In turn, it re-weights the instance uncertainty scores by minimizing the image classification loss. This actually defines an Expectation-Maximization procedure <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b4">5]</ref> to re-weight instance uncertainty across bags while filtering out noisy instances.</p><p>Specifically, we add an MIL classifier f mil parameterized by θ f mil in parallel with the instance classifiers, <ref type="figure" target="#fig_6">Fig. 4</ref>. The image classification scoreŷ cls i,c for multiple instances in an image is calculated aŝ</p><formula xml:id="formula_7">y cls i,c = exp(ŷ f mil i,c ) c exp(ŷ f mil i,c ) · exp (ŷ f1 i,c +ŷ f2 i,c )/2 i exp (ŷ f1 i,c +ŷ f2 i,c )/2 ,<label>(5)</label></formula><p>whereŷ f mil = f mil (g(x)) is an N × C score matrix, and y f mil i,c is the element inŷ f mil indicating the score of the i-th instance for class c. According to Eq. (5), the image classification scoreŷ cls i,c is large only when x i belongs to class c (the first term in Eq. (5)) and its instance classification scoresŷ f1 i,c andŷ f2 i,c are significantly larger than those of others (the second term in Eq. (5)).</p><p>Considering that the image classification scores of the instances from other classes/backgrounds are small, the image classification loss l imgcls is defined as</p><formula xml:id="formula_8">l imgcls (x) = − c y cls c log iŷ cls i,c +(1 − y cls c ) log(1 − iŷ cls i,c ) ,<label>(6)</label></formula><p>where y cls c ∈ {0, 1} denotes the image class label, which can be directly obtained from the instance class label y cls i in the labeled set. Optimizing Eq. (6) drives the MIL classifier to activate instances with large MIL score (ŷ f mil i,c ) and large classification outputs (ŷ f1 i,c +ŷ f2 i,c ). The instances with small MIL scores will be suppressed as background. The image classification loss is firstly applied in the label set training to get the initial model, and then used to re-weight the instance uncertainty in the unlabeled set.</p><p>Uncertainty Re-weighting. To ensure that the instance uncertainty is consistent with the image uncertainty, we assemble the image classification scores for all classes to a score vector w i and re-weight the instance uncertainty as</p><formula xml:id="formula_9">l dis (x) = i |w i · (ŷ f1 i −ŷ f2 i )|,<label>(7)</label></formula><p>where w i =ŷ cls i . We then update Eq. (2) to </p><formula xml:id="formula_10">argmiñ Θ\θgL max = x∈X L l det (x)+l imgcls (x) − x∈X U λ·l dis (x),<label>(8)</label></formula><formula xml:id="formula_11">min = x∈X L l det (x) + l imgcls (x) + x∈X U λ ·l dis (x) + l imgcls (x) .<label>(9)</label></formula><p>In Eq. (9), the image classification loss is applied to the unlabeled set, where the pseudo image labels are estimated using the outputs of the instance classifiers, as</p><formula xml:id="formula_12">y pseudo c = 1 max i ŷ f1 i,c +ŷ f2 i,c 2 , 0.5 ,<label>(10)</label></formula><p>where <ref type="figure" target="#fig_1">1(a, b)</ref> is a binarization function. When a &gt; b, it returns 1; otherwise 0. Eq. <ref type="formula" target="#formula_3">(10)</ref> is defined based on that instance classifiers can find true instances but are easy to be confused by complex backgrounds. We use the maximum instance score to predict pseudo image labels and leverage MIL to reduce background interference. According to Eqs. <ref type="formula" target="#formula_7">(5)</ref> and <ref type="formula" target="#formula_8">(6)</ref>, the image classification loss ensures the highlighted instances are representative of the image, i.e., minimizing the image classification loss bridges the gap between the instance uncertainty and image uncertainty. By iteratively optimizing Eqs. <ref type="bibr" target="#b7">(8)</ref> and <ref type="formula" target="#formula_11">(9)</ref>, informative object instances in the same class are statistically highlighted, while the background instances are suppressed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Informative Image Selection</head><p>In each learning cycle, after instance uncertainty learning (IUL) and instance uncertainty re-weighting (IUR), we select the most informative images from the unlabeled set by observing the top-k instance uncertainty defined in Eq. (3) for each image, where k is a hyper-parameter. This is based on the fact that the noisy instances have been suppressed and the instance uncertainty becomes consistent with the image uncertainty. The selected images are merged into the labeled set for the next learning cycle.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Experimental Settings</head><p>Datasets. The trainval sets of PASCAL VOC 2007 and 2012 datasets which contain 5011 and 11540 images are used for training. The VOC 2007 test set is used to evaluate mean average precision (mAP). The MS COCO dataset contains 80 object categories with challenging aspects including dense objects and small objects with occlusion. We use the train set with 117k images for active learning and the val set with 5k images for evaluating AP.</p><p>Active Learning Settings. We use the RetinaNet <ref type="bibr" target="#b18">[19]</ref> with ResNet-50 and SSD <ref type="bibr" target="#b22">[23]</ref> with VGG-16 as the base detector. For RetinaNet, MI-AOD uses 5.0% of randomly se-lected images from the training set to initialize the labeled set on PASCAL VOC. In each active learning cycle, it selects 2.5% images from the rest unlabeled set until the labeled images reach 20.0% of the training set. For the largescale MS COCO, MI-AOD uses only 2.0% of randomly selected images from the training set to initialize the labeled set, and then selects 2.0% images from the rest of the unlabeled set in each cycle until reaching 10.0% of the training set. In each cycle, the model is trained for 26 epochs with the mini-batch size 2 and the learning rate 0.001. After 20 epochs, the learning rate decreases to 0.0001. The momentum and the weight decay are set to 0.9 and 0.0001 respectively. For SSD, we follow the settings in LL4AL <ref type="bibr" target="#b41">[42]</ref> and CDAL <ref type="bibr" target="#b0">[1]</ref>, where 1k images in the training set are selected to initialize the labeled set and 1k images are selected in each cycle. The learning rate is 0.001 for the first 240 epochs and reduced to 0.0001 for the last 60 epochs. The mini-batch size is set to 32 which is required by LL4AL.</p><p>We compare MI-AOD with random sampling, entropy sampling, Core-set <ref type="bibr" target="#b29">[30]</ref>, LL4AL <ref type="bibr" target="#b41">[42]</ref> and CDAL <ref type="bibr" target="#b0">[1]</ref>. For entropy sampling, we use the averaged instance entropy as the image uncertainty. We repeat all experiments for 5 times and use the mean performance. MI-AOD and other methods share the same random seed and initialization for a fair comparison. λ defined in Eqs. (2), (4), <ref type="bibr" target="#b7">(8)</ref> and <ref type="formula" target="#formula_11">(9)</ref> is set to 0.5 and k mentioned in Sec. 3.4 is set to 10k.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Performance</head><p>PASCAL VOC. In <ref type="figure" target="#fig_8">Fig. 5</ref>, we report the performance of MI-AOD and compare it with state-of-the-art methods on a TITAN V GPU. Using either the RetinaNet <ref type="bibr" target="#b18">[19]</ref> or SSD <ref type="bibr" target="#b21">[22]</ref> detector, MI-AOD outperforms state-of-the-art methods with large margins. Particularly, it respectively outperforms state-of-the-art methods by <ref type="bibr" target="#b17">18</ref>  <ref type="table">Table 3</ref>. Ablation study on IUR. "wi" is the wi in Eq. <ref type="bibr" target="#b6">(7)</ref>. "Set" denotes the sample set for IUR. X and XL denote the whole sample set and the labeled set, respectively. mAP, which significantly outperforms CDAL by 3.20%. The improvements validate that MI-AOD can precisely learn instance uncertainty while selecting informative images. When using the SSD detector, MI-AOD outperforms state-of-the-art methods in almost all cycles, demonstrating the general applicability of MI-AOD to object detectors.</p><p>MS COCO. MS COCO is a challenging dataset for more categories, denser objects, and larger scale variation, where MI-AOD also outperforms the compared methods, <ref type="figure" target="#fig_8">Fig. 5</ref>. Particularly, it respectively outperforms Core-set and CDAL by 0.6%, 0.5%, and 2.0%, and 0.6%, 1.3%, and 2.6% when using 2.0%, 4.0%, and 10.0% labeled images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Ablation Study</head><p>IUL. As shown in Tab. 1, with IUL, the detection performance is improved up to 70.06% in the last cycle, which outperforms the Random method by 2.97% (70.06% vs. 67.09%). In Tab. 2, IUL also significantly improves the image classification performance with active learning on CIFAR-10. Particularly when using 2.0% samples, it improves the classification performance by 7.06% (58.07% vs. 51.01%), demonstrating the effectiveness of the discrepancy learning module for instance uncertainty estimation.</p><p>IUR. In Tab. 1, IUL achieves comparable performance with the method using the random image selection strategy in the early cycles. This is because there are significant noisy instances that make the instance uncertainty inconsistent with image uncertainty. After using IUR to re-weight instance uncertainty, the performance at early cycles is improved by 5.04%∼17.09% in the first three cycles (row 4 vs. row 1 in Tab. 3). In the last cycle, the performance is improved by 1.28% (68.48% vs. 67.20%) in comparison with IUL and 1.39% in comparison with the Random method (68.48% vs. 67.09%). As shown in Tab. 3, image classification scoreŷ cls i is the best re-weighting metric (row 4 vs. others). Interestingly, when using 100.0% images for training, the detector with IUR outperforms the detector without IUR by 1.09% (78.37% vs. 77.28%). These results clearly verify that the IUR module can suppress the interfering instances while highlighting more representative ones, which can indicate informative images for detector training.</p><p>Hyper-parameters and Time Cost. The effects of the regularization factor λ defined in Eqs. (2), (4), <ref type="bibr" target="#b7">(8)</ref> and <ref type="bibr" target="#b8">(9)</ref> and the valid instance number k in each image for selection are shown in Tab. 4. MI-AOD has the best performance when λ is set to 0.5 and k is set to 10k (for ∼100k instances/anchors in each image). Tab. 5 shows that MI-AOD costs less time at early cycles than CDAL. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Model Analysis</head><p>Visualization Analysis. In <ref type="figure">Fig. 6</ref>, we visualize the learned and re-weighted uncertainty and image classification scores of instances. The heatmaps are calculated by summarizing the uncertainty scores of all instances. With only IUL, there exist interference instances from the background (row 1) or around the true positive instance (row 2), and the results tend to miss the true positive instances (row 3) or instance parts (row 4). MIL can assign high image classification scores to the instances of interesting while suppressing backgrounds. As a result, IUR leverages the image classification scores to re-weight instances towards accurate instance uncertainty prediction.</p><p>Statistical Analysis. In <ref type="figure">Fig. 7</ref>, we calculate the number of true positive instances selected in each active learning cycle. It can be seen that MI-AOD significantly hits more true positives in all learning cycles. This shows that the proposed MI-AOD approach can activate true positive objects better while filtering out interfering instances, which facilities selecting informative images for detector training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>We proposed Multiple Instance Active Object Detection (MI-AOD) to select informative images for detector training by observing instance uncertainty. MI-AOD incorporates a discrepancy learning module, which leverages adversarial instance classifiers to learn the uncertainty of unlabeled instances. MI-AOD treats the unlabeled images as instance bags and estimates the image uncertainty by re-weighting instances in a multiple instance learning (MIL) fashion. Iterative instance uncertainty learning and re-weighting facilitate suppressing noisy instances, towards selecting informative images for detector training. Experiments on largescale datasets have validated the superiority of MI-AOD, in striking contrast with state-of-the-art methods. MI-AOD sets a solid baseline for active object detection.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 .</head><label>1</label><figDesc>Comparison of active object detection methods. (a) Conventional methods compute image uncertainty by simply averaging instance uncertainties, ignoring interference from a large number of background instances. (b) Our MI-AOD leverages uncertainty re-weighting via multiple instance learning to filter out interfering instances while bridging the gap between instance uncertainty and image uncertainty. (Best viewed in color)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 .</head><label>2</label><figDesc>MI-AOD illustration. (a) Instance uncertainty learning (IUL) utilizing two adversarial classifiers. (b) Instance uncertainty reweighting (IUR) using multiple instance learning. Bigger symbols ("+" and "−") indicate larger weights. (Best viewed in color)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 .</head><label>3</label><figDesc>Network architecture for instance uncertainty learning. (a) Label set training. (b) Maximizing instance uncertainty by maximizing classifier prediction discrepancy. (c) Minimizing instance uncertainty by minimizing classifier prediction discrepancy.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>the prediction results (classification and localization) for the instances. y cls i and y loc i denote the ground-truth class label and bounding box label, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 4 .</head><label>4</label><figDesc>Network architecture for instance uncertainty re-weighting. (a) Label set training. (b) Re-weighting and maximizing instance uncertainty. (c) Re-weighting while minimizing instance uncertainty.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>whereΘ = Θ∪{θ f mil }. By optimizing Eq. (8), the discrepancies of instances with large image classification scores are preferentially estimated, while those with small classification scores are suppressed. Similarly, Eq. (4) is updated to argmin θg,θ f milL</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 5 .</head><label>5</label><figDesc>Performance comparison of active object detection methods. (a) On PASCAL VOC using RetinaNet. (b) On PASCAL VOC using SSD. (c) On MS COCO using RetinaNet.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 6 .Figure 7 .</head><label>67</label><figDesc>Visualization of learned and re-weighted instance uncertainty and image classification score. (Best viewed in color) The number of true positive instances selected in each active learning cycle on PASCAL VOC using RetinaNet.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .Table 2 .</head><label>12</label><figDesc>28.31 49.42 56.03 59.81 64.02 65.95 67.09 77.28 30.09 49.17 55.64 60.93 64.10 65.77 67.20 30.09 49.79 58.94 63.11 65.61 67.84 69.01 30.09 49.74 60.60 64.29 67.13 68.76 70.06 47.18 57.12 60.68 63.72 66.10 67.59 68.48 78.37 47.18 57.58 61.74 64.58 66.98 68.79 70.33 47.18 58.03 63.98 66.58 69.57 70.96 72.03 Module ablation on PASCAL VOC. The first line shows the result of the baseline method with random image selection. "Max Unc." and "Mean Unc." respectively denote that the image uncertainty is represented by the maximum and averaged instance uncertainty. The effect of IUL for active image classification. Experiments are conducted on CIFAR-10 using the ResNet-18 backbone while the images are randomly selected in all cycles. ∅ 31.67 50.67 55.93 60.78 64.17 66.22 67.30 1 X L 42.52 54.08 57.18 63.43 65.04 66.74 68.32</figDesc><table><row><cell>.08%, 7.78%,</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 4 .Table 5 .</head><label>45</label><figDesc>λ k mAP (%) on Proportion (%) of Labeled Imgs. 5.0 7.5 10.0 12.5 15.0 17.5 20.0 2 10k 47.18 56.94 64.44 67.70 69.58 70.67 72.12 1 10k 47.18 57.30 64.93 67.40 69.63 70.53 71.62 0.5 10k 47.18 58.41 64.02 67.72 69.79 71.07 72.27 0.2 10k 47.18 58.02 64.44 67.67 69.42 70.98 72.06 0.5 N 47.18 58.03 63.98 66.58 69.57 70.96 72.03 0.5 10k 47.18 58.41 64.02 67.72 69.79 71.07 72.27 0.5 100 47.18 58.74 63.62 67.03 68.63 70.26 71.47 0.5 1 47.18 57.58 61.74 64.58 66.98 68.79 70.33 Performance under different hyper-parameters. Random 0.77 1.12 1.45 1.78 2.12 2.45 2.78 CDAL [1] 1.18 1.50 1.87 2.19 2.68 2.83 2.82 MI-AOD 1.03 1.42 1.78 2.18 2.55 2.93 3.12 Comparison of time cost on PASCAL VOC.</figDesc><table><row><cell>Method</cell><cell>Time (h) on Proportion (%) of Labeled Imgs. 5.0 7.5 10.0 12.5 15.0 17.5 20.0</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">For example, the RetinaNet detector<ref type="bibr" target="#b18">[19]</ref> produces ∼100k of anchors (instances) for an image.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Contextual diversity for active learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharat</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Himanshu</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saket</forename><surname>Anand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chetan</forename><surname>Arora</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="137" to="153" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Active learning for deep detection neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abel</forename><surname>Hamed Habibi Aghdam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><forename type="middle">M</forename><surname>Gonzalez-Garcia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joost</forename><surname>López</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van De Weijer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Hierarchical subquery evaluation for active learning on a graph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oisin</forename><surname>Mac Aodha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">F</forename><surname>Neill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Campbell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><forename type="middle">J</forename><surname>Kautz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Brostow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="564" to="571" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The power of ensembles for active learning in image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>William</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Beluch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Genewein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><forename type="middle">M</forename><surname>Nürnberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Köhler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="9368" to="9377" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Weakly supervised deep detection networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hakan</forename><surname>Bilen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Vedaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2846" to="2854" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Bag-level aggregation for multiple-instance active learning in instance classification problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc-Andre</forename><surname>Carbonneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Granger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ghyslain</forename><surname>Gagnon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TNNLS</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1441" to="1451" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A convex optimization framework for active learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehsan</forename><surname>Elhamifar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillermo</forename><surname>Sapiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Allen</forename><forename type="middle">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sastry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="209" to="216" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Selecting influential examples: Active learning with expected model output changes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Freytag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Rodner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joachim</forename><surname>Denzler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="562" to="577" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Deep bayesian active learning with image data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yarin</forename><surname>Gal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Riashat</forename><surname>Islam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zoubin</forename><surname>Ghahramani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1183" to="1192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Deep active learning for biased datasets via fisher kernel self-supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denis</forename><forename type="middle">A</forename><surname>Gudovskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Hodgkinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takuya</forename><surname>Yamaguchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sotaro</forename><surname>Tsukizawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="9038" to="9046" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Active instance sampling via matrix partition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhong</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="802" to="810" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Context aware active learning of activity recognition models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mahmudul</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amit</forename><forename type="middle">K</forename><surname>Roy-Chowdhury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="4543" to="4551" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Multi-instance multi-label active learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng-Jun</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nengneng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Songcan</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1886" to="1892" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Fatih Porikli, and Nikolaos Papanikolopoulos. Multi-class active learning for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ajay</forename><forename type="middle">J</forename><surname>Joshi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="2372" to="2379" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Active and continuous exploration with deep neural networks and expected model output changes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Käding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Rodner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Freytag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joachim</forename><surname>Denzler</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1612.06129</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Heterogeneous uncertainty sampling for supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Catlett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="page" from="148" to="156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A sequential algorithm for training text classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">A</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="page" from="3" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Active self-paced learning for cost-effective and progressive face identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keze</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyu</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangmeng</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="7" to="19" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Kaiming He, and Piotr Dollár. Focal loss for dense object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="318" to="327" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Anti-aliasing semantic reconstruction for few-shot semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Binghao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yao</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianbin</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji</forename><surname>Xiangyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qixiang</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Harmonic feature activation for few-shot semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Binghao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianbin</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qixiang</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TIP</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3142" to="3153" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Ssd: Single shot multibox detector</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng-Yang</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander C</forename><surname>Berg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="21" to="37" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">SSD: single shot multibox detector</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><forename type="middle">E</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng-Yang</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="21" to="37" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Active sampling for open-set classification without initial annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng-Jun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4416" to="4423" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Uncertainty aware graph gaussian process for semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhao-Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shao-Yuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Songcan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yao</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng-Jun</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="4957" to="4964" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Latent structured active learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjie</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">G</forename><surname>Schwing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="728" to="736" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Active learning using pre-clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tat</forename><surname>Hieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arnold</forename><forename type="middle">W M</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smeulders</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Margin-based active learning for structured output spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Small</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECML</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="413" to="424" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Toward optimal active learning through sampling estimation of error reduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="441" to="448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Active learning for convolutional neural networks: A core-set approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ozan</forename><surname>Sener</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICLR</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Burr Settles. Active Learning. Synthesis Lectures on Artificial Intelligence and Machine Learning</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2012" />
			<publisher>Morgan &amp; Claypool Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">An analysis of active learning strategies for sequence labeling tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Burr</forename><surname>Settles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Craven</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1070" to="1079" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Multipleinstance active learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Burr</forename><surname>Settles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Craven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumya</forename><surname>Ray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1289" to="1296" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Variational adversarial active learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samarth</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sayna</forename><surname>Ebrahimi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5971" to="5980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Support vector machines for multiple-instance learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrews</forename><surname>Stuart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsochantaridis</forename><surname>Ioannis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hofmann</forename><surname>Thomas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="561" to="568" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Self-paced active learning: Query the right thing at the right time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying-Peng</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng-Jun</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5117" to="5124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">C-mil: Continuation multiple instance learning for weakly supervised object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fang</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyang</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianbin</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qixiang</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2199" to="2208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Min-entropy latent model for weakly supervised object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fang</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengxu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenjun</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianbin</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qixiang</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2395" to="2409" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Cost-effective active learning for deep image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keze</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ya</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruimao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TCSVT</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2591" to="2600" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Incorporating diversity and informativeness in multipleinstance active learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ran</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi-Zhao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Kwong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TFS</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1460" to="1475" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Multi-class active learning by uncertainty sampling with diversity maximization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhigang</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feiping</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">G</forename><surname>Hauptmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="113" to="127" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Learning loss for active learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donggeun</forename><surname>Yoo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">In</forename><surname>So Kweon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">State-relabeling adversarial active learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beichen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shijie</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuhui</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Zheng-Jun Zha, and Qingming Huang</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="8753" to="8762" />
		</imprint>
	</monogr>
	<note>CVPR</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Freeanchor: Learning to match anchors for visual object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaosong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fang</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rongrong</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qixiang</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="147" to="155" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Learning to match anchors for visual object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaosong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fang</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyang</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qixiang</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
