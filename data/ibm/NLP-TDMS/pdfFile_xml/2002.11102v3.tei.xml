<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">On Feature Normalization and Data Augmentation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boyi</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Wu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ser-Nam</forename><surname>Lim</surname></persName>
							<email>sernamlim@fb.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
							<email>kilian@cornell.edu</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Cornell University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Cornell Tech</orgName>
								<address>
									<addrLine>3 ASAPP 4 Facebook AI</addrLine>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">On Feature Normalization and Data Augmentation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T09:38+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The moments (a.k.a., mean and standard deviation) of latent features are often removed as noise when training image recognition models, to increase stability and reduce training time. However, in the field of image generation, the moments play a much more central role. Studies have shown that the moments extracted from instance normalization and positional normalization can roughly capture style and shape information of an image. Instead of being discarded, these moments are instrumental to the generation process. In this paper we propose Moment Exchange, an implicit data augmentation method that encourages the model to utilize the moment information also for recognition models. Specifically, we replace the moments of the learned features of one training image by those of another, and also interpolate the target labels-forcing the model to extract training signal from the moments in addition to the normalized features. As our approach is fast, operates entirely in feature space, and mixes different signals than prior methods, one can effectively combine it with existing augmentation approaches. We demonstrate its efficacy across several recognition benchmark data sets where it improves the generalization capability of highly competitive baseline networks with remarkable consistency.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Image recognition and image generation are two corner stones of computer vision. While both are burgeoning fields, specialized techniques from both sub-areas can sometimes form a dichotomy. Examples are mixup <ref type="bibr" target="#b73">[74]</ref> and squeeze-and-excitation <ref type="bibr" target="#b20">[21]</ref> from the former, and adaptive instance normalization <ref type="bibr" target="#b23">[24]</ref> from the latter, although exceptions exist. Historically, the field of deep learning was widely popularized in discriminative image classification with AlexNet <ref type="bibr" target="#b33">[34]</ref>, and image generation through GANs <ref type="bibr" target="#b13">[14]</ref> and VAEs <ref type="bibr" target="#b31">[32]</ref>.</p><p>One particular aspect of this dichotomy is that in image * : Equal contribution. recognition, popularized by batch normalization <ref type="bibr" target="#b25">[26]</ref>, the first and second moments (a.k.a., mean and standard deviation) in image recognition are computed across instances in a mini-batch and typically removed as noise <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b64">65]</ref>. Studies have shown that this smoothes the optimization landscape <ref type="bibr" target="#b49">[50]</ref> and enables larger learning rates <ref type="bibr" target="#b1">[2]</ref>, which leads to faster convergence in practice. In contrast, for techniques like instance normalization <ref type="bibr" target="#b58">[59]</ref> and positional normalization <ref type="bibr" target="#b35">[36]</ref>, moments play a central role in the image generation process. For example, exchanging moments of latent features across samples has become a popular way to control for the style or shape of generated images <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b44">45]</ref>. Here, moments are viewed as features, not noise, with research showing that they encode the style of an image <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b28">29]</ref>, as well as the underlying structure <ref type="bibr" target="#b35">[36]</ref>. To substantiate this point, we depict the first and second moments of the features extracted in the first layer of a ResNet <ref type="bibr" target="#b17">[18]</ref> in <ref type="figure" target="#fig_0">Fig. 1</ref> , using the technique described in <ref type="bibr" target="#b35">[36]</ref>. The class label can still be inferred visually from both moments, which is a testament to the signal that remains in these statistics. To further substantiate our observation, we also show in <ref type="figure">Fig. 2</ref> that simply using moments (from the first ResNet layer) for image classification already yields non-trivial performance (red bar) as compared to random guessing (gray bar). Similarly, removing the moments from positional normalization has a detrimental effect (blue bar vs. green bar).</p><p>As there is evidently important signal in the moments and in the normalized features, we would like to introduce a Example images are from Shutterstock. way to regulate how much attention the deep net should pay to each source. One approach to direct neural networks to a particular signal source is to introduce dedicated feature augmentation. For example, it has been shown that Con-vNets trained on ImageNet <ref type="bibr" target="#b6">[7]</ref> are biased towards textures instead of shapes <ref type="bibr" target="#b11">[12]</ref>. To overcome this, Geirhos et al. <ref type="bibr" target="#b11">[12]</ref> introduce a style transfer model to create a set of images with unreal textures. For example, they generate cats with elephant skins and bears with Coca-Cola bottle texture. An image classifier is trained to recognize the shape (cats or bears) instead of the textures (elephants or bottles).</p><p>In this paper we propose a novel data augmentation scheme that, to our knowledge, is the first method to systematically regulate how much attention a network pays to the signal in the feature moments. Concretely, we extract the mean and variance (across channels) after the first layer, but instead of simply removing them, we swap them between images. See <ref type="figure" target="#fig_1">Fig. 3</ref> for a schematic illustration, where we extract and remove the feature moments of a cat image, and inject the moments of a plane. Knowing that the resulting features now contain information about both images, we make the network predict an interpolation of the two labels. In the process, we force the network to pay attention to two aspects of the data: the normalized feature (from the cat) and the moments (from the plane). By basing its prediction on two different signals we increase the robustness of the classification, as during testing both would point towards the same label. We call our method Moment Exchange or MoEx for short.</p><p>Through exchanging the moments, we swap the shape (or style) information of two images, which can be viewed as an implicit version of the aforementioned method proposed by Geirhos et al. <ref type="bibr" target="#b11">[12]</ref>. However, MoEx does not require a pre-trained style transfer model to create a dataset explicitly. In fact, MoEx is very effective for training with mini-batches and can be implemented in a few lines of code: During training we compute the feature mean and variance for each instance at a given layer (acros channels), permute them across the mini-batch, and re-inject them into the feature representation of other instances (while interpolating the labels).</p><p>MoEx operates purely in feature space and can therefore easily be applied jointly with existing data augmentation methods that operate in the input space, such as cropping, flipping, rotating, but even label-perturbing approaches like Mixup <ref type="bibr" target="#b73">[74]</ref> or Cutmix <ref type="bibr" target="#b71">[72]</ref>. Importantly, because MoEx only alters the first and second moments of the pixel distributions, it has an orthogonal effect to existing data augmentation methods and its improvements can be "stacked" on top of their established gains in generalization. We conduct extensive experiments on eleven different tasks/datasets using more than ten varieties of models. The results show that MoEx consistently leads to significant im-  <ref type="figure">Figure 2</ref>. Error rates of ResNet-110 using different features on CIFAR-100. The numbers are averaged over three random runs. We compute the moments after the first convolutional layer, and either adds a PONO layer right after the first Conv-BN-ReLU block or computes the first two moments and concatenate them as a two-channel feature map. A ResNet which can only see the moments can still make nontrivial predictions (Red is much better than gray). Additionally, using only the normalized feature (i.e., removing the PONO moments) hurts the performance (Blue is worse than green), which also shows that these moments contains important information. Finally, MoEx improves the performance by encouraging the model to use both sources of signal during training.</p><p>provements across models and tasks, and it is particularly well suited to be combined with existing augmentation approaches. Further, our experiments show that MoEx is not limited to computer vision, but is also readily applicable and highly effective in applications within speech recognition and natural language processing-suggesting that MoEx reveals a fundamental insight about deep nets that crosses areas and data types. Our implementation is available at https://github.com/Boyiliee/MoEx.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Background and Related Work</head><p>Feature normalization has always been a prominent part of neural network training <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b36">37]</ref>. Initially, when networks had predominately one or two hidden layers, the practice of z-scoring the features was limited to the input itself. As networks became deeper, Ioffe and Szegedy <ref type="bibr" target="#b25">[26]</ref> extended the practice to the intermediate layers with the celebrated BatchNorm algorithm. As long as the mean and variance are computed across the entire input, or a randomly picked mini-batch (as it is the case for BatchNorm), the extracted moments reveal biases in the data set with no predictive information -removing them causes no harm but can substantially improve optimization and generalization <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b48">49]</ref>.</p><p>In contrast, recently proposed normalization methods <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b58">59,</ref><ref type="bibr" target="#b64">65]</ref> treat the features of each training instance as a distribution and normalize them for each sample individually. We refer to the extracted mean and variance as intra- instance moments. We argue that intra-instance moments are attributes of a data instance that describe the distribution of its features and should not be discarded. Recent works <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b35">36]</ref> have shown that such attributes can be useful in several generative models. Realizing that these moments capture interesting information about data instances, we propose to use them for data augmentation. Data augmentation has a similarly long and rich history in machine learning. Initial approaches discovered the concept of label-preserving transformations <ref type="bibr" target="#b50">[51,</ref><ref type="bibr" target="#b52">53]</ref> to mimic larger training data sets to suppress overfitting effects and improve generalization. For instance, Simard et al. <ref type="bibr" target="#b53">[54]</ref> randomly translate or rotate images assuming that the labels of the images would not change under such small perturbations. Many subsequent papers proposed alternative flavors of this augmentation approach based on similar insights <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b67">68,</ref><ref type="bibr" target="#b75">76]</ref>. Beyond vision tasks, back-translation <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b51">52,</ref><ref type="bibr" target="#b70">71]</ref> and word dropout <ref type="bibr" target="#b26">[27]</ref> are commonly used to augment text data. Besides augmenting inputs, Ghiasi et al. <ref type="bibr" target="#b12">[13]</ref>, van der Maaten et al. <ref type="bibr" target="#b59">[60]</ref>, Wang et al. <ref type="bibr" target="#b61">[62]</ref> adjust either the features or loss function as implicit data augmentation methods. In addition to labelpreserving transformations, there is an increasing trend to use label-perturbing data augmentation methods. Zhang et al. <ref type="bibr" target="#b73">[74]</ref> arguably pioneered the field with Mixup, which interpolates two training inputs in feature and label space simultaneously. Cutmix <ref type="bibr" target="#b71">[72]</ref>, instead, is designed especially for image inputs. It randomly crops a rectangular region of an image and pastes it into another image, mixing the labels proportional to the number of pixels contributed by each input image to the final composition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Moment Exchange</head><p>In this section we introduce Moment Exchange (MoEx), which blends feature normalization with data augmentation. Similar to Mixup and Cutmix, it fuses features and labels across two training samples, however it is unique in its asymmetry, as it mixes two very different components: The normalized features of one instance are combined with the feature moments of another. This asymmetric composition in feature space allows us to capture and smooth out different directions of the decision boundary, not previously covered by existing augmentation approaches. We also show that MoEx can be implemented very efficiently in a few lines of code, and should be regarded as an effective default companion to existing data augmentation methods.</p><p>Setup. Deep neural networks are composed of layers of transformations including convolution, pooling, transformers <ref type="bibr" target="#b60">[61]</ref>, fully connected layers, and non-linear activation layers. Consider a batch of input instances x, these transformations are applied sequentially to generate a series of hidden features h 1 , ..., h L before passing the final feature h L to a linear classifier. For each instance, any feature presentation h is a 3D tensor indexed by channel (C), height (H), and width (W).</p><p>Normalization. We assume the network is using an invertible intra-instance normalization. We denote this function by F , which takes the features h i of the i-th input x i at layer and produces three outputs: the normalized featureŝ h i , the first moment µ i , and the second moment σ i :</p><formula xml:id="formula_0">(ĥ i , µ i , σ i ) = F (h i ), h i = F −1 (ĥ i , µ i , σ i ).</formula><p>The inverse function F −1 reverses the normalization process. As an example, PONO <ref type="bibr" target="#b35">[36]</ref> computes the first and second moments across channels from the feature representation at a given layer</p><formula xml:id="formula_1">µ b,h,w = 1 C c h b,c,h,w , σ b,h,w = 1 C c h b,c,h,w − µ b,h,w 2 + .</formula><p>The normalized features have zero-mean and standard deviation 1 along the channel dimension. Note that after using MoEx with an intra-instance normalization to exchange features, we can still apply an inter-instance normalization (like BatchNorm) on these exchanged or mixed features, with their well-known beneficial impact on convergence.</p><p>As the norms compute statistics across different dimensions their interference is insignificant. Moment Exchange. The procedure described in the following functions identically for each layer it is applied to and we therefore drop the superscript for notational simplicity. Further, for now, we only consider two randomly chosen samples x A and x B (see <ref type="figure" target="#fig_1">Fig. 3</ref> for a schematic illustration). The intra-instance normalization decomposes the features of input x A at layer into three parts,ĥ A , µ A , σ A . Traditionally, batch-normalization <ref type="bibr" target="#b25">[26]</ref> discards the two moments and only proceeds with the normalized featureŝ h A . If the moments are computed across instances (e.g. over the mini-batch) this makes sense, as they capture biases that are independent of the label. However, in our case we focus on intra-instance normalization (See <ref type="figure" target="#fig_0">Fig. 1</ref>), and therefore both moments are computed only from x A and are thus likely to contain label-relevant signal. This is clearly visible in the cat and plane examples in <ref type="figure" target="#fig_1">Fig. 3</ref>. All four moments (µ A ,σ A ,µ B ,σ B ), capture the underlying structure of the samples, revealing their respective class labels.</p><p>We consider the normalized features and the moments as distinct views of the same instance. It generally helps robustness if a machine learning algorithm leverages multiple sources of signal, as it becomes more resilient in case one of them is under-expressed in a test example. For instance, the first moment conveys primarily structural information and only little color information, which, in the case of cat images can help overcome overfitting towards fur color biases in the training data set.</p><p>In order to encourage the network to utilize the moments, we use the two images and combine them by injecting the moments of image x B into the feature representation of image x A : h</p><formula xml:id="formula_2">(B) A = F −1 (ĥ A , µ B , σ B ).</formula><p>In the case of PONO, the transformation becomes h</p><formula xml:id="formula_3">(B) A = σ B h A −µ A σ A + µ B .</formula><p>We now proceed with these features h</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(B)</head><p>A , which contain the moments of image B (plane) hidden inside the features of image A (cat). In order to encourage the neural network to pay attention to the injected features of B we modify the loss function to predict the class label y A and also y B , up to some mixing constant λ ∈ [0, 1]. The loss becomes a straight-forward combination</p><formula xml:id="formula_4">λ · (h (B) A , y A ) + (1 − λ) · (h (B) A , y B ).</formula><p>Implementation. In practice one needs to apply MoEx only on a single layer in the neural network, as the fused signal is propagated until the end. With PONO as the normalization method, we observe that the first layer ( = 1) usually leads to the best result. In contrast, we find that MoEx is more suited for later layers when using IN <ref type="bibr" target="#b58">[59]</ref>, GN <ref type="bibr" target="#b64">[65]</ref>, or LN <ref type="bibr" target="#b0">[1]</ref> for moment extraction. Please see Sec. 5 for a detailed ablation study. The inherent randomness of mini-batches allows us to implement MoEx very efficiently. For each input instance in the mini-batch x i we compute the normalized features and momentsĥ i , µ i , σ i . Subsequently we sample a random permutation π and apply MoEx with a random pair within the mini-batch h</p><formula xml:id="formula_5">(π(i)) i ← F −1 (ĥ i , µ π(i) , σ π(i) )</formula><p>. See Algorithm 1 in the Appendix for an example implementation in PyTorch <ref type="bibr" target="#b45">[46]</ref>. Note that all computations are extremely fast and only introduce negligible overhead during training.</p><p>Hyper-parameters. To control the intensity of our data augmentation, we perform MoEx during training with some probability p. In this way, the model can still see the original features with probability 1 − p. In practice we found that p = 0.5 works well on most datasets except that we set p = 1 for ImageNet where we need stronger data augmentation. The interpolation weight λ is another hyper-parameter to be tuned. Empirically, we find that 0.9 works well across data sets. The reason can be that the moments contain less information than the normalized features. Please see Appendix for a detailed ablation study.</p><p>Properties. MoEx is performed entirely at the feature level inside the neural network and can be readily combined with other augmentation methods that operate on the raw input (pixels or words). For instance, Cutmix <ref type="bibr" target="#b71">[72]</ref> typically works best when applied on the input pixels directly. We find that the improvements of MoEx are complimentary to such prior work and recommend to use MoEx in combination with established data augmentation methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>We evaluate the efficacy of MoEx thoroughly across several tasks and data modalities. Our implementation will be released as open source upon publication.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Image Classification on CIFAR</head><p>CIFAR-10 and CIFAR-100 <ref type="bibr" target="#b32">[33]</ref> are benchmark datasets containing 50K training and 10K test colored images at 32x32 resolution. We evaluate our method using various model architectures <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b68">69,</ref><ref type="bibr" target="#b72">73]</ref> on CIFAR-10 and CIFAR-100. We follow the conventional setting with random translation as the default data augmentation and apply MoEx to the features after the first layer. Furthermore, to justify the compatibility of MoEx with other regularization methods, we follow the official setup of <ref type="bibr" target="#b71">[72]</ref> and apply MoEx jointly with several regularization methods to PyramidNet-200 <ref type="bibr" target="#b16">[17]</ref> on CIFAR-100. <ref type="table">Table 1</ref> displays the classification results on CIFAR-10 and CIFAR-100 with and without MoEx. We report mean and standard error over three runs <ref type="bibr" target="#b15">[16]</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Image Classification on ImageNet</head><p>We evaluate on ImageNet <ref type="bibr">[</ref> we use NVIDIA's mixed-precision training code base with batch size 1024, default learning rate 0.1 × batch size/256, cosine annealing learning rate scheduler <ref type="bibr" target="#b41">[42]</ref> with linear warmup <ref type="bibr" target="#b14">[15]</ref> for the first 5 epochs. As the model might require more training updates to converge with data augmentation, we apply MoEx to ResNet-50, ResNeXt-50 (32×4d), DenseNet-265 and train them for 90 and 300 epochs. For a fair comparison, we also report Cutmix <ref type="bibr" target="#b71">[72]</ref> under the same setting. Since the test server of ImageNet is no longer available to the public, we follow the common practice <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b68">69,</ref><ref type="bibr" target="#b71">72,</ref><ref type="bibr" target="#b73">74]</ref> reporting the validation scores of the baselines as well as our method. <ref type="table">Table 3</ref> shows the test error rates on the ImageNet data set. MoEx is able to improve the classification performance throughout, regardless of model architecture. Similar to the previous CIFAR experiments, we observe in Table 4 that MoEx is highly competitive when compared to existing regularization methods and truly shines when it https://github.com/NVIDIA/apex/tree/master/examples/imagenet is combined with them. When applied jointly with Cut-Mix (the strongest alternative), we obtain our lowest Top-1 and Top-5 error of 20.9/5.7 respectively. Beyond, we apply MoEx to EfficientNet-B0 <ref type="bibr" target="#b57">[58]</ref> and follow the official training scheme, we find MoEx is able to help reduce the error rate of baseline from 22.9 to 22.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Fintuneing Imagenet pretrained models on Pascal VOC for Object Detection</head><p>To demonstrate that MoEx encourages models to learn better image representations, we apply models pre-trained on ImageNet with MoEx to downstream tasks including object detection on Pascal VOC 2007 dataset. We use the Faster R-CNN <ref type="bibr" target="#b47">[48]</ref> with C4 or FPN <ref type="bibr" target="#b39">[40]</ref> backbones implemented in Detectron2 <ref type="bibr" target="#b65">[66]</ref> and following their default training configurations. We consider three ImageNet pretrained models: the ResNet-50 provided by He et al. <ref type="bibr" target="#b17">[18]</ref>, our ResNet-50 baseline trained for 300 epochs, our ResNet-50 trained with CutMix <ref type="bibr" target="#b71">[72]</ref>, and our ResNet-50 trained with MoEx. A Faster R-CNN is initialized with these pretrained weights and finetuned on Pascal VOC 2007 + 2012 training data, tested on Pascal VOC 2007 test set, and evaluated with the PASCAL VOC style metric: average precision at IoU 50% which we call AP VOC (or AP50 in detectron2). We also report MS COCO <ref type="bibr" target="#b40">[41]</ref> style average precision metric AP COCO which is recently considered as a better choice. Notably, MoEx is not applied during finetuning. <ref type="table" target="#tab_3">Table 5</ref> shows the average precision of different initializations. We discover that MoEx provides a better initialization than the baseline ResNet-50 and is competitive against CutMix <ref type="bibr" target="#b71">[72]</ref> for the downstream cases and leads slightly better performance regardless of backbone architectures. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">3D model classification on ModelNet</head><p>We conduct experiments on Princeton ModelNet10 and ModelNet40 datasets <ref type="bibr" target="#b66">[67]</ref> for 3D model classification. This task aims to classify 3D models encoded as 3D point clouds into 10 or 40 categories. As a proof of concept, we use PointNet++ (SSG) <ref type="bibr" target="#b46">[47]</ref> implemented efficiently in PyTorch Geometric <ref type="bibr" target="#b10">[11]</ref> as the baseline. It does not use surface normal as additional inputs. We apply MoEx to the features after the first set abstraction layer in PointNet++. Following their default setting, all models are trained with ADAM <ref type="bibr" target="#b30">[31]</ref> at batch size 32 for 200 epochs. The learning rate is set to 0.001. We tune the hyper-parameters of MoEx on ModelNet-10 and apply the same hyper-parameters to ModelNet-40. We choose p = 0.5, λ = 0.9, and Instan-ceNorm for this task, which leads to slightly better results. <ref type="table">Table 6</ref> summarizes the results out of three runs, showing mean error rates with standard errors. MoEx reduces the classification errors from 6.0% to 5.3% and 9.2% to 8.8% on ModelNet10 and ModelNet40, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>ModelNet10 ModelNet40 PointNet++ 6.02±0.10 9.16±0.16 + MoEx 5.25±0.18 8.78±0.28 <ref type="table">Table 6</ref>. Classification errors (%) on ModelNet10 and Model-Net40. The mean and standard error out of 3 runs are reported.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Ablation Study</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">MoEx Design Choices</head><p>In the previous section we have established that MoEx yields significant improvements across many tasks and model architectures. In this section we shed light onto which design choices crucially contribute to these improvements. <ref type="table">Table 7</ref> shows results on CIFAR-100 with a ResNet-110 architecture, averaged over 3 runs. The column titled MoEx indicates if we performed moment exchange or not.</p><p>Label smoothing. First, we investigate if the positive effect of MoEx can be attributed to label smoothing <ref type="bibr" target="#b56">[57]</ref>. In label smoothing, one changes the loss of a sample x with label y to λ (x, y) + 1 C−1 y =y (1 − λ) (x, y ), where C denotes the total number of classes. Essentially the neural network is not trained to predict one class with 100% certainty, but instead only up to a confidence λ.</p><p>Further, we evaluate Label Interpolation only. Here, we evaluate MoEx with label interpolation -but without any feature augmentation, essentially investigating the effect of label interpolation alone. Both variations yield some improvements over the baseline, but are significantly worse than MoEx.</p><p>Interpolated targets. The last three rows of <ref type="table">Table 7</ref> demonstrate the necessity of utilizing the moments for prediction. We investigate two variants: λ = 1, which corresponds to no label interpolation; MoEx with label smoothing (essentially assigning a small loss to all labels except https://github.com/rusty1s/pytorch geometric We do hyper-parameter search from p ∈ {0.5, 1}, λ ∈ {0.5, 0.9} and whether to use PONO or InstanceNorm.  <ref type="table">Table 7</ref>. Ablation study on different design choices.</p><p>y A ). The last row corresponds to our proposed method, MoEx (λ = 0.9). Two general observations can be made: 1) interpolating the labels is crucial for MoEx to be beneficial -the approach leads to absolutely no improvement when we set λ = 1. 2) it is also important to perform moment exchange, without it MoEx reduces to a version of label smoothing, which yields significantly smaller benefits.</p><p>Choices of normalization methods. We study how MoEx performs when using moments from LayerNorm (LN) <ref type="bibr" target="#b0">[1]</ref>, InstanceNorm (IN) <ref type="bibr" target="#b58">[59]</ref>, PONO <ref type="bibr" target="#b35">[36]</ref>, GroupNorm (GN) <ref type="bibr" target="#b64">[65]</ref>, and local response normalization (LRN) <ref type="bibr" target="#b33">[34]</ref> perform. For LRN, we use a recent variant <ref type="bibr" target="#b27">[28]</ref> which uses the unnormalized 2nd moment at each position. We conduct experiments on CIFAR-100 with ResNet110. For each normalization, we do a hyper-parameter sweep to find the best setup. <ref type="table">Table 8</ref> shows classification results of MoEx with various feature normalization methods on CIFAR-100 averaged over 3 runs (with corresponding standard errors). We observe that MoEx generally works with all normalization approaches, however PONO has a slight but significant edge, which we attribute to the fact that it catches the structural information of the feature most effectively. <ref type="table">Table 9</ref> shows that different normalization methods work the best at different layers. With PONO or GN, we apply MoEx in the first layer (right before the first stage), whereas the LN moments work best when exchanged before the third stage of a 3-stage ResNet-110; IN is better to be applied right before the second stage. We hypothesize the reason is that PONO moments captures local information while LN and IN compute global features which are better encoded at later stages of a ResNet. For image classification, using PONO seems generally best. While MoEx with other normalization methods in different stages could also obtain competitive results such as LN before Stage 3 in <ref type="table">Table 8</ref>. We assume it is because in the early layers it is important to exchange the whole mode (and PONO has a significant advantage), whereas for the last stage the scale already contains a lot of information (LN performs best here), which is worth being studied in other architecture such as Trans-We select the best result from experiments with λ ∈ {0.6, 0.7, 0.8, 0.9} and p ∈ {0.25, 0.5, 0.75, 1.0}. We choose the best layer among the 1st layer, 1st stage, 2nd stage, and 3rd stage. For each setting, we obtain the mean and standard error out of 3 runs with different random seeds.  <ref type="table">Table 9</ref>. MoEx with different normalization methods applied to different layers in a 3-stage ResNet-110 on CIFAR-100. We bold the best layer of each normalization method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">MoEx Hyper-parameters</head><p>In MoEx, λ and 1 − λ serve as the target interpolation weights of labels y A , y B , respectively. To explore the relationship between λ and model performance, we train a ResNet-50 on ImageNet with λ ∈ {0.3, 0.5, 0.7, 0.9} with on PONO. The results are summarized in <ref type="table">Table 10</ref>. We observe that generally higher λ leads to lower error, probably because more information is captured in the normalized features than in the moments. After all, moments only capture general statistics, whereas the features have many channels and can capture texture information in great detail. We also investigate various values of the exchange probability p (for fixed λ = 0.9), but on the ImageNet data p = 1 (i.e. apply MoEx on every image) tends to perform best.  <ref type="table">Table 10</ref>. Ablation study on ImageNet with different λ and p (exchange probability) trained for 300 epochs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Model Analysis</head><p>To estimate the robustness of the models trained with MoEx, we follow the procedure proposed by <ref type="bibr" target="#b19">[20]</ref> and evaluate our model on their ImageNet-A data set, which contains 7500 natural images (not originally part of Ima-geNet) that are misclassified by a publicly released ResNet-50 in torchvision. We compare our models with various publicly released pretrained models including Cutout <ref type="bibr" target="#b73">[74]</ref>, Mixup <ref type="bibr" target="#b73">[74]</ref>, CutMix <ref type="bibr" target="#b71">[72]</ref>, Shape-ResNet <ref type="bibr" target="#b11">[12]</ref>, and recently proposed AugMix <ref type="bibr" target="#b18">[19]</ref>. We report all 5 metrics implemented in the official evaluation code: model accuracy (Acc), root mean square calibration rrror (RMS), mean absolute distance calibration error (MAD), the area under the response rate accuracy curve (AURRA) and soft F1 <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b55">56]</ref>.  <ref type="table" target="#tab_7">Table 11</ref>. The performance of ResNet-50 variants on ImageNet-A. The up-arrow represents the higher the better, and vice versa.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Beyond Computer Vision</head><p>We also found that MoEx can be beneficial in other areas such as natural language processing and speech recognition. We use the Speech Command dataset <ref type="bibr" target="#b62">[63]</ref> which contains 65000 utterances (one second long) from thousands of people. The goal is to classify them in to 30 command words such as "Go", "Stop", etc. There are 56196, 7477, and 6835 examples for training, validation, and test. We use an open source implementation to encode each audio into a mel-spectrogram of size 1x32x32 and feeds it to 2D ConvNets as an one-channel input. We follow the default setup in the codebase training models with initial learning rate 0.01 with ADAM <ref type="bibr" target="#b30">[31]</ref>   In addition, please see Appendix for additional natural language processing results. In contrast to prior augmentation methods, which combine two images in pixel or feature space through linear or non-linear interpolation, MoEx extracts and injects (higher order) statistics about the features.Moments are a natural first choice, but other statistics are possible (e.g. principal components).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion and Future Work</head><p>In this paper we propose MoEx, a novel data augmentation algorithm for deep recognition models. Instead of disregarding the moments extracted by the (intra-instance) normalization layer, it forces the neural network to pay special attention towards them. We show empirically that this approach is consistently able to improve classification accuracy and robustness across many data sets, model architectures, and prediction tasks. As an augmentation method in feature space, MoEx is complementary to existing state-ofthe-art approaches and can be readily combined with them. Because of its ease of use and extremely simple implementation we hope that MoEx will be useful to many practitioners in computer vision, and beyond -in fact, anybody who trains discriminative deep networks with mini-batches. <ref type="table">Table 13</ref>. Machine translation with DynamicConv [64] on IWSLT-14 German to English, English to German, Italian to English, and English to Italian tasks. The mean and standard error are based on 3 random runs. † : numbers from <ref type="bibr" target="#b63">[64]</ref>. Note: for all these scores, the higher the better. layer. We apply the same set of hyper-parameters to the other three language pairs. When computing the moments, the edge paddings are ignored. We use two metrics to evaluate the models: BLEU <ref type="bibr" target="#b43">[44]</ref> which is a exact word-matching metric and scaled BERTScore F1 <ref type="bibr" target="#b74">[75]</ref>. <ref type="table">Table 13</ref> summarizes the average scores (higher better) with standard error rates over three runs. It shows that MoEx consistently improves the baseline model on all four tasks by about 0.2 BLEU and 0.2% BERT-F1. Although these improvements are not exorbitant, they are highly consistent and, as far as we know, MoEx is the first label-perturbing data augmentation method that improves machine translation models.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. More Examples of MoEx</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>PONO mean and std captures structural information.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>MoEx with PONO normalization. The features hA of the cat image are normalized and then infused with moments µ B , σB from the plane image. See Appendix for more examples.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4</head><label>4</label><figDesc>shows more examples of MoEx. We select top five features out of 64 channels to show here.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>MoEx with PONO normalization. The features of image A are normalized and then infused with moments µ B (PONO mean), σB (PONO std) from the image B.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 5 .</head><label>5</label><figDesc>Object detection on PASCAL VOC 2007 test set using Faster R-CNN whose backbone is initialized with different pretrained weights. We use either the original C4 or feature pyramid network<ref type="bibr" target="#b39">[40]</ref> backbone.</figDesc><table><row><cell cols="2">Backbone Initialization</cell><cell cols="2">APVOC APCOCO</cell></row><row><cell></cell><cell>ResNet-50 (default)</cell><cell>80.3</cell><cell>51.8</cell></row><row><cell>C4</cell><cell>ResNet-50 (300 epochs)</cell><cell>81.2</cell><cell>53.5</cell></row><row><cell></cell><cell>ResNet-50 + CutMix</cell><cell>82.1</cell><cell>54.3</cell></row><row><cell></cell><cell>ResNet-50 + MoEx</cell><cell>81.6</cell><cell>54.6</cell></row><row><cell></cell><cell>ResNet-50 (default)</cell><cell>81.8</cell><cell>53.8</cell></row><row><cell>FPN</cell><cell>ResNet-50 (300 epochs)</cell><cell>82.0</cell><cell>54.2</cell></row><row><cell></cell><cell>ResNet-50 + CutMix</cell><cell>82.1</cell><cell>54.3</cell></row><row><cell></cell><cell>ResNet-50 + MoEx</cell><cell>82.3</cell><cell>54.3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>former<ref type="bibr" target="#b60">[61]</ref>, etc. Beyond, for some other tasks we observe that using moments from IN can be more favorable (See Subsec. 4.4).</figDesc><table><row><cell cols="2">Moments to exchange</cell><cell></cell><cell>Test Error</cell></row><row><cell>No MoEx</cell><cell></cell><cell></cell><cell>26.3±0.10</cell></row><row><cell cols="4">All features in a layer, i.e. LN Feature in each channel, i.e. IN Features in Group of channels, i.e. GN (g=4) Features at each position, i.e. PONO 1st moment at each position 2nd moment at each position Unnormalized 2nd moment at each position, i.e. LRN 26.3±0.05 25.6±0.02 25.7±0.13 25.7±0.09 25.5±0.09 25.9±0.06 26.0±0.13</cell></row><row><cell cols="4">Table 8. MoEx with different normalization methods on CIFAR-</cell></row><row><cell>100.</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">Model Before Stage 1 Before Stage 2 Before Stage 3</cell></row><row><cell>LN</cell><cell>25.9 ± 0.08</cell><cell>25.9 ± 0.07</cell><cell>25.6 ± 0.02</cell></row><row><cell>IN</cell><cell>26.0 ± 0.13</cell><cell>25.7 ± 0.13</cell><cell>26.2 ± 0.13</cell></row><row><cell>GN</cell><cell>25.7 ± 0.09</cell><cell>26.1 ± 0.09</cell><cell>25.8 ± 0.13</cell></row><row><cell>PONO</cell><cell>25.5 ± 0.09</cell><cell>26.1 ± 0.03</cell><cell>26.0 ± 0.09</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 11</head><label>11</label><figDesc>summarizes all results. In general MoEx performs fairly well across the board. The combination of MoEx and Cutmix leads to the best performance on most of the metrics.</figDesc><table><row><cell>Name</cell><cell cols="5">Acc↑ RMS↓ MAD↓ AURRA↑ Soft F1↑</cell></row><row><cell>ResNet-50 (torchvision) Shape-ResNet AugMix Fast AutoAugment Cutout Mixup Cutmix</cell><cell>0 2.3 3.8 4.7 4.4 6.6 7.3</cell><cell>62.6 57.8 51.1 54.7 55.7 51.8 45.0</cell><cell>55.8 50.7 43.7 47.8 48.7 44.4 36.5</cell><cell>0 1.8 3.3 4.5 3.8 7.0 7.2</cell><cell>60.0 62.1 66.8 62.3 61.7 63.7 69.3</cell></row><row><cell>ResNet-50 (300 epochs) MoEx Cutmix + MoEx</cell><cell>4.2 5.5 7.9</cell><cell>54.0 43.2 42.6</cell><cell>46.8 34.2 34.3</cell><cell>3.9 5.7 8.5</cell><cell>63.7 72.9 70.5</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>for 70 epochs. The learning rate is reduce on plateau. We use the validation set for hyperparameter selection and tune MoEx p ∈ {0.25, 0.5, 0.75, 1} and λ ∈ {0.5, 0.9}. We test the proposed MoEx on three https://download.pytorch.org/models/resnet50-19c8e357.pth https://github.com/hendrycks/natural-adv-examples We attribute the Speech Command dataset to the Tensorflow team and AIY project: https://ai.googleblog.com/2017/08/launching-speechcommands-dataset.html https://github.com/tugstugi/pytorch-speech-commands baselines models: DenseNet-BC-100, VGG-11-BN, and WRN-28-10.Table 12displays the validation and test errors. We observe that training models with MoEx improve over the baselines significantly in all but one case. The only exception is DenseNet-BC-100, which has only 2% of the parameters of the wide ResNet, confirming the findings of Zhang et al.<ref type="bibr" target="#b73">[74]</ref> that on this data set data augmentation has little effect on tiny models.</figDesc><table><row><cell>Model</cell><cell cols="3"># Param Val Err Test Err</cell></row><row><cell>DenseNet-BC-100 +MoEx</cell><cell>0.8M 0.8M</cell><cell>3.16 2.97</cell><cell>3.23 3.31</cell></row><row><cell>VGG-11-BN +MoEx</cell><cell>28.2M 28.2M</cell><cell>3.05 2.76</cell><cell>3.38 3.00</cell></row><row><cell>WRN-28-10 +MoEx</cell><cell>36.5M 36.5M</cell><cell>2.42 2.22</cell><cell>2.21 1.98</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 12 .</head><label>12</label><figDesc>Speech classification on Speech Command. Similar to the observation of<ref type="bibr" target="#b73">[74]</ref>, regularization methods work better for models with large capacity on this dataset.</figDesc><table /><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This research is supported in part by the grants from Facebook, DARPA, the National Science Foundation (III-1618134, III-1526012, IIS1149882, IIS-1724282, and TRIPODS-1740822), the Office of Naval Research DOD (N00014-17-1-2175), Bill and Melinda Gates Foundation. We are thankful for generous support by Zillow and SAP 8 America Inc. Facebook has no collaboration with the other sponsors of this project. In particular, we appreciate the valuable discussion with Gao Huang.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. MoEx PyTorch Implementation</head><p>Algorithm 1 shows an example code of MoEx in Py-Torch <ref type="bibr" target="#b45">[46]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. MoEx for NLP</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1. Machine Translation on IWSLT 2014</head><p>To show the potential of MoEx on natural language processing (NLP) tasks, we apply MoEx to the state-of-theart DynamicConv [64] model on 4 tasks in a benchmarking dataset IWSLT 2014 <ref type="bibr" target="#b3">[4]</ref>: German to English, English to German, Italian to English, and English to Italian machine translation. IWSLT 2014 is based on the transcripts of TED talks and their translation, it contains 167K English and German sentence pairs and 175K English and Italian sentence pairs. We use fairseq library <ref type="bibr" target="#b42">[43]</ref> and follow the common setup [10] using 1/23 of the full training set as the validation set for hyper-parameter selection and early stopping. All models are trained with a batch size of 12000 tokens per GPU on 4 GPUs for 20K updates to ensure convergence; however, the models usually don't improve after 10K updates. We use the validation set to select the best model. We tune the hyperparameters of MoEx on the validation set of the German to English task including p ∈ {0.25, 0.5, 0.75, 1.0} and λ ∈ {0.4, 0.5, 0.6, 0.7, 0.8, 0.9} and use MoEx with Instan-ceNorm with p = 0.5 and λ = 0.8 after the first encoder </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><forename type="middle">Lei</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><forename type="middle">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.06450</idno>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">Layer normalization. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Understanding batch normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nils</forename><surname>Bjorck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carla</forename><forename type="middle">P</forename><surname>Gomes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Selman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Tagged back-translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isaac</forename><surname>Caswell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ciprian</forename><surname>Chelba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Grangier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WMT</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Report on the 11th iwslt evaluation campaign, iwslt 2014</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mauro</forename><surname>Cettolo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Niehues</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Stüker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luisa</forename><surname>Bentivogli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Workshop on Spoken Language Translation</title>
		<meeting>the International Workshop on Spoken Language Translation</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Autoaugment: Learning augmentation strategies from data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dandelion</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Mane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Randaugment</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.13719</idno>
		<title level="m">Practical data augmentation with no separate search</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Improved regularization of convolutional neural networks with cutout</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terrance</forename><surname>Devries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Taylor</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.04552</idno>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Understanding back-translation at scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Edunov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Grangier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="489" to="500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Classical structured prediction losses for sequence to sequence learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Edunov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Grangier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc&amp;apos;aurelio</forename><surname>Ranzato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Fast graph representation learning with PyTorch Geometric</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Fey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><forename type="middle">E</forename><surname>Lenssen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR Workshop on Representation Learning on Graphs and Manifolds</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Geirhos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patricia</forename><surname>Rubisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claudio</forename><surname>Michaelis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Bethge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wieland</forename><surname>Felix A Wichmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Brendel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.12231</idno>
		<title level="m">Imagenet-trained cnns are biased towards texture; increasing shape bias improves accuracy and robustness</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Dropblock: A regularization method for convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Golnaz</forename><surname>Ghiasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In NeurIPS</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Noordhuis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Wesolowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aapo</forename><surname>Kyrola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Tulloch</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.02677</idno>
		<title level="m">Yangqing Jia, and Kaiming He. Accurate, large minibatch sgd: Training imagenet in 1 hour</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A simple approximation for unbiased estimation of the standard deviation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Gurland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tripathi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The American Statistician</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="30" to="32" />
			<date type="published" when="1971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Deep pyramidal residual networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongyoon</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwhan</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junmo</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1512.03385</idno>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">AugMix: A simple data processing method to improve robustness and uncertainty. ICLR</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Norman</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balaji</forename><surname>Gilmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lakshminarayanan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Basart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Steinhardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawn</forename><surname>Song</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.07174</idno>
		<title level="m">Natural adversarial examples</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Squeeze-and-excitation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7132" to="7141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Densely connected convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Deep networks with stochastic depth</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Sedra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Arbitrary style transfer in real-time with adaptive instance normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xun</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Multimodal unsupervised image-to-image translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xun</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Yu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Kautz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.03167</idno>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Deep unordered composition rivals syntactic methods for text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Varun</forename><surname>Manjunatha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename><surname>Boyd-Graber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hal</forename><surname>Daumé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL-IJNLP</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Progressive growing of GANs for improved quality, stability, and variation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tero</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Aila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuli</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaakko</forename><surname>Lehtinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICLR</title>
		<imprint>
			<biblScope unit="issue">7</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A style-based generator architecture for generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tero</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuli</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Aila</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Towards understanding generalization via analytical learning theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenji</forename><surname>Kawaguchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vikas</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leslie</forename><forename type="middle">Pack</forename><surname>Kaelbling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.07426</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Auto-encoding variational bayes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6114</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Citeseer</title>
		<imprint>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Efficient backprop</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Orr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Muller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Networks: Tricks of the trade</title>
		<editor>G. Orr and Muller K.</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Kilian Q Weinberger, and Serge Belongie. Positional normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boyi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Sphering and its properties</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoying</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sankhyā: The Indian Journal of Statistics, Series A</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qihang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jieru</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cihang</forename><surname>Xie</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.05981</idno>
		<title level="m">Shapetexture debiased neural network training</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Fast autoaugment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungbin</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ildoo</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taesup</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chiheon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungwoong</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Kaiming He, Bharath Hariharan, and Serge Belongie. Feature pyramid networks for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Microsoft coco: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Sgdr: Stochastic gradient descent with warm restarts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1608.03983</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">fairseq: A fast, extensible toolkit for sequence modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Edunov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><surname>Baevski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Grangier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Bleu: a method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Jing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Semantic image synthesis with spatially-adaptive normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taesung</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Yu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting-Chun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Yan</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2337" to="2346" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Automatic differentiation in pytorch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Pointnet++: Deep hierarchical feature learning on point sets in a metric space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Charles Ruizhongtai Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guibas</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Faster r-cnn: Towards real-time object detection with region proposal networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>Shaoqing Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sun</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Normalized online learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephane</forename><surname>Ross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Mineiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Langford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">UAI</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">How does batch normalization help optimization?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shibani</forename><surname>Santurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><surname>Tsipras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Ilyas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksander</forename><surname>Madry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Incorporating invariances in support vector learning machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Burges</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICANN</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Improving neural machine translation models with monolingual data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06709</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Efficient pattern recognition using a new transformation distance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrice</forename><surname>Simard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">S</forename><surname>Denker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Best practices for convolutional neural networks applied to visual document analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Patrice</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dave</forename><surname>Simard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John C</forename><surname>Steinkraus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Platt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDAR</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Hide-and-seek: Forcing a network to be meticulous for weakly-supervised object and action localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krishna</forename><forename type="middle">Kumar</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><forename type="middle">Jae</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Beyond accuracy, f-score and roc: a family of discriminant measures for performance evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marina</forename><surname>Sokolova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathalie</forename><surname>Japkowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stan</forename><surname>Szpakowicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Australasian joint conference on artificial intelligence</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Rethinking the inception architecture for computer vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zbigniew</forename><surname>Wojna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Efficientnet: Rethinking model scaling for convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6105" to="6114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Ulyanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Lempitsky</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.08022</idno>
		<title level="m">stance normalization: The missing ingredient for fast stylization</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Learning with marginalized corrupted features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minmin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Tyree</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Łukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Implicit semantic data augmentation for deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuran</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiji</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pete</forename><surname>Warden</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.03209</idno>
		<title level="m">Speech commands: A dataset for limited-vocabulary speech recognition</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Pay less attention with lightweight and dynamic convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><surname>Baevski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Group normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kirillov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wan-Yen</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Detectron2</surname></persName>
		</author>
		<ptr target="https://github.com/facebookresearch/detectron2" />
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">3d shapenets: A deep representation for volumetric shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhirong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuran</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fisher</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linguang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxiong</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cihang</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boqing</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.09665</idno>
		<title level="m">Adversarial examples improve image recognition</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Aggregated residual transformations for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuowen</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshihiro</forename><surname>Yamada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masakazu</forename><surname>Iwamura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takuya</forename><surname>Akiba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koichi</forename><surname>Kise</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.02375</idno>
		<title level="m">Shakedrop regularization for deep residual learning</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<title level="m" type="main">Qanet: Combining local convolution with global self-attention for reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adams</forename><forename type="middle">Wei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Dohan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.09541</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Cutmix: Regularization strategy to train strong classifiers with localizable features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sangdoo</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongyoon</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanghyuk</forename><surname>Seong Joon Oh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junsuk</forename><surname>Chun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youngjoon</forename><surname>Choe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yoo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Zagoruyko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Komodakis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.07146</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">Wide residual networks. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">mixup: Beyond empirical risk minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moustapha</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yann N Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lopez-Paz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<title level="m" type="main">Bertscore: Evaluating text generation with bert</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Varsha</forename><surname>Kishore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Artzi</surname></persName>
		</author>
		<idno>ICLR, 2020. 12</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Random erasing data augmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhun</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoliang</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaozi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
