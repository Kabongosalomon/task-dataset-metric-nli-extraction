<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Neural Network Models for Paraphrase Identification, Semantic Textual Similarity, Natural Language Inference, and Question Answering</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wuwei</forename><surname>Lan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Ohio State University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Ohio State University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Neural Network Models for Paraphrase Identification, Semantic Textual Similarity, Natural Language Inference, and Question Answering</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T10:58+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we analyze several neural network designs (and their variations) for sentence pair modeling and compare their performance extensively across eight datasets, including paraphrase identification, semantic textual similarity, natural language inference, and question answering tasks. Although most of these models have claimed state-of-the-art performance, the original papers often reported on only one or two selected datasets. We provide a systematic study and show that (i) encoding contextual information by LSTM and inter-sentence interactions are critical, (ii) Tree-LSTM does not help as much as previously claimed but surprisingly improves performance on Twitter datasets, (iii) the Enhanced Sequential Inference Model (Chen et al., 2017) is the best so far for larger datasets, while the Pairwise Word Interaction Model (He and Lin, 2016) achieves the best performance when less data is available. We release our implementations as an open-source toolkit.</p><p>This work is licensed under a Creative Commons Attribution 4.0 International License. License details:</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Sentence pair modeling is a fundamental technique underlying many NLP tasks, including the following:</p><p>• Semantic Textual Similarity (STS), which measures the degree of equivalence in the underlying semantics of paired snippets of text <ref type="bibr" target="#b1">(Agirre et al., 2016)</ref>. • Paraphrase Identification (PI), which identifies whether two sentences express the same meaning <ref type="bibr" target="#b9">(Dolan and Brockett, 2005;</ref><ref type="bibr" target="#b38">Xu et al., 2015)</ref>. • Natural Language Inference (NLI), also known as recognizing textual entailment (RTE), which concerns whether a hypothesis can be inferred from a premise, requiring understanding of the semantic similarity between the hypothesis and the premise <ref type="bibr" target="#b8">(Dagan et al., 2006;</ref><ref type="bibr" target="#b2">Bowman et al., 2015)</ref>. • Question Answering (QA), which can be approximated as ranking candidate answer sentences or phrases based on their similarity to the original question <ref type="bibr" target="#b39">(Yang et al., 2015)</ref>. • Machine Comprehension (MC), which requires sentence matching between a passage and a question, pointing out the text region that contains the answer. <ref type="bibr" target="#b25">(Rajpurkar et al., 2016)</ref>.</p><p>Traditionally, researchers had to develop different methods specific for each task. Now neural networks can perform all the above tasks with the same architecture by training end to end. Various neural models <ref type="bibr" target="#b12">(He and Lin, 2016;</ref><ref type="bibr" target="#b23">Parikh et al., 2016;</ref><ref type="bibr" target="#b35">Wieting et al., 2016;</ref><ref type="bibr" target="#b30">Tomar et al., 2017;</ref><ref type="bibr" target="#b27">Shen et al., 2017a;</ref><ref type="bibr" target="#b40">Yin et al., 2016)</ref> have declared state-of-the-art results for sentence pair modeling tasks; however, they were carefully designed and evaluated on selected (often one or two) datasets that can demonstrate the superiority of the model. The research questions are as follows: Do they perform well on other tasks and datasets? How much performance gain is due to certain system design choices and hyperparameter optimizations?</p><p>To answer these questions and better understand different network designs, we systematically analyze and compare the state-of-the-art neural models across multiple tasks and multiple domains. Namely, we implement five models and their variations on the same PyTorch platform: InferSent model , Shortcut-stacked Sentence Encoder Model <ref type="bibr">(Nie and Bansal, 2017)</ref>, Pairwise Word Interaction Model <ref type="bibr" target="#b12">(He and Lin, 2016)</ref>, Decomposable Attention Model <ref type="bibr" target="#b23">(Parikh et al., 2016)</ref>, and Enhanced Sequential Inference Model . They are representative of the two most common approaches: sentence encoding models that learn vector representations of individual sentences and then calculate the semantic relationship between sentences based on vector distance and sentence pair interaction models that use some sorts of word alignment mechanisms (e.g., attention) then aggregate inter-sentence interactions. We focus on identifying important network designs and present a series of findings with quantitative measurements and in-depth analyses, including (i) incorporating inter-sentence interactions is critical; (ii) Tree-LSTM does not help as much as previously claimed but surprisingly improves performance on Twitter data; (iii) Enhanced Sequential Inference Model has the most consistent high performance for larger datasets, while Pairwise Word Interaction Model performs better on smaller datasets and Shortcut-Stacked Sentence Encoder Model is the best performaning model on the Quora corpus. We release our implementations as a toolkit to the research community. 1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">General Framework for Sentence Pair Modeling</head><p>Various neural networks have been proposed for sentence pair modeling, all of which fall into two types of approaches. The sentence encoding approach encodes each sentence into a fixed-length vector and then computes sentence similarity directly. The model of this type has advantages in the simplicity of the network design and generalization to other NLP tasks. The sentence pair interaction approach takes word alignment and interactions between the sentence pair into account and often show better performance when trained on in-domain data. Here we outline the two types of neural networks under the same general framework:</p><p>• The Input Embedding Layer takes vector representations of words as input, where pretrained word embeddings are most commonly used, e.g. GloVe  or Word2vec <ref type="bibr" target="#b21">(Mikolov et al., 2013)</ref>. Some work used embeddings specially trained on phrase or sentence pairs that are paraphrases <ref type="bibr" target="#b34">(Wieting and Gimpel, 2017;</ref><ref type="bibr" target="#b30">Tomar et al., 2017)</ref>; some used subword embeddings, which showed improvement on social media data <ref type="bibr" target="#b18">(Lan and Xu, 2018)</ref>.</p><p>• The Context Encoding Layer incorporates word context and sequence order into modeling for better vector representation. This layer often uses CNN <ref type="bibr" target="#b13">(He et al., 2015)</ref>, LSTM , recursive neural network <ref type="bibr" target="#b29">(Socher et al., 2011)</ref>, or highway network <ref type="bibr" target="#b11">(Gong et al., 2017)</ref>. The sentence encoding type of model will stop at this step, and directly use the encoded vectors to compute the semantic similarity through vector distances and/or the output classification layer.</p><p>• The Interaction and Attention Layer calculates word pair (or n-gram pair) interactions using the outputs of the encoding layer. This is the key component for the interaction-aggregation type of model. In the PWIM model <ref type="bibr" target="#b12">(He and Lin, 2016)</ref>, the interactions are calculated by cosine similarity, Euclidean distance, and the dot product of the vectors. Various models put different weights on different interactions, primarily simulating the word alignment between two sentences. The alignment information is useful for sentence pair modeling because the semantic relation between two sentences depends largely on the relations of aligned chunks as shown in the SemEval-2016 task of interpretable semantic textual similarity <ref type="bibr" target="#b1">(Agirre et al., 2016)</ref>.</p><p>• The Output Classification Layer adapts CNN or MLP to extract semantic-level features on the attentive alignment and applies softmax function to predict probability for each class.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">The Bi-LSTM Max-pooling Network (InferSent)</head><p>We choose the simple Bi-LSTM max-pooling network from InferSent :</p><formula xml:id="formula_0">← → h i = BiLST M (x i , ← → h i−1 ) (1) v = max( ← → h 1 , ← → h 2 , ..., ← → h n )<label>(2)</label></formula><p>where ← → h i represents the concatenation of hidden states in both directons. It has shown better transfer learning capabilities than several other sentence embedding models, including SkipThought <ref type="bibr" target="#b17">(Kiros et al., 2015)</ref> and FastSent <ref type="bibr" target="#b14">(Hill et al., 2016)</ref>, when trained on the natural language inference datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">The Shortcut-Stacked Sentence Encoder Model (SSE)</head><p>The Shortcut-Stacked Sentence Encoder model (Nie and Bansal, 2017) is a sentence-based embedding model, which enhances multi-layer Bi-LSTM with skip connection to avoid training error accumulation, and calculates each layer as follows:</p><formula xml:id="formula_1">← → h k i = BiLST M (x k i , ← → h k i−1 ) (3) x 1 i = w i (k = 1), x k i = [w i , ← → h k−1 i , ← → h k−2 i , ..., ← → h 1 i ] (k &gt; 1) (4) v = max( ← → h m 1 , ← → h m 2 , ..., ← → h m n )<label>(5)</label></formula><p>where x k i is the input of the kth Bi-LSTM layer at time step i, which is the combination of outputs from all previous layers, ← → h k i represents the hidden state of the kth Bi-LSTM layer in both directions. The final sentence embedding v is the row-based max pooling over the output of the last Bi-LSTM layer, where n denotes the number of words within a sentence and m is the number of Bi-LSTM layers (m = 3 in SSE).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">The Pairwise Word Interaction Model (PWIM)</head><p>In the Pairwise Word Interaction model <ref type="bibr" target="#b12">(He and Lin, 2016)</ref>, each word vector w i is encoded with context through forward and backward LSTMs:</p><formula xml:id="formula_2">− → h i = LST M f (w i , − → h i−1 ) and ← − h i = LST M b (w i , ← − h i+1 ).</formula><p>For every word pair (w a i , w b j ) across sentences, the model directly calculates word pair interactions using cosine similarity, Euclidean distance, and dot product over the outputs of the encoding layer:</p><formula xml:id="formula_3">D( − → h i , − → h j ) = [cos( − → h i , − → h j ), − → h i − − → h j , − → h i · − → h j ]<label>(6)</label></formula><p>The above equation not only applies to forward hidden state − → h i and backward hidden state</p><formula xml:id="formula_4">← − h i , but also to the concatenation ← → h i = [ − → h i , ← − h i ] and summation h + i = − → h i + ← − h i , resulting in a tensor D 13×|sent1|×|sent2|</formula><p>after padding one extra bias term. A "hard" attention is applied to the interaction tensor to build word alignment: selecting the most related word pairs and increasing the corresponding weights by 10 times. Then a 19-layer deep CNN is applied to aggregate the word interaction features for final classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">The Decomposable Attention Model (DecAtt)</head><p>The Decomposable Attention model <ref type="bibr" target="#b23">(Parikh et al., 2016)</ref> is one of the earliest models to introduce attentionbased alignment for sentence pair modeling, and it achieved state-of-the-art results on the SNLI dataset with about an order of magnitude fewer parameters than other models (see more in <ref type="table" target="#tab_7">Table 5</ref>) without relying on word order information. It computes the word pair interaction between w a i and w b j (from input sentences s a and s b , each with m and n words, respectively) as</p><formula xml:id="formula_5">e ij = F (w a i ) T F (w b j ),</formula><p>where F is a feedforward network; then alignment is determined as follows:</p><formula xml:id="formula_6">β i = n j=1 exp(e ij ) n k=1 exp(e ik ) w b j α j = m i=1 exp(e ij ) m k=1 exp(e kj ) w a i (7)</formula><p>where β i is the soft alignment between w a i and subphrases w b j in sentence s b , and vice versa for α j . The aligned phrases are fed into another feedforward network G:</p><formula xml:id="formula_7">v a i = G([w a i ; β i ]) and v b j = G([w b j ; α j ]) to generate sets {v a i } and {v b j },</formula><p>which are aggregated by summation and then concatenated together for classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">The Enhanced Sequential Inference Model (ESIM)</head><p>The Enhanced Sequential Inference Model  is closely related to the DecAtt model, but it differs in a few aspects. First,  demonstrated that using Bi-LSTM to encode sequential contexts is important for performance improvement. They used the concatenation</p><formula xml:id="formula_8">w i = ← → h i = [ − → h i , ← − h i ]</formula><p>of both directions as in the PWIM model. The word alignment β i and α j between w a and w b are calculated the same way as in DecAtt. Second, they showed the competitive performance of recursive architecture with constituency parsing, which complements with sequential LSTM. The feedforward function G in DecAtt is replaced with Tree-LSTM:</p><formula xml:id="formula_9">v a i = T reeLST M ([w a i ; β i ; w a i − β i ; w a i β i ]) (8) v b j = T reeLST M ([w b j ; α j ; w b j − α j ; w b j α j ])<label>(9)</label></formula><p>Third, instead of using summation in aggregation, ESIM adapts the average and max pooling and concate- </p><formula xml:id="formula_10">nation v = [v a ave ; v a max ; v b ave ; v b max ] before passing through multi-layer perceptron (MLP) for classification: v a ave = m i=1 v a i m , v a max = m max i=1 v a i , v b ave = n j=1 v b j n , v b max = n max j=1 v b j<label>(10)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments and Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets</head><p>We conducted sentence pair modeling experiments on eight popular datasets: two NLI datasets, three PI datasets, one STS dataset and two QA datasets. <ref type="table" target="#tab_3">Table 2</ref> gives a comparison of these datasets:</p><p>• SNLI <ref type="bibr" target="#b2">(Bowman et al., 2015)</ref> contains 570k hypotheses written by crowdsourcing workers given the premises. It focuses on three semantic relations: the premise entails the hypothesis (entailment), they contradict each other (contradiction), or they are unrelated (neutral). • Multi-NLI <ref type="bibr" target="#b36">(Williams et al., 2017)</ref> extends the SNLI corpus to multiple genres of written and spoken texts with 433k sentence pairs.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Implementation Details</head><p>We implement all the models with the same PyTorch framework. <ref type="bibr">23</ref> Below, we summarize the implementation details that are key for reproducing results for each model:</p><p>• SSE: This model can converge very fast, for example, 2 or 3 epochs for the SNLI dataset. We control the convergence speed by updating the learning rate for each epoch:</p><formula xml:id="formula_11">specifically, lr = 1 2 epoch i 2 * init lr,</formula><p>where init lr is the initial learning rate and epoch i is the index of current epoch.</p><p>• DecAtt: It is important to use gradient clipping for this model: for each gradient update, we check the L2 norm of all the gradient values, if it is greater than a threshold b, we scale the gradient by a factor α = b/L2 norm. Another useful procedure is to assemble batches of sentences with similar length.</p><p>• ESIM: Similar but different from DecAtt, ESIM batches sentences with varied length and uses masks to filter out padding information. In order to batch the parse trees within Tree-LSTM recursion, we follow <ref type="bibr">Bowman et al.'s (2016)</ref> procedure that converts tree structures into the linear sequential structure of a shift reduce parser. Two additional masks are used for producing left and right children of a tree node. • PWIM: The cosine and Euclidean distances used in the word interaction layer have smaller values for similar vectors while dot products have larger values. The performance increases if we add a negative sign to make all the vector similarity measurements behave consistently. <ref type="table" target="#tab_5">Table 3</ref> and 4 show the results reported in the original papers and the replicated results with our implementation. We use accuracy, F1 score, Pearson's r, Mean Average Precision (MAP), and Mean Reciprocal Rank (MRR) for evaluation on different datasets following the literature. Our reproduced results are slightly lower than the original results by 0.5 ∼ 1.5 points on accuracy. We suspect the following potential reasons: (i) less extensive hyperparameter tuning for each individual dataset; (ii) only one run with random seeding to report results; and (iii) use of different neural network toolkits: for example, the original ESIM model was implemented with Theano, and PWIM model was in Torch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Re-implementation Results vs. Previously Reported Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Effects of Model Components</head><p>Herein, we examine the main components that account for performance in sentence pair modeling.</p><p>How important is LSTM encoded context information for sentence pair modeling? Regarding DecAtt, <ref type="bibr" target="#b23">Parikh et al. (2016)</ref> mentioned that "intra-sentence attention is optional"; they can achieve competitive results without considering context information. However, not surprisingly, our experiments consistently show that encoding sequential context information with LSTM is critical. Compared to DecAtt, ESIM shows better performance on every dataset (see <ref type="table">Table 4</ref> and <ref type="figure">Figure 3</ref>). The main difference between ESIM and DecAtt that contributes to performance improvement, we found, is the use of Bi-LSTM and Tree-LSTM for sentence encoding, rather than the different choices of aggregation functions.</p><p>Why does Tree-LSTM help with Twitter data?  offered a simple combination (ESIM seq+tree ) by averaging the prediction probabilities of two ESIM variants that use sequential Bi-LSTM and Tree-LSTM respectively, and suggested "parsing information complements very well with ESIM and further improves the performance". However, we found that adding Tree-LSTM only helps slightly or not at all for most datasets, but it helps noticably with the two Twitter paraphrase datasets. We hypothesize the reason is that these two datasets come from real-world tweets which often contain extraneous text fragments, in contrast to SNLI and other datasets that have sentences written by crowdsourcing workers. For example, the segment "ever wondered ," in the sentence pair ever wondered , why your recorded #voice sounds weird to you? and why do our recorded voices sound so weird to us? introduces a disruptive context into the Bi-LSTM encoder, while Tree-LSTM can put it in a less important position after constituency parsing.</p><p>How important is attentive interaction for sentence pair modeling? Why does SSE excel on Quora? Both ESIM and DecAtt (Eq. 7) calculate an attention-based soft alignment between a sentence pair, which was also proposed in <ref type="bibr">(Rocktäschel et al., 2016)</ref> and <ref type="bibr" target="#b31">(Wang and Jiang, 2017)</ref> for sentence pair modeling, whereas PWIM utilizes a hard attention mechanism. Both attention strategies are critical for model performance. In PWIM model <ref type="bibr" target="#b12">(He and Lin, 2016)</ref>, we observed a 1∼2 point performance drop after   <ref type="table">Table 4</ref>: Replicated results with our reimplementation in PyTorch across multiple tasks and datasets. The best result in each dataset is denoted by a bold typeface, and the second best is denoted by an underline.</p><p>removing the hard attention, 0∼3 point performance drop and ∼25% training time reduction after removing the 19-layer CNN aggregation. Likely without even the authors of SSE knowing, the SSE model performs extraordinarily well on the Quora corpus, perhaps because Quora contains many sentence pairs with less complicated inter-sentence interactions (e.g., many identical words in the two sentences) and incorrect ground truth labels (e.g., What is your biggest regret in life? and What's the biggest regret you've had in life? are labeled as non-duplicate questions by mistake). <ref type="figure">Figure 3</ref> shows the learning curves. The DecAtt model converges quickly and performs well on large NLI datasets due to its design simplicity. PWIM is the slowest model (see time comparison in <ref type="table" target="#tab_7">Table 5</ref>) but shows very strong performance on semantic similarity and paraphrase identification datasets. ESIM and SSE keep a good balance between training time and performance.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.3">Learning Curves and Training Time</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.4">Effects of Training Data Size</head><p>As shown in <ref type="figure">Figure 4</ref>, we experimented with different training sizes of the largest SNLI dataset. All the models show improved performance as we increase the training size. ESIM and SSE have very similar trends and clearly outperform PWIM on the SNLI dataset. DecAtt shows a performance jump when the training size exceeds a threshold.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.5">Categorical Performance Comparison</head><p>We conducted an in-depth analysis of model performance on the Multi-domain NLI dataset based on different categories: text genre, sentence pair overlap, and sentence length. As shown in <ref type="table">Table 7</ref>, all models have comparable performance between matched genre and unmatched genre. Sentence length and overlap turn out to be two important factors -the longer the sentences and the fewer tokens in common, the more challenging it is to determine their semantic relationship. These phenomena shared by the state-of-the-art systems reflect their similar design framework which is symmetric at processing both sentences in the pair, while question answering and natural language inference tasks are directional <ref type="bibr" target="#b10">(Ghaeini et al., 2018)</ref>. How to incorporate asymmetry into model design will be worth more exploration in future research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.6">Transfer Learning Experiments</head><p>In addition to the cross-domain study <ref type="table">(Table 7)</ref>, we conducted transfer learning experiments on three paraphrase identification datasets <ref type="table" target="#tab_9">(Table 6</ref>). The most noteworthy phenomenon is that the SSE model performs better on Twitter-URL and PIT-2015 when trained on the large out-of-domain Quora data than the small in-domain training data. Two likely reasons are: (i) the SSE model with over 29 million parameters is data hungry and (ii) SSE model is a sentence encoding model, which generalizes better across domains/tasks than sentence pair interaction models. Sentence pair interaction models may encounter difficulties on Quora, which contains sentence pairs with the highest word overlap (51.5%) among all datasets and often causes   <ref type="table">Table 7</ref>: Categorical performance (accuracy) on Multi-NLI dataset. Overlap is the percentage of shared tokens between two sentences. Length is calculated based on the number of tokens of the longer sentence.</p><p>the interaction patterns to focus on a few key words that differ. In contrast, the Twitter-URL dataset has the lowest overlap (23.0%) with a semantic relationship that is mainly based on the intention of the tweets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We analyzed five different neural models (and their variations) for sentence pair modeling and conducted a series of experiments with eight representative datasets for different NLP tasks. We quantified the importance of the LSTM encoder and attentive alignment for inter-sentence interaction, as well as the transfer learning ability of sentence encoding based models. We showed that the SNLI corpus of over 550k sentence pairs cannot saturate the learning curve. We systematically compared the strengths and weaknesses of different network designs and provided insights for future work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Sentence encoding models focus on learning vector representations of individual sentences and then calculate the semantic relationship between sentences based on vector distance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Sentence pair interaction models use different word alignment mechanisms before aggregation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>•</head><label></label><figDesc>Quora<ref type="bibr" target="#b16">(Iyer et al., 2017)</ref> contains 400k question pairs collected from the Quora website. This dataset has balanced positive and negative labels indicating whether the questions are duplicated or not.• Twitter-URL includes 50k sentence pairs collected from tweets that share the same URL of news articles. This dataset contains both formal and informal language. • PIT-2015<ref type="bibr" target="#b38">(Xu et al., 2015)</ref> comes from SemEval-2015 and was collected from tweets under the same trending topic. It contains naturally occurred (i.e. written by independent Twitter users spontaneously) paraphrases and non-paraphrases with varied topics and language styles. • STS-2014 (Agirre et al., 2014) is from SemEval-2014, constructed from image descriptions, news headlines, tweet news, discussion forums, and OntoNotes<ref type="bibr" target="#b15">(Hovy et al., 2006)</ref>.• WikiQA (<ref type="bibr" target="#b39">Yang et al., 2015)</ref> is an open-domain question-answering dataset. Following<ref type="bibr" target="#b12">He and Lin (2016)</ref>, questions without correct candidate answer sentences are excluded, and answer sentences are truncated to 40 tokens, resulting in 12k question-answer pairs for our experiments. • TrecQA<ref type="bibr" target="#b32">(Wang et al., 2007</ref>) is an answer selection task of 56k question-answer pairs and created in Text Retrieval Conferences (TREC). For both WikiQA and TrecQA datasets, the best answer is selected according to the semantic relatedness with the question.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>gives a summary of typical models for sentence pair modeling in recent years. In particular, we investigate five models in depth: two are representative of the sentence encoding type of model, and three are representative of the interaction-aggregation type of model. These models have reported state-or-the-art results with varied architecture design (this section) and implementation details (Section 4.2).</figDesc><table><row><cell>Models</cell><cell>Sentence Encoder</cell><cell>Interaction and Attention</cell><cell>Aggregation and Classification</cell></row><row><cell>(Shen et al., 2017b)</cell><cell>Directional self-attention network</cell><cell>-</cell><cell>MLP</cell></row><row><cell>(Choi et al., 2017)</cell><cell>Gumbel Tree-LSTM</cell><cell>-</cell><cell>MLP</cell></row><row><cell>(Wieting and Gimpel, 2017)</cell><cell>Gated recurrent average network</cell><cell>-</cell><cell>MLP</cell></row><row><cell>SSE (Nie and Bansal, 2017)</cell><cell>Shortcut-stacked BiLSTM</cell><cell>-</cell><cell>MLP</cell></row><row><cell>(He et al., 2015)</cell><cell>CNN</cell><cell>multi-perspective matching</cell><cell>pooling + MLP</cell></row><row><cell>(Rocktäschel et al., 2016)</cell><cell>LSTM</cell><cell>word-by-word neural attention</cell><cell>MLP</cell></row><row><cell></cell><cell></cell><cell></cell><cell>dynamic pooling +</cell></row><row><cell>(Liu et al., 2016)</cell><cell>LSTM</cell><cell>coupled LSTMs</cell><cell>MLP</cell></row><row><cell>(Yin et al., 2016)</cell><cell>CNN</cell><cell>attention matrix</cell><cell>logistic regression</cell></row><row><cell>DecAtt (Parikh et al., 2016)</cell><cell>-</cell><cell>dot product + soft alignment</cell><cell>summation + MLP</cell></row><row><cell>PWIM (He and Lin, 2016)</cell><cell>BiLSTM</cell><cell>+ hard alignment cosine, Euclidean, dot product</cell><cell>CNN + MLP</cell></row><row><cell>(Wang and Jiang, 2017)</cell><cell>LSTM encodes both context and attention</cell><cell>word-by-word neural attention</cell><cell>MLP</cell></row><row><cell>ESIM (Chen et al., 2017)</cell><cell>BiLSTM (Tree-LSTM) before and after attention</cell><cell>dot product + soft alignment</cell><cell>average and max pooling + MLP</cell></row><row><cell>(Wang et al., 2017)</cell><cell>BiLSTM</cell><cell>multi-perspective matching</cell><cell>BiLSTM + MLP</cell></row><row><cell>(Shen et al., 2017a)</cell><cell>BiLSTM + intra-attention</cell><cell>decomposition soft alignment + orthogonal</cell><cell>MLP</cell></row><row><cell>(Ghaeini et al., 2018)</cell><cell>dependent reading BiLSTM</cell><cell>dot product + soft alignment</cell><cell>average and max pooling+MLP</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table /><note>Summary of representative neural models for sentence pair modeling. The upper half contains sentence encoding models, and the lower half contains sentence pair interaction models.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Two men on bicycles competing in a race. entailment dev 10,000 s b : Men are riding bicycles on the street.</figDesc><table><row><cell>Dataset</cell><cell>Size</cell><cell>Example and Label</cell><cell></cell></row><row><cell>SNLI</cell><cell>train 550,152</cell><cell cols="2">sa: neutral</cell></row><row><cell></cell><cell>test 10,000</cell><cell></cell><cell>contradict</cell></row><row><cell>Multi-NLI</cell><cell>train 392,703 dev 20,000 test 20,000</cell><cell>sa: The Old One always comforted Ca'daan, except today. s b : Ca'daan knew the Old One very well.</cell><cell>entailment neutral contradict</cell></row><row><cell>Quora</cell><cell>train 384,348 dev 10,000 test 10,000</cell><cell>sa: What should I do to avoid sleeping in class? s b : How do I not sleep in a boring class?</cell><cell>paraphrase non-paraphrase</cell></row><row><cell>Twitter-URL</cell><cell>train 42,200 dev -test 9,324</cell><cell cols="2">sa: Letter warned Wells Fargo of "widespread" fraud in 2007. paraphrase s b : Letters suggest Wells Fargo scandal started earlier. non-paraphrase</cell></row><row><cell>PIT-2015</cell><cell>train 11,530 dev 4,142 test 838</cell><cell>sa: Ezekiel Ansah w the 3D shades Popped out lens s b : Ezekiel Ansah was wearing lens less 3D glasses</cell><cell>paraphrase non-paraphrase</cell></row><row><cell>STS-2014</cell><cell>train 7,592 dev -test 3,750</cell><cell>sa: Then perhaps we could have avoided a catastrophe. s b : Then we might have been able to avoid a disaster.</cell><cell>score [0, 5] 4.6</cell></row><row><cell>WikiQA</cell><cell>train 8,672 dev 1,130 test 2,351</cell><cell>sa: How much is 1 tablespoon of water? s b : In Australia one tablespoon (measurement unit) is 20 mL.</cell><cell>true false</cell></row><row><cell>TrecQA</cell><cell>train 53,417 dev 1,148 test 1,517</cell><cell>sa: Who was Lincoln's Secretary of State? s b : William Seward</cell><cell>true false</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table /><note>Basic statistics and examples of different datasets for sentence pair modeling tasks.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>Reported results from original papers, which are mostly limited to a few datasets. For the Multi-NLI dataset, Acc m represents testing accuracy for the matched genre and Acc um for the unmatched genre.</figDesc><table><row><cell>Model</cell><cell>SNLI</cell><cell>Multi-NLI</cell><cell>Quora</cell><cell>Twitter-URL</cell><cell>PIT-2015</cell><cell>STS-2014</cell><cell>WikiQA</cell><cell>TrecQA</cell></row><row><cell></cell><cell>Acc</cell><cell cols="2">Acc m/Acc um Acc</cell><cell>F1</cell><cell>F1</cell><cell>r</cell><cell cols="2">MAP/MRR MAP/MRR</cell></row><row><cell>InferSent</cell><cell>0.846</cell><cell>0.705/0.703</cell><cell>0.866</cell><cell>0.746</cell><cell>0.451</cell><cell>0.715</cell><cell cols="2">0.287/0.287 0.521/0.559</cell></row><row><cell>SSE</cell><cell>0.855</cell><cell>0.740/0.734</cell><cell>0.878</cell><cell>0.650</cell><cell>0.422</cell><cell>0.378</cell><cell cols="2">0.624/0.638 0.628/0.670</cell></row><row><cell>DecAtt</cell><cell>0.856</cell><cell>0.719/0.713</cell><cell>0.845</cell><cell>0.652</cell><cell>0.430</cell><cell>0.317</cell><cell cols="2">0.603/0.619 0.660/0.712</cell></row><row><cell>ESIMtree</cell><cell>0.864</cell><cell>0.736/0.727</cell><cell>0.755</cell><cell>0.740</cell><cell>0.447</cell><cell>0.493</cell><cell cols="2">0.618/0.633 0.698/0.734</cell></row><row><cell>ESIMseq</cell><cell>0.870</cell><cell>0.752/0.738</cell><cell>0.850</cell><cell>0.748</cell><cell>0.520</cell><cell>0.602</cell><cell cols="2">0.652/0.664 0.771/0.795</cell></row><row><cell cols="2">ESIMseq+tree 0.871</cell><cell>0.753/0.748</cell><cell>0.854</cell><cell>0.759</cell><cell>0.538</cell><cell>0.589</cell><cell cols="2">0.647/0.658 0.749/0.768</cell></row><row><cell>PWIM</cell><cell>0.822</cell><cell>0.722/0.716</cell><cell>0.834</cell><cell>0.761</cell><cell>0.656</cell><cell>0.743</cell><cell cols="2">0.706/0.723 0.739/0.795</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>Training curves of ESIM, DecAtt, PWIM, SSE and InferSent models on eight datasets.</figDesc><table><row><cell cols="2">Figure 3: InferSent</cell><cell>SSE</cell><cell>DecAtt</cell><cell cols="2">ESIMseq ESIMtree</cell><cell>PWIM</cell></row><row><cell>Number of parameters</cell><cell>47M</cell><cell>140M</cell><cell>380K</cell><cell>4.3M</cell><cell>7.7M</cell><cell>2.2M</cell></row><row><cell>Avg epoch time (seconds) / sentence pair</cell><cell>0.005</cell><cell>0.032</cell><cell>0.0006</cell><cell>0.013</cell><cell>0.016</cell><cell>0.60</cell></row><row><cell>Ratio compared to DecAtt model</cell><cell>×8</cell><cell>×53</cell><cell>1</cell><cell>×22</cell><cell>×26</cell><cell>×1000</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 :</head><label>5</label><figDesc>Average training time per sentence pair in the Twitter-URL dataset (similar time for other datasets).</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 6 :</head><label>6</label><figDesc>Transfer learning experiments for paraphrase identification task.</figDesc><table><row><cell></cell><cell>Category</cell><cell>#Examples</cell><cell>InferSent</cell><cell>SSE</cell><cell>DecAtt</cell><cell>ESIMseq</cell><cell>PWIM</cell></row><row><cell></cell><cell>Fiction</cell><cell>1973</cell><cell>0.703</cell><cell>0.727</cell><cell>0.706</cell><cell>0.742</cell><cell>0.707</cell></row><row><cell>Matched Genre</cell><cell>Government Slate Telephone</cell><cell>1945 1955 1966</cell><cell>0.753 0.653 0.718</cell><cell>0.746 0.670 0.728</cell><cell>0.743 0.671 0.717</cell><cell>0.790 0.697 0.753</cell><cell>0.751 0.670 0.709</cell></row><row><cell></cell><cell>Travel</cell><cell>1976</cell><cell>0.705</cell><cell>0.701</cell><cell>0.733</cell><cell>0.752</cell><cell>0.714</cell></row><row><cell></cell><cell>9/11</cell><cell>1974</cell><cell>0.685</cell><cell>0.710</cell><cell>0.699</cell><cell>0.737</cell><cell>0.711</cell></row><row><cell>Mismatched Genre</cell><cell>Face-to-face Letters OUP</cell><cell>1974 1977 1961</cell><cell>0.713 0.734 0.698</cell><cell>0.729 0.757 0.715</cell><cell>0.720 0.754 0.719</cell><cell>0.761 0.775 0.759</cell><cell>0.710 0.757 0.710</cell></row><row><cell></cell><cell>Verbatim</cell><cell>1946</cell><cell>0.691</cell><cell>0.701</cell><cell>0.709</cell><cell>0.725</cell><cell>0.713</cell></row><row><cell></cell><cell>&gt;60%</cell><cell>488</cell><cell>0.756</cell><cell>0.795</cell><cell>0.805</cell><cell>0.842</cell><cell>0.811</cell></row><row><cell>Overlap</cell><cell>30% ∼ 60%</cell><cell>3225</cell><cell>0.740</cell><cell>0.751</cell><cell>0.745</cell><cell>0.769</cell><cell>0.743</cell></row><row><cell></cell><cell>&lt;30%</cell><cell>6102</cell><cell>0.685</cell><cell>0.689</cell><cell>0.691</cell><cell>0.727</cell><cell>0.682</cell></row><row><cell></cell><cell>&gt;20 tokens</cell><cell>3730</cell><cell>0.692</cell><cell>0.676</cell><cell>0.685</cell><cell>0.731</cell><cell>0.694</cell></row><row><cell>Length</cell><cell>10∼20 tokens</cell><cell>3673</cell><cell>0.712</cell><cell>0.725</cell><cell>0.721</cell><cell>0.753</cell><cell>0.720</cell></row><row><cell></cell><cell>&lt;10 tokens</cell><cell>2412</cell><cell>0.721</cell><cell>0.758</cell><cell>0.748</cell><cell>0.762</cell><cell>0.724</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">The code is available on the authors' homepages and GitHub: https://github.com/lanwuwei/SPM_toolkit</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">InferSent and SSE have open-source PyTorch implementations by the original authors, for which we reused part of the code. 3 Our code is available at: https://github.com/lanwuwei/SPM_toolkit</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">This number was reported in<ref type="bibr" target="#b30">(Tomar et al., 2017)</ref> by co-authors of DecAtt<ref type="bibr" target="#b23">(Parikh et al., 2016)</ref>. 4 This number was reproduced by<ref type="bibr" target="#b36">Williams et al. (2017)</ref>. 5 This number was generated by InferSent traind on SNLI and Multi-NLI datasets.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We thank Ohio Supercomputer Center (Center, 2012) for computing resources. This work was supported in part by NSF CRII award (RI-1755898) and DARPA through the ARO (W911NF-17-C-0095). The content of the information in this document does not necessarily reflect the position or the policy of the U.S. Government, and no official endorsement should be inferred.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Fine-tuning the Models</head><p>It is not practical to fine tune every hyper-parameter in every model and every dataset, since we want to show how these models can generalize well on other datasets, we need try to avoid fine-tuning these parameters on some specific datasets, otherwise we can easily get over-fitted models. Therefore, we keep the hyperparameters unchanged across different datasets, to demonstrate the generalization capability of each model. The default number of epochs for training these models is set to 20, if some models could converge earlier (no more performance gain on development set), we would stop running them before they approached epoch 20. The 20 epochs can guarantee every model get converged on every dataset.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Semeval-2014 task 10: Multilingual semantic textual similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>References [agirre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th International Workshop on Semantic Evaluation</title>
		<meeting>the 8th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Semeval-2016 task 2: Interpretable semantic textual similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agirre</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval)</title>
		<meeting>the 10th International Workshop on Semantic Evaluation (SemEval)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A large annotated corpus for learning natural language inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Bowman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>EMNLP</publisher>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A fast unified model for parsing and sentence understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Bowman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Oakley supercomputer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ohio Supercomputer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Center</surname></persName>
		</author>
		<ptr target="http://osc.edu/ark:/19495/hpc0cvqn" />
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Enhanced LSTM for natural language inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Unsupervised learning of task-specific tree structures with tree-LSTMs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Choi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.02786</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Supervised learning of universal sentence representations from natural language inference data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Conneau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>EMNLP</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The PASCAL recognising textual entailment challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dagan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First International Conference on Machine Learning Challenges: Evaluating Predictive Uncertainty Visual Object Classification, and Recognizing Textual Entailment</title>
		<meeting>the First International Conference on Machine Learning Challenges: Evaluating Predictive Uncertainty Visual Object Classification, and Recognizing Textual Entailment</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Automatically constructing a corpus of sentential paraphrases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brockett2005]</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>William</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Brockett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third International Workshop on Paraphrasing (IWP)</title>
		<meeting>the Third International Workshop on Paraphrasing (IWP)</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">DR-BiLSTM: Dependent reading bidirectional LSTM for natural language inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Ghaeini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Gong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.04348</idno>
		<title level="m">Natural language inference over interaction space</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Pairwise word interaction modeling with deep neural networks for semantic similarity measurement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin2016] Hua</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Multi-perspective sentence similarity modeling with convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>EMNLP</publisher>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>Hua He, Kevin Gimpel, and Jimmy Lin</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Learning distributed representations of sentences from unlabelled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Hill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Ontonotes: The 90% solution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL (NAACL)</title>
		<meeting>the Human Language Technology Conference of the North American Chapter of the ACL (NAACL)</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Shankar Iyer, Nikhil Dandekar, and Kornl Csernai</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Iyer</surname></persName>
		</author>
		<ptr target="https://data.quora.com/First-Quora-Dataset-Release-Question-Pairs" />
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>First Quora Dataset Release: Question Pairs</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Antonio Torralba, and Sanja Fidler. 2015. Skip-thought vectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Kiros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The importance of subword embeddings in sentence pair modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu2018] Wuwei</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A continuously growing dataset of sentential paraphrases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 2017 Conference on Empirical Methods on Natural Language Processing (EMNLP)</title>
		<meeting>The 2017 Conference on Empirical Methods on Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Modelling interaction of sentence pair with coupled-LSTMs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>Pengfei Liu, Xipeng Qiu, and Xuanjing Huang</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Shortcut-stacked sentence encoders for multi-domain inference</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Evaluating Vector Space Representations for NLP</title>
		<meeting>the 2nd Workshop on Evaluating Vector Space Representations for NLP</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A decomposable attention model for natural language inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankur</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oscar</forename><surname>Täckström</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>EMNLP</publisher>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>Parikh et al.2016</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">GloVe: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pennington</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>EMNLP</publisher>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">SQuAD: 100,000+ questions for machine comprehension of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantin</forename><surname>Lopyrev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>EMNLP</publisher>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>Rajpurkar et al.2016</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Reasoning about entailment with neural attention</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations</title>
		<editor>Tim Rocktäschel, Edward Grefenstette, Karl Moritz Hermann, Tomáš Kočiskỳ, and Phil Blunsom</editor>
		<meeting>the International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>Rocktäschel et al.2016. ICLR</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Inter-weighted alignment network for sentence pair modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Disan: Directional self-attention network for RNN/CNN-free language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Association for the Advancement of Artificial Intelligence (AAAI)</title>
		<meeting>the Association for the Advancement of Artificial Intelligence (AAAI)</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Parsing natural scenes and natural language with recursive neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Socher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Machine Learning (ICML)</title>
		<meeting>the 28th International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Neural paraphrase identification of questions with noisy pretraining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Tomar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Subword and Character Level Models in NLP</title>
		<meeting>the First Workshop on Subword and Character Level Models in NLP</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A compare-aggregate model for matching text sequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuohang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR</title>
		<meeting>the International Conference on Learning Representations (ICLR</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">What is the Jeopardy model? A quasi-synchronous grammar for qa</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL)</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Bilateral multi-perspective matching for natural language sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence (IJCAI)</title>
		<meeting>the Twenty-Sixth International Joint Conference on Artificial Intelligence (IJCAI)</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Revisiting recurrent networks for paraphrastic sentence embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Wieting</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Wieting and Gimpel2017</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Towards universal paraphrastic sentence embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Wieting</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th International Conference on Learning Representations (ICLR</title>
		<meeting>the 4th International Conference on Learning Representations (ICLR</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">A broad-coverage challenge corpus for sentence understanding through inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Williams</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.05426</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Extracting lexically divergent paraphrases from Twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2014" />
			<publisher>TACL</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">SemEval-2015 Task 1: Paraphrase and semantic similarity in Twitter (PIT)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval)</title>
		<meeting>the 9th International Workshop on Semantic Evaluation (SemEval)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">WikiQA: A challenge dataset for open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>EMNLP</publisher>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">ABCNN: Attention-based convolutional neural network for modeling sentence pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2016" />
			<publisher>TACL</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">2015) datasets, and the 300-dimensional GloVe vectors, trained on 840 billion words (vocabulary size of 2.2 milion words) from Common Crawl for all other datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pennington</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Appendices A Pretrained Word Embeddings We used the 200-dimensional GloVe word vectors</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page">2015</biblScope>
		</imprint>
	</monogr>
	<note>trained on 27 billion words from Twitter (vocabulary size of 1.2 milion words) for Twitter URL. For out-of-vocabulary words, we initialized</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">2017) both use Bi-LSTM for context encoding, having 200 hidden units and 300 hidden units respectively. The DecAtt model (Parikh et al., 2016) uses three kinds of feed forward networks, all of which have 300 hidden units. Other parameters like learning rate, batch size</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Conneau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The fully connected layers have 1600 units. PWIM (He and Lin, 2016) and ESIM</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>the hidden dimension size for Bi-LSTM is 2048, and the fully connected layers have 512 hidden units. dropout rate, and all of them use the same settings as in original papers</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
