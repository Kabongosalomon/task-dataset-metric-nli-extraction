<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Deep Density-based Image Clustering</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yazhou</forename><surname>Ren</surname></persName>
							<email>yazhou.ren@uestc.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="laboratory">SMILE Lab</orgName>
								<orgName type="institution">University of Electronic Science and Technology of China</orgName>
								<address>
									<postCode>611731</postCode>
									<settlement>Chengdu</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ni</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="laboratory">SMILE Lab</orgName>
								<orgName type="institution">University of Electronic Science and Technology of China</orgName>
								<address>
									<postCode>611731</postCode>
									<settlement>Chengdu</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxia</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="laboratory">SMILE Lab</orgName>
								<orgName type="institution">University of Electronic Science and Technology of China</orgName>
								<address>
									<postCode>611731</postCode>
									<settlement>Chengdu</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zenglin</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="laboratory">SMILE Lab</orgName>
								<orgName type="institution">University of Electronic Science and Technology of China</orgName>
								<address>
									<postCode>611731</postCode>
									<settlement>Chengdu</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Deep Density-based Image Clustering</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T05:44+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recently, deep clustering, which is able to perform feature learning that favors clustering tasks via deep neural networks, has achieved remarkable performance in image clustering applications. However, the existing deep clustering algorithms generally need the number of clusters in advance, which is usually unknown in real-world tasks. In addition, the initial cluster centers in the learned feature space are generated by k-means. This only works well on spherical clusters and probably leads to unstable clustering results. In this paper, we propose a two-stage deep densitybased image clustering (DDC) framework to address these issues. The first stage is to train a deep convolutional autoencoder (CAE) to extract low-dimensional feature representations from high-dimensional image data, and then apply t-SNE to further reduce the data to a 2-dimensional space favoring density-based clustering algorithms. The second stage is to apply the developed density-based clustering technique on the 2-dimensional embedded data to automatically recognize an appropriate number of clusters with arbitrary shapes. Concretely, a number of local clusters are generated to capture the local structures of clusters, and then are merged via their density relationship to form the final clustering result. Experiments demonstrate that the proposed DDC achieves comparable or even better clustering performance than state-of-the-art deep clustering methods, even though the number of clusters is not given.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Image clustering is one of the extensively exploited topics in computer vision and has many applications in a wide range of fields, including image retrieval <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b40">40]</ref> and annotation <ref type="bibr" target="#b17">[18]</ref>. It seeks to partition images into clusters according to a similarity measure, such that similar images are grouped in the same cluster and images which are dissimilar from each other are grouped into different clusters. A number of traditional clustering methods have been pro-posed in the past decades, such as partitional clustering (e.g., k-means <ref type="bibr" target="#b22">[23]</ref>), hierarchical clustering <ref type="bibr" target="#b16">[17]</ref>, densitybased clustering (e.g., DBSCAN <ref type="bibr" target="#b10">[11]</ref>, mean shift clustering <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b28">28]</ref>), distribution-based clustering (e.g., Gaussian mixture model <ref type="bibr" target="#b4">[5]</ref>), etc. These methods typically fail to clustering image data sets which are with high dimensionality. The main reason is that reliable similarity measures are hard to obtain in the high dimensional space.</p><p>To mitigate this issue, a normal method is to first reduce the dimensionality of data via feature selection or feature extraction techniques, and then conduct clustering in the lower dimensional space. Another way is to consider clustering and feature learning together in the clustering framework, such as Torre et al. performs k-means clustering and linear discriminant analysis jointly <ref type="bibr" target="#b34">[34]</ref>. However, these shallow models are typically with limited representation power and thus their improvement on image clustering performance is not significant.</p><p>Recently, deep clustering methods, which perform feature learning by applying deep neural networks (DNN) and conduct clustering in the latent learned feature space, have shown impressive performance in image clustering tasks and have attracted people's increasing attentions <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b26">26,</ref><ref type="bibr" target="#b33">33,</ref><ref type="bibr" target="#b39">39,</ref><ref type="bibr" target="#b42">42,</ref><ref type="bibr" target="#b43">43</ref>]. Despite the huge success, most of the existing deep clustering methods actually apply a partitional clustering, e.g., k-means clustering in the latent learned feature space. This brings the following drawbacks: (1) The number of clusters must be given in advance, which is usually unknown in practical clustering tasks. <ref type="bibr" target="#b1">(2)</ref> The partitional clustering techniques can only find spherical clusters and perform worse on irregular clusters or imbalanced data.</p><p>(3) The k-means like clustering methods have randomness, probably leading to unstable clustering results.</p><p>Some methods have been proposed to estimate the number of clusters in deep clustering models <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b30">30,</ref><ref type="bibr" target="#b37">37]</ref>. However, these methods do not consider the local information of clusters, and do not consider that points with different densities should play different roles in density-based clustering technique. Thus, the performance of these methods is still not satisfied and two questions are normally raising:</p><p>(1) How deep clustering methods effectively find appropriate number of clusters with irregular shape when the number of clusters is not known a-prior? (2) Do we really need to refine the deep neural networks with the initial cluster assignment?</p><p>In this paper, we aim to answer these two questions and propose a novel effective deep density-based clustering (DDC) method for images. Specifically, DDC first learns deep feature representation of data via a deep autoencoder. Second, t-SNE <ref type="bibr" target="#b21">[22]</ref> is adopted to further reduce the learned features to a 2-dimensional space while preserving the pairwise similarity of data instances. Finally, we develop a novel density-based clustering method which considers both the local structures of clusters and importance of instances to generate the final clustering results.</p><p>The contributions of this work are stated as below:</p><p>• We propose a novel effective density-based technique for deep clustering which can automatically find appropriate number of image clusters with arbitrary shapes.</p><p>• DDC is with good cluster visualization and interpretability. Its properties are theoretically and empirically analyzed. Its efficiency and robustness to parameter setting are also empirically verified.</p><p>• Extensive experiments are conducted to show that DDC becomes the new state-of-the-art deep clustering method on various image clusters discovering tasks when the number of clusters is unknown.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work 2.1. Deep clustering</head><p>Due to the good representation ability, deep neural networks (DNN) have gained impressive achievements in various types of machine learning and computer vision applications <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b15">16]</ref>. Most of the DNN methods focus on supervised problems in which the label information is known. In recent several years, people pay increasing attentions to adopting DNN in unsupervised learning tasks and a number of deep clustering methods have been proposed.</p><p>One kind of deep clustering methods divide the clustering procedure into two stages, i.e., feature learning and clustering. They first perform feature learning via DNN and then apply clustering algorithms in the learned space <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b26">26,</ref><ref type="bibr" target="#b31">31,</ref><ref type="bibr" target="#b33">33]</ref>. The other kind of deep clustering methods incorporate the abovementioned two stages into one framework. Song et al. <ref type="bibr" target="#b32">[32]</ref> refine the autoencoder such that data representations in the learned space are close to their affiliated cluster centers. Xie et al. <ref type="bibr" target="#b39">[39]</ref> propose deep embedded clustering (DEC) to jointly learn the cluster assignment and the feature representations. Ren et al. <ref type="bibr" target="#b27">[27]</ref> propose semi-supervised deep embedded clustering to enhance the performance of DEC by using pairwise constraints. Yang et al. <ref type="bibr" target="#b43">[43]</ref> and Chang et al. <ref type="bibr" target="#b5">[6]</ref> apply convolutional neural networks (CNN) for exploring image clusters. Guo et al. <ref type="bibr" target="#b12">[13]</ref> improve DEC with local structure preservation. Guo et al. <ref type="bibr" target="#b13">[14]</ref> use data augmentation in the DEC framework and achieve state-of-the-art clustering performance on several image data sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Density-based clustering</head><p>The key advantage of density-based clustering is that the number of clusters is not needed and clusters with arbitrary shape can be found. Over the past decades, many densitybased clustering methods have been developed. DBSCAN <ref type="bibr" target="#b10">[11]</ref> defines a cluster with points from continuous highdensity regions and treats those points in low-density regions as outliers or noises. Inspired by this popular algorithm, a lot of density-based clustering methods have been designed, such as OPTICS <ref type="bibr" target="#b1">[2]</ref>, DENCLUE <ref type="bibr" target="#b14">[15]</ref>, DESCRY <ref type="bibr" target="#b0">[1]</ref>, and others <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr">24]</ref>. DenPeak (clustering by fast search and find of density peaks ) <ref type="bibr" target="#b29">[29]</ref> is another immensely popular density-based clustering method, which assumes that cluster centers locate in regions with higher density and the distances among different centers should be relatively large. Some improvements of DenPeak have also been made <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b25">25,</ref><ref type="bibr" target="#b41">41]</ref>. These methods described above are applied in the original feature space. Thus, their performance for grouping images which are with high dimensionality is not satisfied due to the limited representation ability.</p><p>In 2018, several deep clustering methods <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b30">30,</ref><ref type="bibr" target="#b37">37]</ref> which seek to address the issue of estimating the number of clusters have been proposed, i.e., DDC-UF (deep density clustering of unconstrained faces) <ref type="bibr" target="#b18">[19]</ref>, DCC (deep continuous clustering) <ref type="bibr" target="#b30">[30]</ref>, and DED (deep embedding determination) <ref type="bibr" target="#b37">[37]</ref>. However, these methods ignore the local structures in each cluster, and do not allow points to play different roles according to their densities. By contrast, the proposed DDC takes into both the local information of clusters and importance of points account and achieves significant improvements on clustering performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Deep density-based image clustering</head><p>This section presents the proposed deep density-based image clustering (DDC) in detail.</p><formula xml:id="formula_0">Let X = {x i ∈ R D } n i=1</formula><p>denote the image data set, where n is number of data points and D is the dimensionality. DDC aims at grouping X into an appropriate number of disjoint clusters without any prior knowledge such as the number of clusters and label information. DDC is a two-stage deep clustering model which contains two main steps, i.e., deep feature learning which nonlinearly transfers the original features to a low dimensional space, and density-based clustering which automat-ically recognizes an appropriate number of clusters with shapes in the latent space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Deep feature learning</head><p>As deep clustering methods generally do, we adopt deep autoencoder to initialize the feature transformation due to its excellent representation ability. An autoencoder is consisted of two parts: the encoder h = f Θ (x) (maps each data point x to a learned representation h) and the decoder x = g Ω (h) (transfers data from the learned feature space to the original one). Here, the feature dimensionality of h is d. Θ and Ω denote the parameters of the encoder and decoder, respectively. In this paper, we use the denoising autoencoder <ref type="bibr" target="#b35">[35]</ref> that solves the following problem:</p><formula xml:id="formula_1">arg min Θ,Ω 1 n n i=1 x i − g Ω (f Θ (x i )) 2 2 (1)</formula><p>wherex is a corrupted copy of x by adding noises, e.g., adding Gaussian noise or randomly setting a portion of input data to 0. We use the stacked autoencoder (SAE) <ref type="bibr" target="#b36">[36]</ref> in this work, in which each layer is a denoising autoencoder trained to reconstruct the previous layer's output. For image clustering, we adopt the deep convolutional autoencoder (CAE) in the experiments, whose structure will be stated in Section 3.3.</p><p>In <ref type="bibr" target="#b13">[14]</ref>, the data augmentation (DA) technique is used in the training process of deep autoencoder and has achieved significant improvements of clustering performance. The resulting optimization model is:</p><formula xml:id="formula_2">arg min Θ,Ω 1 n n i=1 x i − g Ω (f Θ (x i )) 2 2 (2) wherex i = T rand (x i ) denotes the random transformation 1 of x i .</formula><p>When the training of deep autoencoder (solving Eq. (1) or Eq. <ref type="formula">(2)</ref>) is finished, we observe the feature represen-</p><formula xml:id="formula_3">tations H = {h i = f Θ (x i ) ∈ R d } n i=1</formula><p>. For visualization and better fitting the designed density-based clustering algorithm, we further reduce data H to a 2-dimensional</p><formula xml:id="formula_4">space Z = {z i ∈ R 2 } n i=1</formula><p>by using t-SNE <ref type="bibr" target="#b21">[22]</ref> which owns good preservation ability of pairwise similarities. Then, we develop a novel density-based clustering in the embedded space Z as below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Density-based clustering</head><p>We propose a novel density-based clustering method to obtain an appropriate partition of data</p><formula xml:id="formula_5">Z = {z i ∈ R 2 } n i=1</formula><p>in the 2-dimensional feature space when the number of clusters is unavailable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Local clusters generation</head><p>DDC shares two fundamental definitions (i.e., ρ i and δ i of point z i ) with DenPeak <ref type="bibr" target="#b29">[29]</ref>. Concretely, DDC defines the density of ρ i of point z i via a Gaussian kernel:</p><formula xml:id="formula_6">ρ i = zj ∈Z\{zi} exp −( d ij d c ) 2<label>(3)</label></formula><p>where d ij is the Euclidean distance between points z i and z j , and d c is the cutoff distance that need to be predefined. A higher value of ρ i means a higher density of point z i . δ i of point z i denotes the minimum Euclidean distance between z i and those points whose densities are larger than z i . That is,</p><formula xml:id="formula_7">δ i = min j:ρj &gt;ρi (d ij )<label>(4)</label></formula><p>For the point with the highest density, its ρ is set to the maximum of pairwise distances. DenPeak simply chooses several points with the highest ρ and δ values as cluster centers. Different from DenPeak, we consider those points with relatively large ρ and δ values as local cluster centers. The corresponding definition is given in Definition 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 1. (Local cluster centers)</head><p>Those points satisfying the following condition are defined as local cluster centers:</p><formula xml:id="formula_8">δ i &gt; d c and ρ j &gt;ρ (5) whereρ = 1 n n j=1 ρ j is the average density of all the points {z i } n i=1 .</formula><p>It is easy to verify that a local cluster center z i owns the largest density in its d c -neighborhood, i.e., a circle with z i and d c as the center and radius, respectively. When all the local cluster centers are obtained, we assign each remaining point to the cluster as its nearest neighbor of higher density. Then, a set of local clusters are found and will be used to generate the final clustering. To analyze the characteristic of local cluster centers, the following two theorems are stated. Theorem 1. A local cluster center z i owns the largest density value ρ i locally in its d c -neighborhood.</p><p>Proof. We use 'proof by contradiction' method to prove the theorem. For a local cluster center z i , assume that there exists a point z j in the d c -neighborhood of z i satisfying ρ j &gt; ρ i . Then, δ i ≤ d c holds according to Eq. (4). This actually contradicts Eq. (5) in Definition 1. Thus, the assumption is wrong and the theorem is proved.</p><p>Theorem 2. The distance of two local cluster centers with different densities is at least d c .</p><p>Proof. Suppose z i and z j are two local cluster centers with ρ i = ρ j . We assume the distance d ij &lt; d c , then z i and z j are in the d c -neighborhoods of each other. Since z i is a local cluster center, it owns the highest density in its d cneighborhood. Thus, ρ i ≥ ρ j . z j is also a local cluster center. Similarly, we have ρ j ≥ ρ i . Thus, ρ i = ρ j . This contradicts the condition of the theorem.</p><p>Thus, the distance of two local clusters is smaller than d c only when they have the same density and Eq. (5) holds at the same time. In real tasks, this situation extremely rarely occurs. As a consequence, Theorems 1 and 2 indicate two important properties of local cluster centers: (1) Each local center is with the highest density locally. <ref type="formula">(2)</ref> The selected cluster centers are not too close to each other, preventing a huge number of cluster centers from being selected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Merging local clusters</head><p>Suppose L local clusters (C <ref type="bibr" target="#b0">(1)</ref> , C (2) , . . . , C (L) ) are obtained, they will be merged to form the final clustering result. First, we define core and border points in Definition 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 2. (Core and border points of a cluster)</head><p>Suppose a point z i is from local cluster C (k) , it is defined as a core point if the following condition holds:</p><formula xml:id="formula_9">ρ j &gt;ρ (k)<label>(6)</label></formula><p>whereρ (k) = 1 n k zj ∈C (k) ρ j is the average density of all the points in C (k) and n k is the number of points in C (k) . Otherwise, z i is considered as a border point.</p><p>Definition 2 indicates that whether a point is a core or border point depends on its own density and the average density of the local cluster to which this point belongs. Generally, the core points of a cluster locate in the central regions, while the border points place in the boundary of areas with lower density.</p><p>Then, we define connectivity of clusters in Definitions 3 and 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 3. (Density directly-connectable of clusters)</head><p>A local cluster C (k) is density directly-connectable from a local cluster C (l) if:</p><p>∃ core points z i ∈ C (k) and z j ∈ C (l) , such that d ij &lt; d c .</p><p>(7)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 4. (Density connectable of clusters)</head><p>A local cluster C (k) is density-connectable to a local cluster C (l) if:</p><formula xml:id="formula_10">∃ a path C (k) = C 1 , C 2 , . . . , C m = C (l)<label>(8)</label></formula><p>where cluster C j is density directly-connectable from cluster C j−1 (j = 2, . . . , m) and m is the path length. Compute ρ i and δ i via Eqs. (3) and (4). <ref type="bibr" target="#b7">8</ref>: end for 9: Choose local cluster centers via Eq. (5). 10: Assign the remaining points and observe local clusters C <ref type="bibr" target="#b0">(1)</ref> , C (2) , . . . , C (L) . 11: Define core and border points via Eq. (6). <ref type="bibr">12:</ref> Merge all the density connectable local clusters. <ref type="bibr">13:</ref> Return the final clustering result.</p><p>It is easy to verify that both density directly-connectable and density connectable are symmetric. Finally, all the densityconnectable local clusters are merged and the final clustering result is provided. When two local clusters are merged, the cluster center with higher density becomes the center of the new merged cluster.</p><p>According to Definitions 3 and 4, two clusters are merged only when their central areas are very close to each other. This ensures the new merged cluster also has continuous high-density areas.</p><p>The pseudo-code of the proposed DDC is summarized in Algorithm 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Implementation</head><p>According to different optimization problems, DDC provides two specific algorithms:</p><p>(1) DDC: Use CAE and solve Eq. (1).</p><p>(2) DDC-DA: Use CAE and solve Eq. (2) in which data augmentation is adopted. represents a convolutional layer with 32 filters and a 5 × 5 kernel. The stride is always set to 2. Fc 10 denotes the full connected layer with 10 neurons. In convolutional autoencoders, all the internal layers except for the input, embedding, and output layers are activated by ReLU function. The structures of autoencoders also indicate that the dimensionality of learned representations H is 10.</p><p>Given the embedded 2-dimensional data Z, DDC has only one parameter (d c ) needed to be set. We set the value of d c according to data Z itself. Concretely, we computed as the average value of all pairwise distances in Z. Then, set d c =d×ratio. If ratio is extremely large, a small number of clusters will be found by DDC. If ratio is extremely small, a large number of clusters will be detected. However, we will empirically verify that DDC achieves stable performance in a wide range of ratio. The default value of ratio is 0.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Relations to exiting methods</head><p>DBSCAN <ref type="bibr" target="#b10">[11]</ref> and DenPeak <ref type="bibr" target="#b29">[29]</ref> are two worldwide popular density-based clustering methods. They are applied in the original feature space, while the proposed DDC works in the 2-dimensional embedded space. Besides, DB-SCAN is sensitive to the parameters and tends to merge clusters with overlapping areas <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b28">28]</ref>. These shortcomings prevent its successful use in image clustering tasks.</p><p>DenPeak assumes that each cluster has only one center, leading to the following disadvantages: (1) In real applications, multiple centers/modes usually coexist in one cluster. <ref type="bibr" target="#b1">2</ref> http://cs.joensuu.fi/sipu/datasets/ Thus, DenPeak typically loses information of local structures of a cluster. (2) It is difficult for DenPeak to select a suitable number of clusters because usually a number of (which is much larger than the ground-truth number of clusters) points with high ρ and δ values can be considered as candidates of cluster centers. To address these issues, DDC firstly selects all the potential cluster centers to obtain the local clusters, and then aggregates all density connectable cluster to form the final clustering result. An illustration exhibiting the different behaviors of DenPeak and DDC is given in <ref type="figure">Figs. (1)</ref> and <ref type="bibr" target="#b1">(2)</ref>. Here, DCC is directly applied on the 2-dimensional data without using CAE and t-SNE. DenPeak follows the parameter setting described in Section 4.3.</p><p>DED <ref type="bibr" target="#b37">[37]</ref> is a recently proposed deep clustering model that transforms the original data via DNN to a 2dimensional feature space that favors the density-based clustering algorithm. However, DED directly applies Den-Peak on the 2-dimensional data, thereby inheriting the disadvantages of DenPeak.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental setup</head><p>This section describes the tested image data sets, comparing methods, parameter settings, and evaluation measures. Five popular image data sets are used to assess the performance of comparing methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Image data sets</head><p>The MNIST data base 3 consists of 70000 handwritten digits of 28×28 pixel size from 10 categories (digits 0-9). The MNIST-test data set only contains the test set of MNIST, with 10000 images. The USPS data set 4 is collected from handwritten digits from envelopes by the U.S. postal service. It contains 9298 grayscale images with size 16 × 16. Fashion <ref type="bibr" target="#b38">[38]</ref> is a data set comprising 28 × 28 gray images of 70000 fashion products from 10 categories. Its test set with 10000 images are used in our experiments. The LetterA-J data set 5 is consisted of more than 500k 28 × 28 greyscale images of English letters from A to J. We randomly select 10000 images from its uncleaned subset as test set.</p><p>The summary of all data sets is shown in <ref type="table" target="#tab_2">Table 1</ref>. The features of each data set are scaled to [0, 1].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Evaluation measures</head><p>Clustering accuracy (ACC) and normalized mutual information (NMI) are used to estimate the performance of comparing algorithms. Their values are both in [0,1]. A higher value of ACC or NMI indicates a better clustering performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Comparing methods</head><p>We compare the proposed DDC with both shallow clustering methods and deep ones. Shallow baselines are kmeans <ref type="bibr" target="#b22">[23]</ref>, DBSCAN <ref type="bibr" target="#b10">[11]</ref>, and DenPeak <ref type="bibr" target="#b29">[29]</ref>. Deep methods based on both full connected and convolutional autoencoders are compared, including DEC (deep embedded clustering) <ref type="bibr" target="#b39">[39]</ref>, IDEC (improved DEC with local structure preservation) <ref type="bibr" target="#b12">[13]</ref>, DCN (deep clustering network) <ref type="bibr" target="#b42">[42]</ref>, JULE (joint unsupervised learning for image clustering) <ref type="bibr" target="#b43">[43]</ref>, DCC (deep continuous clustering) <ref type="bibr" target="#b30">[30]</ref>, DED (deep embedding determination) <ref type="bibr" target="#b37">[37]</ref>, DEC-DA (DEC with data augmentation) <ref type="bibr" target="#b13">[14]</ref>.</p><p>Among all the comparing methods, DBSCAN, DenPeak, DCC, DED, and the proposed DCC do not need the number of clusters in advance. For all other methods, the number of clusters is set to the the ground-truth number of categories. When applying DBSCAN, the 4-th nearest neighbor distances are computed w.r.t. the entire data, and parameter Eps is set to the median of those values. The M inP ts value of DBSCAN is always set to 4. For DenPeak, the Gaussian kernel is used and d c is set such that the average number of points in d c -neighborhood is approximately 1% × n. To give DenPeak and DED an advantage, the detected number of clusters is set to the true number of classes according to the decision graph. So far, given the groundtruth number of clusters, ConvDEC-DA achieves state-ofthe-art clustering performance in image clustering <ref type="bibr" target="#b13">[14]</ref>. We compare ConvDEC-DA and its version without using DA in our experiments.</p><p>The reported ACC and NMI values are either excerpted from the original papers, or are the average values of running the released code with corresponding suggested parameters for 10 independent trials. <ref type="table">Table 2</ref> gives the clustering results of comparing methods measured by ACC and NMI. In each column, the best two results are highlighted in boldface. From <ref type="table">Table 2</ref> we have the following observations: (1) The shallow models generally perform worse than deep clustering methods. DBSCAN works the worst mainly because it is hard to choose suitable parameters in high dimensional space. (2) Data augmentation (DA) can improve the clustering performance. Except for two methods using DA (i.e., ConvDEC-DA and DDC-DA), our DDC always achieves the highest ACC and NMI values. (3) Our DDC-DA always achieves one of the best two clustering results, even the number of clusters is not given. Even given the true number of clusters, DED still performs much worse than DDC and DDC-DA. (4) We also find that ConvDEC-DA can usually obtain a high ACC value (&gt;0.98), but it performs worse (ACC &lt;0.84) occasionally. This might be caused by the bad initial cluster centers provided by k-means in the learned feature space. By contrast, our DDC and DDC-DA are more stable with small standard deviations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Results and analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Results on real image data</head><p>The average number of clusters detected by our DDC and DDC-DA as well as the corresponding standard deviations are given in <ref type="table" target="#tab_4">Table 3</ref>. From <ref type="table" target="#tab_4">Table 3</ref> we find that our methods can always find the correct numbers of cate- <ref type="table">Table 2</ref>. Results of the comparing methods. In each column, the best two results are highlighted in boldface. The results marked by '*' are excerpted from the papers. '-' denotes the results are unavailable from the papers or codes, and '--' means 'out of memory' when applying.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MNIST</head><p>MNIST   gories on MNIST-test, and USPS. On MNIST, Fashion and LetterA-J, the recognized numbers of clusters are slightly different from the true values. These indicate the capability of the proposed DDC framework of automatically recognizing reasonable numbers of clusters.  <ref type="figure" target="#fig_1">Fig. 3</ref>, from which we can observe that our method achieves stably excellent performance in a wide range of ratio. When applying the DDC methods in real clustering applications, the default value of ratio is recommended to be set to 0.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Sensitivity analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Runtime analysis</head><p>We compare our method with DEC-DA <ref type="bibr" target="#b13">[14]</ref> because these two models use the same CAE structure and DEC-DA has been proved to be efficient compared with other existing deep clustering methods. The experiments are tested on a server with 32 GB RAM and 2 Tesla P100 GPUs. Concretely, the runtimes of our DDC-DA on MNIST-test and USPS are 737 and 583 seconds, respectively. Those of ConvDEC-DA are 798 and 436 seconds, respectively. DDC-DA needs time to estimate the density ρ and δ for each point. ConvDEC-DA needs to refine the CAE with initial cluster centers. Thus, these two methods show competitive performance in terms of efficiency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Discussion</head><p>We also conduct experiments to directly use t-SNE to reduce the original data to the 2-dimensional space and then apply the proposed density-based clustering technique. The clustering results are much worse than our DDC methods. The main reason is that CAE can transform the original data to a lower dimensional space in which the intrinsic local structures are preserved. It is better to further reduce the lower dimensional representations to a 2-dimensional space rather than extracting from the original high dimensional data. As a consequence, DED <ref type="bibr" target="#b37">[37]</ref> and our DDC make use of both CAE and t-SNE to obtain the 2-dimensional representations that favor the density-based clustering. Now, let us come back to the question raised in Section 1: Is it really needed to refine the deep autoencoder with the initial cluster assignment? To answer this question, we first visualize the clustering results on MNIST-test and LetterA-J in the embedded 2-dimensional space of DDC-DA in Figs. 4 and 5, respectively. For data whose clusters are well separated (as shown in <ref type="figure">Fig. 4 (a)</ref>), those centroid-based cluster- ing methods, such as ConvDEC-DA, which depends greatly on the initial selection of cluster centers, needs to refine the CAE iteratively to achieve satisfied results. By contrast, our DDC can output remarkable performance without refinement even when several clusters in the middle area have overlapped areas.</p><p>For data in which many points from different categories mess together (as shown in the middle area of <ref type="figure">Fig. 5 (a)</ref>), the refinement of ConvDEC-DA can not separate the messed points correctly, neither does our DDC. If this happens and no additional information is given, the effectiveness of refining autoencoder is not significant for both centroid-based and density-based clustering. In our opinion, one needs prior information (e.g., pairwise constraints) or knowledge transferred from related tasks to handle this situation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusion and future work</head><p>This article has introduced a novel deep density-based clustering (DDC) method for images. It is well known that for high-dimensional data such as images, it is difficult to obtain satisfied performance by applying clustering methods in the original space of image data. So in DDC, first, we use CAE with good representation ability to extract 10-dimensional features from the original data. After this, t-SNE is used to reduce the 10-dimensional data to a 2-dimensional space, which favors our density-based clustering. DDC consider both the local information of clusters and the importance of points in the clustering process.</p><p>It is empirically proved to be the new state-of-the-art deep clustering method when the number of clusters is not given. Its efficiency and robustness are also verified. An interesting future work is to exploit semi-supervised learning and transfer learning into deep density-based clustering.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .Figure 2 .</head><label>12</label><figDesc>Twomoon: Clustering performance comparison of DenPeak and DDC. The Twomoon data set has 2000 points from two classes. (a): The decision graph of DenPeak. (b): The final result of DenPeak. (c): Initial local clusters of DDC. (d): The final result of DDC. (e): The border points detected by DDC are plotted as black points. The center of each cluster is highlighted with black ' '. Points with the same color are from the same cluster. As shown in (a), a number of points with high ρ and δ values can be considered as centers and it is hard for DenPeak to choose an appropriate number of clusters. Even it is told that 2 clusters exist, the result of DenPeak is still not satisfied, as (b) shows. By contrast, DDC first generate a relatively large number of local cluster centers and then merge them to form the final clustering result. Compared (c) with (e), we find that two clusters are typically merged if there exists core points that are from both clusters and are close to each other. It is shown in (e) that border points generally locate around the boundary of each real cluster, while core points locate in central areas. Clustering results of DenPeak and DDC on Flame and t4 data sets 2 . (a) and (b) correspond to the Flame data set. (c) and (d)show the results on t4. DenPeak is told to select the true number of clusters. Due to loss information of local structures, DenPeak fails to find suitable clusters (as shown in (a) and (c)). In contrast, DDC performs perfectly on these two data sets. Even when noisy data exist (as exhibited in (d)), DDC can still automatically recognize the 4 irregular clusters.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>Sensitivity analysis of parameter ratio (ACC and NMI).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 .Figure 5 .</head><label>45</label><figDesc>Visualization of DDC-DA on MNIST-test. (a) The ground truth labels of the embedded 2-dimensional data. (b) The initial result of DDC-DA. (c) The final result of DDC-DA. (d) The border points detected by DDC-DA. (a) Ground truth labels (b) Initial result (c) Final result (d) Border points Visualization of DDC-DA on LetterA-J. (a) The ground truth labels of the embedded 2-dimensional data. (b) The initial result of DDC-DA. (c) The final result of DDC-DA. (d) The border points detected by DDC-DA.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Algorithm 1 Deep Density-based Image Clustering (DDC). Input: Image data set X ; Cutoff distance d c . Output: The final clustering result. : Map H to a 2-dimensional data set Z via t-SNE. Stage 2 → Density-based clustering 6: for each point z i in Z do</figDesc><table><row><cell>7:</cell></row></table><note>1: Stage 1 → Deep feature learning2: Train a deep autoencoder via Eq. (1) or (2).3: Transform X to lower feature representations H via the encoder f Θ (·).45:</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 .</head><label>1</label><figDesc>Image data sets used in the experiments.</figDesc><table><row><cell>data set</cell><cell cols="3"># examples # classes image size</cell></row><row><cell>MNIST</cell><cell>70000</cell><cell>10</cell><cell>28×28</cell></row><row><cell>MNIST-test</cell><cell>10000</cell><cell>10</cell><cell>28×28</cell></row><row><cell>USPS</cell><cell>9298</cell><cell>10</cell><cell>16×16</cell></row><row><cell>Fashion</cell><cell>10000</cell><cell>10</cell><cell>28×28</cell></row><row><cell>LetterA-J</cell><cell>10000</cell><cell>10</cell><cell>28×28</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 .</head><label>3</label><figDesc>The average number of detected clusters.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>This section tests the sensitivity of DCC w.r.t. the parameter ratio on MNIST-test and USPS data sets. The tested range is [0.05, 0.16]. Both ACC and NMI values of DDC-DA are reported in</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">As in<ref type="bibr" target="#b13">[14]</ref>, we randomly shift for at most 3 pixels in each direction and randomly rotate for at most 10 • .</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">http://yann.lecun.com/exdb/mnist/ 4 https://www.csie.ntu.edu.tw/˜cjlin/ libsvmtools/datasets/multiclass.html 5 https://yaroslavvb.blogspot.com/2011/09/ notmnist-dataset.html</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Descry: a density based clustering algorithm for very large data sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Angiulli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Pizzuti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ruffolo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Intelligent Data Engineering and Automated Learning</title>
		<meeting>the International Conference on Intelligent Data Engineering and Automated Learning</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="203" to="210" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Optics: ordering points to identify the clustering structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ankerst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Breunig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-P</forename><surname>Kriegel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sander</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Sigmod record</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1999" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="49" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Learning deep architectures for AI. Foundations and Trends in Machine Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Representation learning: A review and new perspectives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1798" to="1828" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Bishop</surname></persName>
		</author>
		<title level="m">Pattern Recognition and Machine Learning</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="430" to="439" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Deep adaptive image clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Pan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="5879" to="5887" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Deep learning with nonparametric clustering. Computing Research Repository</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<idno>abs/1501.03084</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">CLUE: cluster-based retrieval of images by unsupervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Krovetz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1187" to="1201" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Mean shift: a robust approach toward feature space analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Comaniciu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Meer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="603" to="619" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Density-based clustering with geographical background constraints using a semantic expression model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISPRS International Journal of Geo-Information</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">72</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A densitybased algorithm for discovering clusters in large spatial databases with noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-P</forename><surname>Kriegel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 2nd International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="226" to="231" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A parallel varied density-based clustering algorithm with optimized data partition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Spatial Science</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Improved deep embedded clustering with local structure preservation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Joint Conference on Artificial Intelligence</title>
		<meeting>the International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Deep embedded clustering with data augmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Asian Conference on Machine Learning</title>
		<meeting>the Asian Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">An efficient approach to clustering in large multimedia databases with noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hinneburg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Keim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGKDD Conference on Knowledge Discovery and Data Mining</title>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="page" from="58" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A fast learning algorithm for deep belief nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">W</forename><surname>Teh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1527" to="1554" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Data clustering: A review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">N</forename><surname>Murty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Flynn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="264" to="323" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Real-time computerized annotation of pictures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Z</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="985" to="1002" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Deep density clustering of unconstrained faces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-A</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Castillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="8128" to="8137" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Adaptive density peak clustering based on k-nearest neighbors with aggregating strategy. Knowledge-Based Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">133</biblScope>
			<biblScope unit="page" from="208" to="220" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">An efficient and scalable density-based clustering algorithm for datasets with complex structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Al-Dhelaan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Al-Rodhaan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">171</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="9" to="22" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Visualizing data using t-sne</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">V D</forename><surname>Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Some methods for classification and analysis of multivariate observations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Macqueen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th</title>
		<meeting>the 5th</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Berkeley Symposium on Mathematical Statistics and Probability</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="1967" />
			<publisher>University of California Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Anytime density-based clustering of complex data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">T</forename><surname>Mai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Plant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Böhm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge and Information Systems</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="319" to="355" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Clustering by fast search and merge of local density peaks for gene expression microarray data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mehmood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>El-Ashram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Dawood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific reports</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">45602</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Deep subspace clustering with sparsity prior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">Y</forename><surname>Yau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Joint Conference on Artificial Intelligence</title>
		<meeting>the International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1925" to="1931" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Semi-supervised deep embedded clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>Hoi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">325</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="121" to="130" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Boosted mean shift clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Kamath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Domeniconi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the The European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases</title>
		<meeting>the The European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Clustering by fast search and find of density peaks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Laio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">344</biblScope>
			<biblScope unit="issue">6191</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Koltun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.01449</idno>
		<title level="m">Deep continuous clustering</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Deep linear coding for fast graph clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Joint Conference on Artificial Intelligence</title>
		<meeting>the International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3798" to="3804" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Autoencoder based data clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Progress in Pattern Recognition, Image Analysis, Computer Vision, and Applications</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="117" to="124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Learning deep representations for graph clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1293" to="1299" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Discriminative cluster analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">D</forename><surname>Torre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning</title>
		<meeting>the International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="241" to="248" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Extracting and composing robust features with denoising autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-A</forename><surname>Manzagol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning</title>
		<meeting>the International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1096" to="1103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Lajoie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-A</forename><surname>Manzagol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Exploration of human activities using sensing data via deep embedded determination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Wireless Algorithms, Systems, and Applications</title>
		<meeting>the International Conference on Wireless Algorithms, Systems, and Applications</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Fashion-MNIST: a novel image dataset for benchmarking machine learning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Rasul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vollgraf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.07747</idno>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Unsupervised deep embedding for clustering analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Farhadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning</title>
		<meeting>the International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="478" to="487" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Integrating image clustering and codebook learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1903" to="1909" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">DenPEHC: Density peak based efficient hierarchical clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">373</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="200" to="218" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Towards k-means-friendly spaces: Simultaneous deep learning and clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Sidiropoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning</title>
		<meeting>the International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Joint unsupervised learning of deep representations and image clusters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Batra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="5147" to="5156" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
