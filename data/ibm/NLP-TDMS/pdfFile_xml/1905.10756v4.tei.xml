<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Selective Transfer with Reinforced Transfer Network for Partial Domain Adaptation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhihong</forename><surname>Chen</surname></persName>
							<email>zhihongchen@zju.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institue of Information Science and Electronic Engineering</orgName>
								<orgName type="institution">Zhejiang University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Chen</surname></persName>
							<email>chench@zju.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institue of Information Science and Electronic Engineering</orgName>
								<orgName type="institution">Zhejiang University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaowei</forename><surname>Cheng</surname></persName>
							<email>chengzhaowei@zju.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institue of Information Science and Electronic Engineering</orgName>
								<orgName type="institution">Zhejiang University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boyuan</forename><surname>Jiang</surname></persName>
							<email>byjiang@zju.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institue of Information Science and Electronic Engineering</orgName>
								<orgName type="institution">Zhejiang University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Fang</surname></persName>
							<email>ke-fang@zju.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institue of Information Science and Electronic Engineering</orgName>
								<orgName type="institution">Zhejiang University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyu</forename><surname>Jin</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institue of Information Science and Electronic Engineering</orgName>
								<orgName type="institution">Zhejiang University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Selective Transfer with Reinforced Transfer Network for Partial Domain Adaptation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T12:39+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>One crucial aspect of partial domain adaptation (PDA) is how to select the relevant source samples in the shared classes for knowledge transfer. Previous PDA methods tackle this problem by re-weighting the source samples based on their high-level information (deep features). However, since the domain shift between source and target domains, only using the deep features for sample selection is defective. We argue that it is more reasonable to additionally exploit the pixel-level information for PDA problem, as the appearance difference between outlier source classes and target classes is significantly large. In this paper, we propose a reinforced transfer network (RTNet), which utilizes both high-level and pixel-level information for PDA problem. Our RTNet is composed of a reinforced data selector (RDS) based on reinforcement learning (RL), which filters out the outlier source samples, and a domain adaptation model which minimizes the domain discrepancy in the shared label space. Specifically, in the RDS, we design a novel reward based on the reconstruct errors of selected source samples on the target generator, which introduces the pixel-level information to guide the learning of RDS. Besides, we develope a state containing high-level information, which used by the RDS for sample selection. The proposed RDS is a general module, which can be easily integrated into existing DA models to make them fit the PDA situation. Extensive experiments indicate that RTNet can achieve state-of-the-art performance for PDA tasks on several benchmark datasets.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Deep neural networks have achieved impressive performance in a variety of applications. However, when applied to related but different domains, the generalization ability of the learned model may be severely degraded due to the harmful effects of the domain shift <ref type="bibr" target="#b2">[3]</ref>. Re-collecting labeled data from the coming new domain is prohibitive be-  cause of the huge cost of data annotation. Domain adaptation (DA) techniques solve such a problem by transferring knowledge from a source domain with rich labeled data to a target domain where labels are scarce or unavailable. These DA methods learn domain-invariant features by moment matching <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b8">9]</ref> or adversarial training <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b11">12]</ref>.</p><p>Previous DA methods generally assume that the source and target domains have shared label space, i.e., the category set of the source domain is consistent with that of the target domain. However, in real applications, it is usually formidable to find a relevant source domain with identical label space as the target domain. Thus, a more realistic scenario is partial domain adaptation (PDA) <ref type="bibr" target="#b3">[4]</ref>, which relaxes the constraint that source and target domains share the same label space and assumes that the unknown target label space is a subset of the source label space. In such a scenario, as shown in <ref type="figure" target="#fig_1">Figure 1a</ref>, existing DA methods force an error match between the outlier source class (blue triangle) and the unrelated target class (red square) by aligning the whole source domain with the target domain. As a result, the negative transfer may be triggered due to the mismatch. Negative transfer is a dilemma that the transfer model performs even worse than the non-adaptation (NoA) model <ref type="bibr" target="#b20">[21]</ref>.</p><p>Several approaches have been proposed to solve the PDA problem by re-weighting the source samples, where the weights can be get from the distribution of the predicted target label probabilities <ref type="bibr" target="#b4">[5]</ref> or the prediction of the domain discriminator <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b31">32]</ref>. These methods select the relevant source samples only considering the high-level information (deep features), which however ignore the most discriminative features hidden in the pixel-level information, such as appearance, style or background. Since the difference of appearance between the outlier source samples and the target samples is significantly large, taking into account the pixellevel information for outlier sample selection is expected to benefit the adaptation performance <ref type="bibr" target="#b12">[13]</ref>. Moreover, these PDA modules based on adversarial networks are difficult to integrate into matching-based DA methods lacking discriminators. Therefore, most existing matching-based methods are hard to extend to address the PDA problem.</p><p>In this paper, to address the PDA problem, we present a reinforced transfer network (RTNet), as shown in <ref type="figure" target="#fig_1">Figure  1b</ref>, which exploits reinforcement learning (RL) to learn a reinforced data selector (RDS) for filtering outlier source samples. In this respect, the DA model from RTNet can align distributions in the shared label space to avoid negative transfer. To utilize both pixel-level and high-level information, we design a RDS. The RDS takes action (keep or drop a sample) based on the state of sample. Then, the reconstruction error of the selected source sample on the target generator is used as a reward to guide the learning of RDS via the actor-critic algorithm <ref type="bibr" target="#b14">[15]</ref>. Note that, the state contains high-level information, and the reward contains pixel-level information. Specifically, the intuition of using reconstruction error to introduce pixel-level information is that the target generator lacks training samples of outlier classes and the outlier source samples extremely dissimilar to the target classes, so on the generator trained with target samples, the reconstruction error of outlier sample is larger than that of the related source samples. Hence, the reconstruction error can measure the appearance similarity between each source sample and the target domain well, which is the important information in sample selection and hard to get from high-level information.</p><p>The contributions of this work are: (1) a novel PDA framework RTNet is proposed, which joints sample selection and domain discrepancy minimization. (2) we design a reinforced data selector based on reinforcement learning, which solves the PDA problem by taking into account highlevel and pixel-level information to select related samples for positive transfer. As far as we know, this is the first work to address PDA problem with RL technique. (3) most DA methods can be extended to solve PDA problem by integrating the RDS. We use two types of base network to evaluate the effectiveness of integration. (4) The RTNet achieves the best performance on three well-known benchmarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Partial Domain Adaptation: Deep DA methods have been widely studied in recent years. These methods extend deep models by embedding adaptation layers for moment matching <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b7">8]</ref> or adding domain discriminators for adversarial training <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b25">26]</ref>. However, these methods may be restricted by the assumption that source and target domains share the same label space, which is not held in PDA scenario. Several methods have been proposed to solve the PDA problem. Selective adversarial network (SAN) <ref type="bibr" target="#b3">[4]</ref> trains a separate domain discriminator for each class with a weight mechanism to suppress the harmful influence of outlier classes. Partial adversarial domain adaptation (PADA) <ref type="bibr" target="#b4">[5]</ref> improves SAN by adopting only one domain discriminator and gets the weight of each class based on the target probability distribution output by classifier. Example transfer network (ETN) <ref type="bibr" target="#b5">[6]</ref> quantifies the weights of source examples based on their similarities to the target domain. Unlike previous PDA methods, only high-level information was used, RTNet combines pixel-level and highlevel information to achieve more accurate sample filtering.</p><p>Reinforcement Learning: RL can be roughly divided into two categories <ref type="bibr" target="#b0">[1]</ref>: value-based methods and policybased methods. The value-based methods estimate future expected total rewards through a state, such as SARSA <ref type="bibr" target="#b22">[23]</ref> and deep Q network <ref type="bibr" target="#b18">[19]</ref>. Policy-based methods try to directly find the next best action in the current state, such as REINFORCE algorithm <ref type="bibr" target="#b29">[30]</ref>. To reduce variance, some methods combine value-based and policy-based methods for more stable training, such as the actor-critic algorithm <ref type="bibr" target="#b14">[15]</ref>. So far, data selection based on RL has been applied in the fields of active learning <ref type="bibr" target="#b10">[11]</ref>, co-training <ref type="bibr" target="#b30">[31]</ref>, text matching <ref type="bibr" target="#b21">[22]</ref>, etc. However, there is a lack of reinforced data selection methods to solve the PDA problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Our Approach</head><p>Problem Definition and Notations: In this work, based on PDA settings, we define the labeled source dataset as</p><formula xml:id="formula_0">{X s , Y s } = {(x s i , y s i )} ns i=1</formula><p>from source domain D s associated with |C s | classes, and define the unlabeled target dataset as {X t } = {x t i } nt i=1 from target domain D t associated with |C t | classes. Note that, the target label space is contained in the source label space, i.e., C t ∈ C s and C t is unknown. The two domains follow different marginal distributions, p and q, respectively, we further have p Ct = q. p Ct is the distribution of source samples in the target label space. The goal is to improve the performance of model in D t with the help of the knowledge in D s associated with C t .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Overiew of RTNet</head><p>As shown in <ref type="figure">Figure 2</ref>, RTNet consists of two components: a domain adaptation model (F and C) and a rein-  <ref type="figure">Figure 2</ref>: Overview of RTNet. F is a shared feature extractor, C is a shared classifier, G s and G t are source and target generators respectively, V is a value network and π is a policy network. G s and G t are combined with F to construct source and target auto-encoders to reconstruct samples, respectively. The green line indicates the flow to get the reward.</p><p>forced data selector (G s,t , V and π). The DA model promotes positive transfer by reducing distribution shift in the shared label space. The RDS based on RL mitigates negative transfer by filtering outlier source classes. Specifically, to filter outlier source samples, the policy network π considers high-level information provided by feature extractor F and classifier C for decision making to get selected source samples X s . For the backbone of DA model, C takes source transfer features Z s = F (X s ) as input to produce label predictionsŶ s , and F achieves distribution alignment between F (X s ) and F (X t ). Meanwhile, the selected source samples' reconstruction errors X s − G t F (X s ) 2 2 based on G t are used as a reward to encourage π to select samples with small reconstruction errors. For the stability of training, based on actor-critic algorithm, we use a value network V combined with rewards to optimize π. Besides, the domain-specific generators G s and G t trained with reconstruction errors of reconstructed source images G s (F (X s )) and target images G t (F (X t )), respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Domain Adaptation Model</head><p>Almost all PDA frameworks are based on adversarial network <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b5">6]</ref>, which has led to many existing DA algorithms based on moment matching cannot be extended to solve the PDA problem. The proposed RDS is a general module that can be integrated into most DA frameworks. In this work, we use deep CORAL <ref type="bibr" target="#b24">[25]</ref> as the base DA model to prove that RDS can be embedded into the matchingbased DA framework to make it robust to PDA scene. The reason why we chose CORAL is that it is simple and effective. Although there are some limitations in CORAL, it is beyond our research scope. Besides, the RDS is universal, so CORAL can be replaced with other better DA methods. In the Appendix, we also provide a solution for embedding RDS into DANN to demonstrate that RDS can also be integrated into the method based on adversarial network. In the following, we will give a brief introduction of CORAL.</p><p>We define the last layer of F as adaptation layer and reduce the distribution shift between source and target domains by aligning the covariance matrix of source and target features. Hence, the CORAL objective function is:</p><formula xml:id="formula_1">L c (F ) = 1 d 2 Cov(Z s b ) − Cov(Z t b ) 2 F ,<label>(1)</label></formula><p>where · 2 F denotes the squared matrix Frobenius norm, Z s b ∈ R n×d and Z t b ∈ R n×d represent source and target transferable features output by the adaptation layer, respectively, b is the batch ID, d is the dimension of the transferable feature, and n is the batch size. Cov(Z s b ) and Cov(Z t b ) represent the covariance matrices, which can be computed as</p><formula xml:id="formula_2">Cov(Z s b ) = Z s b Z s b , and Cov(Z t b ) = Z t b Z t b .</formula><p>To ensure the shared feature extractor and classifier can be trained with supervision on labeled samples, we define a standard cross-entropy classification loss L s with respect to labeled source samples. Formally, the full objective function for the domain adaptation model is as follows:</p><formula xml:id="formula_3">L DA = L s + λ 1 L c ,<label>(2)</label></formula><p>where hyperparameter λ 1 control the impact of the corresponding objective function. However, in the PDA scenario, most DA methods (e.g. CORAL) may trigger negative transfer since these methods force alignment of the global distributions p and q, even though p Cs\Ct and q are nonoverlapping and cannot be aligned during transfer. Thus, the motivation of the reinforced data selector is to mitigate negative transfer by filtering out the outlier source classes C s \ C t before performing the distribution alignment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Reinforced Data Selector</head><p>We consider the source sample selection process of RT-Net as Markov decision process, which can be addressed by RL. The RDS is an agent that interacts with the environment created by the DA model. The agent takes action to keep or drop a source sample based on the policy function. The DA model evaluates the actions taken by the agent and provides a reward to guide the learning of agent.</p><p>As shown in <ref type="figure">Figure 2</ref>, given a batch of source sam- , and provides a reward r b according to the source reconstruction errors based on G t to update π and V . In the following sections, we will give a detailed introduction to the state, action, and reward.</p><formula xml:id="formula_4">ples X s b = {x s i } n i=1 ,</formula><p>State: State is defined as a vector s s i ∈ R l . In order to simultaneously consider the unique information of each source sample and the label distribution of target domain when taking action, s s i concatenates the following features: (1) The high-level semantic feature z s i , which is the output of F given x s i , i.e., z s i = F (x s i ).</p><p>(2) The label y s i of the source sample, represented by a one-hot vector. <ref type="formula" target="#formula_5">(3)</ref> The predicted probability distribution α of the target batch X t b , which can be calculated as 1 n n i=1ŷ t i ,ŷ t i = C(F (x t i )). Feature (1) represents high-level information of source sample. Feature (3) based on the intuition that the probabilities of assigning the target data to outlier source classes should be small since the target sample is significantly dissimilar to the outlier source sample. Consequently, α quantifies the contribution of each source class to the target domain. Feature <ref type="formula" target="#formula_3">(2)</ref> is combined with feature (3) to measure the relation between each source sample and the target domain.</p><p>Action: The action a ∈ {0, 1}, which indicates whether the source sample is kept or filtered from the source batch. The selector utilizes -greedy strategy <ref type="bibr" target="#b18">[19]</ref> to sample a based on π(s s i ). π(s s i ) ∈ R 1 represents the probability that the sample is kept. The is decayed from 1 to 0 as the training progresses. π is defined as a policy network with two fully connected layers. Formally, π(s s i ) is computed as:</p><formula xml:id="formula_5">π(s s i ) = sigmoid(W 2 δ(W 1 s s i + b 1 ) + b 2 ),<label>(3)</label></formula><p>where δ is the ReLU activation, W k and b k are the weight matrix and bias of the k-th layer, and s s i is the state of the source sample, which concatenates feature (1), <ref type="bibr" target="#b1">(2)</ref> and <ref type="bibr" target="#b2">(3)</ref>.</p><p>Reward: The selector takes actions to select X s b from X s b . The RTNet uses X s b to update the DA model and obtains a reward r b for evaluating the policy. In contrast to usual reinforcement learning, where one reward corresponds to one action, The RTNet assigns one reward to a batch of actions to improve the efficiency of model training.</p><p>To take advantage of pixel-level information when selecting source samples, the novel reward is designed according to the reconstruction error of the selected source sample based on G t . The intuition of using this reconstruction error as reward is that the reconstruction error</p><formula xml:id="formula_6">x s i −G t F (x s i ) 2 2</formula><p>of outlier source sample is large since they are extremely dissimilar to the target classes. Hence, the selector aims to select source samples with small reconstruction errors for distribution alignment and classifier training. However, the purpose of RL is to maximize the reward, so we design the following novel reward based on reconstruction error:</p><formula xml:id="formula_7">r b = exp(− 1 n n i=1 x s i − G t F (x s i ) 2 2 ),<label>(4)</label></formula><p>where x s i is the sample selected by the reinforced data selector, and n is the number of samples selected. As shown in Eq. 4, the smaller the reconstruction error, the greater the reward, which is in line with our expectations. Note that, to accurately evaluate the efficacy of X s b , rewards are collected after the feature extractor F and classifier C are updated as in Eq. 5 and before the generators G s,t are updated as in Eq. 6. F , C and G s,t can be trained as follows:</p><formula xml:id="formula_8">min (F,C) LDA,<label>(5)</label></formula><formula xml:id="formula_9">min (G s,t ,F ) 1 n n i=1 x s i − GsF (x s i ) 2 2 + 1 n n i=1 x t i − GtF (x t i ) 2 2 .<label>(6)</label></formula><p>In the process of selection, not only the last action contributes to the reward, but all previous actions contribute. Therefore, the future total reward r b for each batch b can be formalized as:</p><formula xml:id="formula_10">r b = N −b j=0 γ j r b+j ,<label>(7)</label></formula><p>where γ is the reward discount factor, and N is the number of batches in this episode.</p><p>Optimization: The selector is optimized based on actorcritic algorithm <ref type="bibr" target="#b14">[15]</ref>. In each episode, the selector aims to maximize the expected total reward. Formally, the objective function is defined as:</p><formula xml:id="formula_11">J (θ) = E π θ [ N b=1 r b ],<label>(8)</label></formula><p>where θ is the parameter of policy network π. θ is updated by performing, typically approximate, gradient ascent on J (θ). Formally, the update step of π is defined as:</p><formula xml:id="formula_12">θ = θ + l * 1 n n i=1 v i ∇ θ log(π θ (s s i )),<label>(9)</label></formula><p>where l is the learning rate, n is the batch size, and v i is an estimate of the advantage function based on future total reward, which guides the update of π. Note that, v i ∇ θ log(π θ (s s i )) is an unbiased estimate of ∇ θ J (θ) <ref type="bibr" target="#b29">[30]</ref>. The actor-critic framework combines π and V for stable training. In this work, we utilize V Ω (s s i ) to estimate the expected feature total reward. Hence, the v i can be considered as an estimate of the advantage of action, which can be defined as follows:</p><formula xml:id="formula_13">v i = r b − V Ω (s s i ).<label>(10)</label></formula><p>The architecture of the value network V is similar to policy network, except that the final output layer is a regression function. V is designed to estimate the expected feature total reward for each state, which can be optimized by:</p><formula xml:id="formula_14">Ω = Ω − l * 1 n n i=1 ∇ Ω r b − V Ω (s s i ) 2 2 ,<label>(11)</label></formula><p>where Ω is the trainable parameters of value network V .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 The optimization strategy of the RTNet</head><p>Require: episode number L, source data {X s , Y s } and target data X t . 1: Initialize each module in the RTNet. <ref type="bibr">2:</ref> for episode = 1 → L do 3:</p><formula xml:id="formula_15">for each (X s b , Y s b ), (X t b ) ∈ (X s , Y s ), (X t ) do 4:</formula><p>Obtain the states S s b = {s s i } n i=1 through the domain adaptation model, where s s i = [F (x s i ), y s i , α].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5:</head><p>Utilizes -greedy strategy to sample A s b = {a s i } n i=1 based on π(S s b ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6:</head><p>Select source training batch</p><formula xml:id="formula_16">(X s b , Y s b ) from (X s b , Y s b ) according to A s b . 7:</formula><p>Update domain adaptation model (F and C) with (X s b , Y s b ) and (X t b ) as in Eq. 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>8:</head><p>Obtain reward r b on G t with X s b as in Eq. 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>9:</head><p>Update G s,t with X s b and X t b as in Eq. 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>10:</head><p>Store (S s b , A s b , r b ) to an episode history H.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>11:</head><p>end for 12:</p><formula xml:id="formula_17">for each (S s b , A s b , r b ) ∈ H do 13:</formula><p>Obtain the future total reward r b as in Eq. 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>14:</head><p>Obtain the estimated future total reward V (S s b ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>15:</head><p>Update π as Eq. 9 and update V as Eq. 11.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>16:</head><p>end for 17: end for</p><p>As the RDS and DA model interact with each other during training, we train them jointly. To ensure that the DA model can provide accurate states and rewards in the early stages of training, we first pre-train G s,t , F , and C through the classification loss L s of source samples and Eq. 6. We follow the previous work <ref type="bibr" target="#b21">[22]</ref> to train the RTNet, the detailed training process is shown in Algorithm 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Theoretical Analysis</head><p>In this section, we prove theoretically that our method improves the expected error boundary on the target sample by using the theory of domain adaptation <ref type="bibr" target="#b1">[2]</ref>. Theorem 1. Let H be the common hypothesis class for source S and target T , the upper bound of the expected error for the target domain, t (h), is defined as:</p><formula xml:id="formula_18">t (h) ≤ s (h) + 1 2 d H∆H (p, q) + C, ∀h ∈ H,<label>(12)</label></formula><p>where the expected error for the target domain is bounded by three terms: (1) s (h) is the expected error for source domain; (2) d H∆H (p, q) is the domain divergence measured by a discrepancy distance between source distribution p and target distribution q;</p><formula xml:id="formula_19">(3) C = min h [ s (h) + t (h)]</formula><p>is the shared error of the ideal joint hypothesis.</p><p>In Eq. 12, s (h) is expected to be small due to it can be optimized by a deep network with the source labels. Prior DA methods <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b11">12]</ref> seek to minimize d H∆H (p, q) by aligning the global distributions of S and T . However, Eq. 12 assumes that the label space of the source and target domains is consistent, which is not held in the PDA scenario. Therefore, blindly aligning the global distribution is an erroneous solution, which forces the target sample to align with the outlier source classes <ref type="figure" target="#fig_1">(Figure 1a</ref>), resulting in a large t (h) in C and triggering a negative transfer. To this end, we need to ensure the consistency of the source and target label spaces. However, it is not possible to directly filter the outlier source classes as the label space of the target domain is unknown. Hence, we propose the RT-Net, which extends the DA methods to automatically filter the outlier source classes, so that the Eq. 12 can get the correct results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Datasets</head><p>Office-31 <ref type="bibr" target="#b23">[24]</ref> is a widely-used visual domain adaptation dataset, which contains 4,110 images of 31 categories from three distinct domains: Amazon website (A), Webcam (W) and DSLR camera (D). Following the settings in <ref type="bibr" target="#b3">[4]</ref>, we select the same 10 categories in each domain to build new target domains and create 6 transfer scenarios as in <ref type="table" target="#tab_2">Table 1</ref>.  Digital Dataset includes five domain adaptation benchmarks: Street View House Numbers (SVHN) <ref type="bibr" target="#b19">[20]</ref>, MNIST <ref type="bibr" target="#b15">[16]</ref>, MNIST-M <ref type="bibr" target="#b11">[12]</ref>, USPS <ref type="bibr" target="#b13">[14]</ref> and synthetic digits dataset (SYN) <ref type="bibr" target="#b11">[12]</ref>, which consist of ten categories. We select 5 categories (digit 0 to digit 4) as target domain in each dataset and construct four PDA tasks as in <ref type="table" target="#tab_2">Table 1</ref>.</p><p>Office-Home <ref type="bibr" target="#b27">[28]</ref> is a more challenging DA dataset, which consists of 4 different domains: Artistic images (Ar), Clipart images (Cl), Product images (Pr) and Real-World images (Rw). For each transfer task, when a domain is used as the source domain, we use samples from all 65 categories; when a domain is used as the target domain, we select the samples from the same 25 categories as <ref type="bibr" target="#b5">[6]</ref>. Hence, we can build twelve PDA tasks as in <ref type="table" target="#tab_3">Table 2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Implementation Details</head><p>The RTNet is implemented via Tensorflow and trained with the Adam optimizer. For the experiments on Office-31 and Office-Home, we employ the ResNet-50 pre-trained on ImageNet as the backbone of domain adaptation model and fine-tune the parameters of the fully connected layers and the final block. For the experiments on digital datasets, we adopt modified LeNet as the backbone of domain adaptation model and update all of the weights. All images are converted to grayscale and resized to 32 × 32.</p><p>In RTNet, the structure of each module can be seen in Appendix. To guarantee fair comparison, the same frameworks are used for F and C in all comparison methods, and each method is trained five times and the average is taken as the final result. For all hyperparameters, we set l = 1e − 4, λ 1 = 7 and γ = 0.85, which selected by using a grid search on the performance of the validation set. The parameter sensitivity analysis can be seen in Appendix. To ease model selection, the hyperparameters of comparison methods are gradually changing from 0 to 1 as in <ref type="bibr" target="#b17">[18]</ref>. <ref type="table" target="#tab_2">Tables 1 and 2</ref> show the classification results on three datasets. By looking these tables, several observations can be made. (1) the previous standard DA methods including those based on adversarial network (DANN), and those based on moment match (DAN, JDDA, and CORAL) perform even worse than non-adaptation (NoA) model, indicating that they were affected by the negative transfer. the previous PDA methods which only rely on the highlevel information to obtain the weight, RTNet / RTNet adv adopts the high-level information to select the source sample, and employs the pixel-level information as evaluation criteria to guide the learning of policy network. Thus, this selection mechanism can detect outlier source classes more effectively and transfer relevant samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Result and Discussion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Analysis</head><p>Feature Visualization: We visualize the features of adaptation layer using t-SNE <ref type="bibr" target="#b9">[10]</ref>. As shown in <ref type="figure" target="#fig_2">Figure 3</ref>, several observations can be made. (1) by comparing <ref type="figure" target="#fig_2">Figures 3a, 3e and Figures 3b, 3f</ref>, we find that CORAL forces the target domain to be aligned with the whole source domain, including outlier classes that do not exist in the target label space, which triggers negative transfer. <ref type="bibr" target="#b1">(2)</ref> as can be seen in <ref type="figure" target="#fig_2">Figures 3d, 3h</ref>, RTNet correctly matches the target samples to related source samples by integrating the RDS into CORAL to filter outlier classes, which confirms that the matching-based DA methods can be extended to solve PDA problem by embedding RDS. (3) compared with <ref type="figure" target="#fig_2">Figure 3c</ref>, 3g, RTNet matches the related source domain and the target domain more accurately, indicating that it is more effective than ETN in suppressing the side effect of outlier classes by considering high-level and pixel-level information.</p><p>Convergence Performance: We analyze the convergence of RTNet. As shown in <ref type="figure" target="#fig_4">Figure 4a</ref>, the test errors of DANN and CORAL are higher than ResNet due to negative transfer. RTNet fast and stably converges to the lowest test error, indicating that it can be efficiently trained to solve PDA problem. As shown in <ref type="figure" target="#fig_4">Figure 4b</ref>, the reward gradually increases as the episode progresses, meaning that the RDS can learn the correct policy to maximize the reward and filter out outlier source classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Case Study and Performance Interpretation</head><p>The results in Section 4.3 demonstrate the effectiveness of the RTNet. However, the lack of interpretability of the neural architecture makes it difficult to speculate on the reasons behind decisions made by RDS. Therefore, we introduce the overall performance and specific case to prove the ability of the selector to select and filter samples.</p><p>Statistics of Class-wise Retention Probabilities: We utilize E(π θ (S s c )) to verify the ability of the selector to filter the samples, averaging the retention probabilities of each class of source domain. S s c represents a source sample set, which contains samples belonging to class c. As shown in <ref type="figure" target="#fig_4">Figure 4c</ref>, RTNet assigns much larger retention probabilities to the shared classes than to the outlier classes. These results prove that RTNet has the ability to automatically select relevant source classes and filter out outlier classes. Besides, the outlier classes with a similar appearance to the shared classes, such as 7 and 9, have a larger retention probability than other outlier classes, which indicates that the selector we develop can indeed select source samples similar to the target domain based on the pixel-level information.</p><p>Class-wise Selected Ratio and Filtered Ratio: We input the sampled SVHN samples into RTNet for sample selection. As shown in <ref type="figure" target="#fig_4">Figure 4d</ref>, the outlier samples (5, 6 and 8) that differ significantly in appearance from the shared samples (0-4) can be filtered out by 92% on average, while the outlier classes (7 and 9) with smaller appearance differences from the shared classes can be filtered out by 72% on average. For shared classes, the ratio of samples filtered   in each class is not much different, and an average of 8.2% of the samples are filtered by error. These results indicate that RTNet can effectively filter outlier source samples, especially those that have large differences in appearance with shared classes and keep related source samples well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Wasserstein Distances between Domains:</head><p>The Wasserstein distance measures the distance between two probability distributions <ref type="bibr" target="#b28">[29]</ref>. We take the selection of the selector in the last episode as the result of the selection and calculate the Wasserstein distance between target samples and source samples, including selected and filtered source samples. We observe that the patterns of the two tasks are identical through the results of <ref type="table" target="#tab_5">Table 3</ref>: (1) W select &lt; W all , which indicates that the sample selected by the selector is closer to the target domain and thus may contribute to the transfer process. (2) W f ilter &gt; W all , which means that the filtered source samples are extremely dissimilar to the target domain and may result in a negative transfer. These findings show that our proposal can select source samples whose Wasserstein distances are close to the target domain. This makes sense because such source samples can be more easily transferred and helpful to the target domain. Target Classes:</p><p>We conduct experiments to evaluate the performance of RTNet when the number of target classes varies. As shown in <ref type="figure" target="#fig_4">Figure 4e</ref>, as the number of target classes decreases, the performance of CORAL degrades rapidly, indicating that negative transfer becomes more and more serious as the label distribution becomes larger. RT-Net performs better than other methods, indicating that it can suppress negative transfer more effectively. Moreover, RTNet is superior to CORAL when the source and target label spaces are consistent (A31→W31), which shows that our method does not filter erroneously when there are no outlier classes. As shown in <ref type="figure">Figure 5</ref>, on the A31→W31 task, we analyze some of the source samples filtered by RDS and find that most of them are noise samples, which have mismatches between labels and images. For example, an image of a mouse is wrongly labeled as a keyboard in the Office-31 dataset. This case study shows that the RDS can filter noisy samples to improve the performance even if the label space of the source and target domains are consistent.  <ref type="figure">Figure 5</ref>: Case study on A31→W31 task. These noisy samples with mismatches between labels and images are sampled from the source samples filtered by RDS. The description below the image is the label provided by the dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this work, we propose an end-to-end RTNet, which utilizes both high-level and pixel-level information to address PDA problem. RTNet applies RL to train a reinforced data selector based on actor-critic framework to filter outlier source classes with the purpose of mitigating negative transfer. Unlike previous adversarial-based PDA methods, The RDS we proposed can be integrated into almost all DA models including those based on adversarial network, and those based on moment match. Note that, the results of RTNet adv based on adversarial model are shown in Appendix. The state-of-the-art experimental results confirm the efficacy of RTNet.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>(a) Negative transfer is triggered by mismatch. (b) Negative transfer is mitigated by filtering out outlier classes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>(2) PDA methods (ETN and PADA) improve classification accuracy by a large margin since their weighting mechanisms can mitigate negative transfer caused by outlier categories. (3) Comparing the model with the RDS (RTNet and RTNet adv ) and the model without the RDS (CORAL and DANN), the model with the RDS can alleviate the negative transfer to greatly improve the performance of the model in the target domain. This proves that the selector we design is a general model and can be easily integrated into existing DA models, including not only matching-based methods but also adversarial-based methods. (4) RTNet / RTNet adv achieves the best accuracy on most transfer tasks. Different from The t-SNE visualization on A31→W10 ((a)-(d)) and SVHN10→MNIST5 ((e)-(h)). Red points represent target samples and blue points represent source samples. The results generated from category information are shown in Appendix.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>(a) Convergence analysis on SVHN10→MNIST5. (b) Learning curve on SVHN10→MNIST5. (c) Source classwise retention probability learned by policy network on SVHN10→MNIST5. (d) Class-wise selected ratio and filtered ratio evaluated by RDS trained on SVHN10→MNIST5. (e) The accuracy curve of varying the number of target classes on A→W.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Outlier Sample Related Sample High Reward Low Reward F Selected Source Batch Target Batch C G s Reward Reward Accumulation Value Network Update ′ Policy Network ( ) State Actions Source Batch after Data Selection Reinforced Data Selector Domain Adaptation Model</head><label></label><figDesc></figDesc><table><row><cell>DA Method</cell><cell>′ − ( )</cell><cell>Update</cell></row><row><cell>G t</cell><cell>Source Batch</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>, we feed X s b into the DA model to solve the PDA problem. Finally, the DA model moves to the next state s after updated with X s</figDesc><table><row><cell>we can obtain the corresponding</cell></row><row><cell>states S s b = {s s i } n i=1 through the DA model. The RDS then utilizes the policy π(S s b ) to determine the actions A s b = {a s i } n i=1 taken on source samples, where a s i ∈ {0, 1}. a s i = 0 means to filter outlier sample from X s b . Thus, we</cell></row><row><cell>get a new source batch X s b related to target domain. In-</cell></row><row><cell>stead of X s b</cell></row></table><note>b and X t b</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Performance on Office-31 dataset and Digital Dataset. RTNet adv represents the model that integrates the reinforced data selector into the DANN. For the integrity and readability of the paper, RTNet adv will be introduced in the Appendix.</figDesc><table><row><cell>Type</cell><cell>Method</cell><cell></cell><cell></cell><cell cols="2">Office-31</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Digital Dataset</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="7">A31→W10 D31→W10 W31→D10 A31→D10 D31→A10 W31→A10 Avg</cell><cell>SVHN10 → MNIST5</cell><cell>MNIST10 →MNIST-M5</cell><cell>USPS10 →MNIST5</cell><cell>SYN10 →MNIST5</cell><cell>Avg</cell></row><row><cell cols="2">NoA ResNet / LeNet</cell><cell>76.5±0.3</cell><cell>99.2±0.2</cell><cell>97.7±0.1</cell><cell>87.5±0.2</cell><cell>87.2±0.1</cell><cell>84.1±0.3</cell><cell>88.7</cell><cell>79.6±0.3</cell><cell>60.2±0.4</cell><cell>76.6±0.6</cell><cell>91.3±0.4</cell><cell>76.9</cell></row><row><cell></cell><cell>DAN[17]</cell><cell>53.6±0.7</cell><cell>62.7±0.5</cell><cell>57.8±0.6</cell><cell>47.7±0.5</cell><cell>61.2±0.6</cell><cell>69.7±0.5</cell><cell>58.8</cell><cell>63.5±0.5</cell><cell>48.9±0.5</cell><cell>61.3±0.4</cell><cell>55.0±0.3</cell><cell>57.2</cell></row><row><cell>DA</cell><cell>DANN[12] CORAL[25]</cell><cell>62.8±0.6 52.1±0.5</cell><cell>71.6±0.4 65.2±0.2</cell><cell>65.6±0.5 64.1±0.7</cell><cell>65.1±0.7 58.0±0.5</cell><cell>78.9±0.3 73.1±0.4</cell><cell>79.2±0.4 77.9±0.3</cell><cell>70.5 65.1</cell><cell>68.9±0.7 60.8±0.6</cell><cell>50.6±0.7 43.4±0.5</cell><cell>83.3±0.5 61.7±0.5</cell><cell>77.6±0.4 74.4±0.4</cell><cell>70.1 60.1</cell></row><row><cell></cell><cell>JDDA[7]</cell><cell>73.5±0.6</cell><cell>93.1±0.3</cell><cell>89.3±0.2</cell><cell>76.4±0.4</cell><cell>77.6±0.1</cell><cell>82.8±0.2</cell><cell>82.1</cell><cell>72.1±0.4</cell><cell>54.3±0.2</cell><cell>71.7±0.4</cell><cell>85.2±0.2</cell><cell>70.8</cell></row><row><cell></cell><cell>PADA [5]</cell><cell>86.3±0.4</cell><cell>99.3±0.1</cell><cell>100±0.0</cell><cell>90.4±0.1</cell><cell>91.3±0.2</cell><cell>92.6±0.1</cell><cell>93.3</cell><cell>90.4±0.3</cell><cell>89.1±0.2</cell><cell>97.4±0.3</cell><cell>96.5±0.1</cell><cell>93.4</cell></row><row><cell>PDA</cell><cell>ETN[6] RTNet</cell><cell>93.4±0.3 95.1±0.3</cell><cell>99.3±0.1 100±0.0</cell><cell>99.2±0.2 100±0.0</cell><cell>95.5±0.4 97.8±0.1</cell><cell>95.4±0.1 93.9±0.1</cell><cell>91.7±0.2 94.1±0.1</cell><cell>95.8 96.8</cell><cell>93.6±0.2 95.3±0.1</cell><cell>92.5±0.1 94.2±0.2</cell><cell>96.5±0.1 98.9±0.1</cell><cell>97.8±0.2 99.2±0.0</cell><cell>95.1 96.9</cell></row><row><cell></cell><cell>RTNetadv</cell><cell>96.2±0.3</cell><cell>100±0.0</cell><cell>100±0.0</cell><cell>97.6±0.1</cell><cell>92.3±0.1</cell><cell>95.4±0.1</cell><cell>96.9</cell><cell>97.2±0.1</cell><cell>94.6±0.2</cell><cell>98.5±0.1</cell><cell>99.7±0.0</cell><cell>97.5</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Performance on the Office-Home dataset. RTNet adv represents the model that integrates the reinforced data selector into the DANN. For the integrity and readability of the paper, RTNet adv will be introduced in the Appendix. 52.9±0.4 63.7±0.2 45.0±0.3 51.7±0.3 49.3±0.1 42.4±0.2 31.5±0.4 68.7±0.1 59.7±0.3 34.6±0.4 67.8±0.1 50.3 DANN[12] 43.2±0.5 61.9±0.2 72.1±0.4 52.3±0.4 53.5±0.2 57.9±0.1 47.2±0.3 35.4±0.1 70.1±0.3 61.3±0.2 37.0±0.2 71.7±0.3 55.3 CORAL[25] 38.2±0.1 55.6±0.3 65.9±0.2 48.4±0.4 52.5±0.1 51.3±0.2 48.9±0.3 32.6±0.1 67.1±0.2 63.8±0.4 35.9±0.2 69.8±0.77.2±0.3 64.3±0.1 67.5±0.3 75.8±0.2 69.3±0.1 54.2±0.1 83.7±0.2 75.6±0.3 56.7±0.2 84.5±0.3 70.5 RTNet 62.7±0.1 79.3±0.2 81.2±0.1 65.1±0.1 68.4±0.3 76.5±0.1 70.8±0.2 55.3±0.1 85.2±0.3 76.9±0.2 59.1±0.2 83.4±0.3 72.0 RTNet adv 63.2±0.1 80.1±0.2 80.7±0.1 66.7±0.1 69.3±0.2 77.2±0.2 71.6±0.3 53.9±0.3 84.6±0.1 77.4±0.2 57.9±0.3 85.5±0.1 72.3</figDesc><table><row><cell>Type</cell><cell>Method</cell><cell>Ar→Cl</cell><cell>Ar→Pr</cell><cell>Ar→Rw</cell><cell>Cl→Ar</cell><cell>Cl→Pr</cell><cell>Cl→Rw</cell><cell>Pr→Ar</cell><cell>Pr→Cl</cell><cell>Pr→Rw</cell><cell>Rw→Ar</cell><cell>Rw→Cl</cell><cell>Rw→Pr</cell><cell>Avg</cell></row><row><cell>NoA</cell><cell>ResNet</cell><cell cols="13">47.2±0.2 66.8±0.3 76.9±0.5 57.6±0.2 58.4±0.1 62.5±0.3 59.4±0.3 40.6±0.2 75.9±0.3 65.6±0.1 49.1±0.2 75.8±0.4 61.3</cell></row><row><cell>DA</cell><cell>DAN[17]</cell><cell cols="13">35.7±0.2 1 52.5</cell></row><row><cell></cell><cell>JDDA[7]</cell><cell cols="13">45.8±0.4 63.9±0.2 74.1±0.3 51.8±0.2 55.2±0.3 60.3±0.2 53.7±0.2 38.3±0.1 72.6±0.2 62.5±0.1 43.3±0.3 71.3±0.1 57.7</cell></row><row><cell></cell><cell>PADA[5]</cell><cell cols="13">53.2±0.2 69.5±0.1 78.6±0.1 61.7±0.2 62.7±0.3 60.9±0.1 56.4±0.5 44.6±0.2 79.3±0.1 74.2±0.1 55.1±0.3 77.4±0.2 64.5</cell></row><row><cell>PDA</cell><cell>ETN[6]</cell><cell cols="2">60.4±0.3 76.5±0.2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>The Wasserstein distances between domains.</figDesc><table><row><cell>Name</cell><cell>Domains</cell><cell>SVHN10 →MNIST5</cell><cell>A31→W10</cell></row><row><cell>W all</cell><cell>T ↔ S</cell><cell>0.2574</cell><cell>4.3233</cell></row><row><cell cols="2">W select T ↔ S select</cell><cell>0.1645</cell><cell>2.3179</cell></row><row><cell cols="2">W f ilter T ↔ S filter</cell><cell>0.3679</cell><cell>5.6308</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Deep reinforcement learning: A brief survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Arulkumaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><forename type="middle">Peter</forename><surname>Deisenroth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miles</forename><surname>Brundage</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anil Anthony</forename><surname>Bharath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Magazine</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="26" to="38" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">A theory of learning from different domains. Machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shai</forename><surname>Ben-David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koby</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Kulesza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><forename type="middle">Wortman</forename><surname>Vaughan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="151" to="175" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Dataset shift in machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masashi</forename><surname>J Quiñonero Candela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anton</forename><surname>Sugiyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil D</forename><surname>Schwaighofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lawrence</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Partial transfer learning with selective adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhangjie</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingsheng</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael I Jordan</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2724" to="2732" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Partial adversarial domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhangjie</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lijia</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingsheng</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="135" to="150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Learning to transfer examples for partial domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhangjie</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaichao</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingsheng</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.12230</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Joint domain alignment and discriminative feature learning for unsupervised deep domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhihong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boyuan</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyu</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="3296" to="3303" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Homm: Higherorder moment matching for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhihang</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhihong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaowei</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyu</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xian-Sheng</forename><surname>Hua</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.11976</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Deep joint two-stream wasserstein autoencoder and selective attention alignment for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhihong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyu</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaowei</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Computing and Applications</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Decaf: A deep convolutional activation feature for generic visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judy</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ning</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="647" to="655" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Learning how to active learn: A deep reinforcement learning approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="595" to="605" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Domain-adversarial training of neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaroslav</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniya</forename><surname>Ustinova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hana</forename><surname>Ajakan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Germain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">François</forename><surname>Laviolette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Marchand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2096" to="2030" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Cycada: Cycle-consistent adversarial domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judy</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taesung</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Yan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A database for handwritten text recognition research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Hull</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis &amp; Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="550" to="554" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Actor-critic algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vijay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">N</forename><surname>Konda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tsitsiklis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="1008" to="1014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition. proc ieee</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">L</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Learning transferable features with deep adaptation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingsheng</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="97" to="105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Deep transfer learning with joint adaptation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingsheng</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael I Jordan</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2208" to="2217" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Human-level control through deep reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Volodymyr</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Veness</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Marc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Bellemare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><forename type="middle">K</forename><surname>Riedmiller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Fidjeland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ostrovski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">518</biblScope>
			<biblScope unit="issue">7540</biblScope>
			<biblScope unit="page">529</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Reading digits in natural images with unsupervised feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuval</forename><surname>Netzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Bissacco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Nips Workshop on Deep Learning &amp; Unsupervised Feature Learning</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A survey on transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Sinno Jialin Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on knowledge and data engineering</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1345" to="1359" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Learning to selectively transfer: Reinforced transfer learning for deep text matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minghui</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyu</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haiqing</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="699" to="707" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">On-line Qlearning using connectionist systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gavin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mahesan</forename><surname>Rummery</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Niranjan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="volume">37</biblScope>
		</imprint>
		<respStmt>
			<orgName>Department of Engineering Cambridge, England</orgName>
		</respStmt>
	</monogr>
	<note>University of Cambridge</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Adapting visual category models to new domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Kulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Fritz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="213" to="226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Deep coral: Correlation alignment for deep domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baochen</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="443" to="450" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Adversarial discriminative domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judy</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Deep domain confusion: Maximizing for domain invariance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judy</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ning</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.3474</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Deep hashing network for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hemanth</forename><surname>Venkateswara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jose</forename><surname>Eusebio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shayok</forename><surname>Chakraborty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sethuraman</forename><surname>Panchanathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5018" to="5027" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Topics in optimal transportation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cdric</forename><surname>Villani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ams Graduate Studies in Mathematics</title>
		<imprint>
			<biblScope unit="page">370</biblScope>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Simple statistical gradient-following algorithms for connectionist reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ronald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="229" to="256" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Reinforced cotraining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">Yang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL HLT 2018</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1252" to="1262" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Importance weighted adversarial nets for partial domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zewei</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanqing</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Ogunbona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8156" to="8164" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
