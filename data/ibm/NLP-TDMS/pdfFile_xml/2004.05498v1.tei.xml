<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">FDA: Fourier Domain Adaptation for Semantic Segmentation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanchao</forename><surname>Yang</surname></persName>
							<email>yanchao.yang@cs.ucla.edu</email>
							<affiliation key="aff0">
								<orgName type="laboratory">UCLA Vision Lab</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Soatto</surname></persName>
							<email>soatto@cs.ucla.edu</email>
							<affiliation key="aff1">
								<orgName type="laboratory">UCLA Vision Lab</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">FDA: Fourier Domain Adaptation for Semantic Segmentation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T18:38+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We describe a simple method for unsupervised domain adaptation, whereby the discrepancy between the source and target distributions is reduced by swapping the lowfrequency spectrum of one with the other. We illustrate the method in semantic segmentation, where densely annotated images are aplenty in one domain (e.g., synthetic data), but difficult to obtain in another (e.g., real images). Current state-of-the-art methods are complex, some requiring adversarial optimization to render the backbone of a neural network invariant to the discrete domain selection variable. Our method does not require any training to perform the domain alignment, just a simple Fourier Transform and its inverse. Despite its simplicity, it achieves state-of-the-art performance in the current benchmarks, when integrated into a relatively standard semantic segmentation model. Our results indicate that even simple procedures can discount nuisance variability in the data that more sophisticated methods struggle to learn away. 1</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Unsupervised domain adaptation (UDA) refers to adapting a model trained with annotated samples from one distribution (source), to operate on a different (target) distribution for which no annotations are given. For example, the source domain can consist of synthetic images and their corresponding pixel-level labels (semantic segmentation), and the target can be real images with no ground-truth annotations. Simply training the model on the source data does not yield satisfactory performance on the target data, due to the covariate shift. In some cases, perceptually insignificant changes in the low-level statistics can cause significant deterioration of the performance of the trained model, unless UDA is performed.</p><p>State-of-the-art UDA methods train a deep neural network (DNN) model for a given task (say, semantic segmentation) plus an auxiliary loss designed to make the model <ref type="bibr" target="#b0">1</ref> Code available at: https://github.com/YanchaoYang/FDA invariant to the binary selection of source/target domain. This requires difficult adversarial training. We explore the hypothesis that simple alignment of the low-level statistics between the source and target distributions can improve performance in UDA, without any need for training beyond the primary task of semantic segmentation.</p><p>Our method is illustrated in <ref type="figure">Fig. 1</ref>: One simply computes the (Fast) Fourier Transform (FFT) of each input image, and replaces the low-level frequencies of the target images into the source images before reconstituting the image for training, via the inverse FFT (iFFT), using the original annotations in the source domain.</p><p>To test our hypothesis, we use as a baseline (lower bound) the performance on the target data of a model trained on the source. As a paragon (upper bound), we use a state-of-the-art model with adversarial training <ref type="bibr" target="#b18">[19]</ref>. We expect that such a simple, "zero-shot" alignment of lowlevel statistics would improve the baseline, and hopefully come close to the paragon. However, the method actually outperforms the paragon in semantic segmentation. We do not take this to mean that our method is the way to perform UDA, in particular for general tasks beyond semantic segmentation. However, the fact that such a simple method outperforms sophisticated adversarial learning suggests that these models are not effective at managing low-level nuisance variability.</p><p>Fourier domain adaptation requires selecting one free parameter, the size of the spectral neighborhood to be swapped (green square in <ref type="figure">Fig. 1</ref>). We test a variety of sizes, as well as a simple multi-scale method consisting of averaging the results arising from different domain sizes.</p><p>The motivation for our approach stems from the observation that the low-level spectrum (amplitude) can vary significantly without affecting the perception of high-level semantics. Whether something is a vehicle or a person should not depend on the characteristics of the sensor, or the illuminant, or other low-level sources of variability. Yet such variability has significant impact on the spectrum, forcing a learning-based model to "learn it away" along with other nuisance variability. If this variability is not represented in the training set, the models fail to generalize. However, <ref type="figure">Figure 1</ref>. Spectral Transfer: Mapping a source image to a target "style" without altering semantic content. A randomly sampled target image provides the style by swapping the low-frequency component of the spectrum of the source image with its own. The outcome "source image in target style" shows a smaller domain gap perceptually and improves transfer learning for semantic segmentation as measured in the benchmarks in Sect. <ref type="bibr">3.</ref> there are sources of variability that we know at the outset not to be informative of the task at hand. The categorical interpretation of an image is unchanged if we manipulated global photometric statistics. Any monotonic rescaling of the color map, including non-linear contrast changes, are known nuisance factors, and can be eliminated at the outset without having to be learned. This is especially important since it appears that networks do not transfer well across different low-level statistics <ref type="bibr" target="#b0">[1]</ref>. While one could normalize contrast transformations, in the absence of a canonical reference our Fourier transfer is among the simplest methods to register them. The broader point is that known nuisance variability can be dealt with at the outset, without the need to learn it through complex adversarial training.</p><p>In the next section, we describe our method in more detail and then test it empirically in standard UDA benchmarks. Before doing so, we place our work in the context of the current literature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.">Related Work</head><p>Semantic Segmentation has benefited by the continuous evolution of DNN architectures <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b40">41]</ref>. These are generally trained on datasets with dense pixellevel annotations, such as Cityscapes <ref type="bibr" target="#b8">[9]</ref>, PASCAL <ref type="bibr" target="#b10">[11]</ref> and MSCOCO <ref type="bibr" target="#b23">[24]</ref>. Manual annotation is not scalable <ref type="bibr" target="#b52">[53]</ref>, and capturing representative imaging conditions adds to the challenges. This has spurred interest in using synthetic data, such as from GTA5 <ref type="bibr" target="#b32">[33]</ref> and SYNTHIA <ref type="bibr" target="#b33">[34]</ref>. Due to the domain shift, models trained on the former tend to perform poorly on the latter.</p><p>Domain Adaptation aims to reduce the shift between two distributions <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b45">46]</ref>. A common discrepancy measure is MMD (Maximum Mean Discrepancy) and its kernel variants <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b26">27]</ref>, extended by CMD (Central Moment Discrepancy) <ref type="bibr" target="#b51">[52]</ref> to higher-order statistics <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b29">30]</ref>. Unfortunately, two datasets are not guaranteed to be aligned even if the MMD is minimized, due to the limited expressiveness of such metrics. Adversarial Learning for domain adaptation <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b20">21]</ref> uses a discriminator trained to maximize the confusion between source and target representations, thus reducing the domain discrepancy. Alignment in high-level feature space <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b30">31]</ref> can be counter-productive for semantic segmentation, unlike image-level classification, <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b36">37]</ref>, due to the complex representations and the difficulty in stabilizing adversarial training.</p><p>We draw on image-to-image translation and style transfer <ref type="bibr" target="#b54">[55,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b7">8]</ref> to improve domain adaptation for semantic segmentation. Cycada <ref type="bibr" target="#b18">[19]</ref> aligns representations at both the pixel-level and feature-level. DCAN <ref type="bibr" target="#b46">[47]</ref> preserves spatial structures and semantics by the channel-wise alignment of multi-level features. To facilitate image space alignment, <ref type="bibr" target="#b3">[4]</ref> proposes domain-invariant structure extraction to disentangle domain-invariant and domain-specific representations. <ref type="bibr" target="#b5">[6]</ref> uses dense depth, readily available in synthetic data. <ref type="bibr" target="#b16">[17]</ref> generates intermediate style images between source and target. CLAN <ref type="bibr" target="#b28">[29]</ref> enforce local semantic consistency in global alignment. <ref type="bibr" target="#b52">[53]</ref> proposes curriculumstyle learning to align both global distributions over images and local distributions over landmark superpixels. BDL <ref type="bibr" target="#b22">[23]</ref> employs bidirectional learning, where the segmentation network is exploited by the image transformation network. There are also discriminators applied on the output space <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b42">43]</ref> to align source and target segmentation.</p><p>The use of a transformer network and discriminators at multiple levels is computationally demanding, and more challenging to train within the adversarial framework. In contrast, our method does not utilize any image translation networks to generate training images, nor discriminators to align pixel/feature-level distributions. The only network trained in our method is for the primary task of semantic segmentation. We use a fully convolutional network that outputs pixel-wise class (log) likelihoods. Note in the concurrent work <ref type="bibr" target="#b47">[48]</ref>, a transformer network trained with phase preservation as a constraint also generates domain aligned images that maintain semantic content in the source images. Similar adaptation gain is then achieved by enforcing the scene compatibility learned using Conditional Prior Networks <ref type="bibr" target="#b48">[49]</ref>.</p><p>Domain adaptation and Semi-Supervised Learning (SSL) are closely related. When the domains are aligned, unsupervised domain adaptation becomes SSL. CBST <ref type="bibr" target="#b55">[56]</ref> and BDL <ref type="bibr" target="#b22">[23]</ref> used "self-training" as a form of regularization <ref type="bibr" target="#b34">[35]</ref>, exploiting target images by treating pseudo-labels as ground truth. ADVENT <ref type="bibr" target="#b44">[45]</ref> minimizes both the entropy of the pixel-wise predictions and the adversarial loss of the entropy maps. The computation of the pixel-wise entropy does not depend on any networks and entails no overhead. We employ entropy minimization to regularize the training of our segmentation network. Motivated by <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b11">12]</ref>, we also average the output of different models that are trained with different spectral domain size, which fosters multiband transfer as discussed in detail next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Method</head><p>We first describe the simple Fourier alignment, which does not require any training, and then describe the loss we use to train the overall semantic segmentation network to leverage the Fourier alignment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Fourier Domain Adaptation (FDA)</head><p>In unsupervised domain adaptation (UDA), we are given a source dataset</p><formula xml:id="formula_0">D s = {(x s i , y s i ) ∼ P (x s , y s )} Ns i=1 , where x s ∈ R H×W ×3 is a color image, and y s ∈ R H×W is the semantic map associated with x s . Similarly D t = {x t i } Nt i=1</formula><p>is the target dataset, where the ground truth semantic labels are absent. Generally, the segmentation network trained on D s will have a performance drop when tested on D t . Here, we propose Fourier Domain Adaptation (FDA) to reduce the domain gap between the two datasets. Let F A , F P : R H×W ×3 → R H×W ×3 be the amplitude and phase components of the Fourier transform F of an RGB image, i.e., for a single channel image x we have:</p><formula xml:id="formula_1">F(x)(m, n) = h,w x(h, w)e −j2π   h H m+ w W n   , j 2 = −1</formula><p>(1) which can be implemented efficiently using the FFT algorithm in <ref type="bibr" target="#b12">[13]</ref>. Accordingly, F −1 is the inverse Fourier transform that maps spectral signals (phase and amplitude) back to image space. Further, we denote with M β a mask, whose value is zero except for the center region where β ∈ (0, 1):</p><formula xml:id="formula_2">M β (h, w) = 1 (h,w)∈[−βH:βH,−βW :βW ]<label>(2)</label></formula><p>here we assume the center of the image is (0, 0). Note that β is not measured in pixels, thus the choice of β does not depend on image size or resolution. Given two randomly sampled images x s ∼ D s , x t ∼ D t , Fourier Domain Adaptation can be formalized as:</p><formula xml:id="formula_3">x s→t = F −1 ([M β •F A (x t )+(1−M β )•F A (x s ), F P (x s )]) (3)</formula><p>where the low frequency part of the amplitude of the source image F A (x s ) is replaced by that of the target image x t . Then, the modified spectral representation of x s , with its phase component unaltered, is mapped back to the image x s→t , whose content is the same as x s , but will resemble the appearance of a sample from D t . The process is illustrated in <ref type="figure">Fig. 1</ref> where the mask M β is shown in green.</p><p>Choice of β: As we can see from Eq. (3), β = 0 will render x s→t the same as the original source image x s . On the other hand, when β = 1.0, the amplitude of x s will be replaced by that of x t . <ref type="figure" target="#fig_0">Fig. 2</ref> illustrates the effect of β. We find that, as β increases to 1.0, the image x s→t approaches the target image x t , but also exhibits visible artifacts, as can be seen from the enlarged area in <ref type="figure" target="#fig_0">Fig. 2</ref>. We set β ≤ 0.15. However, in <ref type="table">Table 1</ref> we show the effect of various choices of β along with the average of the resulting models, akin to a simple multi-scale pooling method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">FDA for Semantic Segmentation</head><p>Given the adapted source dataset D s→t , 2 we can train a semantic segmentation network φ w , with parameters w, by minimizing the following cross-entropy loss:</p><formula xml:id="formula_4">L ce (φ w ; D s→t ) = − i y s i , log(φ w (x s→t i )) . (4)</formula><p>Since FDA aligns the two domains, UDA becomes a semisupervised learning (SSL) problem. The key to SSL is the regularization model. We use as a criterion a penalty for the decision boundary to cross clusters in the unlabeled space.  <ref type="figure">Fig. 1</ref>, where the spectrum is swapped: increasing β will decrease the domain gap but introduce artifacts (see zoomed insets). We tune β until artifacts in the transformed images become obvious and use a single value for some experiments. In other experiments, we maintain multiple values simultaneously in a multi-scale setting ( <ref type="table">Table 1</ref>). This can be achieved, assuming class separation, by penalizing the decision boundary traversing regions densely populated by data points, which can be done by minimizing the prediction entropy on the target images. However, as noted in <ref type="bibr" target="#b44">[45]</ref>, this is ineffective in regions with low entropy. Instead of placing an arbitrary threshold on which pixels to apply the penalty to, we use a robust weighting function for entropy minimization, namely</p><formula xml:id="formula_5">L ent (φ w ; D t ) = i ρ(− φ w (x t i ), log(φ w (x t i )) ) (5)</formula><p>where ρ(x) = (x 2 + 0.001 2 ) η is the Charbonnier penalty function <ref type="bibr" target="#b1">[2]</ref>. It penalizes high entropy predictions more than the low entropy ones for η &gt; 0.5 as shown in <ref type="figure" target="#fig_1">Fig. 3</ref>.</p><p>Combining this with the segmentation loss on the adapted source images, we can use the following overall loss to train the semantic segmentation network φ w from scratch:</p><formula xml:id="formula_6">L(φ w ; D s→t , D t ) = L ce (φ w ; D s→t ) + λ ent L ent (φ w ; D t )<label>(6)</label></formula><p>Self-Supervised training (or, more accurately, "selflearning") is a common way of attempting to boost the performance of SSL by using highly confident pseudo-labels predicted with φ w as if they were ground truth. In the absence of regularization, this practice is self-referential, so we focus on regularization.</p><p>As observed in <ref type="bibr" target="#b41">[42]</ref>, the mean teacher improves semisupervised learning performance by averaging the model weights, which provides regularization in the learning process. Here, we propose using the mean of the predictions of multiple models to regularize self-learning. However, instead of training multiple models using the same loss at once, with an explicit divergence term as in <ref type="bibr" target="#b20">[21]</ref>, we directly train multiple models φ w β with different β s in the FDA process, with no need to explicitly force model divergence. We instantiate M=3 segmentation networks φ w βm , m = 1, 2, 3, which are all trained from scratch using <ref type="bibr" target="#b5">(6)</ref>, and the mean prediction for a certain target image x t i can be obtained by:</p><formula xml:id="formula_7">y t i = arg max k 1 M m φ w βm (x t i ).<label>(7)</label></formula><p>Note that the output of the network is the softmax activation, so the average is still a probability distribution over K categories. Using the pseudo-labels generated by M models, we can train φ w β to get further improvement using the following self-supervised training loss:</p><formula xml:id="formula_8">L sst (φ w ; D s→t ,D t ) = L ce (φ w ; D s→t ) + λ ent L ent (φ w ; D t ) + L ce (φ w ;D t ) (8)</formula><p>whereD t is D t augmented with pseudo labelsŷ t i 's. Since our training entails different β's in the FDA operation, we call the self-supervised training using the mean prediction of different segmentation networks Multi-band Transfer (MBT). The full training procedure of our FDA semantic segmentation network consists of one round of initial training of M models from scratch using Eq. (6), and two more rounds of self-supervised training using Eq. (8), as we detail in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Datasets and Training Details</head><p>We evaluate the proposed method on two challenging synthetic-to-real unsupervised domain adaptation tasks, where we have abundant semantic segmentation labels in the synthetic domain (source), but zero in the real domain (target). The two synthetic datasets are GTA5 <ref type="bibr" target="#b32">[33]</ref> and SYNTHIA <ref type="bibr" target="#b33">[34]</ref>; the real domain dataset is CityScapes <ref type="bibr" target="#b8">[9]</ref>.</p><p>GTA5: consists of 24,966 synthesized images captured in a video game, with the original image size 1914×1052. During training, we resize the images to 1280×720, and then random crop them to 1024×512. The original GTA5 provides pixel-wise semantic annotations of 33 classes, but we use the 19 classes in common with CityScapes for standard comparison to other state-of-the-art methods.</p><p>SYNTHIA: also aligned with the other SOTA methods, we use the SYNTHIA-RAND-CITYSCAPES subset which has 9,400 annotated images with the original resolution 1280×760. The images are randomly cropped to 1024×512 during training. Again, the 16 common classes are used for training, but evaluations are performed on both the 16 classes and a subset of 13 classes following the standard protocol.</p><p>CityScapes: is a real-world semantic segmentation dataset collected in driving scenarios. We use the 2,975 images from the training set as the target domain data for training. We test on the 500 validation images with dense manual annotations. Images in CityScapes are simply resized to 1024×512, with no random cropping. The two domain adaptation scenarios are GTA5→CityScapes and SYNTHIA→CityScapes.</p><p>Note that, in all experiments, we perform FDA via Eq. (3) on the training images in the range [0, 255] before we do mean subtraction, since the FFT algorithm we employ is numerically stable for non-negative values.</p><p>Segmentation Network φ w : We experiment with two different architectures to show the robustness of FDA, DeepLabV2 <ref type="bibr" target="#b4">[5]</ref> with a ResNet101 <ref type="bibr" target="#b17">[18]</ref> backbone, and FCN-8s <ref type="bibr" target="#b25">[26]</ref> with a VGG16 <ref type="bibr" target="#b39">[40]</ref> backbone. We use the same initialization as in <ref type="bibr" target="#b22">[23]</ref> for both networks. Again, the segmentation network φ w is the only network in our method.</p><p>Training: Our training is carried out on a GTX1080 Ti GPU; due to memory limitations, the batch size is set to 1 in all our experiments. To train DeepLabV2 with ResNet101 using SGD, the initial learning rate is 2.5e-4, and adjusted according to the 'poly' learning rate scheduler with a power of 0.9, and weight decay 0.0005. For FCN-8s with VGG16, we use ADAM with the initial learning rate 1e-5, which is decreased by the factor of 0.1 every 50000 steps until 150000 steps. We also apply early stopping as in <ref type="bibr" target="#b22">[23]</ref>. The momentum for Adam is 0.9 and 0.99.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">FDA with Single Scale</head><p>We first test the proposed FDA method with single scale on the task GTA5→CityScapes. We instantiate three DeepLabV2 segmentation netowrks φ w β , with β = 0.01, 0.05, 0.09, and train them separately using Eq. (6). We set λ ent = 0.005 and η = 2.0 for all experiments. We report the mean intersection over union score (mIOU) across semantic classes on the validation set of CityScapes in Tab. 1, where T=0 represents training from scratch. As we can see from the first section in Tab. 1, The segmentation networks trained with different β's in the FDA operation maintain similar performance. This demonstrates the robustness of FDA with respect to the choice of β when training with Eq. <ref type="figure">(6)</ref>.</p><p>Moreover, the network φ w β=0.09 trained simply using Eq. (4) (β = 0.09, λ ent = 0) i.e., without entropy loss, surpasses the baseline Cycada <ref type="bibr" target="#b18">[19]</ref> by 4.54%, which demonstrates better management of variability by FDA than the two-stage image translation based adversarial domain adaptation, where an image transformer is trained from one domain to another, and a discriminator is trained to distinguish between the two domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Multi-band Transfer (MBT)</head><p>We could apply self-training (SST) using the pseudo labels generated for the target domain to further improve the performance of a single network. However, the gain is pretty marginal as expected, as can be seen from the second section in Tab. 1, entry (β=0.09, SST). The relative improvement after SST is only 0.9%, compared to (β=0.09, T=0) in the first section. However, when we analyze the networks trained from scratch with different β's in the first section, we can see that, even though the performance is robust to the change of β, the best performing entries (underlined) are equally distributed across classes, rather than being dominated by a single network. This suggests averaging over predictions of different φ w β 's. By simply averaging prediction from the first round (MBT, T=0), we get a more significant relative improvement of 3.9% than the best performer from the first round (β = 0.09, T=0). This is consistently observed also in subsequent self-supervised training rounds in the third and fourth sections in Tab. 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Self-supervised Training with MBT</head><p>We can treat the pseudo labels generated from MBT (T=0) as if they are ground truth labels to train φ w β 's using Eq. (8). However, this is self-referential and cannot be expected to work. To regularize, we also apply a thresholding on the confidence values of each prediction. More specifically, for each semantic class, we accept the predictions with confidence that is within the top 66% or above 0.9. In the third and fourth sections in Tab. 1, we list the   <ref type="table">Table 1</ref>. Ablation study on the GTA5→CityScapes task. The first section (T=0) shows the performance of the segmentation networks φ w β 's when trained from scratch using Eq. <ref type="bibr" target="#b5">(6)</ref>. Note that as β varies, the performance of each φ w β stays similar, whereas, the best performing entries (underlined) equally distribute among the three individual networks. When the predictions across different φ w β 's are averaged (MBT (T=0)), the mIOU improves over all the constituent ones. And this is true even after the first (T=1) and the second (T=2) round of selfsupervised training using Eq. <ref type="bibr" target="#b7">(8)</ref>. Also note that, simply performing self-supervised training without averaging (MBT), the improvement over (β=0.09 (T=0)) is marginal (β=0.09 (SST)). performance of each φ w β after the first round of SST (T=1) and the second round (T=2).</p><p>However, if we check the relative improvement of each φ w β by SST <ref type="figure" target="#fig_0">(T=0,1,2)</ref>, we see that the best performer in the training from scratch round (T=0) is φ w β=0.09 , which becomes the worst performer during the first SST round (T=1), and finally, after the second round of SST (T=2), φ w β=0.01 becomes the best performer rater than φ w β=0.09 . We conjecture that small β will yield less variations (artifacts), thus the adapted source dataset D s→t has less chance to cover the target dataset than the one with larger β. However, when pseudo labels are used to further align the two domains, D s→t will impose less bias, since its center is closer to the target dataset and variance is smaller. We illustrate this in <ref type="figure" target="#fig_3">Fig. 4</ref>. Also this observation provides us a reference to set β, i.e. if we just perform a single scale FDA, we may want to use relatively larger β, however, for MBT, we may gradually raise the weight on the predictions from φ w β with smaller β.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Benchmarks</head><p>GTA5→CityScapes: We report the quantitative evaluation of our method in Tab. 2. Again, we can observe that the single scale FDA (FDA) with ResNet101 outperforms most methods that employ adversarial training by instantiating an image transformer and a discriminator <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b28">29]</ref>. With entropy minimization activated, the single scale FDA (FDA-ENT) achieves similar performance as <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b44">45]</ref>, which incorporates spatial priors or more sophisticated adversar- ial training on the structured output of entropy map. By applying SST using the Multi-band Transfer, our method achieves the top performance among others (FDA-MBT). Note that BDL <ref type="bibr" target="#b22">[23]</ref> also performs SST in the adversarial setting, and our method achieves a 4.0% improvement over BDL. The advantage of our method is also demonstrated on the VGG backbone in the second section of Tab. 2.</p><p>SYNTHIA→CityScapes:</p><p>Following the evaluation protocol in <ref type="bibr" target="#b22">[23]</ref>, we report the mIOU of our method on 16 classes using the VGG16 backbone, and on 13 classes using the ResNet101 backbone. Quantitative comparison is shown in Tab. 3. Note again, our method achieves the top performance using different backbones and outperforms the seconder performer BDL <ref type="bibr" target="#b22">[23]</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.">Qualitative Results</head><p>We visually compare to the second performer BDL <ref type="bibr" target="#b22">[23]</ref> who uses the same segmentation network backbone as ours. As we can see from <ref type="figure">Fig. 5</ref>, the predictions from our model appear much less noisy, like the road in the first row. Not only smoother, but our method can also maintain the fine structures, like the poles in the fifth row. Moreover, our method performs well on rare classes, for example, the truck in the second row, and the bicycles in the third and fourth rows. We accredit this to both the generalization ability of the single scale FDA, and the regularized SST by our Multiband Transfer. <ref type="figure">Figure 5</ref>. Visual Comparison. Left to right: Input image from CityScapes, ground-truth semantic segmentation, BDL <ref type="bibr" target="#b22">[23]</ref>, FDA-MBT. Note that the predictions from FDA-MBT are generally smoother, e.g. the road in the first and fourth row, and the wall in the third row. Moreover, FDA-MBT achieves better performance on fine structures, e.g., the poles in the fifth row.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Discussion</head><p>We have proposed a simple method for domain alignment that does not require any learning, and can be easily integrated into a learning system that transforms unsupervised domain adaptation into semi-supervised learning. Some attention needs to be devoted to proper regularization of the loss function, for which we propose an entropic regularizer with anisotropic (Charbonnier) weighting. The selfreferential problem in self-supervised training is addressed by the Multi-band Transfer scheme that requires no joint training of student networks with complicated model selection.</p><p>The results indicate that our method not only improves on the baseline, which was expected, but actually surpasses the current state of the art, which is considerably more involved, despite its simplicity. This suggests that some distributional misalignment due to low-level statistics, which has been known to wreak havoc with generalization across different domains, is quite simple to capture with a fast Fourier transform. Moreover, the inverse Fourier transform of the spectrum of a real signal is guaranteed to be real, as one can easily show that the imaginary part is canceled given the skew-symmetry of the integrand; thus, images that are domain adapted using our method still reside in the real image space.</p><p>Robustness to nuisance variability affecting the image domain remains a difficult problem in machine learning, and we do not claim our method to be the final solution. However, we show that in some cases, it may not be necessary to learn what we already know, such as the fact that low-level statistics of the image can vary widely without affecting the semantics of the underlying scene. Such preprocessing could be an alternative to sophisticated architectures or laborious data augmentation. In the future, we would like to see applications of our method on other domain adaptation tasks.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>Effect of the size of the domain β, shown in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>Charbonnier penalty used for robust entropy minimization, visualized for different values of the parameter η.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Larger β generalizes better if trained from scratch, but induce more bias when combined with Self-supervised Training.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>β=0.01 (T=0) 88.<ref type="bibr" target="#b7">8</ref> 35.4 80.5 24.0 24.9 31.3 34.9 32.0 82.6 35.6 74.4 59.4 31.0 81.7 29.3 47.1 1.2 21.1 32.3 44.61 β=0.05 (T=0) 90.7 45.0 80.4 24.6 22.6 31.8 30.3 39.4 81.4 33.8 72.6 57.6 29.1 83.2 26.3 36.9 6.6 20.6 34.9 44.6 β=0.09 (T=0) 90.8 42.7 80.8 28.1 26.6 31.8 32.8 29.1 81.6 31.2 76.2 56.9 27.7 82.8 25.3 44.1 15.3 21.1 30.2 45.01 Cycada[19] 86.7 35.6 80.1 19.8 17.5 38.0 39.9 41.5 82.7 27.9 73.6 64.9 19 65.0 12.0 28.6 4.5 31.1 42.0 42.7 β=0.09 (λ ent = 0) 90.0 40.5 79.4 25.3 26.7 30.6 31.9 29.3 79.4 28.8 76.5 56.4 27.5 81.7 27.7 45.1 17.0 23.8 29.6 44.64 β=0.09 (SST) 91.6 52.4 81.2 26.8 22.7 31.6 33.3 32.6 81.1 29.2 73.8 57.2 27.1 82.5 23.8 44.4 15.4 21.9 34.7 45.42 MBT (T=0) 91.3 44.2 82.2 32.1 29.4 32.8 35.7 30.4 83.2 35.7 76.3 59.8 31.7 84.5 29.5 46.1 6.9 23.2 33.7 46.77</figDesc><table><row><cell cols="2">β=0.01 (T=1) 92.3 51.4 82.3 30.5 24.5 31.2 36.9 34.2 82.4 39.7 76.6 57.6 28.5 82.3 27.9 47.0 5.5 21.7 40.3 47.03</cell></row><row><cell cols="2">β=0.05 (T=1) 92.2 50.9 81.5 27.2 27.3 32.5 35.8 35.7 81.3 37.1 76.3 58.6 30.0 83.0 23.4 45.1 6.7 23.8 40.0 46.8</cell></row><row><cell cols="2">β=0.09 (T=1) 91.0 46.9 80.3 25.3 21.1 30.1 35.5 37.8 80.8 38.9 79.1 58.5 31.2 82.4 29.4 46.0 9.1 24.2 39.1 46.71</cell></row><row><cell>MBT (T=1)</cell><cell>92.5 52.0 82.4 30.3 25.6 32.4 38.3 36.6 82.5 41.0 78.6 59.4 30.6 83.7 28.4 48.3 6.4 24.0 40.8 48.14</cell></row><row><cell cols="2">β=0.01 (T=2) 92.1 51.5 82.3 26.3 26.8 32.6 36.9 39.6 81.7 40.7 78.2 57.8 29.1 82.8 36.1 49.0 13.9 24.5 43.9 48.77</cell></row><row><cell cols="2">β=0.05 (T=2) 91.6 49.7 81.1 25.2 22.7 31.5 35.0 35.1 80.8 38.2 77.5 58.9 31.3 83.0 26.9 50.5 20.8 26.4 42.2 47.86</cell></row><row><cell cols="2">β=0.09 (T=2) 91.6 50.6 81.0 24.4 26.0 32.2 35.3 36.5 81.3 33.1 74.5 57.8 31.2 82.9 30.0 49.7 7.0 26.1 41.6 47.03</cell></row><row><cell>MBT (T=2)</cell><cell>92.5 53.3 82.3 26.5 27.6 36.4 40.5 38.8 82.2 39.8 78.0 62.6 34.4 84.9 34.1 53.12 16.8 27.7 46.4 50.45</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .Table 3 .</head><label>23</label><figDesc>AdaStruct<ref type="bibr" target="#b42">[43]</ref> 86.<ref type="bibr" target="#b4">5</ref> 25.9 79.8 22.1 20.0 23.6 33.1 21.8 81.8 25.9 75.9 57.3 26.2 76.3 29.8 32.1 7.2 29.5 32.5 41.4 DCAN[47] 85.0 30.8 81.3 25.8 21.2 22.2 25.4 26.6 83.4 36.7 76.2 58.9 24.9 80.7 29.5 42.9 2.5 26.9 11.6 41.Quantitative Comparison on GTA5→CityScapes. The scores under each backbone represent the upper bound (train and test on the source domain). FDA: our method with a single scale; FDA-ENT: again single scale but with entropy regularization; FDA-MBT: FDA with multiple scales and Self-supervised Training. Note that our method consistently achieves better performance across different backbones. ] 77.7 30.0 77.5 9.6 0.3 25.8 10.3 15.6 77.6 79.8 44.5 16.6 67.8 14.5 7.0 23.8 36.2 GIO-Ada[6] 78.3 29.2 76.9 11.4 0.3 26.5 10.8 17.2 81.7 81.9 45.8 15.4 68.0 15.9 7.5 30.4 37.3 BDL [23] 72.0 30.3 74.5 0.1 0.3 24.6 10.2 25.2 80.5 80.0 54.7 23.2 72.7 24.0 7.5 44.9 39.0 FDA-MBT 84.2 35.1 78.0 6.1 0.44 27.0 8.5 22.1 77.2 79.6 55.5 19.9 74.8 24.9 14.3 40.7 40.5 Quantitative Comparison on SYNTHIA→CityScapes. Scores under each backbone represent the upper bound. For VGG, we evaluate on the 16 subclasses, and for ResNet101, 13 of the 16 classes are evaluated according to the evaluation protocol in the literature.Classes not evaluated are replaced by '-.' Our method consistently achieves better performance than the others across different backbones.</figDesc><table><row><cell>by</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">the cardinality of D s→t should be |D s | × |D t |, which is large, so we do online random generation of D s→t given the efficiency of the FFT.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>Research supported by ARO W911NF-17-1-0304 and ONR N00014-19-1-2066.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Critical learning periods in deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Achille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matteo</forename><surname>Rovere</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Soatto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Towards ultimate motion estimation: Combining highest accuracy with real-time performance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andres</forename><surname>Bruhn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joachim</forename><surname>Weickert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Tenth IEEE International Conference on Computer Vision (ICCV&apos;05</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2005" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="749" to="755" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Autodial: Automatic domain alignment layers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><forename type="middle">Maria</forename><surname>Cariucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenzo</forename><surname>Porzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Caputo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elisa</forename><surname>Ricci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel Rota</forename><surname>Bulò</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5077" to="5085" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">All about structure: Adapting structural information across domains for boosting semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Lun</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui-Po</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Hsiao</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Chen</forename><surname>Chiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="1900" />
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iasonas</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Learning semantic segmentation from synthetic data: A geometrically guided input-output adaptation approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhua</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoran</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Road: Reality oriented adaptation for semantic segmentation of urban scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhua</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7892" to="7901" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Stargan: Unified generative adversarial networks for multi-domain image-to-image translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunjey</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minje</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Munyoung</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jung-Woo</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sunghun</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaegul</forename><surname>Choo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8789" to="8797" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The cityscapes dataset for semantic urban scene understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>Cordts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Omran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Ramos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Rehfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Enzweiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>Benenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uwe</forename><surname>Franke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A comprehensive survey on domain adaptation for visual applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriela</forename><surname>Csurka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Domain adaptation in computer vision applications</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">The pascal visual object classes challenge: A retrospective. International journal of computer vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Everingham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Eslami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">I</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zisserman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">111</biblScope>
			<biblScope unit="page" from="98" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Self-ensembling for visual domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>French</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Mackiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Fisher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Fftw: An adaptive software architecture for the fft</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matteo</forename><surname>Frigo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Steven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1998 IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP&apos;98 (Cat. No. 98CH36181)</title>
		<meeting>the 1998 IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP&apos;98 (Cat. No. 98CH36181)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1998" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1381" to="1384" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation by backpropagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaroslav</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1180" to="1189" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Daml: Domain adaptation metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dacheng</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2980" to="2989" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Deep reconstructionclassification networks for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammad</forename><surname>Ghifary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengjie</forename><surname>Bastiaan Kleijn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Balduzzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="597" to="613" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Dlow: Domain flow for adaptation and generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhua</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Alexei Efros, and Trevor Darrell. Cycada: Cycle-consistent adversarial domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judy</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taesung</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Yan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th International Conference on Machine Learning</title>
		<meeting>the 35th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judy</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dequan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fisher</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1612.02649</idno>
		<title level="m">Fcns in the wild: Pixel-level adversarial and constraint-based adaptation</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Co-regularized alignment for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prasanna</forename><surname>Sattigeri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kahini</forename><surname>Wadhawan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonid</forename><surname>Karlinsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rogerio</forename><surname>Feris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Wornell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Temporal ensembling for semisupervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuli</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Aila</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.02242</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Bidirectional learning for domain adaptation of semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunsheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nuno</forename><surname>Vasconcelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="6936" to="6945" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Microsoft coco: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="740" to="755" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Unsupervised image-to-image translation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Yu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Breuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Kautz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="700" to="708" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Fully convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Learning transferable features with deep adaptation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingsheng</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="97" to="105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Significance-aware information bottleneck for domain adaptive semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yawei</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junqing</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Taking a closer look at domain shift: Category-level adversaries for semantics consistent domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yawei</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junqing</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Boosting domain adaptation by discovering latent domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimiliano</forename><surname>Mancini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenzo</forename><surname>Porzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><forename type="middle">Rota</forename><surname>Bulò</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Caputo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elisa</forename><surname>Ricci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3771" to="3780" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Unified deep supervised domain adaptation and generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saeid</forename><surname>Motiian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Piccirilli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Donald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gianfranco</forename><surname>Adjeroh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Doretto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5715" to="5725" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Visual domain adaptation: A survey of recent advances</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Vishal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raghuraman</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruonan</forename><surname>Gopalan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rama</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE signal processing magazine</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="53" to="69" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Playing for data: Ground truth from computer games</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vibhav</forename><surname>Stephan R Richter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Vineet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">The synthia dataset: A large collection of synthetic images for semantic segmentation of urban scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">German</forename><surname>Ros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Sellart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joanna</forename><surname>Materzynska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Vazquez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio M</forename><surname>Lopez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Semi-supervised self-training of object detection models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuck</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henry</forename><surname>Hebert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schneiderman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh IEEE Workshops on Application of Computer Vision (WACV/MOTION&apos;05</title>
		<meeting>the Seventh IEEE Workshops on Application of Computer Vision (WACV/MOTION&apos;05</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="29" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Asymmetric tri-training for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuniaki</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshitaka</forename><surname>Ushiku</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tatsuya</forename><surname>Harada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="2988" to="2997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Learning from synthetic data: Addressing domain shift for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Swami</forename><surname>Sankaranarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yogesh</forename><surname>Balaji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arpit</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nam</forename><surname>Ser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rama</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Learning transferrable representations for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ozan</forename><surname>Sener</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyun</forename><forename type="middle">Oh</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashutosh</forename><surname>Saxena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2110" to="2118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A dirt-t approach to unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hirokazu</forename><surname>Bui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Narui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ermon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 6th International Conference on Learning Representations</title>
		<meeting>6th International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.1556</idno>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Deep high-resolution representation learning for human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingdong</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5693" to="5703" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antti</forename><surname>Tarvainen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harri</forename><surname>Valpola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Learning to adapt structured output space for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Hsuan</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Chih</forename><surname>Hung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Schulter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manmohan</forename><surname>Chandraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Adversarial discriminative domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judy</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="7167" to="7176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Advent: Adversarial entropy minimization for domain adaptation in semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tuan-Hung</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Himalaya</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxime</forename><surname>Bucher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Cord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Pérez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Deep visual domain adaptation: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weihong</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">312</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="135" to="153" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Dcan: Dual channel-wise alignment networks for unsupervised scene adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zuxuan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xintong</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yen-Liang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mustafa</forename><forename type="middle">Gokhan</forename><surname>Uzunbas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Goldstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nam</forename><surname>Ser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry S</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Phase consistent ecological domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanchao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Lao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ganesh</forename><surname>Sundaramoorthi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Soatto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Conditional prior networks for optical flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanchao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Soatto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="271" to="287" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Dualgan: Unsupervised dual learning for image-to-image translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zili</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minglun</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2849" to="2857" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Multi-scale context aggregation by dilated convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fisher</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Koltun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.07122</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Central moment discrepancy (cmd) for domain-invariant representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Werner</forename><surname>Zellinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Grubinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edwin</forename><surname>Lughofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Natschläger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Susanne</forename><surname>Saminger-Platz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1702.08811</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Curriculum domain adaptation for semantic segmentation of urban scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boqing</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2020" to="2030" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Pyramid scene parsing network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojuan</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2881" to="2890" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Unpaired image-to-image translation using cycleconsistent adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Yan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taesung</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2223" to="2232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation for semantic segmentation via class-balanced self-training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiding</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinsong</forename><surname>Bvk Vijaya Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
