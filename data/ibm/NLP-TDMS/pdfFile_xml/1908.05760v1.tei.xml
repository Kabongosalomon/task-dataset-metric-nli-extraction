<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">BioFLAIR: Pretrained Pooled Contextualized Embeddings for Biomedical Sequence Labeling Tasks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shreyas</forename><surname>Sharma</surname></persName>
							<email>shreyas.kumar3@learner.manipal.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ron</forename><surname>Daniel</surname><genName>Jr</genName></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Manipal Institute of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="laboratory">Elsevier Labs</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">BioFLAIR: Pretrained Pooled Contextualized Embeddings for Biomedical Sequence Labeling Tasks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T10:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Biomedical Named Entity Recognition (NER) is a challenging problem in biomedical information processing due to the widespread ambiguity of out of context terms and extensive lexical variations. Performance on bioNER benchmarks continues to improve due to advances like BERT, GPT, and XLNet. FLAIR <ref type="formula">(1)</ref> is an alternative embedding model which is less computationally intensive than the others mentioned. We test FLAIR and its pretrained PubMed embeddings (which we term BioFLAIR 2 ) on a variety of bio NER tasks and compare those with results from BERT-type networks. We also investigate the effects of a small amount of additional pretraining on PubMed content, and of combining FLAIR and ELMO models. We find that with the provided embeddings, FLAIR performs on-par with the BERT networkseven establishing a new state of the art on one benchmark. Additional pretraining did not provide a clear benefit, although this might change with even more pretraining being done. Stacking the FLAIR embeddings with others typically does provide a boost in the benchmark results.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>There continues to be a rapid increase in the number of biomedical publications each year, making NLP an essential tool for large-scale knowledge extraction and machine reading of this scientific literature. Deep learning has gained popularity among researchers as it has shown to boost the development of effective biomedical text mining models. But training these deep learning models often requires large amounts of labeled data, which is very hard to acquire in scientific fields like Biology and Medicine. As an alternative to the supervised learning approach, ELMo (2), GPT (3) and BERT (4) have shown the effectiveness of semi-supervision. In that approach, a large corpus of unlabeled text is used to pretrain a model. That model can then be finetuned to the specifics of an individual benchmark task such as Gene or Protein detection, POS tagging, etc. This has been shown to significantly improve performance on many NLP tasks <ref type="bibr" target="#b13">(14)</ref>. FLAIR (1) is an alternative unsupervised embedding method which has not been as well studied as the others. FLAIR has seen to achieve state-of-the-art results for many common NER datasets like Conll-03(8), Ontonotes, etc., but we have not seen results for FLAIR on biomedical NER benchmarks. In this paper we evaluate the most recent version of FLAIR on several bio NER benchmarks to compare its performance with that of BERT and other well-known methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Method</head><p>We downloaded the most recent version of FLAIR (0.4.2) from its GitHub site, https://github.com/zalandoresearch/flair. The FLAIR authors make a number of pretrained models available. We initially use the 'pubmed-x' embeddings which they provide. These were trained on about 5% of the PubMed abstracts from before 2015. We refer to this combination as BioFLAIR v1. Having a model pretrained on biomedical material is very important, as it has been shown <ref type="bibr" target="#b13">(14,</ref><ref type="bibr" target="#b14">15)</ref> that models pretrained on the same kind of material as will be used in the fine-tuning makes a significant difference in performance.</p><p>The pubmed-x embeddings are based on much less training than the BioBERT (14) embeddings. Time and budget did not allow for an extensive pre-training, but we did look at the effect of some additional pretraining. <ref type="table" target="#tab_0">Table 1</ref> lists the three corpora extracted from PubMed. The first is the corpus used for the pubmed-x embeddings.  <ref type="bibr" target="#b13">(14)</ref> and SciBERT (15) tested on several benchmarks, including a number of NER tasks. We selected six of these benchmarks for testing with FLAIR in order to make comparison as simple as possible. The benchmark corpora used are listed below in <ref type="table" target="#tab_2">Table 2</ref>. The benchmark corpora were downloaded. Their training splits were used to fine-tune separate models for each benchmark, which were then evaluated on each test split. These benchmark corpora are not large. We also tested the effect of combining similar corpora (NCBI-Disease and BC5DR-Disease) to obtain a larger test corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset</head><p>Entity Type # sents  configuration was selected, then that configuration was used for the other benchmarks of <ref type="table" target="#tab_2">Table  2</ref>. The configurations tested are shown in <ref type="table">Table 3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Name</head><p>Model Description BioFLAIR (V1) <ref type="bibr" target="#b2">3</ref> FLAIR's pubmed-x model, pretrained on PubMed (V1) BioFLAIR (V2) BioFLAIR (V1) further trained on PubMed (V2) BioFLAIR (V3) BioFLAIR (V2) further trained on PubMed (V3) CRAWL FastText embeddings over Web crawls BioELMo <ref type="bibr" target="#b3">4</ref> PubMed model for ELMo MULTI FLAIR embeddings trained on a mix of corpora (Web, Wikipedia, Subtitles, News) <ref type="table">Table 3</ref>: Models tested on NCBI-Disease Corpus</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Results</head><p>The results of our first experiment, on adding additional pretraining data, are shown below in the first three rows of <ref type="table" target="#tab_4">Table 4</ref>. FLAIR's provided pubmed-x model is indicated by BioFLAIR (V1). This outscored the models with additional PubMed pretraining. Note, however, that the score does not decline monotonically. This may indicate that additional pretraining would eventually be of benefit.</p><p>The last three rows of <ref type="table" target="#tab_4">Table 4</ref> show the effect of stacking different embeddings. Here we uniformly see a benefit to combining some other kind of embeddings. The ELMo embeddings seem particularly beneficial. It should be noted however, that this requires significantly more computation than the FLAIR embeddings alone.  The results of our main experimentcomparing FLAIR with BERTare shown below in <ref type="table">Table  5</ref>. We have multiple BERT variants. Two are from the BioBERT paper <ref type="bibr" target="#b13">(14)</ref> and one from the SciBERT paper <ref type="bibr" target="#b14">(15)</ref>. These models are the state of the art on these benchmarks at this time. We compare with the BioFLAIR model that had the best performance on the NCBI-Disease benchmark. That used the provided pubmed-x embeddings, stacked with BioELMo embeddings). The best-scoring configuration for each benchmark is shown in bold text, the second best is underlined.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Effect Of</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>88.47</head><p>We see that the FLAIR+ELMo model is very competitive with the BERT models. It typically trails only the BioBERT model that was trained on much more material, and it outscores all BERT variants on the BC5DR and Species-800 benchmarks. We even set a new state of the art score for the Species-800 benchmark.  <ref type="table">Table 5</ref>: Test results in biomedical named entity recognition. We compared our results with BioBERT <ref type="bibr" target="#b13">(14)</ref> and SciBERT <ref type="bibr" target="#b14">(15)</ref>, which are similar in nature and have current state-of-the-art scores for these datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Benchmark BioBERT</head><p>The results of our final experiment, combining similar benchmark corpora to obtain larger training and test sets, are shown in <ref type="table" target="#tab_7">Table 6</ref>. We do not see a consistent benefit from this. Adding the BC5DR-Disease training material to the NCBI-Disease training material does boost the score on the NCBI-Disease test. However, the converse is not true. In fact, the decline in the BC5DR-Disease scores after merging is greater than the improvement in the NCBI-Disease score.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Discussion</head><p>Our main result is that the FLAIR embeddings are competitive with those from BERT. In an ensemble with ELMo, they occasionally even gave better results. It is not surprising that the combination outperforms the single FLAIR model, indeed it would be surprising if that were not the case. What is surprising is how close the results were, considering how little pretraining was performed on the FLAIR model compared to that of BioBERT.</p><p>We saw that increasing the amount of pretraining data didn't automatically improve the scores on the downstream benchmarks. The relation was more complex, with some additional data harming results and then still more data starting to recover those losses. More analysis, including hyperparameter optimization, is needed to understand and explain this behavior.</p><p>Not surprisingly, we saw that combining the training material from different benchmark tasks, even ones as similar as the disease identification benchmarks, did not automatically improve the scores. Here again, more analysis of the benchmarks and the hyperparameters is needed to fully understand this. Intuitively, the difficulties in multi-task training make it unsurprising that a simple combination of data would not yield improvements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion and Future Work</head><p>In this paper, we introduce BioFLAIR, a pretrained pooled contextualized embedding model for Biomedical Sequence Labeling tasks like NER. It achieves near state-of-the-art scores, with a much lighter model than the current SOTAs.</p><p>We expect we could improve performance with more pretraining; in line with that of BioBERT.</p><p>There are other lines of investigation as well. Applying the FLAIR embeddings to tasks other than NER, such as relation classification and question answering, would be interesting.</p><p>Comparison against more recent models, such as XLNet, is another line of investigation.</p><p>Ensembles of all combinations of BERT, XLNet, ELMo, FastText, FLAIR, etc. would be interesting to see which ones are more or less like the others and bring different value to the ensemble. It would also be interesting to see how well it works when applied to other scientific domains.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Size of pretraining corporaBioBERT</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table><row><cell>Name Of Corpus</cell><cell>Details</cell></row><row><cell>PubMed (V1)</cell><cell>1,219,734 PubMed abstracts: 5% sample of</cell></row><row><cell></cell><cell>PubMed abstracts until 2015</cell></row><row><cell>PubMed (V2)</cell><cell>261,736 PubMed abstracts: sample of</cell></row><row><cell></cell><cell>PubMed abstracts after 2000</cell></row><row><cell>PubMed (V3)</cell><cell>281,394 PubMed abstracts: sample of</cell></row><row><cell></cell><cell>PubMed abstracts after 2000</cell></row></table><note>The entity types and size of each benchmark corpus used for evaluation. The sentence counts are totals, including the train, dev and test splits. The NCBI-disease corpus is the smallest of those used by BioBERT. We used that corpus to test a few configurations of FLAIR and its pretraining corpus. Based on those results a single</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Dataset Model Details F1 score</head><label></label><figDesc></figDesc><table><row><cell>Additional</cell><cell>NCBI</cell><cell>BioFLAIR (V1)</cell><cell>87.33</cell></row><row><cell>Pretraining data</cell><cell>NCBI</cell><cell>BioFLAIR (V2)</cell><cell>86.99</cell></row><row><cell></cell><cell>NCBI</cell><cell>BioFLAIR (V3)</cell><cell>87</cell></row><row><cell>Different Stacked</cell><cell>NCBI</cell><cell>BioFLAIR (V1) + CRAWL</cell><cell>88.18</cell></row><row><cell>Embeddings</cell><cell>NCBI</cell><cell>BioFLAIR (V3) + BioELMo</cell><cell>88.3</cell></row><row><cell></cell><cell>NCBI</cell><cell>BioFLAIR (V1) + BioELMo</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Studying effect of amount of pretraining data and different embeddings on NCBI disease NER dataset.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 6 :</head><label>6</label><figDesc>Result after adding more training data by combing similar datasets.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Most work was done while author was an intern at Elsevier 2 Code is available at https://github.com/shreyashub/BioFLAIR</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">https://github.com/zalandoresearch/flair/pull/519 4 https://github.com/zalandoresearch/flair/pull/503</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">Trained on NCBI (+BC5DR-disease) dataset.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">FLAIR: An Easy-to-Use Framework for State-of-the-Art NLP</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Akbik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics (Demonstrations)</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics (Demonstrations)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Deep contextualized word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.05365</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Improving language understanding with unsupervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<pubPlace>OpenAI</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)</title>
		<meeting>the 2014 conference on empirical methods in natural language processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Pooled contextualized embeddings for named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Akbik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tanja</forename><surname>Bergmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roland</forename><surname>Vollgraf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Long and Short Papers</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Introduction to the CoNLL-2003 shared task: Language-independent named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><forename type="middle">F</forename><surname>Sang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fien De</forename><surname>Meulder</surname></persName>
		</author>
		<idno>arXiv preprint cs/0306050</idno>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">NCBI disease corpus: a resource for disease name recognition and concept normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rezarta</forename><surname>DoÄŸan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Islamaj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyong</forename><surname>Leaman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of biomedical informatics</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">BioCreative V CDR task corpus: a resource for chemical disease relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiao</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Database</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Introduction to the bio-entity recognition task at JNLPBA</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin-Dong</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the international joint workshop on natural language processing in biomedicine and its applications</title>
		<meeting>the international joint workshop on natural language processing in biomedicine and its applications</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The SPECIES and ORGANISMS resources for fast and accurate identification of taxonomic names in text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evangelos</forename><surname>Pafilis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS One</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">65390</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">LINNAEUS: a species name identification system for biomedical literature</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Gerner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Goran</forename><surname>Nenadic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Casey</forename><forename type="middle">M</forename><surname>Bergman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC bioinformatics</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">85</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Biobert: pre-trained biomedical language representation model for biomedical text mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinhyuk</forename><surname>Lee</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.08746</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Scibert: Pretrained contextualized embeddings for scientific text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iz</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arman</forename><surname>Cohan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyle</forename><surname>Lo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.10676</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
