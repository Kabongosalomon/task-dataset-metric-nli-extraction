<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">ADVERSARIALLY LEARNED INFERENCE</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Dumoulin</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">MILA</orgName>
								<orgName type="institution" key="instit2">Université de Montréal</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishmael</forename><surname>Belghazi</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">MILA</orgName>
								<orgName type="institution" key="instit2">Université de Montréal</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Poole</surname></persName>
							<email>poole@cs.stanford.edu.</email>
							<affiliation key="aff1">
								<orgName type="laboratory">Neural Dynamics and Computation Lab, Stanford</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Mastropietro</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">MILA</orgName>
								<orgName type="institution" key="instit2">Université de Montréal</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Lamb</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">MILA</orgName>
								<orgName type="institution" key="instit2">Université de Montréal</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Arjovsky</surname></persName>
							<email>martinarjovsky@gmail.com.</email>
							<affiliation key="aff2">
								<orgName type="institution">New York University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">MILA</orgName>
								<orgName type="institution" key="instit2">Université de Montréal</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">ADVERSARIALLY LEARNED INFERENCE</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>Published as a conference paper at ICLR 2017 † CIFAR Fellow.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T11:26+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We introduce the adversarially learned inference (ALI) model, which jointly learns a generation network and an inference network using an adversarial process. The generation network maps samples from stochastic latent variables to the data space while the inference network maps training examples in data space to the space of latent variables. An adversarial game is cast between these two networks and a discriminative network is trained to distinguish between joint latent/data-space samples from the generative network and joint samples from the inference network. We illustrate the ability of the model to learn mutually coherent inference and generation networks through the inspections of model samples and reconstructions and confirm the usefulness of the learned representations by obtaining a performance competitive with state-of-the-art on the semi-supervised SVHN and CIFAR10 tasks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Deep directed generative model has emerged as a powerful framework for modeling complex highdimensional datasets. These models permit fast ancestral sampling, but are often challenging to learn due to the complexities of inference. Recently, three classes of algorithms have emerged as effective for learning deep directed generative models: 1) techniques based on the Variational Autoencoder (VAE) that aim to improve the quality and efficiency of inference by learning an inference machine <ref type="bibr" target="#b13">(Kingma &amp; Welling, 2013;</ref>, 2) techniques based on Generative Adversarial Networks (GANs) that bypass inference altogether <ref type="bibr" target="#b9">(Goodfellow et al., 2014)</ref> and 3) autoregressive approaches <ref type="bibr" target="#b35">(van den Oord et al., 2016b;</ref><ref type="bibr">c;</ref><ref type="bibr">a)</ref> that forego latent representations and instead model the relationship between input variables directly. While all techniques are provably consistent given infinite capacity and data, in practice they learn very different kinds of generative models on typical datasets. VAE-based techniques learn an approximate inference mechanism that allows reuse for various auxiliary tasks, such as semi-supervised learning or inpainting. They do however suffer from a wellrecognized issue of the maximum likelihood training paradigm when combined with a conditional independence assumption on the output given the latent variables: they tend to distribute probability mass diffusely over the data space <ref type="bibr" target="#b33">(Theis et al., 2015)</ref>. The direct consequence of this is that image samples from VAE-trained models tend to be blurry <ref type="bibr" target="#b9">(Goodfellow et al., 2014;</ref><ref type="bibr" target="#b18">Larsen et al., 2015)</ref>. Autoregressive models produce outstanding samples but do so at the cost of slow sampling speed and foregoing the learning of an abstract representation of the data. GAN-based approaches represent a good compromise: they learn a generative model that produces higher-quality samples than the best VAE techniques <ref type="bibr" target="#b25">(Radford et al., 2015;</ref><ref type="bibr" target="#b18">Larsen et al., 2015)</ref> without sacrificing sampling speed and also make use of a latent representation in the generation process. However, GANs lack an efficient inference mechanism, which prevents them from reasoning about data at an abstract level. For instance, GANs don't allow the sort of neural photo manipulations showcased in <ref type="bibr" target="#b4">(Brock et al., 2016)</ref>. Recently, efforts have aimed to bridge the gap between VAEs and GANs, to learn generative models with higher-quality samples while learning an efficient inference network <ref type="bibr">(Larsen et al.,</ref> Published as a conference paper at ICLR 2017 <ref type="bibr">Gz(x)</ref> Gx <ref type="formula">(</ref> 2015; <ref type="bibr" target="#b17">Lamb et al., 2016;</ref><ref type="bibr" target="#b7">Dosovitskiy &amp; Brox, 2016)</ref>. While this is certainly a promising research direction, VAE-GAN hybrids tend to manifest a compromise of the strengths and weaknesses of both approaches.</p><formula xml:id="formula_0">x ∼ q(x) z ∼ q(z | x) D(x, z)x ∼ p(x | z) z ∼ p(z)</formula><p>In this paper, we propose a novel approach to integrate efficient inference within the GAN framework. Our approach, called Adversarially Learned Inference (ALI), casts the learning of both an inference machine (or encoder) and a deep directed generative model (or decoder) in an GAN-like adversarial framework. A discriminator is trained to discriminate joint samples of the data and the corresponding latent variable from the encoder (or approximate posterior) from joint samples from the decoder while in opposition, the encoder and the decoder are trained together to fool the discriminator. Not only are we asking the discriminator to distinguish synthetic samples from real data, but we are requiring it to distinguish between two joint distributions over the data space and the latent variables.</p><p>With experiments on the Street View House Numbers (SVHN) dataset <ref type="bibr" target="#b23">(Netzer et al., 2011)</ref>, the CIFAR-10 object recognition dataset <ref type="bibr" target="#b16">(Krizhevsky &amp; Hinton, 2009</ref>), the CelebA face dataset <ref type="bibr" target="#b20">(Liu et al., 2015)</ref> and a downsampled version of the ImageNet dataset <ref type="bibr" target="#b28">(Russakovsky et al., 2015)</ref>, we show qualitatively that we maintain the high sample fidelity associated with the GAN framework, while gaining the ability to perform efficient inference. We show that the learned representation is useful for auxiliary tasks by achieving results competitive with the state-of-the-art on the semi-supervised SVHN and CIFAR10 tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">ADVERSARIALLY LEARNED INFERENCE</head><p>Consider the two following probability distributions over x and z:</p><p>• the encoder joint distribution q(x, z) = q(x)q(z | x),</p><p>• the decoder joint distribution p(x, z) = p(z)p(x | z).</p><p>These two distributions have marginals that are known to us: the encoder marginal q(x) is the empirical data distribution and the decoder marginal p(z) is usually defined to be a simple, factorized distribution, such as the standard Normal distribution p(z) = N (0, I). As such, the generative process between q(x, z) and p(x, z) is reversed.</p><p>ALI's objective is to match the two joint distributions. If this is achieved, then we are ensured that all marginals match and all conditional distributions also match. In particular, we are assured that the conditional q(z | x) matches the posterior p(z | x).</p><p>In order to match the joint distributions, an adversarial game is played. Joint pairs (x, z) are drawn either from q(x, z) or p(x, z), and a discriminator network learns to discriminate between the two, while the encoder and decoder networks are trained to fool the discriminator.</p><p>The value function describing the game is given by:</p><formula xml:id="formula_1">min G max D V (D, G) = E q(x) [log(D(x, G z (x)))] + E p(z) [log(1 − D(G x (z), z))] = q(x)q(z | x) log(D(x, z))dxdz + p(z)p(x | z) log(1 − D(x, z))dxdz.</formula><p>(1)</p><formula xml:id="formula_2">Algorithm 1 The ALI training procedure. θ g , θ d ← initialize network parameters repeat x (1) , . . . , x (M ) ∼ q(x)</formula><p>Draw M samples from the dataset and the prior</p><formula xml:id="formula_3">z (1) , . . . , z (M ) ∼ p(z) z (i) ∼ q(z | x = x (i) ), i = 1, . . . , M Sample from the conditionals x (j) ∼ p(x | z = z (j) ), j = 1, . . . , M ρ (i) q ← D(x (i) ,ẑ (i) ), i = 1, . . . , M Compute discriminator predictions ρ (j) p ← D(x (j) , z (j) ), j = 1, . . . , M L d ← − 1 M M i=1 log(ρ (i) q ) − 1 M M j=1 log(1 − ρ (j) p )</formula><p>Compute discriminator loss</p><formula xml:id="formula_4">L g ← − 1 M M i=1 log(1 − ρ (i) q ) − 1 M M j=1 log(ρ (j) p ) Compute generator loss θ d ← θ d − ∇ θ d L d</formula><p>Gradient update on discriminator network θ g ← θ g − ∇ θg L g Gradient update on generator networks until convergence An attractive property of adversarial approaches is that they do not require that the conditional densities can be computed; they only require that they can be sampled from in a way that allows gradient backpropagation. In the case of ALI, this means that gradients should propagate from the discriminator network to the encoder and decoder networks.</p><p>This can be done using the the reparametrization trick <ref type="bibr" target="#b2">Bengio et al., 2013b;</ref><ref type="bibr">a)</ref>. Instead of sampling directly from the desired distribution, the random variable is computed as a deterministic transformation of some noise such that its distribution is the desired distribution. For instance, if q(z | x) = N (µ(x), σ 2 (x)I), one can draw samples by computing</p><formula xml:id="formula_5">z = µ(x) + σ(x)</formula><p>, ∼ N (0, I).</p><p>(2)</p><p>More generally, one can employ a change of variable of the form</p><formula xml:id="formula_6">v = f (u, )<label>(3)</label></formula><p>where is some random source of noise.</p><p>The discriminator is trained to distinguish between samples from the encoder (x,ẑ) ∼ q(x, z) and samples from the decoder (x, z) ∼ p(x, z). The generator is trained to fool the discriminator, i.e., to generate x, z pairs from q(x, z) or p(x, z) that are indistinguishable one from another. See <ref type="figure" target="#fig_0">Figure 1</ref> for a diagram of the adversarial game and Algorithm 1 for an algorithmic description of the procedure.</p><p>In such a setting, and under the assumption of an optimal discriminator, the generator minimizes the Jensen-Shannon divergence <ref type="bibr" target="#b19">(Lin, 1991)</ref> between q(x, z) and p(x, z). This can be shown using the same proof sketch as in the original GAN paper <ref type="bibr" target="#b9">(Goodfellow et al., 2014)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">RELATION TO GAN</head><p>ALI bears close resemblance to GAN, but it differs from it in the two following ways:</p><p>• The generator has two components: the encoder, G z (x), which maps data samples x to z-space, and the decoder G x (z), which maps samples from the prior p(z) (a source of noise) to the input space. • The discriminator is trained to distinguish between joint pairs (x,ẑ = G x (x)) and (x = G x (z), z), as opposed to marginal samples x ∼ q(x) andx ∼ p(x).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">ALTERNATIVE APPROACHES TO FEEDFORWARD INFERENCE IN GANS</head><p>The ALI training procedure is not the only way one could learn a feedforward inference network in a GAN setting.</p><p>In recent work,  introduce a model called InfoGAN which minimizes the mutual information between a subset c of the latent code and x through the use of an auxiliary distribution Q(c | x). However, this does not correspond to full inference on z, as only the value for c is inferred. Additionally, InfoGAN requires that Q(c | x) is a tractable approximate posterior that can be sampled from and evaluated. ALI only requires that inference networks can be sampled from, allowing it to represent arbitrarily complex posterior distributions.</p><p>One could learn the inverse mapping from GAN samples: this corresponds to learning an encoder to reconstruct z, i.e. finding an encoder such that</p><formula xml:id="formula_7">E z∼p(z) [ z − G z (G x (z)) 2 2 ] ≈ 0.</formula><p>We are not aware of any work that reports results for this approach. This resembles the InfoGAN learning procedure but with a fixed generative model and a factorial Gaussian posterior with a fixed diagonal variance.</p><p>Alternatively, one could decompose training into two phases. In the first phase, a GAN is trained normally. In the second phase, the GAN's decoder is frozen and an encoder is trained following the ALI procedure (i.e., a discriminator taking both x and z as input is introduced). We call this post-hoc learned inference. In this setting, the encoder and the decoder cannot interact together during training and the encoder must work with whatever the decoder has learned during GAN training. Post-hoc learned inference may be suboptimal if this interaction is beneficial to modeling the data distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">GENERATOR VALUE FUNCTION</head><p>As with GANs, when ALI's discriminator gets too far ahead, its generator may have a hard time minimizing the value function in Equation 1. If the discriminator's output is sigmoidal, then the gradient of the value function with respect to the discriminator's output vanishes to zero as the output saturates.</p><p>As a workaround, the generator is trained to maximize</p><formula xml:id="formula_8">V (D, G) = E q(x) [log(1 − D(x, G z (x)))] + E p(z) [log(D(G x (z), z))]<label>(4)</label></formula><p>which has the same fixed points but whose gradient is stronger when the discriminator's output saturates.</p><p>The adversarial game does not require an analytical expression for the joint distributions. This means we can introduce variable changes without having to know the explicit distribution over the new variable. For instance, sampling from p(z) could be done by sampling ∼ N (0, I) and passing it through an arbitrary differentiable function z = f ( ).</p><p>However, gradient propagation into the encoder and decoder networks relies on the reparametrization trick, which means that ALI is not directly applicable to either applications with discrete data or to models with discrete latent variables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">DISCRIMINATOR OPTIMALITY</head><p>Proposition 1. Given a fixed generator G, the optimal discriminator is given by</p><formula xml:id="formula_9">D * (x, z) = q(x, z) q(x, z) + p(x, z) .<label>(5)</label></formula><p>Proof. For a fixed generator G, the complete data value function is</p><formula xml:id="formula_10">V (D, G) = E x,z∼q(x,z) [log(D(x, z))] + E x,z∼p(x,z) [log(1 − D(x, z))].<label>(6)</label></formula><p>The result follows by the concavity of the log and the simplified Euler-Lagrange equation first order conditions on (x, z) → D(x, z).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">RELATIONSHIP WITH THE JENSEN-SHANNON DIVERGENCE</head><p>Proposition 2. Under an optimal discriminator D * , the generator minimizes the Jensen-Shanon divergence which attains its minimum if and only if q(x, z) = p(x, z).</p><p>Proof. The proof is a straightforward extension of the proof in <ref type="bibr" target="#b9">Goodfellow et al. (2014)</ref>.    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">INVERTIBILITY</head><p>Proposition 3. Assuming optimal discriminator D and generator G.</p><formula xml:id="formula_11">If the encoder G x is determin- istic, then G x = G −1 z and G z = G −1 x almost everywhere. Sketch of proof. Consider the event R = {x : x − (G x • G z )(x)) &gt; } for some positive .</formula><p>This set can be seen as a section of the (x, z) space over the elements z such that z = G z (x).</p><p>The generator being optimal, the probabilities of R under p(x, z) and q(x, z) are equal. Now</p><formula xml:id="formula_12">p(x | z) = δ x−Gx(z)</formula><p>, where δ is the Dirac delta distribution. This is enough to show that there are no x satisfying the event R and thus G x = G −1 z almost everywhere. By symmetry, the same argument can be applied to show that G z = G −1</p><p>x . The complete proof is given in <ref type="bibr" target="#b6">(Donahue et al., 2016)</ref>, in which the authors independently examine the same model structure under the name Bidirectional GAN (BiGAN).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RELATED WORK</head><p>Other recent papers explore hybrid approaches to generative modeling. One such approach is to relax the probabilistic interpretation of the VAE model by replacing either the KL-divergence term or the reconstruction term with variants that have better properties. The adversarial autoencoder model <ref type="bibr" target="#b22">(Makhzani et al., 2015)</ref> replaces the KL-divergence term with a discriminator that is trained to distinguish between approximate posterior and prior samples, which provides a more flexible approach to matching the marginal q(z) and the prior. Other papers explore replacing the reconstruction term with either GANs or auxiliary networks. <ref type="bibr" target="#b18">Larsen et al. (2015)</ref> collapse the decoder of a VAE and the generator of a GAN into one network in order to supplement the reconstruction loss with a learned similarity metric. <ref type="bibr" target="#b17">Lamb et al. (2016)</ref> use the hidden layers of a pre-trained classifier as auxiliary reconstruction losses to help the VAE focus on higher-level details when reconstructing. <ref type="bibr" target="#b7">Dosovitskiy &amp; Brox (2016)</ref> combine both ideas into a unified loss function.</p><p>ALI's approach is also reminiscent of the adversarial autoencoder model, which employs a GAN to distinguish between samples from the approximate posterior distribution q(z | x) and prior samples. However, unlike adversarial autoencoders, no explicit reconstruction loss is being optimized in ALI, and the discriminator receives joint pairs of samples (x, z) rather than marginal z samples. <ref type="bibr" target="#b6">Donahue et al. (2016)</ref> proposes the same model under the name Bidirectional GAN (BiGAN), in which the authors emphasize the learned features' usefulness for auxiliary supervised and semi-supervised tasks. The main difference in terms of experimental setting is that they use a deterministic q(z | x) network, whereas we use a stochastic network. In our experience, this does not make a big difference when x is a deterministic function of z as the stochastic inference networks tend to become determinstic as training progresses. When using stochastic mappings from z to x, the additional flexiblity of stochastic posteriors is critical.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Independent work by</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTAL RESULTS</head><p>We applied ALI to four different datasets, namely CIFAR10 <ref type="bibr" target="#b16">(Krizhevsky &amp; Hinton, 2009</ref>), SVHN <ref type="bibr" target="#b23">(Netzer et al., 2011)</ref>, CelebA <ref type="bibr" target="#b20">(Liu et al., 2015)</ref> and a center-cropped, 64 × 64 version of the ImageNet dataset <ref type="bibr" target="#b28">(Russakovsky et al., 2015)</ref>. 1 Transposed convolutions are used in G x (z). This operation corresponds to the transpose of the matrix representation of a convolution, i.e., the gradient of the convolution with respect to its inputs. For more details about transposed convolutions and related operations, see <ref type="bibr" target="#b8">Dumoulin &amp; Visin (2016)</ref>; <ref type="bibr" target="#b30">Shi et al. (2016)</ref>; <ref type="bibr" target="#b24">Odena et al. (2016)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">SAMPLES AND RECONSTRUCTIONS</head><p>For each dataset, samples are presented <ref type="figure" target="#fig_2">(Figures 2a, 3a 4a and 5a)</ref>. They exhibit the same image fidelity as samples from other adversarially-trained models.  We also qualitatively evaluate the fit between the conditional distribution q(z | x) and the posterior distribution <ref type="figure" target="#fig_2">Figures 2b, 3b, 4b and 5b</ref>). This corresponds to reconstructing the input in a VAE setting. Note that the ALI training objective does not involve an explicit reconstruction loss.</p><formula xml:id="formula_13">p(z | x) by samplingẑ ∼ q(z | x) andx ∼ p(x | z =ẑ) (</formula><p>We observe that reconstructions are not always faithful reproductions of the inputs. They retain the same crispness and quality characteristic to adversarially-trained models, but oftentimes make mistakes in capturing exact object placement, color, style and (in extreme cases) object identity. The extent to which reconstructions deviate from the inputs varies between datasets: on CIFAR10, which arguably constitutes a more complex input distribution, the model exhibits less faithful reconstructions. This leads us to believe that poor reconstructions are a sign of underfitting.</p><p>This failure mode represents an interesting departure from the bluriness characteristic to the typical VAE setup. We conjecture that in the underfitting regime, the latent variable representation learned by ALI is potentially more invariant to less interesting factors of variation in the input and do not devote model capacity to capturing these factors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">LATENT SPACE INTERPOLATIONS</head><p>As a sanity check for overfitting, we look at latent space interpolations between validation set examples ( <ref type="figure">Figure 6</ref>). We sample pairs of validation set examples x 1 and x 2 and project them into z 1 and z 2 by sampling from the encoder. We then linearly interpolate between z 1 and z 2 and pass the intermediary points through the decoder to plot the input-space interpolations.</p><p>We observe smooth transitions between pairs of examples, and intermediary images remain believable. This is an indicator that ALI is not concentrating its probability mass exclusively around training examples, but rather has learned latent features that generalize well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">SEMI-SUPERVISED LEARNING</head><p>We investigate the usefulness of the latent representation learned by ALI through semi-supervised benchmarks on SVHN and CIFAR10.</p><p>We first compare with GAN on SVHN by following the procedure outlined in <ref type="bibr" target="#b25">Radford et al. (2015)</ref>.</p><p>We train an L2-SVM on the learned representations of a model trained on SVHN. The last three hidden layers of the encoder as well as its output are concatenated to form a 8960-dimensional feature vector. A 10,000 example held-out validation set is taken from the training set and is used for model selection. The SVM is trained on 1000 examples taken at random from the remainder of the training set. The test error rate is measured for 100 different SVMs trained on different random 1000-example training sets, and the average error rate is measured along with its standard deviation. <ref type="figure">Figure 6</ref>: Latent space interpolations on the CelebA validation set. Left and right columns correspond to the original pairs x 1 and x 2 , and the columns in between correspond to the decoding of latent representations interpolated linearly from z 1 to z 2 . Unlike other adversarial approaches like DCGAN <ref type="bibr" target="#b25">(Radford et al., 2015)</ref>, ALI allows one to interpolate between actual data points.</p><p>Using ALI's inference network as opposed to the discriminator to extract features, we achieve a misclassification rate that is roughly 3.00 ± 0.50% lower than reported in <ref type="bibr" target="#b25">Radford et al. (2015)</ref> ( <ref type="table" target="#tab_0">Table 1)</ref>, which suggests that ALI's inference mechanism is beneficial to the semi-supervised learning task.</p><p>We then investigate ALI's performance when label information is taken into account during training.</p><p>We adapt the discriminative model proposed in . The discriminator takes x and z as input and outputs a distribution over K + 1 classes, where K is the number of categories. When label information is available for q(x, z) samples, the discriminator is expected to predict the label. When no label information is available, the discriminator is expected to predict K + 1 for p(x, z) samples and k ∈ {1, . . . , K} for q(x, z) samples.</p><p>Interestingly,  found that they required an alternative training strategy for the generator where it tries to match first-order statistics in the discriminator's intermediate activations with respect to the data distribution (they refer to this as feature matching). We found that ALI did not require feature matching to obtain comparable results. We achieve results competitive with the state-of-the-art, as shown in Tables 1 and 2. <ref type="table" target="#tab_2">Table 2</ref> shows that ALI offers a modest improvement over , more specifically for 1000 and 2000 labeled examples.  <ref type="bibr" target="#b38">(Zhao et al., 2015)</ref> 23.56 DCGAN + L2-SVM <ref type="bibr" target="#b25">(Radford et al., 2015)</ref> 22.18 SDGM <ref type="bibr" target="#b21">(Maaløe et al., 2016)</ref> 16.61  We are still investigating the differences between ALI and GAN with respect to feature matching, but we conjecture that the latent representation learned by ALI is better untangled with respect to the classification task and that it generalizes better.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">CONDITIONAL GENERATION</head><p>We extend ALI to match a conditional distribution. Let y represent a fully observed conditioning variable. In this setting, the value function reads <ref type="figure">D(G x (z, y)</ref>, z, y))]</p><formula xml:id="formula_14">min G max D V (D, G) = E q(x) p(y) [log(D(x, G z (x, y), y))] + E p(z) p(y) [log(1 −</formula><p>(7) We apply the conditional version of ALI to CelebA using the dataset's 40 binary attributes. The attributes are linearly embedded in the encoder, decoder and discriminator. We observe how a single element of the latent space z changes with respect to variations in the attributes vector y. Conditional samples are shown in <ref type="figure" target="#fig_7">Figure 7</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">IMPORTANCE OF LEARNING INFERENCE JOINTLY WITH GENERATION</head><p>To highlight the role of the inference network during learning, we performed an experiment on a toy dataset for which q(x) is a 2D gaussian mixture with 25 mixture components laid out on a grid. The covariance matrices and centroids have been chosen such that the distribution exhibits lots of modes separated by large low-probability regions, which makes it a decently hard task despite the 2D nature of the dataset.</p><p>We trained ALI and GAN on 100,000 q(x) samples. The decoder and discriminator architectures are identical between ALI and GAN (except for the input of the discriminator, which receives the concatenation of x and z in the ALI case). Each model was trained 10 times using Adam <ref type="bibr" target="#b11">(Kingma &amp; Ba, 2014)</ref> with random learning rate and β 1 values, and the weights were initialized by drawing from a gaussian distribution with a random standard deviation.</p><p>We measured the extent to which the trained models covered all 25 modes by drawing 10,000 samples from their p(x) distribution and assigning each sample to a q(x) mixture component according to the mixture responsibilities. We defined a dropped mode as one that wasn't assigned to any sample. Using this definition, we found that ALI models covered 13.4 ± 5.8 modes on average (min: 8, max: 25) while GAN models covered 10.4 ± 9.2 modes on average (min: 1, max: 22). The ALI model in (a) does a much better job of covering the latent space (second row) and producing good samples than the two GAN models (b, c) augmented with an inference mechanism.</p><p>We then selected the best-covering ALI and GAN models, and the GAN model was augmented with an encoder using the learned inverse mapping and post-hoc learned inference procedures outlined in subsection 2.2. The encoders learned for GAN inference have the same architecture as ALI's encoder. We also trained a VAE with the same encoder-decoder architecture as ALI to outline the qualitative differences between ALI and VAE models.</p><p>We then compared each model's inference capabilities by reconstructing 10,000 held-out samples from q(x). <ref type="figure" target="#fig_8">Figure 8</ref> summarizes the experiment. We observe the following:</p><p>• The ALI encoder models a marginal distribution q(z) that matches p(z) fairly well (row 2, column a). The learned representation does a decent job at clustering and organizing the different mixture components.</p><p>• The GAN generator (row 5, columns b-c) has more trouble reaching all the modes than the ALI generator (row 5, column a), even over 10 runs of hyperparameter search.</p><p>• Learning an inverse mapping from GAN samples does not work very well: the encoder has trouble covering the prior marginally and the way it clusters mixture components is not very well organized (row 2, column b). As discussed in subsection 2.2, reconstructions suffer from the generator dropping modes.</p><p>• Learning inference post-hoc doesn't work as well as training the encoder and the decoder jointly. As had been hinted at in subsection 2.2, it appears that adversarial training benefits from learning inference at training time in terms of mode coverage. This also negatively impacts how the latent space is organized (row 2, column c). However, it appears to be better at matching q(z) and p(z) than when inference is learned through inverse mapping from GAN samples.</p><p>• Due to the nature of the loss function being optimized, the VAE model covers all modes easily (row 5, column d) and excels at reconstructing data samples (row 3, column d). However, they have a much more pronounced tendency to smear out their probability density (row 5, column d) and leave "holes" in q(z) (row 2, column d). Note however that recent approaches such as Inverse Autoregressive Flow <ref type="bibr" target="#b15">(Kingma et al., 2016)</ref> may be used to improve on this, at the cost of a more complex mathematical framework.</p><p>In summary, this experiment provides evidence that adversarial training benefits from learning an inference mechanism jointly with the decoder. Furthermore, it shows that our proposed approach for learning inference in an adversarial setting is superior to the other approaches investigated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION</head><p>We introduced the adversarially learned inference (ALI) model, which jointly learns a generation network and an inference network using an adversarial process. The model learns mutually coherent inference and generation networks, as exhibited by its reconstructions. The induced latent variable mapping is shown to be useful, achieving results competitive with the state-of-the-art on the semisupervised SVHN and CIFAR10 tasks. </p><formula xml:id="formula_15">√ 0.0 Leaky ReLU Convolution 1 × 1 1 × 1 32 √ 0.0 Leaky ReLU Convolution 1 × 1 1 × 1 3 × 0.0 Sigmoid D(x) -3 × 32 × 32 input Convolution 5 × 5 1 × 1 32 × 0.2 Maxout Convolution 4 × 4 2 × 2 64 × 0.5 Maxout Convolution 4 × 4 1 × 1 128 × 0.5 Maxout Convolution 4 × 4 2 × 2 256 × 0.5 Maxout Convolution 4 × 4 1 × 1 512 × 0.5 Maxout D(z) -64 × 1 × 1 input Convolution 1 × 1 1 × 1 512 × 0.2 Maxout Convolution 1 × 1 1 × 1 512 × 0.5 Maxout D(x, z) -1024 × 1 × 1 input</formula><p>Concatenate D(x) and D(z) along the channel axis</p><formula xml:id="formula_16">Convolution 1 × 1 1 × 1 1024 × 0.5 Maxout Convolution 1 × 1 1 × 1 1024 × 0.5 Maxout Convolution 1 × 1 1 × 1 1 × 0.5 Sigmoid</formula><p>Optimizer Adam (α = 10 −4 , β 1 = 0.5, β 2 = 10 −3 ) Batch size 100 Epochs 6475 Leaky ReLU slope, maxout pieces 0.1, 2</p><p>Weight, bias initialization Isotropic gaussian (µ = 0, σ = 0.01), Constant(0)  <ref type="bibr" target="#b10">(Goodfellow et al., 2013)</ref> are used in the discriminator.   Optimizer Adam (α = 10 −4 , β 1 = 0.5, β 2 = 10 −3 ) Batch size 128 Epochs 125 Leaky ReLU slope 0.01 Weight, bias initialization Isotropic gaussian (µ = 0, σ = 0.01), Constant(0)  The Circle of Infinite Painters is a very prolific artistic group. Very little is known about the Circle, but what we do know is that it is composed of two very brilliant artists. It has produced new paintings almost daily for more than twenty years, each one more beautiful than the others. Not only are the paintings exquisite, but their title and description is by itself a literary masterpiece.</p><p>However, some scholars believe that things might not be as they appear: certain discrepancies in the Circle's body of work hints at the Circle being composed of more than one artistic duo. This is what Joseph Discriminator, art critique and world expert on the Circle, believes. He's recently been working intensively on the subject. Without knowing it, he's right: the Circle is not one, but two artistic duos.</p><p>Xavier and Zach Prior form the creative component of the group. Xavier is a painter and can, in one hour and starting from nothing, produce a painting that would make any great painter jealous. Impossible however for him to explain what he's done: he works by intuition alone. Zach is an author and his literary talent equals Xavier's artistic talent. His verb is such that the scenes he describes could just as well be real.</p><p>By themselves, the Prior brothers cannot collaborate: Xavier can't paint anything from a description and Zach is bored to death with the idea of describing anything that does not come out of his head. This is why the Prior brothers depend on the Conditional sisters so much.</p><p>Zelda Conditional has an innate descriptive talent: she can examine a painting and describe it so well that the original would seem like an imitation. Xena Conditional has a technical mastery of painting that allows her to recreate everything that's described to her in the most minute details. However, their creativity is inversely proportional to their talent: by themselves, they cannot produce anything of interest.</p><p>As such, the four members of the Circle work in pairs. What Xavier paints, Zelda describes, and what Zach describes, Xena paints. They all work together to fulfill the same vision of a unified Circle of Infinite Painters, a whole greater than the sum of its parts. This is why Joseph Discriminator's observations bother them so much. Secretly, the Circle put Mr. Discriminator under surveillance. Whatever new observation he's made, they know right away and work on attenuating the differences to maintain the illusion of a Circle of Infinite Painters made of a single artistic duo.</p><p>Will the Circle reach this ideal, or will it be unmasked by Mr. Discriminator?</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>The adversarially learned inference (ALI) game.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Samples and reconstructions on the SVHN dataset. For the reconstructions, odd columns are original samples from the validation set and even columns are corresponding reconstructions (e.g., second column contains reconstructions of the first column's validation set samples). (a) CelebA samples. (b) CelebA reconstructions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Samples and reconstructions on the CelebA dataset. For the reconstructions, odd columns are original samples from the validation set and even columns are corresponding reconstructions. (a) CIFAR10 samples. (b) CIFAR10 reconstructions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Samples and reconstructions on the CIFAR10 dataset. For the reconstructions, odd columns are original samples from the validation set and even columns are corresponding reconstructions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 :</head><label>5</label><figDesc>Samples and reconstructions on the Tiny ImageNet dataset. For the reconstructions, odd columns are original samples from the validation set and even columns are corresponding reconstructions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 :</head><label>7</label><figDesc>Conditional generation sequence. We sample a single fixed latent code z. Each row has a subset of attributes that are held constant across columns. The attributes are male, attractive, young for row I; male, attractive, older for row II; female, attractive, young for row III; female, attractive, older for Row IV. Attributes are then varied uniformly over rows across all columns in the following sequence: (b) black hair; (c) brown hair; (d) blond hair; (e) black hair, wavy hair; (f) blond hair, bangs; (g) blond hair, receding hairline; (h) blond hair, balding; (i) black hair, smiling; (j) black hair, smiling, mouth slightly open; (k) black hair, smiling, mouth slightly open, eyeglasses; (l) black hair, smiling, mouth slightly open, eyeglasses, wearing hat.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 8 :</head><label>8</label><figDesc>Comparison of (a) ALI, (b) GAN with an encoder learned to reconstruct latent samples (c) GAN with an encoder learned through ALI, (d) variational autoencoder (VAE) on a 2D toy dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 9 :</head><label>9</label><figDesc>A Circle of Infinite Painters' view of the ALI game.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>SVHN test set missclassification rate .</figDesc><table><row><cell>Model</cell><cell>Misclassification rate</cell></row><row><cell>VAE (M1 + M2) (Kingma et al., 2014)</cell><cell>36.02</cell></row><row><cell>SWWAE with dropout</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>CIFAR10 test set missclassification rate for semi-supervised learning using different numbers of trained labeled examples. For ALI, error bars correspond to 3 times the standard deviation.</figDesc><table><row><cell>Number of labeled examples</cell><cell>1000</cell><cell>2000</cell><cell>4000</cell><cell>8000</cell></row><row><cell>Model</cell><cell></cell><cell cols="2">Misclassification rate</cell><cell></cell></row><row><cell>Ladder network (Rasmus et al., 2015)</cell><cell></cell><cell></cell><cell>20.40</cell><cell></cell></row><row><cell>CatGAN (Springenberg, 2015)</cell><cell></cell><cell></cell><cell>19.58</cell><cell></cell></row></table><note>GAN (feature matching) (Salimans et al., 2016) 21.83 ± 2.01 19.61 ± 2.09 18.63 ± 2.32 17.72 ± 1.82 ALI (ours, no feature matching) 19.98 ± 0.89 19.09 ± 0.44 17.99 ± 1.62 17.05 ± 1.49</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>CIFAR10 model hyperparameters (unsupervised). Maxout layers</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>SVHN model hyperparameters (unsupervised).</figDesc><table><row><cell>G z (x) -3 × 64 × 64 input Convolution 2 × 2 Convolution 7 × 7 Convolution 5 × 5 Convolution 7 × 7 Convolution 4 × 4</cell><cell>1 × 1 2 × 2 2 × 2 2 × 2 1 × 1</cell><cell>64 128 256 256 512</cell><cell>√ √ √ √ √</cell><cell>0.0 0.0 0.0 0.0 0.0</cell><cell>Leaky ReLU Leaky ReLU Leaky ReLU Leaky ReLU Leaky ReLU</cell></row><row><cell>Convolution 1 × 1</cell><cell>1 × 1</cell><cell>512</cell><cell>×</cell><cell>0.0</cell><cell>Linear</cell></row><row><cell>G x (z) -512 × 1 × 1 input Transposed convolution 4 × 4 Transposed convolution 7 × 7 Transposed convolution 5 × 5 Transposed convolution 7 × 7 Transposed convolution 2 × 2</cell><cell>1 × 1 2 × 2 2 × 2 2 × 2 1 × 1</cell><cell>512 256 256 128 64</cell><cell>√ √ √ √ √</cell><cell>0.0 0.0 0.0 0.0 0.0</cell><cell>Leaky ReLU Leaky ReLU Leaky ReLU Leaky ReLU Leaky ReLU</cell></row><row><cell>Convolution 1 × 1</cell><cell>1 × 1</cell><cell>3</cell><cell>×</cell><cell>0.0</cell><cell>Sigmoid</cell></row><row><cell>D(x) -3 × 64 × 64 input Convolution 2 × 2 Convolution 7 × 7 Convolution 5 × 5 Convolution 7 × 7 Convolution 4 × 4</cell><cell>1 × 1 2 × 2 2 × 2 2 × 2 1 × 1</cell><cell>64 128 256 256 512</cell><cell>√ √ √ √ √</cell><cell>0.0 0.0 0.0 0.0 0.0</cell><cell>Leaky ReLU Leaky ReLU Leaky ReLU Leaky ReLU Leaky ReLU</cell></row><row><cell>D(z) -512 × 1 × 1 input</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Convolution 1 × 1</cell><cell>1 × 1</cell><cell>1024</cell><cell>×</cell><cell>0.2</cell><cell>Leaky ReLU</cell></row><row><cell>Convolution 1 × 1</cell><cell>1 × 1</cell><cell>1024</cell><cell>×</cell><cell>0.2</cell><cell>Leaky ReLU</cell></row><row><cell>D(x, z) -1024 × 1 × 1 input</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">Concatenate D(x) and D(z) along the channel axis</cell><cell></cell></row><row><cell>Convolution 1 × 1</cell><cell>1 × 1</cell><cell>2048</cell><cell>×</cell><cell>0.2</cell><cell>Leaky ReLU</cell></row><row><cell>Convolution 1 × 1</cell><cell>1 × 1</cell><cell>2048</cell><cell>×</cell><cell>0.2</cell><cell>Leaky ReLU</cell></row><row><cell>Convolution 1 × 1</cell><cell>1 × 1</cell><cell>1</cell><cell>×</cell><cell>0.2</cell><cell>Sigmoid</cell></row><row><cell cols="3">Optimizer Adam (α = 10 −4 , β 1 = 0.5)</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Batch size 100</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Epochs 123</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Leaky ReLU slope 0.02</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">Weight, bias initialization Isotropic gaussian (µ = 0, σ = 0.01), Constant(0)</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 :</head><label>5</label><figDesc>CelebA model hyperparameters (unsupervised).</figDesc><table><row><cell>G z (x) -3 × 64 × 64 input Convolution 4 × 4 Convolution 4 × 4 Convolution 4 × 4 Convolution 4 × 4 Convolution 4 × 4 Convolution 4 × 4 Convolution 1 × 1 Convolution 1 × 1</cell><cell>2 × 2 1 × 1 2 × 2 1 × 1 2 × 2 1 × 1 1 × 1 1 × 1</cell><cell>64 64 128 128 256 256 2048 2048</cell><cell>√ √ √ √ √ √ √ √</cell><cell>0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0</cell><cell>Leaky ReLU Leaky ReLU Leaky ReLU Leaky ReLU Leaky ReLU Leaky ReLU Leaky ReLU Leaky ReLU</cell></row><row><cell>Convolution 1 × 1</cell><cell>1 × 1</cell><cell>512</cell><cell>×</cell><cell>0.0</cell><cell>Linear</cell></row><row><cell>G x (z) -256 × 1 × 1 input Convolution 1 × 1 Convolution 1 × 1 Transposed convolution 4 × 4 Transposed convolution 4 × 4 Transposed convolution 4 × 4 Transposed convolution 4 × 4 Transposed convolution 4 × 4 Transposed convolution 4 × 4</cell><cell>1 × 1 1 × 1 1 × 1 2 × 2 1 × 1 2 × 2 1 × 1 2 × 2</cell><cell>2048 256 256 128 128 64 64 64</cell><cell>√ √ √ √ √ √ √ √</cell><cell>0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0</cell><cell>Leaky ReLU Leaky ReLU Leaky ReLU Leaky ReLU Leaky ReLU Leaky ReLU Leaky ReLU Leaky ReLU</cell></row><row><cell>Convolution 1 × 1</cell><cell>1 × 1</cell><cell>3</cell><cell>×</cell><cell>0.0</cell><cell>Sigmoid</cell></row><row><cell>D(x) -3 × 64 × 64 input</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Convolution 4 × 4 Convolution 4 × 4 Convolution 4 × 4 Convolution 4 × 4 Convolution 4 × 4 Convolution 4 × 4</cell><cell>2 × 2 1 × 1 2 × 2 1 × 1 2 × 2 1 × 1</cell><cell>64 64 128 128 256 256</cell><cell>× √ √ √ √ √</cell><cell>0.2 0.2 0.2 0.2 0.2 0.2</cell><cell>Leaky ReLU Leaky ReLU Leaky ReLU Leaky ReLU Leaky ReLU Leaky ReLU</cell></row><row><cell>D(z) -256 × 1 × 1 input</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Convolution 1 × 1</cell><cell>1 × 1</cell><cell>2048</cell><cell>×</cell><cell>0.2</cell><cell>Leaky ReLU</cell></row><row><cell>Convolution 1 × 1</cell><cell>1 × 1</cell><cell>2048</cell><cell>×</cell><cell>0.2</cell><cell>Leaky ReLU</cell></row><row><cell>D(x, z) -2304 × 1 × 1 input</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">Concatenate D(x) and D(z) along the channel axis</cell><cell></cell></row><row><cell>Convolution 1 × 1</cell><cell>1 × 1</cell><cell>4096</cell><cell>×</cell><cell>0.2</cell><cell>Leaky ReLU</cell></row><row><cell>Convolution 1 × 1</cell><cell>1 × 1</cell><cell>4096</cell><cell>×</cell><cell>0.2</cell><cell>Leaky ReLU</cell></row><row><cell>Convolution 1 × 1</cell><cell>1 × 1</cell><cell>1</cell><cell>×</cell><cell>0.2</cell><cell>Sigmoid</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 6 :</head><label>6</label><figDesc>Tiny ImageNet model hyperparameters (unsupervised). B A GENERATIVE STORY FOR ALI</figDesc><table><row><cell>Zelda's description</cell><cell>Zach's description</cell></row><row><cell>Mr. Discriminator</cell><cell></cell></row><row><cell>Xavier's painting</cell><cell>Xena's depiction</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">The code for all experiments can be found at https://github.com/IshmaelBelghazi/ALI. Readers can also consult the accompanying website at https://ishmaelbelghazi.github.io/ALI.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>The authors would like to acknowledge the support of the following agencies for research funding and computing support: NSERC, Calcul Québec, Compute Canada. We would also like to thank the developers of Theano <ref type="bibr" target="#b3">(Bergstra et al., 2010;</ref><ref type="bibr" target="#b0">Bastien et al., 2012;</ref><ref type="bibr" target="#b32">Theano Development Team, 2016)</ref>, Blocks and Fuel (van Merriënboer et al., 2015), which were used extensively for the paper. Finally, we would like to thank Yoshua Bengio, David Warde-Farley, Yaroslav Ganin and Laurent Dinh for their valuable feedback.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frédéric</forename><surname>Bastien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Lamblin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Razvan</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bergstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arnaud</forename><surname>Bergeron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Bouchard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1211.5590</idno>
		<title level="m">Theano: new features and speed improvements</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Estimating or propagating gradients through stochastic neurons for conditional computation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Léonard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1308.3432</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Thibodeau-Laufer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Alain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Yosinski</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1306.1091</idno>
		<title level="m">Deep generative stochastic networks trainable by backprop</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Theano: a cpu and gpu math expression compiler</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bergstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Breuleux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frédéric</forename><surname>Bastien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Lamblin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Razvan</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Desjardins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Turian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Python for scientific computing conference (SciPy)</title>
		<meeting>the Python for scientific computing conference (SciPy)<address><addrLine>Austin, TX</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Brock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theodore</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Ritchie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weston</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.07093</idno>
		<title level="m">Neural photo editing with introspective adversarial networks</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Infogan: Interpretable representation learning by information maximizing generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rein</forename><surname>Houthooft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2172" to="2180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Krähenbühl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.09782</idno>
		<title level="m">Adversarial feature learning</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Generating images with perceptual similarity metrics based on deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.02644</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">A guide to convolution arithmetic for deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Dumoulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesco</forename><surname>Visin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.07285</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1302.4389</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">Maxout networks. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Fast gradient-based inference with continuous latent variable models in auxiliary form</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kingma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1306.0733</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6114</idno>
		<title level="m">Auto-encoding variational bayes</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Semi-supervised learning with deep generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shakir</forename><surname>Diederik P Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danilo</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Jimenez Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3581" to="3589" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.04934</idno>
		<title level="m">Improving variational inference with inverse autoregressive flow</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Discriminative regularization for generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Lamb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Dumoulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.03220</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Autoencoding beyond pixels using a learned similarity metric</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Boesen Lindbo Larsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Søren</forename><forename type="middle">Kaae</forename><surname>Sønderby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ole</forename><surname>Winther</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1512.09300</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Divergence measures based on the shannon entropy. Information Theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianhua</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="145" to="151" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Deep learning face attributes in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3730" to="3738" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><surname>Maaløe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Casper</forename><forename type="middle">Kaae</forename><surname>Sønderby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ole</forename><surname>Søren Kaae Sønderby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Winther</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.05473</idno>
		<title level="m">Auxiliary deep generative models</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alireza</forename><surname>Makhzani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navdeep</forename><surname>Jaitly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.05644</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">Adversarial autoencoders. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Reading digits in natural images with unsupervised feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuval</forename><surname>Netzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Bissacco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS workshop on deep learning and unsupervised feature learning</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">2011</biblScope>
		</imprint>
	</monogr>
	<note>4. Granada, Spain</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Deconvolution and checkerboard artifacts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Augustus</forename><surname>Odena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Dumoulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Olah</surname></persName>
		</author>
		<ptr target="http://distill.pub/2016/deconv-checkerboard/" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Unsupervised representation learning with deep convolutional generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06434</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Semi-supervised learning with ladder network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antti</forename><surname>Rasmus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harri</forename><surname>Valpola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikko</forename><surname>Honkala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathias</forename><surname>Berglund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tapani</forename><surname>Raiko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Stochastic backpropagation and approximate inference in deep generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danilo</forename><surname>Jimenez Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shakir</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1401.4082</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Imagenet large scale visual recognition challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Bernstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="252" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vicki</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.03498</idno>
		<title level="m">Improved techniques for training gans</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Is the deconvolution layer the same as a convolutional layer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenzhe</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jose</forename><surname>Caballero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Theis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ferenc</forename><surname>Huszar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Aitken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Ledig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zehan</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.07009</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Unsupervised and semi-supervised learning with categorical generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jost</forename><surname>Tobias Springenberg</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06390</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Theano: A Python framework for fast computation of mathematical expressions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theano</forename><surname>Development Team</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.02688</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Theis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.01844</idno>
		<title level="m">Aron van den Oord, and Matthias Bethge. A note on the evaluation of generative models</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sander</forename><surname>Dieleman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heiga</forename><surname>Zen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">W</forename><surname>Senior</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.03499</idno>
		<title level="m">Wavenet: A generative model for raw audio</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1601.06759</idno>
		<title level="m">Pixel recurrent neural networks</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lasse</forename><surname>Espeholt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.05328</idno>
		<title level="m">Conditional image generation with pixelcnn decoders</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bart Van Merriënboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitriy</forename><surname>Dumoulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Serdyuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Warde-Farley</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.00619</idno>
		<title level="m">Chorowski, and Yoshua Bengio. Blocks and fuel: Frameworks for deep learning</title>
		<imprint>
			<date type="published" when="2015-01" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junbo</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Mathieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Goroshin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.02351</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">Stacked what-where auto-encoders. arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
