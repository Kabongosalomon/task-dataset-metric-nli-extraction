<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Metric Learning With HORDE: High-Order Regularizer for Deep Embeddings</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Jacob</surname></persName>
							<email>pierre.jacob@ensea.fr</email>
							<affiliation key="aff0">
								<orgName type="laboratory">ETIS UMR 8051</orgName>
								<orgName type="institution" key="instit1">Université Paris Seine</orgName>
								<orgName type="institution" key="instit2">UCP</orgName>
								<orgName type="institution" key="instit3">ENSEA</orgName>
								<orgName type="institution" key="instit4">CNRS</orgName>
								<address>
									<postCode>F-95000</postCode>
									<settlement>Cergy</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Picard</surname></persName>
							<email>picard@ensea.fr</email>
							<affiliation key="aff0">
								<orgName type="laboratory">ETIS UMR 8051</orgName>
								<orgName type="institution" key="instit1">Université Paris Seine</orgName>
								<orgName type="institution" key="instit2">UCP</orgName>
								<orgName type="institution" key="instit3">ENSEA</orgName>
								<orgName type="institution" key="instit4">CNRS</orgName>
								<address>
									<postCode>F-95000</postCode>
									<settlement>Cergy</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory" key="lab1">LIGM</orgName>
								<orgName type="laboratory" key="lab2">UMR 8049</orgName>
								<orgName type="institution">UPE</orgName>
								<address>
									<addrLine>École des Ponts</addrLine>
									<settlement>Champs-sur-Marne</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aymeric</forename><surname>Histace</surname></persName>
							<email>aymeric.histace@ensea.fr</email>
							<affiliation key="aff0">
								<orgName type="laboratory">ETIS UMR 8051</orgName>
								<orgName type="institution" key="instit1">Université Paris Seine</orgName>
								<orgName type="institution" key="instit2">UCP</orgName>
								<orgName type="institution" key="instit3">ENSEA</orgName>
								<orgName type="institution" key="instit4">CNRS</orgName>
								<address>
									<postCode>F-95000</postCode>
									<settlement>Cergy</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Klein</surname></persName>
							<affiliation key="aff2">
								<orgName type="laboratory">C3N</orgName>
								<orgName type="institution">Pôle Judiciaire de la Gendarmerie Nationale</orgName>
								<address>
									<addrLine>5 boulevard de l&apos;Hautil</addrLine>
									<postCode>95000</postCode>
									<settlement>Cergy</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Metric Learning With HORDE: High-Order Regularizer for Deep Embeddings</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T09:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Learning an effective similarity measure between image representations is key to the success of recent advances in visual search tasks (e.g. verification or zero-shot learning). Although the metric learning part is well addressed, this metric is usually computed over the average of the extracted deep features. This representation is then trained to be discriminative. However, these deep features tend to be scattered across the feature space. Consequently, the representations are not robust to outliers, object occlusions, background variations, etc. In this paper, we tackle this scattering problem with a distribution-aware regularization named HORDE 1 . This regularizer enforces visually-close images to have deep features with the same distribution which are well localized in the feature space. We provide a theoretical analysis supporting this regularization effect. We also show the effectiveness of our approach by obtaining state-of-the-art results on 4 well-known datasets (Cub-200-2011, Cars-196, Stanford Online Products and Inshop  Clothes Retrieval).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Deep Metric Learning (DML) is an important yet challenging topic in the Computer Vision community with numerous applications such as visual product search <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b17">18]</ref>, multi-modal retrieval <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b30">31]</ref>, face verification and clustering <ref type="bibr" target="#b21">[22]</ref>, person or vehicle identification <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b37">38]</ref>. To deal with such applications, a DML method aims to learn an embedding space where all the visually-related images (e.g., images of the same car model) are close to each other and dissimilar ones (e.g., images of two cars from the same brand but from different models) are far apart.</p><p>Recent contributions in DML can be divided into three categories. A first category includes methods that focus <ref type="bibr" target="#b0">1</ref> Code is available at https://github.com/pierre-jacob/ ICCV2019-Horde on batch construction to maximize the number of pairs or triplets available to compute the similarity (e.g., N-pair loss <ref type="bibr" target="#b22">[23]</ref>). A second category involves the design of loss functions to improve the generalization (e.g., binomial deviance <ref type="bibr" target="#b25">[26]</ref>). The third category covers ensemble methods that tackle the embedding space diversity (e.g., BIER <ref type="bibr" target="#b18">[19]</ref>).</p><p>This similarity metric is trained jointly with the image representation which is computed using deep neural network architectures such as GoogleNet <ref type="bibr" target="#b24">[25]</ref> or BN-Inception <ref type="bibr" target="#b7">[8]</ref>. For all of these networks, the image representations are obtained by the aggregation of the deep features using a Global Average Pooling <ref type="bibr" target="#b36">[37]</ref>. Hence, the deep features are summarized using the sample mean, and the training process makes sure that the sample mean is discriminative enough for the target task.</p><p>Our insight is that ignoring the characteristics of the deep feature distribution leads to a lack of distinctiveness in the deep features. We illustrate this phenomenon in <ref type="figure" target="#fig_0">Figure 1</ref>. In <ref type="figure" target="#fig_0">Figure 1a</ref>, we train a DML model on MNIST and plot both the deep features and the image representations from a set of images sampled from the training set. We observe that the representations are perfectly organized while the deep features are in contrast scattered in the entire space. As the representations are obtained using the sample mean only, they are sensitive to outliers or sampling problems (occlusions, illumination, background variation, etc.), which we refer to as the scattering problem. We illustrate this problem in <ref type="figure" target="#fig_0">Figure 1b</ref> where the representations are computed using the same architecture but by sampling only 1/6-th of the original deep features. As we can see, the resulting representations are no longer correctly organized.</p><p>In this paper, we propose HORDE, a High-Order Regularizer for Deep Embeddings which tackles this scattering problem. By minimizing (resp. maximizing) the distance between high-order moments of the deep feature distributions, this DML regularizer enforces deep feature distributions from similar (resp. dissimilar) images to be nearly identical (resp. to not overlap). As illustrated in <ref type="figure" target="#fig_0">Figure 1c</ref>, our HORDE regularizer produces well localized features,  <ref type="figure" target="#fig_0">Figure 1a</ref> shows discriminative representations but with scattered deep features (Remark the scale of the axes). <ref type="figure" target="#fig_0">Figure 1b</ref> shows representations computed with 1/6-th of the deep features, leading to a disorganized space. <ref type="figure" target="#fig_0">Figure 1c</ref> shows the same model trained with HORDE: the deep features are well concentrated and the representations computed using 1/6-th of the deep features are organized according to the classes (best viewed on a computer screen).</p><p>leading to robust image representations even if they are computed using only 1/6-th of the original deep features. Our contributions are the following: First, we propose a High-Order Regularizer for Deep Embeddings (HORDE) that reduces the scattering problem and allows the sample mean to be a robust representation. We provide a theoretical analysis in which we support this claim by showing that HORDE is a lower bound of the Wasserstein distance between the deep feature distributions while also being an upper-bound of their Maximum Mean Discrepancy. Second, we show that HORDE consistently improves DML with varying loss functions, even when considering ensemble methods. Using HORDE, we are able to obtain state of the art results on four standard DML datasets (Cub-200-2011 <ref type="bibr" target="#b26">[27]</ref>, Cars-196 <ref type="bibr" target="#b11">[12]</ref>, In-Shop Clothes Retrieval <ref type="bibr" target="#b14">[15]</ref> and Stanford Online Products <ref type="bibr" target="#b17">[18]</ref>).</p><p>The remaining of this paper is organized as follows: In section 2, we review recent works on deep metric learning and how our approach differs. In section 3, after an overview of our proposed method, we present the practical implementation of HORDE as well as a theoretical analysis. In section 4 we compare our proposed architecture with the state-of-the-art on four image retrieval datasets. We show the benefit of HORDE regularization for different loss functions and an ensemble method. In section 5 we conduct extensive experiments to demonstrate the robustness of our regularization and its statistical consistency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>In DML, we jointly learn the image representations and an embedding in such a way that the Euclidean distance corresponds with the semantic content of the images. Current approaches use a pre-trained CNN to produce deep features, then they aggregate these features using Global Average Pooling <ref type="bibr" target="#b36">[37]</ref>. Finally they learn the target representation with a linear projection. The whole network is fine-tuned to solve the metric learning task according to three criteria: a loss function, a sampling strategy and an ensemble method.</p><p>Regarding the loss function, popular approaches consider pairs <ref type="bibr" target="#b2">[3]</ref> or triplets <ref type="bibr" target="#b21">[22]</ref> of similar/dissimilar samples. Recent works generalize these loss functions to larger tuples <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b25">26]</ref> or improve the design <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b33">34]</ref>. The sampling of the training tuples receive plenty of attention <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b22">23]</ref>, either through mining <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b21">22]</ref>, proxy based approximations <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17]</ref> or hard negative generation <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b12">13]</ref>. Finally, ensemble methods have recently become an increasingly popular way of improving the performances of DML architectures <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b34">35]</ref>. Our proposed HORDE regularizer is a complementary approach. We show in section 4 that it consistently improves these popular DML models.</p><p>Recent approaches also consider a distribution analysis for DML <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b12">13]</ref>. Contrarily to us, they only consider the distribution of the representations to design a loss function or a hard negative generator but they do not take into account the distribution of the underlying deep features. Consequently, they do not address the scattering problem. More precisely, Magnet loss <ref type="bibr" target="#b20">[21]</ref> proposes to better represent a given class manifold by learning a K-mode distribution instead of the standard uni-mode assumption. To that aim, the per-class distribution is approximated using K-means clustering. The proposed loss tries to minimize the distance between a representation and its nearest class mode and tries to maximize the distance between all modes of all other classes. However, since the magnet loss is directly applied to the sample means of the deep features, it leads to the scattering problem illustrated in <ref type="figure" target="#fig_0">Figure 1</ref>. In DVML <ref type="bibr" target="#b12">[13]</ref>, the authors assume that the representations follow a per-class Gaussian distribution. They propose to estimate the parameters of these distributions using a variational auto-encoder approach. Then, by sampling from a Gaussian distribution with the learned parameters, they are able to generate artificial hard samples to train the network. However, no assumption is made on the distribution of the deep features, which leads to the scattering problem illustrated in <ref type="figure" target="#fig_0">Figure 1</ref> (see also <ref type="bibr" target="#b12">[13]</ref>, <ref type="figure" target="#fig_0">Figure 1</ref>). In contrast, we show that focusing on the distribution of the deep features reduces the scattering problem and improves the performances of DML architectures.</p><p>In the next section, we first give an overview of the proposed HORDE regularization. Then, we describe the practical implementation of the high-order moments computation. Finally, we give theoretical insights which support the regularization effect of HORDE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Proposed High-Order Regularizer</head><p>We first give an overview of the proposed method in Figure 2. We start by extracting a deep feature map of size h × w × c using a CNN where h and w are the height and width of the feature map and c is the deep features dimension. Following standard DML practices, these features are aggregated using a Global Average Pooling to build the image representation and are projected into an embedding space before a similarity-based loss function is computed over these representations (top-right blue box in <ref type="figure" target="#fig_1">Figure 2</ref>).</p><p>In HORDE, we directly optimize the distribution of the deep features by minimizing (respectively maximizing) a distance between the deep feature distributions of similar images (respectively dissimilar images). We approximate the deep feature distribution distance by computing highorder moments (bottom-right red box in <ref type="figure" target="#fig_1">Figure 2</ref>). We recursively approximate the high-order moments and we compute an embedding after each of these approximations. Then, we apply a DML loss function on each of these embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">High-order computation</head><p>In practice, the computation of high-order moments is very intensive due to their high dimension. Furthermore, it has been shown in <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b18">19]</ref> that an independence assumption over all high-order moment components is unrealistic. Hence, we rely on factorization schemes to approximate their computation, such as Random Maclaurin (RM) <ref type="bibr" target="#b9">[10]</ref>. The RM algorithm relies on a set of random projectors to approximate the inner product between two high-order moments. In the case of the second-order, we sample two independent random vectors w 1 , w 2 ∼ W where W is a uniform distribution in {−1, +1}. For two non random vectors x and y, the inner product between their second-order moments can be approximated as:</p><formula xml:id="formula_0">E w1,w2∼W [φ 2 (x)φ 2 (y)] = x ; y 2 = x ⊗ x ; y ⊗ y<label>(1)</label></formula><p>where ⊗ is the Kronecker product, E w1,w2∼W is the expectation over the random vectors w 1 and w 2 which follow the distribution W and φ 2 (x) = w 1 ; x w 2 ;</p><p>x . This approach easily holds to estimate any inner product between K-th moments:</p><formula xml:id="formula_1">E w k ∼W [φ K (x)φ K (y)] = x ; y K = x ⊗ · · · ⊗ x K times ; y ⊗ · · · ⊗ y K times<label>(2)</label></formula><p>where φ K (x) is computed as:</p><formula xml:id="formula_2">φ K (x) = K k=1 w k ; x<label>(3)</label></formula><p>In practice, we approximate the expectation of this quantity by using the sample mean over d sets of these random projectors. That is, we sample independent random matrices W 1 , W 2 , ..., W K ∈ R c×d and we compute the vector φ K (x) ∈ R d that approximates the K-th moments of x with the following equation:</p><formula xml:id="formula_3">φ K (x) = W 1 x W 2 x · · · W K x<label>(4)</label></formula><p>where is the Hadamard (element-wise) product. Thus, the inner product between the K-th moments is:</p><formula xml:id="formula_4">x ; y K ≈ 1 d φ K (x) ; φ K (y)<label>(5)</label></formula><p>However, Random Maclaurin produces a consistent estimator independently of the analyzed distributions, and thus also encodes non informative high-order moment components. To ignore these non-informative components, the projectors W k can be learned from the data. However, the high number of parameters in O(K 2 cd) makes it difficult to learn a consistent estimator, as we empirically show in subsection 5.2. We solve this problem by computing the high-order moment approximation using the following recursion:</p><formula xml:id="formula_5">φ k (x) = φ k−1 (x) W k x<label>(6)</label></formula><p>This last equation leads to the proposed cascaded architecture for HORDE summarized in Algorithm 1. We empirically show in subsection 5.2 that this recursive approach produces a consistent estimator of the informative highorder moment components. Then, the HORDE regularizer consists in computing a DML-like loss function on each of the high-order moments, such that similar (respectively dissimilar) images have similar (respectively dissimilar) high-order moments:</p><formula xml:id="formula_6">L HORDE = K k=2 L k (E x∼I [φ k (x)], E y∼J [φ k (y)]) (7)</formula><p>In practice, we cannot compute the expectation E x∼I [φ k (x)] since the distribution of x is unknown. We propose to estimate it using the empirical estimator:  </p><formula xml:id="formula_7">L HORDE (I, J ) = K k=2 L k 1 |I| xi∈I φ k (x i ), 1 |J | xj ∈J φ k (y j )  <label>(8</label></formula><formula xml:id="formula_8">φ 2 (x) ← 1 √ d W 1 x W 2 x 3: k ← 3 4: while k ≤ K do 5: φ k (x) = φ k−1 (x) W k x 6: k ← k + 1 7: end while 8: return φ 2 (x), . . . , φ K (x) 9: end procedure</formula><p>This can easily be extended to any tuple based loss function.</p><p>In practice, we use the same DML loss function for HORDE (∀k, L k = L DML ). Remark also that at inference time, the image representation φ 1 (I) consists only of the sample mean of the deep features:</p><formula xml:id="formula_10">φ 1 (I) = 1 |I| xi∈I x i ,<label>(10)</label></formula><p>and the HORDE part of the model can be discarded.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Theoretical analysis</head><p>In this section, we show that optimizing distances between high-order moments is directly related to the Maximum Mean Discrepancy (MMD) <ref type="bibr" target="#b5">[6]</ref> and the Wasserstein distance. We consider the Reproducing Kernel Hilbert Space (RKHS) H of distributions f : Ω → R + defined on the compact Ω ⊂ R c , endowed with the Gaussian kernel k(x, y) = e −γ x−y <ref type="bibr" target="#b1">2</ref> . An image is then represented as a distribution I ∈ H from which we can sample a set of deep features {x i ∈ Ω} i . We denote E x∼I [x] ∈ R c the expectation of x sampled from I. The high-order moments are denoted using their vectorized forms, that is</p><formula xml:id="formula_11">E x∼I [x ⊗k ] ∈ R c k where x ⊗2 = x ⊗ x, x ⊗3 = x ⊗ x ⊗ x, etc. By extension, we use E x∼I [x ⊗1</formula><p>] for the mean. We assume that all moments exist for every distributions in H and we note, ∀I ∈ H:</p><formula xml:id="formula_12">max k E x∼I [x ⊗k ] 2 = K &lt; ∞<label>(11)</label></formula><p>Following <ref type="bibr" target="#b5">[6]</ref>, the MMD between two distributions I and J is expressed as:</p><formula xml:id="formula_13">MMD(I, J ) = sup T E x∼I [T (x)] − E y∼J [T (y)] (12)</formula><p>The MMD searches for a transform T that maximizes the difference between the expectation of two distributions. Intuitively, a low MMD implies that both distributions are concentrated in the same regions of the feature space.</p><p>In the following theorem, we show that the distance over high-order moments is an upper-bound of the squared MMD (the proof mainly follows <ref type="bibr" target="#b5">[6]</ref>): Theorem 1. There exists A ∈ R + * such that, for every distributions I, J ∈ H, the MMD is bounded from above by the p first moments of I and J by:</p><formula xml:id="formula_14">MMD 2 (I, J ) ≤ A p k=1 E x∼I [x ⊗k ] − E y∼J [y ⊗k ] 2 + 1 + o( γ p K p! )<label>(13)</label></formula><p>Proof. As the MMD is a distance on the RKHS H <ref type="bibr" target="#b5">[6]</ref>, the square of the MMD can be re-written such as:</p><formula xml:id="formula_15">MMD 2 (I, J ) = E x∼I [φ(x)] − E y∼J [φ(y)] 2 H<label>(14)</label></formula><p>where φ is defined using the kernel trick k(x, y) = φ(x) ; φ(y) . Then, we can approximate the Gaussian kernel using its Taylor expansion:</p><formula xml:id="formula_16">k(x, y) = exp(−γ x 2 − γ y 2 ) exp(2γ x ; y ) = exp(−γ x 2 − γ y 2 ) +∞ k=0 (2γ) k k! x; y k ≤ 1 + +∞ k=1 a k x ⊗k ; y ⊗k<label>(15)</label></formula><p>where a k = (2γ) k k! &gt; 0. Thus, we can define φ as the direct sum of all weighted and vectorized moments:</p><formula xml:id="formula_17">φ(x) = +∞ k=1 √ a k x ⊗k<label>(16)</label></formula><p>As all moments exist, we can swap the expectation and the direct sum. Moreover, since the sequence a k = (2γ) k k! − → 0 when k − → +∞ and the moments are bounded by K, the higher-order moment contributions become negligible compared to the p first moments. Thus, we have:</p><formula xml:id="formula_18">MMD 2 (I, J ) ≤ 1 + +∞ k=1 a k E x∼I [x ⊗k ] − E y∼J [y ⊗k ] 2 ≤ A p k=1 E x∼I [x ⊗k ] − E x∼J [x ⊗k ] 2 + 1 + o( γ p K p! )<label>(17)</label></formula><p>where A = max k a k .</p><p>This result implies that regularizing high-order moments to be similar enforces similar images to have deep features sampled from similar distributions. Thus, deep features from similar images have a higher probability of being concentrated in the same regions of the feature space.</p><p>Next, we show a converse relation between high-order moments and the Wasserstein distance: Theorem 2. There exists a ∈ R + * such that, for every distributions I, J ∈ H, the squared Wasserstein distance is bounded from below by the p first moments of I and J by:</p><formula xml:id="formula_19">W 2 1 (I, J ) ≥ a p k=1 E x∼I [x ⊗k ] − E y∼J [y ⊗k ] 2 − o( γ p p! )<label>(18)</label></formula><p>Proof. Similarly to the Theorem 1, we can lower-bound the Gaussian kernel using its Taylor expansion:</p><formula xml:id="formula_20">k(x, y) ≥ α +∞ k=1 a k x ⊗k ; y ⊗k</formula><p>where α = exp(−2γK) and a k = (2γ) k k! &gt; 0. Then, by using the definition of φ from Equation <ref type="bibr" target="#b15">16</ref>, a lower-bound for the MMD is:</p><formula xml:id="formula_21">MMD 2 (I, J ) ≥ α a p k=1 E x∼I [x ⊗k ] − E y∼J [y ⊗k ] 2 − o( γ p K p! )<label>(19)</label></formula><p>where a = min k a k . Finally, the MMD is a lower-bound of the Wasserstein distance <ref type="bibr" target="#b23">[24]</ref>:</p><formula xml:id="formula_22">√ KW 1 (I, J ) ≥ MMD(I, J )<label>(20)</label></formula><p>By combining Equation <ref type="bibr" target="#b18">19</ref> and Equation 20, we get the expected lower-bound:</p><formula xml:id="formula_23">W 2 1 (I, J ) ≥ a p k=1 E x∼I [x ⊗k ] − E y∼J [y ⊗k ] 2 − o( γ p p! )<label>(21)</label></formula><p>where a = α a K .   Hence, regularizing high-order moments to be dissimilar enforces dissimilar images to have deep features sampled from different distributions. As such, deep features are more distinctive as they are sampled from different regions of the feature space for dissimilar images. This is illustrated in <ref type="figure" target="#fig_0">Figure 1c</ref> (p = 5) compared to <ref type="figure" target="#fig_0">Figure 1a</ref> (p = 1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Comparison to the state-of-the-art</head><p>We present the benefits of our method by comparing our results with the state-of-the-art on four datasets, namely CUB-200-2011 (CUB) <ref type="bibr" target="#b26">[27]</ref>, Cars-196 (CARS) <ref type="bibr" target="#b11">[12]</ref>, Stanford Online Products (SOP) <ref type="bibr" target="#b17">[18]</ref> and In-Shop Clothes Retrieval (INSHOP) <ref type="bibr" target="#b14">[15]</ref>. We report the Recall@K (R@K) on the standard DML splits associated with these datasets. Following standard practices, we use GoogleNet <ref type="bibr" target="#b24">[25]</ref> as a backbone network and we add a fully connected layer at the end for the embedding. For CUB and CARS, we train HORDE using 5 high-order moments with 5 classes and 8 images per instance per batch. For SOP and INSHOP, we use 4 high-order moments with a batch size of 2 images and 40 different classes as there are classes with only 2 images in these datasets. We use 256 × 256 crops and the following data augmentation at training time: multi-resolution where the resolution is uniformly sampled in [80%, 180%] of the crop size, random crop and horizontal flip. At inference time, we only use the images resized to 256 × 256. For HORDE, we use 8192 dimensions for all high-order moments and we fix all embedding dimensions to 512. Finally, we take advantage of the high-order moments at testing time by concatenating them together. To be fair with other methods, we reduce their dimensionality to 512 using a PCA.  <ref type="table" target="#tab_2">2  3  4  5  6  n  1  1  2  1  2  3  1  2  3  4  1  2  3  4  5  1  2  3  4</ref>   <ref type="table">Table 3</ref>: Impact of the high order moments as regularizers. We report the Recall@K on CUB. k is the number of chosen orders at training time, and n is the order used at testing time to evaluate the performances. k = n = 1 is the baseline. <ref type="table" target="#tab_2">k  1  2  3  4  5  6  n  1  1  2  1  2  3  1  2  3  4  1  2  3  4  5  1  2  3  4</ref>   <ref type="table">Table 4</ref>: Impact of the high order moments when all parameters are trained. We report the Recall@K on CUB. k is the number of chosen orders at training time, and n is the order used at testing time. k = n = 1 is the baseline.</p><p>These results are annotated with a † .</p><p>First, we show in the upper part of <ref type="table" target="#tab_2">Table 1</ref> that HORDE significantly improves three popular baselines (contrastive loss, triplet loss and binomial deviance). These improvements allow us to claim state of the art results for single model methods on CUB with 58.3% R@1 (compared to 57.1% R@1 for HTL <ref type="bibr" target="#b4">[5]</ref>) and second best for CARS.</p><p>We also present ensemble method results in the second part of <ref type="table" target="#tab_2">Table 1</ref>. We show that HORDE is also a benefit to ensemble methods by improving ABE <ref type="bibr" target="#b10">[11]</ref> by 2.7% R@1 on CUB and 7.2% R@1 on CARS. To the best of our knowledge, this allows us to outperform the state of the art methods on both datasets with 62.7% R@1 on CUB and 86.4% R@1 on CARS, despite our implementation of ABE underperforming compared to the results reported in <ref type="bibr" target="#b10">[11]</ref>.</p><p>Note that both single models and ensemble ones are further improved by using the high-order moments at testing: +1.1% on CUB and +1.7% on CARS for the single models + HORDE and +1.2% on CUB and +1.6% on CARS for ABE + HORDE.</p><p>Furthermore, we show that HORDE generalizes well to large scale datasets by reporting results on SOP and IN-SHOP in <ref type="table" target="#tab_3">Table 2</ref>. HORDE improves our baseline binomial deviance by 5.2% R@1 on SOP and 3.1% R@1 on IN-SHOP. This improvement allows us to claim state of the art results for single model methods on INSHOP with 84.2% R@1 (compared to 80.9% R@1 for HTL) and second best on SOP with 72.6% R@1 (compared to 74.8% R@1 for HTL). Remark also that HORDE outperforms HTL on 3 out of 4 datasets.</p><p>We also report some results with the BN-Inception <ref type="bibr" target="#b7">[8]</ref>. Our model trained with HORDE and contrastive loss leads to similar results compared to the recent MS loss with mining <ref type="bibr" target="#b29">[30]</ref> on smaller datasets while on larger datasets we outperform it by 1.9% on SOP and by 0.7% on INSHOP. By using the high-order moments are testing, performances are further increased and outperforms MS loss with mining by 1.1% on CUB and by 2.1% on CARS.</p><p>Finally, we show some example queries and their nearest neighbors in <ref type="figure" target="#fig_5">Figure 3</ref> on the test split of CUB.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Ablation study</head><p>In this section, we provide an ablation study on the different contributions of this paper. We perform 3 experiments on the CUB dataset <ref type="bibr" target="#b26">[27]</ref>. The first experiment shows the impact of high-order regularization on a standard architecture while the high-order moments are consistently approximated using the Random Maclaurin approximation. The second experiment illustrates the benefit of learning the high-order moments projection matrices. The last experiment confirms the statistical consistency of our cascaded architecture when the parameters are learned.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Regularization effect</head><p>In this section, we assess the regularization impact of HORDE. To that aim, we use the baseline detailed in section 4 and we train the architecture with a number of highorder moments varying from 2 to 6. In this first experiment, the computation of the high-order moments does not rely on the cascade computation approach of Equation 6. Instead, the matrices to approximate the high-order moments are untrainable and sampled using the Random Maclaurin method of Equation <ref type="bibr" target="#b3">4</ref>. Remark also that the embedding layers on all high-order moments are not added. We use the binomial deviance loss with the standard parameters <ref type="bibr" target="#b25">[26]</ref>. The results are shown in <ref type="table">Table 3</ref>.</p><p>First, we can see that HORDE consistently improves the baseline from 1% to 2% in R@1. These results corroborate the insights of our theoretical analysis in section 3 and also provide a quantitative evaluation of the behavior observed in <ref type="figure" target="#fig_0">Figure 1</ref> on the retrieval ranking. When consider- <ref type="table" target="#tab_2">k   1  2  3  4  5  6  n  1  1  2  1  2  3  1  2  3  4  1  2  3  4  5  1  2  3  4</ref>   <ref type="table">Table 5</ref>: Impact of the cascaded architecture when all parameters are trained using Algorithm 1. We report the Recall@K on CUB. k is the number of chosen orders at training time, and n is the order used at testing time. k = n = 1 is the baseline. ing the high-order moments as representations, we observe improved results with respect to the baseline for orders 2 and 3. Note however that the reported high-order results are not comparable to the first order as the similarity measure is computed on the 8192 dimensional representations. While adding orders higher than 2 does not seem interesting in terms of performances, we found that the training process is more stable with 5 or 6 orders than only 2. This is observed in practice by measuring the Recall@K with K ≥ 8 which tend to vary less between training steps. Moreover on the CUB dataset, while the baseline requires around 6k steps to reach the best results, we usually need 1k steps less to reach higher accuracy with HORDE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Statistical consistency</head><p>To evaluate the impact of estimating only informative high-order moments, we first train the projection matrices and the embeddings but without the cascade architecture and report the results in <ref type="table">Table 4</ref>.</p><p>In this second experiment, we empirically show that such scheme also increases the baseline by at least 1% in R@1. Notably, by focusing on the most informative high-order moment components, HORDE further improves the performances of the untrainable HORDE from 57.8% to 58.4%. However, the retrieval performances of the high-order representations are heavily degraded compared to <ref type="table">Table 3</ref>. We interpret these results as an inconsistent estimations of the high-order moments due to overfitting the model. For example, the 6% loss in R@1 for the third-order moment between the first and the second experiments suggests a reduced interest for even higher-order moments.</p><p>For the third experiment, we report the results of our cascaded architecture in <ref type="table">Table 5</ref>. Interestingly, the high-order moments computed from the cascaded architecture perform almost identically to those computed from the untrained method <ref type="table">Table 3</ref> but with a smaller dimension. Moreover, we keep the performance improvement of the second experiments of <ref type="table">Table 4</ref>. This confirms that the proposed cascaded architecture does not overfit its estimations of the high-order moments while still improving the baseline. Finally, this cascaded architecture only produces a small computational overhead during the training compared to the architecture without the cascade.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In this paper, we have presented HORDE, a new deep metric learning regularization scheme which improves the distinctiveness of the deep features. This regularizer, based on the optimization of the distance between the distributions of the deep features, provides consistent improvements to a wide variety of popular deep metric learning methods. We give theoretical insights that show HORDE upper-bounds the Maximum Mean Discrepancy and lowerbounds the Wasserstein distance. The computation of highorder moments is tackled using a trainable Random Maclaurin factorization scheme which is exploited to produce a cascaded architecture with small computation overhead. Finally, HORDE achieves very competitive performances on four well known datasets.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>(a) Representations using all deep features (b) Representations using 1/6-th of deep features (c) Representations using 1/6-th of deep features trained with HORDE 2D visualizations of representations (stars) and deep features (points) using t-SNE computed from a DML architecture on MNIST dataset with one color per class. Representations and features come from the training set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Global overview of our HORDE architecture. The deep convolutional neural network extracts h × w × c deep features. The standard architecture (top blue block) relies on a global average pooling and an embedding before computing the L DML loss. The bottom red block is our HORDE regularizer, composed by the approximation of all high-order moments φ k , global average pooling and embeddings before computing the sum of each L k loss.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>where {x i ∈ I} and {x j ∈ J } are the sets of deep features extracted from images I and J . Hence, the DML model is trained on a combination of a standard DML loss and the HORDE regularizer on pairs of images I and J : L(I, J ) = L DML (I, J ) + L HORDE (I, J )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>k 1</head><label>1</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>9 57.0 53.4 57.6 54.7 50.6 57.9 55.4 52.3 47.6 58.1 55.9 53.1 48.4 43.7 58.4 55.7 52.9 47.8 43.9 40.5 R@2 67.6 68.3 65.4 69.9 67.0 63.0 69.5 67.1 65.0 60.2 70.3 67.7 65.0 60.8 56.0 69.9 67.6 64.9 59.9 56.0 53.0 R@4 78.3 78.3 75.8 79.1 76.8 73.6 79.6 77.5 75.2 71.0 79.9 78.2 75.5 72.8 67.2 79.8 78.0 75.6 70.2 67.2 64.7 R@8 86.4 86.2 84.2 87.0 84.7 82.4 87.1 85.8 83.6 80.2 87.1 85.2 83.9 81.7 78.0 87.3 85.6 83.8 79.6 77.5 75.2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 3 :</head><label>3</label><figDesc>Qualitative results on CUB for HORDE. Correct results are highlighted green (incorrect in red).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>)</head><label></label><figDesc>Algorithm 1 High-order moments computationRequire: W 1 , . . . , W K sampled from {−1; +1} Ensure: K first moments approximations1:  procedure APPROXMOMENTS(x)</figDesc><table /><note>2:</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Comparison with the state-of-the-art on Cub-200-2011 and Cars-196 datasets. Results in percents. † means that the test scores are computed using all the high-order moments (concatenation + PCA to the embedding size).</figDesc><table><row><cell></cell><cell></cell><cell cols="4">Stanford Online Products</cell><cell></cell><cell cols="4">In-Shop Clothes Retrieval</cell><cell></cell></row><row><cell>Backbone</cell><cell>R@</cell><cell>1</cell><cell>10</cell><cell>100</cell><cell>1000</cell><cell>1</cell><cell>10</cell><cell>20</cell><cell>30</cell><cell>40</cell><cell>50</cell></row><row><cell></cell><cell>Angular loss [29]</cell><cell>70.9</cell><cell>85.0</cell><cell>93.5</cell><cell>98.0</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell>HDML [36]</cell><cell>68.7</cell><cell>83.2</cell><cell>92.4</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell>DAMLRMM [32]</cell><cell>69.7</cell><cell>85.2</cell><cell>93.2</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>GoogleNet</cell><cell>DVML [13]</cell><cell>70.2</cell><cell>85.2</cell><cell>93.8</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell>HTL [5]</cell><cell>74.8</cell><cell>88.3</cell><cell>94.8</cell><cell>98.4</cell><cell>80.9</cell><cell>94.3</cell><cell>95.8</cell><cell>97.2</cell><cell>97.4</cell><cell>97.8</cell></row><row><cell></cell><cell>Binomial Deviance (Ours)</cell><cell>67.4</cell><cell>81.7</cell><cell>90.2</cell><cell>95.4</cell><cell>81.3</cell><cell>94.2</cell><cell>95.9</cell><cell>96.7</cell><cell>97.2</cell><cell>97.6</cell></row><row><cell></cell><cell>Binomial Deviance + HORDE</cell><cell>72.6</cell><cell>85.9</cell><cell>93.7</cell><cell>97.9</cell><cell>84.4</cell><cell>95.4</cell><cell>96.8</cell><cell>97.4</cell><cell>97.8</cell><cell>98.1</cell></row><row><cell>BN-Inception</cell><cell>Multi-similarity loss [30] contrastive loss + HORDE</cell><cell>78.2 80.1</cell><cell>90.5 91.3</cell><cell>96.0 96.2</cell><cell>98.7 98.7</cell><cell>89.7 90.4</cell><cell>97.9 97.8</cell><cell>98.5 98.4</cell><cell>98.8 98.7</cell><cell>99.1 98.9</cell><cell>99.2 99.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table /><note>Comparison with the state-of-the-art on Stanford Online Products and In-Shop Clothes Retrieval. Results in percents.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>57.8 58.6 56.8 58.0 56.9 57.8 58.8 57.6 56.1 57.4 57.7 56.8 56.3 53.3 57.4 57.9 57.1 55.6 54.4 50.7 R@2 67.6 69.5 70.4 68.1 69.4 68.7 69.2 70.6 70.0 68.5 68.8 69.9 69.3 68.1 65.4 69.9 70.6 70.5 68.9 66.2 63.0 R@4 78.3 79.0 79.8 78.3 78.8 78.1 78.6 79.9 79.2 78.1 78.7 78.8 79.2 78.0 75.9 79.4 80.0 79.9 78.7 76.5 74.0 R@8 86.4 86.7 87.2 86.2 86.7 86.6 86.5 87.2 87.0 85.5 87.0 87.1 87.1 86.5 84.2 86.9 87.4 87.4 86.7 85.4 82.5</figDesc><table><row><cell>5</cell><cell>6</cell></row><row><cell>R@1 55.9</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>5 6 R@1 55.9 57.0 53.4 57.9 56.1 54.2 57.6 55.4 54.3 53.0 58.3 56.3 56.0 54.7 52.4 57.9 56.6 55.8 55.0 53.9 51.6 R@2 67.6 68.3 65.4 69.4 67.9 66.2 69.3 67.2 66.0 65.2 70.4 68.7 68.1 66.9 64.7 69.5 68.8 68.3 67.7 65.2 64.0 R@4 78.3 78.3 75.8 79.2 77.8 76.4 79.5 77.2 77.0 75.8 80.2 78.5 78.3 76.9 75.6 79.6 76.6 77.9 77.9 75.3 74.4 R@8 86.4 86.2 84.2 86.6 85.3 84.4 87.1 85.6 84.4 84.1 87.7 86.3 86.0 85.4 84.1 87.0 86.4 85.6 84.8 84.0 83.7</figDesc><table /><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>Authors would like to acknowledge the COMUE Paris Seine University, the Cergy-Pontoise University and M2M Factory for their financial and technical support.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Crossmodal retrieval in the cooking context: Learning semantic text-image embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Micael</forename><surname>Carvalho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rémi</forename><surname>Cadène</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Picard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laure</forename><surname>Soulier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Thome</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Cord</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 41st International ACM SIGIR Conference on Research &amp; Development in Information Retrieval</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Beyond triplet loss: A deep quadruplet network for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weihua</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaotang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianguo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiqi</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning a similarity metric discriminatively, with application to face verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raia</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Deep adversarial metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yueqi</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenzhao</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xudong</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwen</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Deep metric learning with hierarchical triplet loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weifeng</forename><surname>Ge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2018-09" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A kernel method for the two-sample-problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Gretton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Karsten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Malte</forename><surname>Borgwardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Rasch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><forename type="middle">J</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Smart mining for deep metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Harwood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B G</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gustavo</forename><surname>Carneiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Drummond</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd International Conference on Machine Learning</title>
		<meeting>the 32nd International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2015-07" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Negative evidences and co-occurrences in image retrieval: the benefit of PCA and whitening</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hervé</forename><surname>Jégou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondrej</forename><surname>Chum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Random feature maps for dot product kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Purushottam</forename><surname>Kar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harish</forename><surname>Karnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifteenth International Conference on Artificial Intelligence and Statistics</title>
		<meeting>the Fifteenth International Conference on Artificial Intelligence and Statistics</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Attention-based ensemble for deep metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wonsik</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bhavya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kunal</forename><surname>Chawla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jungmin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keunjoo</forename><surname>Kwon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">3d object representations for fine-grained categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Stark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">4th International IEEE Workshop on 3D Representation and Recognition</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="3" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Deep variational metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xudong</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yueqi</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiyuan</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwen</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Deep relative distance learning: Tell the difference between similar vehicles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongye</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonghong</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaowei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiejun</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Deepfashion: Powering robust clothes recognition and retrieval with rich annotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shi</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">No fuss distance metric learning using proxies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yair</forename><surname>Movshovitz-Attias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Toshev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">K</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurabh</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Deep metric learning via facility location</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyun Oh</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanie</forename><surname>Jegelka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vivek</forename><surname>Rathod</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Deep metric learning via lifted structured feature embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyun Oh</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanie</forename><surname>Jegelka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Bier -boosting independent embeddings robustly</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Opitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Waltner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Horst</forename><surname>Possegger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Horst</forename><surname>Bischof</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Deep metric learning with BIER: boosting independent embeddings robustly. IEEE transactions on pattern analysis and machine intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Opitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Waltner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Horst</forename><surname>Possegger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Horst</forename><surname>Bischof</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Metric learning with adaptive density discrimination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Rippel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manohar</forename><surname>Paluri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Dollar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lubomir</forename><surname>Bourdev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Facenet: A unified embedding for face recognition and clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Kalenichenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Philbin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Improved deep metric learning with multi-class n-pair loss objective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">29</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Lanckriet. Hilbert space embeddings and metrics on probability measures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bharath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Sriperumbudur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenji</forename><surname>Gretton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Fukumizu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gert</forename><forename type="middle">R G</forename><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Going deeper with convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2015-06" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Learning deep embeddings with histogram loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniya</forename><surname>Ustinova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">29</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">The Caltech-UCSD Birds-200-2011 Dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Catherine</forename><surname>Wah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Welinder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<idno>CNS-TR- 2011-001</idno>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page">7</biblScope>
		</imprint>
		<respStmt>
			<orgName>California Institute of Technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Cosface: Large margin cosine loss for deep face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yitong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dihong</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingchao</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Deep metric learning with angular loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shilei</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanqing</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2017-10" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Multi-similarity loss with general pair weighting for deep metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xintong</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weilin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dengke</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">R</forename><surname>Scott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019-06" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Bidirectional retrieval made simple</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jnatas</forename><surname>Wehrmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><forename type="middle">C</forename><surname>Barros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Deep asymmetric metric learning via rich relationship mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyi</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanhua</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019-06" />
			<biblScope unit="page" from="4076" to="4085" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Deep randomized ensembles for metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Xuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Souvenir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Pless</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Correcting the triplet selection bias for triplet loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baosheng</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tongliang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingming</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
	<note>Changxing Ding, and Dacheng Tao</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Hardaware deeply cascaded embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhui</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuiyuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2017-10" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Hardness-aware deep metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenzhao</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaodong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwen</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019-06" />
			<biblScope unit="page" from="72" to="81" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Learning deep features for discriminative localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bolei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agata</forename><surname>Lapedriza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aude</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Efficient online local metric adaptation via negative samples for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiahuan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
