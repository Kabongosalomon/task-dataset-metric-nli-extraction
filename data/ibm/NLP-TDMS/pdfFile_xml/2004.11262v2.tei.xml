<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Supervised Domain Adaptation: A Graph Embedding Perspective and a Rectified Experimental Protocol</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukas</forename><forename type="middle">Hedegaard</forename><surname>Morsing</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Engineering</orgName>
								<orgName type="institution">Aarhus University</orgName>
								<address>
									<country key="DK">Denmark</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omar</forename><forename type="middle">Ali</forename><surname>Sheikh-Omar</surname></persName>
							<email>sheikhomar@mailbox.org</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Engineering</orgName>
								<orgName type="institution">Aarhus University</orgName>
								<address>
									<country key="DK">Denmark</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandros</forename><surname>Iosifidis</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Engineering</orgName>
								<orgName type="institution">Aarhus University</orgName>
								<address>
									<country key="DK">Denmark</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Supervised Domain Adaptation: A Graph Embedding Perspective and a Rectified Experimental Protocol</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>1</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T17:52+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-Supervised Domain Adaptation</term>
					<term>Graph Embed- ding</term>
					<term>Transfer Learning</term>
					<term>Few-shot</term>
					<term>Domain Shift</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The performance of machine learning models tends to suffer when the distributions of the training and test data differ. Domain Adaptation is the process of closing the distribution gap between datasets. In this paper, we show that Domain Adaptation methods using pair-wise relationships between source and target domain data can be formulated as a Graph Embedding in which the domain labels are incorporated into the structure of the intrinsic and penalty graphs. We analyse the loss functions of existing state-of-the-art Supervised Domain Adaptation methods and demonstrate that they perform Graph Embedding. Moreover, we highlight some generalisation and reproducibility issues related to the experimental setup commonly used to demonstrate the few-shot learning capabilities of these methods. We propose a rectified evaluation setup for more accurately assessing and comparing Supervised Domain Adaptation methods, and report experiments on the standard benchmark datasets Office31 and MNIST-USPS.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Deep neural networks have been applied successfully to a variety of applications. However, their performance tends to suffer when a trained model is applied to another domain. This is of no surprise, as statistical learning theory makes the simplifying assumption that both training and test data are generated by the same underlying process; the use of realworld datasets makes the i.i.d. assumption impractical as it requires collecting data and training a model for each domain. The collection and labelling of datasets that are sufficiently large to train a well-performing model from random initialisation are daunting and costly. Therefore, we often have little data for the task at hand. Training a deep network with scarce training data, in turn, can lead to overfitting <ref type="bibr" target="#b0">[1]</ref>.</p><p>The process aiming to alleviate this challenge is commonly referred to as Transfer Learning. The main idea in Transfer Learning is to leverage knowledge extracted from one or more source domains to improve the performance on problems defined in a related target domain <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b3">4]</ref>. In the image classification task, we may want to utilise the large number of labelled training samples in the ImageNet database to improve the performance on another image classification task on a very different domain, e.g. that of fine-grained classification of aquatic macroinvertebrates <ref type="bibr" target="#b4">[5]</ref>. This is often done by reusing the parameters of a deep learning model trained on a large  <ref type="figure">Fig. 1</ref>: The two-stream network architecture used in DAGE, CCSA <ref type="bibr" target="#b5">[6]</ref>, d-SNE <ref type="bibr" target="#b6">[7]</ref> and NEM <ref type="bibr" target="#b7">[8]</ref>. It allows source domain samples X S and target domain samples X T to be introduced to a deep convolutional neural network simultaneously. The network is split into a feature extractor ϕ n (·) and a classifier h(·). A domain adaptation loss L domain is defined on the output of the feature extractors to encourage the generation of domain-invariant features.</p><p>source domain dataset under the assumption that the two datasets are similar. To clearly define Transfer Learning, the literature distinguishes between a domain and a task. A domain D consists of an input space X and a marginal probability distribution p(X), where X = {x 1 , . . . , x N } ∈ X are N samples from that space. Given a domain, a task T is composed of an output space Y and a posterior probability p(y i | x i ) for a label y i ∈ Y given some input x i . Suppose we have a source domain D S with its associated task T S and a target domain D T with a corresponding task T T . Transfer Learning is defined as the process of improving the target predictive function f T (x i ) ≈ p T (y i | x i ) using the knowledge in D S and T S when there is a difference between the domains (D S = D T ) or the tasks (T S = T T ) <ref type="bibr" target="#b1">[2]</ref>.</p><p>Two domains or two tasks are said to be different if their constituent parts are not the same. In some cases, the feature space and the label space of the source and target domains are equal. Then, the performance degradation, when reusing a model in another domain, is caused by a domain shift. The process of aligning the distributions between the domains is called Domain Adaptation. A special case of domain shift, which has been studied extensively in the literature, is when the difference between domains is caused by a covariate shift, i.e. a difference in data distributions between the domains <ref type="bibr" target="#b8">[9]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>arXiv:2004.11262v2 [cs.LG] 8 Sep 2020</head><p>An efficient approach to Domain Adaptation in this case, is to use a feature-extractor ϕ to transform the inputs of the respective domain to a common, domain-invariant space using deep neural networks in a Siamese network architecture as seen in <ref type="figure">Fig. 1</ref>. A common classifier h can then be trained on the latent features to make predictions on target domain data.</p><p>To align the domains using this approach, it is not strictly necessary to have labels available in the target dataset, and many Unsupervised Domain Adaptation methods can achieve good performance given enough (unlabelled) target data. In cases where the data is difficult to acquire, such as for medical images of a rare disease, Supervised Domain Adaptation methods are superior, and can utilise the few available target samples to efficiently align the domains. However, as we will show, having very few target data samples complicates the experiment design if best practices for train, validation, and test split independence is to be followed. This few-shot supervised case is the focus of this work.</p><p>A typical optimisation goal in Supervised Domain Adaptation methods is to explicitly map samples belonging to the same class close together in a common latent subspace, while separating samples with different labels irrespective of the originating domain. In <ref type="bibr" target="#b9">[10]</ref> it was shown that Graph Embedding <ref type="bibr" target="#b10">[11]</ref>, which aims at increasing the within-class compactness and between-class separability by appropriately connecting samples in intrinsic and penalty graph structures, provides a natural framework for Supervised Domain Adaptation, and produces results on par with the state-of-the-art. In this extension of <ref type="bibr" target="#b9">[10]</ref>, the following contributions are presented:</p><p>1) We show that many existing Supervised Domain Adaptation methods aiming at producing a domain-invariant space by using pairwise similarities can be expressed as Graph Embedding methods. Specifically, we analyse the loss functions of three recent state-of-the-art Supervised Domain Adaptation methods: Classification and Contrastive Semantic Alignment (CCSA) <ref type="bibr" target="#b5">[6]</ref>, Domain Adaptation using Stochastic Neighborhood Embedding (d-SNE) <ref type="bibr" target="#b6">[7]</ref>, and Domain Adaptation with Neural Embedding Matching (NEM) <ref type="bibr" target="#b7">[8]</ref>. 2) We argue that Graph Embedding and the specification of edges in the intrinsic and penalty graphs provides an expressive framework for encoding and exploiting assumptions about the datasets at hand. 3) We identify flaws in the traditionally employed experiment protocol for Few-shot Supervised Domain Adaptation that violate machine learning best practices with regards to independence of train, validation and test splits. 4) We propose a rectified experimental protocol, which clearly defines a validation set and ensures that the test set remains independent throughout experiments. 5) We publish ready-to-use Python packages for the two most commonly used Few-shot Supervised Domain Adaptation datasets, Office31 1 and MNIST→USPS 2 ,  <ref type="bibr" target="#b11">[12]</ref> and MNIST → USPS <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b13">14]</ref> datasets using the rectified experimental protocol. The source code of our experiments has been made available online <ref type="bibr" target="#b3">4</ref> . The remainder of the paper is structured as follows: In Section II, we provide a brief overview of Domain Adaptation methods that aim to find a domain-invariant latent space. We introduce Graph Embedding, how to optimise the graph preserving criterion, and multi-view extensions in Section III. Section IV delineates the Domain Adaptation via Graph Embedding (DAGE) framework and the DAGE-LDA method as proposed in <ref type="bibr" target="#b9">[10]</ref>. In Section V, we analyse three recent stateof-the-art methods and show that they can also be viewed as Graph Embedding methods. In Section VI, we explain the issues with the existing experimental setup used in prior Domain Adaptation work and propose a rectified experimental protocol. Finally, in Section VII we present updated benchmark results on the canonical datasets Office-31 and MNIST-USPS using the rectified protocol, and Section VIII draws the conclusions of the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORKS</head><p>In Domain Adaptation (DA), it is usually assumed that all source data is labelled. Depending on the label availability for the target data, DA methods are categorised as Supervised (labels available for all target data), Semi-supervised (labels available for some but not all target data), and Unsupervised (labels are not available for target data). It is important to distinguish between these cases, as experiment protocols and the volume of data used for training varies widely between the three cases, even using the same datasets.</p><p>Supervised Domain Adaptation methods have their focus on few-shot learning scenarios, where the target data is scarce with very few samples per class. Classification and Contrastive Semantic Alignment (CCSA) <ref type="bibr" target="#b5">[6]</ref> is one such method, which embeds the contrastive loss introduced by Hadsell et al. <ref type="bibr" target="#b14">[15]</ref> as a loss term in a two-stream deep neural network. Effectively, it places a penalty on the distance between samples belonging to the same class across source and target domains, as well as the proximity of samples belonging to different classes, that fall within a distance margin. Domain Adaptation using Stochastic Neighborhood Embedding (d-SNE) <ref type="bibr" target="#b6">[7]</ref> uses the same deep two-stream architecture, and finds its inspiration in the dimensionality reduction method of Stochastic Neighbor Embedding (SNE). From it, the work in <ref type="bibr" target="#b6">[7]</ref> derives as loss a modified-Hausdorffian distance, which minimises the Euclidean distance in the embedding space between the furthest same-class data pairs, and maximises the distance of the closest different-label pairs. Domain Adaptation With Neural Embedding Matching (NEM) <ref type="bibr" target="#b7">[8]</ref> extends the contrastive loss of CCSA with an additional loss term to match the local neighbourhood relations of the target data prior to and after feature embedding. It does so by constructing a graph embedding loss connecting the nearest neighbours of the target data in their original feature space, and adding the weighted sum of distances between corresponding embedded features to the constrastive loss. In <ref type="bibr" target="#b15">[16]</ref>, an add-on domain classification layers is tasked with classifying the domain of training samples to produce a domain confusion loss that is used in feature extraction layers. Moreover, they take inspiration in distillation works, and use a soft label loss that matches a target sample to the average output distribution for the corresponding label in the source domain. Few-shot Adversarial Domain Adaptation (FADA) <ref type="bibr" target="#b16">[17]</ref> uses a similar approach by training a domainclass discriminator using a four-way classification procedure for combinations of same-or different domain or class. In <ref type="bibr" target="#b17">[18]</ref>, an alignment loss for Second-or Higher-Order Scatter Tensors (So-HoT) is used to bring each within-class scatter closer in terms of their means and covariances. They do this by taking the squared norm of the difference between scatter tensors for each class.</p><p>Semi-supervised Domain Adaptation methods also have very few labelled target samples, but use unlabelled data in addition. Examples of this are d-SNE and NEM, both of which provide extensions to include unlabelled data. In d-SNE <ref type="bibr" target="#b6">[7]</ref>, the semi-supervised extension is achieved by a technique similar to the Mean-Teacher network technique <ref type="bibr" target="#b18">[19]</ref>, which entails training a parallel network on the unsupervised data and using an L2 consistency loss between the embeddings for the two networks. In NEM <ref type="bibr" target="#b7">[8]</ref>, a progressive learning strategy is used, which gradually assigns pseudo labels to the most confident predictions on unlabelled data in each epoch. The pseudo-labelled data is then used for training in the next epoch. In graph-embedding based methods, such as DAGE-LDA <ref type="bibr" target="#b9">[10]</ref>, it is straight forward to incorporate unlabelled data into the loss by means of Label Propagation <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b20">21]</ref>. Moreover, some unsupervised methods (e.g. <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b22">23]</ref>) include semi-supervised extensions as well.</p><p>Unsupervised Domain Adaptation methods do not assume that any labels are available in the target domain, and use only the label information from the source domain. In Transfer Component Analysis (TCA) <ref type="bibr" target="#b23">[24]</ref>, domain are aligned by projecting data onto a set of learned transfer components. To learn the components, they minimise the Maximum Mean Discrepancy (MMD) in a Reproducing Kernel Hilbert Space (RKHS). In practice, the kernel trick is used to define a kernel matrix, and a projection matrix is learned using the corresponding empirical kernel map. Scatter Component Analysis (SCA) <ref type="bibr" target="#b24">[25]</ref> also operates in a RKHS, but uses the notion of scatter (which recovers MMD) to align the domains. A projection matrix is then found by maximising the totaland between-class scatters, while minimising the domain-, within-class scatters. Here, between-and within-class scatters are defined only using source domain data. A recent addition to this space is the Graph Embedding Framework for Maximum Mean Discrepancy-Based Domain Adaptation Algorithm (GEF) <ref type="bibr" target="#b25">[26]</ref>, which assigns pseudo-labels to target data and solves the generalised eigenvalue problem for a MMD-based graph to compute a linear projection of the source data. The reconstructed source data is then used to train a classifier which in turn updates the psuedo-labels of the target data. In Locality Preserving Joint Transfer for Domain Adaptation (LPJT) <ref type="bibr" target="#b21">[22]</ref>, they use a multi-faceted approach of distribution matching, minimising the marginaland conditional MMD; landmark selection, learning importance weights for each source and target sample; label propagation, assigning pseudo labels to unlabelled samples; and locality preservation by use of Graph Embedding solving the generalised eigenvalue problem. Joint Distribution Invariant Projections (JDIP) <ref type="bibr" target="#b22">[23]</ref> use a least-squares estimation of the L2 distance for the joint distribution of source and target domains to produce mappings to a domain-invariant subspace with either linear or kernelized projections. Another branch of Unsupervised DA techniques use Adversarial methods to confuse the domains: In Domain-Adversarial Neural Networks (DANN) <ref type="bibr" target="#b26">[27]</ref>, a deep neural network is extended with an additional Discriminator head, that is trained to distinguish the source and target domains. This is similar to what was done in <ref type="bibr" target="#b15">[16]</ref> for Supervised Domain Adaptation. Conditional Domain Adversarial Networks (CDAN) <ref type="bibr" target="#b27">[28]</ref> take inspiration in the recent advances of Conditional Generative Adversarial Networks, and use multilinear-and entropy conditioning to improve discriminability and transferability between domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. GRAPH EMBEDDING AND ITS OPTIMIZATION PROBLEM</head><p>Graph Embedding <ref type="bibr" target="#b10">[11]</ref> is a general dimensionality reduction framework based on exploiting graph structures. Suppose we have a data matrix X = [x 1 , · · · , x N ] ∈ R D×N and we want to obtain its one-dimensional counterpart z = [z 1 , · · · , z N ] ∈ R 1×N . To encode the data relationships that we want to preserve in the subspace, we can construct a so-called intrinsic graph G = (X, W) where W ∈ R N ×N is a non-negative adjacency matrix encoding the (weighted) pair-wise relationships between the representations of the graph vertices included in X. When we want to also suppress relationships between some graph vertices in the embedding space, we can create a penalty graph G p = (X, W p ). The optimal embeddings z * are found by optimising the graph preserving criterion <ref type="bibr" target="#b10">[11]</ref>:</p><formula xml:id="formula_0">z * = argmin z Bz=c i =j z i − z j 2 2 W (i,j) = argmin z Bz=c z Lz (1)</formula><p>where c is a constant, L = D−W and B = D p −W p are N × N graph Laplacian matrices of G and G p , respectively, and D = j W (i,j) and D p = j W (i,j) p are the corresponding (diagonal) Degree matrices. When using a linear embedding, z i = v x i , the above criterion takes the following form:</p><formula xml:id="formula_1">z * = argmin v XBX v=c v XLX v.<label>(2)</label></formula><p>which is equivalent to maximizing the trace ratio problem <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b29">30]</ref>:</p><formula xml:id="formula_2">J (v) = v XBX v v XLX v .<label>(3)</label></formula><p>Following Lagrange-based optimisation, the optimal projection v ∈ R D is found by solving the generalized eigenanalysis problem XBX v = λXLX v and is given by the eigenvector corresponding to the maximal eigenvalue.</p><p>When more than one-dimensional embedding spaces are needed, i.e. when the mapping takes the form of R D → R d with 1 &lt; d ≤ D, trace ratio problem in Eq. (3) takes the form:</p><formula xml:id="formula_3">J (V) = Tr V XBX V Tr V XLX V .<label>(4)</label></formula><p>where Tr(·) is the trace operator and V ∈ R D×d is the corresponding projection matrix. The trace ratio problem in Eq. (4) does not have a closed-form solution. Therefore, it is conventionally approximated by solving the ratio trace problem,</p><formula xml:id="formula_4">J (V) = Tr[(V XLX V) −1 (V XBX V)],</formula><p>which is equivalent to the optimization problem XBX v = λXLX v, λ = 0, and the columns of V are given by the eigenvectors of the matrix (XLX ) −1 (XBX ) corresponding to the d maximal eigenvalues. Although the trace ratio problem in Eq. (3) does not have a closed form solution, it was shown in <ref type="bibr" target="#b28">[29]</ref> that it can be converted to an equivalent trace difference problem:</p><formula xml:id="formula_5">J (V, λ) = Tr V (XBX − λXLX )V ,<label>(5)</label></formula><p>where λ is the trace ratio calculated by applying an iterative process. After obtaining the trace ratio value λ * , the optimal projection matrix V * is obtained by substituting λ * to the trace difference problem in Eq. (5) and maximizing its value. Non-linear mappings from x i ∈ R D to z i ∈ R d can be obtained by exploiting the Representer Theorem, i.e. by using an implicit nonlinear mapping φ : R D → F, with F being a reproducing kernel space, leading to</p><formula xml:id="formula_6">x i ∈ R D → φ(x i ) ∈ F.</formula><p>We can then express the mapping in the form of</p><formula xml:id="formula_7">z i = α Φ φ(x i ) where Φ = [φ(x 1 ), . . . , φ(x N )]</formula><p>are the training data representations in F and the projection matrix is given by V = ΦA. In that case, the problems in Eqs. <ref type="formula" target="#formula_3">(4)</ref> and <ref type="formula" target="#formula_5">(5)</ref> are transformed by substituting X with K = Φ Φ, which is the kernel matrix calculated using the so-called kernel function</p><formula xml:id="formula_8">κ(x i , x j ) = K (i,j) .</formula><p>Multi-view extensions using intrinsic and penalty graphs for jointly determining data transformations for data coming from multiple input spaces (views) have also been proposed. As was shown in <ref type="bibr" target="#b30">[31]</ref>, several standard multi-view methods such as Multi-View Fisher Discriminant Analysis <ref type="bibr" target="#b31">[32]</ref>, Partial Least Squares <ref type="bibr" target="#b32">[33]</ref>, (deep) Canonical Correlation Analysis <ref type="bibr" target="#b33">[34]</ref>, and Multi-view Discriminant Analysis <ref type="bibr" target="#b34">[35]</ref> can be expressed as specific instantiations of the problem in Eq. (4), which exploit the view label information to define corresponding intrinsic and penalty graphs. Moreover, the Multi-view Nonparametric Discriminant Analysis <ref type="bibr" target="#b35">[36]</ref> and Deep Multi-view Learning to Rank <ref type="bibr" target="#b36">[37]</ref> methods have been formulated based on the problem in Eq. (4) for retrieval and ranking problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. DOMAIN ADAPTATION VIA GRAPH EMBEDDING</head><p>Given the versatility of graph embedding, we derive the proposed Domain Adaptation via Graph Embedding (DAGE) framework. In this section, we detail DAGE and an instantiation of it inspired by Linear Discriminant Analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. DAGE Framework</head><p>The aim of transformation-based Domain Adaptation methods is to learn a common subspace where the distribution gap between source domain data and target domain data is as small as possible. In the supervised setting, we want a transformation ϕ(·) which places samples belonging to the same class close together without regard to the originating domain to achieve within-class compactness. On the other hand, we want ϕ(·) to clearly separate samples with different labels irrespective of the domain, gaining between-class separability.</p><p>Let X S ∈ R D×N S and X T ∈ R D×N T be two data matrices from the source and target domains, respectively, and let N = N S +N T . Suppose we have a transformation ϕ(·) which can produce d-dimensional vectors from D-dimensional data. Then we can construct a matrix Φ = [ϕ(X S )ϕ(X T )] ∈ R d×N containing the transformed data from both domains. By encoding the desired pair-wise data relationships in an intrinsic graph G = (X, W) and computing its graph Laplacian matrix L, we can formulate a measure of within-class spread as:</p><formula xml:id="formula_9">N i=1 N j=1 Φ (i) − Φ (j) 2 2 W (i,j) = Tr ΦLΦ<label>(6)</label></formula><p>Similarly, we can create a penalty graph G p = (X, W p ) and express the between-class separability using:</p><formula xml:id="formula_10">N i=1 N j=1 Φ (i) − Φ (j) 2 2 W (i,j) p = Tr ΦBΦ<label>(7)</label></formula><p>Posing the domain adaptation problem in these terms, lets us utilise common objective functions from Graph Embedding. Since the goal is to minimise the within-class compactness and maximise the between-class separability, DAGE optimises:</p><formula xml:id="formula_11">ϕ * = argmin ϕ Tr ΦLΦ Tr ΦBΦ (8)</formula><p>Note that since Eq. (8) corresponds to a minimization problem, the graphs Laplacian matrices of the intrinsic and the penalty graphs are placed respectively in the numerator and denominator of the trace ratio problem.</p><p>When the transformation is linear using a projection matrix V, i.e. ϕ(X) = V X, then the DAGE criterion becomes:</p><formula xml:id="formula_12">V * = argmin V Tr V XLX V Tr V XBX V (9) where X = [X S , X T ].</formula><p>The optimal transformation matrix V * is obtained by solving the ratio trace problem. Its solution is formed by the eigenvectors corresponding to the d largest eigenvalues of the generalised eigenvalue problem XBX v * = λXLX v * , or by minimising the trace difference problem as described in Section III:</p><formula xml:id="formula_13">J (V, λ) = Tr V (XLX − λXBX )V<label>(10)</label></formula><p>The linear DAGE criterion in Eq. (9) can also be formulated using the kernel trick for deriving non-linear mappings. Suppose φ : R D → F is a nonlinear function mapping the input data into a reproducing kernel Hilbert space F. Let the matrix Φ = [φ(x 1 ), · · · , φ(x N )] be composed of data in F. Based on the Representer Theorem, we let V = ΦA and get:</p><formula xml:id="formula_14">A * = argmin A Tr A KLKA Tr A KBKA (11) where K = Φ Φ has elements equal to K (i,j) = φ(x i ) · φ(x j ).</formula><p>The solution of the kernelised DAGE formulation in Eq. (11) can be found via generalised eigenvalue decomposition or applying an iterative process similar to the linear case.</p><p>Eigenvalue decomposition for nonlinear DAGE is intractable for large datasets as the computational complexity is in the order of O(N 3 ) <ref type="bibr" target="#b37">[38]</ref>. An alternative solution is to express the DAGE criterion as part of the loss function in a deep neural network. For supervised domain adaptation problems in the visual domain, the first layers of a neural network architecture can be seen as a non-linear parametric function ϕ n (·) taking as input the raw image data and giving as output vector representations. This allows the DAGE objective to be optimised using gradient descent-based approaches. Moreover, the DAGE loss can be optimised together with a classification loss (e.g. cross-entropy) in an end-to-end manner. Given a mini-batch b of data, the DAGE loss can be computed:</p><formula xml:id="formula_15">L DAGE = Tr Φ b L b Φ b Tr Φ b B b Φ b ,<label>(12)</label></formula><p>where</p><formula xml:id="formula_16">Φ b = ϕ n X (b) S , ϕ n X (b) T</formula><p>is a matrix formed by the transformed features in the mini-batch b and the graph Laplacian matrices L b and B b are computed on the data forming the mini-batch. The gradient for a mini-batch is:</p><formula xml:id="formula_17">∇ Φ b L DAGE = Tr Φ b L b + Φ b L b Tr Φ b B b Φ b − Tr Φ b L b Φ b Φ b B b + Φ b B b Tr Φ b B b Φ b 2<label>(13)</label></formula><p>The resulting loss function to be optimised is the sum of the DAGE loss and classification losses for source and target domain data:</p><formula xml:id="formula_18">argmin θϕ,θ h L DAGE + β L S CE + γ L T CE<label>(14)</label></formula><p>where θ ϕ and θ h denote the parameters of the parametric functions ϕ n (·) (feature extractor) and h(·) (classifier), respectively. β and γ indicate the weight of the cross-entropy losses for classification of the source and target data, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. DAGE-LDA</head><p>The DAGE criterion in Eq. <ref type="formula">(8)</ref> is a generic criterion which can lead to a multitude of Domain Adaptation solutions. Constructing the two graphs G and G p in different ways gives rise to different properties to be optimised in the subspace R d . A simple instantiation of DAGE inspired by Linear Discriminant Analysis is obtained by using an intrinsic graph structure connecting the samples belonging to the same class:</p><formula xml:id="formula_19">W (i,j) = 1, if i = j 0, otherwise<label>(15)</label></formula><p>where i and j are the labels associated with the i-th and j-th samples, respectively. The corresponding penalty graph structure connects samples belonging to different classes:</p><formula xml:id="formula_20">W (i,j) p = 1, if i = j 0, otherwise<label>(16)</label></formula><p>Despite the simplicity of the above-described DAGE instantiation, the resulting method performs on par with state-of-the-art Domain Adaptation methods, as will be shown in Section VII.</p><p>V. STATE OF THE ART SUPERVISED DOMAIN ADAPTATION METHODS PERFORM GRAPH EMBEDDING In Section IV, we analysed the domain-invariant space approach to Supervised Domain Adaptation, and showed that it can be naturally described as multi-view Graph Embedding. In fact, any domain adaptation method, which uses pairs of samples to produce a domain-invariant latent space, can be cast as a multi-view Graph Embedding method. To illustrate this point, we analyse three recent state-of-the-art methods and show that they are instances of Domain Adaptation via Graph Embedding. Here we should note that a similar relationship can be shown for several other Domain Adaptation methods such as <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b38">39]</ref>. In the subsequent subsections, we focus on the Domain Adaptation terms included in the optimisation function of each method, while we omit the corresponding cross-entropy terms of each method for simplicity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Classification and Contrastive Semantic Alignment</head><p>The contrastive semantic alignment loss of CCSA <ref type="bibr" target="#b5">[6]</ref> is constructed from two terms: A similarity loss L S , which penalises the distance between within-class samples of different domains, and a dissimilarity loss L D , which penalises the proximity of between-class samples if they come within a distance margin , i.e.:</p><formula xml:id="formula_21">L CSA = L S + L D .<label>(17)</label></formula><p>Using as notational shorthand d ij = ϕ n (x i ) − ϕ n (x j ) 2 , the partial losses are defined as follows:</p><formula xml:id="formula_22">L S = xi∈D S xj ∈D T i= j 1 2 d 2 ij<label>(18)</label></formula><formula xml:id="formula_23">L D = xi∈D S xj ∈D T i = j 1 2 max {0, − d ij } 2 .<label>(19)</label></formula><p>The similarity loss can be expressed equivalently in terms of the weighted summation over graph edges:</p><formula xml:id="formula_24">L S = xi∈D S xj ∈D T ϕ n (x i ) − ϕ n (x j ) 2 2 W (i,j) = Tr(ΦLΦ )<label>(20)</label></formula><p>where the graph weight matrix W has an edge for samplepairs with the same label but different originating domains</p><formula xml:id="formula_25">W (i,j) = 1 2 , if i = j and D i = D j 0, otherwise,<label>(21)</label></formula><p>and L is the graph Laplacian matrix associated with W. Using the fact that max{f (x)} = − min{−f (x)}, the dissimilarity loss can likewise be expressed in terms of a summation over graph edges:</p><formula xml:id="formula_26">L D = − xi∈D S xj ∈D T i = j dij &lt; 1 2 (d ij − ) 2 = − xi∈D S xj ∈D T i = j dij &lt; d 2 ij 1 2 1 + 2 d 2 ij − 2 d ij = − xi∈D S xj ∈D T ϕ n (x i ) − ϕ n (x j ) 2 2 W (i,j) p = −Tr(ΦBΦ )<label>(22)</label></formula><p>where</p><formula xml:id="formula_27">W (i,j) p =      1 2 + 2 2d 2 ij − dij , if d ij &lt; and i = j and D i = D j 0, otherwise<label>(23)</label></formula><p>and B is the graph Laplacian matrix associated with the corresponding weight matrix W p . Note that the weight matrix of Eq. (23) constitutes an -distance margin rule for graph embedding. The partial similarity and dissimilarity losses can thus be expressed using graph Laplacian matrices encoding the within-class and between-class relations. Combining Eqs. <ref type="bibr" target="#b19">(20)</ref> and <ref type="formula" target="#formula_1">(22)</ref>, we see that the contrastive semantic alignment loss of CCSA is equivalent to:</p><formula xml:id="formula_28">L CSA = Tr ΦLΦ − λΦBΦ<label>(24)</label></formula><p>which is equivalent to the trace difference problem in Eq. (10) used in the DAGE framework. While CCSA employs a value of λ = 1, one can also determine an optimised value for λ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Domain Adaptation using Stochastic Neighborhood Embedding</head><p>Following the procedure outlined above, it is straightforward to show that d-SNE <ref type="bibr" target="#b6">[7]</ref> can also be viewed as a graph embedding. For each target sample, the domain adaptation loss term of d-SNE penalises the furthest distance to a within-class source sample, and encourages the distance for the closest between-class to source sample to be maximised:</p><formula xml:id="formula_29">L d-SNE = xj ∈D T max xi∈D S i= j a|a ∈ d 2 ij − min xi∈D S i = j b|b ∈ d 2 ij<label>(25)</label></formula><p>We can readily express this using the trace difference formulation:</p><formula xml:id="formula_30">L d-SNE = Tr ΦLΦ − λΦBΦ<label>(26)</label></formula><p>with λ = 1 and L and B being the Graph Laplacian matrices corresponding to the following weight matrices:</p><formula xml:id="formula_31">W (i,j) =      1, if d ij = max x k ∈D S {a | a ∈ d kj } and j = i = k and D i = D j 0, otherwise,<label>(27)</label></formula><formula xml:id="formula_32">W (i,j) p =      1, if d ij = min x k ∈D S {b | b ∈ d kj } and j = i = k and D i = D j 0, otherwise.<label>(28)</label></formula><p>Because only a single edge is specified for each source sample per graph Laplacian, it is worth noting that the resulting graph connectivity for d-SNE is highly dependent on the batch size used during optimisation. Small batch sizes will result in more densely connected graphs than large batch sizes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Neural Embedding Matching</head><p>NEM <ref type="bibr" target="#b7">[8]</ref> extends the contrastive loss of CCSA with an additional term designed to maintain the neighbour relationship of target data throughout the feature embedding:</p><formula xml:id="formula_33">L NEM = L CSA + νL neighbour<label>(29)</label></formula><p>Here, ν is a hyperparameter weighting the importance of the neighbour matching loss, which is specified as the loss over a neighbourhood graph with edges between each target sample i and its k nearest neighbours N (i) in the original feature space:</p><formula xml:id="formula_34">L neighbour = xi∈D T xj ∈N (i) ϕ n (x i ) − ϕ n (x j ) 2 κ RBF (x i , x j ) (30) where κ RBF (x, x ) = exp (− x − x 2 2 /2σ 2 )</formula><p>is the Radial Basis Function kernel used to assign a weight to the edge between any pair of vertices. To express the NEM loss in terms of a graph embedding, the neighbour term can be incorporated into the similarity weight matrix by extending the encoding rule from Eq. <ref type="formula" target="#formula_1">(21)</ref>:</p><formula xml:id="formula_35">W (i,j) =      ν κRBF(xi,xj ) dij , if j ∈ N (i) and D i = D j = D T 1 2 , if i = j and D i = D l 0, otherwise,<label>(31)</label></formula><p>where ν is a hyper-parameter weighting the influence of the neighbour term. The penalty weight matrix for NEM is the same as for CCSA in Eq. (23) and the final graph embedding problem is a trace difference problem as in Eqs. <ref type="bibr" target="#b23">(24)</ref> and <ref type="bibr" target="#b25">(26)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Discussion</head><p>While some methods <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b25">26]</ref> explicitly formulate the process of Domain Adaptation as Graph Embedding, we have shown that many others <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b7">8]</ref>, which employ pairwise (dis)similarities between data, can also be formulated as such. It would be trivial to perform the same analysis on other methods (e.g <ref type="bibr" target="#b17">[18]</ref>).</p><p>Of course, not all Domain Adaptation methods fit nicely into the structure of Graph Embedding. The use of an adversarial network branch <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b27">28]</ref> is not straight-forward to integrate into the intrinsic and penalty matrices of a Graph Embedding. Moreover, progressive learning strategies and the use of pseudo-labels in semi-and unsupervised methods <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b25">26]</ref> relates more to the training loop than the loss-formulation. Nonetheless, Graph Embedding captures many existing powerful Domain Adaptation methods, and gives us a common lens through which to see them: In CCSA, all same-class sample pairs are given a similar attraction, while different-class pairs are only repelled if they come within a distance margin; in NEM, target domain samples are additionally encouraged to remain close, if they were similar in their input-space; in d-SNE, for each sample only the furthest same-class sample is attracted, while the closest sample of different label is repelled; in DAGE-LDA, we simply attract same-class pairs and repel different-class pairs without further assumptions.</p><p>An ongoing challenge in Machine Learning and Domain Adaptation is how to clearly encode our prior knowledge and assumptions into the learning problem for a specific application <ref type="bibr" target="#b8">[9]</ref>. We would argue that the construction rules for the graph Laplacian matrices of Graph Embedding may be an ideal way to specify this in a simple if-then-else manner. Say, we want to encode an assumption that some classes (e.g. bike and bookcase) have large within-class differences, while other to not. In the the intrinsic matrix, we might then state a rule, that the bike and bookcase classes should only attract the most similar same-class sample and ignore the others, while all samples should be attracted equally for the other classes. The is a plethora of options for constructing the graphs using margins, nearest-neighbour rules, etc. We leave thier exploration to future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. RECTIFIED EXPERIMENTAL PROTOCOL FOR FEW-SHOT SUPERVISED DOMAIN ADAPTATION</head><p>An important aspect of conducting experiments on domain adaptation in few-shot settings relates to how the data should be split. In this section, we describe the experimental setup that is normally used to evaluate and compare supervised Domain Adaptation methods. We showcase issues related to non-exclusive use of data in model selection and testing phases and we describe how the evaluation process can be improved by proposing a new experimental setup.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Traditional Experiment Setup</head><p>The experiment setup used to evaluate the performance of Domain Adaptation methods, e.g. <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7]</ref>, is as follows: A number of samples of each class are drawn from the source domain, and a few samples per class are drawn from the target domain to be used for training. For instance, in experiments using the Office31 dataset <ref type="bibr" target="#b11">[12]</ref> with the Amazon data as source domain and the Webcam data as target domain, the number of samples per class forming the training set is equal to twenty and three, respectively. The remaining target data is used for testing. The sampled data from both source and target domains are paired up as the Cartesian product of the two sets, producing as the resulting dataset all combinations of two samples from either domain. To limit the size and redundancy, the dataset is filtered to have a predefined ratio of same-class samples (where both samples in a pair have the same label) to different-class samples. This ratio is commonly set equal to 1:3. An illustration of this is found in <ref type="figure">Fig. 2</ref>. This combined dataset is then used to train a model with a Domain Adaptation technique e.g. using the two stream architecture as illustrated in <ref type="figure">Fig. 1</ref>. The final evaluation is conducted on the test set coming from the target domain. Because very few unique samples from the target domain are used for training in each experiment, the results will usually vary significantly between runs and will depend on the random seed used for creating the training and test splits. Therefore, each experiment is repeated multiple times, each time with a new seed value, and the mean accuracy alongside the standard deviation over the runs is reported. The absence of validation data on each experiment has the risk of performing model selection (including hyper-parameter search) based on the performance on the test data. One could try to avoid the problem by performing model selection and hyper-parameter search using training/test splits from seed values which are not used for the final training/test splits. This, however, is not enough to guarantee that the test performance generalises to unseen data, since it is probable that test data is used for model selection and hyper-parameter search, as illustrated in <ref type="figure">Fig. 3</ref>.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Rectified Experiment Setup</head><p>To avoid the above described issues of the experiment setup used in evaluating the performance of Domain Adaptation methods, we need to conduct our sampling in two steps: First, we need to define the data in the target domain that will be used for evaluating the performance of the Domain Adaptation method in all the runs. The remaining data in the target domain will be used to form the training and validation sets in the target domain in different runs. This can be done exactly as described in Section VI-A: We draw few samples from the source domain and the training set of the target domain, and combine them using the Cartesian Product with an optional ratio for filtering. This way, we ensure that independent test data is used for method evaluation, and a validation set is available for model selection and hyper-parameter search. This data splitting procedure is illustrated in <ref type="figure" target="#fig_4">Fig. 4a</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. EXPERIMENTS AND RESULTS</head><p>In this section, we conduct experiments on the Office31 and MINST-USPS datasets using the rectified experimental setup and compare the results to those from the traditional experimental setup.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Datasets</head><p>The Office31 dataset <ref type="bibr" target="#b11">[12]</ref> contains images of 31 object classes found in the modern office. It has three visual domains: Amazon (A) consists of 2.817 images found on the e-commerce site www.amazon.com. These images are generally characterised by their white background and studiolighting conditions. DSLR (D) contains 498 high resolution images taken using a digital single-lens reflex camera. Here, multiple photos are taken of each object in an office setting. Finally, Webcam (W) has 795 images captured using a cheap web-camera. The objects photographed are the same as for DSLR, but the images in this case are low-resolution and suffer from visual artefacts such as colour imbalances and optical distortion. A sample of the Office31 images is shown in <ref type="figure" target="#fig_5">Fig. 5</ref>.</p><p>The MNIST <ref type="bibr" target="#b12">[13]</ref> and USPS <ref type="bibr" target="#b13">[14]</ref> datasets contain handwritten digits from 0 to 9 captured in grayscale. MNIST consists of 70,000 images with a 28 × 28 resolution, and USPS has 11,000 images in a 16 × 16 format.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Office31</head><p>In our experiments on the Office31 dataset, we used a model consisting of the convolutional layers of a VGG-16 <ref type="bibr" target="#b39">[40]</ref> network pretrained on ImageNet <ref type="bibr" target="#b40">[41]</ref> with randomly initialised dense layers of 1024 and 128 neurons, respectively, as done in <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7]</ref>. This network is subsequently fine-tuned on all source data (FT-Source). We found a gradual-unfreeze procedure <ref type="bibr" target="#b42">[42]</ref>,   where four pretrained layers are unfrozen each time the model converges, to work well. To produce a baseline method (FT-Target), the FT-Source model is further fine-tuned on the target data.</p><p>We follow the experimental procedure described in Section VI-B. After first splitting off 30% of the target data to form the test set, we create the training set using twenty source samples per class for the Amazon domain, and eight source samples per class for DSLR and Webcam. From the target domain, three samples per class are drawn in each case. The remaining target data is used as a validation set. Thus, we employ the same number of samples for training as in the traditional split <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b15">16]</ref>, but ensure an independent test split as well as a well-defined validation split. The model is duplicated across two streams with shared weights as depicted in <ref type="figure">Fig. 1</ref> and trained on the combined training data, with one domain entering each stream. This experiment is performed for all six combinations of source and target domain in {A, D, W}, and each combination is run five times using different seeds. We re-implemented CCSA and d-SNE using their publicly available source code and included them in our experiments. Prior to executing the five runs, an independent hyper-parameter search on the space summarised in <ref type="table" target="#tab_1">Table III</ref> was conducted for each method using Bayesian Optimisation with the Expected Improvement acquisition function <ref type="bibr" target="#b43">[43]</ref> given 100 trials. For the final tests, we used data augmentation with random modifications of colour hue and saturation, image brightness and contrast, as well as rotation and zoom. For a fair comparison, all hyper-parameter tuning and tests are performed with the exact same computational budget and data available for all methods tested.</p><p>The results for Office31 are shown in <ref type="table" target="#tab_1">Table I and Table II.</ref> Comparing the CCSA and d-SNE results of the traditional experimental setup with the rectified one, we see that the achieved macro accuracy is generally lower: −1.2% on average for for CCSA, d-SNE and DAGE-LDA. This is in-line with our expectations, and confirms that that the traditional setup may have suffered from generalisation issues as described in Section VI-A. Comparing CCSA, d-SNE, and DAGE-LDA in the rectified experimental setup, we see that though DAGE-LDA only outperforms the other methods on a single adaptation (W → A), it has the highest average score across all six adaptations. CCSA performs next best, and d-SNE comes last of the three. This suggests, that the higher accuracy originally reported in <ref type="bibr" target="#b6">[7]</ref> as compared to <ref type="bibr" target="#b5">[6]</ref> may be due to better hyper-parameter optimisation rather than a better Domain Adaptation loss.</p><p>As an additional experiment, we repeat the adaptation task for DAGE-LDA using the ResNet-50 <ref type="bibr" target="#b44">[44]</ref> to gauge the effect of using an improved feature-extractor. Comparing the VGG-16 results with those for ResNet-50, we an average improvement of 4.0%. This matches the relative difference in  <ref type="bibr" target="#b44">[44]</ref>), and highlights the importance of disclosing which feature-extractor is used in derived methods <ref type="bibr" target="#b45">[45]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. MNIST-USPS</head><p>For our experiments in the MNIST to USPS domain adaptation problem, we used a network architecture which has two streams with shared weights, with two convolutional layers containing 6 and 16 5 × 5 filters respectively, maxpooling, and two dense layers of size 120 and 84 prior to the classification layer. This architecture is the same as the one used in <ref type="bibr" target="#b5">[6]</ref>. We trained the network from random initialisation using 2,000 randomly sampled images per class from MNIST (source) and a varying number of USPS (target) samples per class. Experiments using 1, 3, 5 and 7 target samples per class were conducted and each experiment was repeated 10 times. Here, we used the predefined test-train splits from TorchVision Datasets, sampling the training and validation data from the train split. Though our implementation uses Tensorflow, the datasets were made compatible by using the Dataset Ops library. Aside from following the rectified sampling, the experiments use the procedure from <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b46">46]</ref>. Prior to conducting the final experiment runs, a hyper-parameter search was conducted using the same settings as for Office31, and for testing, similar data augmentation was employed. The results obtained by running the experiments are shown in <ref type="table" target="#tab_1">Table IV</ref>. Comparing CCSA, d-SNE and DAGE-LDA, we find the same trend as for the Office31 experiments: DAGE-LDA has the highest average accuracy, closely followed by CCSA and then d-SNE. While the originally reported results for d-SNE <ref type="bibr" target="#b6">[7]</ref> show better performance than the other methods, it should be noted they used a LeNet++ <ref type="bibr" target="#b47">[47]</ref> architecture for feature extraction. Based on our own results for d-SNE, which used a CNN-architecture similar to the other methods, we attribute their higher accuracy to the choice of featureextractor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VIII. CONCLUSION</head><p>In this paper, we have shown that by viewing Domain Adaptation as Graph Embedding (DAGE), many existing methods for Supervised Domain Adaptation can be formulated in a common framework. Within the DAGE framework, a very simple LDA-inspired instantiation matches or surpasses the current state-of-the-art methods on few-shot supervised adaptation task using the standard benchmark datasets Office31 and MNIST-USPS. Moreover, we argued that the intrinsic and penalty graph Laplacian matrices in Graph Embedding give us a straight-forward way of encoding application specific assumptions about the domain and tasks at hand. Finally, we highlighted some generalisation and reproducibility issues related to the experimental setup commonly used to evaluate the performance of Domain Adaptation methods and proposed a rectified experimental setup for more accurately assessing and comparing the generalisation capability of Supervised DA methods. Alongside our source code, we made the revised training-validation-test splits for Office31 and MNIST-USPS available to facilitate fair comparisons of Supervised Domain Adaptation methods in future research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENT</head><p>This work has received partial funding from the European Unions Horizon 2020 research and innovation programme under grant agreement No 871449 (OpenDR). This publication reflects the authors views only. The European Commission is not responsible for any use that may be made of the information it contains. Dr. Iosifidis has contributed in more than twenty R&amp;D projects financed by EU, Finnish and Danish funding agencies and companies. He has (co-)authored 73 articles in international journals and 89 papers in international conferences proposing novel Machine Learning techniques and their application in a variety of problems. He is a Senior Member of IEEE since 2016, and he served as an Officer of the Finnish IEEE Signal Processing-Circuits and Systems Chapter during 2016-2018. He is currently a member of the EURASIP Technical Area Committee on Visual Information Processing, and serves as Area/Associate Editor in Neurocomputing, Signal Processing: Image Communications, IEEE Access and BMC Bioinformatics journals. He served as an Area Chair for IEEE ICIP-2018,2019,2020 and EUSIPCO-2019, Technical Program Committee Chair for IEEE ICASSP-2019, and he is the Publicity co-Chair of IEEE ICME-2021. His research interests focus on topics of neural networks and statistical machine learning finding applications in computer vision, financial engineering and graph mining problems.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 :Fig. 3 :</head><label>23</label><figDesc>Cartesian product of two sets, each with three samples. Sample labels are indicated by their shape, while the colour indicates their origin. The Cartesian product produces all pairwise combinations of samples with one sample from each set. A ratio filter (here with a 1:1 ratio) can be used to limit the ratio of same-class samples to different-class samples. (a) Current domain adaptation setup in<ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7]</ref> leads to dependent splits. (b) Drawing a validation does not ensure test set independence. (c) To produce an independent test split, an initial fixed train-rest split should be made followed by trainval splits for each experimental run.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Data preparation procedure. Test data is a constant subset of target data, whereas training and validation data are sampled with different seeds for each experiment. Training data is the Cartesian product of training samples from target and source domain, filtered to have a predefined ratio of same-class to different class pairs. Here, ovals represent operations and rectangles represent data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Automated hyperparameter search is performed using a single trainvalidation split, producing the tuned hyperparameters to be used for evaluation with other splits.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 :</head><label>4</label><figDesc>Rectified experimental setup</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 :</head><label>5</label><figDesc>Samples from Office31 (Amazon, DSLR, Webcam) as well as MNIST and USPS.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>Conference on Computer Vision and Pattern Recognition, 2016, pp. 499-515. Lukas Hedegaard Morsing is a PhD student at Aarhus University, Denmark. He received his M.Sc. degree in Computer Engineering in 2019 and B.Eng. degree in Electronics in 2017 at Aarhus University, specialising in signal processing and machine learning. His current research interests include deep learning and transfer learning focused on efficient utilisation of training data and computational resources. Omar Ali Sheikh-Omar received a B.Sc. degree in Software Engineering from Aalborg University, Denmark in 2017 and a M.Sc. degree in Computer Engineering from Aarhus University, Denmark in 2019. He is interested in data science and machine learning finding application in computer vision and natural language processing problems. Alexandros Iosifidis (SM'16) is an Associate Professor of Machine Learning at the Department of Engineering, Aarhus University, Denmark. He received the B.Sc. degree in Electrical and Computer Engineering and the M.Sc. degree with a specialisation in Mechatronics from the Democritus University of Thrace, Greece, in 2008 and 2010, respectively. He also received his PhD in Computer Science from the Aristotle University of Thessaloniki, Greece, in 2014. Before he joined Aarhus University, he held Postdoctoral Researcher positions at Aristotle University of Thessaloniki and at Tampere University of Technology, Finland, where he was an Academy of Finland Postdoctoral Research Fellow.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>rectified experimental protocol and are compatible with both Tensorflow and PyTorch though the use of a new open source library called Dataset Ops 3 . 6) We supply an updated benchmark for DAGE-LDA [10], CCSA, and d-SNE on the Office31</figDesc><table /><note>1 Rectified Office31 splits: www.github.com/lukashedegaard/office312 Rectified M→U splits: www.github.com/lukashedegaard/mnist-usps which follow the</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE I :</head><label>I</label><figDesc>Macro average classification accuracy (%) on the supervised adaptation setting of Office-31. Top rows: Results using the traditional experiment setup. Bottom rows: Results when using the rectified experiment setup. Unless stated otherwise, the convolutional layers of a VGG-16 pretrained on imagenet network were used for feature-extraction. The results are reported as the mean and standard deviation across five runs.</figDesc><table><row><cell>A → D</cell><cell>A → W</cell><cell>D → A</cell><cell>D → W</cell><cell>W → A</cell><cell>W → D</cell><cell>Avg.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE II</head><label>II</label><figDesc></figDesc><table><row><cell cols="4">: Office-31 average classification accuracy (%) for</cell></row><row><cell cols="4">the traditional and rectified experimental methodology. As</cell></row><row><cell cols="4">feature-extractor, the convolutional layers of a VGG-16 pre-</cell></row><row><cell cols="3">trained on ImageNet network were used.</cell><cell></cell></row><row><cell cols="2">Experiment setup Traditional [10]</cell><cell cols="2">Rectified Difference</cell></row><row><cell>CCSA</cell><cell>83.1</cell><cell>82.2</cell><cell>-0.9</cell></row><row><cell>d-SNE</cell><cell>83.6</cell><cell>81.6</cell><cell>-2.0</cell></row><row><cell>DAGE-LDA</cell><cell>83.6</cell><cell>82.8</cell><cell>-0.8</cell></row><row><cell>Average</cell><cell></cell><cell></cell><cell>-1.2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE III :</head><label>III</label><figDesc>Employed hyper-parameter search space. Uniform § Only relevant for CCSA and d-SNE. Only relevant for the experiments in Office31 dataset.</figDesc><table><row><cell>Hyper-Parameter</cell><cell cols="2">Lower Upper</cell><cell>Prior</cell></row><row><cell>Learning Rate</cell><cell>10 −6</cell><cell>0.1</cell><cell>Log-Uniform</cell></row><row><cell>Learning Rate Decay</cell><cell>10 −7</cell><cell>0.01</cell><cell>Log-Uniform</cell></row><row><cell>Momentum</cell><cell>0.5</cell><cell cols="2">0.99 Inv Log-Uniform</cell></row><row><cell>Dropout</cell><cell>0.1</cell><cell>0.8</cell><cell>Uniform</cell></row><row><cell>L2 Regularisation</cell><cell>10 −7</cell><cell>10 −3</cell><cell>Log-Uniform</cell></row><row><cell>Batch Norm</cell><cell>False</cell><cell>True</cell><cell>Uniform</cell></row><row><cell>Margin,  §</cell><cell>10 −3</cell><cell>10</cell><cell>Log-Uniform</cell></row><row><cell>No. Unfrozen Base-Layers  ¶</cell><cell>0</cell><cell>16</cell><cell>Uniform</cell></row><row><cell>DA-CE Loss Ratio, β+γ 1+β+γ</cell><cell>0.01</cell><cell>0.99</cell><cell>Uniform</cell></row><row><cell>S-T CE Loss Ratio, β β+γ</cell><cell>0.0</cell><cell>1.0</cell><cell></cell></row></table><note>¶</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE IV :</head><label>IV</label><figDesc>MNIST → USPS classification accuracy (%) using the rectified experimental protocol. The number of available target samples per class is varied and 200 source samples per class are used. The mean and standard deviation is reported across ten runs.</figDesc><table><row><cell></cell><cell>Samples/class</cell><cell>1</cell><cell>3</cell><cell>5</cell><cell>7</cell><cell>Avg.</cell></row><row><cell>Trad.</cell><cell>CCSA [6] FADA [17] d-SNE (LeNet++) [7]</cell><cell>85.0 89.1 92 .9</cell><cell>90.1 91.9 93 .6</cell><cell>92.4 93.4 95 .1</cell><cell>92.9 94.4 96 .1</cell><cell>90.1 92.2 94 .4</cell></row><row><cell></cell><cell>NEM [8]</cell><cell>72.2</cell><cell>86.6</cell><cell>91.4</cell><cell>91.8</cell><cell>85.5</cell></row><row><cell>Rect.</cell><cell>CCSA d-SNE DAGE-LDA</cell><cell>89.1 ± 1.1 88.3 ± 1.7 88.8 ± 1.8</cell><cell>91.2 ± 0.9 91.4 ± 1.2 92.4 ± 0.5</cell><cell cols="2">93.8 ± 0.4 94.3 ± 0.4 93.1 ± 0.5 93.6 ± 0.6 93.4 ± 0.4 94.1 ± 0.3</cell><cell>92.1 91.6 92.2</cell></row><row><cell cols="4">top-1 accuracy on ImageNet (75.6% for VGG16 and 79.3% for</cell><cell></cell><cell></cell><cell></cell></row><row><cell>ResNet-50</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">Dataset Ops: https://github.com/lukashedegaard/datasetops 4 DAGE: www.github.com/lukashedegaard/dage</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Traditional FT-Source <ref type="bibr" target="#b9">[10]</ref> 66.6 ± 3.0 59. <ref type="bibr" target="#b7">8</ref>  </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A closer look at memorization in deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Arpit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jastrzebski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ballas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Kanwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Maharaj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="233" to="242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A survey on transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1345" to="1359" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A survey of transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Khoshgoftaar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Big data</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Torrey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shavlik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of Research on Machine Learning Applications and Trends: Algorithms, Methods, and Techniques</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="242" to="264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Data enrichment in finegrained classification of aquatic macroinvertebrates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Raitoharju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Riabchenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Meissner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Iosifidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gabbouj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kiranyaz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICPR 2nd Workshop on Computer Vision for Analysis of Underwater Imagery</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="43" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Unified deep supervised domain adaptation and generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Motiian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Piccirilli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Adjeroh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Doretto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5715" to="5725" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Domain Adaptation Using Stochastic Neighborhood Embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Venkatesan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Swaminathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-</forename><surname>Sne</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>Springer International Publishing</publisher>
			<biblScope unit="page" from="43" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Domain adaptation with neural embedding matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">An introduction to domain adaptation and transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">M</forename><surname>Kouw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Loog</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.11806</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Supervised domain adaptation using graph embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Hedegaard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">A</forename><surname>Sheikh-Omar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Iosifidis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.04063</idno>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
	<note type="report_type">preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Graph embedding and extensions: A general framework for dimensionality reduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="40" to="51" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Adapting visual category models to new domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fritz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="213" to="226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE</title>
		<meeting>the IEEE</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="2278" to="2324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Handwritten digit recognition with a back-propagation network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">E</forename><surname>Boser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Denker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">E</forename><surname>Hubbard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">D</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="1990" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="396" to="404" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Dimensionality reduction by learning an invariant mapping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1735" to="1742" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Simultaneous deep transfer across domains and tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="4068" to="4076" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Fewshot adversarial domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Motiian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Iranmanesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Doretto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="6670" to="6680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Domain adaptation by mixture of alignments of second-or higher-order scatter tensors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koniusz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Porikli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="7139" to="7148" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Mean teachers are better role models: Weight-averaged consistency targets improve semisupervised deep learning results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tarvainen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Valpola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="1195" to="1204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Semi-supervised learning using gaussian fields and harmonic functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page">912919</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Deep learning via semi-supervised embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ratle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page">11681175</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Locality preserving joint transfer for domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">T</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="6103" to="6115" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Domain adaptation by joint distribution invariant projections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Harandi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="8264" to="8277" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Domain adaptation via transfer component analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">W</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Kwok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="199" to="210" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Scatter component analysis: A unified framework for domain adaptation and domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ghifary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Balduzzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">B</forename><surname>Kleijn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1414" to="1430" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A graph embedding framework for maximum mean discrepancy-based domain adaptation algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="199" to="213" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Domain-adversarial training of neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ustinova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ajakan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Germain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Laviolette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>March</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">59</biblScope>
			<biblScope unit="page" from="1" to="35" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Conditional adversarial domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="1640" to="1650" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Trace ratio problem revisited</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="729" to="735" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">On the optimal class representation in linear discriminant analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Iosifidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tefas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Pitas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1491" to="1497" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Generalized multi-view embedding for visual recognition and cross-modal retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Iosifidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gabbouj</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Cybernetics</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2542" to="2555" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Multiview fsher discriminant analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Diethe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hardoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shawe-Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">The collinearity problem in linear regression: The partial least squares (pls) approach to generalized inverses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ruhe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dunn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Scientic and Statistical Computing</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="735" to="743" />
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Deep canonical correlation analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Arona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bilmes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Livescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1247" to="1255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Multi-view discriminant analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="188" to="194" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Multi-view nonparametric discriminant analysis for image retrieval and recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Iosifidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabbouj</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Letters</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1537" to="1541" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Deep multi-view learning to rank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Iosifidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gabbouj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Raghavan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gottumukkala</surname></persName>
		</author>
		<idno type="DOI">10.1109/TKDE.2019.2942590</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering (Early Access</title>
		<imprint>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">The complexity of the matrix eigenproblem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">Y</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><forename type="middle">Q</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the thirty-first annual ACM symposium on Theory of computing</title>
		<meeting>the thirty-first annual ACM symposium on Theory of computing</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="507" to="516" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Graph matching and pseudo-label guided deep unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">G</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Neural Networks</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="342" to="352" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<idno>abs/1409.1556</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Imagenet large scale visual recognition challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="252" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Universal language model fine-tuning for text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ruder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annual Meeting of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="328" to="339" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">A tutorial on bayesian optimization of expensive cost functions, with application to active user modeling and hierarchical reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Brochu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">M</forename><surname>Cora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>De Freitas</surname></persName>
		</author>
		<idno>abs/1012.2599</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">A metric learning reality check</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Musgrave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-N</forename><surname>Lim</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Joint crossdomain classification and subspace learning for unsupervised adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Fernando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tommasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tuytelaars</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page" from="60" to="66" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">A discriminative feature learning approach for deep face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qiao</surname></persName>
		</author>
		<imprint>
			<publisher>IEEE</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
