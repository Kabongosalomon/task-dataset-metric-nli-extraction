<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongliang</forename><surname>Chang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiyue</forename><surname>Pang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixiao</forename><surname>Zheng</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhanyu</forename><surname>Ma</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Zhe</forename><surname>Song</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Guo</surname></persName>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>Your &quot;Flamingo&quot; is My &quot;Bird&quot;: Fine-Grained, or Not</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T22:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Whether what you see in <ref type="figure">Figure 1</ref> is a "flamingo" or a "bird", is the question we ask in this paper. While finegrained visual classification (FGVC) strives to arrive at the former, for the majority of us non-experts just "bird" would probably suffice. The real question is thereforehow can we tailor for different fine-grained definitions under divergent levels of expertise. For that, we re-envisage the traditional setting of FGVC, from single-label classification, to that of top-down traversal of a pre-defined coarse-to-fine label hierarchy -so that our answer becomes "bird" ⇒ "Phoenicopteriformes" ⇒ "Phoenicopteridae" ⇒ "flamingo".</p><p>To approach this new problem, we first conduct a comprehensive human study where we confirm that most participants prefer multi-granularity labels, regardless whether they consider themselves experts. We then discover the key intuition that: coarse-level label prediction exacerbates fine-grained feature learning, yet fine-level feature betters the learning of coarse-level classifier. This discovery enables us to design a very simple albeit surprisingly effective solution to our new problem, where we (i) leverage levelspecific classification heads to disentangle coarse-level features with fine-grained ones, and (ii) allow finer-grained features to participate in coarser-grained label predictions, which in turn helps with better disentanglement. Experiments show that our method achieves superior performance in the new FGVC setting, and performs better than stateof-the-art on the traditional single-label FGVC problem as well. Thanks to its simplicity, our method can be easily implemented on top of any existing FGVC frameworks and is parameter-free.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Fine-grained visual classification (FGVC) was first introduced to the vision community almost two decades ago with the landmark paper of <ref type="bibr" target="#b1">[2]</ref>. It brought out a critical D. <ref type="bibr">Chang</ref>  question that was largely overlooked back then -that can machines match up to humans on recognising objects at fine-grained level (e.g., a "flamingo" other than a "bird"). Great strides have been made over the years, starting with the conventional part-based models <ref type="bibr" target="#b50">[51,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b2">3]</ref>, to the recent surge of deep models that either explicitly or implicitly tackle part learning with or without strong supervision <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b51">52,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b47">48]</ref>. Without exception, the focus has been on mining fine-grained discriminative features to better classification performances. In this paper, we too are interested in the fine-grained rationale at large -yet we do not set out to pursue performance gains, we instead question the very definition of fine-grained classification itself. In particular, we ask whether the fine-grained expert labels commonplace to current FGVC datasets indeed convey what end users are accustomed to -i.e., are the "Florida scrub jay", "Fisker Karma Sedan 2012", "Boeing 737-200" are indeed the desired, or would "bird", "car", "aircraft" suffice for manymy "flamingo" can be just your "bird". The answer is of course subjective <ref type="bibr" target="#b30">[31]</ref>, and largely correlates with expert knowledge -the more you are a bird lover, the more finegrained labels you desire, some might even look for "American flamingo" other than just "flamingo". The follow-up question is therefore, how can we tailor for the various subjective definitions of what is fine-grained, and design a system that best accommodates practical usage scenarios of FGVC.</p><p>To answer this, we first conduct a human study on the popular CUB-200-2011 bird dataset <ref type="bibr" target="#b41">[42]</ref> with two questions in mind (i) how useful are the pre-defined fine-grained labels to a general user, and (ii) whether a single label output is in fact a preferred solution. We first build a hierarchical taxonomy of bird, by tracing existing fine-grained labels in CUB-200-2011 to its parent sub-category, all the way to the super node of "bird" using Wikipedia. We then recruited 50 participants with various background of bird knowledge, each of whom rated 100 bird photos by (i) picking a label amongst fine-and coarse-grained ones relating to the bird, and (ii) indicating whether more label choices are desirable other than just the single label previously selected. We find that (i) participants do not necessarily choose the pre-defined fine-grained (bottom) labels as their preferred choice, (ii) only 36.4% of all returned choices prefer just a single label, and (iii) although domain experts tend to choose finer-grained labels while amateurs prefer coarser ones, close to 80% of choices from experts also turn to the option of multi-granularity labels.</p><p>Following results from the human study, we propose to re-instantiate the FGVC problem by extending it from a single-label classification problem, to that of multiple label predictions on a pre-defined label hierarchy. The central idea is while people tend to feel baffled facing a single expert label, a chain of coarse-to-fine labels that describe an object can potentially be more practical -we leave it to the users to decide which fine-grained level along the hierarchy best suits their needs. Compared with a single label telling you it is a "flamingo" (as per conventional FGVC), our model offers a coarse-to-fine series of labels such as "bird" ⇒ "Phoenicopteriformes" ⇒ "Phoenicopteridae" ⇒ "flamingo" (See <ref type="figure" target="#fig_1">Figure 1</ref>).</p><p>On the outset, classifying an image into multiple crossgranularity labels seems an easy enough extension to the well-studied problem of FGVC with single-label output. One can simply train a single model for classifying all nodes in the hierarchy, or better yet use separate classifiers for each hierarchy level. Although these do work as baselines, they do not benefit from the inherent coarse-fine hierarchical relationship amongst labels -we show exploring these relationships not only helps to solve for the new FGVC setting, but also in turn benefits the learning of fine-grained features which then helps the conventional task.</p><p>Our design is based on the discovery of two key observations on the label hierarchy: (i) coarse-level features in fact exacerbates the learning of fine-grained features, and (ii) finer-grained label learning can be exploited to enhance the discriminability of coarser-grained label classifier. Our first technical contribution is therefore a multi-task learning framework to perform level-wise feature disentanglement, with the aim to separate the adverse effect of coarse feature from fine-grained ones. To further encourage the disentanglement, we then resort to the clever use of gradients to reflect our second observation. Specifically, dur-ing the forward pass only, we ask finer-grained features to participate in the classification of coarser-grained labels via feature concatenation. We, however, constrain the gradient flow to only update the parameters within each multitask head. Our method is generic to any existing FGVC works and experiments show that it yields stronger classifiers across all granularities. Interestingly, our model also delivers state-of-the-art result when evaluated on the traditional FGVC setting, while not introducing any additional parameters.</p><p>Our contributions are as follows: (i) we re-envisage the problem setting of FGVC, to accommodate the various subjective definitions of "fine-grained", where we advocate for top-bottom traversal of a coarse-to-fine label hierarchy, other than the traditional single-label classification; (ii) we discover important insights on the inherent coarse-fine hierarchical relationship to drive our model design, and (iii) we show by disentangling coarse-level feature learning with that of fine-grained, state-of-the-art performances can be achieved both on our new problem, and on the traditional problem of FGVC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Fine-grained image classification Deep learning has emerged as powerful tool that led to remarkable breakthroughs in FGVC <ref type="bibr" target="#b52">[53,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b58">59,</ref><ref type="bibr" target="#b21">22]</ref>. Compared with generic image recognition task <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b42">43]</ref>, FGVC requires a model to pay special attention on the very subtle and local image regions <ref type="bibr" target="#b49">[50,</ref><ref type="bibr" target="#b4">5]</ref>, which are usually hard to notice in human eyes. A major stream of FGVC works thus undergoes two stages by first adopting a localisation subnetwork to localise key visual cues and then a classification subnetwork to perform label prediction. Earlier works on localisation module rely heavily on additional dense part/bounding box annotations to perform detection <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b3">4]</ref>, and gradually move towards weakly supervised setting that only requires image labels <ref type="bibr" target="#b49">[50,</ref><ref type="bibr" target="#b4">5]</ref>. Relevant techniques including unsupervised detection/segmentation, utilisation of deep filters and attention mechanism have been proposed to guide the extraction of the most discriminative image regions <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b20">21]</ref>. Another line of FGVC research focuses on end-to-end feature encoding <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b37">38]</ref>. This saves the effort of explicit image localisation but asks for extra effort to encourage feature discriminability, e.g., high-order feature interactions <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b55">56]</ref>. In this paper, we study a different setting for FGVC that generates multiple output labels at different granularities for an image. Multi-task learning Multi-task learning (MTL) aims to leverage the common information among tasks to improve the generalisability of the model <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b57">58]</ref>. Under the context of deep learning, MTL translates to designing and optimising networks that encourage shared representations under multi-task supervisory signals. There are two types   <ref type="table" target="#tab_1">Table 1</ref>: Human preference between labels at different granularity on CUB-200-2011 bird dataset.</p><p>of parameter sharing. The hard way is to divide the parameter set into shared and task-specific operators <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b8">9]</ref>. In soft parameter sharing, however, each task is assigned its own set of parameters and further regularisation technique are introduced to encourage cross-task talk <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b14">15]</ref>. Joint learning of multiple tasks is prone to negative transfer if the task dictionary contains unrelated tasks <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b18">19]</ref>. This problem triggers another line of MTL research with numerous solutions proposed, including reweighing the individual task loss <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b36">37]</ref>, tailoring task-specific gradient magnitudes <ref type="bibr" target="#b8">[9]</ref> and disentangling features between irrelevant tasks <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b53">54]</ref>. We approach the multi-task learning in FGVC following a similar underlying motivation -by identifying impacts of transfer between label predictions at different granularities. More specifically, we propose a novel solution to simultaneously reinforce positive and mitigate negative task transfer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Human Study</head><p>To inform the practical necessity of our multiple crossgranularity label setting, we conduct a human study <ref type="bibr" target="#b15">[16]</ref> on the CUB-200-2011 bird dataset. This is in order to show (i) single fine-grained label generated by existing FGVC models does not meet the varying subjective requirements for label granularity in practice; (ii) multiple label outputs covering a range of granularity are able to bridge the perceived gaps amongst different populations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data &amp; Participant Setup</head><p>CUB-200-2011 is a bird dataset commonly used by the FGVC community. It contains 11, 877 images each labelled as a fine-grained bird species by the domain expert. We extend it by adding two new hierarchy levels on top of the species with reference to Wikipedia pages, i.e., identifying the family and order name for a bird image. This makes each image annotated with three labels at different granularity, in an increasing fineness level from order to species. We performed an initial test amongst 200 participants across different ages, genders and education levels, to find out their familiarity with birds. We discover that there exists a considerable "long tail" problem in their distribution of scores -there are naturally less bird experts. This motivates us to manually filter for a population that serves as a better basis for statistical analysis. We therefore sample 50 participants from the original 200 and encourage the distribution of their expertise (scores) to follow a Gaussian-like shape. We then divide them into 5 groups ([group 1, group 2, ..., group 5]) based on their scores, where a higher group id corresponds to a population of better domain knowledge. These 50 participants are included for the task below.</p><p>Experiment setting Designing experiments to validate people's preference on one single label across all granularities is straightforward. But it requires extra consideration for making comparative choices between single and multiple labels. For example, it would not be ideal if we show participants an image with two options of single and multiple labels, since people are naturally biased towards multiple labels as they contain more information <ref type="bibr" target="#b39">[40]</ref>. We therefore design a two-stage experiment, with both stages showing a participant the same image but with different questions.  <ref type="bibr">[B]</ref> no Note that participants selecting option D in stage 1 will be directly guided to the next image, skipping stage 2 all to-</p><formula xml:id="formula_0">Disentanglement 1 2 3 1 (·) 2 (·) 3 (·) 1 (·) 2 (·) 3 (·) 1 2 3 1 (·) 2 (·) 3 (·) 1 (·) 2 (·) 3 (·) 1 2 3 Reinforcement ℱ(·) Label_2 Label_1</formula><p>Label_3 From coarse to fine Forward passing with BP Forward passing without BP </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>gether.</head><p>Results We select 1000 images from CUB-200-2011 and from which, a set of random 100 images is assigned to each participant. Images received less then three responses are excluded for statistical significance. We analyse the results as follows: Your label is not mine <ref type="table" target="#tab_1">Table 1</ref> shows the percentage of each option being selected in Stage 1. We can see that (i) participants have varying demands for label granularity; and (ii) The single fine-grained labels (Species option) optimised by existing FGVC models only constitute 36.4% of participant choices in our experiment, while leaving the rest 59.6% (order + family) potentially catered for under a multi-label setting. Multiple labels work In <ref type="figure" target="#fig_2">Figure 2</ref>(a), we show the distribution of preference between single and multiple labels in the second stage. It can be seen that no matter what label (excluding "None") is chosen in the first stage, the majority of participants turn to embrace multiple labels. This is especially true for participants once selecting species as their single choice, who are the target audience under traditional FGVC setting, and yet still consider multiple crossgranularity labels a better way to interpret an image. Further analysis <ref type="figure" target="#fig_2">Figure 2</ref>(b) and (c) further show how populations with different familiarity levels with birds lead to different choices in stage 1 and stage 2 respectively. We can see that (i) participants with more domain knowledge (e.g., group 4) tend to choose finer-grained single labels while amateurs (e.g., group 1) prefer more interpretable coarser-grained counterparts; (ii) choices under multiple labels have greatly converged regardless of the gaps of domain knowledge. In summary, it is hard to have one level of label granularity that caters to every participant. Multiple cross-granularity labels, however, are found to be meaningful to the many.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Methodology</head><p>Conclusions from our human study motivate us to go beyond the single label output as found in most existing FGVC works, and move towards generating multigranularity labels. This makes our new setting fall naturally under the multi-task learning framework. Our first goal is to investigate the impact of transfer between label prediction tasks at different granularities. We next build on the insight gained and propose a simple but effective solution that improves the accuracy of label prediction at all granularities. A schematic illustration of our model is shown in <ref type="figure" target="#fig_3">Figure 3</ref>. Definition Suppose for each image x, we have one finegrained label y K from the existing FGVC dataset. To tailor it for our new FGVC setting, we build upon y K to form (K − 1) label hierarchies by finding its superclasses in the Wikipedia pages. This gives us a re-purposed dataset where each image x is annotated with a chain of K labels defined across different granularities, y 1 , y 2 , ..., y k , ..., y K . We denote the number of categories within each label granularity as C 1 , C 2 , ..., C k , ..., C K , so that y k is a one-hot vector of length C k . Given any CNN-based network backbone F(·),</p><p>We feed x as input to extract its feature embedding f = F(x). Our goal is then to correctly predict labels across K independent classifiers, G 1 (·), G 2 (·), ..., G k (·), ..., G K (·) based on f , i.e.,ŷ k = y k , whereŷ k = G k (f ). Our optimisation objective is K independent cross-entropy loss K k=1 L CE (ŷ k , y k ), and during inference, we take the max- </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Cooperation or Confrontation?</head><p>To explore the transfer effect in the joint learning of multi-granularity labels, we design an image classification task for predicting two labels at different granularities, i.e., K = 2. We form our train/test set from CUB-200-2011 bird dataset and assign each image with two labels at order and family level. During training, we introduce two weights as hyperparameters to control the relative importance of each task. This is formulated as:</p><formula xml:id="formula_1">αL CE (ŷ 1 , y 1 ) + βL CE (ŷ 2 , y 2 )<label>(1)</label></formula><p>where a larger value of α and β then prioritise feature learning towards predicting coarse-grained and fine-trained labels respectively. <ref type="figure" target="#fig_4">Figure 4</ref>(a) shows that by keeping α = 1.0 and gradually increasing the value of β from 0.0 to 1.0, coarse-grained classifier is constantly reinforced when the features is optimised towards fineness. This is in a stark contrast with <ref type="figure" target="#fig_4">Figure 4</ref>(b) where the performance of fine-grained classifier becomes consistently worse with the increasing proportions of coarse-level features. This provides compelling evidence to the discovery we mentioned earlier: coarse-level label prediction in fact hurts fine-grained feature learning, yet fine-level feature betters the learning of coarse-level classifiers. Such finding is also intuitively understandable because models optimised towards finer-grained recognition are forced to interpret and analyse more local and subtle discriminative regions. They thus comprise additional useful information for coarse-grained classifiers as well. In comparison, features optimised for predicting coarse-grained labels are less likely to generalise.</p><p>To provide further proof, we visualise the feature embeddings learned under four weighting strategies using t-SNE, i.e., {α = 1, β = 0}, {α = 1, β = 1}, {α = 0, β = 1}, {α = 1, β = 1}. Same conclusions still hold. The decision boundaries for coarse-grained label classifiers become more separated with the help of finer-grained features, while finegrained classifiers are getting worse in this sense given the increasing involvement of coarser-grained features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Disentanglement and Reinforcement</head><p>Observations in Section 4.1 suggests that there involves both positive and negative task transfer in multi-granularity label predictions. This leads to our two technical considerations: (i) To restrain from the negative transfer between label predictions at different granularity, we first explicitly disentangle the decision space by constructing granularityspecific classification heads. (ii) We then implement the potential of positive transfer by allowing fine-grained features to participate in the coarse-grained label predictions and make smart use of gradients to enable better disentanglement.</p><p>Specifically, We first split f into K equal parts, with each representing a feature f k independently responsible for one classifier G k (·). To allow finer-grained features in jointly predicting a coarse-grained label y k , we concatenate feature f k and all the other finer features f k+1 , f k+2 ,...,f K as input to the classifier G k (·). One issue remains unsolved. While we have adopted finer-grained features to improve coarse-grained label predictions, this risks the fact that features belonging to fine-grained classifiers will be biased towards coarse-grained recognition during model optimisation and undermines our efforts on disentanglement. We therefore introduce a gradient controller Γ(·). That is during the model backward passing stage, we only propagate the gradients flow of one classifier along its own feature di-mensions and stop other gradients via Γ(·). This gives us final representation of predicting a label:</p><formula xml:id="formula_2">y k = G k (CON CAT (f k , Γ(f k + 1), ..., Γ(f K ))) (2)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experimental Settings Datasets</head><p>We evaluate our proposed method on three widely used FGVC datasets. While some dataset only offers one fine-grained label for each of its images, we manually construct a taxonomy of label hierarchy by tracing their parent nodes (superclasses) in Wikipedia pages. Details are as follows. (i) CUB-200-2011 <ref type="bibr" target="#b41">[42]</ref> is a dataset that contains 11, 877 images belonging to 200 bird species. We re-organise this dataset into three-level label hierarchy with 13 orders (e.g., "Passeriformes" and "Anseriformes"), 38 families (e.g., "Icteridae" and "Cardinalidae" ) and 200 species (e.g., "Brewer Blackbird" and "Red winged Blackbird"). (ii) FGVC-Aircraft <ref type="bibr" target="#b28">[29]</ref> is an aircraft dataset with 10, 000 images covering 100 model variants. It comes with three-level label hierarchy with 30 makers (e.g., "Boeing" and "Douglas Aircraft Company"), 70 families (e.g.," Boeing 767"," Boeing 777"), and 100 models (e.g., "767-200", "767-300"), which we directly adopt for our setting. (iii) Stanford Cars <ref type="bibr" target="#b24">[25]</ref> contains 8, 144 car images categorised by 196 car makers. We re-organise this dataset into two-level label hierarchy with 9 car types (e.g., "Cab" and "SUV") and 196 specific models (e.g., "Cadillac Escalade EXT Crew Cab 2007" and "Chevrolet Avalanche Crew Cab 2012"). We follow the standard train/test splits as laid out in the original datasets. We do not use any bounding box/part annotations in all our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Implementation details</head><p>For fair comparisons, we adopted ResNet50 pre-trained on ImageNet as our network backbone and resize each input image to 224×224 throughout the experiments unless otherwise specified. We set the number of hidden units in f as 512 when a single model is asked to predict one label only, and 600 when that is adapted for multiple labels. To deal with the imbalance between ImageNet pre-trained convolutional layers and newly added fully-connected layers in the classification heads, we adopt different learning rates starting from 0.01 and 0.1 respectively. Common training augmentation approaches including horizontal flipping and random cropping, as well as colour jittering are applied. We train every single experiment for 100 epochs with weight decay value as 5 × 10 −4 . MomentumOptimizer is used with momentum value 0.9 throughout. The code will be made publicly accessible. Evaluation metrics Following community convention, FGVC performance is quantified by acc, the percentage of images whose labels are correctly classified. We use avg acc to calculate the mean of the performance across label granularities. Each experiment is run three times. The mean and standard deviation of the results obtained over three trials are then reported. Baselines As our focus is on how to adapt an image classification model with single label output into multiple ones, our baselines comprise alternative multi-label classification models. To show our proposed solution is generic to any existing FGVC frameworks, we also include three other baselines by replacing the backbone of our model with different advanced FGVC-specific components. Vanilla single: this corresponds to one single shared network backbone with multiple classification heads appended to the end. Vanilla multi adopts one independent network backbone for each label prediction. Ours single improves upon Vanilla single aiming to disentangle the decision space in multi-granularity label predictions. This is achieved by splitting f into equal number of segments as that of classifiers, with each independently responsible for one classifier at one granularity. Ours advances Ours single in better feature disentanglement by reinforcing coarse-grained classifiers with fine-grained features. Finally, Ours MC <ref type="bibr" target="#b4">[5]</ref>, Ours NTS <ref type="bibr" target="#b49">[50]</ref>, Ours PMG <ref type="bibr" target="#b11">[12]</ref>, represent three means of training our proposed method on top of state-of-the-art FGVC frameworks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Results and Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Comparison with Baselines</head><p>Our experimental discovery coincides well with our intuition that compared with classifying one fine-grained label, there exists additional issue that needs to be taken care of in multi-granularity label predictions. Our proposed method can not only effectively solve this problem, but also generic in terms of the network backbone used. Belows is more detailed analysis of the results with reference to <ref type="table">Table 2</ref>. Is our model effective in solving FGVC problem with multi-granularity label output?</p><p>Yes. It is evident that the proposed model (Ours) outperforms all other baselines under the metric of avg acc on all three datasets. Furthermore, the consistent performance gain from Our MC to Ours NTS, and to Ours PMG tells one important message: our solution not only supports easy drop-in to existing FGVC models, but also does not undermine their original functionality when adapted. Are the proposed technical contributions appropriate? Yes. The significant gap between Vanilla single and Ours single confirms the severity of feature entanglement between label granularities -that can be alleviated by simply splitting a feature into several parts with each corresponding to an independent classifier. The proposed Reinforce module (Ours single vs. Ours) is effective in boosting the classification performance at coarse granularity (e.g., order acc and family acc in CUB-200-2011). The fact that it can also achieve higher accuracy on the finest labels (e.g.,  <ref type="table">Table 2</ref>: Comparisons with different baselines for FGVC task under multi-granularity label setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>species acc), a task which has not been explicitly designed to improve on, provides direct evidence of how better feature disentanglement is further taking place.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>What does Vanilla multi tell us?</head><p>The performance of Vanilla multi draws our attention. On one hand, its accuracy on the finest label prediction crushes all opponents by significant margins across the datasets. On the other, it performs the worst on classifying coarsest labels. Such contrast, however, echoes our observation that underlies the technical considerations of this paper: finer-grained classifier performs the best when it is portrayed as a single independent task itself, while coarser-level label predictions can benefit significantly from a multi-granularity task setting. Note that since Vanilla multi requires equal number of unshared network backbones as that for classification tasks, it is not a strictly fair comparison in terms of its model capacity. The purpose here is to show solving disentanglement between label prediction at different granularities remains challenging, albeit we have greatly advanced the problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>What does it look like?</head><p>We further carry out model visualisation to demonstrate that classifiers [G 1 , ..., G K ] under Vanilla single and Ours indeed capture different regions of interests that are useful for FGVC, and offer insight on how better disentanglement is taking place. To this end, we adopt Grad-Cam <ref type="bibr" target="#b35">[36]</ref> to visualise the different image supports for each G k by propagating their gradients back to x. It can be seen from the bottom half of <ref type="figure" target="#fig_5">Figure 5</ref> that our classifiers at different hierarchy levels attends to different scales of visual regions -a clear sign of the model's awareness on coarse-fine disentanglement. In contrast, the top half of <ref type="figure" target="#fig_5">Figure 5</ref> shows that Vanilla single appears to focus on similar un-regularised image parts across label granularity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Evaluation on traditional FGVC setting</head><p>Our model can be evaluated for FGVC without any changes -we just need to report classification accuracy for fine-grained labels at the bottom of the hierarchy. However, for fair comparison with other state-of-the-art FGVC works, we also resize image input to a size of 448 × 448. We leave all other implementation settings unchanged, and do not perform grid search for performance gain. The re-  sults are reported in <ref type="table" target="#tab_4">Table 3</ref>. We can see that by building our method upon the backbone of PMG, new state-of-the-art results (Ours PMG) for traditional FGVC setting are gained on CUB-200-2011 and FGVC-Aircraft datasets. Improvements over state-of-the-art on Stanford Cars dataset is less significant. We attribute this to the relatively shallow hierarchy (two levels) on Stanford Cars. Note that we do not introduce any extra parameters when implemented on top of traditional FGVC methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The role of label hierarchy</head><p>To investigate the impact of label hierarchy on the traditional FGVC performance, we compare our manual method of constructing label hierarchy based on Wikipedia pages with two variants, Hierarchical Clustering (Ours HC) and Deep Fuzzy Tree (Ours DFT) <ref type="bibr" target="#b43">[44]</ref>. These are two clustering methods that automatically mine hierarchical structures from data, which mainly differ in how to measure the distance between clusters and whether there are tree structures explicitly modelled. For both methods, we stop the discovery process when three-level label hierarchy has been formed. From the last two rows in <ref type="table" target="#tab_4">Table 3</ref>, the following observations can be made: (i) Manual hierarchies achieves the best performance across all three datasets, suggesting semantically defined parent-child relationships tend to encourage cross granular- </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Discussions</head><p>Here, we offer discussions on some potentially viable future research directions, with the hope to encourage follow up research. Beyond multi-task learning While our MTL framework has shown promise as a first stab, other means of encouraging information exchange/fusion across hierarchy levels can be explored. One possible alternative is via meta learning <ref type="bibr" target="#b19">[20]</ref>. In this sense, rather than learning multi-granularity label prediction task in one shot, we can treat them as a sequence of related tasks optimised over multiple learning episodes. An idea could be that in the inner loop, we find a meta-learner that serves as good initialisation with few gradients away to each task (as per disentanglement). We then ask the outer task-specific learners to quickly adapt from it (as per reinforcement). From classification to retrieval. Formulating the problem of fine-grained visual analysis as a classification task itself underlies certain limitations: the fixed number of labels makes it rigid to be applied in some open-world scenarios <ref type="bibr" target="#b46">[47]</ref>. By projecting images into a common embedding space (as per retrieval) however, we will not only grant the flexibility but also potentially relax the ways of granularity interpretation into model design. Pretending that we were to address the goal of this paper from a retrieval perspective, we can associate label granularity with the model's receptive field -the finer the label, the more local the regions of interest. We can also potentially directly use label granularity as an external knowledge to dynamically parameterise the embedding space (as per hypernetworks <ref type="bibr" target="#b17">[18]</ref>). More importantly, a successfully-trained model now has a chance to learn a smooth interpolation between label granularities, which is of great practical value but infeasible under the formulation of classifiers. Rethinking ImageNet pre-training FGVC datasets remain significantly smaller than modern counterparts on generic classification <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b32">33]</ref>. This is a direct result of the bottleneck on acquiring expert labels. Consequently, almost all contemporary competitive FGVC models rely heavily on pre-training: the model must be fine-tuned upon the pretrained weights of an ImageNet classifier. While useful in ameliorating the otherwise fatal lack of data, such practice comes with a cost of potential mismatch to the FGVC task -model capacity for distinguishing between "dog"' and "cat" is of little relevance with that for differentiating "Giant Ibis" and "flamingo". In fact, our paper argues otherwisethat coarse-level feature learning is best disentangled from that of fine-grained. Recent advances on self-supervised representation learning provide a promising label-efficient way to tailor pre-training approaches for downstream tasks <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b40">41]</ref>. However, its efficacy remains unknown for FGVC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Conclusion</head><p>Following a human study, we re-envisaged the problem of fine-grained visual classification, from the conventional single label output setting, to that of coarse-fine multigranularity label prediction. We discovered important insights on how positive information exchange across granularities can be explored. We then designed a rather simple yet very effective solution following these insights. Extensive experiments on three challenging FGVC datasets validate the efficacy of our approach. When evaluated on the traditional FGVC setting, we also report state-of-the-art results while not introducing any extra parameters. We will release all human study data, and make our code publicly accessible. Last but not least, we hope to have caused a stir, and trigger potential discussions on the very title of this paper -that whether my "Flamingo" should or should not be your "Bird".</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>, Y. Zheng, Z. Ma, and J. Guo are with the Pattern Recognition and Intelligent System Laboratory, School of Artificial Intelligence, Beijing University of Posts and Telecommunications, Beijing 100876, China (e-mail: mazhanyu@bupt.edu.cn). K. Pang and Y.-Z. Song are with SketchX, CVSSP, University of Surrey, London, United Kingdom.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>FlamingoFigure 1 :</head><label>1</label><figDesc>Definition of what is fine-grained is subjective. Your "flamingo" is my "bird".</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Human study on CUB-200-2011 bird dataset. Order, family, species are three coarse-to-fine label hierarchy for a bird image. A higher group id represents a group of people with better domain knowledge of birds, with group 5 interpreted as domain experts. (a) Human preference between single and multiple labels. (b) Impact of human familiarity with birds on single-label choice. (c) Impact of human familiarity with birds on multi-label choice.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>A schematic illustration of our FGVC model with multi-granularity label output. BP: backpropagation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Joint learning of two-granularity labels under different weighting strategy on CUB-200-2011 bird dataset. (a) x-axis: β value that controls the relative importance of a fine-grained classifier; y axis: performance of the coarse-grained classifier. (b) x-axis: α value that controls the relative importance of a coarse-grained classifier; y axis: performance of the fine-grained classifier. imum output probability from each classifier as its label, l k = argmax C kŷ k .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>ity information change. (Ours vs. Ours HC vs. Ours DFT); (ii) Traditional FGVC problem (FT ResNet) benefits from multi-granularity label setting, regardless of what label hi-We highlight the supporting visual regions for classifiers at different granularity of two compared models. Order, Family, Species represent three coarse-to-fine classifiers trained on CUB-200-2011 bird dataset. erarchy is used.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Stage 1 :</head><label>1</label><figDesc>This is a bird. Which one of the labels further defines this bird? You can only choose one option. [A] order name [B] family name [C] species name [D] none of above Stage 2: At stage 1, do you have the impulse to choose more than one label? [A] yes</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>acc specie acc avg acc maker acc family acc model acc avg acc maker acc model acc avg acc Vanilla single 95.38 ± 0.47 87.70 ± 0.79 74.24 ± 0.86 85.77 90.82 ± 1.02 88.73 ± 1.17 86.26 ± 1.37 88.60 95.30 ± 0.11 88.66 ± 0.45 91.98 Vanilla multi 95.13 ± 0.53 89.70 ± 0.13 78.31 ± 0.35 87.71 90.69 ± 0.48 89.23 ± 0.53 88.10 ± 0.10 89.34 95.24 ± 0.20 89.14 ± 0.16 92.19 Ours single 95.63 ± 0.27 88.50 ± 0.15 77.46 ± 0.10 87.50 90.73 ± 0.23 89.39 ± 0.11 87.96 ± 0.27 89.36 95.23 ± 0.09 89.12 ± 0.29 92.18 Ours 96.37 ± 0.16 90.39 ± 0.15 77.95 ± 0.04 88.24 93.04±0.25 90.73 ± 0.19 88.35±0.18 90.71 95.58 ± 0.06 89.66 ± 0.16 92.62 Ours MC 96.58 ± 0.15 90.36 ± 0.07 77.85 ± 0.38 88.26 92.86 ± 0.12 90.74 ± 0.11 88.19 ± 0.11 90.59 95.56 ± 0.17 89.62 ± 0.21 92.59 Ours NTS 96.57±0.07 91.58±0.57 80.45±0.68 89.53 92.48 ± 0.16 90.75±0.07 88.31 ± 0.23 90.51 95.96±0.39 90.64±0.37 93.30 Ours PMG 97.98±0.12 93.50±0.10 82.26±0.13 91.25 94.57±0.10 92.44±0.07 89.62±0.15 92.21 96.42±0.05 91.05±0.15 93.74</figDesc><table><row><cell>CUB-200-2011</cell><cell>FGVC-Aircraft</cell><cell>Stanford Cars</cell></row><row><cell>order acc family</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Performance comparisons on traditional FGVC setting with single fine-grained label output.</figDesc><table /><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Poof: Part-based onevs.-one features for fine-grained categorization, face verification, and attribute estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Belhumeur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Subordinate-level object classification reexamined</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irving</forename><surname>Biederman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suresh</forename><surname>Subramaniam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moshe</forename><surname>Bar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Kalocsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jozsef</forename><surname>Fiser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological research</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Bird species categorization using pose normalized deep convolutional nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grant</forename><surname>Van Horn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1406.2952</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Symbiotic segmentation and part localization for finegrained categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuning</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Lempitsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The devil is in the channels: Mutual-channel loss for fine-grained image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongliang</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifeng</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiyang</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ayan</forename><surname>Kumar Bhunia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhanyu</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Zhe</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Driving scene perception network: Real-time joint detection, depth estimation and semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liangfu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianjun</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In WACV</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Progressive differentiable architecture search: Bridging the depth gap between search and evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingxi</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Destruction and construction learning for fine-grained image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yalong</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Gradnorm: Gradient normalization for adaptive loss balancing in deep multitask networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Badrinarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen-Yu</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICML</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Meshed-memory transformer for image captioning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcella</forename><surname>Cornia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matteo</forename><surname>Stefanini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenzo</forename><surname>Baraldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rita</forename><surname>Cucchiara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Fine-grained visual classification via progressive multi-granularity training of jigsaw patches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruoyi</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongliang</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ayan</forename><surname>Kumar Bhunia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiyang</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Zhe</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhanyu</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Pairwise confusion for finegrained visual classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhimanyu</forename><surname>Dubey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Otkrist</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pei</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramesh</forename><surname>Raskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Farrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikhil</forename><surname>Naik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ECCV</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Learning category-specific dictionary and shared dictionary for finegrained image categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shenghua</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivor Wai-Hung</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Nddr-cnn: Layerwise feature fusing in multi-task cnns by neural discriminative dimensionality reduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiayi</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingbo</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Hedging your bets: Explaining executives&apos; market labeling strategies in nanotechnology. Organization science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nina</forename><surname>Granqvist</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stine</forename><surname>Grodal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><forename type="middle">L</forename><surname>Woolley</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Dynamic task prioritization for multitask learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michelle</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Haque</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">De-An</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serena</forename><surname>Yeung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ECCV</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hypernetworks</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.09106</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Piotr Dollár, and Ross Girshick. Mask R-CNN</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgia</forename><surname>Gkioxari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Hospedales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antreas</forename><surname>Antoniou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Micaelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amos</forename><surname>Storkey</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.05439</idno>
		<title level="m">Meta-learning in neural networks: A survey</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Interpretable and accurate finegrained recognition via region grouping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zixuan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR, 2020</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Attention convolutional binary neural tree for fine-grained visual categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruyi</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Longyin</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Libo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanjun</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianglong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feiyue</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Multi-task learning using uncertainty to weigh losses for scene geometry and semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Kendall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yarin</forename><surname>Gal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Cipolla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In CVPR</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Ubernet: Training a universal convolutional neural network for low-, mid-, and high-level vision using diverse datasets and limited memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iasonas</forename><surname>Kokkinos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">3d object representations for fine-grained categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Stark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV workshops</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Bilinear cnn models for fine-grained visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yu</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aruni</forename><surname>Roychowdhury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhransu</forename><surname>Maji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Using coarse label constraint for fine-grained visual classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaohao</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuexian</forename><surname>Zou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MMM</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Multi-task collaborative network for joint referring expression comprehension and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gen</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiyi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoshuai</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liujuan</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenglin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rongrong</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Fine-grained visual classification of aircraft</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhransu</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juho</forename><surname>Kannala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Esa</forename><surname>Rahtu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">B</forename><surname>Blaschko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Vedaldi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1306.5151.6</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Cross-stitch networks for multi-task learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishan</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Shrivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martial</forename><surname>Hebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Predicting entry-level categories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vicente</forename><surname>Ordonez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tamara</forename><forename type="middle">L</forename><surname>Berg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Solving mixed-modal jigsaw puzzle for fine-grained sketch-based image retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiyue</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Zhe</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Moment matching for multi-source domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingchao</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qinxun</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xide</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zijun</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Object-part attention model for fine-grained image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxin</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangteng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Image Processing</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Latent multi-task architecture learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Ruder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joachim</forename><surname>Bingel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabelle</forename><surname>Augenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Søgaard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Grad-cam: Visual explanations from deep networks via gradient-based localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ramprasaath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Selvaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Cogswell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramakrishna</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Vedantam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Batra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ayan</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Badrinarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Rabinovich</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.08028</idno>
		<title level="m">Gradient adversarial training of neural networks</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Fine-grained recognition: Accounting for subtle differences between similar classes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guolei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hisham</forename><surname>Cholakkal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salman</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fahad</forename><surname>Shahbaz Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ling</forename><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Multiattention multi-class constraint for fine-grained image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuchen</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Errui</forename><surname>Ding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ECCV</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A tutorial on pilot studies: the what, why and how</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lehana</forename><surname>Thabane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinhui</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rong</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">;</forename><surname>Lorena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rios</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reid</forename><surname>Robson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marroon</forename><surname>Thabane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lora</forename><surname>Giangregorio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles H</forename><surname>Goldsmith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC medical research methodology</title>
		<imprint>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
	<note>Afisi Ismaila</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Self-supervised learning of video-induced visual invariances</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Tschannen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josip</forename><surname>Djolonga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marvin</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aravindh</forename><surname>Mahendran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Houlsby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sylvain</forename><surname>Gelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Lucic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Pietro Perona, and Serge Belongie. The caltech-ucsd birds-200-2011 dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Catherine</forename><surname>Wah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Welinder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Caltech</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Dual super-resolution learning for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yousong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Shan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Deep fuzzy tree for large-scale hierarchical visual classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qinghua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengfei</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linhao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingxu</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><forename type="middle">M</forename><surname>Garibaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianling</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Fuzzy Systems</title>
		<imprint>
			<biblScope unit="issue">7</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Learning a discriminative filter bank within a cnn for fine-grained recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaming</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Vlad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry S</forename><surname>Morariu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Adversarial fine-grained composition learning for unseen attribute-object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muli</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianglong</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Deep learning for fine-grained image analysis: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiu-Shen</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quan</forename><surname>Cui</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.03069</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Leveraging fine-grained labels to regularize fine-grained visual classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junfeng</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheyuan</forename><surname>Ding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCMS</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">The application of two-level attention models in deep convolutional neural network for fine-grained image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianjun</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuiyuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaxing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxin</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Learning to navigate for fine-grained classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ze</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiange</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiqiang</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liwei</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">A codebookfree and annotation-free approach for fine-grained image categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bangpeng</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gary</forename><surname>Bradski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Picking deep filter responses for finegrained image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaopeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongkai</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wengang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiyao</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Weakly supervised fine-grained categorization with part-based image representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiu-Shen</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfei</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiangbo</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Viet-Anh</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh</forename><forename type="middle">N</forename><surname>Do</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">A modulation module for multi-task learning with applications in image retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyun</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoxiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohui</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodan</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ECCV</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Learning multi-attention convolutional neural network for finegrained image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heliang</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianlong</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiebo</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Learning deep bilinear transformation for fine-grained image representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heliang</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianlong</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng-Jun</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiebo</forename><surname>Luo</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Looking for the devil in the details: Learning trilinear attention sampling network for fine-grained image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heliang</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianlong</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng-Jun</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiebo</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Pattern-structure diffusion for multi-task learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ling</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaoqun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Learning attentive pairwise interaction for fine-grained classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peiqin</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yali</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Qiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI, 2020</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
