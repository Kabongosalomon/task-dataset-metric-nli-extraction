<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SCUT-FBP5500 ‡ : A Diverse Benchmark Dataset for Multi-Paradigm Facial Beauty Prediction</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingyu</forename><surname>Liang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">South China University of Technology</orgName>
								<address>
									<postCode>510641</postCode>
									<settlement>Guangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luojun</forename><surname>Lin</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">South China University of Technology</orgName>
								<address>
									<postCode>510641</postCode>
									<settlement>Guangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lianwen</forename><surname>Jin</surname></persName>
							<email>lianwen.jin@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="institution">South China University of Technology</orgName>
								<address>
									<postCode>510641</postCode>
									<settlement>Guangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duorui</forename><surname>Xie</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">South China University of Technology</orgName>
								<address>
									<postCode>510641</postCode>
									<settlement>Guangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengru</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">South China University of Technology</orgName>
								<address>
									<postCode>510641</postCode>
									<settlement>Guangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">SCUT-FBP5500 ‡ : A Diverse Benchmark Dataset for Multi-Paradigm Facial Beauty Prediction</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>‡ Dataset Download URL: https://github.com/HCIILAB/SCUT-FBP5500-Database-Release</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T17:38+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Facial beauty prediction (FBP) is a significant visual recognition problem to make assessment of facial attractiveness that is consistent to human perception. To tackle this problem, various data-driven models, especially state-of-the-art deep learning techniques, were introduced, and benchmark dataset become one of the essential elements to achieve FBP. Previous works have formulated the recognition of facial beauty as a specific supervised learning problem of classification, regression or ranking, which indicates that FBP is intrinsically a computation problem with multiple paradigms. However, most of FBP benchmark datasets were built under specific computation constrains, which limits the performance and flexibility of the computational model trained on the dataset. In this paper, we argue that FBP is a multi-paradigm computation problem, and propose a new diverse benchmark dataset, called SCUT-FBP5500, to achieve multi-paradigm facial beauty prediction. The SCUT-FBP5500 dataset has totally 5500 frontal faces with diverse properties (male/female, Asian/Caucasian, ages) and diverse labels (face landmarks, beauty scores within <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b4">5]</ref>, beauty score distribution), which allows different computational models with different FBP paradigms, such as appearance-based/shape-based facial beauty classification/regression model for male/female of Asian/Caucasian. We evaluated the SCUT-FBP5500 dataset for FBP using different combinations of feature and predictor, and various deep learning methods. The results indicates the improvement of FBP and the potential applications based on the SCUT-FBP5500.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Assessing facial beauty seems natural for human being, but an absolute definition of facial beauty remains elusive. Recently, facial beauty prediction (FBP) have attracted evergrowing interest in the pattern recognition and machining learning communities <ref type="bibr" target="#b7">[8]</ref>- <ref type="bibr" target="#b9">[10]</ref>, which aims to achieve automatic human-consistent facial attractiveness assessment by a computational model. It has application potential in facial makeup synthesis/recommendation <ref type="bibr" target="#b9">[10]</ref>- <ref type="bibr" target="#b11">[12]</ref>, content-based image retrieval <ref type="bibr" target="#b15">[16]</ref>, aesthetic surgery <ref type="bibr" target="#b9">[10]</ref>, or face beautification <ref type="bibr" target="#b3">[4]</ref>- <ref type="bibr" target="#b6">[7]</ref>.</p><p>From the computational perspective, FBP is still a challenging problem. It is involved with the formulation of visual  representation and predictor for the abstract concept of facial beauty. To tackle this problem, various data-driven models, were introduced into FBP. One line of the works follows the classic pattern recognition process, which constructs the FBP system using the combination of the hand-crafted features and the shallow predictors. The related hand-crafted feature derived from visual recognition includes the geometric features, like the geometric ratios and landmark distances <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b18">[19]</ref>- <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b22">[23]</ref>, and the texture features, like the Gabor-/SIFT-like features <ref type="bibr" target="#b23">[24]</ref>- <ref type="bibr" target="#b25">[26]</ref>. Then, a shallow FBP predictoris trained by the extracted feature in a statistical manner. Another line of works is advanced by the reviving of neural networks, especially the stat-of-the-art deep learning <ref type="bibr" target="#b13">[14]</ref>. The hierarchial structure of the deep learning model allows to build an end-to-end FBP system that automatically learns both the representation and the predictor of facial beauty simultaneously from the data. Many works indicate that FBP based on deep learning is superior to the shallow predictors with hand-crafted facial feature <ref type="bibr" target="#b0">[1]</ref>- <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b28">[29]</ref>, <ref type="bibr" target="#b29">[30]</ref>, <ref type="bibr" target="#b32">[33]</ref>. Most of current FBP models are data-driven, which makes benchmark dataset become one of the essential elements for FBP. There have been many works of the benchmark datasets <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b21">[22]</ref>- <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b29">[30]</ref>, <ref type="bibr" target="#b32">[33]</ref>- <ref type="bibr" target="#b34">[35]</ref> involved with FBP, but most of these datasets focus on a specific problem with specific computation constrains, as shown in <ref type="table" target="#tab_0">Table I</ref>. Yan et al. <ref type="bibr" target="#b23">[24]</ref> regarded FBP as a ranking problem, and proposed a dataset with low-resolution images gathered from social networks. Fan et al. <ref type="bibr" target="#b22">[23]</ref> focused on the geometry analysis of FBP and proposed a dataset containing computergenerated faces with different facial proportions. The Northeast China database <ref type="bibr" target="#b21">[22]</ref>, Shanghai database <ref type="bibr" target="#b20">[21]</ref>, Hot-Or-Not database <ref type="bibr" target="#b31">[32]</ref>, <ref type="bibr" target="#b32">[33]</ref>, AVA database <ref type="bibr" target="#b15">[16]</ref> and re-sampled face subset of AVA database <ref type="bibr" target="#b33">[34]</ref> are large-scale databases involved with FBP, where the Northeast China <ref type="bibr" target="#b21">[22]</ref> and Shanghai database <ref type="bibr" target="#b20">[21]</ref> are limited for geometric facial beauty analysis without attractiveness ratings; Hot-Or-Not database <ref type="bibr" target="#b31">[32]</ref>, <ref type="bibr" target="#b32">[33]</ref> only focuses on the appearance-based FBP; and the AVA database <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b33">[34]</ref> is originally designed for aesthetic analysis of entire images but not the facial attractiveness. In our previous work, Xie et al. <ref type="bibr" target="#b0">[1]</ref> published a SCUT-FBP benchmark dataset, which has led to many FBP models <ref type="bibr" target="#b0">[1]</ref>- <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b36">[37]</ref>, especially the hierarchial CNN-based FBP models with the state-of-the-art deep learning <ref type="bibr" target="#b0">[1]</ref>- <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b36">[37]</ref>. Despite the prevalent usage of the SCUT-FBP, it only contains 500 Asian Female faces, which may limit the performance of the datademanded model for FBP.</p><p>We find that FBP have been formulated the recognition of facial beauty as a specific supervised learning problem of classification <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b29">[30]</ref>, regression <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b28">[29]</ref>, <ref type="bibr" target="#b37">[38]</ref> or ranking <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b36">[37]</ref>. It indicates that FBP is intrinsically a computation problem with multiple paradigms. Previous databases built under specific computation constrains would limit the performance and flexibility of the computational model trained on the dataset, and it is difficult to compare different models derived from the dataset with specific computation paradigm. Therefore, this paper argues that FBP is a multi-paradigm computation problem, and proposes a new diverse benchmark dataset, called SCUT-FBP5500, to achieve multi-paradigm facial beauty prediction.</p><p>The SCUT-FBP5500 dataset has totally 5500 frontal faces with diverse properties (male/female, Asian/Caucasian, ages) and diverse labels (face landmark, beauty score, beauty score distribution), which allows different computational model with different FBP paradigms, such as appearance-based/shapebased facial beauty classification/regression/ranking model for male/female with Asian/Caucasian. Furthermore, the diverse faces with beauty scores gathered from 60 different labelers can lead to many interesting research, such as cross-culture facial beauty analysis, personalized FBP <ref type="bibr" target="#b35">[36]</ref>, or automatic face beautification [4]- <ref type="bibr" target="#b6">[7]</ref>. Both shallow prediction model with hand-crafted feature and the state-of-the-art deep learning models were evaluated on the dataset, and the results indicates the improvement of FBP and the potential applications by the SCUT-FBP5500.</p><p>The main contributions of this paper can be summarized as following:</p><p>1) Dataset. We propose a new large-scale SCUT-FBP5500 benchmark dataset that has totally 5500 frontal faces with diverse properties and diverse labels, which allows construction of FBP models with different paradigms. 2) Benchmark Analysis. We analyze the samples, score labels, labelers and facial landmarks of the SCUT-FBP5500 statistically, and the visualization of the data illustrates the properties of the SCUT-FBP5500. 3) Facial Beauty Prediction Evaluation. Both shallow prediction model with hand-crafted feature and deep learning models are trained on the SCUT-FBP5500 for evaluation, and the results indicates the improvement of FBP based on the proposed dataset with better diversity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. CONSTRUCTION OF SCUT-FBP5500 DATASET</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Face Images Collection</head><p>The SCUT-FBP5500 Dataset contains 5500 frontal, unoccluded faces aged from 15 to 60 with neutral expression. It can be divided into four subsets with different races and gender, including 2000 Asian females, 2000 Asian males, 750 Caucasian females and 750 Caucasian males. Most of the images of the SCUT-FBP5500 were collected from Internet, where some portions of Asian faces were from the DataTang <ref type="bibr" target="#b38">[39]</ref> and some Caucasian faces were from the 10k US Adult database <ref type="bibr" target="#b39">[40]</ref>.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Facial Beauty Scores and Facial Landmarks</head><p>All the images are labeled with beauty scores ranging from <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b4">5]</ref> by totally 60 volunteers aged from 18-27 (average 21.6), where the beauty score 5 means most attractive and so on. We developed a web-based GUI system to obtain the facial beauty scores. The labeling system was deployed on the Ali Cloud, and the labeling tasks are distributed to each volunteer in crowdsourcing manners. The four subset, Asian male/female and Caucasian male/female, are labeled separately, where each face of the subset are randomly shown to the volunteer. Then, the volunteer are asked to select the beauty scores within <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b4">5]</ref> for the face. To reduce the variance in the labeling process, about 10% faces recurred randomly. If the correlation coefficient of the two beauty score of the same faces is less than 0.7, the volunteer would be asked to rate this face once more to decide the final score.</p><p>To allow geometric analysis of facial beauty, 86 facial landmarks are located to the significant facial components of each images, such as eyes, eyebrows, nose and mouth. A GUI landmarks location system is developed, where the original location of the landmarks are initialized by the active shape model (ASM) trained by the SCUT-FBP dataset. Then, the detected landmarks by ASM are modified manually by volunteers to ensure the accuracy. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. BENCHMARK ANALYSIS OF THE SCUT-FBP5500</head><p>We made benchmark analysis of the beauty scores, labelers and face landmarks of the SCUT-FBP5500 with different gender and races, including Asian female (AF), Asian male (AM), Caucasian female (CF) and Caucasian male (CM).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Distribution of Beauty Scores</head><p>We visualize the distribution of the beauty scores of AF, AM, CF and CM, respectively. To obtain better visualization, we preprocess the data and filter the outliers of the beauty scores. We regard the average score of all the 60 labelers as the ground-truth. If the score of specific labeler for the same face differs from the ground-truth over 2, the score is treated as outlier and is removed from the distribution visualization.  The number and portion of the outliers in the four subset are listed in <ref type="table" target="#tab_0">Table II</ref>, and the small portion of outlier indicate the reliability of the labeling process for beauty score.</p><p>Since the outlier portion of the beauty score is tiny, the distributions of the original data and the preprocessed data is mostly similar. Therefore, we visualized the score distribution of the SCUT-FBP5500 using the preprocessed data for all the four subset, respectively. Two distribution fitting schemes are used: one is Gaussian fitting (yellow curve), the other is piecewise fitting (red and blue curve), as shown in <ref type="figure" target="#fig_2">Fig. 2</ref>. The results indicates that the beauty scores of all the four subset can be approximately fitted by a mixed distribution model with two Gaussian components.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Standard Deviation of Beauty Scores</head><p>We calculate the standard deviation of the scores gathered from different labelers to the ground-truth, and illustrate the results as histogram in <ref type="figure">Fig. 3</ref> and as box figure in <ref type="figure">Fig. 4</ref>. We observe that the distribution of standard deviations is similar to Gaussian distribution, and most of the standard deviations are within a reasonable range of [0.6, 0.7].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Correlation of Male/Female Labelers</head><p>In this subsection, we investigate the correlation between the male and female Asian labelers for the beauty scores, as shown in <ref type="table" target="#tab_0">Table III</ref> and <ref type="figure">Fig. 5</ref>. We observe that the correlation of Asian faces is persistently larger than Caucasian. It is consistent to the psychological research that human have better facial beauty perception for the faces from the same race.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. PCA Analysis of Facial Geometry</head><p>We visualize the 86-points face landmarks of the dataset using principle component analysis (PCA). <ref type="figure" target="#fig_4">Fig. 6</ref> illustrate the mean and the five first principle component of the facial geometry of Asian female (AF) and Asian male (AM), where the landmarks data of Caucasian share similar distribution to Asian faces. We observe that the face shape is one of the main component influence the face geometry of beauty, which is consistent to related psychological research and previous works in <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b21">[22]</ref> IV. FBP EVALUATION VIA HAND-CRAFTED FEATURE AND SHALLOW PREDICTOR This section, we evaluate the SCUT-FBP5500 using the hand-crafted feature with shallow predictor, while the next section introduce some state-of-the-art deep learning model to achieve FBP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Geometric Feature with Shallow Predictor</head><p>We extract a 18-dimensional ratio feature vector from the faces and formulate FBP based on different regression models, such as the linear regression (LR), Gaussian regression (GR), and support vector regression (SVR). Comparison were performed for Caucasian female/male and Asian female/male subsets, and the performance of different model are measured using pearson correlation coefficient (PC) <ref type="bibr" target="#b14">[15]</ref>, maximum absolute error (MAE) and root mean square error (RMSE) after 10 folds cross validation. The results are listed in <ref type="table" target="#tab_0">Table IV and  Table V</ref>, which can be regarded as a baseline for the geometric analysis of FBP. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Appearance Feature with Shallow Predictor</head><p>We extract 40 Gabor feature maps from every original image in five directions and eight angles. Then, we obtain the appearance feature of FBP using two different sampling schemes that extracts some component of the Gabor feature maps as following:</p><p>• Sample 86-keypoints from each 40 Gabor feature maps to obtain a 3340-dimensional feature vector, as shown in the right sub-figure of <ref type="figure">Fig. 7</ref>; • Use 64UniSample to obtain a 2560-dimensional feature vector, as shown in the left sub-figure of <ref type="figure">Fig. 7</ref>. Finally, we use PCA to reduce the extracted feature dimension before we train the predictor. The results of the appearancebased shallow predictors for all the data are shown in <ref type="table" target="#tab_0">Table VI</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. FBP EVALUATION VIA DEEP PREDICTOR</head><p>We evaluate three recently proposed CNN models with different structures for FBP, including AlexNet <ref type="bibr" target="#b40">[41]</ref>, ResNet-18 <ref type="bibr" target="#b41">[42]</ref> and ResNeXt-50 <ref type="bibr" target="#b42">[43]</ref>. All these CNN models are trained by initializing weights using networks pre-trained on the ImageNet dataset. The evaluation of were performed under two different experiment settings as following:</p><p>1) The models were trained and tested using 5-fold cross validation, which means each fold containing 20% samples (1100 images). The accuracy of each fold and the average of all the 5 fold are shown in <ref type="table" target="#tab_0">Table VII</ref>. 2) The models were trained using 60% samples (3300 images), and tested with the rest 40% (2200 images). The results are shown in <ref type="table" target="#tab_0">Table VIII</ref>. The results illustrates that the deepest CNN-based ResNeXt-50 model <ref type="bibr" target="#b42">[43]</ref> obtains the best performance comparing to the ResNet-18 and AlexNet in both the experiment setting. It can be observed that all the deep CNN model are superior to the shallow predictor with hand-crafted geometric feature in <ref type="table" target="#tab_0">Table V or appearance feature in Table VI</ref>. It indicates the effectiveness and powerfulness of the end-to-end feature learning deep model for FBP.</p><p>Comparing the results of <ref type="table" target="#tab_0">Table VII and Table VIII</ref>, we also find that the accuracy of all the 5-fold cross validation is slightly higher than the results of the split of 60% training and 40% testing. One of the reasons may be due to the amounts and diversity of the training samples, since the 5-fold cross validation use 80% samples to train the models. This observation indicates that the data augmentation techniques may further improve the performance of the deep FBP model, which merits exploring in the future.</p><p>VI. CONCLUSION In this paper, we introduce a new diverse benchmark dataset, called SCUT-FBP5500, to achieve multi-paradigm facial beauty prediction. The SCUT-FBP5500 dataset has totally 5500 frontal faces with diverse properties (male/female, Asian/Caucasian, ages) and diverse labels (face landmarks, beauty scores within <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b4">5]</ref>, beauty score distribution). Benchmark analysis have been made for the beauty scores and landmarks in SCUT-FBP5500, and the visualization of the data shows the statistical properties of the dataset. Since the SCUT-FBP5500 is designed for multi-paradigm, it can be adapted to different FBP models for different tasks, like appearancebased or shape-based model for facial beauty classification/regression/ranking. We evaluated the SCUT-FBP5500 using different combinations of feature and predictor, and deep learning models, where the results indicates the reliability of the dataset.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>This work was supported in part by the National Natural Science Foundation of China (NSFC) under Grant 61472144 and Grant 61502176; in part by GDSTP under Grant 2015B010101004, Grant 2015B010130003, Grant 2015B010131004; in part by the National Key Research &amp; Development Plan of China under Grant 2016YFB1001405; and in part by Fundamental Research Funds for the Central Universities (No.2017BQ058). *Corresponding author: Lianwen Jin.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>The images with different facial properties and beauty scores from the proposed SCUT-FBP5500 benchmark dataset. The dataset download URL is shown below the title.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>(a) Score distribution of CF (b) Score distribution of CM (c) Score distribution of AF (d) Score distribution of AM Gaussian fitting (yellow curve) and piecewise fitting (red and blue curve) for the visualization of the beauty score distribution of Caucasian female (CF), Caucasian male (CM), Asian female (AF) and Asian male (AM).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .Fig. 4 .</head><label>34</label><figDesc>Distribution of standard deviations of Caucasian female, Asian female, Caucasian male and Asian male, respectively. (a) Box figure of CF (b) Box figure of AF (c) Box figure of CM (d) Box figure of AM Box figures of standard deviations of Caucasian female (CF), Asian female (AF), Caucasian male (CM) and Asian male (AM), respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 .</head><label>6</label><figDesc>PCA analysis of face landmarks of Asian female (AF) and Asian male (AM).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I REPRESENTATIVE</head><label>I</label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">DATABASES FOR FACIAL BEAUTY PREDICTION</cell><cell></cell><cell></cell></row><row><cell>Database</cell><cell>Image Num.</cell><cell>Labelers/Image</cell><cell>Beauty Class</cell><cell>Face Property</cell><cell>Face Landmarks</cell><cell>Publicly Available</cell></row><row><cell>Y. Eisenthal et al. [15] F. Chen et al. [22] H. Gunes et al. [35] J. Fan et al. [23] M. Redi et al. [34] SCUT-FBP [1] SCUT-FBP5500</cell><cell>184 23412 215 432 10141 500 5500</cell><cell>28 or 18 unknown 46 30 78-549 70 60</cell><cell>7 2 10 7 10 5 5</cell><cell>Caucasian Female Asian Male/Female Female Generated Female Multiple (Sampled from AVA [16]) Asian Female Asian/Caucasian; Male/Female</cell><cell>× √ √ √ × √ √</cell><cell>× × × × √ √ √</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE II THE</head><label>II</label><figDesc>OUTLIER NUMBER AND PORTION OF BEAUTY SCORES OF CAUCASIAN FEMALE (CF), CAUCASIAN MALE (CM), ASIAN FEMALE (AF) AND ASIAN MALE (AM).</figDesc><table><row><cell>Subset</cell><cell>CF</cell><cell>CM</cell><cell>AF</cell><cell>AM</cell></row><row><cell>Total Score Num.</cell><cell>45000</cell><cell>45000</cell><cell>120000</cell><cell>120000</cell></row><row><cell>Outlier Num.</cell><cell>143</cell><cell>181</cell><cell>356</cell><cell>497</cell></row><row><cell>Outlier Portion</cell><cell>0.3%</cell><cell>0.4%</cell><cell>0.3%</cell><cell>0.4%</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE III CORRELATION</head><label>III</label><figDesc>COEFFICIENTS BETWEEN MALE AND FEMALE LABELERS FOR BEAUTY SCORE OF CAUCASIAN FEMALE (CF), CAUCASIAN MALE (CM), ASIAN FEMALE (AF) AND ASIAN MALE (AM).</figDesc><table><row><cell></cell><cell>CF</cell><cell>AF</cell><cell>CM</cell><cell></cell><cell>AM</cell><cell>All Faces</cell></row><row><cell>Female Labelers</cell><cell>0.785</cell><cell>0.800</cell><cell cols="2">0.747</cell><cell>0.793</cell><cell>0.785</cell></row><row><cell>Male Labelers</cell><cell>0.791</cell><cell>0.795</cell><cell cols="2">0.763</cell><cell>0.797</cell><cell>0.781</cell></row><row><cell>All Labelers</cell><cell>0.788</cell><cell>0.785</cell><cell cols="2">0.743</cell><cell>0.782</cell><cell>0.770</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Female Labeler</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Male Labeler</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>All Labeler</cell></row><row><cell>CF</cell><cell>AF</cell><cell>CM</cell><cell>AM</cell><cell cols="2">All Faces</cell></row><row><cell>1st PC</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>2nd PC</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>3rd PC</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>4th PC</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>5th PC</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>mean-4*sigma</cell><cell></cell><cell>mean</cell><cell></cell><cell></cell><cell></cell><cell>mean+4*sigma</cell></row><row><cell></cell><cell cols="4">(a) PCA Analysis of AF</cell><cell></cell></row><row><cell>1st PC</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>2nd PC</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>3rd PC</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>4th PC</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>5th PC</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>mean-4*sigma</cell><cell></cell><cell>mean</cell><cell></cell><cell></cell><cell></cell><cell>mean+4*sigma</cell></row></table><note>Fig. 5. Correlation Coefficient of male and female labelers for beauty score of CF, AF, CM, AM and all the faces in SCUT-FBP5500.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE IV FACIAL</head><label>IV</label><figDesc>BEAUTY PREDICTION USING GEOMETRIC FEATURE WITH SHALLOW MODELS FOR SUBSETS OF DIFFERENT RACES AND GENDER</figDesc><table><row><cell></cell><cell></cell><cell>Asian Female</cell><cell></cell><cell></cell><cell cols="2">Asian Male</cell></row><row><cell></cell><cell>LR</cell><cell>GR</cell><cell>SVR</cell><cell>LR</cell><cell>GR</cell><cell>SVR</cell></row><row><cell>PC</cell><cell cols="3">0.6771 0.7057 0.7008</cell><cell cols="3">0.6348 0.6923 0.6816</cell></row><row><cell>MAE</cell><cell>0.402</cell><cell>0.387</cell><cell>0.3876</cell><cell cols="2">0.3894 0.3572</cell><cell>0.356</cell></row><row><cell>RMSE</cell><cell cols="3">0.5246 0.5057 0.5089</cell><cell cols="3">0.5085 0.4752 0.4823</cell></row><row><cell></cell><cell cols="3">Caucasian Female</cell><cell cols="3">Caucasian Male</cell></row><row><cell></cell><cell>LR</cell><cell>GR</cell><cell>SVR</cell><cell>LR</cell><cell>GR</cell><cell>SVR</cell></row><row><cell>PC</cell><cell cols="3">0.6809 0.7263 0.7093</cell><cell>0.6063</cell><cell>0.63</cell><cell>0.6397</cell></row><row><cell>MAE</cell><cell cols="3">0.3986 0.3862 0.4001</cell><cell cols="3">0.3871 0.3689 0.3617</cell></row><row><cell>RMSE</cell><cell cols="3">0.5239 0.4908 0.5087</cell><cell cols="3">0.4899 0.4784 0.4739</cell></row><row><cell></cell><cell></cell><cell cols="2">TABLE V</cell><cell></cell><cell></cell></row><row><cell cols="7">FACIAL BEAUTY PREDICTION USING GEOMETRIC FEATURE WITH</cell></row><row><cell></cell><cell cols="5">SHALLOW MODELS FOR THE WHOLE DATASET</cell></row><row><cell></cell><cell cols="5">Linear Regression Gaussian Regression</cell><cell>SVR</cell></row><row><cell>PC</cell><cell></cell><cell>0.5948</cell><cell></cell><cell>0.6738</cell><cell></cell><cell>0.6668</cell></row><row><cell>MAE</cell><cell></cell><cell>0.4289</cell><cell></cell><cell>0.3914</cell><cell></cell><cell>0.3898</cell></row><row><cell>RMSE</cell><cell></cell><cell>0.5531</cell><cell></cell><cell>0.5085</cell><cell></cell><cell>0.5132</cell></row><row><cell></cell><cell></cell><cell cols="2">TABLE VI</cell><cell></cell><cell></cell></row><row><cell cols="7">FACIAL BEAUTY PREDICTION USING GABOR FEATURE WITH TWO</cell></row><row><cell></cell><cell cols="5">SAMPLING SCHEME ON WHOLE DATASET</cell></row><row><cell></cell><cell></cell><cell cols="2">86-keypoints</cell><cell cols="2">64UniSample</cell></row><row><cell></cell><cell></cell><cell>GR</cell><cell>SVR</cell><cell>GR</cell><cell>SVR</cell></row><row><cell></cell><cell>PC</cell><cell cols="2">0.7472 0.6691</cell><cell cols="2">0.6764 0.8065</cell></row><row><cell></cell><cell>MAE</cell><cell cols="2">0.3554 0.3891</cell><cell cols="2">0.4014 0.3976</cell></row><row><cell></cell><cell>RMSE</cell><cell cols="2">0.4599 0.5065</cell><cell cols="2">0.5177 0.5126</cell></row><row><cell cols="7">Fig. 7. Two sampling schemes to extract the appearance feature of FBP,</cell></row><row><cell cols="7">where the left one is the 86-keypoints method and the right one is the</cell></row><row><cell cols="3">UniSamplePoint method.</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE VII COMPARISON</head><label>VII</label><figDesc>OF ALEXNET<ref type="bibr" target="#b40">[41]</ref>, RESNET-18<ref type="bibr" target="#b41">[42]</ref> AND RESNEXT-50<ref type="bibr" target="#b42">[43]</ref> IN MEASUREMENT OF PC, MAE AND RMSEBY   5-FOLD CROSS VALIDATION</figDesc><table><row><cell>PC</cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>Average</cell></row><row><cell>AlexNet</cell><cell>0.8667</cell><cell>0.8645</cell><cell>0.8615</cell><cell>0.8678</cell><cell>0.8566</cell><cell>0.8634</cell></row><row><cell>ResNet-18</cell><cell>0.8847</cell><cell>0.8792</cell><cell>0.8929</cell><cell>0.8932</cell><cell>0.9004</cell><cell>0.89</cell></row><row><cell>ResNeXt-50</cell><cell>0.8985</cell><cell>0.8932</cell><cell>0.9016</cell><cell>0.899</cell><cell>0.9064</cell><cell>0.8997</cell></row><row><cell>MAE</cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>Average</cell></row><row><cell>AlexNet</cell><cell>0.2633</cell><cell>0.2605</cell><cell>0.2681</cell><cell>0.2609</cell><cell>0.2728</cell><cell>0.2651</cell></row><row><cell>ResNet-18</cell><cell>0.248</cell><cell>0.2459</cell><cell>0.243</cell><cell>0.2383</cell><cell>0.2383</cell><cell>0.2419</cell></row><row><cell>ResNeXt-50</cell><cell>0.2306</cell><cell>0.2285</cell><cell>0.226</cell><cell>0.2349</cell><cell>0.2258</cell><cell>0.2291</cell></row><row><cell>RMSE</cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>Average</cell></row><row><cell>AlexNet</cell><cell>0.3408</cell><cell>0.3449</cell><cell>0.3538</cell><cell>0.3438</cell><cell>0.3576</cell><cell>0.3481</cell></row><row><cell>ResNet-18</cell><cell>0.3258</cell><cell>0.3286</cell><cell>0.3184</cell><cell>0.3107</cell><cell>0.2994</cell><cell>0.3166</cell></row><row><cell>ResNeXt-50</cell><cell>0.3025</cell><cell>0.3084</cell><cell>0.3016</cell><cell>0.3044</cell><cell>0.2918</cell><cell>0.3017</cell></row><row><cell></cell><cell></cell><cell cols="2">TABLE VIII</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">COMPARISON OF ALEXNET [41], RESNET-18 [42] AND</cell><cell></cell></row><row><cell cols="7">RESNEXT-50 [43] IN MEASUREMENT OF PC, MAE AND RMSE BY 60%</cell></row><row><cell></cell><cell cols="4">TRAINING AND 40% TESTING</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="5">AlexNet ResNet-18 ResNeXt-50</cell><cell></cell></row><row><cell></cell><cell>PC</cell><cell>0.8298</cell><cell>0.8513</cell><cell cols="2">0.8777</cell><cell></cell></row><row><cell></cell><cell>MAE</cell><cell>0.2938</cell><cell>0.2818</cell><cell cols="2">0.2518</cell><cell></cell></row><row><cell></cell><cell>RMSE</cell><cell>0.3819</cell><cell>0.3703</cell><cell cols="2">0.3325</cell><cell></cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">SCUT-FBP: A Benchmark Dataset for Facial Beauty Perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE SMC</title>
		<meeting>of IEEE SMC</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1821" to="1826" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Region-aware scattering convolution networks for facial beauty prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE ICIP</title>
		<meeting>of IEEE ICIP</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2861" to="2865" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Facial attractiveness prediction using psychologically inspired convolutional neural network (PI-CNN)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Mao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE ICASSP</title>
		<meeting>of IEEE ICASSP</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1657" to="1661" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Edge-aware label propagation for mobile facial enhancement on the cloud</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Circuits and Systems for Video Technology</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="125" to="138" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Facial skin beautification using adaptive region-aware mask</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Cybernetics</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2600" to="2612" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Deep face beautification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM International Conference on Multimedia</title>
		<meeting>ACM International Conference on Multimedia</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="793" to="794" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Data-driven enhancement of facial attractiveness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Leyvand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cohen-Or</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Dror</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lischinski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph., pp</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A survey of perception and computation of human beauty</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Gunes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of J-HGBU</title>
		<meeting>of J-HGBU</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="19" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Computer analysis of face beauty: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Laurentini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bottino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Vision and Image Underst</title>
		<imprint>
			<biblScope unit="volume">125</biblScope>
			<biblScope unit="page" from="184" to="199" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Computer models for facial beauty analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>Springer International Publishing Switzerland</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Wow! you are so beautiful today!</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Multimedia Computing</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1s</biblScope>
			<biblScope unit="page">20</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>Communications, and Applications</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Computer-suggested facial makeup</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Scherbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ritschel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hullin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Thormählen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Blanz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Seidel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Graph. Forum</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="485" to="492" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Computational facial attractiveness prediction by aestheticsaware features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Mu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="page" from="59" to="64" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">251</biblScope>
			<biblScope unit="page" from="436" to="444" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Facial Attractiveness: Beauty and the Machine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Eisenthal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Dror</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ruppin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="119" to="142" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">AVA: A large-scale database for aesthetic visual analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Marchesotti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Perronnin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of CVPR</title>
		<meeting>of CVPR</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="2408" to="2415" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Computer analysis of face beauty: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Laurentini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bottino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision and Image Understanding</title>
		<imprint>
			<biblScope unit="volume">125</biblScope>
			<biblScope unit="page" from="184" to="199" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Facial skin coloration affects perceived health of human faces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Stephen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stirrat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Perrett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Primatology</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="845" to="857" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A humanlike predictor of facial attractiveness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kagian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Dror</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Leyvand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cohen-Or</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ruppin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NIPS</title>
		<meeting>of NIPS</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="649" to="656" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Automatic classification of Chinese female facial beauty using Support Vector Machine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Du</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE SMC</title>
		<meeting>of IEEE SMC</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="4842" to="4846" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Quantitative analysis of human facial beauty using geometric features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="940" to="950" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A benchmark for geometric facial beauty study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical Biometrics</title>
		<imprint>
			<biblScope unit="page" from="21" to="32" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Prediction of facial attractiveness from facial proportions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">P</forename><surname>Chau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Lau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="2326" to="2334" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Cost-sensitive ordinal regression for fully automatic facial beauty assessment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="issue">129</biblScope>
			<biblScope unit="page" from="334" to="342" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Relative ranking of facial attractiveness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Altwaijry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Workshop on WACV</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="117" to="124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A novel method for evaluating facial attractiveness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Proc. ICALIP</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1382" to="1386" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">The cluster assessment of facial attractiveness using fuzzy neural network classifier based on 3D Moir features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1249" to="1260" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Automatic analysis of facial attractiveness from video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kalayci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">K</forename><surname>Ekenel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Gunes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ICIP</title>
		<meeting>of ICIP</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="4191" to="4195" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Deep self-taught learning for facial beauty prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="issue">144</biblScope>
			<biblScope unit="page" from="295" to="303" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Attractive or not? Beauty prediction with attractiveness-aware encoders and robust late fusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>ACM Multimedia</publisher>
			<biblScope unit="page" from="805" to="808" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Sense beauty by label distribution learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Geng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc, IJCAI</title>
		<meeting>IJCAI</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2648" to="2654" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Automatic prediction of human attractiveness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Eden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">UC Berkeley CS280A Proj</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Predicting facial beauty without landmarks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">The Beauty of Capturing Faces: Rating the Quality of Digital Portraits</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Redi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Rasiwasia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jaimes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Workshops on AFGR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Assessing facial beauty through proportion analysis by image processing and supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Gunes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Piccardi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Human-Computer Studies</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1184" to="1199" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Personalized facial attractiveness prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Whitehill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Movellan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. AFGR</title>
		<meeting>AFGR</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Label Distribution based facial attractiveness computation by deep residual learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Samal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stan</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Multimedia</title>
		<imprint>
			<biblScope unit="page">2017</biblScope>
			<publisher>Online</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Analysis of human attractiveness using manifold kernel regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lazebnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICIP</title>
		<meeting>ICIP</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">DataTang</title>
		<ptr target="http://datatang.com/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">The intrinsic memorability of face images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">A</forename><surname>Bainbridge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">142</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1323" to="1334" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc, NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc, CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Aggregated residual transformations for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.05431</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
