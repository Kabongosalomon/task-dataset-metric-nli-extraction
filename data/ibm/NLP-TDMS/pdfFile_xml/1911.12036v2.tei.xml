<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Discriminative Adversarial Domain Adaptation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Tang</surname></persName>
							<email>eehuitang@mail.scut.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">South China University of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kui</forename><surname>Jia</surname></persName>
							<email>kuijia@scut.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">South China University of Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Discriminative Adversarial Domain Adaptation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T06:34+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Given labeled instances on a source domain and unlabeled ones on a target domain, unsupervised domain adaptation aims to learn a task classifier that can well classify target instances. Recent advances rely on domain-adversarial training of deep networks to learn domain-invariant features. However, due to an issue of mode collapse induced by the separate design of task and domain classifiers, these methods are limited in aligning the joint distributions of feature and category across domains. To overcome it, we propose a novel adversarial learning method termed Discriminative Adversarial Domain Adaptation (DADA). Based on an integrated category and domain classifier, DADA has a novel adversarial objective that encourages a mutually inhibitory relation between category and domain predictions for any input instance. We show that under practical conditions, it defines a minimax game that can promote the joint distribution alignment. Except for the traditional closed set domain adaptation, we also extend DADA for extremely challenging problem settings of partial and open set domain adaptation. Experiments show the efficacy of our proposed methods and we achieve the new state of the art for all the three settings on benchmark datasets.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Many machine learning tasks are advanced by large-scale learning of deep models, with image classification <ref type="bibr">(Russakovsky et al. 2015)</ref> as one of the prominent examples. A key factor to achieve such advancements is the availability of massive labeled data on the domains of the tasks of interest. For many other tasks, however, training instances on the corresponding domains are either difficult to collect, or their labeling costs prohibitively. To address the scarcity of labeled data for these target tasks/domains, a general strategy is to leverage the massively available labeled data on related source ones via domain adaptation <ref type="bibr">(Pan and Yang 2010)</ref>. Even though the source and target tasks share the same label space (i.e. closed set domain adaptation), domain adaptation still suffers from the shift in data distributions. The main objective of domain adaptation is thus to learn domaininvariant features, so that task classifiers learned from the source data can be readily applied to the target domain. In this work, we focus on the unsupervised setting where training instances on the target domain are completely unlabeled.</p><p>Recent domain adaptation methods are largely built on modern deep architectures. They rely on great model capacities of these networks to learn hierarchical features that are empirically shown to be more transferable across domains <ref type="bibr">(Yosinski et al. 2014;</ref><ref type="bibr">Zhang, Tang, and Jia 2018)</ref>. Among them, those based on domain-adversarial training <ref type="bibr" target="#b12">(Ganin et al. 2016;</ref><ref type="bibr">Wang et al. 2019)</ref> achieve the current state of the art. Based on the seminal work of DANN <ref type="bibr" target="#b12">(Ganin et al. 2016)</ref>, they typically augment a classification network with an additional domain classifier. The domain classifier takes features from the feature extractor of the classification network as inputs, which is trained to differentiate between instances from the two domains. By playing a minimax game <ref type="bibr" target="#b15">(Goodfellow et al. 2014)</ref>, adversarial training aims to learn domain-invariant features.</p><p>Such domain-adversarial networks can largely reduce the domain discrepancy. However, the separate design of task and domain classifiers has the following shortcomings. Firstly, feature distributions can only be aligned to a certain level, since model capacity of the feature extractor could be large enough to compensate for the less aligned feature distributions. More importantly, given practical difficulties of aligning the source and target distributions with high granularity to the category level (especially for complex distributions with multi-mode structures), the task classifier obtained by minimizing the empirical source risk cannot well generalize to the target data due to an issue of mode collapse (Kurmi and Namboodiri 2019; Tran et al. 2019), i.e., the joint distributions of feature and category are not well aligned across the source and target domains.</p><p>Recent methods <ref type="bibr">(Kurmi and Namboodiri 2019;</ref><ref type="bibr">Tran et al. 2019</ref>) take the first step to address the above shortcomings by jointly parameterizing the task and domain classifiers into an integrated one. To further push this line, based on such a classifier, we propose a novel adversarial learning method termed Discriminative Adversarial Domain Adaptation (DADA), which encourages a mutually inhibitory relation between its domain prediction and category prediction for any input instance, as illustrated in <ref type="figure" target="#fig_0">Figure 1</ref>. This dis-criminative interaction between category and domain predictions underlies the ability of DADA to reduce domain discrepancy at both the feature and category levels. Intuitively, the adversarial training of DADA mainly conducts competition between the domain neuron (output) and the true category neuron (output). Different from the work <ref type="bibr">(Tran et al. 2019</ref>) whose mechanism to align the joint distributions is rather implicit, DADA enables explicit alignment between the joint distributions, thus improving the classification of target data. Except for closed set domain adaptation, we also extend DADA for partial domain adaptation <ref type="bibr" target="#b5">(Cao et al. 2018b)</ref>, i.e. the target label space is subsumed by the source one, and open set domain adaptation <ref type="bibr">(Saito et al. 2018c</ref>), i.e. the source label space is subsumed by the target one. Our main contributions can be summarized as follows.</p><p>• We propose in this work a novel adversarial learning method, termed DADA, for closed set domain adaptation.</p><p>Based on an integrated category and domain classifier, DADA has a novel adversarial objective that encourages a mutually inhibitory relation between category and domain predictions for any input instance, which can promote the joint distribution alignment across domains. • For more realistic partial domain adaptation, we extend DADA by a reliable category-level weighting mechanism, termed DADA-P, which can significantly reduce the negative influence of outlier source instances. • For more challenging open set domain adaptation, we extend DADA by balancing the joint distribution alignment in the shared label space with the classification of outlier target instances, termed DADA-O. • Experiments show the efficacy of our proposed methods and we achieve the new state of the art for all the three adaptation settings on benchmark datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Related Works</head><p>Closed Set Domain Adaptation After the seminal work of DANN <ref type="bibr" target="#b12">(Ganin et al. 2016)</ref>, <ref type="bibr">ADDA (Tzeng et al. 2017</ref>) proposes an untied weight sharing strategy to align the target feature distribution to a fixed source one. SimNet (Pinheiro 2018) replaces the standard FC-based cross-entropy classifier by a similarity-based one. <ref type="bibr">MADA (Pei et al. 2018)</ref> and <ref type="bibr">CDAN (Long et al. 2018b</ref>) integrate the discriminative category information into domain-adversarial training. VADA <ref type="bibr">(Shu et al. 2018</ref>) reduces the cluster assumption violation to constrain domain-adversarial training. Some methods <ref type="bibr">(Wang et al. 2019;</ref><ref type="bibr">Wen et al. 2019</ref>) focus on transferable regions to learn domain-invariant features and task classifier. <ref type="bibr">TAT (Liu et al. 2019</ref>) enhances the discriminability of features to guarantee the adaptability. Some methods <ref type="bibr">(Saito et al. 2018b;</ref><ref type="bibr" target="#b4">2018a;</ref><ref type="bibr">Lee et al. 2019</ref>) utilize category predictions from two task classifiers to measure the domain discrepancy. The most related works <ref type="bibr">(Kurmi and Namboodiri 2019;</ref><ref type="bibr">Tran et al. 2019)</ref> to us propose joint parameterization of the task and domain classifiers, which implicitly align the joint distributions. Differently, our proposed DADA makes the joint distribution alignment more explicit, thus promoting classification on the target domain.</p><p>Partial Domain Adaptation The work <ref type="bibr">(Zhang et al. 2018a)</ref> weights each source instance by its importance to the target domain based on one domain classifier, and then trains another domain classifier on target and weighted source instances. The works <ref type="bibr" target="#b4">(Cao et al. 2018a;</ref><ref type="bibr" target="#b5">2018b)</ref> reduce the contribution of outlier source instances to the task or domain classifiers by utilizing category predictions. Differently, DADA-P weights the proposed source discriminative adversarial loss by a reliable category confidence.</p><p>Open Set Domain Adaptation Previous research <ref type="bibr">(Jain, Scheirer, and Boult 2014)</ref> proposes to reject an instance as the unknown category by threshold filtering. The work <ref type="bibr">(Saito et al. 2018c)</ref> proposes to utilize adversarial training for both domain adaptation and unknown outlier detection. Differently, DADA-O balances the joint distribution alignment in the shared label space with the outlier rejection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Given {(x s i , y s i )} ns i=1 of labeled instances sampled from the source domain D s , and {x t j } nt j=1 of unlabeled instances sampled from the target domain D t , the objective of unsupervised domain adaptation is to learn a feature extractor G(·) and a task classifier C(·) such that the expected target risk E (x t ,y t )∼Dt [L cls (C(G(x t )), y t )] is low for a certain classification loss function L cls (·). The domains D s and D t are assumed to have different distributions. To achieve a low target risk, a typical strategy is to learn G(·) and C(·) by minimizing the sum of the source risk and some notion of distance between the source and target domain distributions, inspired by domain adaptation theories <ref type="bibr" target="#b0">(Ben-David et al. 2007;</ref><ref type="bibr" target="#b1">2010)</ref>. This strategy is based on a simple rational that the source risk would become a good indicator of the target risk when the distance between the two distributions is getting closer. While most of existing methods use distance measures based on the marginal distributions, it is arguably better to use those based on the joint distributions.</p><p>The above strategy is generally implemented by domainadversarial learning <ref type="bibr" target="#b12">(Ganin et al. 2016;</ref><ref type="bibr">Wang et al. 2019)</ref>, where separate task classifier C(·) and domain classifier D(·) are typically stacked on top of the feature extractor G(·). As discussed before, this type of design has the following shortcomings: (1) model capacity of G(·) could be large enough to make D(G(x s )) and D(G(x t )) hardly differentiable for any instance, even though the marginal feature distributions are not well aligned; (2) more importantly, it is difficult to align the source and target distributions with high granularity to the category level (especially for complex distributions with multi-mode structures), and thus C(·) obtained by minimizing the empirical source risk cannot perfectly generalize to the target data due to an issue of mode collapse, i.e. the joint distributions are not well aligned.</p><p>To alleviate the above shortcomings, inspired by semisupervised learning methods based on GANs <ref type="bibr">(Salimans et al. 2016;</ref><ref type="bibr" target="#b11">Dai et al. 2017)</ref>, the recent work <ref type="bibr">(Tran et al. 2019)</ref> proposes joint parameterization of C(·) and D(·) into an integrated one F (·). Suppose the classification task of interest has K categories, F (·) is formed simply by augmenting the last FC layer of C(·) with one additional neuron. , which includes a feature extractor G(·) and an integrated category and domain classifier F (·). The blue and orange colors denote G(·) and F (·), and the losses applied to them, respectively. Note that DADA explicitly establishes a discriminative interaction between category and domain predictions. Please refer to the main text for how the adversarial training objective of DADA is defined.</p><p>Denote p(x) ∈ [0, 1] K+1 as the output vector of class probabilities of F (G(x)) for an instance x, and p k (x), k ∈ {1, . . . , K + 1}, as its k th element. The k th element of the conditional probability vectorp(x) is written as follows</p><formula xml:id="formula_0">p k (x) =    p k (x) 1 − p K+1 (x) , k = 1, 2, ..., K 0 , k = K + 1 .<label>(1)</label></formula><p>For ease of subsequent notations, we also write p s k = p k (x s ) and p t k = p k (x t ). Then, such a network is trained by the classification-aware adversarial learning objective</p><formula xml:id="formula_1">min F − 1 n s ns i=1 log p y s i (x s i ) − 1 n t nt j=1 log p K+1 (x t j ) (2) max G 1 n s ns i=1 logp y s i (x s i ) + λ 1 n t nt j=1 log(1 − p K+1 (x t j )),</formula><p>where λ balances category classification and domain adversarial losses. The mechanism of this objective to align the joint distributions across domains is rather implicit. To make it more explicit, based on the integrated classifier F (·), we propose a novel adversarial learning method termed Discriminative Adversarial Domain Adaptation (DADA), which explicitly enables a discriminative interplay of predictions among the domain and K categories for any input instance, as illustrated in <ref type="figure" target="#fig_0">Figure 1</ref>. This discriminative interaction underlies the ability of DADA to promote the joint distribution alignment, as explained shortly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discriminative Adversarial Learning</head><p>To establish a direct interaction between category and domain predictions, we propose a novel source discriminative adversarial loss that is tailored to the design of the integrated classifier F (·). The proposed loss is inspired by the principle of binary cross-entropy loss. It is written as</p><formula xml:id="formula_2">L s (G, F ) = − 1 n s ns i=1 [(1 − p K+1 (x s i )) log p y s i (x s i ) + p K+1 (x s i ) log 1 − p y s i (x s i ) ].<label>(3)</label></formula><p>Intuitively, the proposed loss (3) establishes a mutually inhibitory relation between p y s (x s ) of the prediction on the true category of x s , and p K+1 (x s ) of the prediction on the domain of x s . We first discuss how the proposed loss (3) works during adversarial training, and we show that under practical conditions, minimizing (3) over the classifier F (·) has the effects of discriminating among task categories while distinguishing the source domain from the target one, and maximizing (3) over the feature extractor G(·) can discriminatively align the source domain to the target one. Discussion We first write the gradient formulas of L s on any source instance x s w.r.t. p s y s and p s K+1 as (2) in case of p s y s &lt; 0.5 that guarantees ∇ p s K+1 &lt; 0, when minimizing the loss (3) over F (·) by SGD update, we have increased p s K+1 , and when maximizing it over G(·) by SGA update, we have decreased p s K+1 , as shown in <ref type="figure">Figure 2</ref>. For discriminative adversarial domain adaptation, we expect that (1) when minimizing the proposed loss (3) over F (·), task categories of the source domain is discriminative and the source domain is distinctive from the target one, which can be achieved when p s y s increases and p s K+1 decreases; (2) when maximizing it over G(·), the source domain is aligned to the target one while retains discriminability, which can be achieved when p s y s decreases and p s K+1 <ref type="figure">Figure 2</ref>: Changes of p s y s and p s K+1 when minimizing and maximizing the loss (3) in the two cases.</p><formula xml:id="formula_3">∇ p s y s = ∂L s ∂p s y s = p s y s p s K+1 − (1 − p s y s )(1 − p s K+1 ) p s y s (1 − p s y s ) , ∇ p s K+1 = ∂L s ∂p s K+1 = log p s y s 1 − p s y s .</formula><p>increases in the case of p s y s &gt; 0.5. To meet the expectations, the condition of p s y s &gt; 0.5 for all source instances should be always satisfied. This is practically achieved by pre-training DADA on the labeled source data using a Kway cross-entropy loss, and maintaining in the adversarial training of DADA the same supervision signal. We present in the supplemental material empirical evidence on benchmark datasets that shows the efficacy of our used scheme.</p><p>To achieve the joint distribution alignment, the explicit interplay between category and domain predictions for any target instance should also be created. Motivated by recent works <ref type="bibr">(Pei et al. 2018;</ref><ref type="bibr" target="#b5">Long et al. 2018b</ref>) which alleviate the issue of mode collapse by aligning each instance to several most related categories, we propose a target discriminative adversarial loss based on the design of the integrated classifier F (·), by using the conditional category probabilities to weight the domain predictions. It is written as</p><formula xml:id="formula_4">L t F (G, F ) = − 1 n t nt j=1 K k=1p k (x t j ) logp k K+1 (x t j ) L t G (G, F ) = 1 n t nt j=1 K k=1p k (x t j ) log(1 −p k K+1 (x t j )),<label>(4)</label></formula><p>where the k th element of the domain prediction vectorp k for the k th category is written as followŝ</p><formula xml:id="formula_5">p k k (x) =    p k (x) p k (x) + p K+1 (x) , k = k, K + 1 0 , otherwise .<label>(5)</label></formula><p>An intuitive explanation for our proposed (4) is provided in the supplemental material. Established knowledge from cluster analysis (Nalewajski 2012) indicates that we can estimate clusters with a low probability of error only if the conditional entropy is small. To this end, we adopt the entropy minimization principle <ref type="bibr" target="#b16">(Grandvalet and Bengio 2005)</ref>, which is written as</p><formula xml:id="formula_6">L t em (G, F ) = 1 n t nt j=1 H(p(x t j )),<label>(6)</label></formula><p>where H(·) computes the entropy of a probability vector. Combining (3), (4), and (6) gives the following minimax problem of our proposed DADA</p><formula xml:id="formula_7">min F L F = λ(L s + L t F ) − L t em max G L G = λ(L s + L t G ) − L t em ,<label>(7)</label></formula><p>where λ is a hyper-parameter that trade-offs the adversarial domain adaptation objective with the entropy minimization one in the unified optimization problem. Note that in the minimization problem of (7), L t em serves as a regularizer for learning F (·) to avoid the trivial solution (i.e. all instances are assigned to the same category), and in the maximization problem of (7), it helps learn more target-discriminative features, which can alleviate the negative effect of adversarial feature adaptation on the adaptability <ref type="bibr">(Liu et al. 2019)</ref>.</p><p>By optimizing <ref type="formula" target="#formula_7">(7)</ref>, the joint distribution alignment can be enhanced. This ability comes from the better use of discriminative information from both the source and target domains. Concretely, DADA constrains the domain classifier so that it clearly/explicitly knows the classification boundary, thus reducing false alignment between different categories. By deceiving such a strong domain classifier, DADA can learn a feature extractor that better aligns the two domains. We also theoretically prove in the supplemental material that DADA can better bound the expected target error.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Extension for Partial Domain Adaptation</head><p>Partial domain adaptation is a more realistic setting, where the target label space is subsumed by the source one. The false alignment between the outlier source categories and the target domain is unavoidable. To address it, existing methods <ref type="bibr" target="#b4">(Cao et al. 2018a;</ref><ref type="bibr">Zhang et al. 2018a;</ref><ref type="bibr" target="#b5">Cao et al. 2018b)</ref> utilize the category or domain predictions, to decrease the contribution of source outliers to the training of task or domain classifiers. Inspired by these ideas, we extend DADA for partial domain adaptation by using a reliable categorylevel weighting mechanism, which is termed DADA-P.</p><p>Concretely, we average the conditional probability vectors p(x t ) ∈ [0, 1] K over all target data and then normalize the averaged vectorc ∈ [0, 1] K by dividing its largest element. The category weight vector c ∈ [0, 1] K with c k as its k th element is derived by a convex combination of the normalized vector and an all-ones vector 1, as follows</p><formula xml:id="formula_8">c = 1 n t nt j=1p (x t j ) c = λc max(c) + (1 − λ)1,<label>(8)</label></formula><p>where λ ∈ [0, 1] is to suppress the detection noise of outlier source categories in the early stage of training. Then, we apply the category weight vector c to the proposed discriminative adversarial loss for any source instance, leading to</p><formula xml:id="formula_9">L s (G, F ) = − 1 n s ns i=1 c y s i [(1 − p K+1 (x s i )) log p y s i (x s i ) + p K+1 (x s i ) log 1 − p y s i (x s i ) ].</formula><p>(9) Since predicted probabilities on the outlier source categories are more likely to increase when minimizing −L t em over F (·), which incurs negative transfer. To avoid it, we minimize L t em over F (·) and the objective of DADA-P is min</p><formula xml:id="formula_10">F L F = λ(L s + L t F ) + L t em max G L G = λ(L s + L t G ) − L t em .<label>(10)</label></formula><p>By optimizing it, DADA-P can simultaneously alleviate negative transfer and promote the joint distribution alignment across domains in the shared label space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Extension for Open Set Domain Adaptation</head><p>Open set domain adaptation is a very challenging setting, where the source label space is subsumed by the target one. We denominate the shared category and all unshared categories between the two domains as the "known category" and "unknown category" respectively. The goal of open set domain adaptation is to correctly classify any target instance as the known or unknown category. The false alignment between the known and unknown categories is inevitable. To this end, the work (Saito et al. 2018c) proposes to make a pseudo decision boundary for the unknown category, which enables the feature extractor to reject some target instances as outliers. Inspired by this work, we extend DADA for open set domain adaptation by training the classifier to classify all target instances as the unknown category with a small probability q, which is termed DADA-O. Assuming the predicted probability on the unknown category as the K th element of p(x t ), i.e., p K (x t ), the modified target adversarial loss when minimized over the integrated classifier F (·) is</p><formula xml:id="formula_11">L t F (G, F ) = − 1 n t nt j=1 q log p K (x t j ) − (1 − q) log p K+1 (x t j ),<label>(11)</label></formula><p>where 0 &lt; q &lt; 0.5. When maximized over the feature extractor G(·), we still use the discriminative loss L t G in (4). Replacing L t F in <ref type="formula" target="#formula_7">(7)</ref> with <ref type="formula" target="#formula_0">(11)</ref> gives the overall adversarial objective of DADA-O, which can achieve a balance between domain adaptation and outlier rejection.</p><p>We utilize all target instances to obtain the concept of "unknown", which is very helpful for the classification of unknown target instances as the unknown category but can cause the misclassification of known target instances as the unknown category. This issue can be alleviated by selecting an appropriate q. If q is too small, the unknown target instances cannot be correctly classified; if q is too large, the known target instances can be misclassified. By choosing an appropriate q, the feature extractor can separate the unknown target instances from the known ones while aligning the joint distributions in the shared label space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiments</head><p>Datasets and Implementation Details <ref type="bibr">Office-31 (Saenko et al. 2010</ref>) is a popular benchmark domain adaptation dataset consisting of 4, 110 images of 31 categories collected from three domains: Amazon (A), Webcam (W), and DSLR (D). We evaluate on six settings. Syn2Real (Peng et al. 2018) is the largest benchmark. Syn2Real-C has over 280K images of 12 shared categories in the combined training, validation, and testing domains. The 152, 397 images on the training domain are synthetic ones by rendering 3D models. The validation and test domains comprise real images, and the validation one has 55, 388 images. We use the training domain as the source domain and validation one as the target domain. For partial domain adaptation, we choose images of the first 6 categories (in alphabetical order) in the validation domain as the target domain and form the setting: Synthetic 12 → Real 6. For open set domain adaptation, we evaluate on Syn2Real-O, which includes two domains. The training/synthetic domain uses synthetic images from the 12 categories of Syn2Real-C as "known". The validation/real domain uses images of the 12 categories from the validation domain of Syn2Real-C as "known", and 50k images from 69 other categories as "unknown". We use the training and validation domains of Syn2Real-O as the source and target domains respectively. Implementation Details We follow standard evaluation protocols for unsupervised domain adaptation <ref type="bibr" target="#b12">(Ganin et al. 2016;</ref><ref type="bibr">Wang et al. 2019)</ref>: we use all labeled source and all unlabeled target instances as the training data. For all tasks of Office-31 and Synthetic 12 → Real 6, based on ResNet-50 (He et al. 2016), we report the classification result on the target domain of mean(±standard deviation) over three random trials. For other tasks of Syn2Real, we evaluate the accuracy of each category based on ResNet-101 and ResNet-152 (for closed and open set domain adaptation respectively). For each base network, we use all its layers up to the second last one as the feature extractor G(·), and set the neuron number of its last FC layer as K + 1 to have the integrated classifier F (·). Exceptionally, we follow the work (Peng et al. 2018) and replace the last FC layer of ResNet-152 with three FC layers of 512 neurons. All base networks are pre-trained on ImageNet <ref type="bibr">(Russakovsky et al. 2015)</ref>. We firstly pre-train them on the labeled source data, and then fine-tune them on both the labeled source data and unlabeled target data via adversarial training, where we maintain the same supervision signal as the pre-training.</p><p>We follow DANN <ref type="bibr" target="#b12">(Ganin et al. 2016)</ref> to use the SGD training schedule: the learning rate is adjusted by η p = η0 (1+αp) β , where p denotes the process of training iterations that is normalized to be in [0, 1], and we set η 0 = 0.0001, α = 10, and β = 0.75; the hyper-parameter λ is initialized at 0 and is gradually increased to 1 by λ p = 2 1+exp(−γp) − 1, where we set γ = 10. We empirically set q = 0.1. We implement all our methods by PyTorch. The code will be available at https://github.com/huitangtang/DADA-AAAI2020.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analysis</head><p>Ablation Study We conduct ablation studies on Office-31 to investigate the effects of key components of our proposed DADA based on ResNet-50. Our ablation studies start with the very baseline termed "No Adaptation" that simply finetunes a ResNet-50 on the source data. To validate the mutually inhibitory relation enabled by DADA, we use DANN <ref type="bibr" target="#b12">(Ganin et al. 2016</ref>) and DANN-CA (Tran et al. 2019) respectively as the second and third baselines. To investigate how the entropy minimization principle helps learn more targetdiscriminative features, we remove the entropy minimization loss (6) from our main minimax problem (7), denoted as "DADA (w/o em)". To know effects of the proposed source and target discriminative adversarial losses (3) and (4), we </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head><p>A    remove both <ref type="formula" target="#formula_6">(6)</ref> and <ref type="formula" target="#formula_4">(4)</ref> from <ref type="formula" target="#formula_7">(7)</ref>, denoted as "DADA (w/o em + w/o td)". Results in <ref type="table" target="#tab_1">Table 1</ref> show that although DANN improves over "No Adaptation", its result is much worse than DANN-CA, verifying the efficacy of the design of the integrated classifier F (·). "DADA (w/o em + w/o td)" improves over DANN-CA and "DADA (w/o em)" improves over "DADA (w/o em + w/o td)", showing the efficacy of our proposed discriminative adversarial learning. DADA significantly outperforms DANN and DANN-CA, confirming the efficacy of the proposed mutually inhibitory relation between the category and domain predictions in aligning the joint distribu-tions of feature and category across domains. <ref type="table" target="#tab_1">Table 1</ref> also confirms that entropy minimization is helpful to learn more target-discriminative features. Quantitative Comparison To compare the efficacy of different methods in reducing domain discrepancy at the category level, we visualize the average probability on the true category over all target instances by task classifiers of No Adaptation, DANN, DANN-CA, and DADA on A → W in <ref type="figure" target="#fig_1">Figure 3</ref>. Note that here we use labels of the target data for the quantization of category-level domain discrepancy. <ref type="figure" target="#fig_1">Figure 3</ref> shows that our proposed DADA gives the predicted probability on the true category of any target instance a better chance to approach 1, meaning that target instances are more likely to be correctly classified by DADA, i.e., a better category-level domain alignment.</p><formula xml:id="formula_12">→ W D → W W → D A → D D → A W → A</formula><formula xml:id="formula_13">Methods A → W D → W W → D A → D D → A W → A</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Closed Set Domain Adaptation We compare in <ref type="table" target="#tab_3">Tables 2  and 3</ref> our proposed method with existing ones on Office-31 and Syn2Real-C based on ResNet-50 and ResNet-101 respectively. Whenever available, results of existing methods are quoted from their respective papers or the recent works <ref type="bibr">(Pei et al. 2018;</ref><ref type="bibr" target="#b5">Long et al. 2018b;</ref><ref type="bibr">Liu et al. 2019;</ref><ref type="bibr">Saito et al. 2018b</ref>). Our proposed DADA outperforms existing methods, testifying the efficacy of DADA in aligning the joint distributions of feature and category across domains. Partial Domain Adaptation We compare in <ref type="table" target="#tab_7">Table 5</ref> our proposed method to existing ones on Syn2Real-C based on   It is noteworthy that DADA-O improves over the state-of-theart method AODA by a large margin when the known-tounknown ratio in the target domain is much smaller than 1, i.e. the false alignment between the known source and unknown target instances will be much more serious. This observation confirms the efficacy of DADA-O. We provide more results and analysis for the three problem settings in the supplemental material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>We propose a novel adversarial learning method termed Discriminative Adversarial Domain Adaptation (DADA) to overcome the limitation in aligning the joint distributions of feature and category across domains, which is due to an issue of mode collapse induced by the separate design of task and domain classifiers. Based on an integrated task and domain classifier, DADA has a novel adversarial objective that encourages a mutually inhibitory relation between the category and domain predictions, which can promote the joint distribution alignment. Unlike previous methods, DADA explicitly enables a discriminative interaction between category and domain predictions. Except for closed set domain adaptation, we also extend DADA for more challenging problem settings of partial and open set domain adaptation. Experiments on benchmark datasets testify the efficacy of our proposed methods for all the three settings.  <ref type="formula" target="#formula_5">(5)</ref> We provide an intuitive explanation for our proposed loss (4) in Section A. We theoretically prove that our proposed method can better bound the expected target error than existing ones in Section B. We provide more results and analysis on benchmark datasets of Digits, Office-31, Office-Home, and ImageNet-Caltech for closed set, partial, and open set domain adaptation in Section C. We present empirical evidence on benchmark datasets of digits that shows the efficacy of our used training scheme in Section D. We will release the code soon.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Intuitive Explanation for Our Proposed</head><p>Loss <ref type="formula" target="#formula_4">(4)</ref> We denote the output vector of class scores of F (G(x)) before the final softmax operation for an instance x as o(x) ∈ R K+1 , and its k th element as o k (x), k ∈ {1, . . . , K + 1}. We denote the output vector of class probabilities of F (G(x)) after the final softmax operation for an instance x as p(x) ∈ [0, 1] K+1 , and its k th element as p k (x), k ∈ {1, . . . , K + 1}. We write p k (x), k ∈ {1, . . . , K + 1} as</p><formula xml:id="formula_14">p k (x) = exp(o k (x)) K+1 k =1 exp(o k (x))</formula><p>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(A.1)</head><p>We always have K+1 k=1 p k (x) = 1 for any instance x. When maximized over the feature extractor G(·), the adversarial loss on an unlabeled target instance x t (cf. objective <ref type="formula">(2)</ref> in Section Discriminative Adversarial Domain Adaptation in the paper) is written as</p><formula xml:id="formula_15">l t (G, F ) = log(1 − pK+1(x t )) = log( K k=1 p k (x t )) = log K k=1 exp(o k (x t )) K+1 k =1 exp(o k (x t ))</formula><p>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(A.2)</head><p>We write the gradient formulas of l t w.r.t. o k (x), k ∈ {1, . . . , K} as</p><formula xml:id="formula_16">∇ o k (x t ) = ∂l t ∂o k (x t ) = K+1 k =1 exp(o k (x t )) K k=1 exp(o k (x t )) · exp(o k (x t )) · exp(oK+1(x t )) K+1 k =1 exp(o k (x t )) 2 , (A.3) where ∇ o k (x t ) , k ∈ {1, . . . , K} differ in the term of exp(o k (x t ))</formula><p>, meaning that they are proportional to the class scores of o k (x t ).</p><p>In other words, the higher the class score is (i.e., the higher the class probability is), the stronger gradient the corresponding category neuron back-propagates, suggesting that the target instance is aligned to several most confident/related categories on the source domain. Such a mechanism to align the joint distributions of feature and category across domains is rather implicit. To make it more explicit, our proposed target discriminative adversarial loss (cf. loss (4) in Section Discriminative Adversarial Learning in the paper) uses the conditional probabilities to weight the category-wise domain predictions. By such a design, the discriminative adversarial training on the target data explicitly conducts the competition between the domain neuron (output) and the most confident category neuron (output) as the discriminative adversarial training on the source data does, thus promoting the category-level domain alignment. This is what we mean by the mutually inhibitory relation between the category and domain predictions for any input instance. This intuitive explanation manifests that the adversarial training of DADA clearly and explicitly utilizes the discriminative information of the target domain, thus improving the alignment of joint distributions of feature and category across domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Generalization Error Analysis for Our</head><p>Proposed DADA</p><p>We prove that our proposed DADA can better bound the expected target error than existing domain adaptation methods <ref type="formula">(</ref> For all hypothesis spaces introduced below, we assume them of finite effective size, i.e., finite VC dimension, so that the following distance measures defined over these spaces can be estimated from finite instances <ref type="bibr" target="#b1">(Ben-David et al. 2010)</ref>. We consider a fixed representation function G(·) from the instance set X to the feature space Z, i.e., z = G(x), and a hypothesis space H for the K-category task classifier C(·) from the feature space Z to the label space Y , i.e., C ∈ H <ref type="bibr" target="#b12">(Ganin et al. 2016)</ref>. Note that y ∈ Y is the K-dimensional one-hot vector for any label y. Denote the marginal feature distribution and the joint distribution of feature and category by P s Z and P s Z,Y for the source domain Ds, and similarly and P t Z,Y respectively. Specified by the two works <ref type="bibr" target="#b0">(Ben-David et al. 2007;</ref><ref type="bibr" target="#b1">2010)</ref>, the probabilistic bound of the expected target error t(C ) of the hypothesis C is given by the sum of the expected source error s(C ), the combined error [ s(C * ) + t(C * )] of the ideal joint hypothesis C * , and the distribution discrepancy across data domains, as the follow</p><formula xml:id="formula_17">t(C ) ≤ s(C ) + [ s(C * ) + t(C * )] + | s(C, C * ) − t(C, C * )|. (B.1)</formula><p>For domain adaptation to be possible, a natural assumption is that there exists the ideal joint hypothesis C * ∈ H so that the combined error [ s(C * ) + t(C * )] is small. The ideal joint hypothesis C * may not be unique, since in practice we always have the same error obtained by two different machine learning models. Denote a set of ideal joint hypotheses by H * , which is a subset of H, i.e., H * ⊂ H. Based on this assumption, domain adaptation aims to reduce the domain discrepancy | s(C, C * ) − t(C, C * )|. Let c = C(z) be the proxy of the label vector y of z, for every pair of (z, y) ∼ P s Z,Y ∪ P t Z,Y . Denote the thus obtained proxies of the joint distributions P s Z,Y and P t Z,Y by P s Z,C = (z, C(z)) z∼P s Z and P t Z,C = (z, C(z)) z∼P t Z , respectively <ref type="bibr" target="#b9">(Courty et al. 2017)</ref> . Based on the two joint distribution proxies, we have the domain discrepancy</p><formula xml:id="formula_18">| s(C, C * ) − t(C, C * )| = |E (z,y)∼P s Z,Y I[C(z) = C * (z)] − E (z,y)∼P t Z,Y I[C(z) = C * (z)]| = |E (z,c)∼P s Z,C I[c = C * (z))] − E (z,c)∼P t Z,C I[c = C * (z)]|. (B.2)</formula><p>Inspired by the two works <ref type="bibr" target="#b5">(Long et al. 2018b;</ref><ref type="bibr">Mansour, Mohri, and Rostamizadeh 2009)</ref>, we next introduce four definitions of the distance measure that can upper bound the domain discrepancy.</p><p>Definition 1. Let FH * = {F (C * (z), c) = I[c = C * (z)]|C * ∈ H * } be a (loss) difference hypothesis space over the joint variable of (C * (z), c), where F : (C * (z), c) → {0, 1} computes the empirical 0-1 classification loss of the task classifier C * ∈ H * for any input pair of (z, c) ∼ P s Z,C ∪ P t Z,C . Then, the FH * -distance between two distributions P s Z,C and P t Z,C , is defined as</p><formula xml:id="formula_19">dF H * (P s Z,C , P t Z,C ) sup F ∈F H * ,C * ∈H * |E (z,c)∼P s Z,C F (C * (z), c) − E (z,c)∼P t Z,C F (C * (z), c)| = sup C * ∈H * |E (z,c)∼P s Z,C I[c = C * (z))] − E (z,c)∼P t Z,C I[c = C * (z)]|. (B.3)</formula><p>Definition 2. Let F be a (loss) difference hypothesis space, which contains a class of functions F : (z, c) → {0, 1} over the joint variable of (z, c) ∼ P s Z,C ∪ P t Z,C . Then, the F-distance between two distributions P s Z,C and P t Z,C , is defined as</p><formula xml:id="formula_20">dF (P s Z,C , P t Z,C ) sup F ∈F |E (z,c)∼P s Z,C F (z, c) − E (z,c)∼P t Z,C F (z, c)|. (B.4)</formula><p>Definition 3. Let FH = {F : (C (z), c) → {0, 1}|C ∈ H} be a (loss) difference hypothesis space over the joint variable of (C (z), c), where F (C (z), c) computes the empirical 0-1 classification loss of the task classifier C ∈ H for any input pair of (z, c) ∼ P s Z,C ∪ P t Z,C . Then, the FH-distance between two distributions P s Z,C and P t Z,C , is defined as</p><formula xml:id="formula_21">dF H (P s Z,C , P t Z,C ) sup F ∈F H ,C ∈H |E (z,c)∼P s Z,C F (C (z), c) − E (z,c)∼P t Z,C F (C (z), c)|. (B.5)</formula><p>Definition 4. Let D be a (loss) difference hypothesis space, which contains a class of functions D : z → {0, 1} over z ∼ P s Z ∪ P t Z . Then, the D-distance between two distributions P s Z,C and P t Z,C , is defined as</p><formula xml:id="formula_22">dD(P s Z , P t Z ) sup D∈D |E z∼P s Z D(z) − E z∼P t Z D(z)|. (B.6)</formula><p>We are now ready to give an upper bound on the domain discrepancy in terms of the distance measures we have defined.</p><p>Theorem 1. The distribution discrepncy between the source and target domains | s(C, C * ) − t(C, C * )| can be upper bounded by the FH * -distance, the FH-distance, the F-distance, and the Ddistance as follows</p><formula xml:id="formula_23">| s(C, C * ) − t(C, C * )| ≤ dF H * (P s Z,C , P t Z,C ) ≤ dF H (P s Z,C , P t Z,C ) ≤ dF (P s Z,C , P t Z,C ) ≤ dD(P s Z , P t Z ). (B.7)</formula><p>Proof <ref type="figure" target="#fig_1">. Comparing (B.2) and (B.3)</ref></p><formula xml:id="formula_24">, since |E (z,c)∼P s Z,C I[c = C * (z))] − E (z,c)∼P t Z,C I[c = C * (z)]| ≤ sup C * ∈H * |E (z,c)∼P s Z,C I[c = C * (z))] − E (z,c)∼P t Z,C I[c = C * (z)]|, we have | s(C, C * ) − t(C, C * )| ≤ dF H * (P s Z,C , P t Z,C )</formula><p>. Since by definition the hypothesis space F contains all functions that map (z, c) to {0, 1}, F (C * (z), c) is also a function in F that can be written as the form of functions in FH * . The hypothesis space FH * is subsumed by F , i.e., FH * ⊂ F .</p><formula xml:id="formula_25">Thus, we have | s(C, C * ) − t(C, C * )| ≤ dF H * (P s Z,C , P t Z,C ) ≤ dF (P s Z,C , P t Z,C ). Similarly, since FH ⊂ F, we have dF H (P s Z,C , P t Z,C ) ≤ dF (P s Z,C , P t Z,C ).</formula><p>Since by definition the ideal joint hypothesis set H * ⊂ H, the hypothesis space FH * is subsumed by FH, i.e., FH * ⊂ FH. Thus, we have | s</p><formula xml:id="formula_26">(C, C * ) − t(C, C * )| ≤ dF H * (P s Z,C , P t Z,C ) ≤ dF H (P s Z,C , P t Z,C )</formula><p>. Since by definition the hypothesis space D contains all functions that map z to {0, 1}, F (z, c) = F (z, C(z)) is also a function in D that can be written as the form of functions in F. The hypothesis space F is subsumed by D, i.e., F ⊂ D. Thus, we have</p><formula xml:id="formula_27">dF (P s Z,C , P t Z,C ) ≤ dD(P s Z , P t Z ). These prove the inequality | s(C, C * ) − t(C, C * )| ≤ dF H * (P s Z,C , P t Z,C ) ≤ dF H (P s Z,C , P t Z,C ) ≤ dF (P s Z,C , P t Z,C ) ≤ dD(P s Z , P t Z ).</formula><p>Theorem 1 shows that the FH * -distance can best upper bound the domain discrepncy | s(C, C * ) − t(C, C * )|, but cannot be computable, since instances on the target domain for unsupervised domain adaptation are unlabeled; the FH-distance can better bound the domain discrepncy | s(C, C * ) − t(C, C * )| than the F-distance and the D-distance, and the hypothesis space FH can be implemented by conditioning the function F (z, c) ∈ F on the other one C(z) ∈ H; the F-distance can tighter bound the domain discrepncy | s(C, C * ) − t(C, C * )| than the D-distance, and the hypothesis space F can be realized by taking as input both the feature representation z and the category prediction c; the D-distance can loosely bound the domain discrepncy | s(C, C * )− t(C, C * )|, and the hypothesis space D can be instantiated by taking as input only the feature representation z. Since existing deep domain adaptation methods are based on deep neuron networks, the inference of the hypothesis space FH * ⊂ FH ⊂ F ⊂ D is reasonable and realistic in that, for any given function, there must exist a feedforward neural network or multilayer perceptron, which can approximate it with arbitrarily small error <ref type="bibr">(Hornik, Stinchcombe, and White 1989;</ref><ref type="bibr" target="#b10">Cybenko 1989)</ref>, however, the effective model capacity is limited by the capabilities of the optimization algorithm <ref type="bibr" target="#b14">(Goodfellow, Bengio, and Courville 2016)</ref>.</p><p>Since these methods <ref type="bibr" target="#b12">(Ganin et al. 2016;</ref><ref type="bibr">Tzeng et al. 2017;</ref><ref type="bibr">Pinheiro 2018;</ref><ref type="bibr">Zhang et al. 2018b;</ref><ref type="bibr">Shu et al. 2018</ref>) are based on a separate domain classifier that takes as input only the feature representation, they aim to measure and minimize the D-distance. Since these methods <ref type="bibr">(Pei et al. 2018;</ref><ref type="bibr" target="#b5">Long et al. 2018b;</ref><ref type="bibr">Wang et al. 2019;</ref><ref type="bibr">Wen et al. 2019</ref>) are based on one or several conditional domain classifiers that take as input both the feature representation and the category prediction, they aim to measure and minimize the Fdistance. Since the recent work <ref type="bibr">(Tran et al. 2019</ref>) and the proposed DADA unify the task and domain classifiers into an integrated one, i.e., conditioning the domain classifier on the task classifier, they aim to measure and minimize the FH-distance. The FH-distance can be upper bounded by the optimal solution of the integrated domain and task classifier F (·). In the meanwhile, the upper bound of FH-distance is minimized by learning a domain-invariant feature extractor G(·).</p><p>Furthermore, our proposed DADA can be intuitively formalized as category-regularized domain-adversarial training, since our proposed discriminative adversarial training can learn an integrated classifier F (·) that has explicit intra-domain discrimination and inter-domain indistinguishability, which may enable a better performed ideal joint hypothesis C * . Consequently, the expected target error t(C ) can be better approximated by the expected source error s(C ). As verified above, our proposed DADA can formally better bound the expected target error than existing domain adaptation methods. Office-31 (Saenko et al. 2010) is a benchmark domain adaptation dataset as introduced in Section Datasets and Implementation Details in the paper. For partial domain adaptation, we select images of 10 categories shared by Office-31 and Caltech-256 <ref type="bibr" target="#b17">(Griffin, Holub, and Perona 2007)</ref> in each domain of Office-31 as the target domain. Note that the source domain here contains 31 categories and the target domain here contains 10 categories. For open set domain adaptation, we use the selected 10 categories as the known categories. In alphabetical order, 11 − 20 categories and 21 − 31 categories are used as the unknown categories in the source and target domains respectively. In this setting, an 11-category classification is performed. Office-Home (Venkateswara et al. 2017) is a much more challenging benchmark dataset for domain adaptation, which includes 15, 500 images of 65 object categories in office and home scenes, shared by four extremely distinct domains: Artistic images (Ar), Clip Art (Cl), Product images (Pr), and Real-World images (Rw). We build 12 adaptation settings: Ar → Cl, Ar → Pr, Ar → Rw, Cl → Ar, Cl → Pr, Cl → Rw, Pr → Ar, Pr → Cl, Pr → Rw, Rw → Ar, Rw → Cl, Rw → Pr. For partial domain adaptation, we choose images of the first 25 categories (in alphabetical order) in each domain of this dataset as target domains. Note that each source domain here contains 65 categories and each target domain here contains 25 categories. ImageNet-Caltech is built from ImageNet (Russakovsky et al. 2015) that contains 1000 categories, and Caltech-256 <ref type="bibr" target="#b17">(Griffin, Holub, and Perona 2007)</ref> that contains 256 categories. They share 84 common categories, thus we construct two adaptation settings: I (1000) → C (84), and C (256) → I (84). When ImageNet is used as the source domain, we use its training set; when it is used as the target domain, we use its validation set to prevent the model from the effect of pre-training on its training set.   <ref type="figure" target="#fig_8">Figure 4</ref>, which shows that the rate of source instances failing to satisfy the condition rises rapidly in the early stage of adversarial training when the λ is not used.</p><p>Alternative Choice of Adversarial Loss for Target Instances For a target adversarial loss, when maximized over the feature extractor G(·), we have an alternative choice. In this section, we give further discussion and experiments to compare our used L t G in loss (4) in the paper with this alternative.   which when maximized over G(·), gives a confused prediction of pK+1(x t ) = 0.5. This result does not give category prediction p y t (x t ) on the unknown true category y t of a target instance x t a chance to approach 1. Thus, this alternative choice is sub-optimal. In contrast, our used L t G in loss (4) in the paper gives a prediction of pK+1(x t ) = 0 when maximized over G(·). This result gives p y t (x t ) a better chance to approach 1, i.e.p y t (x t ) is more likely to approach 1. In other words, the target data are more likely to be correctly classified, which is enabled by our proposed mutually inhibitory relation between the category and domain predictions.</p><p>To compare the effectiveness of our used L t G in loss (4) in the paper and this alternative choice, we conduct experiments on <ref type="bibr">Office-31 (Saenko et al. 2010</ref>) based on <ref type="bibr">ResNet-50 (He et al. 2016)</ref>, by replacing L t G in loss (4) in the paper with the domain confusion loss (C.1) in our main minimax probem (7) in the paper. We denote these this alternative as "DADA-DC". Results in <ref type="table" target="#tab_9">Table 6</ref> and convergence performances in <ref type="figure">Figure 5</ref> show advantages of our used L t G in loss (4) in the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Feature Visualization</head><p>To visualize how different methods are effective at aligning learned features on the source and target domains, we use t-SNE embeddings (van der Maaten and Hinton 2008) to plot the output activations from the feature extractors of "No Adaptation", DANN, DANN-CA, and DADA. <ref type="figure">Figure 6</ref> gives the plotting, where samples are from the adaptation setting of A → W of <ref type="bibr">Office-31 (Saenko et al. 2010</ref>) based on <ref type="bibr">ResNet-50 (He et al. 2016)</ref>. <ref type="figure">Figure 6</ref> shows qualitative improvements of these meth-  <ref type="table" target="#tab_10">Table 7</ref>. Note that results of existing methods are quoted from their respective papers or the recent works <ref type="bibr">(Saito et al. 2018a;</ref><ref type="bibr" target="#b5">2018b)</ref>. We follow these methods and report accuracies on the target test data in the format of mean±std over five random trials. Our proposed DADA consistently achieves a good result on different adaptation settings, showing its excellent robustness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.3 Partial Domain Adaptation.</head><p>For each partial adaptation setting of Office-31, Office-Home, and ImageNet-Caltech, we follow the work <ref type="bibr" target="#b5">(Cao et al. 2018b</ref>) to report the mean classification result on the target domain over three random trials.</p><p>Office-31 We compare in <ref type="table" target="#tab_12">Table 8</ref> our proposed method with existing ones on Office-31 based on <ref type="bibr">ResNet-50 (He et al. 2016</ref>) pretrained on ImageNet <ref type="bibr">(Russakovsky et al. 2015)</ref>. Results of existing methods are quoted from PADA <ref type="bibr" target="#b5">(Cao et al. 2018b</ref>). Our proposed DADA-P outperforms all comparative methods by a large margin, showing the effectiveness of the adopted category-level weighting mechanism on reducing the negative influence of source outliers on adaptation settings with small source domain and small target domain, e.g., A → W. Although PADA uses the same weighting mechanism, it performs much worse than our proposed DADA-P, suggesting the effectiveness of DADA-P on enhancing the positive influence of shared categories. From the experimental results, several interesting observations can be derived. (1) Previous deep domain adaptation methods including those based on domain-adversarial training (e.g., DANN) and those based on MMD (e.g., DAN) perform much worse than the very baseline "No Adaptation", showing the huge impact of negative transfer. Domain-adversarial training based methods aim to learn domain-invariant intermediate features to deceive the domain classifier, and MMD based methods aim to minimize the dis-crepancy between data distributions of the source and target domains. Both of them align the whole source domain to the whole target one. However, in partial domain adaptation, since the source domain contains categories that do not exist in the target domain, i.e., outlier source categories, they will suffer false alignment between the outlier source categories and the target domain. This explains their poor performance in partial domain adaptation.</p><p>(2) Among previous deep domain adaptation methods, RTN is the only one that performs better than "No Adaptation". RTN exploits the entropy minimization principle <ref type="bibr" target="#b16">(Grandvalet and Bengio 2005)</ref> to encourage the low-density separation of target categories. Its target task classifier directly has access to the unlabeled target data and can amend itself to pass through the target low-density regions where the outlier source categories may exist, which alleviate the negative influence of source outliers. Nevertheless, PADA, which does not use the entropy minimization principle but a category-level weighting mechanism, performs much better than RTN, demonstrating that RTN still suffers negative transfer and may be not able to bridge such a large domain discrepancy caused by different label spaces. (3) Although our proposed DADA-P applies the same weighting mechanism as PADA, it performs much better than PADA. PADA has a separate design of task and domain classifiers and only aims to align marginal feature distributions, whereas our proposed DADA-P based on an integrated domain and task classifier, aims to promote the joint distribution alignment across domains. This explains the good performance of our proposed method in partial domain adaptation.</p><p>To investigate a wider spectrum of partial domain adaptation, we conduct experiments by varying the number of target categories. <ref type="figure" target="#fig_10">Figure 7</ref> shows results for the baseline DANN <ref type="bibr" target="#b12">(Ganin et al. 2016)</ref> and our proposed DADA-P on the partial adaptation setting A → W of Office-31 with a base network of ResNet-50. The source domain has always 31 categories, but the number of target categories varies from 30 to 10, i.e., <ref type="bibr">{30, 28, 26, 24, 22, 20, 18, 16, 14, 12, 10}</ref>. As the number of target categories decreases, performances of the two methods have no evident decline in spite of the aggravation of negative transfer effect, since the difficulty of domain adaptation problem itself becomes smaller. We observe a sharp rise and a dramatic drop when the number of target categories decreases from 20 to 18 and from 14 to 12 respectively. One explanation is that the positive influence incurred by reducing the difficulty of domain adaptation problem itself is more (for the former observation) or less (for the latter one) than the negative influence caused by increasing the domain discrepancy. The results show that our proposed DADA-P performs much better than DANN in all settings. It is noteworthy   that the relative performance improvement becomes larger when the number of target categories decreases, testifying the superiority of our methods in reducing the influence of negative transfer. Thus, given a source domain, our methods can perform much better when applied to the target domain with unknown number of categories. We compare in <ref type="table" target="#tab_13">Table 9</ref> our proposed method with existing ones on Office-31 based on AlexNet (Krizhevsky, Sutskever, and Hinton 2012) pre-trained on ImageNet. Results of existing methods are quoted from their respective papers or SAN <ref type="bibr" target="#b4">(Cao et al. 2018a</ref>). Our proposed DADA-P achieves a much better result than all comparative methods, showing the efficacy of our methods with a shallower neuron network as the base network. <ref type="figure">Figure 8</ref>: The accuracy curve of varying the number of source categories for the baseline DANN <ref type="bibr" target="#b12">(Ganin et al. 2016)</ref> and our proposed DADA-P on the partial adaptation setting A → W of Office-31 with a base network of AlexNet.</p><p>To investigate the influence of the number of outlier source categories on the performance, we conduct experiments by varying the number of source categories. <ref type="figure">Figure 8</ref> shows results for the baseline DANN <ref type="bibr" target="#b12">(Ganin et al. 2016</ref>) and our proposed DADA-P on the partial adaptation setting A → W of Office-31 with a base network of AlexNet. The target domain has always 10 categories, but the number of source categories varies from 12 to 31, i.e., <ref type="bibr">{12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 31}</ref>. As the number of source categories increases, performances of the two methods have evident decline but also some rises, e.g., when the number of source categories increases from 22 to 24 and from 28 to 30. One explanation is that the positive influence incurred by increasing dis-  criminative information of categories, especially those related to the target domain, is more than the negative influence caused by increasing the domain discrepancy. The results show that our proposed DADA-P significantly outperforms DANN in all settings. Particularly, the relative performance improvement is larger when the number of source categories is larger, demonstrating that our methods are more robust to the number of outlier source categories. Thus, for a given target task, our methods can have a much better performance when utilizing different source tasks.</p><p>Office-Home We compare in <ref type="table" target="#tab_1">Table 10</ref> our proposed method with existing ones on Office-Home based on ResNet-50. Results of existing methods are quoted from PADA <ref type="bibr" target="#b5">(Cao et al. 2018b</ref>). Our proposed DADA-P significantly outperforms all comparative methods, showing the efficacy of DADA-P on adaptation settings with more categories in both the source and target domains and larger domain discrepancy between the two domains, e.g., Cl → Rw.</p><p>ImageNet-Caltech We compare in <ref type="table" target="#tab_1">Table 11</ref> our proposed method with existing ones on ImageNet-Caltech based on ResNet-50. Results of existing methods are quoted from PADA <ref type="bibr" target="#b5">(Cao et al. 2018b</ref>). Our proposed DADA-P outperforms all comparative methods by a large margin, showing the effectiveness of DADA-P on adaptation settings with large-scale source and target domains and a large number of categories in the two domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.4 Open Set Domain Adaptation.</head><p>We compare in (1) DAN and DANN perform much worse than "No Adaptation". DAN and DANN aim to align the whole marginal feature distributions across the source and target domains. If the target domain contains unknown instances, false alignment between the known source instances and unknown target ones will occur, resulting in a sharp drop of the classification performance.</p><p>(2) DANN performs worse than DAN, since DANN is better at aligning marginal feature distributions across data domains, leading to more serious false alignment.</p><p>(3) ATI-λ and AODA can effectively reduce false alignment, since they have a good outlier rejection mechanism to recognize the unknown instances. (4) The results of all comparative methods on almost all adaptation settings are better in the evaluation metric OS than OS*, showing that many known target instances are classified as the unknown category. Since Open-set SVM is trained to detect outliers and the task classifier of AODA is trained to recognize all the target instances as the unknown category, they are inclined to classify the target instances as the unknown category. (5) For our proposed DADA-O, the results of all adaptation settings are better in the evaluation metric OS* than OS, since their classifiers are trained to classify all target instance as the unknown category with a small probability q, which can minimize the misclassification of the known target instances as the unknown category. <ref type="figure">Figure 9</ref>: The accuracy curve of varying q for our proposed DADA-O on the open set adaptation setting A → W of Office-31 with a base network of AlexNet. The accuracy for unknown target instances is denoted by the blue line.</p><p>To investigate the influence of q on the performance, we conduct experiments by varying q. <ref type="figure">Figure 9</ref> shows results for our proposed DADA on the open set adaptation setting A → W of Office-31 with a base network of AlexNet. As q increases, accuracies of OS and OS* decrease and the accuracy of Unknown increases, which means that the target instances are more likely classified as the unknown category. This confirms the statements we present in Section Extension for Open Set Domain Adaptation in the paper. When q = 0, the objective of the feature extractor is to align the whole source domain and the whole target domain, resulting in the misclassification of all unknown target instances as the known categories, as illustrated in <ref type="figure">Figure 9</ref>. This demonstrates that the model does not learn feature representations that can separate the unknown target instances from the known instances. To make a trade-off, we empirically set q = 0.1 for all open set adaptation settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Investigation for Our Used Training Scheme</head><p>In this section, we investigate our used training scheme of pretraining DADA on the labeled source data and maintaining the same supervision signal in the adversarial training of DADA, on benchmark datasets of <ref type="bibr">MNIST (Lecun et al. 1998</ref>) and USPS (Hull 1994), where two adaptation settings of MNIST→USPS and USPS→MNIST are built.</p><p>To always satisfy the condition of p s y s &gt; 0.5 discussed in Section Discriminative Adversarial Learning in the paper, we train DADA of F (G(·)) by a well-designed scheme, which can be formulated as alternating the classification training on the labeled source data and the adversarial training of DADA on the labeled source data and unlabeled target data. We denote the number of training epochs or training iterations for classification training in each alternation respectively as T cls andT cls , the number of training epochs or training iterations for adversarial training in each alternation respectively as T adv andT adv , and the number of alternating the classification training and adversarial training as N alter . For the two adaptation settings of MNIST→USPS and USPS→MNIST, T cls , T adv , and N alter are respectively set to 10, 2, and 16, according to the rate of source instances failing to satisfy the condition; the hyper-parameter λ (cf. Section Discriminative Adversarial Learning in the paper for its definition) is not used, since T adv is a quite small number. We investigate the efficacy of our used training scheme on keeping the condition satisfied by visualizing training processes on the two adaptation settings in <ref type="figure" target="#fig_0">Figure 10</ref>.</p><p>From <ref type="figure" target="#fig_0">Figure 10</ref>, we can obtain several interesting observations. (1) The classification training makes "Rate of Source Instances Failing to Satisfy Condition" fall into a valley whereas the adversarial training of DADA makes it rise to a peak, showing that a part of source instances change from satisfying the condition to not satisfying it during adversarial training. (2) "Rate of Source Instances Failing to Satisfy Condition (No Target Data)" is much lower than "Rate of Source Instances Failing to Satisfy Condition" at epochs of adversarial training, showing that the training of target data affects the source data and results in that a part of them do not satisfy the condition.  <ref type="formula" target="#formula_6">6)</ref> The good performances of DADA on the two adaptation settings of MNIST→USPS and USPS→MNIST, which are very close to the perfect performance of 100%, confirm the efficacy of our proposed DADA in aligning the joint distributions of feature and category across the two domains.</p><p>For each closed set adaptation setting of Office-31, T cls ,T adv , and N alter are respectively set to 200, 800, and 1. For the closed set adaptation setting of Syn2Real,T cls ,T adv , and N alter are respectively set to 2000, 1000, 1. For all these adaptation settings, the hyper-parameter λ is used. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>(Best viewed in color.) Discriminative Adversarial Domain Adaptation (DADA)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Average probability on the true category over all target instances by task classifiers of different methods.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>:550-554. Jain, L. P.; Scheirer, W. J.; and Boult, T. E. 2014. Multi-class open set recognition using probability of inclusion. In European Conference on Computer Vision. Kim, M.; Sahu, P.; Gholami, B.; and Pavlovic, V. 2019. Unsupervised visual domain adaptation: A deep max-margin gaussian process approach. In Computer Vision and Pattern Recognition. Krizhevsky, A.; Sutskever, I.; and Hinton, G. E. 2012. Imagenet classification with deep convolutional neural networks. In Pereira, F.; Burges, C. J. C.; Bottou, L.; and Weinberger, K. Q., eds., Advances in Neural Information Processing Systems 25. Curran Associates, Inc.1097-1105. Kurmi, V. K., and Namboodiri, V. P. 2019. Looking back at labels: A class based domain adaptation technique. ArXiv abs/1904.01341. Lecun, Y.; Bottou, L.; Bengio, Y.; and Haffner, P. 1998. Gradientbased learning applied to document recognition. Proceedings of the IEEE 86(11):2278-2324. Lee, C.-Y.; Batra, T.; Baig, M. H.; and Ulbricht, D. 2019. Sliced wasserstein discrepancy for unsupervised domain adaptation. In Computer Vision and Pattern Recognition. Li, S.; Song, S.; and Wu, C. 2018. Layer-wise domain correction for unsupervised domain adaptation. Frontiers of Information Technology and Electronic Engineering 19:91-103. Liu, M.-Y., and Tuzel, O. 2016. Coupled generative adversarial networks. In Advances in Neural Information Processing Systems. Liu, H.; Long, M.; Wang, J.; and Jordan, M. 2019. Transferable adversarial training: A general approach to adapting deep classifiers. In International Conference on Machine Learning. Long, M.; Zhu, H.; Wang, J.; and Jordan, M. I. 2016. Unsupervised domain adaptation with residual transfer networks. In Advances in Neural Information Processing Systems. Curran Associates Inc. Long, M.; Zhu, H.; Wang, J.; and Jordan, M. I. 2017. Deep transfer learning with joint adaptation networks. In International Conference on Machine Learning. Long, M.; Cao, Y.; Cao, Z.; Wang, J.; and Jordan, M. I. 2018a. Transferable representation learning with deep adaptation networks. IEEE Transactions on Pattern Analysis and Machine Intelligence 1-1. Long, M.; CAO, Z.; Wang, J.; and Jordan, M. I. 2018b. Conditional adversarial domain adaptation. In Bengio, S.; Wallach, H.; Larochelle, H.; Grauman, K.; Cesa-Bianchi, N.; and Garnett, R., eds., Advances in Neural Information Processing Systems 31. Curran Associates, Inc. 1640-1650. Luo, Z.; Zou, Y.; Hoffman, J.; and Fei-Fei, L. F. 2017. Label efficient learning of transferable representations acrosss domains and tasks. In Guyon, I.; Luxburg, U. V.; Bengio, S.; Wallach, H.; Fergus, R.; Vishwanathan, S.; and Garnett, R., eds., Advances in Neural Information Processing Systems 30. Curran Associates, Inc. 165-177. Mansour, Y.; Mohri, M.; and Rostamizadeh, A. 2009. Domain adaptation: Learning bounds and algorithms. COLT 2009 -The 22nd Conference on Learning Theory. Morerio, P.; Cavazza, J.; and Murino, V. 2018. Minimal-entropy correlation alignment for unsupervised deep domain adaptation. In International Conference on Learning Representations. Nalewajski, R. F. 2012. Elements of Information Theory. Berlin, Heidelberg: Springer Berlin Heidelberg. 371-395. Netzer, Y.; Wang, T.; Coates, A.; Bissacco, A.; Wu, B.; and Ng, A. Y. 2011. Reading digits in natural images with unsupervised feature learning. In NIPS Workshop on Deep Learning and Unsupervised Feature Learning 2011. Pan, S. J., and Yang, Q. 2010. A survey on transfer learning. IEEE Transactions on Knowledge and Data Engineering 22:1345-1359. Pan, Y.; Yao, T.; Li, Y.; Wang, Y.; Ngo, C.-W.; and Mei, T. 2019. Transferrable prototypical networks for unsupervised domain adaptation. Computer Vision and Pattern Recognition.Pei, Z.; Cao, Z.; Long, M.; and Wang, J. 2018. Multi-adversarial domain adaptation. In Association for the Advancement of Artificial Intelligence. Peng, X.; Usman, B.; Saito, K.; Kaushik, N.; Hoffman, J.; and Saenko, K. 2018. Syn2real: A new benchmark forsynthetic-to-real visual domain adaptation. ArXiv abs/1806.09755. Pinheiro, P. O. 2018. Unsupervised domain adaptation with similarity learning. In Computer Vision and Pattern Recognition. Russakovsky, O.; Deng, J.; Su, H.; Krause, J.; Satheesh, S.; Ma, S.; Huang, Z.; Karpathy, A.; Khosla, A.; Bernstein, M.; et al. 2015. Imagenet large scale visual recognition challenge. International Journal of Computer Vision 115(3):211-252. Russo, P.; Carlucci, F. M.; Tommasi, T.; and Caputo, B. 2018. From source to target and back: Symmetric bi-directional adaptive gan. In Computer Vision and Pattern Recognition. Saenko, K.; Kulis, B.; Fritz, M.; and Darrell, T. 2010. Adapting visual category models to new domains. In European Conference on Computer Vision. Saito, K.; Ushiku, Y.; Harada, T.; and Saenko, K. 2018a. Adversarial dropout regularization. In International Conference on Learning Representations. Saito, K.; Watanabe, K.; Ushiku, Y.; and Harada, T. 2018b. Maximum classifier discrepancy for unsupervised domain adaptation. In Computer Vision and Pattern Recognition. Saito, K.; Yamamoto, S.; Ushiku, Y.; and Harada, T. 2018c. Open set domain adaptation by backpropagation. In European Conference on Computer Vision. Salimans, T.; Goodfellow, I.; Zaremba, W.; Cheung, V.; Radford, A.; Chen, X.; and Chen, X. 2016. Improved techniques for training gans. In Lee, D. D.; Sugiyama, M.; Luxburg, U. V.; Guyon, I.; and Garnett, R., eds., Advances in Neural Information Processing Systems 29. Curran Associates, Inc. 2234-2242. Sankaranarayanan, S.; Balaji, Y.; Castillo, C. D.; and Chellappa, R. 2018. Generate to adapt: Aligning domains using generative adversarial networks. In Computer Vision and Pattern Recognition. Shu, R.; Bui, H.; Narui, H.; and Ermon, S. 2018. A DIRT-t approach to unsupervised domain adaptation. In International Conference on Learning Representations. Tran, L.; Sohn, K.; Yu, X.; Liu, X.; and Chandraker, M. K. 2019. Gotta adapt 'em all: Joint pixel and feature-level domain adaptation for recognition in the wild. In Computer Vision and Pattern Recognition. Tzeng, E.; Hoffman, J.; Zhang, N.; Saenko, K.; and Darrell, T. 2014. Deep domain confusion: Maximizing for domain invariance. CoRR abs/1412.3474. Tzeng, E.; Hoffman, J.; Darrell, T.; and Saenko, K. 2015. Simultaneous deep transfer across domains and tasks. In International Conference on Computer Vision. Tzeng, E.; Hoffman, J.; Saenko, K.; and Darrell, T. 2017. Adversarial discriminative domain adaptation. In Computer Vision and Pattern Recognition. van der Maaten, L., and Hinton, G. 2008. Visualizing data using t-sne. Journal of Machine Learning Research 9 (Nov):25792605. Venkateswara, H.; Eusebio, J.; Chakraborty, S.; and Panchanathan, S. 2017. Deep hashing network for unsupervised domain adaptation. Computer Vision and Pattern Recognition 5385-5394. Wang, X.; Li, L.; Ye, W.; Long, M.; and Wang, J. 2019. Transferable attention for domain adaptation. In Association for the Advancement of Artificial Intelligence. Wen, J.; Liu, R.; Zheng, N.; Zheng, Q.; Gong, Z.; and Yuan, J. 2019. Exploiting local feature patterns for unsupervised domain adaptation. In Association for the Advancement of Artificial Intelligence. Xie, S.; Zheng, Z.; Chen, L.; and Chen, C. 2018. Learning semantic representations for unsupervised domain adaptation. In Dy, J., and Krause, A., eds., Proceedings of the 35th International Conference on Machine Learning, volume 80 of Proceedings of Machine Learning Research, 5423-5432. Stockholmsmssan, Stockholm Sweden: PMLR. Yosinski, J.; Clune, J.; Bengio, Y.; and Lipson, H. 2014. How transferable are features in deep neural networks? In Ghahramani, Z.; Welling, M.; Cortes, C.; Lawrence, N. D.; and Weinberger, K. Q., eds., Advances in Neural Information Processing Systems. Curran Associates, Inc. 3320-3328. Zhang, J.; Ding, Z.; Li, W.; and Ogunbona, P. 2018a. Importance weighted adversarial nets for partial domain adaptation. In Computer Vision and Pattern Recognition. Zhang, W.; Ouyang, W.; Li, W.; and Xu, D. 2018b. Collaborative and adversarial network for unsupervised domain adaptation. In Computer Vision and Pattern Recognition. Zhang, Y.; Tang, H.; Jia, K.; and Tan, M. 2019. Domain-symmetric networks for adversarial domain adaptation. In Computer Vision and Pattern Recognition. Zhang, Y.; Tang, H.; and Jia, K. 2018. Fine-grained visual categorization using meta-learning optimization with sample selection of auxiliary data. In The European Conference on Computer Vision. Zou, H.; Zhou, Y.; Yang, J.; Liu, H.; Das, H. P.; and Spanos, C. J. 2019. Consensus adversarial domain adaptation. In Association for the Advancement of Artificial Intelligence.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc><ref type="bibr" target="#b12">Ganin et al. 2016;</ref> Tzeng et al. 2017; Pei et al. 2018; Pinheiro 2018; Zhang et  al. 2018b; Shu et al. 2018;<ref type="bibr" target="#b5">Long et al. 2018b;</ref> Wang et al. 2019;  Wen et al. 2019; Tran et al. 2019), taking the similar formalism of theoretical results of domain adaptation<ref type="bibr" target="#b0">(Ben-David et al. 2007;</ref><ref type="bibr" target="#b1">2010)</ref>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>P t Z and P t Z,Y for the target domain Dt, respectively. Lets(C ) = E (z,y)∼P s Z,Y I[C(z) = y] be the expected source error of a hypothesis C ∈ H w.r.t. the joint distribution P s Z,Y , where I[a] is the indicator function which is 1 if predicate a is true, and 0 otherwise. Similarly, t(C ) = E (z,y)∼P t Z,YI[C(z) = y] denotes the expected target error of C w.r.t. the joint distribution P t Z,Y . Let C * = argmin C∈H [ s(C ) + t(C )] be the ideal joint hypothesis that explicitly embodies the notion of adaptability (Ben-David et al. 2010). Let s(C, C * ) = E (z,y)∼P s Z,Y I[C(z) = C * (z)] and t(C, C * ) = E (z,y)∼P t Z,Y I[C(z) = C * (z)] be the disagreement between hypotheses C and C * w.r.t. the joint distributions P s Z,Y</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>. Then, by definition, s(C, C * ) = E (z,y)∼P s Z,Y I[C(z) = C * (z)] = E (z,c)∼P s Z,C I[c = C * (z))], and similarly t(C, C * ) = E (z,y)∼P t Z,Y I[C(z) = C * (z)] = E (z,c)∼P t Z,C I[c = C * (z)]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>C</head><label></label><figDesc>Additional Results and Analysis C.1 Datasets Digits datasets of MNIST (Lecun et al. 1998), Street View House Numbers (SVHN) (Netzer et al. 2011), and USPS (Hull 1994) are popular. we follow ADR (Saito et al. 2018a) and evaluate on three adaptation settings of SVHN→MNIST, MNIST→USPS, and USPS→MNIST. For all adaptation settings, we adopt the same network architecture and experimental setting as ADR.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 4 :</head><label>4</label><figDesc>An illustration for the effect of the λ on the rate of source instances failing to satisfy the condition in the early stage (e.g., the first 100 iterations) of adversarial training on the two adaptation settings of (a) A→D and (b) D→A. C.2 Closed Set Domain Adaptation. Effect of the λ We provide the empirical evidence on Office-31 (Saenko et al. 2010) based on ResNet-50 (He et al. 2016) for the effect of the hyper-parameter λ on keeping the source instances satisfying the condition of p s y s &gt; 0.5 (cf. Section Discriminative Adversarial Learning in the paper for its derivation) in the early stage of adversarial training of DADA in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>Inspired by the works (Tzeng et al. 2015; Zhang et al. 2019), one may opt for a symmetric adversarial loss L t G (G, F )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 7 :</head><label>7</label><figDesc>The accuracy curve of varying the number of target categories for the baseline DANN<ref type="bibr" target="#b12">(Ganin et al. 2016</ref>) and our proposed DADA-P on the partial adaptation setting A → W of Office-31 with a base network of ResNet-50.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>(3) "Rate of Source Instances Failing to Satisfy Condition" declines to a very low value in an oscillatory manner, showing the efficacy of this training scheme on keeping the condition satisfied. (4) "Training Error of Source Data" is low at epochs of adversarial training, showing that our proposed DADA has the same effect as classification training. (5) All valleys of "Test Error of Target Data" are derived from the adversarial training of DADA, showing the excellent efficacy of our proposed DADA in aligning the source and target domains. (6) At epochs of adversarial training, the lower "Rate of Source Instances Failing to Satisfy Condition" is, the more improvement of performance is obtained, showing the necessity of satisfying the condition. (</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>(a) MNIST→USPS (N alter = 32) (b) USPS→MNIST (N alter = 32)Figure 10: Training processes in terms of the test error of the target data for each epoch, the test error of the target data for each epoch of adversarial training, the training error of the source data for each epoch, the rate of source instances failing to satisfy the condition for each epoch, and the rate of source instances failing to satisfy the condition for each epoch when no target data is used in the adversarial training, on the two adaptation settings of (a) MNIST→USPS and (b) USPS→MNIST.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Ablation studies using Office-31 based on ResNet-50. Please refer to the main text for how they are defined.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Avg No Adaptation 79.9±0.3 96.8±0.4 99.5±0.1 84.1±0.4 64.5±0.3 66.4±0.4 81.9 DANN 81.2±0.3 98.0±0.2 99.8±0.0 83.3±0.3 66.8±0.3 66.1±0.3 82.5 DANN-CA 85.4±0.4 98.2±0.2 99.8±0.0 87.1±0.4 68.5±0.2 67.6±0.3 84.4 DADA (w/o em + w/o td) 91.0±0.2 98.7±0.1 100.0±0.0 90.8±0.2 70.9±0.3 70.2±0.3 86.9 DADA (w/o em) 91.8±0.1 99.0±0.1 100.0±0.0 92.5±0.3 72.8±0.2 72.3±0.3 88.1 DADA 92.3±0.1 99.2±0.1 100.0±0.0 93.9±0.2 74.4±0.1 74.2±0.1 89.0</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Results for closed set domain adaptation on Office-31 based on ResNet-50. Note that SimNet is implemented by an unknown framework; MADA and DANN-CA are implemented by Caffe; all the other methods are implemented by PyTorch.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>Sankaranarayanan et al. 2018) 89.5±0.5 97.9±0.3 99.8±0.4 87.7±0.5 72.8±0.3 71.4±0.4 86.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Avg</cell></row><row><cell>No Adaptation (He et al. 2016)</cell><cell cols="7">79.9±0.3 96.8±0.4 99.5±0.1 84.1±0.4 64.5±0.3 66.4±0.4 81.9</cell></row><row><cell>DAN (Long et al. 2018a)</cell><cell cols="7">81.3±0.3 97.2±0.0 99.8±0.0 83.1±0.2 66.3±0.0 66.3±0.1 82.3</cell></row><row><cell>DANN (Ganin et al. 2016)</cell><cell cols="7">81.2±0.3 98.0±0.2 99.8±0.0 83.3±0.3 66.8±0.3 66.1±0.3 82.5</cell></row><row><cell>ADDA (Tzeng et al. 2017)</cell><cell cols="7">86.2±0.5 96.2±0.3 98.4±0.3 77.8±0.3 69.5±0.4 68.9±0.5 82.9</cell></row><row><cell>MADA (Pei et al. 2018)</cell><cell cols="7">90.0±0.1 97.4±0.1 99.6±0.1 87.8±0.2 70.3±0.3 66.4±0.3 85.2</cell></row><row><cell>VADA (Shu et al. 2018)</cell><cell cols="7">86.5±0.5 98.2±0.4 99.7±0.2 86.7±0.4 70.1±0.4 70.5±0.4 85.4</cell></row><row><cell>DANN-CA (Tran et al. 2019)</cell><cell>91.35</cell><cell>98.24</cell><cell>99.48</cell><cell>89.94</cell><cell>69.63</cell><cell>68.76</cell><cell>86.2</cell></row><row><cell>GTA (</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>5 MCD (Saito et al. 2018b) 88.6±0.2 98.5±0.1 100.0±0.0 92.2±0.2 69.5±0.1 69.7±0.3 86.5 CDAN+E (Long et al. 2018b) 94.1±0.1 98.6±0.1 100.0±0.0 92.9±0.2 71.0±0.3 69.3±0.3 87.7 TADA (Wang et al. 2019) 94.3±0.3 98.7±0.1 99.8±0.2 91.6±0.3 72.9±0.2 73.0±0.3 88.4 SymNets (Zhang et al. 2019) 90.8±0.1 98.8±0.3 100.0±0.0 93.9±0.5 74.6±0.6 72.5±0.5 88.4 TAT (Liu et al. 2019) 92.5±0.3 99.3±0.1 100.0±0.0 93.2±0.2 73.1±0.3 72.1±0.3 88.4 DADA 92.3±0.1 99.2±0.1 100.0±0.0 93.9±0.2 74.4±0.1 74.2±0.1 89.0</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>Results for closed set domain adaptation on Syn2Real-C based on ResNet-101. Note that all compared methods are based on PyTorch implementation.</figDesc><table><row><cell>Methods</cell><cell cols="2">plane bcycl bus</cell><cell cols="9">car horse knife mcycl person plant sktbrd train truck mean</cell></row><row><cell cols="2">No Adaptation (He et al. 2016) 55.1</cell><cell cols="2">53.3 61.9 59.1 80.6</cell><cell>17.9</cell><cell>79.7</cell><cell>31.2</cell><cell>81.0</cell><cell>26.5</cell><cell>73.5</cell><cell>8.5</cell><cell>52.4</cell></row><row><cell>DANN (Ganin et al. 2016)</cell><cell>81.9</cell><cell cols="2">77.7 82.8 44.3 81.2</cell><cell>29.5</cell><cell>65.1</cell><cell>28.6</cell><cell>51.9</cell><cell>54.6</cell><cell>82.8</cell><cell>7.8</cell><cell>57.4</cell></row><row><cell>DAN (Long et al. 2018a)</cell><cell>87.1</cell><cell cols="2">63.0 76.5 42.0 90.3</cell><cell>42.9</cell><cell>85.9</cell><cell>53.1</cell><cell>49.7</cell><cell>36.3</cell><cell cols="2">85.8 20.7</cell><cell>61.1</cell></row><row><cell>MCD (Saito et al. 2018b)</cell><cell>87.0</cell><cell cols="2">60.9 83.7 64.0 88.9</cell><cell>79.6</cell><cell>84.7</cell><cell>76.9</cell><cell>88.6</cell><cell>40.3</cell><cell cols="2">83.0 25.8</cell><cell>71.9</cell></row><row><cell>GPDA (Kim et al. 2019)</cell><cell>83.0</cell><cell cols="2">74.3 80.4 66.0 87.6</cell><cell>75.3</cell><cell>83.8</cell><cell>73.1</cell><cell>90.1</cell><cell>57.3</cell><cell cols="2">80.2 37.9</cell><cell>73.3</cell></row><row><cell>ADR (Saito et al. 2018a)</cell><cell>87.8</cell><cell cols="2">79.5 83.7 65.3 92.3</cell><cell>61.8</cell><cell>88.9</cell><cell>73.2</cell><cell>87.8</cell><cell>60.0</cell><cell cols="2">85.5 32.3</cell><cell>74.8</cell></row><row><cell>DADA</cell><cell>92.9</cell><cell cols="2">74.2 82.5 65.0 90.9</cell><cell>93.8</cell><cell>87.2</cell><cell>74.2</cell><cell>89.9</cell><cell>71.5</cell><cell cols="2">86.5 48.7</cell><cell>79.8</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>Results for open set domain adaptation on Syn2Real-O based on ResNet-152. Known indicates the mean classification result over the known categories whereas Mean also includes the unknown category. The table below shows the results when the Known-to-Unknown Ratio in the target domain is set to 1 : 10. All compared methods are based on PyTorch implementation.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="5">Known-to-Unknown Ratio = 1 : 1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Methods</cell><cell cols="14">plane bcycl bus car horse knife mcycl person plant sktbrd train truck unk Known Mean</cell></row><row><cell>No Adaptation (He et al. 2016)</cell><cell>49</cell><cell>20</cell><cell>29 47</cell><cell>62</cell><cell>27</cell><cell>79</cell><cell>3</cell><cell>37</cell><cell>19</cell><cell>70</cell><cell>1</cell><cell>62</cell><cell>36</cell><cell>38</cell></row><row><cell>DAN (Long et al. 2018a)</cell><cell>51</cell><cell>40</cell><cell>42 56</cell><cell>68</cell><cell>24</cell><cell>75</cell><cell>2</cell><cell>39</cell><cell>30</cell><cell>71</cell><cell>2</cell><cell>75</cell><cell>41</cell><cell>44</cell></row><row><cell>DANN (Ganin et al. 2016)</cell><cell>59</cell><cell>41</cell><cell>16 54</cell><cell>77</cell><cell>18</cell><cell>88</cell><cell>4</cell><cell>44</cell><cell>32</cell><cell>68</cell><cell>4</cell><cell>61</cell><cell>42</cell><cell>43</cell></row><row><cell>AODA (Saito et al. 2018c)</cell><cell>85</cell><cell>71</cell><cell>65 53</cell><cell>83</cell><cell>10</cell><cell>79</cell><cell>36</cell><cell>73</cell><cell>56</cell><cell>79</cell><cell>32</cell><cell>87</cell><cell>60</cell><cell>62</cell></row><row><cell>DADA-O</cell><cell>88</cell><cell>76</cell><cell>76 64</cell><cell>79</cell><cell>46</cell><cell>91</cell><cell>62</cell><cell>52</cell><cell>63</cell><cell>86</cell><cell>8</cell><cell>55</cell><cell>66</cell><cell>65</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="5">Known-to-Unknown Ratio = 1 : 10</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>AODA (Saito et al. 2018c)</cell><cell>80</cell><cell>63</cell><cell>59 63</cell><cell>83</cell><cell>12</cell><cell>89</cell><cell>5</cell><cell>61</cell><cell>14</cell><cell>79</cell><cell>0</cell><cell>69</cell><cell>51</cell><cell>52</cell></row><row><cell>DADA-O</cell><cell>77</cell><cell>63</cell><cell>75 71</cell><cell>38</cell><cell>33</cell><cell>92</cell><cell>58</cell><cell>47</cell><cell>50</cell><cell>89</cell><cell>1</cell><cell>50</cell><cell>58</cell><cell>57</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 :</head><label>5</label><figDesc>Results for partial domain adaptation on Syn2Real-C based on ResNet-50. Note that all compared methods are based on PyTorch implementation.ResNet-50. Results of existing methods are quoted from the work<ref type="bibr" target="#b5">(Cao et al. 2018b</ref>). Our proposed DADA-P substantially outperforms all comparative methods by +15.53%, showing the effectiveness of DADA-P on reducing the negative influence of source outliers while promoting the joint distribution alignment in the shared label space. Open Set Domain Adaptation We compare inTable 4our proposed method with existing ones on Syn2Real-O based on ResNet-152. Results of existing methods are quoted from the recent work (Peng et al. 2018). Our proposed DADA-O outperforms all comparative methods in both evaluation metrics of Known and Mean, showing the efficacy of DADA-O in both aligning joint distributions of the known instances and identifying the unknown target instances.</figDesc><table><row><cell>Methods</cell><cell>Synthetic 12→Real 6</cell></row><row><cell>No Adaptation (He et al. 2016)</cell><cell>45.26</cell></row><row><cell>DAN (Long et al. 2018a)</cell><cell>47.60</cell></row><row><cell>DANN (Ganin et al. 2016)</cell><cell>51.01</cell></row><row><cell>RTN (Long et al. 2016)</cell><cell>50.04</cell></row><row><cell>PADA (Cao et al. 2018b)</cell><cell>53.53</cell></row><row><cell>DADA-P</cell><cell>69.06</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>He, K.; Zhang, X.; Ren, S.; and Sun, J. 2016. Deep residual learning for image recognition. In Computer Vision and Pattern Recognition. Hoffman, J.; Tzeng, E.; Park, T.; Zhu, J.-Y.; Isola, P.; Saenko, K.; Efros, A.; and Darrell, T. 2018. CyCADA: Cycle-consistent adversarial domain adaptation. In International Conference on Machine Learning. Hornik, K.; Stinchcombe, M.; and White, H. 1989. Multilayer feedforward networks are universal approximators. Neural Networks 2(5):359 -366. Hull, J. J. 1994. A database for handwritten text recognition research. IEEE Transactions on Pattern Analysis and Machine Intelligence 16</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 6 :</head><label>6</label><figDesc>Comparison on Office-31 based on ResNet-50 with an alternative choice of adversarial loss for target instances. Please refer to the main text for how this alternative is defined. DC 90.4±0.1 98.7±0.1 100.0±0.0 92.5±0.3 72.5±0.2 73.0±0.3 87.9 DADA 92.3±0.1 99.2±0.1 100.0±0.0 93.9±0.2 74.4±0.1 74.2±0.1 89.0</figDesc><table><row><cell>Methods</cell><cell>A → W</cell><cell>D → W</cell><cell>W → D</cell><cell>A → D</cell><cell>D → A</cell><cell>W → A</cell><cell>Avg</cell></row><row><cell>DADA-</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 7 :</head><label>7</label><figDesc>Analysis of robustness for different methods on benchmark datasets of MNIST (Lecun et al. 1998), SVHN (Netzer et al. 2011), and USPS (Hull 1994) based on modified LeNet.</figDesc><table><row><cell>Methods</cell><cell cols="4">SVHN → MNIST MNIST → USPS USPS → MNIST Avg</cell></row><row><cell>No Adaptation</cell><cell>67.1</cell><cell>77.0</cell><cell>68.1</cell><cell>70.7</cell></row><row><cell>DDC (Tzeng et al. 2014)</cell><cell>68.1±0.3</cell><cell>79.1±0.5</cell><cell>66.5±3.3</cell><cell>71.2</cell></row><row><cell>DANN (Ganin et al. 2016)</cell><cell>73.9</cell><cell>77.1±1.8</cell><cell>73.0±0.2</cell><cell>74.7</cell></row><row><cell>DRCN (Ghifary et al. 2016)</cell><cell>82.0±0.1</cell><cell>91.8±0.09</cell><cell>73.7±0.04</cell><cell>82.5</cell></row><row><cell>ADDA (Tzeng et al. 2017)</cell><cell>76.0±1.8</cell><cell>89.4±0.2</cell><cell>90.1±0.8</cell><cell>85.2</cell></row><row><cell>SBADA-GAN (Russo et al. 2018)</cell><cell>76.1</cell><cell>97.6</cell><cell>95.0</cell><cell>89.6</cell></row><row><cell>RAAN (Chen et al. 2018)</cell><cell>89.2</cell><cell>89.0</cell><cell>92.1</cell><cell>90.1</cell></row><row><cell>ADR (Saito et al. 2018a)</cell><cell>94.1±1.37</cell><cell>91.3±0.65</cell><cell>91.5±3.61</cell><cell>92.3</cell></row><row><cell>TPN (Pan et al. 2019)</cell><cell>93.0</cell><cell>92.1</cell><cell>94.1</cell><cell>93.1</cell></row><row><cell>CyCADA (Hoffman et al. 2018)</cell><cell>90.4±0.4</cell><cell>95.6±0.2</cell><cell>96.5±0.1</cell><cell>94.2</cell></row><row><cell>MCD (Saito et al. 2018b)</cell><cell>96.2±0.4</cell><cell>94.2±0.7</cell><cell>94.1±0.3</cell><cell>94.8</cell></row><row><cell>CADA (Zou et al. 2019)</cell><cell>90.9±0.2</cell><cell>96.4±0.1</cell><cell>97.0±0.1</cell><cell>94.8</cell></row><row><cell>DAN (Long et al. 2018a)</cell><cell>71.1</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>CoGAN (Liu and Tuzel 2016)</cell><cell>-</cell><cell>91.2±0.8</cell><cell>89.1±0.8</cell><cell>-</cell></row><row><cell>DSN (Bousmalis et al. 2016)</cell><cell>82.7</cell><cell>91.3</cell><cell>-</cell><cell>-</cell></row><row><cell>LDC (Li, Song, and Wu 2018)</cell><cell>89.5±2.1</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>MSTN (Xie et al. 2018)</cell><cell>91.7±1.5</cell><cell>92.9±1.1</cell><cell>-</cell><cell>-</cell></row><row><cell>PFAN (Chen et al. 2019b)</cell><cell>93.9±0.8</cell><cell>95.0±1.3</cell><cell>-</cell><cell>-</cell></row><row><cell>JDDA-C (Chen et al. 2019a)</cell><cell>94.2±0.1</cell><cell>-</cell><cell>96.7±0.1</cell><cell>-</cell></row><row><cell>MECA (Morerio, Cavazza, and Murino 2018)</cell><cell>95.2</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>ASSC (Haeusser et al. 2017)</cell><cell>95.7±1.5</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>DADA</cell><cell>95.6 ± 0.5</cell><cell>96.1±0.4</cell><cell>96.5±0.2</cell><cell>96.1</cell></row><row><cell cols="2">Figure 5: Convergence performance in terms of test error on</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">the adaptation setting A → W. Note that here we only show</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">the convergence performance during adversarial training.</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 8 :</head><label>8</label><figDesc>Results for partial domain adaptation on Office-31 based on ResNet-50.Methods A → W D → W W → D A → D D → A W → A</figDesc><table><row><cell>Avg</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 9 :</head><label>9</label><figDesc>Results for partial domain adaptation on Office-31 based on AlexNet.</figDesc><table><row><cell>Methods</cell><cell cols="6">A → W D → W W → D A → D D → A W → A</cell><cell>Avg</cell></row><row><cell>No Adaptation (Krizhevsky, Sutskever, and Hinton 2012)</cell><cell>58.51</cell><cell>95.05</cell><cell>98.08</cell><cell>71.23</cell><cell>70.60</cell><cell>67.74</cell><cell>76.87</cell></row><row><cell>DAN (Long et al. 2018a)</cell><cell>56.52</cell><cell>71.86</cell><cell>86.78</cell><cell>51.86</cell><cell>50.42</cell><cell>52.29</cell><cell>61.62</cell></row><row><cell>DANN (Ganin et al. 2016)</cell><cell>49.49</cell><cell>93.55</cell><cell>90.44</cell><cell>49.68</cell><cell>46.72</cell><cell>48.81</cell><cell>63.11</cell></row><row><cell>ADDA (Tzeng et al. 2017)</cell><cell>70.68</cell><cell>96.44</cell><cell>98.65</cell><cell>72.90</cell><cell>74.26</cell><cell>75.56</cell><cell>81.42</cell></row><row><cell>RTN (Long et al. 2016)</cell><cell>66.78</cell><cell>86.77</cell><cell>99.36</cell><cell>70.06</cell><cell>73.52</cell><cell>76.41</cell><cell>78.82</cell></row><row><cell>SAN (Cao et al. 2018a)</cell><cell>80.02</cell><cell>98.64</cell><cell>100.00</cell><cell>81.28</cell><cell>80.58</cell><cell>83.09</cell><cell>87.27</cell></row><row><cell>Zhang et al. (Zhang et al. 2018a)</cell><cell>76.27</cell><cell>98.98</cell><cell>100.00</cell><cell>78.98</cell><cell>89.46</cell><cell>81.73</cell><cell>87.57</cell></row><row><cell>DADA-P</cell><cell>76.61</cell><cell>98.98</cell><cell>100.00</cell><cell>85.56</cell><cell>93.81</cell><cell>93.28</cell><cell>91.37</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 10 :</head><label>10</label><figDesc>Results for partial domain adaptation on Office-Home based on ResNet-50.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 11 :</head><label>11</label><figDesc>Results for partial domain adaptation on ImageNet-Caltech based on ResNet-50.</figDesc><table><row><cell>Methods</cell><cell>I→C C→I</cell><cell>Avg</cell></row><row><cell cols="3">No Adaptation (He et al. 2016) 71.65 66.14 68.90</cell></row><row><cell>DAN (Long et al. 2018a)</cell><cell cols="2">71.57 66.48 69.03</cell></row><row><cell>DANN (Ganin et al. 2016)</cell><cell cols="2">68.67 52.97 60.82</cell></row><row><cell>RTN (Long et al. 2016)</cell><cell cols="2">72.24 68.33 70.29</cell></row><row><cell>PADA (Cao et al. 2018b)</cell><cell cols="2">75.03 70.48 72.76</cell></row><row><cell>DADA-P</cell><cell cols="2">80.94 76.91 78.93</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table 12</head><label>12</label><figDesc></figDesc><table><row><cell>our proposed method with existing ones</cell></row><row><cell>on Office-31 based on AlexNet (Krizhevsky, Sutskever, and Hinton</cell></row><row><cell>2012) pre-trained on ImageNet (Russakovsky et al. 2015). Results</cell></row><row><cell>of existing methods are quoted from AODA (Saito et al. 2018c).</cell></row><row><cell>Our proposed DADA-O outperforms all comparative methods in</cell></row><row><cell>both evaluation metrics of OS* and OS, showing the efficacy of</cell></row><row><cell>DADA-O in both aligning distributions of the known instances</cell></row><row><cell>across domains and identifying the unknown target instances as the</cell></row><row><cell>unknown category for open set domain adaptation.</cell></row><row><cell>From the experimental results, we have some interesting ob-</cell></row><row><cell>servations.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table 12 :</head><label>12</label><figDesc>Results for open set domain adaptation on Office-31 based on AlexNet. Note that all methods do not use unknown source instances. OS* indicates the mean classification result over known categories whereas OS also includes the unknown category. OS OS* OS OS* OS OS* OS OS* OS OS* OS OS* No Adaptation (Krizhevsky, Sutskever, and Hinton 2012) 57.1 55.0 44.1 39.3 62.5 59.2 59.6 59.1 14.3 5.9 13.0 4.5 40.6 37.1 DAN (Long et al. 2018a) 41.5 36.2 34.4 28.4 62.0 58.5 47.8 44.3 9.9 0.9 11.5 2.7 34.5 28.5 DANN (Ganin et al. Saito et al. 2018c) 70.1 69.1 94.4 94.6 96.8 96.9 76.6 76.4 62.5 62.3 82.3 82.2 80.4 80.2 DADA-O 75.5 75.6 91.2 93.0 93.3 94.4 82.7 83.9 73.5 74.8 71.1 71.6 81.2 82.2</figDesc><table><row><cell>Methods</cell><cell cols="2">A → W</cell><cell cols="2">D → W</cell><cell cols="2">W → D</cell><cell cols="2">A → D</cell><cell cols="2">D → A</cell><cell cols="2">W → A</cell><cell>Avg</cell><cell></cell></row><row><cell cols="15">OS OS* 2016) 31.0 24.3 33.6 27.3 49.7 44.8 40.8 35.6 10.4 1.5 11.5 2.7 29.5 22.7</cell></row><row><cell>ATI-λ (Busto, Iqbal, and Gall 2018)</cell><cell>65.3</cell><cell>-</cell><cell>82.2</cell><cell>-</cell><cell>92.7</cell><cell>-</cell><cell>72.0</cell><cell>-</cell><cell>66.4</cell><cell>-</cell><cell>71.6</cell><cell>-</cell><cell>75.0</cell><cell>-</cell></row><row><cell>AODA (</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work is supported in part by the National Natural Science Foundation of China (Grant No.: 61771201), the Program for Guangdong Introducing Innovative and Enterpreneurial Teams (Grant No.: 2017ZT07X183), and the Guangdong R&amp;D key project of China (Grant No.: 2019B010155001).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Analysis of representations for domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ben-David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>Schölkopf, B.</editor>
		<editor>Platt, J. C.</editor>
		<editor>and Hoffman, T.</editor>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="137" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A theory of learning from different domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ben-David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kulesza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Vaughan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="151" to="175" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Domain separation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bousmalis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Trigeorgis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Silberman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Open set domain adaptation for image and action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">P</forename><surname>Busto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Iqbal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="page" from="1" to="1" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Partial transfer learning with selective adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Partial adversarial domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Reweighted adversarial adaptation network for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Wassell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chetty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Joint domain alignment and discriminative feature learning for unsupervised deep domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for the Advancement of Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Progressive feature alignment for unsupervised domain adaptation. Computer Vision and Pattern Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Rong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Joint distribution optimal transportation for domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Courty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Flamary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Habrard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rakotomamonjy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><forename type="middle">V</forename><surname>Luxburg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vishwanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Garnett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="3730" to="3739" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Approximation by superpositions of a sigmoidal function</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cybenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematics of Control, Signals and Systems</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="303" to="314" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Good semi-supervised learning that requires a bad gan</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><forename type="middle">V</forename><surname>Luxburg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vishwanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Garnett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="6510" to="6520" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Domainadversarial training of neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ustinova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ajakan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Germain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Laviolette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Marchand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2096" to="2030" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Deep reconstruction-classification networks for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ghifary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">B</forename><surname>Kleijn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Balduzzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Deep Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<ptr target="http://www.deeplearningbook.org" />
		<imprint>
			<date type="published" when="2016" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 27</title>
		<editor>Ghahramani, Z.</editor>
		<editor>Welling, M.</editor>
		<editor>Cortes, C.</editor>
		<editor>Lawrence, N. D.</editor>
		<editor>and Weinberger, K. Q.</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Semi-supervised learning by entropy minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Grandvalet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 17</title>
		<editor>Saul, L. K.</editor>
		<editor>Weiss, Y.</editor>
		<editor>and Bottou, L.</editor>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="529" to="536" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Caltech-256 object category dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Griffin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Holub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note type="report_type">CalTech Report</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Associative domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haeusser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Frerix</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mordvintsev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cremers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Methods Ar→Cl Ar→Pr Ar→Rw Cl→Ar Cl→Pr Cl→Rw Pr→Ar Pr→Cl Pr→Rw Rw→Ar Rw→Cl Rw→Pr Avg No Adaptation</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
