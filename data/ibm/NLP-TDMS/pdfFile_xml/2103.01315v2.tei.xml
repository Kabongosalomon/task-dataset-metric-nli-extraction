<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Exploring Complementary Strengths of Invariant and Equivariant Representations for Few-Shot Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mamshad</forename><forename type="middle">Nayeem</forename><surname>Rizve</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salman</forename><surname>Khan</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Mohamed bin Zayed</orgName>
								<orgName type="institution">University of AI</orgName>
								<address>
									<country key="AE">UAE</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">‡</forename><surname>Fahad</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shahbaz</forename><surname>Khan</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Mohamed bin Zayed</orgName>
								<orgName type="institution">University of AI</orgName>
								<address>
									<country key="AE">UAE</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Mubarak Shah † † Center for Research in Computer Vision</orgName>
								<orgName type="institution" key="instit2">UCF</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Exploring Complementary Strengths of Invariant and Equivariant Representations for Few-Shot Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T19:20+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In many real-world problems, collecting a large number of labeled samples is infeasible. Few-shot learning (FSL) is the dominant approach to address this issue, where the objective is to quickly adapt to novel categories in presence of a limited number of samples. FSL tasks have been predominantly solved by leveraging the ideas from gradient-based meta-learning and metric learning approaches. However, recent works have demonstrated the significance of powerful feature representations with a simple embedding network that can outperform existing sophisticated FSL algorithms. In this work, we build on this insight and propose a novel training mechanism that simultaneously enforces equivariance and invariance to a general set of geometric transformations. Equivariance or invariance has been employed standalone in the previous works; however, to the best of our knowledge, they have not been used jointly. Simultaneous optimization for both of these contrasting objectives allows the model to jointly learn features that are not only independent of the input transformation but also the features that encode the structure of geometric transformations. These complementary sets of features help generalize well to novel classes with only a few data samples. We achieve additional improvements by incorporating a novel self-supervised distillation objective. Our extensive experimentation shows that even without knowledge distillation our proposed method can outperform current state-ofthe-art FSL methods on five popular benchmark datasets. Our codes are available at: https://github.com/ nayeemrizve/invariance-equivariance.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In recent years, deep learning methods have made great strides on several challenging problems <ref type="bibr" target="#b29">[29,</ref><ref type="bibr" target="#b73">72,</ref><ref type="bibr" target="#b28">28,</ref><ref type="bibr" target="#b6">6,</ref><ref type="bibr" target="#b7">7]</ref>. This success can be partially attributed to the availability of large-scale labeled datasets <ref type="bibr" target="#b14">[14,</ref><ref type="bibr" target="#b6">6,</ref><ref type="bibr" target="#b84">83,</ref><ref type="bibr" target="#b44">44]</ref>. However, acquiring large amounts of labeled data is infeasible in several real-world problems due to practical constraints such as the rarity of an event or the high cost of manual anno- tation. Few-shot learning (FSL) targets this problem by learning a model on a set of base classes and studies its adaptability to novel classes with only a few samples (typically 1-5) <ref type="bibr" target="#b19">[19,</ref><ref type="bibr" target="#b78">77,</ref><ref type="bibr" target="#b67">66,</ref><ref type="bibr" target="#b72">71]</ref>. Remarkably, this setting is different from transfer and self/semi-supervised learning that assumes the availability of pretrained models <ref type="bibr" target="#b65">[64,</ref><ref type="bibr" target="#b82">81,</ref><ref type="bibr" target="#b36">36]</ref> or large-amounts of unlabeled data <ref type="bibr" target="#b17">[17,</ref><ref type="bibr" target="#b9">9,</ref><ref type="bibr" target="#b3">3]</ref>. FSL has been predominantly solved using ideas from meta-learning. The two most dominant approaches are optimization-based meta-learning <ref type="bibr" target="#b19">[19,</ref><ref type="bibr" target="#b32">32,</ref><ref type="bibr" target="#b63">62]</ref> and metriclearning based methods <ref type="bibr" target="#b67">[66,</ref><ref type="bibr" target="#b72">71,</ref><ref type="bibr" target="#b1">1]</ref>. Both sets of approaches attempt to train a base learner which can be quickly adapted in the presence of a few novel class examples. However, recently it has been shown in <ref type="bibr" target="#b57">[56]</ref> that the quick adaptation of the base learner crucially depends on feature reuse. Other recent works <ref type="bibr" target="#b74">[73,</ref><ref type="bibr" target="#b15">15,</ref><ref type="bibr" target="#b10">10]</ref> have also shown that a baseline feature extractor trained on all the meta-train set can achieve comparable performance to the state-of-the-art meta learning based methods. This brings in an interesting question: How much further can FSL performance be pushed by simply improving the base feature extractor?</p><p>To answer this question, first, we take a look at the inductive biases in machine learning (ML) algorithms. The optimization of all ML algorithms takes advantage of different inductive biases for hypothesis selection; as the solutions are never unique. The generalization of these algorithms often relies on the effective design of inductive biases, since they encode our priori preference for a particular set of solutions. For instance, regularization methods like 1 / 2 -penalties <ref type="bibr" target="#b75">[74]</ref>, dropout <ref type="bibr" target="#b68">[67]</ref>, or early stopping <ref type="bibr" target="#b54">[53]</ref> implicitly impose Occam's razor in the optimization process by selecting simpler solutions. Likewise, convolutional neural networks (CNN) by design impose translation invariance <ref type="bibr" target="#b2">[2]</ref> which makes the internal embeddings translation equivariant. Inspired by this, several methods <ref type="bibr" target="#b12">[12,</ref><ref type="bibr" target="#b20">20,</ref><ref type="bibr" target="#b16">16]</ref> have attempted to generalize CNNs by imposing equivariance to different geometric transformations so that the internal structure of data can be modeled more efficiently. On the other hand, methods like <ref type="bibr" target="#b38">[38]</ref> try to be robust against nuisance variations by learning transformation invariant features. However, such inductive biases do not provide optimal generalization on FSL tasks and the design of efficient inductive designs for FSL is relatively unexplored.</p><p>In this paper, we propose a novel feature learning approach by designing an effective set of inductive biases. We observe that the features required to achieve invariance against input transformations can provide better discrimination, but do not ensure optimal generalization. Similarly, features that focus on transformation discrimination are not optimal for class discrimination but learn equivariant properties that help in learning the data structure leading to better transferability. Therefore, we propose to combine the complementary strengths of both feature types through a multi-task objective that simultaneously seeks to retain both invariant and equivariant features. We argue that learning such generic features encourages the base feature extractor to be more general. We validate this claim by performing extensive experimentation on multiple benchmark datasets. We also conduct thorough ablation studies to demonstrate that enforcing both equivariance and invariance outperforms enforcing either of these objectives alone (see <ref type="figure" target="#fig_0">Fig. 1</ref>).</p><p>Our main contributions are:</p><p>• We enforce complimentary equivariance and invariance to a general set of geometric transformations to model the underlying structure of the data, while remaining discriminative, thereby improving generalization for FSL.</p><p>• Instead of extensive architectural changes, we propose a simple alternative by defining self-supervised tasks as auxiliary supervision. For equivariance, we introduce a transformation discrimination task, while an instance discrimination task is developed to learn transformation invariant features.</p><p>• We demonstrate additional gains with cross-task knowledge distillation that retains the variance properties.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Works</head><p>Few-shot Learning: The FSL approaches generally belong to the meta-learning family, which either learn a generalizable metric space <ref type="bibr" target="#b67">[66,</ref><ref type="bibr" target="#b35">35,</ref><ref type="bibr" target="#b79">78,</ref><ref type="bibr" target="#b52">51]</ref> or apply gradientbased updates to obtain a good initialization. In the first class of methods, Siamese networks related a pair of images <ref type="bibr" target="#b35">[35]</ref>, matching networks applied an LSTM based context encoder to match query and support set images <ref type="bibr" target="#b79">[78]</ref>, and prototypical networks used the distance between the query and the prototype embedding for class assignment <ref type="bibr" target="#b67">[66]</ref>. A task-dependent metric scaling approach to improve FSL was introduced in <ref type="bibr" target="#b52">[51]</ref>. The second category use gradientbased meta-learning methods that include using a sequence model (e.g., LSTM) to learn generalizable optimization rules <ref type="bibr" target="#b59">[58]</ref>, Model-agnostic Meta-Learning (MAML) to find a good initialization that can be quickly adapted to new tasks with minimal supervision <ref type="bibr" target="#b19">[19]</ref>, and Latent Embedding Optimization (LEO) that applied MAML in the low dimensional space from which high-dimensional parameters can be generated. A few recent efforts, e.g., ProtoMAML <ref type="bibr" target="#b77">[76]</ref>, combined the complementary strengths of metric-learning and gradient-based meta-learning methods.</p><p>Inductive Biases in CNNs: Inductive biases reflect our prior knowledge regarding a particular problem. State of the art CNNs are based on such design choices which range from the convolutional operator (e.g., the weight sharing and translational equivariance) <ref type="bibr" target="#b40">[40]</ref>, pooling operator (e.g., local neighbourhood relevance) <ref type="bibr" target="#b11">[11]</ref>, regularization mechanisms (e.g., sparsity with 1 regularizer) <ref type="bibr" target="#b33">[33]</ref>, and loss functions (e.g., max-margin boundaries) <ref type="bibr" target="#b27">[27]</ref>. Similarly, recurrent architectures and attention mechanisms are biased towards preserving contextual information and being invariant to time translation <ref type="bibr" target="#b2">[2]</ref>. A number of approaches have been designed to achieve invariance to nuisances such as natural perturbations <ref type="bibr" target="#b30">[30,</ref><ref type="bibr" target="#b76">75]</ref>, viewpoint changes <ref type="bibr" target="#b46">[46]</ref>, and image transformations <ref type="bibr" target="#b13">[13,</ref><ref type="bibr" target="#b5">5]</ref>. On the other hand, equivariant representations have also been investigated to retain knowledge regarding group actions <ref type="bibr" target="#b12">[12,</ref><ref type="bibr" target="#b55">54,</ref><ref type="bibr" target="#b64">63,</ref><ref type="bibr" target="#b42">42]</ref>, thereby maintaining meaningful structure in the representations. In this work, we advocate that the representations required to simultaneously achieve invariance and equivariance can be useful for generalization to new tasks with limited data.</p><p>Self-supervised Learning for FSL: Our self-supervised loss is inspired by the recent progress in self-supervised learning (SSL), where proxy tasks are defined to learn transferable representations without adding any manual annotations <ref type="bibr" target="#b58">[57]</ref>. The pretext tasks include colorization <ref type="bibr" target="#b39">[39,</ref><ref type="bibr" target="#b83">82]</ref>, inpainting <ref type="bibr" target="#b53">[52]</ref>, relative patch location <ref type="bibr" target="#b17">[17,</ref><ref type="bibr" target="#b50">50]</ref>, and amount of rotation applied <ref type="bibr" target="#b24">[24]</ref>. Recently, the potential of SSL for FSL was explored in <ref type="bibr" target="#b23">[23,</ref><ref type="bibr" target="#b69">68]</ref>. In <ref type="bibr" target="#b23">[23]</ref> a parallel branch with the rotation prediction task to help learn generalizable features was added. Su et al. <ref type="bibr" target="#b69">[68]</ref> also used rotation and permutation of patches as auxiliary tasks and concluded that SSL is more effective in low-shot regimes and under significant domain shifts. A recent approach employed SimCLR <ref type="bibr" target="#b9">[9]</ref> style contrastive learning with augmented pairs to learn improved representations in either unsupervised pretraining <ref type="bibr" target="#b45">[45]</ref> or episodic training <ref type="bibr" target="#b18">[18]</ref> for FSL.</p><p>In contrast to the existing SSL approaches for FSL, we propose to jointly optimize for a complimentary pair of pretext tasks that lead to better generalization. Our novel distillation objective acquires knowledge from the classification as well as proxy task heads and demonstrates further performance improvements. We present our approach next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Our Approach</head><p>We first describe the problem setting and the baseline training approach and then present our proposed approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Problem Formulation</head><p>Few-shot learning (FSL) operates in two phases, first a model on a set of base classes is trained and then at inference a new set of few-shot classes are received. We define the base training set as D b = {(x, y)}, where x ∈ I ⊂ R h×w×3 is an image, and the one-hot encoded label y ∈ Y ⊂ R N b can belong to a total of N b base classes. At inference, a data set of few-shot classes D f = {(x, y)} is presented for learning such that the label y belongs to one of the N f novel classes, each with a total of K examples (K typically ranges between 1-5). The evaluation setting for few-shot classes is denoted as N f -way, K-shot. Importantly, the N b base and N f few-shot classes belong to totally disjoint sets. For solving the FSL task, most meta-learning methods <ref type="bibr" target="#b19">[19,</ref><ref type="bibr" target="#b67">66,</ref><ref type="bibr" target="#b78">77]</ref> have leveraged an episodic training scheme. An episode consists of a small train and test set D i tr , D i ts . The examples for the train and test set of an episode are sampled from the same distribution i.e. from the same subset of meta-training classes. Meta-learning methods try to optimize the parameters of the base learner by solving a collection of these episodes. The main motivation is that the evaluation conditions should be emulated in the base training stage. However, following recent works <ref type="bibr" target="#b74">[73,</ref><ref type="bibr" target="#b15">15,</ref><ref type="bibr" target="#b10">10]</ref>, we do not use an episodic training scheme which allows us to train a single generalizable model that can be efficiently used for any-way, any-shot setting without retraining. Specifically, we train our base learner on the whole base training set D b in a supervised manner.</p><p>Let's assume our base learner for the FSL task is a neural network, f Θ , parameterized with parameters Θ. The role of this base learner is to extract good feature embeddings that can generalize for novel classes. The base learner f Θ can project an input image x into the embedding space f Θ :</p><p>x → z, such that z ∈ R d . Now, to optimize the parameters of the base learner f Θ we need a classifier to project the extracted embeddings into the label space. To this end, we introduce a classifier function, f Φ , with parameters Φ that projects the embeddings z into the label space Y i.e., f Φ : z →ỹ, such thatỹ ∈ Y.</p><p>We jointly optimize the parameters of both f Θ and f Φ by minimizing cross-entropy loss on the whole base-training set D b . The classification loss is given by,</p><formula xml:id="formula_0">L ce = − log exp(ỹ j:yj =1 ) i exp(ỹ i ) , s.t., y ∈ {0, 1} N b ,ỹ = f Θ,Φ (x).</formula><p>To regularize the parameters of both of the sub-networks, we add a regularization term. Hence, the learning objective for our baseline training algorithm becomes:</p><formula xml:id="formula_1">L baseline = E (x,y)∼D b Lce (fΘ,Φ(x), y) + R(Θ, Φ). (1)</formula><p>Here, R(Θ, Φ) is an L 2 regularization term for the parameters Θ and Φ. Next, we present our inductive objectives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Injecting Inductive Biases through SSL</head><p>We propose to enforce equivariance and invariance to a general set of geometric transformations T by simply performing self-supervised learning (SSL). Self-supervision is particularly useful for learning general features without accessing semantic labels. For representation learning, self-supervised methods generally aim for either achieving equivariance to some input transformations or learn to discriminate instances by making the representations invariant. To the best of our knowledge, simultaneous equivariance and invariance to a general set of geometric transformations T has not been explored in the self-supervised literature. We are the first ones to do so.</p><p>The transformation set T can be obtained from a family of geometric transformations, D T ; T ∼ D T . Here, D T can be interpreted as a family of geometric transformations like Euclidean transformation, Similarity transformation, Affine transformation, and Projective transformation. All of these geometric transformations can be represented with a R 3×3 matrix with varying degrees of freedom. However, enforcing equivariance and invariance for a continuous space of geometric transformations, T , is difficult and may even lead to suboptimal solutions. To overcome this issue, in this work, we quantize the complete space of affine transformations. We approximate D T by dividing it into M discrete  For training, we generate M transformed copies of an input image x by applying all M transformations. Then we combine all of these transformed images together into a single tensor,</p><formula xml:id="formula_2">x all = {x 0 , x 1 , ..., x M −1 }.</formula><p>Here, x i is the input image x transformed through i th transformation, T i (the subscript of x i is dropped in the subsequent discussion for clarity). We send this composite input to the network and optimize for both equivariance and invariance. The training is performed in a multi-task fashion. In addition to the classification head, which is needed for the baseline supervised training, two other heads are added on top of the base learner, as shown in <ref type="figure" target="#fig_2">Figure 2</ref>. One of these heads is used for enforcing equivariance, and the other is used for enforcing invariance. This multi-task training scheme ensures that the base learner retains both transformation equivariant and invariant features in the output embedding. We explain each component of our inductive loss below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Enforcing Equivariance</head><p>As discussed above, equivariant features help us encode the inherent structure of data that improves generalization of features to new tasks. To enforce equivariance for the set T comprising of M quantized transformations, we introduce an MLP f Ψ with parameters Ψ. The role of f Ψ is to project the output embeddings from the base learner z into an equivariant space i.e., f Ψ : z →ũ, whereũ ∈ U ⊂ R M .</p><p>In order to train the network, we create proxy labels without any manual supervision. For a specific transformation, a M dimensional one-hot encoded vector u ∈ {0, 1} M (such that i u i = 1) is used to represent the label for f Ψ . Once proxy labels are assigned, training is performed in a supervised manner with the cross-entropy loss, as follows:</p><formula xml:id="formula_3">Leq = − log exp(ũj:u j =1) i exp(ũi) , s.t.,ũ = fΘ,Ψ(x).<label>(2)</label></formula><p>This supervised training with proxy labels in the equivariant space U ensures that the output embedding z retains transformation equivariant features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Enforcing Invariance</head><p>While equivariant representations are important to encode the structure in data, they may not be optimal for class discrimination. This is because the transformations we consider are nuisance variations that do not change the image class, therefore a good feature extractor should also encode representations that are independent of these input variations. To enforce invariance to the set T consisting of M quantized transformations, we introduce another MLP f Ω with parameters Ω. The role of f Ω is to project the output embeddings from the base learner z into an invariant space</p><formula xml:id="formula_4">i.e., f Ω : z → v where v ∈ V ⊂ R D and D is the dimen- sion of the invariant embedding.</formula><p>To optimize for invariance we leverage a contrastive loss <ref type="bibr" target="#b26">[26]</ref> for instance discrimination. We enforce invariance by maximizing the similarity between an embedding v m corresponding to a transformed image (after undergoing m th transformation T m ), and the reference embedding v 0 (embedding from the original image without applying any transformation T ). Importantly, we note that selecting negatives within a batch is not sufficient to obtain discriminant representations <ref type="bibr" target="#b80">[79,</ref><ref type="bibr" target="#b48">48]</ref>. We employ a memory bank in our contrastive loss to sample more negative samples without arbitrarily increasing the batch size. Further, the memory bank allows a stable convergence behavior <ref type="bibr" target="#b48">[48]</ref>. Our learning objective is as follows:</p><formula xml:id="formula_5">Lin = − 1 M M −1 m=0 log (h(v r , v m )) m = 0 → v r = v 0 m = 0 → v r =ṽ 0 (3)</formula><p>where, m denotes the transformation index,ṽ 0 represents a previous copy of the reference v 0 held in the memory and the function h(·) is defined as,</p><formula xml:id="formula_6">h(v r , v m ) = exp s(v r ,v m ) τ exp s(v r ,v m ) τ + v ∈Dn exp s(v ,v m ) τ .</formula><p>Here, s(.) is a similarity function, τ is the temperature, and D n is the set of negative samples drawn from the memory bank for a particular minibatch. Note that we also maximize the similarity between the reference embedding v 0 and its past representationṽ 0 which helps stabilize the learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Multi-head Distillation</head><p>Once the invariant and equivariant representations are learned by our model, we use self-distillation to train a new model using outputs from the previous model as anchor points <ref type="figure" target="#fig_2">(Fig. 2</ref>). Note that in typical knowledge distillation <ref type="bibr" target="#b31">[31]</ref>, information is exchanged from a larger model (teacher) to a smaller one (student) by matching their softened outputs. In contrast, the outputs from the same models are matched in the self-distillation <ref type="bibr" target="#b21">[21]</ref> where the smooth predictions encode inter-label dependencies, thereby helping the model to learn better representations. In our case, a simple knowledge distillation by pairing the logits <ref type="bibr" target="#b74">[73]</ref> would not ensure the transfer of invariant and equivariant representations learned by the previous model version. Therefore, we extend the idea of logit-based knowledge distillation and employ it to our invariant and equivariant embedding embeddings. Specifically, in parallel to minimizing the Kullback Leibler (KL) divergence for the soft output of supervised classifier head f Φ , we also minimize the KL divergence between the outputs of the equivariant head f Ψ . Since the output of our invariant head f Ω is not a probability distribution, we minimize a L 2 loss for distilling the knowledge at this head. The overall learning objective for knowledge distillation is as follows:</p><formula xml:id="formula_7">L kd =KL(f t Θ,Φ (x), f Θ,Φ (x)) + KL(f t Θ,Ψ (x), f Θ,Ψ (x)) + L 2 (f t Θ,Ω (x), f Θ,Ω (x)).<label>(4)</label></formula><p>Here, f t (.,.) and f (.,.) are the teacher and student networks for distillation, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.4">Overall Objective</head><p>Finally, we obtain the resultant loss for injecting the desired inductive biases by combining both equivariant L eq , invari-ant L in , and multi-head distillation L kd losses:</p><formula xml:id="formula_8">L inductive = E x∼D b ,v ∼Dn L eq (f Θ,Ψ (x), u)+ L in (f Θ,Ω (x), v ) + L kd (f .,t Θ,Φ (x), f .,t Θ,Ψ (x), f .,t Θ,Ω (x)) .</formula><p>The overall loss is simply a combination of inductive and baseline objectives,</p><formula xml:id="formula_9">L = L baseline + L inductive .<label>(5)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Few-Shot Evaluation</head><p>For evaluation, we test our base learner f Θ by sampling FSL tasks from a held-out test set comprising of images from novel classes. Each FSL task contains a support set and a corresponding query set {D supp , D query }; both contain images from the same subset of test classes. Using f Θ , we obtain embeddings for the images of both D supp and D query . Following <ref type="bibr" target="#b74">[73]</ref>, we train a simple logistic regression classifier based on the image embeddings and the corresponding labels from the D supp . We use that linear classifier to infer the labels of the query embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental Evaluation</head><p>Datasets: We evaluate our method on five popular benchmark FSL datasets. Two of these datasets are subset of the CIFAR100 dataset: CIFAR-FS <ref type="bibr" target="#b4">[4]</ref> and FC100 <ref type="bibr" target="#b52">[51]</ref>. Another two are derivatives of the ImageNet <ref type="bibr" target="#b14">[14]</ref> dataset: miniImageNet <ref type="bibr" target="#b78">[77]</ref> and tieredImageNet <ref type="bibr" target="#b62">[61]</ref>. The CIFAR-FS dataset is constructed by randomly splitting the 100 classes of the CIFAR-100 dataset into 64, 16, and 20 train, validation, and test splits. FC100 dataset makes the FSL task more challenging by making the splits more diverse; the FC100 train, validation, and test splits contain 60, 20, and 20 classes. Following <ref type="bibr" target="#b60">[59]</ref>, we use 64, 16, and 20 classes of the miniImageNet dataset for training, validation, and testing. The tieredImageNet dataset contains 608 Ima-geNet classes that are grouped into 34 high-level categories, and we use 20/351, 6/97, and 8/160 categories/classes for training, validation, and testing. We also evaluate our method on the newly proposed Meta-Dataset <ref type="bibr" target="#b77">[76]</ref>, which contains 10 diverse datasets to make the FSL task more challenging and closer to realistic classification problems. Implementation Details: Following <ref type="bibr" target="#b74">[73,</ref><ref type="bibr" target="#b47">47,</ref><ref type="bibr" target="#b52">51,</ref><ref type="bibr" target="#b41">41]</ref>, we use a ResNet-12 network as our base learner to conduct experiments on CIFAR-FS, FC100, miniImageNet, tieredIm-ageNet datasets. Following <ref type="bibr" target="#b74">[73,</ref><ref type="bibr" target="#b41">41]</ref>, we also apply Dropblock <ref type="bibr" target="#b22">[22]</ref> regularizer to our Resnet-12 base learner. For Meta-Dataset experiments we use a Resnet-18 <ref type="bibr" target="#b29">[29]</ref> network as our base learner to be consistent with <ref type="bibr" target="#b74">[73]</ref>. We instantiate both of our equivariant and invariant embedding learners (f Ψ , f Ω ) with an MLP consisting of a single hidden layer.</p><p>The classifier, f Φ , is instantiated with a single linear layer.  We use SGD optimizer with a momentum of 0.9 in all experiments. For CIFAR-FS, FC100, miniImageNet, tiered-ImageNet datasets we set the initial learning rate to 0.05 and use a weight decay of 5e − 4. For experiments on CIFAR-FS, FC100, miniImageNet datasets, we train for 65 epochs; the learning rate is decayed by a factor of 10 after the first 60 epochs. We train for 60 epochs for experiments on the tieredImageNet dataset; the learning rate is decayed by a factor of 10 for 3 times after the first 30 epochs. For Meta-Dataset experiments, we set the initial learning rate to 0.1 and use a weight decay of 1e−4. We train our method for 90 epochs and decay the learning rate by a factor of 10 every 30 epochs. We use a batch size of 64 in all of our experiments except on Meta-Dataset where the batch size is set to 256 following <ref type="bibr" target="#b74">[73]</ref>. For Meta-dataset experiments, we use standard data augmentation which includes random horizontal flip and random resized crop. For all the other dataset experiments we use random crop, color jittering and random hor- izontal flip for data augmentation following <ref type="bibr" target="#b74">[73,</ref><ref type="bibr" target="#b41">41]</ref>. Consistent with <ref type="bibr" target="#b74">[73]</ref>, we use a temperature coefficient of 4.0 for our knowledge distillation experiments. For all datasets, we perform one stage of distillation. We sample 600 FSL tasks to report our scores on all datasets except Meta-Dataset. For our geometric transformations, we sample from a complete space of similarity transformation and use four rotation transformations: {0 • , 90 • , 180 • , 270 • }, two scaling transformations: {0.67, 1.0} and three aspect ration transformations: {0.67, 1.0, 1.33}. These geometric transformations can be applied in any combination. For all of our experiments, we set the total number of applied transformations to <ref type="bibr" target="#b16">16</ref>. Additional details and experiments with more geometric transformations are included in the supplementary materials. For the contrastive loss, we use a memory bank that stores 64-dimensional embedding of instances; we sample 6400 negative samples from the memory bank for each mini-batch and set the value of τ to 1.0.</p><formula xml:id="formula_10">Methods Backbone 1-Shot 5-Shot</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Results</head><p>We present our results on five popular benchmark FSL datasets in <ref type="table" target="#tab_0">Table 1</ref>-5 which demonstrates that even without multi-head distillation our proposed method consistently outperforms the current state-of-the-art (SOTA) FSL methods on both 5-way 1-shot and 5-way 5-shot tasks. By virtue of our novel representation learning approach which re-  tains both the transformation invariant and equivariant features in the learned embeddings, our proposed method improves over the baseline RFS-Simple <ref type="bibr" target="#b74">[73]</ref> method across all datasets by 2-5% for both 1-shot and 5-shot tasks. To be more specific, our method outperforms the current best results on CIFAR-FS dataset ( <ref type="table" target="#tab_0">Table 1</ref>) by 1.3% in the 1shot task whereas for the 5-shot task it improves the score by 2.8%. However, unlike <ref type="bibr" target="#b15">[15]</ref>, which achieves the current best results on the CIFAR-FS 1-shot task, we do not perform any transductive fine-tuning. For FC100 dataset ( <ref type="table" target="#tab_1">Table  2)</ref> we observe an even bigger improvement; 2.7% and 4.4% for 1 and 5-shot, respectively. We see similar trends in mini-ImageNet and tieredImageNet ( <ref type="table" target="#tab_2">Table 3</ref>,4) where we consistently improve over the current SOTA methods by 0.7-2.2%. For the Meta-Dataset <ref type="bibr" target="#b77">[76]</ref>, we train our model on the ILSVRC train split and test on 10 diverse datasets. Our results in <ref type="table">Table 5</ref> demonstrate that our method outperforms the fo-Proto-MAML <ref type="bibr" target="#b77">[76]</ref> across all 10 datasets. Even without multi-head distillation, we outperform both simple and distilled version of the RFS method on 6 out of 10 datasets. Overall, we perform favorably well against the RFS, achieving a new SOTA result on the challenging Meta-Dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Ablations</head><p>To study the contribution of different components of our method we do a thorough ablation study on three benchmark FSL datasets: miniImageNet, CIFAR-FS, and FC100 ( <ref type="table">Table 6</ref>). On these three datasets, our baseline supervised training achieves 62.02%, 71.50%, and 42.60% average accuracy on 5-way 1-shot task respectively; which is the same as RFS-Simple <ref type="bibr" target="#b74">[73]</ref>. By enforcing invariance we obtain 2.62%, 2%, and 3.5% improvements respectively. Likewise, enforcing equivariance gives 4.07%, 4.87%, and 4.13% improvements over the baseline respectively. On the  <ref type="table">Table 5</ref>. Results on Meta-Dataset. Average accuracy (%) is reported with variable number of ways and shots, following the setup in <ref type="bibr" target="#b77">[76]</ref>. 1000 tasks are sampled for evaluation. Top two results are shown in red and blue.</p><p>other hand, we get even bigger improvements by simultaneously optimizing for both equivariance and invariance; achieving 4.8%, 5.33%, and 4.78% improvements on top of the baseline supervised training. Besides, joint training gives 1.3%-3.3% improvement over only invariance training and 0.5%-0.7% improvement in comparison to only equivariance training. We observe similar trends for 5-way 5-shot task. This consistent improvement across all datasets for both tasks empirically validates our claim that joint optimization for both equivariance and invariance is beneficial for FSL tasks. Our ablation study also shows that the multihead distillation improves the performance over the standard logit-level supervised distillation across all datasets.</p><p>Effect of the number of Transformations: To investigate the effect of the total number of applied transformations, we perform an ablation study on the CIFAR-FS validation set by varying the number of transformations, M . We present the results in <ref type="table">Table 7</ref>, which demonstrates that initially, the performance of our method improves with the increasing M . However, the performance starts to saturate beyond a particular point. We hypothesize that the performance for an increasing number of transformations decreases since discriminating a higher number of transformations is more difficult and the model spends more representation capability for solving this harder task. A similar trend is observed in <ref type="bibr" target="#b24">[24]</ref>, where increasing the number of recognizable rotations does not lead to better performance. Based on <ref type="table">Table  7</ref> results, we set the value of M to 16 for all of our experiments and do not tune the M value from dataset to dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Analysis</head><p>We do a t-SNE visualization of the output embeddings from f Θ for the test images of miniImageNet to demonstrate the effectiveness of our method (see <ref type="figure">Fig. 3</ref>). We observe that the base learner trained in a supervised manner can retain good class discrimination even for unseen test classes. However, as evident in <ref type="figure">Fig. 3, the</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Baseline Baseline+INV</head><p>Baseline+EQ Ours <ref type="figure">Figure 3</ref>. t-SNE visualization of features for 1000 randomly sampled images from 5 randomly selected test classes of miniIma-geNet dataset. In our case, the learned embeddings provide better discrimination for unseen test classes.</p><p>base learner leads to more compact class boundaries; however, the sample embeddings of different classes are still relatively closer to one another. On the other hand, enforcing equivariance leads to class representations that are well spread out since it retains the transformation equivariant information in the embedding space. Finally, our proposed method takes advantage of both of these complementary properties and generates embeddings that lead to more compact clusters and discriminative class boundaries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Alternate Self-Supervision Losses</head><p>In <ref type="table" target="#tab_8">Table 8</ref>, to further analyze the performance improvement of our method, we conduct a set of experiments where commonly used self-supervised objectives like solving jig-  saw puzzles <ref type="bibr" target="#b50">[50]</ref>, patch location prediction <ref type="bibr" target="#b71">[70]</ref>, context prediction <ref type="bibr" target="#b17">[17]</ref>, rotation classification <ref type="bibr" target="#b24">[24]</ref> are added on top of the base learner as an auxiliary task. We found that our proposed method which aims to learn representations that retain both transformation invariant and equivariant information outperforms all of these SSL tasks by a good margin. Besides, we have noticed that the patch-based SSL tasks <ref type="bibr" target="#b50">[50,</ref><ref type="bibr" target="#b71">70,</ref><ref type="bibr" target="#b17">17]</ref> generally underperform in comparison to SSL tasks that rely on changing the global statistics of the image while maintaining the local statistics; this conclusion is in line with the experimental results from <ref type="bibr" target="#b23">[23]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this work, we explored a set of inductive biases that help us learn highly discriminative and transferable representations for FSL. Specifically, we showed that simultaneously learning equivariant and invariant representations to a set of generic transformations results in retaining a complimentary set of features that work well for novel classes. We also designed a novel multi-head knowledge distillation objective which delivers additional gains. We conducted extensive ablation to empirically validate our claim that joint optimization for invariance and equivariance leads to more generic and transferable features. We obtained new stateof-the-art results on four popular benchmark FSL datasets as well as on the newly proposed challenging Meta-Dataset. cial policies or endorsements, either expressed or implied, of the ODNI, IARPA, or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright annotation thereon.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Supplementary Materials Overview</head><p>In the supplementary materials we include the following: additional details about the applied geometric transformations (Section B), additional results with the transformations sampled from the complete space of affine transformations (Section C), ablation study on the coefficient of inductive loss (Section D), ablation study on the temperature of knowledge distillation (Section E), effect of successive self knowledge distillation (Section F), and effect of enforcing invariance and equivariance for supervised classification (Section G).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Geometric Transformations</head><p>For our geometric transformations, we sample from a complete space of similarity transformation and use four rotation transformations: {0 • , 90 • , 180 • , 270 • }, two scaling transformations: {0.67, 1.0} and three aspect ratio transformations: {0.67, 1.0, 1.33}. Different combinations of these transformations lead to different values of M (total number of applied transformations). An ablation study on the value of M is included in section 4.2 of the main paper. In <ref type="table">Table  9</ref> we include the complete description of different values of M that we use in our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Additonal Resutls with Affine Transformations</head><p>We perform a set of experiments where the objective is to sample geometric transformation from the complete space of affine transformations. To this end, we quantize the affine transformation space according to <ref type="table" target="#tab_0">Table 10</ref>. This leads to 972 distinct geometric transformations. Since it's not feasible to apply all the 972 transformations on an input image x to obtain the input tensor x all = {x 0 , x 1 , ..., x 971 }, we randomly sample 10 geometric transformations from the set of 972 transformations. We apply these randomly sampled 10 geometric transformations on an input image x and generate the input tensor x all . The results of these experiments are presented in <ref type="table" target="#tab_0">Table 11</ref>. From <ref type="table" target="#tab_0">Table 11</ref> it's evident that training with either invariance or equivariance improves over the baseline training for both 1 and 5 shot tasks  both invariance and equivariance are enforced simultaneously. This provides additional support for our claim that enforcing both invariance and equivariance is beneficial for learning good general representations for solving challenging FSL tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Ablation Study for Coefficient of Inductive Loss</head><p>We conduct an ablation study to measure the effect of different values of the coefficient of inductive loss (without multi-head distillation) on the CIFAR-FS [4] validation set; the results of 5-way 1-shot FSL tasks are presented in <ref type="figure" target="#fig_4">fig.  4</ref>. From <ref type="figure" target="#fig_4">fig.4</ref> it is evident that the proposed method is fairly robust to the different values of the coefficient of the inductive loss. However, the best performance is obtained when we set the loss coefficient to 1.0. Based on this ablation study, we use a loss coefficient of 1.0 for the inductive loss in all of our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Ablation Study for Knowledge Distillation Temperature</head><p>To analyse the effect of knowledge distillation temperature (for Kullback Leibler (KL) divergence losses) we conduct an ablation study on the validation set of CIFAR-FS <ref type="bibr" target="#b4">[4]</ref> dataset. From <ref type="figure" target="#fig_6">fig. 5</ref> we can observe that the proposed method with multi-head distillation objective is not very sensitive to the temperature coefficient of knowledge distillation. The proposed method achieves similar performance on the CIFAR-FS validation set when the value of distillation temperature is set to 4.0 and 5.0. Based on this ablation study and to be consistent with <ref type="bibr" target="#b74">[73]</ref>, we set the value of the coefficient of knowledge distillation temperature to 4.0 in all of our experiments.     </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Effect of Successive Distillation</head><p>In all of our experiments, we use only one stage of multihead knowledge distillation. To further investigate the effect of knowledge distillation we perform multiple stages of self knowledge distillation on CIFAR-FS <ref type="bibr" target="#b4">[4]</ref> dataset. The results are presented in <ref type="figure" target="#fig_8">fig. 6</ref>. Here, the 0 th distillation stage is the base learner trained with only the supervised baseline loss (L baseline ), equivariant loss (L eq ), and invariant loss (L in ). From <ref type="figure" target="#fig_8">fig. 6</ref>, we observe that the performance in the FSL task improves for the first 2 stages of distillation, after that the performance saturates. Besides, the improvement from stage 1 to stage 2 is minimal (∼ 0.1%). Therefore, to make the proposed method more computationally efficient we perform only one stage of distillation in all of our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G. Invariance and Equivariance for Supervised Classification</head><p>To demonstrate the effectiveness of complementary strengths of invariant and equivariant representations we conduct fully supervised classification experiments on benchmark CIFAR-100 dataset <ref type="bibr" target="#b37">[37]</ref>. For these experiments, we use the standard Wide-Resnet-28-10 [80] architecture as the backbone. For training, we use an SGD optimizer with an initial learning rate of 0.1. We set the momentum to 0.9 and use a weight decay of 5e−4. For all the experiments, the training is performed for 200 epochs where the learning rate is decayed by a factor of 5 at epochs 60, 120, and 160. We use a batch size of 128 for all the experiments as well as a dropout rate of 0.3. The training augmentations include standard data augmentations: random crop and random horizontal flip. For enforcing invariance and equivariance, we set the value of M to 12 for computational efficiency; description of M = 12 is available in <ref type="table">Table 9</ref>. We do not perform knowledge distillation for these experiments. The results of these experiments are presented in <ref type="table" target="#tab_0">Table 12</ref>.</p><p>From <ref type="table" target="#tab_0">Table 12</ref>, we can notice that enforcing invariance provides little improvement (0.2%) over the supervised baseline. This is expected since the train and test data is coming from the same distribution and same set of classes; making the class boundaries compact (for seen classes) doesn't provide that much additional benefit. However, in the case of FSL we observe that enforcing invariance over baseline provides 2.62%, 2%, and 3.5% improvement for miniImageNet <ref type="bibr" target="#b78">[77]</ref>, CIFAR-FS <ref type="bibr" target="#b4">[4]</ref>, and FC100 <ref type="bibr" target="#b52">[51]</ref> datasets respectively (section 4.2 of main text). On the other hand, enforcing equivariance for supervised classification provides better improvement (1.8%) since it helps the model to better learn the structure of data. Even though enforcing equivariance provides noticeable improvement for supervised classification, in the case of FSL we obtain a much bigger improvement of 4.07%, 4.87%, and 4.13% for miniImageNet <ref type="bibr" target="#b78">[77]</ref>, CIFAR-FS <ref type="bibr" target="#b4">[4]</ref>, and FC100 <ref type="bibr" target="#b52">[51]</ref> datasets respectively (section 4.2 of main text). Finally, joint optimization for both invariance and equivariance achieves the best performance and provides minimal but consistent improvement of 0.1% over enforcing only equivariance. However, joint optimization provides a much larger improvement on FSL tasks (see section 4.2 of the main text). From these experiments, we conclude that, although enforcing both invariance and equivariance is beneficial for supervised classification, injecting these inductive biases is more crucial for FSL tasks since the inductive inference for FSL tasks is more challenging (inference on unseen/novel classes).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Approach Overview: Shapes represent different transformations and colors represent different classes. While the invariant features provide better discrimination, the equivariant features help us learn the internal structure of the data manifold. These complimentary representations help us generalize better to new tasks with only a few training samples. By jointly leveraging the strengths of equivariant and invariant features, our method achieves significant improvement over baseline (bottom row).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 .</head><label>2</label><figDesc>Network Architecture during Training: A series of transformed inputs (transformed by applying transformations T1...TM ) are provided to a shared feature extractor fΘ. The resulting embedding is forwarded to three parallel heads fΨ, fΦ and fΩ that focus on learning equivariant features, discriminative class boundaries, and invariant features, respectively. The resulting output representations are distilled from an old copy of the model (teacher model on the right) across multiple-heads to further improve the encoded representations. Notably, a dedicated memory bank of negative samples helps stabilize our invariant contrastive learning. set of transformations. Here, M can be selected based on the nature of the data and computation budget.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>(2.5-3.7% improvement). Joint optimization for both invariance and equivariance provides additional improvement of ∼ 1%. Even though the experiments with geometric transformations sampled from the complete affine transformation space do not improve over the training with M = 16 (description of M = 16 is available inTable 9), the experiments demonstrate consistent improvement when</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 .</head><label>4</label><figDesc>Ablation study on CIFAR-FS validation set with different coefficients of the inductive loss (W/O KD); the reported score is average 5-way 1-shot classification accuracy with 95% confidence intervals.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 .</head><label>5</label><figDesc>Ablation study on CIFAR-FS validation set with different values of knowledge distillation temperature; the reported score is average 5-way 1-shot classification accuracy with 95% confidence intervals.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 6 .</head><label>6</label><figDesc>Evaluation of different knowledge distillation stages on CIFAR-FS dataset; the reported score is average 5-way 1-shot classification accuracy with 95% confidence intervals.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>-32-32 58.90 ± 1.90 71.50 ± 1.00 Proto-Net † [66] 64-64-64-64 55.50 ± 0.70 72.00 ± 0.60 Relation Net[71] 64-96-128-256 55.00 ± 1.00 69.30 ± 0.80 R2D2[4] 96-192-384-512 65.30 ± 0.20 79.40 ± 0.10 MetaOptNet[41] ResNet-12 41.10 ± 0.60 55.50 ± 0.60 MTL[69] ResNet-12 45.10 ± 1.80 57.60 ± 0.90 Fine-tuning[15] WRN-28-10 43.16 ± 0.59 57.57 ± 0.55</figDesc><table><row><cell>Methods</cell><cell>Backbone</cell><cell>1-Shot</cell><cell>5-Shot</cell></row><row><cell cols="2">MAML[19] 32-32Shot-Free[60] ResNet-12</cell><cell>69.20</cell><cell>84.70</cell></row><row><cell>TEWAM[55]</cell><cell>ResNet-12</cell><cell>70.40</cell><cell>81.30</cell></row><row><cell>Proto-Net  † [66]</cell><cell>ResNet-12</cell><cell cols="2">72.20 ± 0.70 83.50 ± 0.50</cell></row><row><cell>MetaOptNet[41]</cell><cell>ResNet-12</cell><cell cols="2">72.60 ± 0.70 84.30 ± 0.50</cell></row><row><cell>Boosting[23]</cell><cell>WRN-28-10</cell><cell cols="2">73.60 ± 0.30 86.00 ± 0.20</cell></row><row><cell>Fine-tuning[15]</cell><cell>WRN-28-10</cell><cell cols="2">76.58 ± 0.68 85.79 ± 0.50</cell></row><row><cell>DSN-MR[65]</cell><cell>ResNet-12</cell><cell cols="2">75.60 ± 0.90 86.20 ± 0.60</cell></row><row><cell>MABAS[34]</cell><cell>ResNet-12</cell><cell cols="2">73.51 ± 0.92 85.49 ± 0.68</cell></row><row><cell>RFS-Simple[73]</cell><cell>ResNet-12</cell><cell cols="2">71.50 ± 0.80 86.00 ± 0.50</cell></row><row><cell>RFS-Distill[73]</cell><cell>ResNet-12</cell><cell cols="2">73.90 ± 0.80 86.90 ± 0.50</cell></row><row><cell>Ours</cell><cell>ResNet-12</cell><cell cols="2">76.83 ± 0.82 89.26 ± 0.58</cell></row><row><cell>Ours-Distill</cell><cell>ResNet-12</cell><cell cols="2">77.87 ± 0.85 89.74 ± 0.57</cell></row><row><cell>Methods</cell><cell>Backbone</cell><cell>1-Shot</cell><cell>5-Shot</cell></row><row><cell>Proto-Net  MABAS[34]</cell><cell cols="3">ResNet-12 42.31 ± 0.75 57.56 ± 0.78</cell></row><row><cell>RFS-Simple[73]</cell><cell cols="3">ResNet-12 42.60 ± 0.70 59.10 ± 0.60</cell></row><row><cell>RFS-Distill[73]</cell><cell cols="3">ResNet-12 44.60 ± 0.70 60.90 ± 0.60</cell></row><row><cell>Ours</cell><cell cols="3">ResNet-12 47.38 ± 0.79 64.43 ± 0.77</cell></row><row><cell>Ours-Distill</cell><cell cols="3">ResNet-12 47.76 ± 0.77 65.30 ± 0.76</cell></row></table><note>. Average 5-way few-shot classification accuracy with 95% confidence intervals on CIFAR-FS dataset; † trained on train and validation sets. Top two results are shown in red and blue.† [66] 64-64-64-64 35.30 ± 0.60 48.60 ± 0.60 Proto-Net † [66] ResNet-12 37.50 ± 0.60 52.50 ± 0.60 TADAM[51] ResNet-12 40.10 ± 0.40 56.10 ± 0.40</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc></figDesc><table /><note>Average 5-way few-shot classification accuracy with 95% confidence intervals on FC100 dataset; † trained on train and vali- dation sets. Top two results are shown in red and blue.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc></figDesc><table /><note>Average 5-way few-shot classification accuracy with 95% confidence intervals on miniImageNet dataset; † trained on train and validation sets. Top two results are shown in red and blue.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>-32-32 51.67 ± 1.81 70.30 ± 1.75 Proto-Net † [66] 64-64-64-64 53.31 ± 0.89 72.69 ± 0.74 Relation Net[71] 64-96-128-256 54.48 ± 0.93 71.32 ± 0.78</figDesc><table><row><cell>Methods</cell><cell>Backbone</cell><cell>1-Shot</cell><cell>5-Shot</cell></row><row><cell cols="2">MAML[19] 32-32Shot-Free[60] ResNet-12</cell><cell>63.52</cell><cell>82.59</cell></row><row><cell>MetaOptNet[41]</cell><cell>ResNet-12</cell><cell cols="2">65.99 ± 0.72 81.56 ± 0.53</cell></row><row><cell>Boosting[23]</cell><cell cols="3">WRN-28-10 70.53 ± 0.51 84.98 ± 0.36</cell></row><row><cell>Fine-tuning[15]</cell><cell cols="3">WRN-28-10 66.58 ± 0.70 85.55 ± 0.48</cell></row><row><cell cols="4">LEO-trainval  † [62] WRN-28-10 66.33 ± 0.05 81.44 ± 0.09</cell></row><row><cell>AWGIM[25]</cell><cell cols="3">WRN-28-10 67.69 ± 0.11 82.82 ± 0.13</cell></row><row><cell>DSN-MR[65]</cell><cell>ResNet-12</cell><cell cols="2">67.39 ± 0.82 82.85 ± 0.56</cell></row><row><cell>RFS-Simple[73]</cell><cell>ResNet-12</cell><cell cols="2">69.74 ± 0.72 84.41 ± 0.55</cell></row><row><cell>RFS-Distill[73]</cell><cell>ResNet-12</cell><cell cols="2">71.52 ± 0.69 86.03 ± 0.49</cell></row><row><cell>Ours</cell><cell>ResNet-12</cell><cell cols="2">71.87 ± 0.89 86.82 ± 0.58</cell></row><row><cell>Ours-Distill</cell><cell>ResNet-12</cell><cell cols="2">72.21 ± 0.90 87.08 ± 0.58</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 .</head><label>4</label><figDesc>Average 5-way few-shot classification accuracy with 95% confidence intervals on tieredImageNet dataset; † trained on train and validation sets. Top two results are shown in red and blue.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 .Table 7 .</head><label>67</label><figDesc>class boundaries are not precise and compact. Enforcing invariance on top of the Baseline Training 62.02 ± 0.63 79.64 ± 0.44 71.50 ± 0.80 86.00 ± 0.50 42.60 ± 0.70 59.10 ± 0.60 Ours with only Invariance 64.64 ± 0.80 82.59 ± 0.54 73.50 ± 0.86 87.55 ± 0.61 46.10 ± 0.78 63.18 ± 0.76 Ours with only Equivariance 66.09 ± 0.80 84.03 ± 0.53 76.37 ± 0.83 89.08 ± 0.58 46.73 ± 0.79 64.09 ± 0.75 Ours with Equi and Invar (W/O KD) 66.82 ± 0.80 84.35 ± 0.51 76.83 ± 0.82 89.26 ± 0.58 47.38 ± 0.79 64.43 ± 0.77 Ours with Supervised KD 66.95 ± 0.78 84.39 ± 0.52 76.92 ± 0.85 89.34 ± 0.57 47.70 ± 0.81 65.09 ± 0.76 Ours Full 67.28 ± 0.80 84.78 ± 0.52 77.87 ± 0.85 89.74 ± 0.57 47.76 ± 0.77 65.30 ± 0.76 Ablation study on miniImageNet, CIFAR-FS, and FC100 datasets. Scale 68.20 ± 0.92 83.63 ± 0.62 20 Aspect-Ratio, Rotation, Scale 68.07 ± 0.90 83.53 ± 0.61 Ablation Study on CIFAR-FS validation set with different values of M . We choose M = 16 for all the experiments.</figDesc><table><row><cell></cell><cell>Method</cell><cell cols="2">miniImageNet, 5-Way 1-Shot 5-Shot</cell><cell>CIFAR-FS, 5-Way 1-Shot 5-Shot</cell><cell>FC100, 5-Way 1-Shot 5-Shot</cell></row><row><cell>M</cell><cell>Description</cell><cell>1-Shot</cell><cell>5-Shot</cell></row><row><cell>3</cell><cell>Aspect-Ratio</cell><cell cols="2">65.13 ± 0.93 81.22 ± 0.66</cell></row><row><cell>4</cell><cell>Rotation</cell><cell cols="2">66.56 ± 0.92 82.64 ± 0.64</cell></row><row><cell>8</cell><cell>Rotation, Scale</cell><cell cols="2">67.46 ± 0.92 82.80 ± 0.64</cell></row><row><cell>12</cell><cell>Aspect-Ratio, Rotation</cell><cell cols="2">68.04 ± 0.93 83.48 ± 0.64</cell></row><row><cell cols="2">16 Aspect-Ratio, Rotation,</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>Jigsaw Puzzle [50] 63.98 ± 0.79 81.08 ± 0.55 Baseline + Location Pred [70] 64.39 ± 0.81 81.75 ± 0.54 Baseline + Context Pred [17] 64.72 ± 0.79 81.83 ± 0.54</figDesc><table><row><cell>Method</cell><cell>1-Shot</cell><cell>5-Shot</cell></row><row><cell>Baseline Training</cell><cell cols="2">62.02 ± 0.63 79.64 ± 0.44</cell></row><row><cell>Baseline + Baseline + Rotation [24]</cell><cell cols="2">65.25 ± 0.80 82.85 ± 0.54</cell></row><row><cell>Ours (W/O KD)</cell><cell cols="2">66.82 ± 0.80 84.35 ± 0.51</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 8 .</head><label>8</label><figDesc>FSL with different SSL objectives on miniImageNet dataset.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 10 .Table 11 .</head><label>1011</label><figDesc>AR:{0.67, 1.0, 1.33} 4 ROT:{0 • , 90 • , 180 • , 270 • } 8 ROT:{0 • , 90 • , 180 • , 270 • }S:{0.67, 1.0} 12 AR:{0.67, 1.0, 1.33}ROT:{0 • , 90 • , 180 • , 270 • } 16 AR:{0.67, 1.0, 1.33}ROT:{0 • , 90 • , 180 • , 270 • } ROT:{0 • , 90 • , 180 • , 270 • }S:{0.67} 20 AR:{0.67, 1.0, 1.33}ROT:{0 • , 90 • , 180 • , 270 • } ROT:{0 • , 90 • , 180 • , 270 • }S:{0.67}AR:{0.67, 1.33} 24 AR:{0.67, 1.0, 1.33}ROT:{0 • , 90 • , 180 • , 270 • }S:{0.67, 1.0} Table 9. Complete description of different values of M based on different combination of aspect ratio (AR), rotation (ROT), and scaling (S) transformations. Quantization of the space of Affine transformations. ± 0.63 79.64 ± 0.44 Ours with only Invar (affine) 65.55 ± 0.81 82.17 ± 0.52 Ours with only Equi (affine) 65.70 ± 0.79 82.47 ± 0.53 Ours with Equi and Invar (affine) 66.82 ± 0.79 82.96 ± 0.53 Ours with Equi and Invar (M =16) 66.82 ± 0.80 84.35 ± 0.51 Average 5-way few-shot classification accuracy with 95% confidence intervals on miniImageNet dataset; trained with different geometric transformations.</figDesc><table><row><cell>M</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head></head><label></label><figDesc>Ours with only Invariance 18.56 Ours with only Equivariance 16.95 Ours with Equi and Invar (W/O KD) 16.84 Table 12. Results with invariance and equivariance for supervised classification on CIFAR-100 dataset.</figDesc><table><row><cell>Method</cell><cell>Error Rate (%)</cell></row><row><cell>Supervised Baseline</cell><cell>18.78</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dsn-Mr</surname></persName>
		</author>
		<idno>ResNet-12</idno>
		<imprint>
			<biblScope unit="volume">65</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Infinite mixture prototypes for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kelsey</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanul</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><surname>Tenenbaum</surname></persName>
		</author>
		<idno>PMLR. 1</idno>
	</analytic>
	<monogr>
		<title level="m">of Proceedings of Machine Learning Research</title>
		<meeting><address><addrLine>Long Beach, California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-06" />
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="9" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jessica</forename><forename type="middle">B</forename><surname>Battaglia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Hamrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alvaro</forename><surname>Bapst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vinicius</forename><surname>Sanchez-Gonzalez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mateusz</forename><surname>Zambaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Malinowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Tacchetti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Raposo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Santoro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Faulkner</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.01261</idno>
		<title level="m">Relational inductive biases, deep learning, and graph networks</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Mixmatch: A holistic approach to semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avital</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><forename type="middle">A</forename><surname>Raffel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>H. Wallach, H. Larochelle, A. Beygelzimer, F. d&apos;Alché-Buc, E. Fox, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="5049" to="5059" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Meta-learning with differentiable closed-form solvers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Bertinetto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joao</forename><forename type="middle">F</forename><surname>Henriques</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Vedaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Albumentations: fast and flexible image augmentations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Buslaev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Vladimir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Iglovikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Khvedchenya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikhail</forename><surname>Parinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandr A</forename><surname>Druzhinin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kalinin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">125</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Quo vadis, action recognition? a new model and the kinetics dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joao</forename><surname>Carreira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6299" to="6308" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Encoder-decoder with atrous separable convolution for semantic image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Liang-Chieh Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European conference on computer vision (ECCV)</title>
		<meeting>the European conference on computer vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="801" to="818" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Diversity transfer network for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxin</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinggang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifeng</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.05709</idno>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A closer look at few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Yu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yen-Cheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zsolt</forename><surname>Kira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Chiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia-Bin</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shashua</surname></persName>
		</author>
		<title level="m">Inductive bias of deep convolutional networks through pooling geometry. International Conference on Learning Representations (ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Group equivariant convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taco</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2990" to="2999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dandelion</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Mane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Autoaugment</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.09501</idno>
		<title level="m">Learning augmentation policies from data</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">ImageNet: A Large-Scale Hierarchical Image Database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR09</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Avinash Ravichandran, and Stefano Soatto. A baseline for few-shot image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guneet</forename><surname>Singh Dhillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pratik</forename><surname>Chaudhari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Exploiting cyclic symmetry in convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sander</forename><surname>Dieleman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><forename type="middle">De</forename><surname>Fauw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.02660</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Unsupervised visual representation learning by context prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1422" to="1430" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Crosstransformers: spatially-aware few-shot transfer. Advances in Neural Information Processing Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankush</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Modelagnostic meta-learning for fast adaptation of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2017-08" />
			<publisher>International Convention Centre</publisher>
		</imprint>
	</monogr>
	<note>PMLR. 1, 2, 3, 6</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Finzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Stanton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Izmailov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Gordon</forename><surname>Wilson</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.12880</idno>
		<title level="m">Generalizing convolutional neural networks for equivariance to lie groups on arbitrary continuous data</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Bornagain neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tommaso</forename><surname>Furlanello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><forename type="middle">Chase</forename><surname>Lipton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Tschannen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Itti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anima</forename><surname>Anandkumar</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th International Conference on Machine Learning, ICML 2018, Stockholmsmässan</title>
		<editor>Jennifer G. Dy and Andreas Krause</editor>
		<meeting>the 35th International Conference on Machine Learning, ICML 2018, Stockholmsmässan<address><addrLine>Stockholm, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1602" to="1611" />
		</imprint>
	</monogr>
	<note>Proceedings of Machine Learning Research</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Dropblock: A regularization method for convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Golnaz</forename><surname>Ghiasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="10727" to="10737" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Boosting few-shot visual learning with self-supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spyros</forename><surname>Gidaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><surname>Bursuc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Komodakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Pérez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Cord</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="8059" to="8068" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Unsupervised representation learning by predicting image rotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spyros</forename><surname>Gidaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Praveer</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Komodakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Attentive weights generation for few shot learning via information maximization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiluan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ngai-Man</forename><surname>Cheung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Dimensionality reduction by learning an invariant mapping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raia</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR&apos;06)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2006" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1735" to="1742" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Gaussian affinity for max-margin class imbalanced learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Munawar</forename><surname>Hayat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salman</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianbing</forename><surname>Syed Waqas Zamir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ling</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6469" to="6479" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Piotr Dollár, and Ross Girshick. Mask r-cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgia</forename><surname>Gkioxari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2961" to="2969" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Benchmarking neural network robustness to common corruptions and perturbations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Dietterich</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.12261</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Distilling the knowledge in a neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS Deep Learning and Representation Learning Workshop</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Task agnostic meta-learning for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammad</forename><forename type="middle">Abdullah</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamal</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guo-Jun</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="11719" to="11727" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A guide to convolutional neural networks for computer vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salman</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hossein</forename><surname>Rahmani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Syed Afaq Ali</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammed</forename><surname>Bennamoun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Synthesis Lectures on Computer Vision</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="207" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Modelagnostic boundary-adversarial sampling for test-time generalization in few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaekyeom</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyoungseok</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gunhee</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision -ECCV 2020</title>
		<editor>Andrea Vedaldi, Horst Bischof, Thomas Brox, and Jan-Michael Frahm</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="599" to="617" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Siamese neural networks for one-shot image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML deep learning workshop</title>
		<meeting><address><addrLine>Lille</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Do better imagenet models transfer better?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2661" to="2671" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Cifar-100 (canadian institute for advanced research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vinod</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Ti-pooling: transformation-invariant pooling for feature learning in convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Laptev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikolay</forename><surname>Savinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joachim</forename><forename type="middle">M</forename><surname>Buhmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Pollefeys</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="289" to="297" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Learning representations for automatic colorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gustav</forename><surname>Larsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Shakhnarovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="577" to="593" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Convolutional networks for images, speech, and time series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="volume">3361</biblScope>
		</imprint>
	</monogr>
	<note>The handbook of brain theory and neural networks</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Meta-learning with differentiable convex optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kwonjoon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhransu</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avinash</forename><surname>Ravichandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Soatto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Group equivariant capsule networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><forename type="middle">Eric</forename><surname>Lenssen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Fey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Libuschewski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8844" to="8853" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Adversarial feature hallucination networks for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kunpeng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="13470" to="13479" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lubomir</forename><surname>Bourdev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Dollár</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>Microsoft coco: Common objects in context</note>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Self-supervised prototypical transfer learning for few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Medina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arnout</forename><surname>Devos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Grossglauser</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.11325,2020.3</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Sequence searching with deep-learnt depth for condition-and viewpoint-invariant route-based place recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Milford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephanie</forename><surname>Lowry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niko</forename><surname>Suenderhauf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sareh</forename><surname>Shirazi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guosheng</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fayao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Pepperell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cesar</forename><surname>Lerma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Upcroft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition Workshops</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="18" to="25" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">A simple neural attentive meta-learner</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikhil</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mostafa</forename><surname>Rohaninejad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Self-supervised learning of pretext-invariant representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishan</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="6707" to="6717" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Rapid adaptation with conditionally shifted neurons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsendsuren</forename><surname>Munkhdalai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingdi</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soroush</forename><surname>Mehri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Trischler</surname></persName>
		</author>
		<idno>PMLR. 6</idno>
	</analytic>
	<monogr>
		<title level="m">of Proceedings of Machine Learning Research</title>
		<meeting><address><addrLine>Stockholmsmässan, Stockholm Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-07" />
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="10" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Unsupervised learning of visual representations by solving jigsaw puzzles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Noroozi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Favaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<biblScope unit="page" from="69" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Springer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Tadam: Task dependent adaptive metric for improved few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boris</forename><surname>Oreshkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Pau Rodríguez López</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lacoste</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Context encoders: Feature learning by inpainting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deepak</forename><surname>Pathak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Krahenbuhl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2536" to="2544" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Early stopping-but when?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lutz</forename><surname>Prechelt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Networks: Tricks of the trade</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1998" />
			<biblScope unit="page" from="55" to="69" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Learning generalized transformation equivariant representations via autoencoding transformations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liheng</forename><surname>Guo-Jun Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="issue">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Transductive episodic-wise adaptive metric for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Limeng</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yemin</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaowei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiejun</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonghong</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3603" to="3612" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Rapid learning or feature reuse? towards understanding the effectiveness of maml</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aniruddh</forename><surname>Raghu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maithra</forename><surname>Raghu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Selfsupervised knowledge distillation for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jathushan</forename><surname>Rajasegaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salman</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Munawar</forename><surname>Hayat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fahad</forename><surname>Shahbaz Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mubarak</forename><surname>Shah</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2006.09785,2020.3" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Optimization as a model for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sachin</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Optimization as a model for fewshot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Few-shot learning with embedded class models and shot-free meta training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avinash</forename><surname>Ravichandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahul</forename><surname>Bhotika</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Soatto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">Meta-learning for semi-supervised fewshot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengye</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eleni</forename><surname>Triantafillou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sachin</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jake</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.00676</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Oriol Vinyals, Razvan Pascanu, Simon Osindero, and Raia Hadsell. Meta-learning with latent embedding optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dushyant</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakub</forename><surname>Sygnowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Dynamic routing between capsules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sara</forename><surname>Sabour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Frosst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3856" to="3866" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Cnn features off-the-shelf: an astounding baseline for recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Sharif Razavian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hossein</forename><surname>Azizpour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josephine</forename><surname>Sullivan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Carlsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition workshops</title>
		<meeting>the IEEE conference on computer vision and pattern recognition workshops</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="806" to="813" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Adaptive subspaces for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Koniusz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Nock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehrtash</forename><surname>Harandi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Prototypical networks for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jake</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="4077" to="4087" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">Dropout: a simple way to prevent neural networks from overfitting. The journal of machine learning research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">When does self-supervision improve few-shot learning? European Conference on Computer Vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jong-Chyi</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhransu</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bharath</forename><surname>Hariharan</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Meta-transfer learning for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qianru</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaoyao</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="403" to="412" />
		</imprint>
	</monogr>
	<note>Tat-Seng Chua, and Bernt Schiele</note>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<title level="m" type="main">Unsupervised domain adaptation through self-supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.11825</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Learning to compare: Relation network for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Flood</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1199" to="1208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Rethinking the inception architecture for computer vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zbigniew</forename><surname>Wojna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2818" to="2826" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<title level="m" type="main">Rethinking few-shot image classification: a good embedding is all you need?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonglong</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilip</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.11539</idno>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Regression shrinkage and selection via the lasso</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Tibshirani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society: Series B (Methodological)</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="267" to="288" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Adversarial training and robustness for multiple perturbations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Tramèr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Boneh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5866" to="5876" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Meta-dataset: A dataset of datasets for learning to learn from few examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eleni</forename><surname>Triantafillou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tyler</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Dumoulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Lamblin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Utku</forename><surname>Evci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kelvin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Goroshin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carles</forename><surname>Gelada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre-Antoine</forename><surname>Manzagol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Matching networks for one shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>D. D. Lee, M. Sugiyama, U. V. Luxburg, I. Guyon, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2005" />
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Matching networks for one shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3630" to="3638" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Unsupervised feature learning via non-parametric instance discrimination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhirong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanjun</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Stella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dahua</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3733" to="3742" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Wide residual networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Zagoruyko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Komodakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the British Machine Vision Conference (BMVC)</title>
		<editor>Edwin R. Hancock Richard C. Wilson and William A. P. Smith</editor>
		<meeting>the British Machine Vision Conference (BMVC)</meeting>
		<imprint>
			<publisher>BMVA Press</publisher>
			<date type="published" when="2011" />
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="87" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Taskonomy: Disentangling task transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Amir R Zamir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Sax</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Guibas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3712" to="3722" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Colorful image colorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="649" to="666" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Places: A 10 million image database for scene recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bolei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agata</forename><surname>Lapedriza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aude</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
