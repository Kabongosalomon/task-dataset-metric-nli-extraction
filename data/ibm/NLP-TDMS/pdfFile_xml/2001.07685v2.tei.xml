<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
							<email>kihyuks@google.com</email>
							<affiliation key="aff0">
								<orgName type="department">Google Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Berthelot</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Google Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun-Liang</forename><surname>Li</surname></persName>
							<email>chunliang@google.com</email>
							<affiliation key="aff0">
								<orgName type="department">Google Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zizhao</forename><surname>Zhang</surname></persName>
							<email>zizhaoz@google.com</email>
							<affiliation key="aff0">
								<orgName type="department">Google Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
							<email>ncarlini@google.com</email>
							<affiliation key="aff0">
								<orgName type="department">Google Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ekin</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
							<email>cubuk@google.com</email>
							<affiliation key="aff0">
								<orgName type="department">Google Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Kurakin</surname></persName>
							<email>kurakin@google.com</email>
							<affiliation key="aff0">
								<orgName type="department">Google Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Zhang</surname></persName>
							<email>zhanghan@google.com</email>
							<affiliation key="aff0">
								<orgName type="department">Google Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Raffel</surname></persName>
							<email>craffel@google.com</email>
							<affiliation key="aff0">
								<orgName type="department">Google Research</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T10:15+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Semi-supervised learning (SSL) provides an effective means of leveraging unlabeled data to improve a model's performance. This domain has seen fast progress recently, at the cost of requiring more complex methods. In this paper we propose FixMatch, an algorithm that is a significant simplification of existing SSL methods. FixMatch first generates pseudo-labels using the model's predictions on weaklyaugmented unlabeled images. For a given image, the pseudo-label is only retained if the model produces a high-confidence prediction. The model is then trained to predict the pseudo-label when fed a strongly-augmented version of the same image. Despite its simplicity, we show that FixMatch achieves state-of-the-art performance across a variety of standard semi-supervised learning benchmarks, including 94.93% accuracy on CIFAR-10 with 250 labels and 88.61% accuracy with 40 -just 4 labels per class. We carry out an extensive ablation study to tease apart the experimental factors that are most important to FixMatch's success. The code is available at https://github.com/google-research/fixmatch.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Deep neural networks have become the de facto model for computer vision applications. Their success is partially attributable to their scalability, i.e., the empirical observation that training them on larger datasets produces better performance <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b20">21]</ref>. Deep networks often achieve their strong performance through supervised learning, which requires a labeled dataset. The performance benefit conferred by the use of a larger dataset can therefore come at a significant cost since labeling data often requires human labor. This cost can be particularly extreme when labeling must be done by an expert (for example, a doctor in medical applications).</p><p>A powerful approach for training models on a large amount of data without requiring a large amount of labels is semi-supervised learning (SSL). SSL mitigates the requirement for labeled data by providing a means of leveraging unlabeled data. Since unlabeled data can often be obtained with minimal human labor, any performance boost conferred by SSL often comes with low cost. This has led to a plethora of SSL methods that are designed for deep networks <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b51">52]</ref>.</p><p>A popular class of SSL methods can be viewed as producing an artificial label for unlabeled images and training the model to predict the artificial label when fed unlabeled images as input. For example, pseudo-labeling <ref type="bibr" target="#b24">[25]</ref> (also called self-training <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b46">47]</ref>) uses the model's class prediction as a label to train against. Similarly, consistency regularization <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b23">24]</ref> obtains an artificial label using the model's predicted distribution after randomly modifying the input or model function. is fed into the model to obtain predictions (red box). When the model assigns a probability to any class which is above a threshold (dotted line), the prediction is converted to a one-hot pseudo-label. Then, we compute the model's prediction for a strong augmentation of the same image (bottom). The model is trained to make its prediction on the strongly-augmented version match the pseudo-label via a cross-entropy loss.</p><p>In this work, we break the trend of recent state-of-the-art methods that combine increasingly complex mechanisms <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b2">3]</ref> and produce a method that is simpler, but also more accurate. Our algorithm, FixMatch, produces artificial labels using both consistency regularization and pseudo-labeling. Crucially, the artificial label is produced based on a weakly-augmented unlabeled image (e.g., using only flip-and-shift data augmentation) which is used as a target when the model is fed a stronglyaugmented version of the same image. Inspired by UDA <ref type="bibr" target="#b53">[54]</ref> and ReMixMatch <ref type="bibr" target="#b2">[3]</ref>, we leverage Cutout <ref type="bibr" target="#b13">[14]</ref>, CTAugment <ref type="bibr" target="#b2">[3]</ref>, and RandAugment <ref type="bibr" target="#b10">[11]</ref> for strong augmentation, which all produce heavily-distorted versions of a given image. Following the approach of pseudo-labeling <ref type="bibr" target="#b24">[25]</ref>, we only retain an artificial label if the model assigns a high probability to one of the possible classes. A diagram of FixMatch is shown in <ref type="figure" target="#fig_0">fig. 1</ref>.</p><p>Despite its simplicity, we show that FixMatch obtains state-of-the-art performance on the most commonly-studied SSL benchmarks. For example, FixMatch achieves 94.93% accuracy on CIFAR-10 with 250 labeled examples compared to the previous state-of-the-art of 93.73% <ref type="bibr" target="#b2">[3]</ref> in the standard experimental setting from <ref type="bibr" target="#b35">[36]</ref>. We also explore the limits of our approach by applying it in the extremely-scarce-labels regime, obtaining 88.61% accuracy on CIFAR-10 with only 4 labels per class. Since FixMatch is a simplification of existing approaches but achieves substantially better performance, we include an extensive ablation study to determine which factors contribute the most to its success. A key benefit of FixMatch being a simplification of existing methods is that it requires many fewer additional hyperparameters. As such, it allows us to perform an extensive ablation study of each of them. Our ablation study also includes basic fully-supervised learning experimental choices that are often ignored or not reported when new SSL methods are proposed (such as the optimizer or learning rate schedule).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">FixMatch</head><p>FixMatch is a combination of two approaches to SSL: Consistency regularization and pseudo-labeling. Its main novelty comes from the combination of these two ingredients as well as the use of a separate weak and strong augmentation when performing consistency regularization. In this section, we first review consistency regularization and pseudo-labeling before describing FixMatch in detail. We also describe the other factors, such as regularization, which contribute to FixMatch's empirical success.</p><p>For an L-class classification problem, let </p><formula xml:id="formula_0">X = (x b , p b ) : b ∈ (1,</formula><formula xml:id="formula_1">= u b : b ∈ (1, .</formula><p>. . , µB) be a batch of µB unlabeled examples where µ is a hyperparameter that determines the relative sizes of X and U. Let p m (y | x) be the predicted class distribution produced by the model for input x. We denote the cross-entropy between two probability distributions p and q as H(p, q). We perform two types of augmentations as part of FixMatch: strong and weak, denoted by A(·) and α(·) respectively. We describe the form of augmentation we use for A and α in section 2.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Background</head><p>Consistency regularization is an important component of recent state-of-the-art SSL algorithms. Consistency regularization utilizes unlabeled data by relying on the assumption that the model should output similar predictions when fed perturbed versions of the same image. This idea was first proposed in <ref type="bibr" target="#b1">[2]</ref> and popularized by <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b23">24]</ref>, where the model is trained both via a standard supervised classification loss and on unlabeled data via the loss function</p><formula xml:id="formula_2">µB b=1 p m (y| α(u b )) − p m (y| α(u b )) 2 2<label>(1)</label></formula><p>Note that both α and p m are stochastic functions, so the two terms in eq. (1) will indeed have different values. Extensions to this idea include using an adversarial transformation in place of α <ref type="bibr" target="#b32">[33]</ref>, using a running average or past model predictions for one invocation of p m <ref type="bibr" target="#b50">[51,</ref><ref type="bibr" target="#b23">24]</ref>, using a cross-entropy loss in place of the squared 2 loss <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b2">3]</ref>, using stronger forms of augmentation <ref type="bibr" target="#b53">[54,</ref><ref type="bibr" target="#b2">3]</ref>, and using consistency regularization as a component in a larger SSL pipeline <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b2">3]</ref>.</p><p>Pseudo-labeling leverages the idea of using the model itself to obtain artificial labels for unlabeled data <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b46">47]</ref>. Specifically, this refers to the use of "hard" labels (i.e., the arg max of the model's output) and only retaining artificial labels whose largest class probability fall above a predefined threshold <ref type="bibr" target="#b24">[25]</ref>. Letting q b = p m (y|u b ), pseudo-labeling uses the following loss function:</p><formula xml:id="formula_3">1 µB µB b=1 1(max(q b ) ≥ τ ) H(q b , q b )<label>(2)</label></formula><p>whereq b = arg max(q b ) and τ is the threshold. For simplicity, we assume that arg max applied to a probability distribution produces a valid "one-hot" probability distribution. The use of a hard label makes pseudo-labeling closely related to entropy minimization <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b44">45]</ref>, where the model's predictions are encouraged to be low-entropy (i.e., high-confidence) on unlabeled data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Our Algorithm: FixMatch</head><p>The loss function for FixMatch consists of two cross-entropy loss terms: a supervised loss s applied to labeled data and an unsupervised loss u . Specifically, s is just the standard cross-entropy loss on weakly augmented labeled examples:</p><formula xml:id="formula_4">s = 1 B B b=1 H(p b , p m (y | α(x b )))<label>(3)</label></formula><p>FixMatch computes an artificial label for each unlabeled example 2 which is then used in a standard cross-entropy loss. To obtain an artificial label, we first compute the model's predicted class distribution given a weakly-augmented version of a given unlabeled image: q b = p m (y | α(u b )). Then, we useq b = arg max(q b ) as a pseudo-label, except we enforce the cross-entropy loss against the model's output for a strongly-augmented version of u b :</p><formula xml:id="formula_5">u = 1 µB µB b=1 1(max(q b ) ≥ τ ) H(q b , p m (y | A(u b )))<label>(4)</label></formula><p>where τ is a scalar hyperparameter denoting the threshold above which we retain a pseudo-label. The loss minimized by FixMatch is simply s + λ u u where λ u is a fixed scalar hyperparameter denoting the relative weight of the unlabeled loss. We present a complete algorithm for FixMatch in algorithm 1 of the supplementary material.</p><p>While eq. (4) is similar to the pseudo-labeling loss in eq. (2), it is crucially different in that the artificial label is computed based on a weakly-augmented image and the loss is enforced against the model's output for a strongly-augmented image. This introduces a form of consistency regularization which, as we will show in section 5, is crucial to FixMatch's success. We also note that it is typical in modern SSL algorithms to increase the weight of the unlabeled loss term (λ u ) during training <ref type="bibr" target="#b50">[51,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b35">36]</ref>. We found that this was unnecessary for FixMatch, which may be due to the fact that max(q b ) is typically less than τ early in training. As training progresses, the model's predictions become more confident and it is more frequently the case that max(q b ) &gt; τ . This suggests that pseudo-labeling may produce a natural curriculum "for free". Similar justifications have been used in the past for ignoring low-confidence predictions in visual domain adaptation <ref type="bibr" target="#b14">[15]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Augmentation in FixMatch</head><p>FixMatch leverages two kinds of augmentations: "weak" and "strong". In all of our experiments, weak augmentation is a standard flip-and-shift augmentation strategy. Specifically, we randomly flip images horizontally with a probability of 50% on all datasets except SVHN and we randomly translate images by up to 12.5% vertically and horizontally.</p><p>For "strong" augmentation, we experiment with two methods based on AutoAugment <ref type="bibr" target="#b9">[10]</ref>, which are then followed by the Cutout <ref type="bibr" target="#b13">[14]</ref>. AutoAugment uses reinforcement learning to find an augmentation strategy comprising transformations from the Python Imaging Library. <ref type="bibr" target="#b2">3</ref> This requires labeled data to learn the augmentation strategy, making it problematic to use in SSL settings where limited labeled data is available. As a result, variants of AutoAugment which do not require the augmentation strategy to be learned ahead of time with labeled data, such as RandAugment <ref type="bibr" target="#b10">[11]</ref> and CTAugment <ref type="bibr" target="#b2">[3]</ref>, have been proposed. Instead of using a learned strategy, both RandAugment and CTAugment randomly select transformations for each sample. For RandAugment, the magnitude that controls the severity of all distortions is randomly sampled from a pre-defined range (RandAugment with random magnitude was also used for UDA by <ref type="bibr" target="#b53">[54]</ref>), whereas the magnitudes of individual transformations are learned on-the-fly for CTAugment. Refer to appendix E for more details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Additional important factors</head><p>Semi-supervised performance can be substantially impacted by factors other than the SSL algorithm used because considerations like the amount of regularization can be particularly important in the low-label regime. This is compounded by the fact that the performance of deep networks trained for image classification can heavily depend on the architecture, optimizer, training schedule, etc. These factors are typically not emphasized when new SSL algorithms are introduced. Instead, we endeavor to quantify their importance and highlight which ones have a significant impact on performance. Most analysis is performed in section 5. In this section we identify a few key considerations.</p><p>First, as mentioned above, we find that regularization is particularly important. In all of our models and experiments, we use simple weight decay regularization. We also found that using the Adam optimizer <ref type="bibr" target="#b21">[22]</ref> resulted in worse performance and instead use standard SGD with momentum <ref type="bibr" target="#b49">[50,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b33">34]</ref>. We did not find a substantial difference between standard and Nesterov momentum. For a learning rate schedule, we use a cosine learning rate decay <ref type="bibr" target="#b27">[28]</ref> which sets the learning rate to η cos 7πk 16K where η is the initial learning rate, k is the current training step, and K is the total number of training steps. Finally, we report final performance using an exponential moving average of model parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Extensions of FixMatch</head><p>Due to its simplicity, FixMatch can be readily extended with techniques in SSL literature. For example, both Augmentation Anchoring (where M strong augmentations are used for consistency regularization for each unlabeled example) and Distribution Alignment (which encourages the model predictions to have the same class distribution as the labeled set) from ReMixMatch <ref type="bibr" target="#b2">[3]</ref> can be straightforwardly applied to FixMatch. Moreover, one may replace strong augmentations in FixMatch with modality-agnostic augmentation strategies, such as MixUp <ref type="bibr" target="#b58">[59]</ref> or adversarial perturbations <ref type="bibr" target="#b32">[33]</ref>. We present some exploration and experiments with these extensions in appendix D.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Related work</head><p>Semi-supervised learning is a mature field with a huge diversity of approaches. In this review, we focus on methods closely related to FixMatch. Broader introductions are provided in <ref type="bibr" target="#b59">[60,</ref><ref type="bibr">61,</ref><ref type="bibr" target="#b5">6]</ref>.</p><p>The idea behind self-training has been around for decades <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b31">32]</ref>. The generality of self-training (i.e., using a model's predictions to obtain artificial labels for unlabeled data) has led it to be applied in many domains including NLP <ref type="bibr" target="#b30">[31]</ref>, object detection <ref type="bibr" target="#b43">[44]</ref>, image classification <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b54">55]</ref>  <ref type="table">Table 1</ref>: Comparison of SSL algorithms which include a form of consistency regularization and which (optionally) apply some form of post-processing to the artificial labels. We only mention those components of the SSL algorithm relevant to producing the artificial labels (for example, Virtual Adversarial Training additionally uses entropy minimization <ref type="bibr" target="#b16">[17]</ref>, MixMatch and ReMixMatch also use MixUp <ref type="bibr" target="#b58">[59]</ref>, UDA includes additional techniques like training signal annealing, etc.).</p><p>adaptation <ref type="bibr">[62]</ref>, to name a few. Pseudo-labeling refers to a specific variant where model predictions are converted to hard labels <ref type="bibr" target="#b24">[25]</ref>, which is often used along with a confidence-based thresholding that retains unlabeled examples only when the classifier is sufficiently confident (e.g., <ref type="bibr" target="#b43">[44]</ref>). While some studies have suggested that pseudo-labeling is not competitive against other modern SSL algorithms on its own <ref type="bibr" target="#b35">[36]</ref>, recent SSL algorithms have used pseudo-labeling as a part of their pipeline to produce better results <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b38">39]</ref>. As mentioned above, pseudo-labeling results in a form of entropy minimization <ref type="bibr" target="#b16">[17]</ref> which has been used as a component for many SSL techniques <ref type="bibr" target="#b32">[33]</ref>.</p><p>Consistency regularization was first proposed by <ref type="bibr" target="#b1">[2]</ref> and later referred to as "Transformation/Stability" (or TS for short) <ref type="bibr" target="#b45">[46]</ref> or the "Π-Model" <ref type="bibr" target="#b42">[43]</ref>. Early extensions included using an exponential moving average of model parameters <ref type="bibr" target="#b50">[51]</ref> or using previous model checkpoints <ref type="bibr" target="#b23">[24]</ref> when producing artificial labels. Several methods have been used to produce random perturbations including data augmentation <ref type="bibr" target="#b14">[15]</ref>, stochastic regularization (e.g. Dropout <ref type="bibr" target="#b48">[49]</ref>) <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b23">24]</ref>, and adversarial perturbations <ref type="bibr" target="#b32">[33]</ref>. More recently, it has been shown that using strong data augmentation can produce better results <ref type="bibr" target="#b53">[54,</ref><ref type="bibr" target="#b2">3]</ref>. These heavily-augmented examples are almost certainly outside of the data distribution, which has in fact been shown to be beneficial for SSL <ref type="bibr" target="#b11">[12]</ref>. Noisy Student <ref type="bibr" target="#b54">[55]</ref> has integrated these techniques into a self-training framework and demonstrated impressive performance on ImageNet with additional massive amount of unlabeled data.</p><p>Of the aforementioned work, FixMatch bears the closest resemblance to two recent methods: Unsupervised Data Augmentation (UDA) <ref type="bibr" target="#b53">[54]</ref> and ReMixMatch <ref type="bibr" target="#b2">[3]</ref>. They both use a weakly-augmented example to generate an artificial label and enforce consistency against strongly-augmented examples. Neither of them uses pseudo-labeling, but both approaches "sharpen" the artificial label to encourage the model to produce high-confidence predictions. UDA in particular also only enforces consistency when the highest probability in the predicted class distribution for the artificial label is above a threshold. The thresholded pseudo-labeling of FixMatch has a similar effect to sharpening. In addition, ReMixMatch anneals the weight of the unlabeled data loss, which we omit from FixMatch because we posit that the thresholding used in pseudo-labeling has a similar effect (as mentioned in section 2.2). These similarities suggest that FixMatch can be viewed as a substantially simplified version of UDA and ReMixMatch, where we have combined two common techniques (pseudo-labeling and consistency regularization) while removing many components (sharpening, training signal annealing from UDA, distribution alignment and the rotation loss from ReMixMatch, etc.).</p><p>Since the core of FixMatch is a simple combination of two existing techniques, it also bears substantial similarities to many previously-proposed SSL algorithms. We provide a concise comparison of each of these techniques in table 1 where we list the augmentation used for the artificial label, the model's prediction, and any post-processing applied to the artificial label. A more thorough comparison of these different algorithms and their constituent approaches is provided in the following section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We evaluate the efficacy of FixMatch on several SSL image classification benchmarks. Specifically, we perform experiments with varying amounts of labeled data and augmentation strategies on CIFAR-10/100 <ref type="bibr" target="#b22">[23]</ref>, SVHN <ref type="bibr" target="#b34">[35]</ref>, STL-10 <ref type="bibr" target="#b8">[9]</ref>, and ImageNet <ref type="bibr" target="#b12">[13]</ref>, following standard SSL evaluation protocols <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b2">3]</ref>. In many cases, we perform experiments with fewer labels than previously considered since FixMatch shows promise in extremely label-scarce settings. Note that we use an identical set of  <ref type="table">Table 2</ref>: Error rates for CIFAR-10, CIFAR-100, SVHN and STL-10 on 5 different folds. FixMatch (RA) uses RandAugment <ref type="bibr" target="#b10">[11]</ref> and FixMatch (CTA) uses CTAugment <ref type="bibr" target="#b2">[3]</ref> for strong-augmentation. All baseline models (Π-Model <ref type="bibr" target="#b42">[43]</ref>, Pseudo-Labeling <ref type="bibr" target="#b24">[25]</ref>, Mean Teacher <ref type="bibr" target="#b50">[51]</ref>, MixMatch <ref type="bibr" target="#b3">[4]</ref>, UDA <ref type="bibr" target="#b53">[54]</ref>, and ReMixMatch <ref type="bibr" target="#b2">[3]</ref>) are tested using the same codebase.</p><p>hyperparameters (λ u = 1, η = 0.03, β = 0.9, τ = 0.95, µ = 7, B = 64, K = 2 20 ) 4 across all amounts of labeled examples and datasets other than ImageNet. A complete list of hyperparameters is reported in appendix B.1. We include an extensive ablation study in section 5 to tease apart the importance of the different components and hyperparameters of FixMatch, including factors that are not explicitly part of the SSL algorithm such as the optimizer and learning rate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">CIFAR-10, CIFAR-100, and SVHN</head><p>We compare FixMatch to various existing methods on the standard CIFAR-10, CIFAR-100, and SVHN benchmarks. As suggested by <ref type="bibr" target="#b35">[36]</ref>, we reimplemented all existing baselines and performed all experiments using the same codebase. In particular, we use the same network architecture and training protocol, including the optimizer, learning rate schedule, data preprocessing, etc. across all SSL methods. Following <ref type="bibr" target="#b3">[4]</ref>, we used a Wide ResNet-28-2 [56] with 1.5M parameters for CIFAR-10 and SVHN, WRN-28-8 for CIFAR-100, and WRN-37-2 for STL-10. For baselines, we consider methods that are similar to FixMatch and/or are state-of-the-art: Π-Model <ref type="bibr" target="#b42">[43]</ref>, Mean Teacher <ref type="bibr" target="#b50">[51]</ref>, Pseudo-Label <ref type="bibr" target="#b24">[25]</ref>, MixMatch <ref type="bibr" target="#b3">[4]</ref>, UDA <ref type="bibr" target="#b53">[54]</ref>, and ReMixMatch <ref type="bibr" target="#b2">[3]</ref>. Besides <ref type="bibr" target="#b2">[3]</ref>, previous work has not considered fewer than 25 labels per class on these benchmarks. Performing better with less supervision is the central goal of SSL in practice since it alleviates the need for labeled data. We also consider the setting where only 4 labeled images are given for each class on each dataset. As far as we are aware, we are the first to run any experiments at 4 labels per class on CIFAR-100.</p><p>We report the performance of all baselines along with FixMatch in table 2. We compute the mean and variance of accuracy when training on 5 different "folds" of labeled data. We omit results with 4 labels per class for Π-Model, Mean Teacher, and Pseudo-Labeling since the performance was poor at 250 labels. MixMatch, ReMixMatch, and UDA all perform reasonably well with 40 and 250 labels, but we find that FixMatch substantially outperforms each of these methods while nevertheless being simpler. For example, FixMatch achieves an average error rate of 11.39% on CIFAR-10 with 4 labels per class. As a point of reference, among the methods studied in <ref type="bibr" target="#b35">[36]</ref> (where the same network architecture was used), the lowest error rate achieved on CIFAR-10 with 400 labels per class was 13.13%. Our results also compare favorably to recent state-of-the-art results achieved by ReMixMatch <ref type="bibr" target="#b2">[3]</ref>, despite the fact that we omit various components such as the self-supervised loss.</p><p>Our results are state-of-the-art on all datasets except for CIFAR-100 where ReMixMatch performs a bit better. To understand why ReMixMatch performs better than FixMatch, we experimented with a few variants of FixMatch which copy various components of ReMixMatch into FixMatch. We find that the most important term is Distribution Alignment (DA), which encourages the model predictions to have the same class distribution as the labeled set. Combining FixMatch with DA reaches a 40.14% error rate with 400 labeled examples, which is substantially better than the 44.28% achieved by ReMixMatch.</p><p>We find that in most cases the performance of FixMatch using CTAugment and RandAugment is similar, except in the settings where we have 4 labels per class. This may be explained by the fact that these results are particularly high-variance. For example, the variance over 5 different folds for CIFAR-10 with 4 labels per class is 3.35%, which is significantly higher than that with 25 labels per class (0.33%). The error rates are also affected significantly by the random seeds when the number of labeled examples per class is extremely small, as shown in table 8 of supplementary material. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">STL-10</head><p>The STL-10 dataset contains 5,000 labeled images of size 96×96 from 10 classes and 100,000 unlabeled images. There exist out-of-distribution images in the unlabeled set, making it a more realistic and challenging test of SSL performance. We test SSL algorithms on five of the predefined folds of 1,000 labeled images each. Following <ref type="bibr" target="#b3">[4]</ref>, we use a WRN-37-2 network (comprising 5.9M parameters). <ref type="bibr" target="#b4">5</ref> As in table 2, FixMatch achieves the state-of-the-art performance of ReMixMatch <ref type="bibr" target="#b2">[3]</ref> despite being significantly simpler.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">ImageNet</head><p>We evaluate FixMatch on ImageNet to verify that it performs well on a larger and more complex dataset. Following <ref type="bibr" target="#b53">[54]</ref>, we use 10% of the training data as labeled and treat the rest as unlabeled examples. We use a ResNet-50 network architecture and RandAugment <ref type="bibr" target="#b10">[11]</ref> as strong augmentation for this experiment. We include additional implementation details in appendix C. FixMatch achieves a top-1 error rate of 28.54 ± 0.52%, which is 2.68% better than UDA <ref type="bibr" target="#b53">[54]</ref>. Our top-5 error rate is 10.87 ± 0.28%. While S 4 L [57] holds state-of-the-art on semi-supervised ImageNet with a 26.79% error rate, it leverages 2 additional training phases (pseudo-label re-training and supervised finetuning) to significantly lower the error rate from 30.27% after the first phase. FixMatch outperforms S 4 L after its first phase, and it is possible that a similar performance gain could be achieved by incorporating these techniques into FixMatch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Barely Supervised Learning</head><p>To test the limits of our proposed approach, we applied FixMatch to CIFAR-10 with only one example per class. <ref type="bibr" target="#b5">6</ref> We conduct two sets of experiments.</p><p>First, we create four datasets by randomly selecting one example per class. We train on each dataset four times and reach between 48.58% and 85.32% test accuracy with a median of 64.28%. The inter-dataset variance is much lower, however; for example, the four models trained on the first dataset all reach between 61% and 67% accuracy, and the second dataset reaches between 68% and 75%.</p><p>We hypothesize that this variability is caused by the quality of the 10 labeled examples comprising each dataset and that sampling low-quality examples might make it more difficult for the model to learn some particular class effectively. To test this, we construct eight new training datasets with examples ranging in "prototypicality" (i.e., representative of the underlying class). Specifically, we take the ordering of the CIFAR-10 training set from <ref type="bibr" target="#b4">[5]</ref> that sorts examples from those that are most representative to those that are least. This example ordering was determined after training many CIFAR-10 models with all labeled data. We thus do not envision this as a practical method for choosing examples for use in SSL, but rather to experimentally verify that examples that are more representative are better suited for low-label training. We divide this ordering evenly into eight buckets (so all of the most representative examples are in the first bucket, and all of the outliers in the last). We then create eight labeled training sets by randomly selecting one labeled example of each class from the same bucket.</p><p>Using the same hyperparameters, the model trained only on the most prototypical examples reaches a median of 78% accuracy (with a maximum of 84% accuracy); training on the middle of the distribution reaches 65% accuracy; and training on only the outliers fails to converge completely, with 10% accuracy. <ref type="figure" target="#fig_1">Figure 2</ref> shows the full labeled training dataset for the split where FixMatch achieved a median accuracy of 78%. Further analysis is presented in Appendix B.7.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Ablation Study</head><p>Since FixMatch comprises a simple combination of two existing techniques, we perform an extensive ablation study to better understand why it is able to obtain state-of-the-art results. Due to the number of experiments in our ablation study, we focus on studying with a single 250 label split from CIFAR-10 and only report results using CTAugment. Note that FixMatch with default parameters achieves 4.84% error rate on this particular split. We present complete ablation results, including optimizer (appendix B.3), learning rate decay schedule (appendix B.4), weight decay (appendix B.6), labeled to unlabeled data ratio µ (appendix B.5), in the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Sharpening and Thresholding</head><p>A "soft" version of pseudo-labeling can be designed by sharpening the predicted distribution. This formulation appears in UDA and is of general interest since other methods such as MixMatch and ReMixMatch also make use of sharpening (albeit without thresholding). Using sharpening instead of an arg max introduces a hyper-parameter: the temperature T [4, 54, 3].</p><p>We study the interactions between the temperature T and the confidence threshold τ . Note that pseudo-labeling in FixMatch is recovered as T → 0. The results are presented in <ref type="figure" target="#fig_2">fig. 3a and fig. 3b</ref>. The threshold value of 0.95 shows the lowest error rate, though increasing it to 0.97 or 0.99 did not hurt much. In contrast, accuracy drops by more than 1.5% when using a small threshold value. Note that the threshold value controls the trade-off between the quality and the quantity of pseudo-labels. As discussed in appendix B.2, the accuracy of pseudo-labels for unlabeled data increases with higher threshold values, while the amount of unlabeled data contributing to u in eq. (4) decreases. This suggests that the quality of pseudo-labels is more important than the quantity for reaching a high accuracy. Sharpening, on the other hand, did not show a significant difference in performance when a confidence threshold is used. In summary, we observe that swapping pseudo-labeling for sharpening and thresholding would introduce a new hyperparameter while achieving no better performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Augmentation Strategy</head><p>We conduct an ablation study on different strong data augmentation policies as it plays a key role in FixMatch. Specifically, we chose RandAugment <ref type="bibr" target="#b10">[11]</ref> and CTAugment <ref type="bibr" target="#b2">[3]</ref>, which have been used for state-of-the-art SSL algorithms such as UDA <ref type="bibr" target="#b53">[54]</ref> and ReMixMatch <ref type="bibr" target="#b3">[4]</ref> respectively. On CIFAR-10, CIFAR-100, and SVHN we observed highly comparable results between the two policies, whereas in STL-10 <ref type="table">(table 2)</ref>, we observe a significant gain by using CTAugment.</p><p>We measure the effect of Cutout in table 3, which is used by default after strong augmentation in both RandAugment and CTAugment. We find that both Cutout and CTAugment are required to obtain the best performance; removing either results in a significant increase in error rate.</p><p>We also study different combinations of weak and strong augmentations for pseudo-label generation and prediction (i.e., the upper and lower paths in <ref type="figure" target="#fig_0">fig. 1</ref>). When we replaced the weak augmentation for label guessing with strong augmentation, we found that the model diverged early in training. Conversely, when replacing weak augmentation with no augmentation, the model overfits the guessed unlabeled labels. Using weak augmentation in place of strong augmentation to generate the model's prediction for training peaked at 45% accuracy but was not stable and progressively collapsed to 12%, suggesting the importance of strong data augmentation. This observation is well-aligned with those from supervised learning <ref type="bibr" target="#b9">[10]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>There has been rapid recent progress in SSL. Unfortunately, much of this progress comes at the cost of increasingly complicated learning algorithms with sophisticated loss terms and numerous difficult-totune hyper-parameters. We introduce FixMatch, a simpler SSL algorithm that achieves state-of-the-art results across many datasets. We show how FixMatch can begin to bridge the gap between low-label semi-supervised learning and few-shot learning or clustering: we obtain surprisingly-high accuracy with just one label per class. Using only standard cross-entropy losses on both labeled and unlabeled data, FixMatch's training objective can be written in just a few lines of code.</p><p>Because of this simplicity, we are able to thoroughly investigate how FixMatch works. We find that certain design choices are important (and often underemphasized) -most importantly, weight decay and the choice of optimizer. The importance of these factors means that even when controlling for model architecture as is recommended in <ref type="bibr" target="#b35">[36]</ref>, the same technique can not always be directly compared across different implementations.</p><p>On the whole, we believe that the existence of such simple but performant semi-supervised machine learning algorithms will help to allow machine learning to be deployed in increasingly many practical domains where labels are expensive or difficult to obtain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Broader Impact</head><p>FixMatch helps democratize machine learning in two ways: first, its simplicity makes it available to a wider audience, and second, its accuracy with only a few labels means that it can be applied to domains where previously machine learning was not feasible. The flip side of democratization of machine learning research is that it becomes easy for both good and bad actors to apply. We hope that this ability will be used for good-for example, obtaining medical scans is often far cheaper than paying an expert doctor to label every image. However, it is possible that more advanced techniques for semi-supervised learning will allow for more advanced surveillance: for example, the efficacy of our one-shot classification might allow for more accurate person identification from a few images. Broadly speaking, any progress on semi-supervised learning will have these same consequences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Funding Disclosure</head><p>Google is the sole source of funding for this work.</p><p>[61] X. <ref type="bibr">Zhu</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Algorithm</head><p>We present the complete algorithm for FixMatch in algorithm 1.</p><p>Algorithm 1 FixMatch algorithm. <ref type="figure" target="#fig_0">∈ (1, . . . , B)</ref> , unlabeled batch U = u b : <ref type="figure" target="#fig_0">b ∈ (1, . . . , µB)</ref> , confidence threshold τ , unlabeled data ratio µ, unlabeled loss weight λu. As mentioned in section 4, we used almost identical hyperparameters of FixMatch on CIFAR-10, CIFAR-100, SVHN and STL-10. Note that we used similar network architectures for these datasets, except that more convolution filters were used for CIFAR-100 (WRN-28-8) to handle larger label space and more convolutions were used for STL-10 (WRN-37-2) to deal with larger input image size. Following the suggestion in <ref type="bibr" target="#b3">[4]</ref>, we doubled the weight decay parameter for WRN-28-8 to avoid overfitting. Here, we provide a complete list of hyperparameters in table 4. Note that we did ablation study for most of these hyperparameters in section 5 (τ in section 5.1, µ in appendix B.5, lr and β (momentum) in appendix B.3, and weight decay in appendix B.6).  <ref type="table">Table 4</ref>: Complete list of FixMatch hyperparameters for CIFAR-10, CIFAR-100, SVHN and STL-10.</p><formula xml:id="formula_6">1: Input: Labeled batch X = (x b , p b ) : b</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 Trade-off between the Quality and the Quantity of Pseudo-Labels with Confidence</head><p>To better understand the role of thresholding in FixMatch, we present in table 5 two additional measurements along with the test set accuracy: the impurity (the error rate of unlabeled data that falls above the threshold) and the mask rate (the number of examples which are masked out) which are computed as follows:</p><formula xml:id="formula_7">impurity = µB b=1 1(max(q b ) ≥ τ )1(y b =q b ) µB b=1 1(max(q b ) ≥ τ )<label>(5)</label></formula><formula xml:id="formula_8">mask rate = 1 µB µB b=1 1(max(q b ) ≥ τ )<label>(6)</label></formula><p>As shown in   <ref type="table" target="#tab_9">Table 6</ref>: Ablation study on learning rate decay schedules. Error rates are reported on a single 250-label split from CIFAR-10.</p><p>impeded by noisy pseudo-labeled examples. This behavior is known as confirmation bias <ref type="bibr" target="#b0">[1]</ref>. On the other hand, using high threshold values allows a smaller fraction of ostensibly higher-quality unlabeled examples to contribute to the unlabeled loss, effectively reducing the confirmation bias with strong data augmentation, resulting in lower error rates on the test set. Given our observation on the trade-off between the quality and the quantity of pseudo-labels, combining improved techniques for confidence calibration and uncertainty estimation <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b18">19]</ref> into FixMatch would be a promising future direction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.3 Ablation Study on Optimizer</head><p>While the study of different optimizers and their hyperparameters is seldom done in previous SSL works, we found that they can have a strong effect on performance. We present ablation results on optimizers in table 7. First, we studied the effect of momentum (β) for the SGD optimizer. We found that the performance is somewhat sensitive to β and the model did not converge when β is set too large. On the other hand, small values of β still worked fine. When β is small, increasing the learning rate improved the performance, though they are not as good as the best performance obtained with β = 0.9. Nesterov momentum resulted in a slightly lower error rate than that of standard momentum SGD, but the difference was not significant.</p><p>As studied in <ref type="bibr" target="#b52">[53,</ref><ref type="bibr" target="#b28">29]</ref>, we did not find Adam performing better than momentum SGD. While the best error rate of the model trained with Adam is only 0.53% larger than that of momentum SGD, we found that the performance was much more sensitive to the change of learning rate (e.g., increase in error rate by more than 8% when increasing the learning rate to 0.002) than momentum SGD. Additional exploration along this direction to make Adam more competitive includes the use of weight decay <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b57">58]</ref> instead of L2 weight regularization and a better exploration of hyperparameters <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.4 Ablation Study on Learning Rate Schedule</head><p>It is a popular choice in recent works <ref type="bibr" target="#b27">[28]</ref> to use a cosine learning rate decay. As shown in Adam η = 0.002 β1 = 0.9 β2 = 0.00 29.42 Adam η = 0.002 β1 = 0.9 β2 = 0.90 14.42 Adam η = 0.002 β1 = 0.9 β2 = 0.99 15.44 Adam η = 0.002 β1 = 0.9 β2 = 0.999 13.93</p><p>Adam η = 0.0008 β1 = 0.9 β2 = 0.999 7.35 Adam η = 0.0006 β1 = 0.9 β2 = 0.999 6.12 Adam η = 0.0005 β1 = 0.9 β2 = 0.999 5.95 Adam η = 0.0004 β1 = 0.9 β2 = 0.999 5.44 Adam η = 0.0003 β1 = 0.9 β2 = 0.999 5.37 Adam η = 0.0002 β1 = 0.9 β2 = 0.999 5.57 Adam η = 0.0001 β1 = 0.9 β2 = 0.999 7.90 <ref type="table">Table 7</ref>: Ablation study on optimizers. Error rates are reported on a single 250-label split from CIFAR-10. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.5 Ratio of Labeled to Unlabeled Data in Minibatch</head><p>In <ref type="figure" target="#fig_5">fig. 5a</ref> we plot the error rates of FixMatch with different ratios of unlabeled data (µ) in each minibatch. We observe a significant decrease in error rates by using a large amount of unlabeled data, which is consistent with the finding in UDA <ref type="bibr" target="#b53">[54]</ref>. In addition, scaling the learning rate η linearly with the batch size (a technique for large-batch supervised training <ref type="bibr" target="#b15">[16]</ref>) was effective for FixMatch, especially when µ is small.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.6 Weight Decay</head><p>While the value 0.0005 appeared as a good default choice for WRN-28-2 across datasets, we find that the weight decay could have a huge impact on performance when tuned incorrectly for low label regimes: choosing a value that is just one order of magnitude larger or smaller than optimal can cost ten percentage points or more, as shown in <ref type="figure" target="#fig_5">fig. 5b</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.7 Labeled Data for Barely Supervised Learning</head><p>In addition to <ref type="figure" target="#fig_1">fig. 2</ref>, we visualize the full labeled training images obtained by ordering mechanism <ref type="bibr" target="#b4">[5]</ref> used for barely supervised learning in <ref type="figure" target="#fig_6">fig. 6</ref>. Each row contains 10 images from 10 different classes 2 4 6 8 10 12 <ref type="bibr">14 16</ref> Ratio of unlabled data  of CIFAR-10 and is used as the complete labeled training dataset for one run of FixMatch. The first row contains the most prototypical images of each class, while the bottom row contains the least prototypical images. We train two models for each dataset and compute the mean accuracy between the two and plot this in <ref type="figure" target="#fig_7">fig. 7</ref>. Observe that we obtain over 80% accuracy when training on the best examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.8 Comparison to Supervised Baselines</head><p>In <ref type="table">table 9 and table 10</ref>, we present the performance of models trained only with the labeled data using strong data augmentations to highlight the effectiveness of using unlabeled data in FixMatch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Implementation Details for Section 4.3</head><p>For our ImageNet experiments we use standard ResNet50 pre-activation model trained in a distributed way on a TPU device with 32 cores. <ref type="bibr" target="#b6">7</ref> We report results over five random folds of labeled data. We use the following set of hyperparameters for our ImageNet model:   <ref type="table">Table 9</ref>: Error rates for CIFAR-10, CIFAR-100 and SVHN on 5 different folds. Models with (RA) uses RandAugment <ref type="bibr" target="#b10">[11]</ref> and the ones with (CTA) uses CTAugment <ref type="bibr" target="#b2">[3]</ref> for strong-augmentation. All models are tested using the same codebase.   <ref type="table">Table 10</ref>: Error rates for STL-10 on 1000-label splits. All models are tested using the same codebase.</p><formula xml:id="formula_9">•</formula><p>• Training time. We train our model for 300 epochs of unlabeled examples 8 .</p><p>• Learning rate schedule. We utilize linear learning rate warmup for the first 5 epochs until it reaches an initial value of 0.4. Then we the decay learning rate at epochs 60, 120, 160, and 200 epoch by multiplying it by 0.1. • Optimizer. We use Nesterov Momentum optimizer with momentum 0.9.</p><p>• Exponential moving average (EMA). We utilize EMA technique with decay 0.999. • FixMatch loss. We use unlabeled loss weight λ u = 10 and confidence threshold τ = 0.7</p><p>in FixMatch loss. • Weight decay. Our weight decay coefficient is 0.0003. Similarly to other datasets we perform weight decay by adding L2 penalty of all weights to model loss. • Augmentation of unlabeled images. For strong augmentation we use RandAugment with random magnitude <ref type="bibr" target="#b10">[11]</ref>. For weak augmentation we use a random horizontal flip. • ImageNet preprocessing. We randomly crop and rescale to 224×224 size all labeled and unlabeled training images prior to performing augmentation. This is considered a standard ImageNet preprocessing technique.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Extensions of FixMatch D.1 Augmentation Anchoring and Distribution Alignment</head><p>Augmentation Anchoring, where M strong augmentations are applied to each unlabeled example for consistency regularization, and Distribution Alignment, which encourages the model predictions to have same class distribution as the labeled set, are two important techniques to the success of ReMixMatch <ref type="bibr" target="#b2">[3]</ref>. Thanks to its simplicity and clean formulation, incorporating these techniques into FixMatch becomes straightforward. Firstly, we incorporate Augmentation Anchoring into FixMatch as follows:</p><formula xml:id="formula_10">u = 1 µB µB b=1 1(max(q b ) ≥ τ ) × 1 M M i=1 H(q b , p m (y | A(u b )))<label>(7)</label></formula><p>Note that the strong augmentation A(u b ) is a stochastic process and it produces M different stronglyaugmented examples of an unlabeled example u b . Using M = 4 and µ = 4, FixMatch (CTA) with Augmentation Anchoring reduces the error rate averaged over 5 different folds on CIFAR-10 with 250 labeled examples from 5.07% to 4.81%.</p><p>As already reported in section 4.1, combining Distribution Alignment into FixMatch improves the SSL performance significantly, especially when the number of labeled training data is very limited. Specifically, we align the predictive distribution of a weakly-augmented example q b = p m (y|α(u b )) using the dataset's marginal class distribution estimated using the labeled data and the running average of the model's prediction estimated by the unlabeled data as follows:</p><formula xml:id="formula_11">q b = Normalize q b × p(y|X ) p m (y|U)<label>(8)</label></formula><p>where Normalize(x) i = xi / j xj . Now, eq. (4) can be modified as follows accordingly: </p><formula xml:id="formula_12">u = 1 µB µB b=1 1(max(q b ) ≥ τ ) H(q b , p m (y | A(u b )))<label>(9)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2 Datatype-Agnostic Data Augmentation</head><p>Strong augmentation plays a key role in FixMatch. Applying FixMatch to different problem domains than vision thus requires one to come up with a novel augmentation strategy. While there are domainspecific data augmentation strategies for different application domains, such as back-translation <ref type="bibr" target="#b47">[48]</ref> for text classification or SpecAugment <ref type="bibr" target="#b37">[38]</ref> for speech recognition, it is desirable if FixMatch can also be combined with datatype-agnostic data augmentation methods.</p><p>In this section, we consider two such augmentation schemes, namely MixUp <ref type="bibr" target="#b58">[59]</ref> and Virtual Adversarial Training (VAT) <ref type="bibr" target="#b32">[33]</ref>, as a replacement of RandAugment or CTAugment in FixMatch for image classification. For MixUp, instead of mixing both input and label, we mixed random pairs of inputs only using α = 9 to be more consistent with the data augmentation in FixMatch. For VAT, we used τ = 0.5. We evaluated on CIFAR-10 with 250 labeled data protocol and report the mean and standard deviation over 5 different folds in table 11. We make comparisons of our FixMatch variants to MixMatch <ref type="bibr" target="#b3">[4]</ref> and VAT <ref type="bibr" target="#b32">[33]</ref>. The FixMatch variant with (input) MixUp obtained comparable error rates to MixMatch, while the variant with VAT achieved significantly lower error rates than VAT. This suggests the generality of the FixMatch's framework against different data augmentation strategies.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E List of Data Transformations</head><p>Given a collection of transformations (e.g., color inversion, translation, contrast adjustment, etc.), RandAugment randomly selects transformations for each sample in a mini-batch. As originally proposed, RandAugment uses a single fixed global magnitude that controls the severity of all distortions <ref type="bibr" target="#b10">[11]</ref>. The magnitude is a hyperparameter that must be optimized on a validation set e.g., using grid search. We found that sampling a random magnitude from a pre-defined range at each training step (instead of using a fixed global value) works better for semi-supervised training, similar to what is used in UDA <ref type="bibr" target="#b53">[54]</ref>.</p><p>Instead of setting the transformation magnitudes randomly, CTAugment <ref type="bibr" target="#b2">[3]</ref> learns them online over the course of training. To do so, a wide range of transformation magnitude values is divided into bins (as in AutoAugment <ref type="bibr" target="#b9">[10]</ref>) and a weight (initially set to 1) is assigned to each bin. All examples are augmented with a pipeline consisting of two transformations which are sampled uniformly at random. For a given transformation, a magnitude bin is sampled randomly with a probability according to the (normalized) bin weights. To update the weights of the magnitude bins, a labeled example is augmented with two transformations whose magnitude bins are sampled uniformly at random. The magnitude bin weights are then updated according to how close the model's prediction is to the true label. Further details on CTAugment can be found in <ref type="bibr" target="#b2">[3]</ref>.</p><p>We used the same sets of image transformations used in RandAugment <ref type="bibr" target="#b10">[11]</ref> and CTAugment <ref type="bibr" target="#b2">[3]</ref>. For completeness, we listed all transformation operations for these augmentation strategies in <ref type="table" target="#tab_4">table 12  and table 13</ref>.    <ref type="table" target="#tab_4">Table 13</ref>: List of transformations used in CTAugment <ref type="bibr" target="#b2">[3]</ref>. The ranges for the listed parameters are discretized into 17 equal bins, except for the M parameter of the Rescale transformation, which takes one of the following six options: anti-alias, bicubic, bilinear, box, hamming, and nearest.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Diagram of FixMatch. A weakly-augmented image (top)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>FixMatch reaches 78% CIFAR-10 accuracy using only above 10 labeled images.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Plots of ablation studies on FixMatch. (a) Varying the confidence threshold for pseudo-labels. (b) Measuring the effect of "sharpening" the predicted label distribution while varying the confidence threshold (τ ). Error rate of FixMatch with default hyperparameters is in red dotted line.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>p b , α(x b )) {Cross-entropy loss for labeled data} 3: for b = 1 to µB do 4: q b = pm(y | α(u b ); θ) {Compute prediction after applying weak data augmentation of u b } 5: end for 6: u = 1 µB µB b=1 1{max(q b ) &gt; τ } H(arg max(q b ), pm(y | A(u b )) {Cross-entropy loss with pseudo-label and confidence for unlabeled data} 7: return s + λu u B Comprehensive Experimental Results B.1 Hyperparameters</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Plots of ablation studies on optimizers. (a) Varying β. (b) Varying η with β = 0.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Plots of ablation studies on FixMatch. (a) Varying the ratio of unlabeled data (µ) with different learning rate (η) scaling strategies. (b) Varying the loss coefficient for weight decay. Error rate of FixMatch with default hyperparameters is in red dotted line.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Labeled training data for the 1-label-per-class experiment. Each row corresponds to the complete labeled training set for one run of our algorithm, sorted from the most prototypical dataset (first row) to least prototypical dataset (last row).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 :</head><label>7</label><figDesc>Accuracy of the model when trained on the 1-label-per-class datasets from Figure 6, ordered from most prototypical (top row) to least (bottom row).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>contrast by setting the darkest (lightest) pixel to black (white). Brightness Adjusts the brightness of the image. B = 0 returns a black image, B = 1 returns the original image. B [0.05, 0.95] Color Adjusts the color balance of the image like in a TV. C = 0 returns a black &amp; white image, C = 1 returns the original image. C [0.05, 0.95] Contrast Controls the contrast of the image. A C = 0 returns a gray image, C = 1 returns the original image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>54±11.50 11.05±0.86 6.42±0.10 67.61±1.32 39.94±0.37 28.31±0.33 42.55±14.53 3.98±0.23 3.50±0.28 10.41±0.61 UDA 29.05±5.93 8.82±1.08 4.88±0.18 59.28±0.88 33.13±0.22 24.50±0.25 52.63±20.51 5.69±2.76 2.46±0.24 7.66±0.56 ReMixMatch 19.10±9.64 5.44±0.05 4.72±0.13 44.28±2.06 27.43±0.31 23.03±0.56 3.34±0.20 2.92±0.48 2.65±0.08 5.23±0.45</figDesc><table><row><cell></cell><cell></cell><cell>CIFAR-10</cell><cell></cell><cell></cell><cell>CIFAR-100</cell><cell></cell><cell></cell><cell>SVHN</cell><cell></cell><cell>STL-10</cell></row><row><cell>Method</cell><cell cols="6">40 labels 250 labels 4000 labels 400 labels 2500 labels 10000 labels</cell><cell cols="4">40 labels 250 labels 1000 labels 1000 labels</cell></row><row><cell>Π-Model</cell><cell cols="2">-54.26±3.97</cell><cell>14.01±0.38</cell><cell>-</cell><cell>57.25±0.48</cell><cell>37.88±0.11</cell><cell cols="2">-18.96±1.92</cell><cell>7.54±0.36</cell><cell>26.23±0.82</cell></row><row><cell>Pseudo-Labeling</cell><cell cols="2">-49.78±0.43</cell><cell>16.09±0.28</cell><cell>-</cell><cell>57.38±0.46</cell><cell>36.21±0.19</cell><cell cols="2">-20.21±1.09</cell><cell>9.94±0.61</cell><cell>27.99±0.83</cell></row><row><cell>Mean Teacher</cell><cell cols="2">-32.32±2.30</cell><cell>9.19±0.19</cell><cell>-</cell><cell>53.91±0.57</cell><cell>35.83±0.24</cell><cell>-</cell><cell>3.57±0.11</cell><cell>3.42±0.07</cell><cell>21.43±2.39</cell></row><row><cell cols="2">MixMatch 47.FixMatch (RA) 13.81±3.37</cell><cell>5.07±0.65</cell><cell cols="2">4.26±0.05 48.85±1.75</cell><cell>28.29±0.11</cell><cell>22.60±0.12</cell><cell>3.96±2.17</cell><cell>2.48±0.38</cell><cell>2.28±0.11</cell><cell>7.98±1.50</cell></row><row><cell>FixMatch (CTA)</cell><cell>11.39±3.35</cell><cell>5.07±0.33</cell><cell cols="2">4.31±0.15 49.95±3.01</cell><cell>28.64±0.24</cell><cell>23.18±0.11</cell><cell>7.65±7.65</cell><cell>2.64±0.64</cell><cell>2.36±0.19</cell><cell>5.17±0.63</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3</head><label>3</label><figDesc></figDesc><table><row><cell>: Ablation</cell></row><row><cell>study with different</cell></row><row><cell>strong data augmenta-</cell></row><row><cell>tion of FixMatch. Er-</cell></row><row><cell>ror rates are reported</cell></row><row><cell>on a single 250-label</cell></row><row><cell>split from CIFAR-10.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>and A. B. Goldberg. Introduction to semi-supervised learning. Synthesis lectures on artificial intelligence and machine learning, 3(1), 2009. 4 [62] Y. Zou, Z. Yu, B. Vijaya Kumar, and J. Wang. Unsupervised domain adaptation for semantic segmentation via class-balanced self-training. In Proceedings of the European Conference on Computer Vision (ECCV), pages 289-305, 2018. 5</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>table 5</head><label>5</label><figDesc></figDesc><table><row><cell>τ</cell><cell cols="3">mask rate impurity error rate</cell></row><row><cell>0.25</cell><cell>100.00</cell><cell>6.39</cell><cell>6.40</cell></row><row><cell>0.5</cell><cell>100.00</cell><cell>5.40</cell><cell>5.87</cell></row><row><cell>0.75</cell><cell>99.82</cell><cell>5.35</cell><cell>5.09</cell></row><row><cell>0.85</cell><cell>99.31</cell><cell>4.32</cell><cell>5.12</cell></row><row><cell>0.9</cell><cell>99.21</cell><cell>3.85</cell><cell>4.90</cell></row><row><cell>0.95</cell><cell>98.13</cell><cell>3.47</cell><cell>4.84</cell></row><row><cell>0.97</cell><cell>96.35</cell><cell>2.30</cell><cell>5.00</cell></row><row><cell>0.99</cell><cell>92.14</cell><cell>2.06</cell><cell>5.05</cell></row></table><note>, when using small threshold values, most unlabeled examples' confidence is above the threshold. Consequently, they all contribute to the unlabeled loss in eq. (4). Unfortunately, pseudo-labels of these examples are not always correct and the learning process is significantly</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 5 :</head><label>5</label><figDesc>The mask rate and impurity at the end of the training along with the test set error rate of FixMatch using different threshold values on a single 250-label split from CIFAR-10.</figDesc><table><row><cell>Decay Schedule</cell><cell>Error</cell></row><row><cell>Cosine (FixMatch)</cell><cell>4.84</cell></row><row><cell cols="2">Linear Decay (end 0.01) 4.95</cell></row><row><cell cols="2">Linear Decay (end 0.02) 5.55</cell></row><row><cell>No Decay</cell><cell>5.70</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>table 6</head><label>6</label><figDesc></figDesc><table><row><cell>Optimizer</cell><cell></cell><cell>Hyperparameters</cell><cell></cell><cell>Error</cell></row><row><cell>SGD</cell><cell>η = 0.03</cell><cell>β = 0.90</cell><cell>Nesterov</cell><cell>4.84</cell></row><row><cell>SGD</cell><cell>η = 0.03</cell><cell cols="2">β = 0.999 Nesterov</cell><cell>84.33</cell></row><row><cell>SGD</cell><cell>η = 0.03</cell><cell>β = 0.99</cell><cell>Nesterov</cell><cell>21.97</cell></row><row><cell>SGD</cell><cell>η = 0.03</cell><cell>β = 0.50</cell><cell>Nesterov</cell><cell>5.79</cell></row><row><cell>SGD</cell><cell>η = 0.03</cell><cell>β = 0.25</cell><cell>Nesterov</cell><cell>6.42</cell></row><row><cell>SGD</cell><cell>η = 0.03</cell><cell>β = 0</cell><cell>Nesterov</cell><cell>6.76</cell></row><row><cell>SGD</cell><cell>η = 0.05</cell><cell>β = 0</cell><cell>Nesterov</cell><cell>6.06</cell></row><row><cell>SGD</cell><cell>η = 0.10</cell><cell>β = 0</cell><cell>Nesterov</cell><cell>5.27</cell></row><row><cell>SGD</cell><cell>η = 0.20</cell><cell>β = 0</cell><cell>Nesterov</cell><cell>5.19</cell></row><row><cell>SGD</cell><cell>η = 0.50</cell><cell>β = 0</cell><cell>Nesterov</cell><cell>5.74</cell></row><row><cell>SGD</cell><cell>η = 0.03</cell><cell>β = 0.90</cell><cell></cell><cell>4.86</cell></row></table><note>, a linear learning rate decay performed nearly as well. Note that, as for the cosine learning rate decay, picking a proper decaying rate is important. Finally, using no decay results in worse accuracy (a 0.86% degradation).</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head></head><label></label><figDesc>Batch size. On each step our batch contains 1024 labeled examples and 5120 unlabeled examples.</figDesc><table><row><cell>Dataset</cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell></row><row><cell cols="6">CIFAR-10 5.46 6.17 9.37 10.85 13.32</cell></row><row><cell>SVHN</cell><cell cols="3">2.40 2.47 6.24</cell><cell>6.32</cell><cell>6.38</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 8 :</head><label>8</label><figDesc>Error rates of FixMatch (CTA) on a single 40-label split of CIFAR-10 and SVHN with different random seeds. Runs are ordered by accuracy. 01±0.76 39.12±0.77 12.74±0.29 79.47±0.18 52.88±0.51 32.55±0.21 52.68±2.29 22.48±0.55 10.89±0.12 Supervised (CTA) 64.53±0.83 41.92±1.17 13.64±0.12 79.79±0.59 54.23±0.48 35.30±0.19 43.05±2.34 15.</figDesc><table><row><cell></cell><cell></cell><cell>CIFAR-10</cell><cell></cell><cell></cell><cell>CIFAR-100</cell><cell></cell><cell></cell><cell>SVHN</cell></row><row><cell>Method</cell><cell>40 labels</cell><cell>250 labels</cell><cell>4000 labels</cell><cell>400 labels</cell><cell cols="2">2500 labels 10000 labels</cell><cell>40 labels</cell><cell>250 labels</cell><cell>1000 labels</cell></row><row><cell>Supervised (RA)</cell><cell cols="8">64.06±1.02</cell><cell>7.69±0.27</cell></row><row><cell>FixMatch (RA)</cell><cell>13.81±3.37</cell><cell>5.07±0.65</cell><cell cols="3">4.26±0.05 48.85±1.75 28.29±0.11</cell><cell>22.60±0.12</cell><cell>3.96±2.17</cell><cell>2.48±0.38</cell><cell>2.28±0.11</cell></row><row><cell>FixMatch (CTA)</cell><cell>11.39±3.35</cell><cell>5.07±0.33</cell><cell cols="3">4.31±0.15 49.95±3.01 28.64±0.24</cell><cell>23.18±0.11</cell><cell>7.65±7.65</cell><cell>2.64±0.64</cell><cell>2.36±0.19</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head></head><label></label><figDesc>FixMatch (CTA) with distribution alignment reduces the error rate averaged over 5 different folds on CIFAR-10 with 40 labeled examples from 11.38% to 9.47%. On CIFAR-100 with 400 labeled examples, it reduces the error rate from 49.95% to 40.14%, which is also lower than 44.28% of ReMixMatch. In addition to Section 4.3, we conduct SSL experiments on ImageNet using 1% of its data as labeled examples. We find that in this regime the role of distribution alignment becomes more critical -FixMatch model does not train well without distribution alignment. On the other hand, after a proper tuning of hyperparameters (weight of unlabeled loss λ u = 3 and confidence threshold τ = 0.9), FixMatch (RA) model with distribution alignment achieves 67.1% top-1 and 47.7% top-5 error rate (this correspond to 32.9% top-1 and 52.3% top-5 accuracy and similar to<ref type="bibr" target="#b56">[57]</ref> results).</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 11 :</head><label>11</label><figDesc>Error rates for CIFAR-10 with 250 labeled examples on 5 different folds. All models are tested using the same codebase.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head></head><label></label><figDesc>Sharpness Adjusts the sharpness of the image, where S = 0 returns a blurred image, and S = 1 returns the original image.</figDesc><table><row><cell></cell><cell></cell><cell>C</cell><cell>[0.05, 0.95]</cell></row><row><cell>Equalize</cell><cell>Equalizes the image histogram.</cell><cell></cell><cell></cell></row><row><cell>Identity</cell><cell>Returns the original image.</cell><cell></cell><cell></cell></row><row><cell>Posterize</cell><cell>Reduces each pixel to B bits.</cell><cell>B</cell><cell>[4, 8]</cell></row><row><cell>Rotate</cell><cell>Rotates the image by θ degrees.</cell><cell>θ</cell><cell>[-30, 30]</cell></row><row><cell></cell><cell></cell><cell>S</cell><cell>[0.05, 0.95]</cell></row><row><cell>Shear_x</cell><cell>Shears the image along the horizontal axis with rate R.</cell><cell>R</cell><cell>[-0.3, 0.3]</cell></row><row><cell>Shear_y</cell><cell>Shears the image along the vertical axis with rate R.</cell><cell>R</cell><cell>[-0.3, 0.3]</cell></row><row><cell>Solarize</cell><cell>Inverts all pixels above a threshold value of T .</cell><cell>T</cell><cell>[0, 1]</cell></row><row><cell>Translate_x</cell><cell>Translates the image horizontally by (λ×image width) pix-</cell><cell>λ</cell><cell>[-0.3, 0.3]</cell></row><row><cell></cell><cell>els.</cell><cell></cell><cell></cell></row><row><cell>Translate_y</cell><cell cols="2">Translates the image vertically by (λ×image height) pixels. λ</cell><cell>[-0.3, 0.3]</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table 12 :</head><label>12</label><figDesc>List of transformations used in RandAugment<ref type="bibr" target="#b10">[11]</ref>.Brightness Adjusts the brightness of the image. B = 0 returns a black image, B = 1 returns the original image. Color Adjusts the color balance of the image like in a TV. C = 0 returns a black &amp; white image, C = 1 returns the original image. Contrast Controls the contrast of the image. A C = 0 returns a gray image, C = 1 returns the original image. crop that is of side-length (L×image width), and rescales to the original image size using method M . Sharpness Adjusts the sharpness of the image, where S = 0 returns a blurred image, and S = 1 returns the original image.</figDesc><table><row><cell cols="2">Transformation Description</cell><cell cols="2">Parameter Range</cell></row><row><cell>Autocontrast</cell><cell>Maximizes the image contrast by setting the darkest (lightest)</cell><cell>λ</cell><cell>[0, 1]</cell></row><row><cell></cell><cell>pixel to black (white), and then blends with the original</cell><cell></cell><cell></cell></row><row><cell></cell><cell>image with blending ratio λ.</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>B</cell><cell>[0, 1]</cell></row><row><cell></cell><cell></cell><cell>C</cell><cell>[0, 1]</cell></row><row><cell></cell><cell></cell><cell>C</cell><cell>[0, 1]</cell></row><row><cell>Cutout</cell><cell>Sets a random square patch of side-length (L×image width)</cell><cell>L</cell><cell>[0, 0.5]</cell></row><row><cell></cell><cell>pixels to gray.</cell><cell></cell><cell></cell></row><row><cell>Equalize</cell><cell>Equalizes the image histogram, and then blends with the</cell><cell>λ</cell><cell>[0, 1]</cell></row><row><cell></cell><cell>original image with blending ratio λ.</cell><cell></cell><cell></cell></row><row><cell>Invert</cell><cell>Inverts the pixels of the image, and then blends with the</cell><cell>λ</cell><cell>[0, 1]</cell></row><row><cell></cell><cell>original image with blending ratio λ.</cell><cell></cell><cell></cell></row><row><cell>Identity</cell><cell>Returns the original image.</cell><cell></cell><cell></cell></row><row><cell>Posterize</cell><cell>Reduces each pixel to B bits.</cell><cell>B</cell><cell>[1, 8]</cell></row><row><cell>Rescale</cell><cell cols="2">Takes a center L</cell><cell>[0.5, 1.0]</cell></row><row><cell></cell><cell></cell><cell>M</cell><cell>see caption</cell></row><row><cell>Rotate</cell><cell>Rotates the image by θ degrees.</cell><cell>θ</cell><cell>[-45, 45]</cell></row><row><cell></cell><cell></cell><cell>S</cell><cell>[0, 1]</cell></row><row><cell>Shear_x</cell><cell>Shears the image along the horizontal axis with rate R.</cell><cell>R</cell><cell>[-0.3, 0.3]</cell></row><row><cell>Shear_y</cell><cell>Shears the image along the vertical axis with rate R.</cell><cell>R</cell><cell>[-0.3, 0.3]</cell></row><row><cell>Smooth</cell><cell>Adjusts the smoothness of the image, where S = 0 returns</cell><cell>S</cell><cell>[0, 1]</cell></row><row><cell></cell><cell>a maximally smooth image, and S = 1 returns the original</cell><cell></cell><cell></cell></row><row><cell></cell><cell>image.</cell><cell></cell><cell></cell></row><row><cell>Solarize</cell><cell>Inverts all pixels above a threshold value of T .</cell><cell>T</cell><cell>[0, 1]</cell></row><row><cell>Translate_x</cell><cell>Translates the image horizontally by (λ×image width) pix-</cell><cell>λ</cell><cell>[-0.3, 0.3]</cell></row><row><cell></cell><cell>els.</cell><cell></cell><cell></cell></row><row><cell>Translate_y</cell><cell cols="2">Translates the image vertically by (λ×image height) pixels. λ</cell><cell>[-0.3, 0.3]</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">In practice, we include all labeled data as part of unlabeled data without their labels when constructing U.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">https://www.pythonware.com/products/pil/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">β refers to a momentum in SGD optimizer. The definition of other hyperparameters are found in section 2.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">We clarify that both FixMatch and ReMixMatch<ref type="bibr" target="#b2">[3]</ref>, which has reported an incorrect number of network parameters (23.8M), are tested with the same network architecture containing 5.9M parameters.<ref type="bibr" target="#b5">6</ref> The experimental protocol of barely supervised learning (BSL) shares similarities to those of few-shot learning (FSL)<ref type="bibr" target="#b36">[37]</ref> as they both assume a limited availability (e.g., 1 or 5) of labeled examples from categories of interest. However, two protocols have a critical difference, where for FSL one is provided with extra labeled training examples from regular classes, whereas for BSL one is given additional unlabeled training examples.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7">https://github.com/tensorflow/tpu/tree/master/models/official/resnet</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8">Note that one epoch of unlabelled examples contains all 1.2 million examples from Imagenet training set and it correspond to 10 passes through labelled set for 10% Imagenet task.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgment</head><p>We thank Qizhe Xie, Avital Oliver, Quoc V. Le, and Sercan Arik for their feedback on this paper.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Pseudo-labeling and confirmation bias in deep semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Arazo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ortego</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Albert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">E</forename><surname>O&amp;apos;connor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mcguinness</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.02983</idno>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">15</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Learning with pseudo-ensembles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Alsharif</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Precup</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Remixmatch: Semi-supervised learning with distribution matching and augmentation anchoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eighth International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page">21</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Mixmatch: A holistic approach to semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">19</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ú</forename><surname>Erlingsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Papernot</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.13427</idno>
		<title level="m">Distribution density, tails, and outliers in machine learning: Metrics and applications</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">16</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Semi-Supervised Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Chapelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Scholkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zien</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Closing the generalization gap of adaptive gradient methods in training deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Gu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.06763</idno>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page">15</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Shallue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Nado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Maddison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Dahl</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.05446</idno>
		<title level="m">On empirical comparisons of optimizers for deep learning</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">15</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">An analysis of single-layer networks in unsupervised feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics</title>
		<meeting>the Fourteenth International Conference on Artificial Intelligence and Statistics</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Autoaugment: Learning augmentation strategies from data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019-06" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">20</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Randaugment</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.13719</idno>
		<title level="m">Practical automated data augmentation with a reduced search space</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page">20</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Good semi-supervised learning that requires a bad GAN</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">ImageNet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Devries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">W</forename><surname>Taylor</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.04552</idno>
		<title level="m">Improved regularization of convolutional neural networks with cutout</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Self-ensembling for visual domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>French</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mackiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fisher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Sixth International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Noordhuis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wesolowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kyrola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tulloch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.02677</idno>
		<title level="m">Accurate, large minibatch sgd: Training imagenet in 1 hour</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page">16</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Semi-supervised learning by entropy minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Grandvalet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">A baseline for detecting misclassified and out-of-distribution examples in neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gimpel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.02136</idno>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page">15</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Augmix: A simple data processing method to improve robustness and uncertainty</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gilmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lakshminarayanan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.02781</idno>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">15</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hestness</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ardalani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Diamos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kianinejad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M A</forename><surname>Patwary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1712.00409</idno>
		<title level="m">Deep learning scaling is predictable, empirically</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Exploring the limits of language modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.02410</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Third International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
		<respStmt>
			<orgName>University of Toronto</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Temporal ensembling for semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Aila</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fifth International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML Workshop on Challenges in Representation Learning</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A simple unified framework for detecting out-of-distribution samples and adversarial attacks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page">15</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Enhancing the reliability of out-of-distribution image detection in neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Srikant</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.02690</idno>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page">15</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">SGDR: Stochastic gradient descent with warm restarts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fifth International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">15</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Decoupled weight decay regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Sixth International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page">15</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Exploring the limits of weakly supervised pretraining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mahajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ramanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Paluri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bharambe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Effective self-training for parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mcclosky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Charniak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the main conference on human language technology conference of the North American Chapter of the Association of Computational Linguistics</title>
		<meeting>the main conference on human language technology conference of the North American Chapter of the Association of Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Iterative reclassification procedure for constructing an asymptotically optimal rule of allocation in discriminant analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">J</forename><surname>Mclachlan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="issue">350</biblScope>
			<biblScope unit="page" from="365" to="369" />
			<date type="published" when="1975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Virtual adversarial training: a regularization method for supervised and semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maeda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ishii</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Koyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A method of solving a convex programming problem with convergence rate o(kˆ2)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">E</forename><surname>Nesterov</surname></persName>
		</author>
		<idno>1983. 4</idno>
	</analytic>
	<monogr>
		<title level="j">Doklady Akademii Nauk</title>
		<imprint>
			<biblScope unit="volume">269</biblScope>
			<biblScope unit="issue">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Reading digits in natural images with unsupervised feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Netzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bissacco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS Workshop on Deep Learning and Unsupervised Feature Learning</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Realistic evaluation of deep semi-supervised learning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Odena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Tadam: Task dependent adaptive metric for improved few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Oreshkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">R</forename><surname>López</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lacoste</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="721" to="731" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Specaugment: A simple data augmentation method for automatic speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-C</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.08779</idno>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">19</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Semi-supervised learning by coaching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=rJe04p4YDB.5" />
	</analytic>
	<monogr>
		<title level="m">Submitted to the 8th International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Some methods of speeding up the convergence of iteration methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">T</forename><surname>Polyak</surname></persName>
		</author>
		<idno>1964. 4</idno>
	</analytic>
	<monogr>
		<title level="j">USSR Computational Mathematics and Mathematical Physics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Language models are unsupervised multitask learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.10683</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Semi-supervised learning with ladder networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rasmus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Berglund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Honkala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Valpola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Raiko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Semi-supervised self-training of object detection models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hebert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Schneiderman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh IEEE Workshops on Application of Computer Vision</title>
		<meeting>the Seventh IEEE Workshops on Application of Computer Vision</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Mutual exclusivity loss for semi-supervised deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sajjadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Javanmardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tasdizen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Image Processing</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Regularization with stochastic transformations and perturbations for deep semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sajjadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Javanmardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tasdizen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Probability of error of some adaptive pattern-recognition machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Scudder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="1965" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Improving neural machine translation models with monolingual data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Birch</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06709</idno>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page">19</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Dropout: a simple way to prevent neural networks from overfitting. The journal of machine learning research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">15</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">On the importance of initialization and momentum in deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Martens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tarvainen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Valpola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Interpolation consistency training for semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lamb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kannala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.03825</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">The marginal value of adaptive gradient methods in machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Roelofs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Srebro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Recht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page">15</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Unsupervised data augmentation for consistency training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-T</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.12848</idno>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page">20</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Self-training with noisy student improves imagenet classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-T</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="10687" to="10698" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Wide residual networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zagoruyko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the British Machine Vision Conference (BMVC)</title>
		<meeting>the British Machine Vision Conference (BMVC)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">S4l: Self-supervised semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Beyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2019-10" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">19</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Grosse</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.12281</idno>
		<title level="m">Three mechanisms of weight decay regularization</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page">15</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.09412</idno>
		<title level="m">MixUp: Beyond empirical risk minimization</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">19</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Semi-supervised learning literature survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<idno>TR 1530</idno>
	</analytic>
	<monogr>
		<title level="j">Computer Sciences</title>
		<imprint>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2008" />
		</imprint>
		<respStmt>
			<orgName>University of Wisconsin -Madison</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
