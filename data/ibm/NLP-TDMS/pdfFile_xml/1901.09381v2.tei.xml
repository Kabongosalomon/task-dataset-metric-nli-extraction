<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Dual Co-Matching Network for Multi-choice Reading Comprehension</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2019-08-20">20 Aug 2019</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuailiang</forename><surname>Zhang</surname></persName>
							<email>zhangzs@sjtu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Key Laboratory of Shanghai Education Commission for Intelligent Interaction and Cognitive Engineering</orgName>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">MoE Key Lab of Artificial Intelligence</orgName>
								<orgName type="institution" key="instit1">AI Institute</orgName>
								<orgName type="institution" key="instit2">Shanghai Jiao Tong University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Zhao</surname></persName>
							<email>zhaohai@cs.sjtu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Key Laboratory of Shanghai Education Commission for Intelligent Interaction and Cognitive Engineering</orgName>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">MoE Key Lab of Artificial Intelligence</orgName>
								<orgName type="institution" key="instit1">AI Institute</orgName>
								<orgName type="institution" key="instit2">Shanghai Jiao Tong University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuwei</forename><surname>Wu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Key Laboratory of Shanghai Education Commission for Intelligent Interaction and Cognitive Engineering</orgName>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">MoE Key Lab of Artificial Intelligence</orgName>
								<orgName type="institution" key="instit1">AI Institute</orgName>
								<orgName type="institution" key="instit2">Shanghai Jiao Tong University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuosheng</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Zhou</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Key Laboratory of Shanghai Education Commission for Intelligent Interaction and Cognitive Engineering</orgName>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">MoE Key Lab of Artificial Intelligence</orgName>
								<orgName type="institution" key="instit1">AI Institute</orgName>
								<orgName type="institution" key="instit2">Shanghai Jiao Tong University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">CloudWalk Technology</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Zhou</surname></persName>
							<email>zhouxiang@cloudwalk.cn</email>
							<affiliation key="aff3">
								<orgName type="institution">CloudWalk Technology</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Dual Co-Matching Network for Multi-choice Reading Comprehension</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2019-08-20">20 Aug 2019</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T21:12+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Multi-choice reading comprehension is a challenging task to select an answer from a set of candidates when given passage and question. This work proposes dual co-matching network which models the relationship among passage, question and answer bidirectionally. The experimental results on RACE, ROCStories and COIN Shared Task 1 show that our model obtains state-of-the-art results and even the single model outperforms the human performance on RACE dataset.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Machine reading comprehension (MRC) is a fundamental and long-standing goal of natural language understanding which aims to teach the machine to answer a question automatically according to a given passage <ref type="bibr" target="#b2">(Hermann et al., 2015;</ref><ref type="bibr" target="#b7">Rajpurkar et al., 2016;</ref><ref type="bibr" target="#b5">Nguyen et al., 2016)</ref>.</p><p>In this paper, we focus on multi-choice MRC task such as ROCStories (?), COIN Shared Task 1 (?) and RACE <ref type="bibr" target="#b4">(Lai et al., 2017)</ref> which requests to choose the right answer from a set of candidate ones according to given passage and question. Different from MRC datasets such as SQuAD <ref type="bibr" target="#b7">(Rajpurkar et al., 2016)</ref> and NewsQA <ref type="bibr" target="#b13">(Trischler et al., 2017)</ref> where the expected answer is usually in the form of a short span from the given passage, answer in multi-choice MRC is non-extractive and may not appear in the original passage, which allows rich types of questions such as commonsense reasoning and passage summarization, as illustrated by two exam- * Corresponding author. This paper was partially supported by National Key Research and Development Program of China (No. 2017YFB0304100), Key Projects of National Natural Science Foundation of China (U1836222 and 61733011), Key Project of National Society Science Foundation of China (No. 15-ZDA041), The Art and Science Interdisciplinary Funds of Shanghai Jiao Tong University (No. 14JCRZ04) ple questions in <ref type="table" target="#tab_0">Table 1</ref>. In Q1, the model suffers the distraction from the similarity between different routes in answer A and many routes in the passage and probably selects answer A by mistake. Thus multi-choice MRC is more challenging and requires a more in-depth understanding of the given passage and question <ref type="bibr" target="#b4">(Lai et al., 2017;</ref><ref type="bibr" target="#b3">Khashabi et al., 2018)</ref>.</p><p>To well handle the multi-choice MRC problem, a common solution should carefully model the relationship among the triplet of three sequences, passage (P), question (Q) and answer (A) with a matching module to determine the answer. Previous matching strategies <ref type="bibr" target="#b11">Tang et al., 2019;</ref><ref type="bibr" target="#b0">Chen et al., 2018;</ref><ref type="bibr" target="#b8">Ran et al., 2019)</ref> are usually unidirectional which only calculate question-aware passage representation and ignore passage-aware question representation when modeling the relationship between passage and question. These unidirectional matching methods obviously cannot take the best of information between two sequences. Besides, previous methods usually fail to cover all the relationship among the triplet. For example,  ignore the relationship between Q and A. Unlike other MRC tasks such as SQuAD that focus on modeling the relationship between P and Q, the three sequences P, Q and A are equally important and any pairwise relationship among the triplet in multichoice MRC should be sufficiently under consideration.</p><p>In this work, we propose dual co-matching network (DMN) which incorporates all the pairwise relationships among the {P, Q, A} triplet bidirectionally. In detail, we model the passage-question, passage-answer and question-answer pairwise relationship simultaneously and bidirectionally for each triplet. What's more, we exploit the gated mechanism to fuse the representations from two directions which is proved to be more effective Passage: Runners in a relay race pass a stick in one direction. However, merchants passed silk, gold, fruit, and glass along the Silk Road in more than one direction. They earned their living by traveling the famous Silk Road. ... The Silk Road was made up of many routes, not one smooth path. They passed through what are now 18 countries. The routes crossed mountains and deserts and had many dangers of hot sun, deep snow and even battles... Question: The Silk Road became less important because .</p><p>A. it was made up of different routes B. silk trading became less popular C. sea travel provided easier routes D. people needed fewer foreign goods than a simple concatenation strategy. Besides, our model leverages the latest pretrained resources BERT <ref type="bibr" target="#b1">(Devlin et al., 2018)</ref> by utilizing its output as our contextual embedding, which plays a role of encoder. Our model is evaluated on the multi-choice MRC benchmark challenge, RACE and ROCStories, which reports new state-of-the-art by 2.6% and 1.2% better than previous best results on RACE and ROCStories, respectively. Especially, our single model performs even better than human turkers on the RACE full dataset, which is the first milestone achievement ever since the RACE challenge has been set up.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Model</head><p>For the task of multi-choice reading comprehension, the machine is given a passage (P), a question (Q), and a set of candidate answers (A) and the goal is to select the correct answer from the candidates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Encoder</head><p>This layer encodes each token in passage and question into a fixed-length vector following BERT <ref type="bibr" target="#b1">(Devlin et al., 2018)</ref>. The passage, the question, and the candidate answer are encoded as follows:</p><formula xml:id="formula_0">H p = Bert(P), H q = Bert(Q), H a = Bert(A)</formula><p>where Bert represents the BERT model which returns the last layer output in BERT. H p ∈ R |P |×l , H q ∈ R |Q|×l , and H a ∈ R |A|×l are sequence representation of the passage, question and answer, respectively. |P |, |Q|, |A| are the sequence length of the passage, the question and the candidate answer, respectively. l is the dimension of the hidden state.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Matching</head><p>To fully model the relationship in a {P, Q, A} triplet, We make use of the bidirectional matching strategy and gated mechanism to get all pairwise matching representation among the triplet, including passage-answer, passage-question and question-answer representation. This part shows how to build matching representation for passageanswer sequence pair and it is the same for the other two pairs.</p><p>Bidirectional matching representation between the passage H p and answer H a can be calculated as follows:</p><formula xml:id="formula_1">G qa = Sof tM ax(H p W H aT ), E p = G qa H a , E a = G qaT H p , S p = ReLU (E p W 1 ), S a = ReLU (E a W 2 ),<label>(1)</label></formula><p>where W , W 1 , W 2 ∈ R l×l are three learnable parameters. G qa ∈ R |P |×|A| is the attention weight matrix between the passage and the answer. E p ∈ R |P |×l , E a ∈ R |A|×l represent answer-aware passage representation and passage-aware answer representation, respectively. <ref type="bibr" target="#b11">Tang et al., 2019)</ref> use elementwise subtraction and multiplication to fuse E p and H p (i.e., [E p ⊖ H p ; E p ⊗H p ]) which is has shown not good enough as such processing breaks the symmetry of equation. Symmetric representations from both directions show essentially helpful for our bidirectional architecture.</p><p>Gated mechanism is used to fuse S p and S a because gate is more powerful to regulate the information flow <ref type="bibr" target="#b9">(Srivastava et al., 2015)</ref>. The final results also prove that the gated mechanism works better than the concatenation strategy.  <ref type="figure">Figure 1</ref>: The framework of our model. P-Passage, Q-Question, A-Answer. ⊕ indicates the gated mechanism in Eq. 2.</p><p>as follows:</p><formula xml:id="formula_2">M p = M axP ooling(S p ), M a = M axP ooling(S a ), g = σ(M p W 3 + M a W 4 + b), M p a = g * M p + (1 − g) * M a ,<label>(2)</label></formula><p>where W 3 , W 4 ∈ R l×l and b ∈ R l are three learnable parameters. After a row-wise max pooling operation, we get the aggregation representation M p ∈ R l and M a ∈ R l . g ∈ R l is the reset gate. M p a ∈ R l is the final bidirectional matching representation of the passage-answer sequence pair.</p><p>Passage-question and question-answer sequence matching representation M p q , M q a ∈ R l can be calculated in the same procedure using Eq.</p><p>(1) and (2). The framework of our model is shown in <ref type="figure">Figure 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Objective function</head><p>In matching layer, we build the matching representation M p q , M p a , M q a for three sequence pairs. Finally, we concatenate them as the final representation C ∈ R 3l for each passage-question-answer triplet. We can build C i for each {P, Q, A i } triplet. So the objective function can be computed as follows:</p><formula xml:id="formula_3">C = [M p q ; M p a ; M q a ], L(A i |P, Q) = −log exp(V T C i ) 4 j=1 exp(V T C j ) ,<label>(3)</label></formula><p>where V ∈ R l is a learnable parameter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiment</head><p>We evaluate our models on Large-scale ReAding Comprehension Dataset From Examinations (RACE) dataset <ref type="bibr" target="#b4">(Lai et al., 2017)</ref>, which consists of two subsets: RACE-M and RACE-H corresponding to middle school and high school difficulty level. RACE contains 27,933 passages and 97,687 questions in total, which is recognized as one of the largest and most difficult datasets in multi-choice reading comprehension. Besides, we also evaluate our model on the ROCStories (Spring 2016) dataset which collects 50k fivesentence commonsense stories. One correct ending sentence needs to be selected from two options when given four sentences in ROCStories dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Experiment Setup</head><p>We use BERT as our encoder. The max sequence length is set to 512. A dropout rate of 0.1 is applied to every BERT layer. We optimize the model using BertAdam <ref type="bibr" target="#b1">(Devlin et al., 2018)</ref> optimizer with a learning rate 5e-6. In the matching layer, the dropout rate is set to 0.3. We train for 10 epochs with batch size 4 when BERT large is used as encoder.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Comparison with Baselines</head><p>Performance comparison against all baseline models is shown in <ref type="table" target="#tab_3">Table 2</ref>. Turkers is the performance of Amazon Turkers on a random subset of the RACE test set. Ceiling is the percentage of unambiguous questions in the test set. From the table, we can see that the large-scale pre-trained language models OpenAI GPT <ref type="bibr" target="#b6">(Radford, 2018)</ref> and BERT <ref type="bibr" target="#b1">(Devlin et al., 2018)</ref> surpass all previous models only by fine-tuning. RSM <ref type="bibr" target="#b10">(Sun et al., 2018)</ref> and OCN <ref type="bibr" target="#b8">(Ran et al., 2019)</ref> further improve the results based on GPT and BERT respectively. RSM <ref type="bibr">(Sun et al.,</ref> Model RACE-M RACE-H RACE DFN <ref type="bibr" target="#b15">(Xu et al., 2017)</ref> 51.5 45.7 47.4 HAF <ref type="bibr" target="#b16">(Zhu et al., 2018)</ref> 45.0 46.4 46.0 MRU <ref type="bibr" target="#b12">(Tay et al., 2018)</ref> 57.7 47.4 50.4 HCM    2018) introduces three domain-independent reading strategies and OCN <ref type="bibr" target="#b8">(Ran et al., 2019)</ref> compares candidate answers at word-level to better identify their correlations. In this work, we propose the bidirectional matching strategy and gated mechanism to model the pairwise sequence relationship among the passage-question-answer triplet.</p><p>Comparison results show that our model is powerful and even the sing model outperforms all baselines and achieves new state-of-the-art accuracy. Our ensemble model further improves the performance for 1.5%. More specifically, our single model is the first to outperform Amazon Turkers on RACE full dataset as shown in <ref type="table" target="#tab_3">Table 2</ref>, which is one milestone achievement ever since the RACE challenge has been set up.</p><p>Comparison with previous models on ROCStories is shown in <ref type="table" target="#tab_5">Table 3</ref>. Our model also outperforms all the baselines and achieves state-of-theart accuracy by improving for 1.2% compared to BERT large .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Ablation Study</head><p>In this work, we mainly focus on show two core model improvements, (1) the bidirectional matching strategy and (2) the gated mechanism. Ablation experiments on RACE are shown in <ref type="table" target="#tab_3">Table 2</ref>. We observe 1.5% performance decrease by only using unidirectional matching. In detail, we only build answer-aware passage representation with-Approach Accuracy ROCStories</p><p>OFT <ref type="bibr" target="#b6">(Radford, 2018)</ref> 86.5 RSM <ref type="bibr" target="#b10">(Sun et al., 2018)</ref> 88 <ref type="formula">.</ref>  out considering passage-aware answer representation when modeling the passage-answer sequence pair relationship (i.e., only use S p as the matching representation without S a in Eq. <ref type="formula" target="#formula_1">(1)</ref>). We also observe 0.5% decrease by replacing the gated mechanism with directly concatenating two sequences (i.e., concatenate M p and M a as M p a in Eq. <ref type="formula" target="#formula_2">(2)</ref>).</p><p>The ablation experiments on ROCStories dataset further prove above descriptions. What's more, the relationship between question-answer sequence pair is not under sufficient consideration in previous work such as . So we remove the questionanswer matching from the model (i.e., only concatenate M p q and M p a as C in Eq. <ref type="formula" target="#formula_3">(3)</ref>) which leads to 0.4% decrease, indicating that this relationship should get more attention.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions</head><p>In this work, we propose Dual Co-Matching Network (DMN) to model the bidirectional sequence relationship among the passage, question, and the candidate answer. By incorporating the well pretrained BERT in an innovative way, our model achieves new state-of-the-art in ROCStories and RACE benchmarks, outperforming the previous state-of-the-art model by 2.6% in RACE and 1.2% in ROCStories. In addition, for the first time the single model outperforms human turkers on the RACE full dataset.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table /><note>An example passage with related question and options from RACE dataset. The ground-truth answer and the evidence sentences in the passage are in bold.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Experiment results on RACE test set. † means it is statistically significant to the models ablating either the bidirectional matching or gated mechanism. * indicates ensemble model. DMN base uses BERT base as encoder and DMN large uses BERT large as encoder.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>Performance comparison on the ROCStories (Spring 2016) and COIN test set. : this result is evaluated on the COIN dev set because we missed the deadline of the evaluation period on COIN test set.</figDesc><table /><note>*</note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Convolutional Spatial Attention Model for Reading Comprehension with Multiple-Choice Questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhipeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wentao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shijin</forename><surname>Wang</surname></persName>
		</author>
		<idno>abs/1811.08610</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno>abs/1810.04805</idno>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Teaching Machines to Read and Comprehend</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Moritz Hermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomás</forename><surname>Kociský</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lasse</forename><surname>Espeholt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Kay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mustafa</forename><surname>Suleyman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<idno>abs/1506.03340</idno>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Looking Beyond the Surface: A Challenge Set for Reading Comprehension over Multiple Sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Khashabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Snigdha</forename><surname>Chaturvedi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shyam</forename><surname>Upadhyay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="252" to="262" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">RACE: Large-scale ReAding Comprehension Dataset From Examinations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guokun</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qizhe</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="785" to="794" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">MS MARCO: A Human Generated MAchine Reading COmprehension Dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tri</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mir</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xia</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurabh</forename><surname>Tiwary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rangan</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<idno>abs/1611.09268</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Improving Language Understanding by Generative Pre-Training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">SQuAD: 100,000+ Questions for Machine Comprehension of Text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantin</forename><surname>Lopyrev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2383" to="2392" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Option comparison network for multiple-choice reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiu</forename><surname>Ran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiwei</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
		<idno>abs/1903.03033</idno>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Rupesh Kumar Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Greff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schmidhuber</surname></persName>
		</author>
		<idno>abs/1505.00387</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Improving Machine Reading Comprehension with General Reading Strategies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dian</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
		<idno>abs/1810.13441</idno>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Multi-Matching Network for Multiple Choice Reading Comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaran</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hankz Hankui</forename><surname>Zhuo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Second AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Multi-range Reasoning for Machine Comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anh</forename><surname>Luu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siu Cheung</forename><surname>Tuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hui</surname></persName>
		</author>
		<idno>abs/1803.09074</idno>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">NewsQA: A Machine Comprehension Dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Trischler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingdi</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaheer</forename><surname>Suleman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Representation Learning for NLP</title>
		<meeting>the 2nd Workshop on Representation Learning for NLP</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="191" to="200" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A Co-Matching Model for Multi-choice Reading Comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuohang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiyu</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="746" to="751" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Towards Humanlevel Machine Reading Comprehension: Reasoning and Inference with Multiple Strategies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingjing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yelong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Liu</surname></persName>
		</author>
		<idno>abs/1711.04964</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Hierarchical Attention Flow for Multiplechoice Reading Comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haichao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Second AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
