<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Deep Ordinal Regression with Label Diversity</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Axel</forename><surname>Berg</surname></persName>
							<email>axel.berg@arm.com</email>
							<affiliation key="aff0">
								<orgName type="department">Arm Research</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Center for Mathematical Sciences</orgName>
								<orgName type="institution">Lund University</orgName>
								<address>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Magnus</forename><surname>Oskarsson</surname></persName>
							<email>magnus.oskarsson@math.lth.se</email>
							<affiliation key="aff1">
								<orgName type="department">Center for Mathematical Sciences</orgName>
								<orgName type="institution">Lund University</orgName>
								<address>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>O&amp;apos;connor</surname></persName>
							<email>mark.oconnor@arm.com</email>
							<affiliation key="aff0">
								<orgName type="department">Arm Research</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Deep Ordinal Regression with Label Diversity</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T18:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Regression via classification (RvC) is a common method used for regression problems in deep learning, where the target variable belongs to a set of continuous values. By discretizing the target into a set of non-overlapping classes, it has been shown that training a classifier can improve neural network accuracy compared to using a standard regression approach. However, it is not clear how the set of discrete classes should be chosen and how it affects the overall solution. In this work, we propose that using several discrete data representations simultaneously can improve neural network learning compared to a single representation. Our approach is end-to-end differentiable and can be added as a simple extension to conventional learning methods, such as deep neural networks. We test our method on three challenging tasks and show that our method reduces the prediction error compared to a baseline RvC approach while maintaining a similar model complexity.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Choosing the right objective function is a crucial part of successfully training an accurate and generalized regression model, for example a deep neural network. Among the standard objective functions are the mean squared error (MSE, or L 2 loss), the mean absolute error (MAE, or L 1 -loss) and hybrid variants such as the Huber loss. Much attention has also been given to deriving problem-specific objective functions that incorporate certain aspects of the target variable, such as modularity and norm constraints for geometric regression. It is also possible to treat a continuous dependent variable as belonging to a finite number of discrete classes, although this necessarily comes at the expense of introducing a discretization error. Such approaches are known as regression via classification (RvC) and they are frequently used in tasks where a regression loss would at first seem more natural <ref type="bibr" target="#b0">[1]</ref>- <ref type="bibr" target="#b5">[6]</ref>.</p><p>Ordinal regression techniques can be applied to classification problems where the dependent variable exhibits a relative ordering. Techniques for ordinal regression can be applied to RvC problems in order to preserve the ordinal structure of the labels, and recent work has shown that this method can be used to improve the accuracy in several regression problems, such as age estimation <ref type="bibr" target="#b6">[7]</ref>  <ref type="bibr" target="#b7">[8]</ref>, image ranking and depth estimation <ref type="bibr" target="#b8">[9]</ref>.</p><p>One problem with the RvC approach is the ambiguity in how the discrete classes should be created from the distribution of the dependent variable. The standard approach is to create bins of equal width covering the target output range. For skewed distributions one can also apply the method of equal frequency, where the bins are created from the cumulative distribution function of the target, such that each bin contains the same number of training examples. Regardless of the method, the number of bins must be selected and optimized for the given task, which raises the question of what the optimal number of bins is for a given problem. If the bin-width is too small, this can result in few training examples in each class, but if it is too large, the discretization error can become a limiting factor.</p><p>The ambiguity in how to bin a continuous variable leads to a diverse range of possibilities in how to represent the target values -a fact that can be exploited. From previous research it is well known that a diverse ensemble of individual predictors can be combined in order to reduce the overall prediction error. Such approaches often involves training multiple regressors where the diversity is ensured by either data augmentation or model selection. This leads to increased overhead at both training and inference time <ref type="bibr" target="#b9">[10]</ref>. However, with the use of label diversity and deep neural networks, one can create a multi-output predictor that enforces diversity without extra computational complexity.</p><p>Contribution: In this paper, we show that a collection of different binning variants of the target values can be used to improve prediction accuracy without increasing the computational complexity compared to a standard classifier. We do so by training a deep multi-output convolutional neural network (CNN) to classify training examples in multiple overlapping bins simultaneously. By doing so, we can effectively take into account the ordinal structure of the regression problem, while also making use of the diversity of the different possible representations of the target variable. We demonstrate our method on a number of different tasks and show competitive results compared to current state-of-the-art methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) Ordinal Regression:</head><p>Ordinal regression, or ranking learning, is used for problems where the target variable exhibits a relative ordering on an arbitrary scale, e.g. categories such as "bad", "good" and "very good". When performing vanilla RvC, the ordinal information contained in the target values is lost, but this can be resolved by using ordinal regression techniques. A common variant is to use extended binary classification, where a single multi-class classification problem is reduced to a set of several binary classification problems <ref type="bibr" target="#b10">[11]</ref>. With the advance of deep learning in recent years, ordinal regression has been used successfully for several tasks, including monocular depth estimation <ref type="bibr" target="#b11">[12]</ref>, age estimation <ref type="bibr" target="#b6">[7]</ref>, head pose estimation <ref type="bibr" target="#b12">[13]</ref>, medical diagnosis <ref type="bibr" target="#b13">[14]</ref> and historical image dating <ref type="bibr" target="#b14">[15]</ref>.</p><p>2) Ensemble Learning: The fact that a set of individual regressors or classifiers can be combined into an ensemble in order to reduce the overall prediction accuracy of a model is frequently exploited in machine learning research <ref type="bibr" target="#b9">[10]</ref>. A key notion in ensemble learning is the bias-variance-covariance decomposition, which says that in order for an ensemble to reduce the prediction error, there has to be some variance in the predictions of the ensemble members. Therefore, the aim should be to create ensembles that consist of accurate but diverse predictors.</p><p>Diversity can be created in several ways, most commonly through methods like bagging <ref type="bibr" target="#b15">[16]</ref> and boosting <ref type="bibr" target="#b16">[17]</ref>, which rely on different forms of data diversity. However, using such method comes at the cost of extra model complexity and training time. Recently, Zhang et al. <ref type="bibr" target="#b17">[18]</ref> proposed a framework for training an ensemble of networks using negative correlation learning, where the high level features are learned via parameter sharing. This reduces the overhead, while keeping the benefits of a diverse ensemble. In general, a multioutput neural network can be used to form an ensemble, which we exploit in our proposed method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Relevant Applications</head><p>1) Age Estimation: Deep learning methods have been used successfully for age estimation, where the task consists of predicting the age of a person given a single RGB image of the person's face. Depending on the implementation, a person's age can be considered either as a continuous variable on the positive real numbers, or as a class belonging to a set of discrete positive integers. Rothe et al. <ref type="bibr" target="#b5">[6]</ref> first highlighted the use of end-to-end training of CNNs for age estimation from a single image. The authors noted that classification yielded better results than direct regression and since then, several new methods using ordinal regression techniques have been published.</p><p>Agustsson et al. <ref type="bibr" target="#b18">[19]</ref> performed end-to-end piecewise linear regression by assigning each regressor to an anchor point. Others have observed that it is easier for a human to distinguish differences in age between two persons, rather than their absolute age and used this as a design principle for ordinal regression <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b19">[20]</ref>. Alternative methods have focused on various soft encodings of the age over classes, where the elements of the probability vector are proportional to the distance from the true class <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b21">[22]</ref>. In this way both the ordinal and metric information can be effectively encoded in the labels. Furthermore, it has also been shown that forcing the output of the classifier to be rank consistent over ages can improve the overall accuracy <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b22">[23]</ref>.</p><p>2) Head Pose Estimation: Head pose estimation is the task of predicting the pose of a human head with three degrees of freedom, given an image and possibly depth information <ref type="bibr" target="#b23">[24]</ref>. There are several ways to represent the pose, including three rotation angles (pitch, yaw and roll) with respect to a set of principal axes, a 3 × 3 rotation matrix or a single quaternion. During the past years, several CNN-based head pose estimators trained on specific loss functions have been proposed. Chang et al. <ref type="bibr" target="#b24">[25]</ref> combined direct head pose regression with facial landmark detection and used it for facial alignment. Ruiz et al. <ref type="bibr" target="#b25">[26]</ref> used a multi-loss CNN and showed that using a balanced hybrid variant of regression and classification yielded improvements over previous methods. Ordinal methods have also been used, such as in <ref type="bibr" target="#b12">[13]</ref>, where a combined ranking and MSE regression loss is used in conjunction with a quaternion representation of the head pose. The results indicated that training the CNN to regress the three angles while simultaneously solving several binary ranking problems improved the prediction accuracy compared to a standard regression or classification baseline.</p><p>3) Historical Image Dating: Palermo et al. <ref type="bibr" target="#b26">[27]</ref> first introduced the task of automatically estimating the historical time in which a color photograph was taken using machine learning techniques. The authors noted that there are several features of the color imaging process that are typical to the era in which the images were taken, such as hue, saturation and color histogram. They then used a support vector machine to classify the images into different decades and showed that this method vastly outperformed untrained humans in terms of classification accuracy. Ginosar et al. <ref type="bibr" target="#b27">[28]</ref> used American high school yearbooks to train a deep neural network for the same task, but in this case the extracted features were also dependent on the image content, e.g. facial attributes and hairstyle. Recently, ordinal regression techniques have also been applied successfully to the task of image dating <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b28">[29]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. PROPOSED METHOD A. Label Diversity by Overlapping Bins</head><p>Let x n ∈ R p denote the n th input (independent variable) and let t n ∈ R be the corresponding target value (dependent value) for n = 1, ..., N . Now let C = {c k } K k=1 be a set of of non-overlapping intervals on the real line R, as shown in <ref type="figure" target="#fig_1">Figure 2a</ref>, such that ∪ K k=1 c k covers the samples t n for all n. The standard RvC approach would now be to map each target value t n to a unique class c k and train a classifier to predict the posterior probability over classes p(c k |x n ). In order to create label diversity, we instead introduce M new sets of class intervals</p><formula xml:id="formula_0">c k D 1 D 2 D 3 D 1 D 2 D 3 C d 1 l a) Standard RvC b) Equal width c) Random bins d 1 l . . . . . .</formula><formula xml:id="formula_1">D m = {d m l } Lm l=1 for m = 1, ..., M , such that ∪ Lm l=1 d m l = ∪ K k=1 c k , ∀m.</formula><p>By doing so, we have created several new discretizations that all cover the support of the target value, but in different ways. Here we do not provide an answer to exactly how these discretizations ought to be chosen, since this in itself is an optimization problem where the solution most likely depends on the problem domain, but instead we focus on the two following possibilities, where we assume that L m = L, ∀m, such that each discretization contains equally many classes:</p><p>1) Assuming that we do not want to increase the complexity of the training algorithm compared to the standard RvC approach, we fix the total number of classes such that M L = K. Then we create M discretizations, each containing L equally wide bins, such that the overlap between d m l and d m+1 l is fixed. An illustration of this approach is shown in <ref type="figure" target="#fig_1">Figure 2b</ref>. We refer to this method as "equal width". 2) In order to maximize diversity between different discretizations, for each m = 1, ..., M , we randomly sample L &lt; K classes (with replacement) from C and let these classes be the centers of the new bins in D m , such that target values that do not belong to any of the chosen classes are assigned to the nearest neighbor in the sample. An illustration of this approach is shown in <ref type="figure" target="#fig_1">Figure 2c</ref> We refer to this method as "randomized bins". If the target is multi-dimensional, the same methods can be applied by creating classes for each dimension individually.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Backpropagation</head><p>The proposed methods can be used together with a neural network by replacing the last fully connected layer and activa- tion with M fully connected layers of size L in parallel, where each layer has its own softmax activation. The network is trained by minimizing the sum of the negative cross-entropies between the individual classifier and the targets over each mini-batch of size N b . The loss function then becomes</p><formula xml:id="formula_2">E = − N b n=1 M m=1 Lm l=1 q n (d m l ) log p(d m l |x n ),<label>(1)</label></formula><p>where q n (d m l ) is a one-hot encoding of the binned target value, such that the only non-zero element is the one where the bin overlaps the true target:</p><formula xml:id="formula_3">q n (d m l ) = 1, t n ∈ d m l 0, otherwise<label>(2)</label></formula><p>The predictions p(d m l |x n ) are computed using the M individual softmax heads of size L, and the loss is then backpropagated through the network by differentiating with respect to the predictions as shown in <ref type="figure" target="#fig_2">Figure 3</ref>.</p><p>In order to see how the loss function incorporates the ordinal relationship between the targets, we can again consider <ref type="figure" target="#fig_1">Figure  2</ref>. In order to make a correct prediction, each softmax head must output a high probability for the correct class in each discretization. If the output probabilities are correct for only a subset of the M different discretizations (which implies that the prediction is slightly off) then this will be penalized by an increased loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Inference</head><p>At inference time, the output posterior should be evaluated and converted to a point estimate of the target value by a hard decision. For standard RvC methods, this is typically done by either taking the expected value of the output distribution over classes or using the maximum-a-posteriori estimator. Therefore, we propose two similar methods to perform inference.</p><p>For problems where the target value t n belongs to the real line, we do this by computing the expected value over each estimated posterior distribution aŝ</p><formula xml:id="formula_4">y m,n = Lm l=1 w m l p(d m l |x n ),<label>(3)</label></formula><p>where w m l denotes the mean value of the bin d m l . This gives us M different estimates of the target, which are then combined using a weighted average. Here we only consider uniform weighting of the individual estimates, i.e.</p><formula xml:id="formula_5">y n = 1 M M m=1ŷ m,n .<label>(4)</label></formula><p>This is a form of ensemble average, and we note that we can decompose an individual error made by the ensemble using the ambiguity decomposition <ref type="bibr" target="#b29">[30]</ref> as</p><formula xml:id="formula_6">(ȳ n −t n ) 2 = 1 M M m=1 (ŷ n,m −t n ) 2 − 1 M M m=1 (ŷ n,m −ȳ n ) 2 ,<label>(5)</label></formula><p>which shows that the ensemble error is less than the average error of the individual estimates if there is enough variance within the ensemble. In this case, the non-zero variance is guaranteed by the different weights associated with each expected value in equation <ref type="formula" target="#formula_4">(3)</ref>.</p><p>On the other hand, if the target belongs to a set of ordinal classes where we cannot define a useful distance metric, it is more suitable to use the MAP estimate. We do this by marginalizing over d m l in order to estimate the average posterior over the original classes c k as</p><formula xml:id="formula_7">p(c k |x n ) = 1 M M m=1 Lm l=1 p(c k |d m l , x n )p(d m l |x n ),<label>(6)</label></formula><p>where we assume that the conditional probability p(c k |d m l , x n ) is independent of the input x n , i.e.</p><formula xml:id="formula_8">p(c k |d m l , x n ) = ||d m l ∩ c k || ||d m l || .<label>(7)</label></formula><p>Then we compute the MAP estimate as</p><formula xml:id="formula_9">k * = arg max k p(c k |x n ).<label>(8)</label></formula><p>This shows that our method can be used both for true regression problems where we can measure distances between target values and for classification problems where an ordering of targets exists, but without a well-defined distance. In section V we show experiments for tasks of both the first and second kind.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. AN ILLUSTRATIVE EXAMPLE</head><p>In order to demonstrate the ensemble-like effect of our method, we train a shallow CNN on the task of predicting the rotation angle of digits from the MNIST dataset of handwritten digits <ref type="bibr" target="#b30">[31]</ref>. The dataset consists of 5,000 training images and 5,000 test images, where a digit is rotated by an integer drawn uniformly in the interval t n ∈ [−45 • , 45 • ]. We implemented label diversity using the randomized bins method for all combinations of M ∈ <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b31">32</ref>, 64] and L ∈ <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr">64]</ref>. We then trained a five-layer CNN, with M softmax heads, each containing L output units, to predict the one-hot encoded labels of the rotation angles. At inference time, we used equation (4) for prediction and evaluated the MAE on the test set. For comparison, we also trained a  <ref type="figure">Fig. 4</ref>: The MAE on the rotated MNIST datasets using the randomized bins method for different combinations of L and M regression baseline by using the same shallow CNN with the MSE loss, but where the softmax heads were replaced by a single output unit with a linear activation. The training process was repeated for 10 random initializations of the network and the MAE was averaged over the 10 different trials.</p><p>The results of the experiment is presented in <ref type="figure">Figure 4</ref>. Here we clearly see the ensemble-like effect of our method, where the error decreases as the number of softmax heads M is increased. This is expected from the error decomposition in equation <ref type="bibr" target="#b4">(5)</ref>. Additionally, we note that increasing the number of output units L, which leads to a decreased discretization error caused by the binning of the target, does not necessarily imply a decrease in prediction error. In this experiment, L = 16 yielded the smallest MAE for all values of M . This agrees with previous findings, namely that too few bins leads to a large discretization error, but too many can lead to poor convergence <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b11">[12]</ref>. In general, the optimal number of bins depends on the specific task and finding it therefore requires an extensive parameter search.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. EXPERIMENTS</head><p>We compare our method with direct regression and classification baselines, as well as current state of the art methods on three challenging datasets. In order to make fair comparisons of the methods, we use the same baseline architecture for all experiments. More specifically, we use a pre-trained ResNet50 <ref type="bibr" target="#b31">[32]</ref> and replace the final fully connected layer with one fully connected layer of size 2048, a ReLU activation, and then a method-specific layer. For the direct regression approach (referred to as "Direct"), we use a fully connected layer of size 1 with a linear activation and train it by minimizing the MSE. For the RvC approach, we use one fully connected layer of size K with a single softmax activation and train it using the cross-entropy loss function. For our own method we use M fully connected layers of size L, with an individual <ref type="figure">Fig. 5</ref>: A subset of the images in UTKFace dataset <ref type="bibr" target="#b33">[34]</ref> with ground truth (GT) labels and predictions using the equal width method.</p><p>softmax activation function on each layer, and train it by minimizing the sum of the individual cross-entropies for each discretization as in equation <ref type="formula" target="#formula_2">(1)</ref>.</p><p>For all datasets, we train the network for 30 epochs using the ADAM optimizer <ref type="bibr" target="#b32">[33]</ref> with a mini-batch size of 32, a learning rate of 0.0005 that is decreased by a factor of 0.1 every 10th epoch, and an L 2 -regularization factor of 0.001 on the weights. For data augmentation, we use random horizontal flipping of the images and apply a uniformly distributed random translation and scaling between <ref type="bibr">[-20, 20]</ref> pixels and [0.7, 1.4] respectively. All results are averaged over 10 trials with different random initializations of the last fully connected layers. The experiments were implemented in Matlab and the network training was done using an NVIDIA Titan V graphics card. The source code for our experiments is available at https://github.com/axeber01/dold.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Age Estimation</head><p>For age estimation, we test our method on the UTKFace dataset <ref type="bibr" target="#b33">[34]</ref>, which provides a large collection of images with human subjects labeled with ground truth ages. More specifically, we use the same train-test split of the data as in <ref type="bibr" target="#b22">[23]</ref> and <ref type="bibr" target="#b34">[35]</ref>, where the ages are in the set of integers t n ∈ <ref type="bibr" target="#b20">[21,</ref><ref type="bibr">60]</ref>. The subset contains 13,144 training images and 3,287 test images. Furthermore, the images have been cropped such that only the faces of the subjects are visible, as is shown in the examples in <ref type="figure">Figure 5</ref>.</p><p>For the RvC baseline, we simply use one class per age group in years, such that C = {21, 22, ..., 60}. We compare the baseline with two implementations of the proposed method: equal-width overlapping bins and randomized bins. For the equal width approach we let L = 8 and M = 5, such that LM = 40, which means that the network complexity similar to the complexity of the RvC baseline. In practice this means that the first output head will classify images into age categories of D 1 ={21-25, 26-30, ..., 56-60}, while the second output head will have D 2 ={21, 22-26, 27-31, ..., 57-60} and so on.</p><p>For the randomized bins approach, we let L = 10 and M = 30 and draw a new sample of randomized bins for each run. This approach leads to a increased number of output heads compared to the RvC baseline, but the increase in model complexity is still small in relation to the size of the CNN backbone.</p><p>The results are shown and compared to current state-ofthe art methods in <ref type="table">Table 1</ref>, where we have evaluated the mean average error (MAE) of the different methods on the test set. The results are averaged over the trials with different random seeds and presented with the corresponding standard deviation. Of the two baselines, the direct method performs best. Since this is perhaps the most natural design choice, it should not come as a surprise, although other papers have reported contrary results on age estimation tasks <ref type="bibr" target="#b5">[6]</ref>. Both the equal width and randomized bins approach improve over the RvC baseline significantly, and they yield a small improvement over the direct method, which show that for this task, our proposed methods are more effective than the baseline methods. Furthermore, we reduce the average error compared to current state of the art by 2%. We hypothesize that this error reduction is due to the diverse representation of the target values, which also incorporates the ordinal relationship between the age categories.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Head Pose Estimation</head><p>The BIWI dataset <ref type="bibr" target="#b35">[36]</ref> consists of 24 video sequences of 20 subjects recorded in a controlled environment and each frame is labeled with the corresponding head pose of the subject. We use the train-test split defined as protocol 2 in <ref type="bibr" target="#b36">[37]</ref>, where 16 videos are used for training and 8 for testing. In total, the training set consists of 10,063 images and the test set of 5,065 images. The pose is represented using the yaw, pitch and roll angles of the head, where each angle is approximately distributed in the range t n ∈ [−75 • , 75 • ].</p><p>Following <ref type="bibr" target="#b34">[35]</ref>, we use the same approach as for head pose estimation, but with small modifications needed to get a three dimensional output from the network. For the direct regression approach, we simply replace the last fully connected layer of size 1 by three fully connected layers of the same size. For the RvC, we use three chains of fully connected layers at the end, one for each angle, with a corresponding softmax head. We discretize each angle using 1 degree per bin, such that C = {−75, −74, ..., 75}.</p><p>For the equal width approach, we let M = 3 and L = 50, such that LM = 150. Again, this gives a similar network complexity as the RvC baseline. Hence each softmax head has 3 degrees per bin, i.e. D 1 ={(-75) -(-73), ..., 72 -75}, D 2 ={-75, (-74) -(-71), ..., 73 -75 } and similarly for D 3 . For the randomized bins approach, we let L = 20 and M = 30 and make a new sample of randomized bins for each run.</p><p>The results for the BIWI dataset are shown in <ref type="table" target="#tab_0">Table II</ref>, where we have evaluated the MAE for the three different angles for each method. On average, direct regression performs best, while the randomized bins method is best at predicting the yaw angle. However, both equal width and randomized bins outperform the standard RvC approach. Additionally, our  <ref type="figure">Fig. 6</ref>: A subset of the images in BIWI dataset <ref type="bibr" target="#b35">[36]</ref> with ground truth (GT) labels and predictions using the equal width method.</p><p>direct method reduces the current state of the art average error by 16 %, which shows that a carefully tuned regression baseline can outperform more sophisticated methods on this problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Historical Image Dating</head><p>In order to test our method on a small dataset with a small number of ordinal classes, we ran experiments on the Historical Color Images (HCI) dataset <ref type="bibr" target="#b26">[27]</ref>. The dataset consists of 1,375 color images from five decades, spanning from the 1930s to the 1970s. For evaluation, we use Monte Carlo random sampling with an 80/20 train-test split for each decade, drawn randomly at each iteration.</p><p>For this dataset, the target value can then be considered as belonging to one of five ordinal classes C = {c 1 , c 2 , c 3 , c 4 , c 5 }, where each class corresponds to one of the five decades. Likewise, the number of possibilities for creating our new sets of bins is limited, so the methods of overlapping and randomized bins are not suitable. We instead create 5 new sets {D m } 5 m=1 as shown in <ref type="figure" target="#fig_4">Figure 7</ref> and refer to this method simply as "Label Diversity". Although it is possible to define a distance metric between classes as the distance in decades, this is unsuitable, since the year 1939 is closer to 1940 than it is to 1949, but the distances in decades are the same. We therefore treat this as an ordinal classification problem and use the MAP estimate in equation <ref type="formula" target="#formula_9">(8)</ref> for inference.</p><p>We evaluate the methods in terms of classification accuracy and MAE. A sample of correct and incorrect predictions are shown in <ref type="figure">Figure 8</ref>. The results are shown in <ref type="table" target="#tab_0">Table III</ref> and we conclude that using label diversity improves both accuracy and MAE over the regression baseline. Label diversity also decreases MAE compared to the RvC baseline, which we claim is due to the exploitation of the ranking between classes. Furthermore, our method improves the accuracy by one percentage point compared to the current state of the art method <ref type="bibr" target="#b28">[29]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUSION</head><p>In this work, we have shown that employing a series of different discrete representations of the target values, it is possible to improve the predictive performance of a deep neural network, compared to when using a single such representation. For some problems, it can also outperform direct regression. We note that our methods yield the strongest improvement compared to the regression baseline on historical image dating, where the target belongs to a small set of ordinal classes. For head pose estimation, where the target is continuous, the improvement was either small or negligible, but there is a significant improvement over the RvC baseline. For age estimation, where the target belongs to a large set of ordered classes, there is an improvement over both the regression and RvC method. Nevertheless, our method consistently improves over the RvC baseline for all methods. Hence our conclusion is that, if it is suitable to approach a regression problem via classification, then using several diverse representations can improve performance.</p><p>This opens up a wide range of options when it comes to selecting the representations, since there are many ways to create different discrete binnings of a continuous target value. As we have also shown, the number of discretizations and the number of bins for each discretization will have an impact on the prediction performance, but since these choices also affect the training convergence, it is difficult to select them for a given problem without extensive parameter search. In future research we will continue to investigate these questions and how diversity in label representations can be exploited in other ways.   <ref type="figure">Fig. 8</ref>: A subset of the images in HCI dataset <ref type="bibr" target="#b26">[27]</ref> with ground truth (GT) labels and predictions using the label diversity method.</p><p>ACKNOWLEDGMENT This work was supported by the Wallenberg Artificial Intelligence, Autonomous Systems and Software Program (WASP), funded by Knut and Alice Wallenberg Foundation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 :</head><label>1</label><figDesc>An illustration of the neural network architecture with multiple output heads. At inference time the expected values of the different distributions are combined using an ensemble average.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 :</head><label>2</label><figDesc>Examples of how the sets of class intervals D m can be constructed using the different methods.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 :</head><label>3</label><figDesc>During training, the loss is backpropagated through the different softmax heads to the previous layers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 7 :</head><label>7</label><figDesc>The sets of overlapping classes used for label diversity on the historical image dating task.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I :</head><label>I</label><figDesc>Mean average error in years for the different methods on the UTKFace<ref type="bibr" target="#b33">[34]</ref> test set.</figDesc><table><row><cell cols="2">Method CORAL [23]</cell><cell>DCTD [35]</cell><cell>Direct (Ours)</cell><cell>RvC (Ours)</cell><cell cols="2">Equal Width (Ours) Randomized Bins (Ours)</cell></row><row><cell>MAE</cell><cell>5.47 ± 0.01</cell><cell>4.65 ± 0.02</cell><cell>4.60 ± 0.02</cell><cell>4.71 ± 0.03</cell><cell>4.58 ± 0.03</cell><cell>4.55 ± 0.04</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE II :</head><label>II</label><figDesc>Mean average error in degrees for the different methods on the Biwi [36] test set. ± 0.08 2.64 ± 0.16 2.85 ± 0.12 2.62 ± 0.11 2.52 ± 0.06 Pitch 4.29 3.61 ± 0.12 2.75 ± 0.05 3.22 ± 0.09 3.12 ± 0.08 3.01 ± 0.10 Roll 3.60 2.75 ± 0.10 2.24 ± 0.07 2.48 ± 0.08 2.33 ± 0.09 2.34 ± 0.10 Average 3.60 3.01 ± 0.07 2.54 ± 0.05 2.85 ± 0.08 2.69 ± 0.04 2.63 ± 0.04</figDesc><table><row><cell>Method</cell><cell>Yang et al. [37]</cell><cell>DCTD [35]</cell><cell>Direct (Ours)</cell><cell>RvC (Ours)</cell><cell>Equal Width (Ours) Randomized Bins (Ours)</cell></row><row><cell>Yaw</cell><cell>2.89</cell><cell>2.67</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE III :</head><label>III</label><figDesc>Accuracy and mean average error in decades for the different methods on the HCI dataset<ref type="bibr" target="#b26">[27]</ref>.</figDesc><table><row><cell>Method</cell><cell>CNNOr [15]</cell><cell>PN [29]</cell><cell>ELB [29]</cell><cell>Direct (Ours)</cell><cell>RvC (Ours)</cell><cell>Label Diversity (Ours)</cell></row><row><cell>Acc (%)</cell><cell>41.56</cell><cell>56.67 ± 2.30</cell><cell>54.90 ± 2.40</cell><cell>46.9 ± 1.7</cell><cell>57.1 ± 1.9</cell><cell>57.7 ± 2.0</cell></row><row><cell>MAE</cell><cell>1.04</cell><cell>0.67 ± 0.05</cell><cell>0.63 ± 0.04</cell><cell>0.76 ± 0.01</cell><cell>0.72 ± 0.04</cell><cell>0.67 ± 0.03</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Horizon lines in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Workman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Jacobs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">British Machine Vision Conference (BMVC)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Designing deep networks for surface normal estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fouhey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="539" to="547" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Discriminatively trained dense surface normal estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zeisl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pollefeys</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="468" to="484" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Viewpoints and keypoints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tulsiani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1510" to="1519" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">A geometric approach to obtain a bird&apos;s eye view from an image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Abbas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.02231</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Dex: Deep expectation of apparent age from a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rothe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Timofte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision workshops</title>
		<meeting>the IEEE international conference on computer vision workshops</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="10" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Ordinal regression with multiple output cnn for age estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4920" to="4928" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Unimodal probability distributions for deep ordinal classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Beckham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1705.05278</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Soft labels for ordinal regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Marathe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4738" to="4747" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Ensemble classification and regression-recent developments, applications and future directions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">N</forename><surname>Suganthan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computational intelligence magazine</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="41" to="53" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Ordinal regression by extended binary classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-T</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="865" to="872" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Deep ordinal regression network for monocular depth estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Batmanghelich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2002" to="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Quatnet: Quaternion-based head pose estimation with multiregression loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-W</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">H</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-Y.</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Multimedia</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1035" to="1046" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Ordinal regression with neuron stick-breaking for medical diagnosis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B. K Vijaya</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="0" to="0" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Deep ordinal regression based on data relationship for small datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">W</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">.-K</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K</forename><surname>Goh</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Bagging predictors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="123" to="140" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Experiments with a new boosting algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Freund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Schapire</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996" />
			<publisher>Citeseer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Robust regression via deep negative correlation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-M</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-W</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zeng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.09066</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Anchored regression networks applied to age estimation and super resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Agustsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Timofte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1643" to="1652" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Quantifying facial age by posterior of age comparisons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Loy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.09687</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Deep label distribution learning with label ambiguity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B.-B</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-W</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Geng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2825" to="2838" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Soft-ranking label encoding for robust facial age estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.03625</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Rank-consistent ordinal regression for neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Mirjalili</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Raschka</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.07884</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Head pose estimation in computer vision: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Murphy-Chutorian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Trivedi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="607" to="626" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Faceposenet: Making a case for landmark-free face alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F.-J</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Tuan</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hassner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Masi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Nevatia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Medioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision Workshops</title>
		<meeting>the IEEE International Conference on Computer Vision Workshops</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1599" to="1608" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Fine-grained head pose estimation without keypoints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ruiz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Chong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Rehg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition workshops</title>
		<meeting>the IEEE conference on computer vision and pattern recognition workshops</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2074" to="2083" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Dating historical color images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Palermo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="499" to="512" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A century of portraits: A visual historical record of american high school yearbooks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ginosar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Rakelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sachs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision Workshops</title>
		<meeting>the IEEE International Conference on Computer Vision Workshops</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Deep ordinal classification with inequality constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belharbi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">B</forename><surname>Ayed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mccaffrey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Granger</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.10720</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">The use of the ambiguity decomposition in neural network ensemble learning methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Wyatt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th International Conference on Machine Learning (ICML-03)</title>
		<meeting>the 20th International Conference on Machine Learning (ICML-03)</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="67" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">The mnist database of handwritten digits</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<ptr target="http://yann.lecun.com/exdb/mnist/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Age progression/regression by conditional adversarial autoencoder</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Dctd: Deep conditional target densities for accurate regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">K</forename><surname>Gustafsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Danelljan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Bhat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">B</forename><surname>Schön</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.12297</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Real time head pose estimation from consumer depth cameras</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Fanelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Weise</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">V</forename><surname>Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">33rd Annual Symposium of the German Association for Pattern Recognition (DAGM&apos;11)</title>
		<imprint>
			<date type="published" when="2011-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Fsa-net: Learning fine-grained structure aggregation for head pose estimation from a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-Y.</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-Y</forename><surname>Chuang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1087" to="1096" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
