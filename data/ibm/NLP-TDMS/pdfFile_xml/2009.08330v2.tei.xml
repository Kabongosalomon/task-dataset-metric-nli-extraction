<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">More Embeddings, Better Sequence Labelers?</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2020-10-10">10 Oct 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyu</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information Science and Technology</orgName>
								<orgName type="institution">ShanghaiTech University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Shanghai Engineering Research Center of Intelligent Vision and Imaging</orgName>
								<orgName type="institution">University of Chinese Academy of Sciences † DAMO Academy</orgName>
								<address>
									<country>Alibaba Group</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">⋄</forename></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Jiang</surname></persName>
							<email>yongjiang.jy@alibaba-inc.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nguyen</forename><surname>Bach</surname></persName>
							<email>nguyen.bach@alibaba-inc.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongqiang</forename><surname>Huang</surname></persName>
							<email>z.huang@alibaba-inc.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Huang</surname></persName>
							<email>f.huang@alibaba-inc.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kewei</forename><surname>Tu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information Science and Technology</orgName>
								<orgName type="institution">ShanghaiTech University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Shanghai Engineering Research Center of Intelligent Vision and Imaging</orgName>
								<orgName type="institution">University of Chinese Academy of Sciences † DAMO Academy</orgName>
								<address>
									<country>Alibaba Group</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">More Embeddings, Better Sequence Labelers?</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2020-10-10">10 Oct 2020</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T09:29+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recent work proposes a family of contextual embeddings that significantly improves the accuracy of sequence labelers over noncontextual embeddings. However, there is no definite conclusion on whether we can build better sequence labelers by combining different kinds of embeddings in various settings. In this paper, we conduct extensive experiments on 3 tasks over 18 datasets and 8 languages to study the accuracy of sequence labeling with various embedding concatenations and make three observations: (1) concatenating more embedding variants leads to better accuracy in rich-resource and cross-domain settings and some conditions of low-resource settings;</p><p>(2) concatenating contextual sub-word embeddings with contextual character embeddings hurts the accuracy in extremely lowresource settings; (3) based on the conclusion of (1), concatenating additional similar contextual embeddings cannot lead to further improvements. We hope these conclusions can help people build stronger sequence labelers in various settings.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In recent years, sequence labelers equipped with contextual embeddings have achieved significant accuracy improvement (Peters et al. . Different types of embeddings have different inductive biases to guide the learning process. However, little work has been done to study how to concatenate these contextual embeddings and non-contextual * Yong Jiang and Kewei Tu are the corresponding authors. ‡ : This work was conducted when Xinyu Wang was interning at Alibaba DAMO Academy. embeddings to build better sequence labelers in multilingual, low-resource, or cross-domain settings over various sequence labeling tasks. In this paper, we empirically investigate the effectiveness of concatenating various kinds of embeddings for multilingual sequence labeling and try to answer the following questions:</p><p>1. In rich-resources settings, does combining different kinds of contextual embeddings result in a better sequence labeler? Are non-contextual embeddings helpful when the models are equipped with contextual embeddings?</p><p>2. When we train models in low-resource and cross-domain settings, do the conclusions from the rich-resource settings still hold?</p><p>3. Can sequence labelers automatically learn the importance of each kind of embeddings when they are concatenated?</p><p>2 Model Architecture</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Sequence Labeling</head><p>We use the BiLSTM structure for all the sequence labeling tasks, which is one of the most popular approaches to sequence labeling (Huang et al., 2015; Ma and Hovy, 2016). Given a n word sentence x = {x 1 , · · · , x n } and L kinds of embeddings, we feed the sentence to generate the l-th kind of word embeddings {e l 1 , · · · , e l n }:</p><formula xml:id="formula_0">e l i = embed l (x)</formula><p>We concatenate these embeddings to generate the word representations {r 1 , · · · , r n } as the input of the BiLSTM layer:</p><formula xml:id="formula_1">r i = e 1 i ⊕ · · · ⊕ e L i</formula><p>where ⊕ represents the vector concatenation operation. We feed the word representations into a single-layer BiLSTM to generate the contextual hidden layer of each word. Then we use either a Softmax layer (the MaxEnt approach) or a Conditional Random Field layer (the CRF approach) (Lafferty et al., 2001; Lample et al., 2016; Ma and Hovy, 2016) fed with the hidden layers to generate the conditional probability p(y|x). Given the corresponding sequence of gold labels y * = {y * 1 , · · · , y * n } for the input sentence, the loss function for a model with parameters θ is:</p><formula xml:id="formula_2">L θ = − log p(y * |x; θ)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Embeddings</head><p>There are mainly four kinds of embeddings that have been proved effective on the sequence labeling task: contextual sub-word embeddings, contextual character embeddings, non-contextual word embeddings and non-contextual character embeddings 1 . As we conduct our experiments in multilingual settings, we need to select suitable embeddings from each category for the concatenation. We use the Flair embeddings due to their high accuracy for sequence labeling task 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Contextual</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Non-contextual Word Embeddings (NWEs)</head><p>The most common approach to the NWEs is Word2vec <ref type="bibr">(Mikolov et al., 2013)</ref>, which is a skipgram model learning word representations by predicting neighboring words. Based on this approach, GloVe (Pennington et al., 2014) creates a co-occurrence matrix for global information and fastText (Bojanowski et al., 2017) represents each word as an n-gram of characters. We use fastText in our experiments as there are pretrained embeddings for 294 languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Non-contextual</head><p>Character Embeddings (NCEs) Using character information to represent the embeddings of word is proposed by Santos and Zadrozny (2014) with a lot of following work using a CNN structure to encode character representation <ref type="bibr">(</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments and Results</head><p>For simplicity, we use M to represent M-BERT embeddings, F to represent Flair embeddings, W to represent fastText embeddings, C to represent non-contextual character embeddings, All to represents the concatenation of all types of embeddings and the operator "+" to represent the concatenation operation. We use the MaxEnt approach for all experiments 3 . Due to the space limit, some detailed experiment settings, extra experiments and discussions are included in the appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Settings</head><p>Datasets  language-specific fastText and Flair embeddings depending on the dataset.</p><p>Embedding Concatenation Since experimenting on all 15 concatenation combinations of the four embeddings is not essential for evaluating the effectiveness of each kind of embeddings, we experiment on the following 7 concatenations: F, F+W, M, M+W, M+W+C, M+F+W, All. Through these concatenations, we can answer the following questions: (1) whether NWEs are still helpful (F vs. F+W and M vs. M+W);</p><p>(2) whether NCEs are still helpful (M+W vs. M+W+C and M+F+W vs. All); (3) whether concatenating different contextual embeddings results in a better sequence labeler (F+W vs. M+F+W and M+W vs. M+F+W); (4) which one is the best concatenation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Rich-resource and Low-resource Settings</head><p>How to build better sequence labelers through embedding concatenations in both rich-resource and low-resource settings is the most important concern for users. We report the results of various concatenations of embeddings for the tasks in <ref type="table" target="#tab_3">Table 1</ref> for rich-resource settings and in <ref type="figure">Figure 1</ref> for low-resource settings. From the results, we have the following observations. Observation #1. Concatenating more embedding variants results in better sequence labelers: In rich-resource settings, concatenating more embedding variants (M+F+W and All) results in best scores in most of the cases, which indicates that the inductive biases in various kind of embeddings are helpful to train a better sequence labeler. In low-resource settings, M+F+W and All performs inferior to the F+W when the number of sentences are lower than 100. However, when the training set gets larger, the gap between these concatenations becomes smaller and reverses when the training set becomes larger than 100 for NER  and POS tagging and the gap also disappears for Chunking. A possible reason is that using CSEs makes the model sample inefficient so that CSEs requires more training samples to improve accuracy than CCEs. The observation suggests that concatenating more embedding variants performs better if the training set is not extremely small. Observation #2. NCEs become less effective when concatenated with CSEs and CCEs: Concatenating NCEs with CSEs only marginally improves the accuracy. There is almost no improvement when concatenated with both CSEs and CCEs but the NCEs does not hurt the accuracy as well. A possible reason is that the CSEs and CCEs largely contain the information in NCEs 4 . Observation #3. NWEs are significantly helpful on top of contextual embeddings: Although models based on contextual embeddings have proved to be stronger than models based on NWEs for sequence labeling, concatenating NWEs with contextual embeddings can still improve the accuracy significantly. The results imply that the contextual embeddings contain more contextual information over the input but lack static word information. From these observations, we find that in most of rich-resource and low-resource settings, concatenating all embeddings variants or all embeddings variants except NCEs is the simplest choice for a better sequence labeler.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Cross-domain Settings</head><p>Another concern for users is that we want to build better sequence labelers not only in indomain settings but in out-of-domain settings as well. We conduct experiments in cross-domain settings to show how the embedding concatenations impact the accuracy when the distribution of training data and test data are different. We evaluate our Wikipedia NER models on almost consistent with rich-resource settings, suggesting that concatenating more embedding variants results in better sequence labelers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Importance of Embeddings</head><p>To study the effectiveness of concatenating embeddings from another perspective, we preserve only one kind of embedding in All and mask out the other embeddings as 0 to study how the models rely upon each kind of embeddings. To avoid the impact of embedding dimensions, we train the model by linearly projecting each kind of embeddings into the same dimension of 4096. The results ( <ref type="figure">Figure 2)</ref> show that the accuracy of preserved embeddings has a positive correlation with the results in  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">On Concatenating Similar Embeddings</head><p>Since concatenating more embeddings variants results in better sequence labelers, we additionally concatenate multilingual Flair embeddings (M-Flair) or English BERT embeddings (En-BERT) with All embeddings to show whether concatenating the same category of embeddings can further improve the accuracy. We evaluate the addition of En-BERT on English and M-Flair on all languages in each task. The results are shown in <ref type="table" target="#tab_7">Table 3</ref>. It can be seen that additionally concatenating the same category of embeddings does not further improve the accuracy in most cases except for concatenating En-BERT on English WikiAnn NER. A possible reason is that the BERT models are trained on the same domain as WikiAnn and hence the inductive biases of BERT embeddings help improve the accuracy. We also find that concatenating En-BERT with All only improves the accuracy of WikiAnn English NER. We think the possible reason for the improvement is that the BERT and the training data have the same domain of Wikipedia. We conduct the same concatenation on the CoNLL English NER dataset for comparison. The results in Ta-     specific CSEs impact the observations. The results <ref type="table" target="#tab_10">(Table 5)</ref> show that our observations do not change in both rich-resource and low-resource settings. Using a language-specific BERT embedding can even get better sequence labelers for the POS tagging and chunking tasks in rich-resource settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7">Hidden Sizes and Accuracy</head><p>In low-resource settings with 10 sentences, we find that models with All perform inferior to the models with F+W. One possible concern is that whether the larger hidden size of All introduces more parameters in the model and makes the model over-fits the training set. We linearly project the hidden size of F+W (4396) to the same hidden size as All (5214). <ref type="table" target="#tab_9">Table 4</ref> shows that with linear projection, F+W performs even better. Therefore, the cause for over-fitting is not the inferior accuracy of All but possibly the sample inefficiency for CSEs.</p><p>Another concern is whether we can project each embedding to a larger hidden size to improve the accuracy. Since we try a projection to 4096 for each embedding in F+W+proj (Section 3.4), we further project each embedding variants to see how the projection affect the accuracy in rich-resource settings. The results ( <ref type="table" target="#tab_11">Table 6)</ref> show that the linear projection for each embedding significantly decreases the accuracy of the models.</p><p>From the two experiments, we find that the hidden sizes of concatenated embeddings do not impact the observations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this paper, we analyze how to get a better sequence labeler by concatenating various kinds of embeddings. We make several empirical observations that we hope can guide future work to build better sequence labelers: (1) in most settings, concatenating more embedding variants leads to better results, while in extremely low-resource settings, only using CSEs and NWEs performs bet-ter; (2) NCEs become less effective when concatenated with contextual embeddings, while NWEs are still beneficial; (3) neural models can automatically learn which embeddings are beneficial to the task; (4) additionally concatenating similar contextual embeddings with the best concatenations from (1) cannot further improve the accuracy in most cases. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>References</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Appendix</head><p>In this appendix, we use ISO 639-1 codes 5 to represent each language for simplification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Settings</head><p>Datasets We use the following datasets for experiments:</p><p>• Model Configuration and Running For the embeddings, the hidden sizes for fastText and Flair embeddings 9 are 300 and 4096, respectively. The dimension of character embeddings is set to 50 10 following previous work <ref type="bibr">(Lample et al., 2016)</ref>. For M-BERT embeddings, we use the cased version that is trained on 104 languages for all datasets. We use the official release of bert-base-cased model in the experiments for English BERT. The word embeddings are fine-tuned and character embeddings are trained for tasks while the Flair and BERT embeddings are fixed. Our codes are mainly based on the official release of Flair 11 which is based on PyTorch v1.1.0 (Paszke et al., 2019). We run our experiments on a GPU server with NVIDIA Tesla V100 GPU. For model training, we set the mini-batch size to 2,000 tokens for better GPU utilization. Following the official release of Flair, we use an SGD optimizer with a learning rate of 0.1 for training all models and set the hidden size of BiLSTM to 256. We anneal the learning rate by 0.5 if there is no improvement on the development sets for 10 and 100 epochs when training rich-resource and 8 https://lindat.mff.cuni.cz/repository/xmlui/handle/11234/1-2837 9 Details of Flair embeddings https://github.com/flairNLP/flair/blob/master/resources/docs/embeddings/FLAIR_EMBEDDINGS.md <ref type="bibr">10</ref> We did not observe further gains when increasing the dimension size.  <ref type="table">Treebank  ar  PADT  cs  FicTree  de  GSD  en  EWT  es  GSD  fr  Sequoia  nl</ref> LassySmall ta TTB low-resource datasets respectively. We fix these hyper-parameters for all experiments because we find that tuning these hyper-parameters does not impact the observation and usually results in lower accuracy. We average over 5 runs for each experiment and report the macro-average score over all languages for each task.</p><p>Pre-processing and Evaluation We evaluate the NER and chunking by the F1 score and POS tagging by the accuracy. We use the evaluation script in the official release of Flair. We convert the BIO format into BIOES format for all NER and chunking datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Detailed Results</head><p>For the models using the CRF layer, similar to the main paper, we plot our results in the rich-resource and low-resource settings in <ref type="figure" target="#fig_3">Figure 3</ref>. The figures have similar trends as the MaxEnt models, showing that output structures do not impact the observations. <ref type="table" target="#tab_3">Table 10</ref> shows the importance of each kind of embeddings for each language and task (Section 3.4 in the main paper). <ref type="table" target="#tab_3">Table 11, 13 and 15</ref> show average scores over each language for each task in the rich-resource and low-resource settings (Section 3.2). <ref type="table" target="#tab_3">Table 12</ref>, 14 and 16 show average scores over each language for each task in the rich-resource and low-resource settings. <ref type="table" target="#tab_17">Table  9</ref> shows the average scores for each language in our cross-domain experiments (Section 3.3). <ref type="table" target="#tab_3">Table 17</ref> show the detailed comparison for additionally concatenating M-Flair embeddings with All for all datasets (Section 3.5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head># of Sentences</head><p>Relative Score 10 50 100 500 1000 All         </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>, 2018; Akbik et al., 2018; Devlin et al., 2019; Martin et al., 2019) over approaches that use static non-contextual word embeddings (Mikolov et al., 2013) and character embeddings (Santos and Zadrozny, 2014)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :Figure 2 :</head><label>12</label><figDesc>CoNLL 2002/2003 NER (Tjong Kim Sang, 2002; Tjong Kim Sang and De Meulder, 2003) datasets from the news domain. The results (Table 2)are Relative score improvements against models with M-BERT embeddings for three tasks. Importance of each embedding over the concatenation of All embeddings. The score percentage represents the average score preserving only one kind of embeddings divided by the score without masking.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>11 https://github.com/flairNLP/flair Language</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Relative score improvements against models with M-BERT embeddings for three tasks. Models are equipped with the CRF layer.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Pires et al., 2019; Karthikeyan et al., 2020).</figDesc><table><row><cell>Sub-word Embeddings (CSEs)</cell></row><row><cell>CSEs such as OpenAI GPT (Radford et al.) and</cell></row><row><cell>BERT (Devlin et al., 2019) are based on trans-</cell></row><row><cell>former (Vaswani et al., 2017) and use WordPiece</cell></row><row><cell>embeddings (Sennrich et al., 2016; Wu et al.,</cell></row><row><cell>2016) as input. Much research has focused on</cell></row><row><cell>improving BERT model's performance such as</cell></row><row><cell>better masking strategy (Liu et al., 2019) and</cell></row><row><cell>cross-lingual training (Conneau and Lample,</cell></row><row><cell>2019). Since we focus on the multilingual settings</cell></row><row><cell>of sequence labeling tasks, we use multilingual</cell></row><row><cell>BERT (M-BERT), as recent researches shows its</cell></row><row><cell>strong generalizability over various languages and</cell></row><row><cell>tasks (Contextual Character Embeddings (CCEs)</cell></row><row><cell>Liu et al. (2018) proposed a character language</cell></row><row><cell>model by applying the BiLSTM over the sen-</cell></row><row><cell>tence and trained jointly with the sequence label-</cell></row><row><cell>ing task. (Pooled) Contextual string embeddings</cell></row><row><cell>(Flair) (Akbik et al., 2018, 2019) are pretrained on</cell></row><row><cell>a large amount of unlabeled data and result in sig-</cell></row><row><cell>nificant improvements for sequence labeling tasks.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1 :</head><label>1</label><figDesc>Averaged F1 scores over languages for each task with different embedding concatenations.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 2 :</head><label>2</label><figDesc>Cross-domain transfer from the Wikipedia domain to the news domain on the NER task.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 1 .</head><label>1</label><figDesc>For example, M gets higher accuracy than other embeddings in NER and Table 1 also shows that the model with F performs inferior to the model with M only. The models with concatenated embeddings almost do not rely on NCEs and relies mostly on CSEs or CCEs depending on the task. These results show that models with concatenated embeddings can extract helpful information from each kind of embeddings to improve accuracy.</figDesc><table><row><cell>EMBEDDINGS</cell><cell></cell><cell></cell><cell>TASKS</cell><cell></cell></row><row><cell cols="5">M F W C B MF NER POS CHUNK</cell></row><row><cell cols="3">+En-BERT (English)</cell><cell></cell><cell></cell></row><row><cell>✓ ✓ ✓ ✓ ✗</cell><cell>✗</cell><cell>81.8</cell><cell>97.0</cell><cell>91.6</cell></row><row><cell>✗ ✓ ✓ ✓ ✓</cell><cell>✗</cell><cell>80.5</cell><cell>97.2</cell><cell>91.8</cell></row><row><cell>✓ ✓ ✓ ✓ ✓</cell><cell>✗</cell><cell>82.1</cell><cell>97.2</cell><cell>91.6</cell></row><row><cell cols="4">+M-Flair (All languages)</cell><cell></cell></row><row><cell>✓ ✓ ✓ ✓ ✗</cell><cell>✗</cell><cell>86.8</cell><cell>96.7</cell><cell>92.9</cell></row><row><cell>✓ ✗ ✓ ✓ ✗</cell><cell>✓</cell><cell>86.1</cell><cell>96.5</cell><cell>92.8</cell></row><row><cell>✓ ✓ ✓ ✓ ✗</cell><cell>✓</cell><cell>86.8</cell><cell>96.7</cell><cell>92.9</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 3 :</head><label>3</label><figDesc>Comparisons of the effectiveness for additionally concatenating the same category of embeddings.</figDesc><table /><note>B represents the En-BERT embeddings and MF rep- resents the M-Flair embeddings.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 4 :</head><label>4</label><figDesc>Comparisons of F+W, All, and F+W+proj (F+W with linearly projecting the hidden size into the hidden size of All) in three tasks with 10-sentence lowresource settings. The accuracy is averaged over tasks.✗  ✓ ✓ ✗ ✗ 35.5±1.4 80.2±0.1 73.3±0.6 2. ✓ ✓ ✓ ✓ ✗ 25.4±0.8 77.9±0.2 70.8±0.5 3. ✗ ✓ ✓ ✓ ✓ 29.3±0.8 79.6±0.2 67.9±0.5</figDesc><table><row><cell>EMBEDDINGS</cell><cell></cell><cell>TASKS</cell><cell></cell></row><row><cell>M F W C B</cell><cell>NER</cell><cell>POS</cell><cell>CHUNK</cell></row><row><cell cols="3">LOW-RESOURCE: 10 SENTENCES</cell><cell></cell></row><row><cell>1.</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 5 :</head><label>5</label><figDesc>Comparisons of using English BERT instead of M-BERT in English datasets. B represents the En-BERT embeddings. We also provide the concatenation of Flair and pretrained word embeddings for reference.</figDesc><table><row><cell>EMBEDDINGS</cell><cell>TASKS</cell><cell></cell></row><row><cell></cell><cell cols="2">NER POS CHUNK</cell></row><row><cell>All</cell><cell>86.8 96.7</cell><cell>92.9</cell></row><row><cell>All+50d Proj.</cell><cell>83.8 96.3</cell><cell>92.0</cell></row><row><cell cols="2">All+1024d Proj. 84.8 96.5</cell><cell>92.2</cell></row><row><cell cols="2">All+4096d Proj. 85.1 96.5</cell><cell>92.2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 6 :</head><label>6</label><figDesc>Comparisons of All with different linear projection size in three tasks with rich-resource settings. The accuracy is averaged over tasks. ble 7 show that concatenating En-BERT with All does not further improve the accuracy on CoNLL English NER.</figDesc><table><row><cell>EMBEDDINGS</cell><cell>TASK</cell></row><row><cell cols="2">M F W C B ENGLISH NER</cell></row><row><cell>✓ ✓ ✓ ✓ ✗</cell><cell>92.1±0.1</cell></row><row><cell>✗ ✓ ✓ ✓ ✓</cell><cell>92.0±0.1</cell></row><row><cell>✓ ✓ ✓ ✓ ✓</cell><cell>92.1±0.1</cell></row></table><note>3.6 English BERT vs. M-BERT We use English BERT embeddings instead of M- BERT embeddings to see whether the language-</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 7 :</head><label>7</label><figDesc>Comparisons of concatenating En-BERT withAll on CoNLL NER. B represents the En-BERT.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head></head><label></label><figDesc>Wei Xu, and Kai Yu. 2015. Bidirectional lstm-crf models for sequence tagging. arXiv preprint arXiv:1508.01991. K Karthikeyan, Zihan Wang, Stephen Mayhew, and Dan Roth. 2020. Cross-lingual ability of multilingual bert: An empirical study. In International Conference on Learning Representations. Neural machine translation of rare words with subword units. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1715-1725, Berlin, Germany. Association for Computational Linguistics.</figDesc><table><row><cell>Alan and Pooled contextualized embeddings for named entity recognition. Akbik, Tanja Rico and Zhiheng Huang, John D. Lafferty, Andrew McCallum, and Fernando Sennrich, Barry Haddow, Alexandra Birch. 2016. Erik F. Tjong Kim Sang. 2002. Introduction to the CoNLL-2002 shared task: Language-independent C. N. Pereira. 2001. Conditional random fields: In COLING-02: The 6th Conference on Natural Probabilistic models for segmenting and labeling se-Language Learning 2002 (CoNLL-2002). quence data. In Proceedings of the Eighteenth Inter-national Conference on Machine Learning, ICML Erik F. Tjong Kim Sang and Fien De Meulder. 2003. '01, page 282-289, San Francisco, CA, USA. Mor-gan Kaufmann Publishers Inc. Introduction to the CoNLL-2003 shared task: Language-independent In Proceedings of the Seventh Conference on Natu-ral Language Learning at HLT-NAACL 2003, pages Guillaume Lample, Miguel Ballesteros, Sandeep Sub-142-147. ramanian, Kazuya Kawakami, and Chris Dyer. 2016. Neural architectures for named entity recognition. In Proceedings of the 2016 Conference of the North Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz American Chapter of the Association for Computa-tional Linguistics: Human Language Technologies, pages 260-270, San Diego, California. Association Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in neural information pro-cessing systems, pages 5998-6008. for Computational Linguistics. Bergmann, Roland Vollgraf. 2019. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computa-tional Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 724-728, Minneapolis, Minnesota. Association for Computational Linguistics. Alan Akbik, Duncan Blythe, and Roland Vollgraf. 2018. Contextual string embeddings for sequence labeling. In Proceedings of the 27th International Conference on Computational Linguistics, pages 1638-1649, Santa Fe, New Mexico, USA. Association for Computational Linguistics. Tomas Mikolov. 2017. Enriching word vectors with subword information. Transactions of the Associa-Jason P.C. Chiu and Eric Nichols. 2016. Named entity recognition with bidirectional LSTM-CNNs. Transactions of the Association for Computational Linguistics, 4:357-370. Alexis Conneau and Guillaume Lample. 2019. Cross-lingual language model pretraining. In Advances in Neural Information Processing Systems, pages 7057-7067. Jacob Devlin, Ming-Wei Chang, Ken-ton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North Louis Martin, Benjamin Muller, Pedro Javier Ortiz Suárez, Yoann Dupont, Laurent Romary, Éric Ville-ity. In Advances in neural information processing Computational Linguistics. pages 25-33, Beijing, China. Association for In Proceedings of the Fifth Named Entity Workshop, systems, pages 3111-3119. Boosting named entity recognition with neural character embeddings. Cícero dos Santos and Victor Guimarães. 2015. tions of words and phrases and their compositional-rado, and Jeff Dean. 2013. Distributed representa-by generative pre-training. Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-Ilya Sutskever. Improving language understanding Alec Radford, Karthik Narasimhan, Tim Salimans, and model. arXiv preprint arXiv:1911.03894. Sagot. 2019. Camembert: a tasty french language tional Linguistics. monte de la Clergerie, Djamé Seddah, and Benoît 5001, Florence, Italy. Association for Computa-ciation for Computational Linguistics, pages 4996-ceedings of the 57th Annual Meeting of the Asso-tion for Computational Linguistics, 5:135-146. Association for Computational Linguistics. How multilingual is multilingual BERT? In Pro-Telmo Pires, Eva Schlinger, and Dan Garrette. 2019. Long Papers), pages 1064-1074, Berlin, Germany. Piotr Bojanowski, Edouard Grave, Armand Joulin, and Liyuan Liu, Jingbo Shang, Xiang Ren, Frank Fangzheng Xu, Huan Gui, Jian Peng, and Jiawei Han. 2018. Empower sequence la-beling with task-aware neural language model. In Thirty-Second AAAI Conference on Artificial Jeffrey Pennington, Richard Socher, and Christopher Manning. 2014. Glove: Global vectors for word rep-Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V Le, Mohammad Norouzi, Wolfgang Macherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus resentation. In Proceedings of the 2014 conference on empirical methods in natural language process-ing (EMNLP), pages 1532-1543. Macherey, et al. 2016. Google's neural machine translation system: Bridging the gap between hu-man and machine translation. arXiv preprint Intelligence. Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-dar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019. Roberta: A robustly optimized bert pretraining ap-proach. arXiv preprint arXiv:1907.11692. Xuezhe Ma and Eduard Hovy. 2016. End-to-end sequence labeling via bi-directional LSTM-CNNs-CRF. sociation for Computational Linguistics (Volume 1: Linguistics. In Proceedings of the 54th Annual Meeting of the As-arXiv:1609.08144. Matthew Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Ken-ton Lee, and Luke Zettlemoyer. 2018. Deep contextualized word representations. In Jie Yang, Shuailong Liang, and Yue Zhang. 2018. Design challenges and misconceptions in neural sequence labeling. In Proceedings of the 27th International Conference Proceedings of the 2018 Conference of the North American Chapter of the Association for Computa-tional Linguistics: Human Language Technologies, Orleans, Louisiana. Association for Computational Volume 1 (Long Papers), pages 2227-2237, New on Computational Linguistics, pages 3879-3889, Santa Fe, New Mexico, USA. Association for Computational Linguistics.</cell></row><row><cell>American Chapter of the Association for Computa-tional Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 4171-Cicero D Santos and Bianca Zadrozny. 2014. Learning character-level representations for part-of-speech tagging. In Proceedings of the 31st international</cell></row><row><cell>4186, Minneapolis, Minnesota. Association for Computational Linguistics. conference on machine learning (ICML-14), pages 1818-1826.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 8 :</head><label>8</label><figDesc>The list of treebank that we used in UD POS tagging.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table 9 :</head><label>9</label><figDesc>Detailed results of cross-domain transfer from the Wikipedia domain to the news domain on the NER task. We use the ISO 639 language code to represent each language. 0±1.4 43.7±1.1 44.9±2.6 0.0±0.0 82.6±0.1 cs 71.6±0.4 54.5±2.4 45.9±2.1 0.0±0.0 88.0±0.1 de 67.0±0.8 58.1±2.5 33.6±1.9 0.0±0.0 85.6±0.2 en 67.7±0.9 46.5±0.9 22.8±0.5 0.0±0.0 88.4±0.7 es 74.9±1.0 54.6±2.5 35.0±2.0 0.0±0.0 79.9±0.6 fr 75.9±1.5 48.0±1.3 35.2±3.9 0.0±0.0 84.2±0.1 nl 63.4±3.7 59.0±1.6 40.3±0.9 0.0±0.0 86.7±0.4 ta 41.3±0.9 51.5±1.5 43.5±1.4 0.0±0.0 83.4±0.2 5±1.7 88.3±0.7 79.3±0.6 27.4±0.9 92.0±0.6 cs 84.0±0.6 90.8±0.1 68.5±0.6 25.6±3.2 96.5±0.1 de 78.3±2.9 88.3±0.2 71.3±0.8 26.3±3.6 98.8±0.0 en 85.1±0.9 85.8±0.2 65.3±1.8 32.5±1.1 97.2±0.0 es 83.2±1.6 92.4±0.5 80.9±1.6 20.4±5.9 96.6±0.0 fr 92.6±0.7 85.2±0.6 63.7±0.2 15.8±3.0 95.2±0.0 nl 80.9±0.3 89.9±0.1 70.9±1.9 18.9±1.7 98.7±0.0 ta 76.8±1.8 76.6±0.3 62.0±0.0 33.1±4.8 96.7±0.0 3±4.0 90.2±0.3 52.9±2.9 28.0±0.5 93.5±0.1 en 46.6±2.1 73.0±0.8 70.7±0.6 19.8±0.3 90.8±0.1</figDesc><table><row><cell>M-BERT</cell><cell>Flair</cell><cell>Word</cell><cell>Char</cell><cell>All</cell></row><row><cell></cell><cell cols="2">WikiAnn NER</cell><cell></cell><cell></cell></row><row><cell>ar 53.Avg. 64.3</cell><cell>52.0</cell><cell>37.6</cell><cell>0.0</cell><cell>84.8</cell></row><row><cell></cell><cell cols="2">UD POS tagging</cell><cell></cell><cell></cell></row><row><cell>ar 84.Avg. 83.2</cell><cell>87.2</cell><cell>70.2</cell><cell>25.0</cell><cell>96.5</cell></row><row><cell></cell><cell></cell><cell>Chunking</cell><cell></cell><cell></cell></row><row><cell>de 66.Avg. 56.4</cell><cell>81.6</cell><cell>61.8</cell><cell>23.9</cell><cell>92.2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18"><head>Table 10 :</head><label>10</label><figDesc>Detailed results on importance of embeddings for each language.</figDesc><table><row><cell>EMBEDDINGS</cell><cell></cell><cell></cell><cell></cell><cell cols="3">MaxEnt models on WikiAnn NER</cell><cell></cell><cell></cell><cell></cell></row><row><cell>M F W C</cell><cell>ar</cell><cell>cs</cell><cell>de</cell><cell>en</cell><cell>es</cell><cell>fr</cell><cell>nl</cell><cell>ta</cell><cell>Avg.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_19"><head>Table 11 :</head><label>11</label><figDesc>Averaged F1 scores over 8 languages for WikiAnn NER.</figDesc><table><row><cell>EMBEDDINGS</cell><cell></cell><cell></cell><cell></cell><cell cols="3">CRF models on WikiAnn NER</cell><cell></cell><cell></cell><cell></cell></row><row><cell>M F W C</cell><cell>ar</cell><cell>cs</cell><cell>de</cell><cell>en</cell><cell>es</cell><cell>fr</cell><cell>nl</cell><cell>ta</cell><cell>Avg.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_20"><head>Table 12 :</head><label>12</label><figDesc>Averaged F1 scores over 8 languages for WikiAnn NER with the CRF layer.</figDesc><table><row><cell>EMBEDDINGS</cell><cell></cell><cell></cell><cell></cell><cell cols="3">MaxEnt models on UD POS tagging</cell><cell></cell><cell></cell><cell></cell></row><row><cell>M F W C</cell><cell>ar</cell><cell>cs</cell><cell>de</cell><cell>en</cell><cell>es</cell><cell>fr</cell><cell>nl</cell><cell>ta</cell><cell>Avg.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_21"><head>Table 13 :</head><label>13</label><figDesc>Averaged accuracy scores over 8 languages for UD POS tagging.</figDesc><table><row><cell>EMBEDDINGS</cell><cell></cell><cell></cell><cell cols="4">BiLSTM-CRF models on UD POS tagging</cell><cell></cell><cell></cell><cell></cell></row><row><cell>M F W C</cell><cell>ar</cell><cell>cs</cell><cell>de</cell><cell>en</cell><cell>es</cell><cell>fr</cell><cell>nl</cell><cell>ta</cell><cell>Avg.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_22"><head>Table 16 :</head><label>16</label><figDesc>Averaged F1 scores over 2 languages for chunking with the CRF layer. 6±0.2 88.4±0.2 85.5±0.3 81.7±0.2 90.6±0.2 88.4±0.5 90.1±0.3 85.5±0.3 86.8 ✓ ✗ ✓ ✓ ✓ 83.6±0.8 87.7±0.3 84.2±0.3 81.4±0.1 90.0±0.1 87.9±0.1 89.9±0.4 84.2±0.2 86.1 ✓ ✓ ✓ ✓ ✓ 84.8±0.5 88.6±0.2 85.1±0.3 82.0±0.2 90.3±0.4 88.1±0.3 90.1±0.2 85.3±0.3 86.8 97.0±0.1 98.8±0.0 95.4±0.1 97.0±0.1 97.3±0.1 99.1±0.1 96.7±0.1 92.5±0.4 96.7 ✓ ✗ ✓ ✓ ✓ 96.8±0.0 98.7±0.0 95.2±0.1 96.6±0.1 97.2±0.0 99.0±0.0 96.5±0.1 91.2±0.3 96.4 ✓ ✓ ✓ ✓ ✓ 97.0±0.0 98.8±0.0 95.3±0.0 96.9±0.1 97.3±0.1 99.1±0.0 96.7±0.1 92.7±0.5 96.7 CHUNKING</figDesc><table><row><cell>EMBEDDINGS</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Languages</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>M F W C MF</cell><cell>ar</cell><cell>cs</cell><cell>de</cell><cell>en</cell><cell>NER es</cell><cell>fr</cell><cell>nl</cell><cell>ta</cell><cell>Avg.</cell></row><row><cell>✓ ✓ ✓ ✓ ✗</cell><cell cols="5">84.POS TAGGING</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>ar</cell><cell>cs</cell><cell>de</cell><cell>en</cell><cell>es</cell><cell>fr</cell><cell>nl</cell><cell>ta</cell><cell>Avg.</cell></row><row><cell>✓ ✓ ✓ ✓ ✗</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>de</cell><cell>en</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Avg.</cell></row><row><cell>✓ ✓ ✓ ✓ ✗</cell><cell cols="2">94.0±0.0 91.5±0.0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>92.8</cell></row><row><cell>✓ ✗ ✓ ✓ ✓</cell><cell cols="2">94.1±0.1 91.6±0.1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>92.9</cell></row><row><cell>✓ ✓ ✓ ✓ ✓</cell><cell cols="2">94.2±0.1 91.7±0.1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>92.9</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_23"><head>Table 17 :</head><label>17</label><figDesc>Detailed comparison for additionally concatenating MF with All. MF represents the M-Flair embeddings.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">We do not use contextual word embeddings such as ELMo (Peters et al., 2018) since Akbik et al. (2018) showed that concatenating Flair embeddings with ELMo embeddings cannot further improve the accuracy.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">We do not use the pooled version of Flair due to its slower speed in training.3  We find that the observations from the MaxEnt experiments do not change in all experiments with the CRF approach.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">The observation is consistent with the observation of Akbik et al. (2018), but we experimented on more languages and tasks with the M-BERT embeddings.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes 6 https://elisa-ie.github.io/wikiann/ 7 https://www.clips.uantwerpen.be/conll2003/ner/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work was supported by the National Natural Science Foundation of China (61976139). This work also was supported by Alibaba Group through Alibaba Innovative Research Program. The authors wish to thank Chao Lou for his helpful comments and suggestions.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✗ ✓ ✓ ✓ ✓</forename></persName>
		</author>
		<idno>43.4±0.9 88.9±0.0 78.8±0.1</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✗ ✓ ✗ ✗</forename></persName>
		</author>
		<idno>33.6±1.3 36.9±1.5 25.5±0.8 35.8±1.2 34.4±2.0 39.4±2.0 26.2±1.7 20.6±0.7 31.5</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>✗ ✓ ✓ ✗ 34</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
	<note>4±1.4 40.5±1.4 26.0±0.4 35.5±1.4 33.9±3.1 41.6±0.2 28.6±1.9 20.8±1.1</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>✓ ✗ ✗ ✗ 29</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>6±2.4 31.0±0.9 13.8±1.9 23.2±1.7 23.2±1.5 24.6±2.3 16.2±1.5 17.5±0.8 22.4</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>✓ ✗ ✓ ✗ 28</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>8±1.9 32.2±0.9 15.7±1.6 22.1±0.6 23.1±1.0 24.2±2.5 20.0±2.9 18.6±0.7 23.1</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>✓ ✗ ✓ ✓ 27</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>8±0.6 32.1±1.5 15.8±2.2 23.1±0.5 23.9±1.3 26.3±2.3 19.2±1.8 18.6±0.4 23.4</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>✓ ✓ ✓ ✗ 29</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
	<note>6±1.9 34.8±0.5 22.3±0.9 26.4±0.9 25.2±1.0 29.8±1.5 29.5±2.1 20.7±0.6</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>✗ ✓ ✗ ✗ 47</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>6±1.0 54.6±1.9 52.7±1.4 47.3±0.3 54.8±0.8 54.5±0.5 49.2±0.6 45.3±0.6 50.8</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✗ ✓ ✓ ✗</forename></persName>
		</author>
		<idno>49.8±0.8 58.0±0.4 55.7±1.0 48.6±0.3 54.2±1.6 54.0±1.1 49.7±0.9 44.5±0.6 51.8</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>✓ ✗ ✓ ✗ 44</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>3±1.2 54.6±0.4 46.6±2.3 46.9±0.5 45.8±1.2 49.2±1.2 46.7±1.3 33.6±1.1 46.0</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✗ ✓ ✓</forename></persName>
		</author>
		<idno>44.1±0.6 55.7±0.9 47.0±4.1 47.1±0.6 44.9±2.0 49.1±1.2 47.6±1.5 35.4±1.1 46.4</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✓ ✓ ✗</forename></persName>
		</author>
		<idno>49.4±1.7 58.0±1.3 50.1±1.1 48.5±0.1 50.4±1.0 53.4±1.3 52.5±0.9 42.5±2.6 50.6</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✓ ✓ ✓</forename></persName>
		</author>
		<idno>48.3±1.4 58.0±1.2 49.6±1.3 48.5±0.4 51.0±1.5 52.4±0.9 51.9±0.5 44.3±2.3 50.5 LOW-RESOURCE: 100 SENTENCES</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✗ ✓ ✗ ✗</forename></persName>
		</author>
		<idno>56.5±0.7 57.8±0.8 55.0±1.9 52.3±0.3 66.1±0.9 56.8±2.8 55.4±1.0 50.6±0.8 56.3</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✗ ✓ ✓ ✗</forename></persName>
		</author>
		<idno>58.7±1.2 61.9±1.0 56.9±1.1 54.8±0.5 67.0±1.0 60.5±0.7 57.9±1.3 54.6±1.3 59.0</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>✓ ✗ ✗ ✗ 47</surname></persName>
		</author>
		<idno>6±3.0 57.7±3.8 49.7±3.7 54.9±0.5 59.2±1.2 57.5±0.9 54.9±1.0 42.3±3.9 53.0</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✗ ✓ ✗</forename></persName>
		</author>
		<idno>51.0±3.2 59.8±0.8 52.3±1.3 56.0±0.3 60.0±1.6 58.4±0.4 59.0±3.1 48.8±4.0 55.7</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✗ ✓ ✓</forename></persName>
		</author>
		<idno>51.2±2.9 61.1±0.9 52.8±1.7 55.9±0.7 61.0±0.9 60.4±2.2 57.3±2.2 46.6±1.6 55.8</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✓ ✓ ✗</forename></persName>
		</author>
		<idno>57.4±1.5 64.3±1.7 55.3±1.0 57.0±0.4 65.7±2.3 62.2±0.7 61.3±0.7 53.2±1.3 59.6</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✓ ✓ ✓</forename></persName>
		</author>
		<idno>58.2±1.1 62.8±1.0 54.4±1.5 56.8±0.1 66.0±0.3 62.7±0.7 61.8±1.3 53.7±0.6 59.5 LOW-RESOURCE: 500 SENTENCES</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✗ ✓ ✗ ✗</forename></persName>
		</author>
		<idno>69.2±0.8 77.2±1.1 72.1±0.7 65.6±0.3 77.6±0.6 73.6±0.4 74.6±1.5 61.9±1.1 71.5</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✗ ✓ ✓ ✗</forename></persName>
		</author>
		<idno>73.2±0.7 78.6±1.3 72.9±1.0 68.3±0.2 78.2±1.3 75.1±1.1 75.0±1.3 66.1±1.2 73.4</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>✓ ✗ ✗ ✗ 67</surname></persName>
		</author>
		<idno>3±1.0 77.0±0.5 71.8±1.0 67.7±0.2 77.6±0.7 76.7±0.9 75.5±1.7 64.9±1.3 72.3</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✗ ✓ ✗ ✗</forename></persName>
		</author>
		<idno>74.7±0.6 80.2±0.4 75.6±0.6 68.9±0.0 82.9±0.4 75.9±0.8 80.1±0.7 73.8±0.4 76.5</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✗ ✓ ✓ ✗</forename></persName>
		</author>
		<idno>77.8±0.2 82.6±0.5 77.2±0.4 72.0±0.1 84.0±0.3 78.4±1.0 83.3±0.5 75.7±0.7 78.9</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✗ ✗ ✗</forename></persName>
		</author>
		<idno>73.6±0.4 81.7±0.4 77.3±0.2 72.2±0.1 84.8±0.6 82.2±0.9 81.4±0.4 71.2±0.8 78.0</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✗ ✓ ✗</forename></persName>
		</author>
		<idno>77.0±0.2 83.3±0.4 78.7±0.6 73.4±0.5 85.2±0.8 83.1±0.4 84.2±0.6 76.3±0.7 80.2</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✗ ✓ ✓</forename></persName>
		</author>
		<idno>77.9±0.6 83.3±0.7 78.9±0.3 73.6±0.0 84.6±0.8 82.3±0.9 84.2±0.7 76.0±0.1 80.1</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✓ ✓ ✗</forename></persName>
		</author>
		<idno>78.3±0.3 84.0±0.4 79.8±0.5 75.3±0.3 86.3±0.4 83.3±0.6 85.0±1.0 78.2±0.5 81.3</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>✓ ✓ ✓ ✓ 78</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>4±0.6 83.8±0.3 79.8±0.3 75.2±0.3 86.4±0.2 83.6±0.3 84.5±0.6 77.9±0.5 81.2 RICH-RESOURCE</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✗ ✓ ✗ ✗</forename></persName>
		</author>
		<idno>81.0±0.5 83.0±2.5 80.4±0</idno>
		<imprint/>
	</monogr>
	<note>5 76.9±0.1 86.2±0.4 81.8±0.6 85.7±0.5 82.3±0.5 82.2 2. ✗ ✓ ✓ ✗ 84.5±0.3 86.9±0.6 81.8±0.4 79.9±0.3 88.4±0.5 83.8±0.3 88.2±0.5 83.5±0.6 84.6</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>✓ ✗ ✓ ✗ 83</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>2±0.4 87.1±0.6 84.2±0.3 80.3±0.6 88.4±0.5 87.4±0.3 89.3±0.4 83.8±0.4 85.5</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✗ ✓ ✓</forename></persName>
		</author>
		<idno>83.2±0.8 87.4±0.3 83.9±0.2 81.0±0.1 88.2±0.4 87.5±0.3 89.2±0.4 83.7±0.6 85.5</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✓ ✓ ✗</forename></persName>
		</author>
		<idno>84.2±0.5 88.8±0.5 85.4±0.5 81.8±0.1 90.4±0.4 88.1±0.5 90.4±0.3 85.4±0.3 86.8</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✓ ✓ ✓</forename></persName>
		</author>
		<idno>84.6±0.2 88.4±0.2 85.5±0.3 81.8±0.2 90.6±0.2 88.4±0.5 90.1±0.3 85.5±0.3 86.8 LOW-RESOURCE: 10 SENTENCES</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>✗ ✓ ✗ ✗ 31</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>0±5.2 38.6±1.1 23.5±0.7 35.1±2.2 37.6±3.6 41.2±2.2 27.4±3.4 19.6±1.1 31.8</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✗ ✓ ✓ ✗</forename></persName>
		</author>
		<idno>32.0±3.3 38.9±4.6 24.1±1.3 33.3±0.5 31.7±2.0 43.1±4.5 30.4±3.9 19.6±3.7 31.6</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✗ ✗ ✗</forename></persName>
		</author>
		<idno>31.5±4.7 30.0±2.8 12.5±4.9 23.1±1.0 23.5±5.2 24.7±3.2 18.3±2.7 17.8±1.0 22.7</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>✓ ✗ ✓ ✗ 28</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>4±3.2 30.9±1.9 14.2±1.3 21.3±2.9 21.5±1.9 25.4±3.4 12.5±8.0 18.5±1.0 21.6</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>✓ ✗ ✓ ✓ 30</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">23</biblScope>
		</imprint>
	</monogr>
	<note>9±1.8 32.8±2.2 11.0±5.7 19.7±1.4 24.7±1.4 28.1±0.3 19.3±3.8 18.8±1.3</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>✓ ✓ ✓ ✗ 29</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>3±1.4 33.0±2.5 20.9±1.5 22.4±0.8 23.8±2.0 28.5±1.9 26.5±4.6 21.7±1.7 25.7</note>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>✓ ✓ ✓ ✓ 30</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>0±2.4 32.2±1.6 22.2±2.2 22.1±0.0 23.1±1.9 30.0±3.6 28.5±2.1 19.2±2.0 25.9</note>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✗ ✓ ✗ ✗</forename></persName>
		</author>
		<idno>49.6±2.0 55.0±1.3 54.3±0.6 43.8±1.7 55.3±2.7 57.6±1.0 53.9±1.3 45.4±2.7 51.9</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>✗ ✓ ✓ ✗ 51</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>3±4.6 58.6±1.8 52.8±1.0 45.1±0.3 55.9±1.7 55.6±2.1 55.2±1.3 46.1±2.2 52.6</note>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✗ ✗ ✗</forename></persName>
		</author>
		<idno>45.5±2.7 55.3±3.3 42.2±3.0 44.4±0.4 44.7±2.7 52.3±1.7 47.0±3.7 32.8±5.2 45.5</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>✓ ✗ ✓ ✗ 45</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">46</biblScope>
		</imprint>
	</monogr>
	<note>9±1.2 54.6±1.3 45.3±2.6 40.6±2.6 45.5±2.1 51.4±2.2 47.7±1.2 37.5±3.4</note>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>✓ ✗ ✓ ✓ 44</surname></persName>
		</author>
		<idno>1±4.4 54.8±1.7 47.0±3.5 40.9±1.3 47.1±2.4 50.8±2.7 46.8±3.0 34.9±7.3 45.8</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>✓ ✓ ✓ ✗ 48</surname></persName>
		</author>
		<idno>2±4.7 57.9±2.3 51.6±1.8 41.7±0.5 51.0±2.7 53.7±3.1 51.3±2.0 42.6±2.8 49.8</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✓ ✓ ✓</forename></persName>
		</author>
		<idno>45.0±6.2 57.1±1.2 50.0±3.3 45.8±0.6 51.5±1.4 53.0±2.6 51.1±4.2 41.3±3.2 49.4 LOW-RESOURCE: 100 SENTENCES</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>✗ ✓ ✗ ✗ 55</surname></persName>
		</author>
		<idno>6±3.0 62.8±0.9 59.3±1.3 52.5±1.7 66.2±1.6 62.7±2.1 58.9±2.5 52.4±1.2 58.8</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>✗ ✓ ✓ ✗ 60</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
	<note>7±1.9 63.1±0.6 58.2±1.9 50.5±1.1 66.7±1.7 66.1±0.8 61.6±0.8 56.6±1.3</note>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>✓ ✗ ✗ ✗ 55</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>1±3.1 59.5±2.1 47.9±3.3 52.6±3.4 61.2±1.4 59.9±3.0 56.4±4.4 45.9±0.9 54.8</note>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✗ ✓ ✗</forename></persName>
		</author>
		<idno>53.9±1.5 61.7±2.4 51.1±2.5 51.4±0.9 62.9±1.8 62.5±0.5 60.9±1.2 49.8±2.3 56.8</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>✓ ✗ ✓ ✓ 53</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>5±2.8 62.8±2.3 52.2±2.1 52.8±1.3 61.9±2.6 61.6±1.8 57.9±4.2 48.7±4.0 56.4</note>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✓ ✓ ✗</forename></persName>
		</author>
		<idno>58.4±2.2 65.0±1.0 55.5±3.0 52.6±2.5 66.3±1.6 62.6±1.4 64.7±1.2 53.4±1.3 59.8</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✓ ✓ ✓</forename></persName>
		</author>
		<idno>59.1±2.1 63.0±2.4 54.5±2.4 52.0±2.9 63.9±1.5 64.1±1.7 61.2±1.3 51.0±2.1 58.6 LOW-RESOURCE: 500 SENTENCES</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✗ ✓ ✗ ✗</forename></persName>
		</author>
		<idno>69.3±0.7 78.0±0.8 73.0±1.9 65.3±0.7 80.4±0.7 76.0±0.5 76.2±0.8 66.8±0.8 73.1</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✗ ✓ ✓ ✗</forename></persName>
		</author>
		<idno>73.0±2.0 79.5±0.8 74.2±0.6 67.4±0.6 81.1±0.9 77.8±0.8 77.4±0.4 69.2±1.1 75.0</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>✓ ✗ ✓ ✗ 74</surname></persName>
		</author>
		<idno>1±1.0 79.1±0.3 76.3±0.6 67.5±0.3 80.7±0.6 80.0±0.3 79.3±1.5 71.6±0.6 76.1</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✗ ✓ ✓</forename></persName>
		</author>
		<idno>73.6±0.5 78.5±1.2 75.5±1.0 68.1±0.5 81.5±1.2 80.3±0.8 78.9±1.5 72.1±0.4 76.1</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✓ ✓ ✗</forename></persName>
		</author>
		<idno>74.5±0.4 80.3±0.6 76.7±0.6 70.3±1.2 82.6±0.4 81.5±0.9 80.5±1.0 72.9±0.9 77.4</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✓ ✓ ✓</forename></persName>
		</author>
		<idno>74.2±0.7 80.2±1.0 75.8±1.0 69.4±0.1 83.9±1.0 81.7±0.8 79.4±0.7 72.4±1.3 77.1 LOW-RESOURCE: 1000 SENTENCES</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✗ ✓ ✗ ✗</forename></persName>
		</author>
		<idno>76.9±0.6 80.7±0.7 77.0±0.5 69.4±0.1 84.2±0.7 78.0±0.5 81.4±0.4 75.5±0.6 77.9</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✗ ✗ ✗</forename></persName>
		</author>
		<idno>75.3±0.7 82.7±0.5 76.9±0.5 72.5±1.4 85.9±0.4 82.4±0.6 82.0±0.4 73.4±0.4 78.9</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✗ ✓ ✓</forename></persName>
		</author>
		<idno>78.7±0.8 84.7±1.1 79.4±0.4 73.7±0.1 86.8±0.2 84.1±0.1 84.8±0.4 78.3±0.4 81.3</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>✓ ✓ ✓ ✓ 79</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>4±0.6 84.8±0.4 80.2±0.6 74.3±0.2 87.1±0.8 84.3±0.5 84.6±0.5 79.2±0.5 81.7 RICH-RESOURCE</note>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✗ ✓ ✗ ✗</forename></persName>
		</author>
		<idno>82.8±0.3 85.8±0.5 81.0±0.6 78.4±0.1 87.1±0.5 82.9±0.7 86.2±0.4 82.8±0.5 83.4</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✗ ✓ ✓ ✗</forename></persName>
		</author>
		<idno>85.2±0.5 87.9±0.2 83.0±0.1 81.1±0.2 89.0±0.4 85.8±0.4 88.8±0.4 84.6±0.3 85.7</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>✓ ✗ ✗ ✗ 80</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>3±0.4 87.1±0.4 84.2±0.4 81.2±0.1 88.8±0.2 87.8±0.4 87.6±0.6 81.3±0.5 84.8</note>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✗ ✓ ✗</forename></persName>
		</author>
		<idno>84.2±0.3 88.0±0.3 84.7±0.3 82.3±0.3 89.1±0.4 87.9±0.4 89.7±0.6 84.9±0.2 86.3</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✗ ✓ ✓</forename></persName>
		</author>
		<idno>84.0±0.4 87.9±0.4 85.0±0.4 82.2±0.2 89.3±0.5 87.6±0.4 89.6±0.5 85.0±0.3 86.3</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>✓ ✓ ✓ ✗ 85</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
	<note>1±0.4 89.6±0.0 85.5±0.6 82.9±0.1 90.6±0.3 88.6±0.4 90.8±0.1 86.1±0.4</note>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✓ ✓ ✓</forename></persName>
		</author>
		<idno>85.0±0.4 89.3±0.2 85.8±0.1 82.8±0.2 91.0±0.3 88.7±0.3 90.4±0.3 86.0±0.3 87.4 LOW-RESOURCE: 10 SENTENCES</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✗ ✓ ✗ ✗</forename></persName>
		</author>
		<idno>86.4±0.3 83.0±0.4 83.4±0.6 79.5±0.1 88.7±0.1 85.5±0.2 72.1±0.5 72.5±0.4 81.4</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✗ ✓ ✓ ✗</forename></persName>
		</author>
		<idno>87.1±0.1 82.5±0.2 83.1±0.3 80.2±0.1 88.8±0.1 86.2±0.2 72.1±0.6 73.2±0.2 81.7</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✗ ✗ ✗</forename></persName>
		</author>
		<idno>80.7±0.7 71.0±1.3 73.4±1.1 72.5±0.1 78.5±1.2 76.4±0.7 62.8±1.3 61.7±1.6 72.1</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✗ ✓ ✗</forename></persName>
		</author>
		<idno>82.4±0.9 74.4±0.8 75.1±0.9 73.7±0.1 80.2±0.9 78.5±0.5 65.0±0.9 65.0±1.4 74.3</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✗ ✓ ✓</forename></persName>
		</author>
		<idno>82.6±0.6 74.7±0.3 75.9±0.4 73.9±0.4 81.4±0.8 78.3±0.9 64.5±0.9 66.4±1.4 74.7</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✓ ✓ ✗</forename></persName>
		</author>
		<idno>86.6±0.2 80.8±0.2 81.8±0.2 77.9±0.0 86.9±0.4 82.6±0.7 72.1±0.8 73.5±0.7 80.3</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✓ ✓ ✓</forename></persName>
		</author>
		<idno>86.8±0.2 81.1±0.2 81.9±0.2 77.9±0.2 86.9±0.3 82.6±0.5 72.1±0.9 73.5±0.4 80.4 LOW-RESOURCE: 50 SENTENCES</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✗ ✓ ✗ ✗</forename></persName>
		</author>
		<idno>91.9±0.1 91.1±0.2 91.4±0.1 88.6±0.1 93.3±0.0 92.2±0.1 83.3±0.1 85.9±0.3 89.7</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✗ ✓ ✓ ✗</forename></persName>
		</author>
		<idno>92.3±0.1 91.6±0.1 91.3±0.2 88.8±0.0 93.6±0.1 92.3±0.1 84.0±0.2 86.7±0.3 90.1</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✗ ✗ ✗</forename></persName>
		</author>
		<idno>87.7±0.3 83.9±1.3 83.5±0.5 82.2±0.2 87.9±0.3 86.0±0.5 71.9±0.8 76.9±0.4 82.5</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✗ ✓ ✗</forename></persName>
		</author>
		<idno>89.3±0.3 86.3±0.4 85.5±0.8 83.9±0.1 89.5±0.7 88.1±0.5 75.1±1.0 81.0±0.7 84.8</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✗ ✓ ✓</forename></persName>
		</author>
		<idno>89.6±0.1 86.5±1.1 86.0±0.7 84.1±0.2 90.0±0.5 88.4±0.3 75.1±0.7 81.4±0.5 85.1</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✓ ✓ ✗</forename></persName>
		</author>
		<idno>91.6±0.1 91.1±0.3 90.8±0.2 87.5±0.2 92.5±0.3 91.7±0.1 82.7±0.1 87.0±0.2 89.3</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✓ ✓ ✓</forename></persName>
		</author>
		<idno>91.6±0.1 91.1±0.3 91.0±0.2 87.5±0.1 92.5±0.2 91.8±0.2 82.8±0.5 86.9±0.2 89.4 LOW-RESOURCE: 100 SENTENCES</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>✗ ✓ ✗ ✗ 93</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>5±0.1 93.6±0.1 92.2±0.1 90.2±0.1 94.2±0.0 94.4±0.1 88.2±0.2 88.5±0.7 91.8</note>
</biblStruct>

<biblStruct xml:id="b88">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>✗ ✓ ✓ ✗ 93</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">92</biblScope>
		</imprint>
	</monogr>
	<note>7±0.1 93.9±0.1 92.2±0.0 90.6±0.1 94.6±0.1 94.5±0.2 89.1±0.1 89.3±0.1</note>
</biblStruct>

<biblStruct xml:id="b89">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✗ ✗ ✗</forename></persName>
		</author>
		<idno>90.4±0.0 88.8±0.2 85.9±0.5 85.7±0.1 90.4±0.2 90.2±0.4 77.9±0.8 81.9±0.4 86.4</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✗ ✓ ✗</forename></persName>
		</author>
		<idno>91.8±0.1 90.6±0.2 87.5±0.3 87.4±0.1 92.1±0.3 91.7±0.3 81.0±1.7 85.7±0.4 88.5</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✗ ✓ ✓</forename></persName>
		</author>
		<idno>91.9±0.1 90.9±0.1 87.8±0.2 87.7±0.1 92.1±0.3 91.8±0.2 81.9±1.7 85.9±0.5 88.8</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✓ ✓ ✗</forename></persName>
		</author>
		<idno>93.6±0.1 93.6±0.1 92.0±0.3 90.4±0.1 94.3±0.2 94.3±0.3 87.8±0.2 89.7±0.2 92.0</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✓ ✓ ✓</forename></persName>
		</author>
		<idno>93.6±0.1 93.6±0.1 91.9±0.1 90.3±0.0 94.4±0.1 94.3±0.1 87.8±0.5 89.8±0.3 91.9 LOW-RESOURCE: 500 SENTENCES</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✗ ✓ ✗ ✗</forename></persName>
		</author>
		<idno>95.2±0.0 96.0±0.1 94.3±0.1 92.7±0.1 95.9±0.1 97.0±0.1 93.0±0.2 92.2±0.3 94.5</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✗ ✓ ✓ ✗</forename></persName>
		</author>
		<idno>95.3±0.0 96.3±0.1 94.4±0.0 92.8±0.0 96.0±0.0 97.4±0.1 93.2±0.2 92.3±0.6 94.7</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>✓ ✗ ✗ ✗ 93</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>5±0.1 92.7±0.1 90.2±0.1 90.0±0.1 93.9±0.1 95.6±0.1 90.3±0.2 86.9±0.1 91.6</note>
</biblStruct>

<biblStruct xml:id="b97">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>✓ ✗ ✓ ✗ 94</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>5±0.1 94.7±0.1 91.5±0.1 91.8±0.1 95.1±0.1 96.7±0.1 91.6±0.1 89.9±0.2 93.2</note>
</biblStruct>

<biblStruct xml:id="b98">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✗ ✓ ✓</forename></persName>
		</author>
		<idno>94.7±0.1 94.9±0.1 91.6±0.1 92.0±0.0 95.2±0.1 96.9±0.1 91.8±0.1 89.7±0.6 93.4</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✓ ✓ ✗</forename></persName>
		</author>
		<idno>95.5±0.1 96.1±0.1 94.0±0.1 93.0±0.0 96.1±0.1 97.5±0.0 93.4±0.1 92.6±0.4 94.8</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✓ ✓ ✓</forename></persName>
		</author>
		<idno>95.5±0.0 96.2±0.1 94.0±0.1 93.0±0.1 96.0±0.2 97.5±0.0 93.4±0.1 92.6±0.3 94.8 LOW-RESOURCE: 1000 SENTENCES</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✗ ✓ ✗ ✗</forename></persName>
		</author>
		<idno>95.7±0.0 96.8±0.1 94.7±0</idno>
		<imprint/>
	</monogr>
	<note>1 93.6±0.1 96.2±0.0 97.5±0.1 94.5±0.2 92.3±0.2 95.2 2. ✗ ✓ ✓ ✗ 95.8±0.0 97.0±0.1 94.6±0.1 94.0±0.1 96.3±0.1 98.0±0.0 94.8±0.0 92.4±0.2 95.4</note>
</biblStruct>

<biblStruct xml:id="b102">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✗ ✗ ✗</forename></persName>
		</author>
		<idno>94.3±0.0 93.9±0.1 91.2±0.1 91.7±0.1 94.7±0.0 96.8±0.1 92.5±0.1 87.1±0.2 92.8</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✗ ✓ ✗</forename></persName>
		</author>
		<idno>95.1±0.1 95.8±0.0 92.5±0.1 93.4±0.0 96.0±0.1 97.6±0.0 94.0±0.1 89.7±0.3 94.3</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>✓ ✗ ✓ ✓ 95</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>2±0.0 96.1±0.1 92.6±0.1 93.5±0.1 96.0±0.1 97.6±0.1 94.2±0.1 89.8±0.5 94.4</note>
</biblStruct>

<biblStruct xml:id="b105">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✓ ✓ ✗</forename></persName>
		</author>
		<idno>95.9±0.0 97.0±0.1 94.6±0.1 94.4±0.1 96.6±0.1 98.2±0.1 95.0±0.0 92.9±0.2 95.6</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>✓ ✓ ✓ ✓ 95</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>9±0.0 97.0±0.0 94.7±0.1 94.4±0.1 96.6±0.1 98.1±0.1 95.0±0.0 92.6±0.5 95.5 RICH-RESOURCE</note>
</biblStruct>

<biblStruct xml:id="b107">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✗ ✓ ✗ ✗</forename></persName>
		</author>
		<idno>96.7±0.1 98.6±0.1 94.9±0.1 96.3±0.0 97.0±0.1 98.6±0.1 96.3±0.0 91.9±0.4 96.3</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✗ ✓ ✓ ✗</forename></persName>
		</author>
		<idno>96.9±0.0 98.6±0.0 95.0±0.1 96.7±0.0 97.1±0.1 98.9±0.0 96.7±0.0 92.4±0.5 96.5</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✗ ✗ ✗</forename></persName>
		</author>
		<idno>96.3±0.0 97.8±0.0 94.9±0.1 95.8±0.0 96.6±0.1 98.4±0.1 95.5±0.1 86.9±0.2 95.3</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✗ ✓ ✗</forename></persName>
		</author>
		<idno>96.7±0.0 98.6±0.1 95.2±0.1 96.6±0.0 97.0±0.1 98.9±0.0 96.2±0.1 89.9±0.3 96.1</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✗ ✓ ✓</forename></persName>
		</author>
		<idno>96.8±0.0 98.6±0.0 95.2±0.1 96.7±0.0 97.1±0.1 99.0±0.1 96.3±0.1 90.1±0.2 96.2</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✓ ✓ ✗</forename></persName>
		</author>
		<idno>96.9±0.0 98.8±0.0 95.3±0.1 97.0±0.1 97.3±0.0 99.1±0.1 96.7±0.1 92.6±0.4 96.7</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b113">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✓ ✓ ✓</forename></persName>
		</author>
		<idno>97.0±0.1 98.8±0.0 95.4±0.1 97.0±0.1 97.3±0.1 99.1±0.1 96.7±0.1 92.5±0.4 96.7</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b114">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✗ ✓ ✗ ✗</forename></persName>
		</author>
		<idno>85.5±0.3 81.6±0.8 82.9±0.2 77.1±0.0 87.9±0.3 84.9±0.7 70.7±0.7 71.5±0.8 80.2 2. ✗ ✓ ✓ ✗ 86.3±0.5 82.0±0.2 82.5±0.4 78.9±0.4 88.2±0.3 85.2±0.4 70.5±1.1 72.6±0.5 80.8</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b115">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✗ ✓ ✗</forename></persName>
		</author>
		<idno>81.7±0.4 74.2±0.8 74.2±0.8 70.9±0.4 80.7±0.3 77.8±0.7 62.7±0.7 66.4±1.2 73.6</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b116">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✗ ✓ ✓</forename></persName>
		</author>
		<idno>82.0±0.5 74.0±0.8 73.9±0.8 70.6±1.9 81.0±0.4 78.5±0.5 63.6±1.2 66.4±1.2 73.7</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b117">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✓ ✓ ✗</forename></persName>
		</author>
		<idno>85.8±0.5 79.5±0.4 80.8±0.5 75.3±0.4 86.6±0.2 82.2±0.4 70.3±0.8 72.5±0.4 79.1</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b118">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✓ ✓ ✓</forename></persName>
		</author>
		<idno>85.9±0.4 80.0±0.1 80.5±0.7 74.7±0.1 86.4±0.4 82.4±0.9 70.7±0.3 72.8±0.5 79.2 LOW-RESOURCE: 50 SENTENCES</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b119">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✗ ✓ ✗ ✗</forename></persName>
		</author>
		<idno>91.7±0.2 90.5±0.1 90.9±0.3 87.6±0.2 93.0±0.1 91.6±0.3 81.8±0.7 85.6±0.5 89.1</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b120">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>✗ ✓ ✓ ✗ 91</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>9±0.2 91.2±0.2 90.8±0.1 87.9±0.3 93.5±0.1 91.8±0.2 83.2±0.4 86.5±0.3 89.6</note>
</biblStruct>

<biblStruct xml:id="b121">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✗ ✗ ✗</forename></persName>
		</author>
		<idno>87.4±0.4 84.2±0.7 83.6±0.2 80.1±0.4 88.3±0.5 86.4±0.4 72.6±0.3 76.1±0.7 82.3</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b122">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✗ ✓ ✗</forename></persName>
		</author>
		<idno>89.4±0.4 86.3±0.3 85.3±0.9 81.0±0.1 89.7±0.4 88.4±1.0 74.2±1.6 80.3±0.3 84.3</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b123">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>✓ ✗ ✓ ✓ 89</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>4±0.4 86.6±0.6 85.0±0.6 81.5±0.6 89.6±0.3 88.1±0.5 75.1±0.6 80.7±0.6 84.5</note>
</biblStruct>

<biblStruct xml:id="b124">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>✓ ✓ ✓ ✗ 91</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>5±0.2 90.7±0.1 90.2±0.3 85.7±0.1 92.8±0.5 91.2±0.5 82.1±0.6 86.5±0.3 88.8</note>
</biblStruct>

<biblStruct xml:id="b125">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✓ ✓ ✓</forename></persName>
		</author>
		<idno>91.5±0.1 90.7±0.5 90.3±0.3 85.3±0.1 92.4±0.2 91.9±0.6 82.5±0.2 86.0±0.7 88.8 LOW-RESOURCE: 100 SENTENCES</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b126">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>✗ ✓ ✗ ✗ 93</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>3±0.1 93.5±0.2 92.0±0.3 89.8±0.1 94.0±0.1 94.2±0.2 87.4±0.3 88.3±0.4 91.6</note>
</biblStruct>

<biblStruct xml:id="b127">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✗ ✓ ✓ ✗</forename></persName>
		</author>
		<idno>93.6±0.1 93.6±0.1 91.8±0.3 90.0±0.1 94.5±0.1 94.5±0.1 88.5±0.1 88.7±0.3 91.9</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b128">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>✓ ✗ ✗ ✗ 90</surname></persName>
		</author>
		<idno>2±0.2 88.4±0.1 85.2±0.3 84.6±0.2 90.5±0.2 90.0±0.3 78.0±0.7 80.8±0.3 86.0</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b129">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✗ ✓ ✗</forename></persName>
		</author>
		<idno>91.6±0.1 90.6±0.1 87.4±0.3 85.5±0.1 92.5±0.5 91.7±0.2 81.7±0.6 85.2±0.4 88.3</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b130">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>✓ ✗ ✓ ✓ 91</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>8±0.1 91.1±0.5 87.4±0.4 86.1±0.1 92.2±0.1 92.1±0.8 81.2±1.1 85.5±0.2 88.4</note>
</biblStruct>

<biblStruct xml:id="b131">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>✓ ✓ ✓ ✗ 93</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>5±0.2 93.7±0.3 91.4±0.2 89.4±0.6 94.3±0.2 94.2±0.2 86.9±0.3 89.6±0.4 91.6</note>
</biblStruct>

<biblStruct xml:id="b132">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✓ ✓ ✓</forename></persName>
		</author>
		<idno>93.6±0.1 93.7±0.3 91.7±0.2 89.3±0.6 94.4±0.1 94.3±0.3 87.0±0.8 89.4±0.2 91.7 LOW-RESOURCE: 500 SENTENCES</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b133">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✗ ✓ ✗ ✗</forename></persName>
		</author>
		<idno>95.2±0.1 96.1±0.1 94.1±0.1 92.6±0.1 95.9±0.0 97.0±0.1 92.8±0.2 91.9±0.4 94.4</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b134">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>✗ ✓ ✓ ✗ 95</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>3±0.1 96.3±0.1 94.3±0.1 92.6±0.1 95.9±0.1 97.2±0.1 93.3±0.1 92.5±0.2 94</note>
</biblStruct>

<biblStruct xml:id="b135">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✗ ✗ ✗</forename></persName>
		</author>
		<idno>93.4±0.1 92.6±0.0 89.6±0.2 89.7±0.0 93.8±0.2 95.5±0.1 89.5±0.2 86.5±0.2 91.3</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b136">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✗ ✓ ✗</forename></persName>
		</author>
		<idno>94.5±0.2 94.7±0.2 91.4±0.1 91.0±0.0 95.1±0.1 96.7±0.0 91.3±0.2 89.9±0.3 93.1</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b137">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✗ ✓ ✓</forename></persName>
		</author>
		<idno>94.8±0.1 95.0±0.2 91.5±0.1 91.1±0.1 95.2±0.1 97.0±0.1 91.6±0.1 90.0±0.4 93.3</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b138">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✓ ✓ ✗</forename></persName>
		</author>
		<idno>95.5±0.0 96.2±0.1 93.8±0.1 92.7±0.1 95.9±0.2 97.5±0.1 93.3±0.1 92.3±0.2 94.7</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b139">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>✓ ✓ ✓ ✓ 95</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>5±0.1 96.1±0.1 93.9±0.1 92.8±0.1 96.2±0.1 97.4±0.1 93.3±0.2 92.7±0.2 94</note>
</biblStruct>

<biblStruct xml:id="b140">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✗ ✓ ✗ ✗</forename></persName>
		</author>
		<idno>95.6±0.0 96.8±0.0 94.6±0.1 93.5±0.1 96.3±0.1 97.5±0.1 94.5±0.1 92.0±0.5 95.1</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b141">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✗ ✓ ✓ ✗</forename></persName>
		</author>
		<idno>95.8±0.1 96.9±0.0 94.5±0.0 93.8±0.1 96.3±0.1 97.9±0.1 94.8±0.1 91.9±0.4 95.2</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b142">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>✓ ✗ ✗ ✗ 94</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>2±0.1 93.9±0.1 90.9±0.2 91.4±0.0 94.7±0.1 96.7±0.2 92.5±0.1 86.4±0.3 92.6</note>
</biblStruct>

<biblStruct xml:id="b143">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✗ ✓ ✗</forename></persName>
		</author>
		<idno>95.1±0.0 95.9±0.1 92.3±0.1 92.8±0.0 95.9±0.2 97.6±0.2 93.9±0.1 89.7±0.4 94.2</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b144">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>✓ ✗ ✓ ✓ 95</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>2±0.1 96.1±0.1 92.5±0.2 93.3±0.1 96.1±0.1 97.5±0.1 94.0±0.1 89.8±0.4 94.3</note>
</biblStruct>

<biblStruct xml:id="b145">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>✓ ✓ ✓ ✗ 95</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>9±0.0 96.9±0.1 94.4±0.2 94.2±0.2 96.5±0.1 98.1±0.1 95.0±0.1 92.7±0.2 95.5</note>
</biblStruct>

<biblStruct xml:id="b146">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>✓ ✓ ✓ ✓ 95</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>9±0.1 97.0±0.0 94.5±0.1 94.1±0.1 96.5±0.0 98.1±0.1 95.0±0.1 92.5±0.3 95.5 RICH-RESOURCE</note>
</biblStruct>

<biblStruct xml:id="b147">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✗ ✓ ✗ ✗</forename></persName>
		</author>
		<idno>96.7±0.0 98.6±0.0 95.0±0.1 96.4±0.1 97.0±0.0 98.5±0.1 96.3±0.0 92.1±0.5 96.3</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b148">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✗ ✓ ✓ ✗</forename></persName>
		</author>
		<idno>96.9±0.0 98.7±0.0 95.0±0.1 96.7±0.1 97.1±0.0 98.9±0.0 96.6±0.0 92.4±0.4 96.5</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b149">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✗ ✗ ✗</forename></persName>
		</author>
		<idno>96.3±0.0 97.8±0.0 94.9±0.0 95.8±0.1 96.6±0.1 98.4±0.1 95.4±0.1 86.7±0.3 95.2</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b150">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✗ ✓ ✗</forename></persName>
		</author>
		<idno>96.7±0.0 98.6±0.0 95.3±0.1 96.6±0.1 97.0±0.1 99.0±0.0 96.2±0.1 89.8±0.3 96.1</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b151">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✗ ✓ ✓</forename></persName>
		</author>
		<idno>96.8±0.1 98.6±0.0 95.1±0.0 96.7±0.0 97.0±0.1 99.0±0.1 96.3±0.1 90.0±0.6 96.2</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b152">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✓ ✓ ✗</forename></persName>
		</author>
		<idno>97.0±0.0 98.8±0.0 95.4±0.1 97.0±0.0 97.3±0.1 99.1±0.1 96.7±0.1 92.7±0.3 96.7</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b153">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">✓ ✓ ✓ ✓</forename></persName>
		</author>
		<idno>97.0±0.0 98.8±0.0 95.4±0.1 97.1±0.0 97.3±0.1 99.1±0.0 96.7±0.1 92.6±0.1 96.7</idno>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
