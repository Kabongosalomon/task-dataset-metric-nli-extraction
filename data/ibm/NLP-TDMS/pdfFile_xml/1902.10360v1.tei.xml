<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">AN EDITORIAL NETWORK FOR ENHANCED DOCUMENT SUMMARIZATION</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2019-02-27">27 Feb 2019 February 28, 2019</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Moroshko</surname></persName>
							<email>edward.moroshko@gmail.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guy</forename><surname>Feigenblat</surname></persName>
							<email>guyf@il.ibm.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haggai</forename><surname>Roitman</surname></persName>
							<email>haggai@il.ibm.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Konopnicki</surname></persName>
							<email>davidko@il.ibm.com</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Electrical Engineering Dept</orgName>
								<orgName type="institution">Technion -Israel Institute of Technology Haifa</orgName>
								<address>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">IBM Research Haifa University</orgName>
								<address>
									<addrLine>Campus Haifa</addrLine>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">AN EDITORIAL NETWORK FOR ENHANCED DOCUMENT SUMMARIZATION</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2019-02-27">27 Feb 2019 February 28, 2019</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T11:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We suggest a new idea of Editorial Network -a mixed extractive-abstractive summarization approach, which is applied as a post-processing step over a given sequence of extracted sentences. Our network tries to imitate the decision process of a human editor during summarization. Within such a process, each extracted sentence may be either kept untouched, rephrased or completely rejected. We further suggest an effective way for training the "editor" based on a novel soft-labeling approach. Using the CNN/DailyMail dataset we demonstrate the effectiveness of our approach compared to state-of-the-art extractive-only or abstractive-only baseline methods. * Work was done during a summer internship in IBM Research.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Automatic text summarizers condense a given piece of text into a shorter version (the summary). This is done while trying to preserve the main essence of the original text and keeping the generated summary as readable as possible.</p><p>Existing summarization methods can be classified into two main types, either extractive or abstractive <ref type="bibr" target="#b7">[8]</ref>. Extractive methods select and order text fragments (e.g., sentences) from the original text source <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b28">29]</ref>. Such methods are relatively simpler to develop and keep the extracted fragments untouched, allowing to preserve important parts, e.g., keyphrases, facts, opinions, etc. Yet, extractive summaries tend to be less fluent, coherent and readable and may include superfluous text.</p><p>Abstractive methods apply natural language paraphrasing and/or compression on a given text. A common approach is based on the encoder-decoder (seq-to-seq) paradigm <ref type="bibr" target="#b23">[24]</ref>, with the original text sequence being encoded while the summary is the decoded sequence. While such methods usually generate summaries with better readability, their quality declines over longer textual inputs, which may lead to higher redundancy <ref type="bibr" target="#b21">[22]</ref>. Moreover, such methods are sensitive to vocabulary size, making them more difficult to train and generalize <ref type="bibr" target="#b22">[23]</ref>.</p><p>A common approach for handling long text sequences in abstractive settings is through attention mechanisms, which aim to imitate the attentive reading behaviour of humans <ref type="bibr" target="#b2">[3]</ref>. Two main types of attention methods may be utilized, either soft or hard. Soft attention methods first locate salient text regions within the input text and then bias the abstraction process to prefer such regions during decoding <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b24">25]</ref>. On the other hand, hard attention methods perform abstraction only on text regions that were initially selected by some extraction process <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b16">17]</ref>.</p><p>Compared to previous works, whose final summary is either entirely extracted or generated using an abstractive process, in this work, we suggest a new idea of "Editorial Network" (EditNet) -a mixed extractive-abstractive summarization approach. A summary generated by EditNet may include sentences that were either extracted, abstracted or of both types. Moreover, per considered sentence, EditNet may decide not to take either of these decisions and completely reject the sentence.  Using the CNN/DailyMail dataset we demonstrate that, EditNet's summarization quality transcends that of state-ofthe-art abstractive-only baselines. EditNet's summarization quality is also demonstrated to be highly competitive with that of NeuSum <ref type="bibr" target="#b29">[30]</ref>, which is, to the best of our knowledge, the best performing extractive-only baseline. Yet, while EditNet obtains (more or less) a similar summarization quality to that of NeuSum, compared to the latter which applies only extraction, the former (on average) applies abstraction to the majority of each summary's extracted sentences. <ref type="figure">Figure 1</ref> now depicts the architecture of our proposed Editorial Network-based approach. We apply this approach as a post-processing step over a given summary whose sentences were selected by some extractor. The key idea is to try to imitate the decision process of a human editor who needs to edit the summary so as to enhance its quality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Editorial Network</head><p>Let S denote a summary which was extracted from a given text (document) D. The editorial process is implemented by iterating over sentences in S according to the selection order of the extractor. For each sentence in S, the "editor" may make three possible decisions. The first decision is to keep the extracted sentence untouched (represented by label E in <ref type="figure">Figure 1</ref>). The second alternative is to rephrase the sentence (represented by label A in <ref type="figure">Figure 1</ref>). Such a decision, for example, may represent the editor's wish to simplify or compress the original source sentence. The last possible decision is to completely reject the sentence (represented by label R in <ref type="figure">Figure 1</ref>). For example, the editor may wish to ignore a superfluous or duplicate information expressed in the current sentence. An example mixed summary generated by our approach is depicted in <ref type="figure" target="#fig_1">Figure 2</ref>, further emphasizing the various editor's decisions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Implementing the editor's decisions</head><p>For a given sentence s ∈ D, we now denote by s e and s a its original (extracted) and paraphrased (abstracted) versions. To obtain s a we use an abstractor, whose details will be shortly explained (see Section 2.2). Let e s ∈ R n and a s ∈ R n further denote the corresponding sentence representations of s e and s a , respectively. Such representations allow to compare both sentence versions on the same grounds.</p><p>Recall that, for each sentence s i ∈ S (in order) the editor makes one of the three possible decisions: extract, abstract or reject s i . Therefore, the editor may modify summary S by paraphrasing or rejecting some of its sentences, resulting in a mixed extractive-abstractive summary S ′ .</p><p>Editor's automatic summary: E: what was supposed to be a fantasy sports car ride at walt disney world speedway turned deadly when a lamborghini crashed into a guardrail. A: the crash took place sunday at the exotic driving experience a . A: the lamborghini 's passenger , gary terry , died at the scene b . R: petty holdings , which operates the exotic driving experience at walt disney world speedway , released a statement sunday night about the crash. a Original extracted sentence: "the crash took place sunday at the exotic driving experience , which bills itself as a chance to drive your dream car on a racetrack". b Original extracted sentence: "the lamborghini 's passenger , 36-year-old gary terry of davenport , florida , died at the scene , florida highway patrol said" Ground truth summary: the crash occurred at the exotic driving experience at walt disney world speedway. officials say the driver , 24-year-old tavon watson , lost control of a lamborghini. passenger gary terry , 36 , died at the scene. Following <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b26">27]</ref>, d is then calculated as follows:</p><formula xml:id="formula_0">d = tanh (W dē + b d ) ,<label>(1)</label></formula><p>where W d ∈ R n×n and b d ∈ R n are learnable parameters.</p><p>The second auxiliary representation is that of the summary that was generated by the editor so far, denoted at step i as g i−1 ∈ R n , with g 0 = 0. Such a representation provides a local context for decision making. Given the four representations as an input, the editor's decision for sentence s i ∈ S is implemented using two fully-connected layers, as follows:</p><formula xml:id="formula_1">sof tmax (V tanh (W c [e si , a si , g i−1 , d] + b c ) + b) ,<label>(2)</label></formula><p>where [·] denotes the vectors concatenation, V ∈ R 3×m , W c ∈ R m×4n , b c ∈ R m and b ∈ R 3 are learnable parameters.</p><p>In each step i, therefore, the editor chooses the action π i ∈ {E, A, R} with the highest likelihood (according to Eq. 2), further denoted p(π i ). Upon decision, in case it is either E or A, the editor appends the corresponding sentence version (i.e., either s e i or s a i ) to S ′ ; otherwise, the decision is R and sentence s i is discarded. Depending on its decision, the current summary representation is further updated as follows:</p><formula xml:id="formula_2">g i = g i−1 + tanh (W g h i ) ,<label>(3)</label></formula><p>where W g ∈ R n×n are learnable parameters, g i−1 is the summary representation from the previous decision step; and h i ∈ {e si , a si , 0}, depending on which decision is made.</p><p>Such a network architecture allows to capture various complex interactions between the different inputs. For example, the network may learn that given the global context, one of the sentence versions may allow to produce a summary with a better coverage. As another example, based on the interaction between both sentence versions with either of the local or global contexts (and possibly among the last two), the network may learn that both sentence versions may only add superfluous or redundant information to the summary, and therefore, decide to reject both.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Extractor and Abstractor</head><p>As a proof of concept, in this work, we utilize the extractor and abstractor that were previously used in <ref type="bibr" target="#b0">[1]</ref>, with a slight modification to the latter, motivated by its specific usage within our approach. We now only highlight important aspects of these two sub-components and kindly refer the reader to <ref type="bibr" target="#b0">[1]</ref> for the full implementation details.</p><p>The extractor of <ref type="bibr" target="#b0">[1]</ref> consists of two main sub-components. The first is an encoder which encodes each sentence s ∈ D into e s using an hierarchical representation 2 . The second is a sentence selector using a Pointer-Network <ref type="bibr" target="#b25">[26]</ref>. For the latter, let P (s) be the selection likelihood of sentence s.</p><p>The abstractor of <ref type="bibr" target="#b0">[1]</ref> is basically a standard encoder-aligner-decoder with a copy mechanism <ref type="bibr" target="#b22">[23]</ref>. Yet, instead of applying it directly only on a single given extracted sentence s e i ∈ S, we apply it on a "chunk" of three consecutive sentences 3 (s e − , s e i , s e + ), where s e − and s e + denote the sentence that precedes and succeeds s e i in D, respectively. This in turn, allows to generate an abstractive version of s e i (i.e., s a i ) that benefits from a wider local context. Inspired by previous soft-attention methods, we further utilize the extractor's sentence selection likelihoods P (·) for enhancing the abstractor's attention mechanism, as follows. Let C(w j ) denote the abstractor's original attention value of a given word w j occurring in (s e − , s e i , s e + ); we then recalculate this value to be C ′ (w j ) = wj ∈s ′ C(w j ) · P (s ′ ) denotes the normalization term.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Sentence representation</head><p>Recall that, in order to compare s e i with s a i , we need to represent both sentence versions on as similar grounds as possible. To achieve that, we first replace s e i with s a i within the original document D. By doing so, we basically treat sentence s a i as if it was an ordinary sentence within D, where the rest of the document remains untouched. We then obtain s a i 's representation by encoding it using the extractor's encoder in a similar way in which sentence s e i was originally supposed to be encoded. This results in a representation a si that provides a comparable alternative to e si , whose encoding is expected to be effected by similar contextual grounds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Network training</head><p>We conclude this section with the description of how we train the editor using a novel soft labeling approach. Given text S (with l extracted sentences), let π = (π 1 , . . . , π l ) denote its editing decisions sequence. We define the following "soft" cross-entropy loss:</p><formula xml:id="formula_3">L(π|S) = − 1 l si∈S πi∈{E,A,R} y(π i ) log p(π i ),<label>(4)</label></formula><p>where, for a given sentence s i ∈ S, y(π i ) denotes its soft-label for decision.</p><p>We next explain how each soft-label y(π i ) is estimated. To this end, we utilize a given summary quality metric r(S ′ ) which can be used to evaluate the quality of any given summary S ′ (e.g., ROUGE <ref type="bibr" target="#b15">[16]</ref>). Overall, for a given text input S with l sentences, there are 3 l possible summaries S ′ to consider. Let π * = (π * 1 , . . . , π * l ) denote the best decision sequence which results in the summary which maximizes r(·). For i ∈ {1, 2, . . . , l}, letr(π * 1 , . . . , π * i−1 , π i ) denote the average r(·) value obtained by decision sequences that start with the prefix (π * 1 , . . . , π * i−1 , π i ). Based on π * , the soft label y(π i ) is then calculated 4 as follows:</p><p>y(π i ) =r (π * 1 , . . . , π * i−1 , π i ) πj ∈{E,A,R}r (π * 1 , . . . , π * i−1 , π j )</p><p>3 Evaluation</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Dataset and Setup</head><p>We trained, validated and tested our approach using the non-annonymized version of the CNN/DailyMail dataset <ref type="bibr" target="#b10">[11]</ref>. Following <ref type="bibr" target="#b18">[19]</ref>, we used the story highlights associated with each article as its ground truth summary. We further used the F-measure versions of ROUGE-1 (R-1), ROUGE-2 (R-2) and ROUGE-L (R-L) as our evaluation metrics <ref type="bibr" target="#b15">[16]</ref>.</p><p>The extractor and abstractor were trained similarly to <ref type="bibr" target="#b0">[1]</ref> (including the same hyperparameters). The Editorial Network (hereinafter denoted EditNet) was trained according to Section 2.4, using the ADAM optimizer with a learning rate of 10 −4 and a batch size of 32. To speedup the training time, we precalculated the soft labels (see Eq. 5). Following <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b26">27]</ref>, we set the reward metric to be r(·) = αR-1(·) + βR-2(·) + γR-L(·); with α = 0.4, β = 1 and γ = 0.5, which were further suggested by <ref type="bibr" target="#b26">[27]</ref>. <ref type="bibr" target="#b1">2</ref> Such a representation is basically a combination of a temporal convolutional model followed by a biLSTM encoder. <ref type="bibr" target="#b2">3</ref> The first and last chunks would only have two consecutive sentences. <ref type="bibr" target="#b3">4</ref> For i = 1 we have:r(π * 1 , . . . , π * 0 , π1) =r(π1).  <ref type="bibr" target="#b17">[18]</ref> 39.60 16.20 35.30 Refresh <ref type="bibr" target="#b19">[20]</ref> 40.00 18.20 36.60 Rnes w/o coherence <ref type="bibr" target="#b27">[28]</ref> 41. <ref type="bibr" target="#b24">25</ref> 18.87 37.75 BanditSum <ref type="bibr" target="#b5">[6]</ref> 41.50 18.70 37.60 Latent <ref type="bibr" target="#b28">[29]</ref> 41.05 18.77 37.54 rnn-ext+RL <ref type="bibr" target="#b0">[1]</ref> 41.47 18.72 37.76 NeuSum <ref type="bibr" target="#b29">[30]</ref> 41.59 19.01 37.98 Abstractive Pointer-Generator <ref type="bibr" target="#b22">[23]</ref> 39.53 17.28 36.38 KIGN+Prediction-guide <ref type="bibr" target="#b14">[15]</ref> 38.95 17.12 35.68 Multi-Task(EG+QG) <ref type="bibr" target="#b9">[10]</ref> 39.81 17.64 36.54 RL+pg+cbdec <ref type="bibr" target="#b12">[13]</ref> 40.66 17.87 37.06 Saliency+Entail. <ref type="bibr" target="#b20">[21]</ref> 40.43 18.00 37.10 Inconsistency loss <ref type="bibr" target="#b11">[12]</ref> 40.68 17.97 37.13 Bottom-up <ref type="bibr" target="#b8">[9]</ref> 41.22 18.68 38.34 rnn-ext+abs+RL <ref type="bibr" target="#b0">[1]</ref> 40.04 17.61 37.59 Mixed Extractive-Abstractive EditNet 41.42 19.03 38.36</p><p>We further applied the Teacher-Forcing approach <ref type="bibr" target="#b13">[14]</ref> during training, where we considered the true-label instead of the editor's decision (including when updating g i at each step i according to Eq. 3). Following <ref type="bibr" target="#b0">[1]</ref>, we set m = 512 and n = 512. We trained for 20 epochs, which has taken about 72 hours on a single GPU. We chose the best model over the validation set for testing. Finally, all components were implemented in Python 3.6 using the pytorch 0.4.1 package. <ref type="table" target="#tab_1">Table 1</ref> compares the quality of EditNet with that of several state-of-the-art extractive-only or abstractive-only baselines. This includes the extractor (rnn-ext-RL) and abstractor (rnn-ext-abs-RL) components of [1] that we further utilized for implementing <ref type="bibr" target="#b4">5</ref> EditNet (see again Section 2.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Results</head><p>Overall, EditNet provides a highly competitive summary quality, where it outperforms all baselines in the R-2 and R-L metrics. On R-1, EditNet outperforms all abstractive baselines and almost all extractive ones. Interestingly, EditNet's summarization quality is quite similar to that of NeuSum <ref type="bibr" target="#b29">[30]</ref>. Yet, while NeuSum applies an extraction-only approach, summaries generated by EditNet include a mixture of sentences that have been either extracted or abstracted.</p><p>On average, 56% and 18% of EditNet's decisions were to abstract (A) or reject (R), respectively. Moreover, on average, per summary, EditNet keeps only 33% of the original (extracted) sentences, while the rest (67%) are abstracted ones. This demonstrates that, EditNet has a high capability of utilizing abstraction, while being also able to maintain or reject the original extracted text whenever it is estimated to provide the best benefit for the summary's quality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion and Future Work</head><p>We have shown that instead of solely applying extraction or abstraction, a better choice would be a mixed one. As future work, we plan to evaluate other alternative extractor+abstractor configurations and try to train the network end-to-end. We further plan to explore reinforcement learning (RL) as an alternative decision making approach.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Figure 1: Editorial Network</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>An example mixed summary (annotated with the editor's decisions) taken from the CNN/DM dataset Let l be the number of sentences in S. In each step i ∈ {1, 2, . . . , l}, in order to make an educated decision, the editor considers both sentence representations e si and a si as its input, together with two additional auxiliary representations. The first auxiliary representation is that of the whole document D itself, hereinafter denoted d ∈ R n . Such a representation provides a global context for decision making. Assuming document D has N sentences, letē = 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>C</head><label></label><figDesc>(wj)·P (s) Z , with w j ∈ s and s ∈ {s e − , s e i , s e + }; Z = s ′ ∈{s e − ,s e i ,s e + }</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Quality evaluation using ROUGE F-measure (ROUGE-1, ROUGE-2, ROUGE-L) on CNN/DailyMail non-</figDesc><table><row><cell>annonymized dataset</cell><cell></cell><cell></cell></row><row><cell></cell><cell>R-1</cell><cell>R-2</cell><cell>R-L</cell></row><row><cell></cell><cell>Extractive</cell><cell></cell></row><row><cell>Lead-3</cell><cell cols="3">40.00 17.50 36.20</cell></row><row><cell>SummaRuNNer</cell><cell></cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">The rnn-ext-RL extractor results reported inTable 1are the ones that were reported by<ref type="bibr" target="#b0">[1]</ref>. Training the public extractor released by these authors, we obtained the following significantly lower results: R-1:38.43, R-2:18.07 and R-L:35.37.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Fast abstractive summarization with reinforce-selected sentence rewriting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yen-Chun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="675" to="686" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Neural summarization by extracting sentences and words</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianpeng</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, ACL 2016</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics, ACL 2016<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Abstractive sentence summarization with attentive recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="93" to="98" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">and Nazli Goharian. A discourse-aware attention model for abstractive summarization of long documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arman</forename><surname>Cohan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franck</forename><surname>Dernoncourt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soon</forename><surname>Doo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trung</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seokhwan</forename><surname>Bui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Walter</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="615" to="621" />
		</imprint>
	</monogr>
	<note>Short Papers</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Using machine learning methods and linguistic features in single-document extractive summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Dlikman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Last</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">DMNLP@PKDD/ECML</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Banditsum: Extractive summarization as a contextual bandit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yikang</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Crawford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jackie Chi Kit</forename><surname>Herke Van Hoof</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cheung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-11-04" />
			<biblScope unit="page" from="3739" to="3748" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Unsupervised query-focused multidocument summarization using the cross entropy method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guy</forename><surname>Feigenblat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haggai</forename><surname>Roitman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Odellia</forename><surname>Boni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Konopnicki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th International ACM SIGIR Conference on Research &amp; Development in Information Retrieval, SIGIR &apos;17</title>
		<meeting>the 37th International ACM SIGIR Conference on Research &amp; Development in Information Retrieval, SIGIR &apos;17</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Recent automatic text summarization techniques: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mahak</forename><surname>Gambhir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vishal</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artif. Intell. Rev</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="66" />
			<date type="published" when="2017-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Bottom-up abstractive summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Gehrmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuntian</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Rush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4098" to="4109" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Soft layer-specific multi-task summarization with entailment and question generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramakanth</forename><surname>Pasunuru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="687" to="697" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Teaching machines to read and comprehend</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Moritz Hermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomáš</forename><surname>Kočiský</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lasse</forename><surname>Espeholt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Kay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mustafa</forename><surname>Suleyman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Neural Information Processing Systems</title>
		<meeting>the 28th International Conference on Neural Information Processing Systems<address><addrLine>Cambridge, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1693" to="1701" />
		</imprint>
	</monogr>
	<note>NIPS&apos;15</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A unified model for extractive and abstractive summarization using inconsistency loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wan-Ting</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chieh-Kai</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Ying</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kerui</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="132" to="141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Closed-book training to improve summarization encoder memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4067" to="4077" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Professor forcing: A new algorithm for training recurrent networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex M</forename><surname>Lamb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anirudh</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alias</forename><surname>Parth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saizheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Aaron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances In Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4601" to="4609" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Guiding generation for abstractive text summarization based on key information guide network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenliang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiran</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Si</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="55" to="60" />
		</imprint>
	</monogr>
	<note>Short Papers</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Rouge: A package for automatic evaluation of summaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Text summarization branches out: Proceedings of the ACL-04 workshop</title>
		<meeting><address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">8</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Etienne</forename><surname>Saleh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Pot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Goodrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Sepassi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shazeer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.10198</idno>
		<title level="m">Generating wikipedia by summarizing long sequences</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Summarunner: A recurrent neural network based sequence model for extractive summarization of documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramesh</forename><surname>Nallapati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feifei</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence</title>
		<meeting>the Thirty-First AAAI Conference on Artificial Intelligence<address><addrLine>San Francisco, California, USA.</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3075" to="3081" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Abstractive text summarization using sequence-to-sequence rnns and beyond</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramesh</forename><surname>Nallapati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cícero</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Çaglar</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Gülçehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th SIGNLL Conference on Computational Natural Language Learning</title>
		<meeting>the 20th SIGNLL Conference on Computational Natural Language Learning<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-08-11" />
			<biblScope unit="page" from="280" to="290" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Ranking sentences for extractive summarization with reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shashi</forename><surname>Narayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shay</forename><forename type="middle">B</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2018</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2018<address><addrLine>New Orleans, Louisiana, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1747" to="1759" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Multi-reward reinforced summarization with saliency and entailment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramakanth</forename><surname>Pasunuru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="646" to="653" />
		</imprint>
	</monogr>
	<note>Short Papers. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">A deep reinforced model for abstractive summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Romain</forename><surname>Paulus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<idno>abs/1705.04304</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Get to the point: Summarization with pointer-generator networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abigail</forename><surname>See</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2017-07-30" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1073" to="1083" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Neural Information Processing Systems</title>
		<meeting>the 27th International Conference on Neural Information Processing Systems<address><addrLine>Cambridge, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Abstractive document summarization with a graph-based attentional neural model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianguo</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1171" to="1181" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Pointer networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meire</forename><surname>Fortunato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navdeep</forename><surname>Jaitly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2692" to="2700" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Learning to extract coherent summary via deep reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxiang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baotian</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-18), the 30th innovative Applications of Artificial Intelligence (IAAI-18), and the 8th AAAI Symposium on Educational Advances in Artificial Intelligence (EAAI-18)</title>
		<meeting>the Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-18), the 30th innovative Applications of Artificial Intelligence (IAAI-18), and the 8th AAAI Symposium on Educational Advances in Artificial Intelligence (EAAI-18)<address><addrLine>New Orleans, Louisiana, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5602" to="5609" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Learning to extract coherent summary via deep reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxiang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baotian</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-18), the 30th innovative Applications of Artificial Intelligence (IAAI-18), and the 8th AAAI Symposium on Educational Advances in Artificial Intelligence (EAAI-18)</title>
		<meeting>the Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-18), the 30th innovative Applications of Artificial Intelligence (IAAI-18), and the 8th AAAI Symposium on Educational Advances in Artificial Intelligence (EAAI-18)<address><addrLine>New Orleans, Louisiana, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5602" to="5609" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Neural latent extractive document summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingxing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="779" to="784" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Neural document summarization by jointly learning to score and select sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingyu</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaohan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiejun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="654" to="663" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
