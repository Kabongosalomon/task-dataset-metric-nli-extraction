<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">UnitedQA: A Hybrid Approach for Open Domain Question Answering</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Cheng</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Microsoft Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yelong</forename><surname>Shen</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft Dynamics</orgName>
								<address>
									<postCode>365 AI</postCode>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Microsoft Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengcheng</forename><surname>He</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft Dynamics</orgName>
								<address>
									<postCode>365 AI</postCode>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weizhu</forename><surname>Chen</surname></persName>
							<email>wzchen@microsoft.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
							<email>jfgao@microsoft.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Microsoft Research</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft Dynamics</orgName>
								<address>
									<postCode>365 AI</postCode>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">UnitedQA: A Hybrid Approach for Open Domain Question Answering</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T20:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>To date, most of recent work under the retrieval-reader framework for open-domain QA focuses on either extractive or generative reader exclusively. In this paper, we study a hybrid approach for leveraging the strengths of both models. We apply novel techniques to enhance both extractive and generative readers built upon recent pretrained neural language models, and find that proper training methods can provide large improvement over previous state-of-the-art models. We demonstrate that a simple hybrid approach by combining answers from both readers can efficiently take advantages of extractive and generative answer inference strategies and outperforms single models as well as homogeneous ensembles. Our approach outperforms previous state-of-the-art models by 3.3 and 2.7 points in exact match on NaturalQuestions and TriviaQA respectively.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Open-domain question answering (QA) has been a long standing problem in natural language processing, information retrieval, and related fields. Compared with most recent popular "reading comprehension" QA tasks <ref type="bibr" target="#b24">(Rajpurkar et al., 2016</ref><ref type="bibr" target="#b23">(Rajpurkar et al., , 2018</ref>, the open-domain QA task is less studied where systems are required to answer a question directly without being provided with the corresponding evidence. In other words, the task evaluates a system's ability to effectively fetch relevant information, consolidate expressed knowledge from multiple sources, and produce valid answers for input questions. One typical framework for open-domain QA is the retrieval-reader framework <ref type="bibr" target="#b0">(Chen et al., 2017;</ref><ref type="bibr" target="#b8">Guu et al., 2020;</ref><ref type="bibr" target="#b13">Karpukhin et al., 2020)</ref> where the relevant information is first retrieved from a large text corpus by an information retrieval module, and a neural answering module then navigates multiple * Equal Contribution passages for answer inference 1 . In this work, we mainly focus on this setting for open-domain QA. More specifically, different from recent work <ref type="bibr" target="#b8">(Guu et al., 2020;</ref><ref type="bibr" target="#b13">Karpukhin et al., 2020)</ref> on improving the retriever, we investigate potential improvements for the reading part.</p><p>With the retrieval-reader framework, there are two paradigms of reading, i.e. extractive <ref type="bibr" target="#b13">(Karpukhin et al., 2020;</ref><ref type="bibr" target="#b8">Guu et al., 2020)</ref> and generative <ref type="bibr">(Lewis et al., 2020b;</ref><ref type="bibr" target="#b9">Izacard and Grave, 2020)</ref> readers. Generally speaking, extractive readers extract contiguous spans out of the retrieved passages while generative ones decode answer strings based on the question and retrieval context. Apparently, extractive and generative readers adopt different answer inference strategies. However, to date, most of existing work on open-domain QA focuses on using either an extractive reader or a generative reader exclusively. In this work, we hypothesize that a hybrid reader combing the extractive and generative readers can be a better option for open domain QA. As shown in <ref type="figure" target="#fig_0">Figure 1</ref>, compared with prediction agreement among only generative or extractive readers <ref type="bibr">(top-left and bottom-right)</ref>, the cross prediction agreement between extractive and generative readers (bottom-left) is pretty low (&lt;50%). This indicates that answers produced by those two types of models are different and they can be complementary to each other. Therefore, in this work, we study a simple hybrid approach, UnitedQA, to combine answers from both extractive and generative readers.</p><p>For open-domain QA, one of the main challenges for the reader model is to produce answers from a noisy collection of retrieved documents. In other words, reading comprehension with evidence returned by information retrieval systems establishes a weakly-supervised QA setting due to the noise in the heuristics-based labeling <ref type="bibr" target="#b0">(Chen et al., 2017)</ref>. To address this issue, recent work based on either extractive or generative readers <ref type="bibr" target="#b8">(Guu et al., 2020;</ref><ref type="bibr" target="#b13">Karpukhin et al., 2020;</ref><ref type="bibr" target="#b16">Lewis et al., 2020a;</ref><ref type="bibr" target="#b9">Izacard and Grave, 2020)</ref> resorts to different largescale pre-trained neural language models. Because of their self-supervised learning over a sheer size of text, those neural language models have been shown to encode world knowledge in their parameters, and achieve state-of-the art results when finetuned on downstream NLP tasks. Built upon recent state-of-the-art pre-trained neural language models, i.e. T5 <ref type="bibr" target="#b22">(Raffel et al., 2019)</ref> and ELECTRA <ref type="bibr" target="#b4">(Clark et al., 2020)</ref>, in the United-QA, we further study techniques to improve and stabilize the model training for both extractive and generative readers. Specifically, we consider posterior differential regularization <ref type="bibr" target="#b2">(Cheng et al., 2020b)</ref> and distant supervision assumptions <ref type="bibr" target="#b1">(Cheng et al., 2020a)</ref> to enhance the extractive reader. For the generative reader, we incorporate attention bias <ref type="bibr" target="#b16">(Lewis et al., 2020a)</ref> into T5-FID <ref type="bibr" target="#b9">(Izacard and Grave, 2020)</ref>, and improve unconstrained generation training with adversarial training <ref type="bibr" target="#b12">(Ju et al., 2019;</ref><ref type="bibr" target="#b10">Jiang et al., 2020)</ref>.</p><p>Our experimental results highlight the benefits of the hybrid approach, i.e. combing extractive and generative readers. Based on both improved extractive and generative readers, UnitedQA sets new state-of-the-art results on two popular open-domain QA datasets, i.e. 54.7 and 70.3 in exact match on NaturalQuestions <ref type="bibr" target="#b14">(Kwiatkowski et al., 2019)</ref> and TriviaQA <ref type="bibr" target="#b11">(Joshi et al., 2017)</ref>, respectively. It is worth noting that our UnitedQA model not only outperforms each single model but also brings more pronounced improvements over homogeneous ensembles of either extractive, or generative readers. Additionally, our improved extractive model, UnitedQA-E, outperforms previous state-of-the-art extractive models of a similar size and generative models of a much larger size (&gt;3x). Based on our analyses on both component readers of United-QA, the extractive reader is found to be better at generalizing to unseen cases and the generative reader excels at temporal reasoning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Method: UnitedQA</head><p>In this section, we present the overall pipeline of the UnitedQA system, which consists of three components: Retrieval, Reading, and Re-ranking. First, the retrieval module fetches a list of relevant passages from a Wikipedia dump for a given question. Second, the module of hybrid readers produce answer candidates from the set of retrieved passages. Lastly, the re-ranking module combines the answer candidates with linear interpolation and produce the final answer. Retrieval. Following <ref type="bibr" target="#b13">Karpukhin et al. (2020)</ref>, we consider two methods, BM25 and dense passage retrieval (DPR), for retrieving the support passages for a given question. For BM25, passages are encoded as bag of words (BOW), and inverse document frequencies are used as the ranking function. For DPR, passages and questions are represented as dense vectors based on two BERT  models. The relevance measure is then computed based on the dot production between the query and passage vectors. In this paper, we use the same implementation from <ref type="bibr" target="#b13">Karpukhin et al. (2020)</ref> 2 . Specifically, the English Wikipedia dump from Dec. 20, 2018 is used as the source documents for retrieval, with the removal of semi-structured data, such as tables or lists. Each document is split into disjoint 100-word passages as the basic retrieval unit. The top-100 passages are then passed for reading. Reading. We combine the generative reader and the extractive reader to produce answer candidates over the retrieved passages. Here, we only give a high-level description of our approach. More details regarding our improved extractive and generative models are presented in section 3 and section 4 respectively.</p><p>The generative reader is based on a sequenceto-sequence model pre-trained in a forwardgeneration fashion on a large corpus, i.e. T5 <ref type="bibr" target="#b22">(Raffel et al., 2019)</ref>. Similar to <ref type="bibr" target="#b9">Izacard and Grave (2020)</ref>, the model takes the question and all of its relevant passages as input, and then generates the answer string token by token. Specifically, the concatenation of all retrieved passages and the corresponding question is used as the encoder input. Then, the decoder performs reasoning over the concatenation of all evidence through an attention mechanism.</p><p>Following state-of-the-art extractive QA models <ref type="bibr" target="#b13">Karpukhin et al., 2020)</ref>, our extractive reader is based on a Transformer neural network pre-trained with a cloze style selfsupervised objective, i.e. ELECTRA <ref type="bibr" target="#b4">(Clark et al., 2020)</ref>. Here, a pair of a given question and a support passage is jointly encoded into neural text representations. These representations are then used to define scores or probabilities of possible answer begin and end positions, which are in turn used to define probabilities over possible answer spans.</p><p>Finally, the answer string probabilities are based on the aggregation over all possible answer spans from the entire set of support passages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Datasets</head><p>We use two representative QA datasets and adopt the same training/dev/testing splits as in previous work <ref type="bibr" target="#b13">Karpukhin et al., 2020)</ref>. In the following, we give an overview of each dataset and refer interested readers to their papers for more details. NaturalQuestions <ref type="bibr" target="#b14">(Kwiatkowski et al., 2019</ref>) is composed of questions by real users to Google Search, each with answers identified by human annotators in Wikipedia. The open-domain version of NaturalQuestions  only consider questions with short answers, i.e. answers with less than 5 tokens. In the NaturualQuestions, the questions are considered to be more information seeking given that the question askers does not already known the answer beforehand. It has promoted several recent advances in open-domain QA <ref type="bibr" target="#b13">Karpukhin et al., 2020;</ref><ref type="bibr" target="#b20">Min et al., 2019;</ref><ref type="bibr" target="#b8">Guu et al., 2020)</ref>. In addition, we use another evaluation set, i.e. the dev set introduced recently by the EfficientQA competition 3 , which is constructed in the same way as the original Natu-ralQuestions dataset. TriviaQA <ref type="bibr" target="#b11">(Joshi et al., 2017)</ref> contains trivia question-answer pairs that were scraped from the web. Different from NaturalQuestions, the questions here are written with known answers in mind. Specifically, the unfiltered set <ref type="bibr" target="#b11">(Joshi et al., 2017)</ref> has been used for developing open-domain QA models <ref type="bibr" target="#b13">Karpukhin et al., 2020;</ref><ref type="bibr" target="#b20">Min et al., 2019;</ref><ref type="bibr" target="#b13">Karpukhin et al., 2020;</ref><ref type="bibr" target="#b8">Guu et al., 2020)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments: Improved Extractive Model</head><p>In this section, we explore different approaches to improving the extractive model for open domain QA. Here, we mainly consider recent advances in 1) improving NLP model robustness <ref type="bibr" target="#b2">(Cheng et al., 2020b)</ref>, 2) extractive QA with weak supervision <ref type="bibr" target="#b20">(Min et al., 2019;</ref><ref type="bibr" target="#b1">Cheng et al., 2020a)</ref>, and 3) enhanced textual representations <ref type="bibr" target="#b4">(Clark et al., 2020)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Extractive Reader</head><p>Different from <ref type="bibr" target="#b13">Karpukhin et al. (2020)</ref> where the extractive prediction is based on two decoupled probabilities (passage selection and span extraction <ref type="bibr" target="#b27">Wang et al., 2019)</ref>, we use a single probability space consisting of token positions of answer spans over all retrieved passages as <ref type="bibr" target="#b1">Cheng et al. (2020a)</ref>. Since the task is to predict an answer string rather than a particular mention for a given question, one potential benefit of the single probability space approach is that it allows aggregating information across answer spans corresponding to the same string during inference. Given a question q and a set of K retrieved passages p 1 , . . . , p K , the text encoder produces contextualized representations for each questionpassage pair (q, p k ) in the form of "[CLS]question [SEP]passage [SEP]". Specifically, for the ith token in passage p k , the final hidden vector h k i ∈ R d is used as the contextualized token embedding, where d is the vector dimension. The span-begin score for the i-th token is computed as</p><formula xml:id="formula_0">s b (i k ) = w T b h k i using a weight vector w b ∈ R d .</formula><p>Thus, the probability of the answer span starting with position i is</p><formula xml:id="formula_1">P b (i k ) = exp(s b (i k )) Z b ,<label>(1)</label></formula><p>where Z b is the normalizing factor computed by summing over I 1 , . . . ,</p><formula xml:id="formula_2">I K (each I k is the set of all possible positions from the k-passage), i.e. Z b = k i k ∈I k exp(s b (i k ))</formula><p>. The span-end score s e (j k ), and the probability P e (j k ) for an end position j in passage k, and the normalizing factor Z e are defined in the same way. The probability of an answer span (i k , j k ) is</p><formula xml:id="formula_3">P (i k , j k ) = P b (i k )P e (j k ) = exp(s b (i k ) + s e (j k )) Z b Z e .</formula><p>During training, either the marginal log-likelihood (MML) of all correct answer spans <ref type="bibr" target="#b13">(Karpukhin et al., 2020)</ref> or the log-likelihood of the most likely outcome (HardEM) <ref type="bibr" target="#b20">(Min et al., 2019)</ref> is maximized.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Improvement Methods</head><p>In addition to better textual representations from ELECTRA <ref type="bibr" target="#b4">(Clark et al., 2020)</ref>, we consider two methods for improving the training of the extractive reader.  <ref type="bibr" target="#b0">(Chen et al., 2017)</ref>, we investigate the recently developed posterior differential regularization (PDR) <ref type="bibr" target="#b2">(Cheng et al., 2020b)</ref> to improve the robustness of the extractive reader. As an extension to recent methods for improving the model local smoothness <ref type="bibr" target="#b21">(Miyato et al., 2018;</ref><ref type="bibr" target="#b25">Sokolić et al., 2017)</ref>, PDR aims at regularizing the posterior difference between the clean and noisy inputs with regard to the family of f -divergences <ref type="bibr" target="#b5">(Csiszár and Shields, 2004)</ref>. Different from <ref type="bibr" target="#b2">Cheng et al. (2020b)</ref> where only clean supervision setting is considered, in this work, we apply PDR to the weakly supervised open-domain QA scenario. Given it is computationally expensive to enumerate all possible spans, we apply two separate regularization terms for the begin and end position probabilities at the multi-passage level, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Main results</head><p>First, we compare our improved extractive models to two recent models, REALM <ref type="bibr" target="#b8">(Guu et al., 2020)</ref> and RAG <ref type="bibr">(Lewis et al., 2020b)</ref>, which are first pretrained with different retrieval augmented objectives and then fine-tuned for open-domain QA. In addition, we include as baselines DPR <ref type="bibr" target="#b13">(Karpukhin et al., 2020)</ref> and T5-FID <ref type="bibr" target="#b9">(Izacard and Grave, 2020)</ref>, both of which are based on the same retriever as ours. <ref type="table">Table 1</ref> shows results for our improved extractive models based on ELECTRA-base (UnitedQA-E base ) and ELECTRA-large (UnitedQA-E large ), respectively, along with recent state-of-the-art models.</p><p>Compared with the recent state-of-the-art extractive model (DPR), our base model leads to pronounced 15% relative improvements for both Nat-uralQuestions (+6.2 absolute improvement) and TriviaQA (+8.4 absolute improvement). More importantly, UnitedQA-E base achieves comparable or even better performance with regard to generative models of larger size, i.e. RAG and T5-FID base . Finally, by using a larger text encoder (i.e. ELECTRA-large), our extractive model sets new state-of-the-art results for both NaturalQuestions and TriviaQA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Ablation Study</head><p>In <ref type="table" target="#tab_2">Table 2</ref>, we present ablation experiments on the effectiveness of different textual representations and methods for improving the extractive model. Compared with the multi-objective using two MML objectives <ref type="bibr" target="#b1">(Cheng et al., 2020a)</ref>, we find that a new multi-objective with HardEM at the multi-passage level and MML at the passage level is more effective for open-domain QA. In addition to the multiobjective training, there is a noticeable improvement brought by the regularization method (PDR) which indicates the importance of proper regularization for training with noisy supervision. Last but not least, the large improvement of ELECTRA over BERT indicates the importance of deriving  4 Experiments: Improved Generative Model</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Generative Reader</head><p>The model architecture of our generative reader is based on T5-Fusion-in-Decoder <ref type="bibr" target="#b9">(Izacard and Grave, 2020)</ref>. Given a question q and a set of K retrieved passages p 1 , . . . , p K , the encoder model encodes each (q, p k ) pair independently, and produces contextualized representations: h k i ∈ R d for the i-th token of the k-th pair. The decoder then performs attention over the concatenation of the representations of all the retrieved passages, and generates the answer string.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Decoder Attention Bias</head><p>The decoder in the T5 transformer model adopts a cross-attention mechanism to compute attention scores between the decoding answer tokens and all the retrieved passage tokens. Specifically, let q i ∈ R d be the query vector of the i-th decoding token 4 , and m k j ∈ R d be the key vector of the j-th token in the k-th retrieved context. The classical multi-head attention scores s k i,j can be calculated as:</p><formula xml:id="formula_4">s k i,j = MultiHead(q i , m k j ) ∈ R |Head|<label>(2)</label></formula><p>To take into account the ranking information of the retrieved passage, we revise the Equation 2 by incorporating the attention bias term:</p><formula xml:id="formula_5">s k i,j = MultiHead(q i , m k j ) + b k<label>(3)</label></formula><p>b k is a trainable cross attention bias vector in the decoder module: b k ∈ R |Head| .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Adversarial Training</head><p>The generative reader is trained by maximizing a sequence-to-sequence objective for a training sample (x, y) as in Equation 4, where x indicates the input of the question and all retrieved passages: x = (q, p 1 ), ..., (q, p K ) , and y the answer string with its tokens as (y 1 , ..., y N ).</p><p>L(x, y; θ) = logp θ (y|x) = </p><p>Adversarial training creates adversarial examples by adding small perturbations to the embedding layer. Assuming the word(-piece) embedding layer is parameterized by a matrix V ∈ R |V |×d , |V | is the vocabulary size, and d is the embeddimension. The adversarial embedding matrixV can be obtained by:</p><formula xml:id="formula_7">g V = −∇ V L(x, y; θ) (5) V = V + SG( g V /||g V || 2 )<label>(6)</label></formula><p>SG(·) is the stop-gradient operation. We use the adversarial embedding matrixV to replace the original V in model parameters θ, and obtainθ. Thus the adversarial loss can be calculated as:</p><formula xml:id="formula_8">L AT (x, y; θ) = L(x, y;θ)<label>(7)</label></formula><p>The overall training objective is the summation of two losses:</p><formula xml:id="formula_9">L = αL(x, y; θ) + βL AT (x, y; θ) (8)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments: Hybrid Model</head><p>In this part, we study whether it is advantageous to combine the generative and extractive readers in a hybrid fashion. Specifically, we leverage the improved extractive and generative models from section 3 and section 4, respectively. Similar to previous experiments, the same retriever is used for retrieving top 100 passages for each given question for both extractive and generative readers. In order to evaluate the advantage of the hybrid of the extractive and generative models (Unit-edQA), we include two homogeneous ensemble baselines, one consisting of only extractive readers (UnitedQA-E++) and the other hybrid of exclusively generative models (UnitedQA-G++). Each model is trained independently with different random seeds. In our study, a simple linear interpolation over all model predictions is used for producing the final answer. Specifically, we combine three models for each ensemble case. For homogeneous ensemble cases, the majority prediction is used. For the hybrid of extractive and generative readers, we select a three-model combination from the set of three generative and three extractive models base on their performance on the dev set. In addition, we use a scalar a for weighting extractive predictions and 1 − a for scaling generative predictions. The answer with the highest weighted vote is then predicted as the final answer. The results are summarized in lower part of <ref type="table">Table 1.</ref> As expected, all ensemble models show an improvement over their single model counterparts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>Dev Test</p><p>UnitedQA-G 48.6 -UnitedQA-E 51.1 -UnitedQA-G++ 50.5 -UnitedQA-E++ 51.9 -UnitedQA 54.1 54.0</p><p>2nd best -53.9 <ref type="table">Table 3</ref>: Results on the dev and test sets of EfficientQA. Exact match score is reported. The 2nd best system's result is from the official leaderboard 6 .</p><p>However, it is worth noting that the two homogeneous ensemble baselines, UnitedQA-E++ and UnitedQA-G++, only provide marginal improvements over the corresponding best single models. The significant improvement brought by our proposed hybrid approach indicates the benefit of combining extractive and generative readers for opendomain QA. Moreover, we evaluate our hybrid model trained on NaturalQuestions directly to the dev and test sets introduced by the EfficientQA competition 5 . As shown in <ref type="table">Table 3</ref>, our UnitedQA again outperforms both single models and homogeneous ensembles on the dev set, and is the best performing system based on the EfficientQA leaderboard.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Analysis</head><p>Given the advantage of the hybrid approach to open-domain QA, we study in detail the behavior of our SOTA extractive and generative readers (i.e. United-E and United-G). First, we evaluate the impact of the retrieval model. Second, following <ref type="bibr" target="#b18">Lewis et al. (2020c)</ref>, we conduct a break-down evaluation of the readers to investigate what drives their overall performance, i.e. the extent of memorizing vs generalization. Lastly, we carry out a manual inspection of the prediction errors made by the extractive and generative models, respectively. Impact of Retrieval Recall. Here, we vary the number of retrieved passages during inference and report the evaluation results in terms of end-to-end QA exact match score of United-E and United-G along with the corresponding top-k retrieval accuracy. The results are summarized in <ref type="table" target="#tab_4">Table 4</ref>. As expected, when the number of retrieved passages increases, both top-k retrieval accuracy and the endto-end QA performance improve. However, there  is a noticeable gap between the improvement of retrieving more passages (i.e., recall) and that of the corresponding end-to-end QA performance, especially for the extractive reader. This is likely caused by additional noise introduced with improved retrieval recall. Specifically, only half of the retriever improvement can be effectively utilized by the extractive model while the generative model can benefit more from retrieving more passages. This suggests that by concatenating all passages in vector space, the generative model are more effective in de-noising in comparison to the extractive model.</p><p>Breakdown Evaluation. Following <ref type="bibr" target="#b18">Lewis et al. (2020c)</ref>, we carry out a breakdown evaluation of model performance over the NaturalQuestions and TriviaQA test sets. Given their superior performance, we again only consider our improved extractive and generative models, i.e. UnitedQA-E large and UnitedQA-G respectively. The evaluation is summarized in <ref type="table" target="#tab_6">Table 5</ref>. In comparison to their corresponding overall performance, both the extractive and generative models achieve much better performance on the "Overlap" categories (i.e. "Question Overlap" and "Answer Overlap") for both NaturalQuestions and TrivaQA, which indicates that both models perform well for question and answer memorization. Different from question and answer memorization, there is a pronounced performance drop for both models on the "Answer Overlap Only" category where certain amount of relevance inference capability is required to succeed. Lastly, we see that both extractive and generative models suffer some significant performance degradation for the "No Overlap" column which highlights model's generalization evaluation. Nevertheless, the extractive model demonstrate a better QA generalization by achieving a better per-formance on the "No Overlap" category on both datasets. Error Analysis. Here, we conduct analyses into prediction errors made by the extractive and generative models based on automatic evaluation. For this study, we use the dev set introduced by the Ef-ficientQA competition 7 which is constructed in the same way as the original NaturalQuestions dataset. Specifically, we group prediction errors into three categorizes: 1) common prediction errors made by both the extractive and generative models, 2) prediction errors made by the extractive model, 3) prediction errors produced by the generative model. In the following, we first carry out a manual inspection into the common errors. Then, we compare the prediction errors made by extractive and generative models, respectively. First of all, there is an error rate of 29% of those consensus predictions made by both extractive and generative models according to the automatic evaluation. Based on 30 randomly selected examples, we find that around 30% of those predictions are actually valid answers as shown in the top part of <ref type="table" target="#tab_7">Table 6</ref>. In addition to predictions that are answers at different granularity or semantically equivalent ones, some of those prediction errors are likely caused by the ambiguity in questions. As the given example in <ref type="table" target="#tab_7">Table 6</ref>, based on the specificity, the model prediction is also a valid answer. This highlights the limitation of the current evaluation metric, which does not accurately estimate the existing open-domain QA system capabilities. As shown in the bottom part of <ref type="table" target="#tab_7">Table 6</ref>, most of representative errors are due to the confusion of related concepts, entities or events that are mentioned frequently together with the corresponding gold answers.</p><p>Next, all questions from the dev set are categorized based the WH question word, i.e. what, which, when, who, how, where. We then report the relative performance change of each WH category for both extractive and generative models over their corresponding overall prediction accuracy in <ref type="figure" target="#fig_2">Figure 2</ref>. First, it is easy to see that both extractive and generative models achieve the best performance for entity related who questions, which is likely to be the result of high ratio of questions and answers of this type seen during training. In contrast, the answers to what questions can play a much richer syntactic role in context, making it more difficult for both extractive and generative models to perform well.   <ref type="bibr" target="#b18">(Lewis et al., 2020c)</ref>. Exact match score is reported. UnitedQA-E and UnitedQA-G denotes our extractive and generative models respectively. Very interestingly, the generative model exhibits the strength for temporal reasoning, whereas the extractive model does not. This difference suggests that it is worth exploring better temporal modeling strategies to improve the extractive model in the future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>Open-domain Question Answering.</p><p>Opendomain QA requires a system to answer questions based on evidence retrieved from a large corpus such as Wikipedia <ref type="bibr" target="#b26">(Voorhees, 1999;</ref><ref type="bibr" target="#b0">Chen et al., 2017)</ref>. Recent progress has been made towards improving evidence retrieval through both sparse vector models like TF-IDF or BM25 <ref type="bibr" target="#b0">(Chen et al., 2017;</ref><ref type="bibr" target="#b20">Min et al., 2019)</ref>, and dense vector models based on BERT <ref type="bibr" target="#b13">Karpukhin et al., 2020;</ref><ref type="bibr" target="#b8">Guu et al., 2020)</ref>. Generally, the dense representations complement the sparse vector methods for passage retrieval as they can potentially give high similarity to semantically related text pairs, even without exact lexical overlap. Unlike most of existing work focusing on a pipeline model,  propose a pre-training objective for jointly training both the retrieval encoder and reader. Their approach outperforms most of recent pipeline methods on multiple open-domain QA datasets, and is further extended by <ref type="bibr" target="#b8">Guu et al. (2020)</ref> with asynchronously re-indexing the passages during the training. Instead, in this work, we focus on developing a hybrid approach for open-domain QA.</p><p>By simply combing answer predictions from our improved extractive and generative models, our UnitedQA achieves significant improvements over recent state-of-the-art models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reading Comprehension with Noisy Labels.</head><p>There has been a line of work on improving distantly-supervised reading comprehension models by developing learning methods and model architectures that can better use noisy labels. Most of them focus on the document-level QA, where all paragraphs share the same document context. <ref type="bibr" target="#b3">Clark and Gardner (2018)</ref> propose a paragraphpair ranking objective for learning with multiple paragraphs so that the model can distinguish relevant paragraphs from irrelevant ones. In <ref type="bibr" target="#b19">(Lin et al., 2018)</ref>, a coarse-to-fine model is proposed to handle label noise by aggregating information from relevant paragraphs and then extracting answers from selected ones. <ref type="bibr" target="#b20">Min et al. (2019)</ref> propose a hard EM learning scheme where only passagelevel loss is considered for document-level QA. More recently, different probabilistic assumptions with corresponding training and inference methods are examined in <ref type="bibr" target="#b1">(Cheng et al., 2020a)</ref> again for document-level QA with distant supervision. In our work, we further extend the multi-objective formulation proposed in <ref type="bibr" target="#b1">(Cheng et al., 2020a)</ref> with the hard EM learning <ref type="bibr" target="#b20">(Min et al., 2019)</ref> for enhancing extractive Open-domain QA, where the input passages are given by a retrieval model and are  typically from different documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>In this study, we propose a hybrid model for opendomain QA, called UnitedQA, which combines the strengths of extractive and generative readers. We validate the effectiveness of UnitedQA on two popular open-domain QA benchmarks, NaturalQuestions and TriviaQA. Our results show that the proposed UnitedQA model significantly outperforms single extractive and generative models as well as their corresponding homogeneous ensembles, and creates new state-of-the-art on both benchmarks. We also perform a comprehensive empirical study to investigate the relative contributions of different components of our model and the techniques we use to improve the readers.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Pairwise prediction agreement ratio. G-1, G-2, G-3 and E-1, E-2, E-3 are three different generative and extractive readers respectively. All readers achieve similar performance on NaturalQuestions. Higher agreement in red and lower agreement in gray.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>y i |x, y 1:i−1 )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Relative accuracy of different WH questions. The relative accuracy is the relative change of a WH category accuracy to the overall model accuracy.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>was harry potter and the deathly hallows part 2 movie released Prediction: 2011 / Gold: 15 July 2011 Semantically equivalent answer Q: minimum age limit for chief justic of india Prediction: 65 / Gold: 65 years Ambiguity question Q: who won her first tennis grand slam in 2018 Prediction: Carolin Wozniacki / Gold: Simona Halep Wrong answers Part as whole error Q: the official U.S. poverty line is based on the cost of what Prediction: food / Gold: ICP purchasing power Entity Confusion Q: actor who played tommy in terms of endearment Prediction: Jeff Daniels / Gold: Troy Bishop Temporal confusion Q: when did the saskatchewan roughriders last won the grey cup Prediction: 2007 / Gold: 2013</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Table 1: Comparison to state-of-the-art models. Exact match score is used for evaluation. The overall best model is in Box , the best single model is in bold, and the best model with the smallest reader size is in underline.</figDesc><table><row><cell>Model</cell><cell></cell><cell cols="4">Reader Type Reader Size NaturalQuestions TriviaQA</cell></row><row><cell>REALM(Guu et al., 2020)</cell><cell></cell><cell>Extractive</cell><cell>110M</cell><cell>40.4</cell><cell>-</cell></row><row><cell>RAG(Lewis et al., 2020b)</cell><cell></cell><cell>Generative</cell><cell>400M</cell><cell>44.5</cell><cell>56.1</cell></row><row><cell>DPR(Karpukhin et al., 2020)</cell><cell></cell><cell>Extractive</cell><cell>110M</cell><cell>41.5</cell><cell>57.9</cell></row><row><cell cols="2">T5-FID base (Izacard and Grave, 2020)</cell><cell>Generative</cell><cell>220M</cell><cell>48.2</cell><cell>65.0</cell></row><row><cell cols="3">T5-FID large (Izacard and Grave, 2020) Generative</cell><cell>770M</cell><cell>51.4</cell><cell>67.6</cell></row><row><cell>UnitedQA-E base (Ours)</cell><cell></cell><cell>Extractive</cell><cell>110M</cell><cell>47.7</cell><cell>66.3</cell></row><row><cell>UnitedQA-E large (Ours)</cell><cell></cell><cell>Extractive</cell><cell>330M</cell><cell>51.9</cell><cell>68.9</cell></row><row><cell>UnitedQA-G large (Ours)</cell><cell></cell><cell>Generative</cell><cell>770M</cell><cell>52.3</cell><cell>67.0</cell></row><row><cell>UnitedQA-E large ++ (Ours)</cell><cell></cell><cell>Ensemble</cell><cell>3x330M</cell><cell>52.4</cell><cell>69.6</cell></row><row><cell>UnitedQA-G large ++ (Ours)</cell><cell></cell><cell>Ensemble</cell><cell>3x770M</cell><cell>53.3</cell><cell>67.8</cell></row><row><cell>UnitedQA (Ours)</cell><cell></cell><cell>Hybrid</cell><cell>-</cell><cell>54.7</cell><cell>70.3</cell></row><row><cell>Model</cell><cell cols="2">NQ TriviaQA</cell><cell></cell><cell></cell></row><row><cell cols="2">(Cheng et al., 2020a) +PDR 43.3</cell><cell>60.1</cell><cell></cell><cell></cell></row><row><cell>BERT base</cell><cell>44.2</cell><cell>62.2</cell><cell></cell><cell></cell></row><row><cell>-PDR</cell><cell>41.8</cell><cell>60.2</cell><cell></cell><cell></cell></row><row><cell>-Multi-obj &amp; PDR</cell><cell>40.6</cell><cell>58.5</cell><cell></cell><cell></cell></row><row><cell>ELECTRA base</cell><cell>46.0</cell><cell>65.4</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Ablation experiments of the extractive model on the development sets of NaturalQuestions (NQ) and TriviaQA. Exact match score is reported.</figDesc><table /><note>better text representations for weakly supervised NLP problems.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4</head><label>4</label><figDesc></figDesc><table><row><cell>: Retieval top-k accuracy and end-to-end QA</cell></row><row><cell>extact match scores on the test sets of NaturalQuestions</cell></row><row><cell>(NQ) and TriviaQA. United-E and United-G stand for</cell></row><row><cell>our extractive and generative models respectively.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 :</head><label>5</label><figDesc>Breakdown evaluation on NaturalQuestions and TriviaQA based on test splits defined in</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 6 :</head><label>6</label><figDesc>Examples of prediction errors as judged by the automatic evaluation.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">These research systems simulate a commercial Web QA system such as Bing QA which incorporates an answering module as a post-web component on top of its Web search engine stack<ref type="bibr" target="#b7">(Gao et al., 2019)</ref>.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://github.com/facebookresearch/ DPR</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">https://efficientqa.github.io/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">we omit the layer notation for simplification</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">https://efficientqa.github.io/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7">https://efficientqa.github.io/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank Yuning Mao for valuable discussions and comments, Microsoft Research Technology Engineering team for setting up GPU machines.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Reading Wikipedia to answer opendomain questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P17-1171</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1870" to="1879" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Probabilistic assumptions matter: Improved models for distantlysupervised document-level question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.501</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="5657" to="5667" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Posterior differential regularization with f-divergence for improving model robustness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lis</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaoliang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Simple and effective multi-paragraph reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P18-1078</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="845" to="855" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">ELECTRA: Pretraining text encoders as discriminators rather than generators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Information theory and statistics: A tutorial</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Csiszár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Shields</surname></persName>
		</author>
		<idno type="DOI">10.1561/0100000004</idno>
	</analytic>
	<monogr>
		<title level="j">Foundations and Trends in Communications and Information Theory</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="417" to="528" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1423</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Long and Short Papers</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Neural approaches to conversational ai</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lihong</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>Now Publishers, Inc</publisher>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="127" to="298" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kelvin</forename><surname>Guu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zora</forename><surname>Tung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Panupong</forename><surname>Pasupat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note>Realm: Retrievalaugmented language model pre-training</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Leveraging passage retrieval with generative models for open domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gautier</forename><surname>Izacard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">SMART: Robust and efficient fine-tuning for pretrained natural language models through principled regularized optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoming</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengcheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weizhu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tuo</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.197</idno>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">TriviaQA: A large scale distantly supervised challenge dataset for reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Weld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P17-1147</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Vancouver</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1601" to="1611" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Ju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fubang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shijie</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuefeng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunfeng</forename><surname>Liu</surname></persName>
		</author>
		<title level="m">Technical report on conversational question answering</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Dense passage retrieval for open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Karpukhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barlas</forename><surname>Oguz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ledell</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Edunov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.550</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="6769" to="6781" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Natural questions: A benchmark for question answering research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennimaria</forename><surname>Palomaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivia</forename><surname>Redfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankur</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Alberti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danielle</forename><surname>Epstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Kelcey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00276</idno>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="453" to="466" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Latent retrieval for weakly supervised open domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6086" to="6096" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Pre-training via paraphrasing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marjan</forename><surname>Ghazvininejad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gargi</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armen</forename><surname>Aghajanyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sida</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ethan</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksandara</forename><surname>Piktus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><surname>Petroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Karpukhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heinrich</forename><surname>Küttler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<title level="m">Tim Rocktäschel, Sebastian Riedel, and Douwe Kiela. 2020b. Retrieval-augmented generation for knowledge-intensive nlp tasks</title>
		<imprint/>
		<respStmt>
			<orgName>Wen tau Yih</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Question and answer test-train overlap in open-domain question answering datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pontus</forename><surname>Stenetorp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Denoising distantly supervised open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yankai</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haozhe</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P18-1161</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1736" to="1745" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A discrete hard EM approach for weakly supervised question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1284</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2851" to="2864" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Virtual adversarial training: a regularization method for supervised and semisupervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeru</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masanori</forename><surname>Shin-Ichi Maeda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shin</forename><surname>Koyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ishii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="1979" to="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katherine</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanqi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter J</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.10683</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robin</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.03822</idno>
		<title level="m">Know what you don&apos;t know: Unanswerable questions for squad</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">SQuAD: 100,000+ questions for machine comprehension of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantin</forename><surname>Lopyrev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D16-1264</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Austin, Texas</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2383" to="2392" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Robust large margin deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sokolić</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Giryes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sapiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R D</forename><surname>Rodrigues</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">16</biblScope>
			<biblScope unit="page" from="4265" to="4280" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">The trec-8 question answering track report</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellen</forename><surname>Voorhees</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Multi-passage BERT: A globally normalized BERT model for open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiguo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaofei</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramesh</forename><surname>Nallapati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xiang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1599</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5878" to="5882" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
