<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Real-Time Anomaly Detection for Streaming Analytics</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subutai</forename><surname>Ahmad</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">SAHMAD@NUMENTA.COM Numenta, Inc</orgName>
								<address>
									<addrLine>791 Middlefield Road</addrLine>
									<postCode>94063</postCode>
									<settlement>Redwood City</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Purdy</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">SPURDY@NUMENTA.COM Numenta, Inc</orgName>
								<address>
									<addrLine>791 Middlefield Road</addrLine>
									<postCode>94063</postCode>
									<settlement>Redwood City</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Real-Time Anomaly Detection for Streaming Analytics</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T07:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Much of the worlds data is streaming, time-series data, where anomalies give significant information in critical situations. Yet detecting anomalies in streaming data is a difficult task, requiring detectors to process data in real-time, and learn while simultaneously making predictions. We present a novel anomaly detection technique based on an on-line sequence memory algorithm called Hierarchical Temporal Memory (HTM). We show results from a live application that detects anomalies in financial metrics in realtime. We also test the algorithm on NAB, a published benchmark for real-time anomaly detection, where our algorithm achieves best-in-class results.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Across every industry, we are seeing an exponential increase in the availability of streaming, time-series data. Largely driven by the rise of the Internet of Things (IoT) and connected real-time data sources, we now have an enormous number of applications with sensors that produce important, continuously changing data.</p><p>The detection of anomalies in real-time streaming data has practical and significant applications across many industries. There are numerous use cases for anomaly detection, including preventative maintenance, fraud prevention, fault detection, and monitoring. The use cases can be found throughout numerous industries such as finance, IT, security, medical, energy, e-commerce, and social media.</p><p>We define an anomaly as a point in time where the behavior of the system is unusual and significantly different from past behavior. Under this definition, an anomaly does not necessarily imply a problem. A change might be for a negative reason like the temperature sensor on an engine going up, indicating a possible imminent failure. Or the change might be for a positive reason like web clicks on a new product page are abnormally high, showing strong demand. Either way, the data is unusual and may require action. Anomalies can be spatial, meaning the value is outside the typical range like the first and third anomalies in <ref type="figure" target="#fig_0">Figure 1</ref>. They can also be temporal, where the value isn't outside the typical range but the sequence in which it occurs is unusual. The middle anomaly in <ref type="figure" target="#fig_0">Figure 1</ref> is a temporal anomaly.</p><p>Real-time applications impose their own unique constraints for machine learning. Anomaly detection in streaming applications is particularly challenging. The detector must process data and output a decision in real-time, rather than making many passes through batches of files. In most scenarios the number of sensor streams is large and there is little opportunity for human, let alone expert, intervention. As such, operating in an unsupervised, automated fashion (e.g. without manual parameter tweaking) is often a necessity. The underlying system is often non-stationary, and detectors must continuously learn and adapt to changing statistics while simultaneously making predictions.</p><p>The goal of this paper is to introduce a novel anomaly detection technique designed for such real-time applications. We show how to use Hierarchical Temporal Memory (HTM) networks <ref type="bibr" target="#b24">Padilla et al., 2013;</ref><ref type="bibr" target="#b26">Rozado et al., 2012)</ref> in a principled way to robustly detect anomalies in a variety of conditions. The resulting system is efficient, extremely tolerant to noisy data, continously adapts to changes in the statistics of the data, and detects very subtle anomalies while minimizing false positives. We show qualitative examples from a real-time financial anomaly detection application. We also report leading results on an open benchmark for real-time anomaly detection. The algorithm has been deployed commercially, and we discuss some of the practical lessons learned from these deployments. We have made the complete source code (including end application code) available in open source repositories 1 . Anomalies are labeled with red circles. The first anomaly was a planned shutdown. The third anomaly is a catastrophic system failure. The second anomaly, a subtle but observable change in the behavior, indicated the actual onset of the problem that led to the eventual system failure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Anomaly detection in time-series is a heavily studied area, dating back to <ref type="bibr" target="#b10">(Fox, 1972)</ref>. Some techniques, like classification-based methods, are supervised or semisupervised. While labelled data can be used to improve results, supervised techniques are typically unsuitable for anomaly detection <ref type="bibr" target="#b11">(Görnitz et al., 2013)</ref>. <ref type="figure" target="#fig_1">Figure 2</ref> illustrates the need for continuous learning, which is not typically possible with supervised algorithms.</p><p>Other techniques, like simple thresholds, clustering, and exponential smoothing, are only capable of detecting spatial anomalies. Holt-Winters is an example of the latter that is commonly implemented for commercial applications <ref type="bibr" target="#b29">(Szmit &amp; Szmit, 2012)</ref>. Also commonly used in practice are change point detection methods, which are capable of identifying temporal anomalies. The typical approach is to model the time series in two independent moving windows and detect when there is a significant deviation in the time series metrics <ref type="bibr">(Basseville &amp; Nikiforov, 1993)</ref>. These methods are often extremely fast to compute and have low memory overhead. The detection performance of these statistical techniques can be sensitive to the size of the windows and thresholds. This sometimes results in many false positives as the data changes, requiring frequent updates to the thresholds in order to detect anomalies while minimizing false positives.</p><p>1 Please see http://numenta.org The Skyline project provides an open source implementation of a number of statistical techniques for detecting anomalies in streaming data <ref type="bibr" target="#b28">(Stanway, 2013)</ref>. The different algorithms can be combined into an ensemble. The Skyline algorithms are included in our results.</p><p>There are other algorithms capable of detecting temporal anomalies in complex scenarios. ARIMA is a general purpose technique for modeling temporal data with seasonality <ref type="bibr" target="#b4">(Bianco et al., 2001)</ref>. It is effective at detecting anomalies in data with regular daily or weekly patterns. It is not capable of dynamically determining the period of seasonality, although extensions have been developed for doing so <ref type="bibr" target="#b15">(Hyndman &amp; Khandakar, 2008)</ref>. A technique for applying ARIMA to multivariate data has also been studied <ref type="bibr" target="#b31">(Tsay, 2000)</ref>. Bayesian change point detection methods are a natural approach to segmenting time series and can be used for online anomaly detection <ref type="bibr" target="#b0">(Adams &amp; Mackay, 2007;</ref><ref type="bibr" target="#b30">Tartakovsky et al., 2013)</ref>. Some additional techniques for general purpose anomaly detection on streaming data include <ref type="bibr" target="#b18">(Keogh et al., 2005;</ref><ref type="bibr" target="#b25">Rebbapragada et al., 2009)</ref>.</p><p>Yahoo released the open source EGADS framework for time series anomaly detection that pairs time series forecasting techniques with common anomaly detection algorithms <ref type="bibr" target="#b21">(Laptev et al., 2015)</ref>. Twitter released its own open source anomaly detection algorithms for time series data <ref type="bibr" target="#b17">(Kejariwal, 2015)</ref>. Both are capable of detecting spatial and temporal anomalies. Empirical comparison with Twitter's detection software are included in our results.</p><p>There have been a number of model-based approaches applied to specific domains. These tend to be extremely specific to the domain they are modeling. Examples include anomaly detection in aircraft engine measurements <ref type="bibr" target="#b27">(Simon &amp; Rinehart, 2015)</ref>, cloud datacenter temperatures <ref type="bibr" target="#b23">(Lee et al., 2013)</ref>, and ATM fraud detection <ref type="bibr" target="#b20">(Klerx et al., 2014)</ref>. While these approaches may have success in a spe-cific domain, they are not suitable for general purpose applications.</p><p>We have reviewed some of the algorithms most relevant to our work. A comprehensive literature review is outside the scope of this paper but there are several thorough reviews of anomaly detection techniques for further reading <ref type="bibr" target="#b8">(Chandola et al., 2009;</ref><ref type="bibr" target="#b14">Hodge &amp; Austin, 2004;</ref><ref type="bibr" target="#b7">Chandola et al., 2008)</ref>.</p><p>In this paper we focus on using Hierarchical Temporal Memory (HTM) for anomaly detection. HTM is a machine learning algorithm derived from neuroscience that models spatial and temporal patterns in streaming data <ref type="bibr" target="#b26">Rozado et al., 2012)</ref>. HTM compares favorably with some state of the art algorithms in sequence prediction, particularly complex non-Markovian sequences <ref type="bibr" target="#b9">(Cui et al., 2015;</ref><ref type="bibr" target="#b24">Padilla et al., 2013)</ref>. HTMs are continuously learning systems that automatically adapt to changing statistics, a property particularly relevant to streaming analytics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Anomaly Detection Using HTM</head><p>Typical streaming applications involve analyzing a continuous stream of data occurring in real-time. Such applications contain some unique challenges. We formalize this as follows. Let the vector x t represent the state of a real-time system at time t. The model receives a continuous stream of inputs:</p><formula xml:id="formula_0">. . . , x t−2 , x t−1 , x t , x t+1 , x t+2 , . . .<label>(1)</label></formula><p>Consider for example, the task of monitoring a datacenter. Components of x t might include CPU usage for various servers, bandwidth measurements, latencies of servicing requests, etc. At each point in time t we would like to determine whether the behavior of the system up to that point is unusual. One of the key challenges is that the determination must be made in real-time, i.e. before time t + 1 and without any look ahead. In practical applications, the statistics of the system can change dynamically. For example, in a production datacenter, software upgrades might be installed at any time that alter the behavior of the system ( <ref type="figure" target="#fig_1">Figure 2</ref>). Any retraining of a model must be done on-line, again before time t + 1. Finally, the individual measurements are not independent and contain significant temporal patterns that can be exploited.</p><p>HTM is a learning algorithm that appears to match the above constraints. HTM networks are continuously learning and model the spatiotemporal characteristics of their inputs. HTMs have been shown to work well for prediction tasks <ref type="bibr" target="#b9">(Cui et al., 2015;</ref><ref type="bibr" target="#b24">Padilla et al., 2013)</ref> but HTM networks do not directly output an anomaly score. In order to perform anomaly detection we utilize two different internal representations available in the HTM. Given an input x t , the vector a(x t ) is a sparse binary code representing the current input. We also utilize an internal state vector π(x t ) which represents a prediction for a(x t+1 ), i.e. a prediction of the next input x t+1 . The prediction vector incorporates inferred information about current sequences. In particular, a given input will lead to different predictions depending on the current detected sequence and the current inferred position of the input within the sequence. The quality of the prediction is dependent on how well the HTM is modeling the current data stream. See  for a more detailed explanation of these representations. a(x t ) and π(x t ) are recomputed at every iteration but do not directly represent anomalies. In order to create a robust anomaly detection system we introduce two additional steps. We first compute a raw anomaly score from the two sparse vectors. We then compute an anomaly likelihood value which is thresholded to determine whether the system is anomolous. <ref type="figure" target="#fig_2">Figure 3</ref> shows a block diagram of our algorithm. These two steps are detailed below. We then describe how to robustly handle a larger system consisting of multiple distinct models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Computing the Raw Anomaly Score</head><p>We compute a raw anomaly score that measures the deviation between the model's predicted input and the actual input. It is computed from the intersection between the predicted and actual sparse vectors. At time t the raw anomaly score, s t , is given as:</p><formula xml:id="formula_1">s t = 1 − π(x t−1 ) · a(x t ) |a(x t )|<label>(2)</label></formula><p>The raw anomaly score will be 0 if the current input is perfectly predicted, 1 if it is completely unpredicted, or somewhere in between depending on the similarity between the input and the prediction.</p><p>An interesting aspect of this score is that branching sequences are handled correctly. In HTMs, multiple predictions are represented in π(x t ) as a binary union of each individual prediction. Similar to Bloom filters, as long as the vectors are sufficiently sparse and of sufficient dimensionality, a moderate number of predictions can be represented simultaneously with exponentially small chance of error <ref type="bibr" target="#b6">(Bloom, 1970;</ref>. The anomaly score handles branching sequences gracefully in the following sense. If two completely different inputs are both possible and predicted, receiving either input will lead to a 0 anomaly score. Any other input will generate a positive anomaly score.</p><p>Changes to the underlying system are also handled gracefully due to the continuous learning nature of HTMs. If there is a shift in the behavior of the system, the anomaly score will be high at the point of the shift, but will automatically degrade to zero as the model adapts to the "new normal". Shifts in the temporal characteristics of the system are handled in addition to spatial shifts in the underlying metric values. (See Results section for some examples.) <ref type="figure">Figure 4</ref>. A very noisy, unpredictable stream. The data shows the latency (in seconds) of a load balancer on a production website. The red dot shows the approximate location of an unusual increase in latencies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Computing Anomaly Likelihood</head><p>The raw anomaly score described above represents an instantaneous measure of the predictability of the current input stream. This works well for predictable scenarios but in many practical applications, the underlying system is inherently noisy and unpredictable. In these situations it is often the change in predictability that is indicative of anamolous behavior. As an example, consider <ref type="figure">Figure 4</ref>. This data shows the latency of a load balancer in serving HTTP requests on a production web site. Although the latency is generally low, it is not unusual to have occasional random jumps, and the corresponding spike in anomaly score. Thresholding the raw anomaly score directly would lead to many false positives. However, a sustained increase in the frequency of high latency requests, as shown in the second half of the figure, is unusual and thus reported as an anomaly.</p><p>To handle this class of scenarios, we introduce a second step. Rather than thresholding the raw score directly, we model the distribution of anomaly scores and use this distribution to check for the likelihood that the current state is anomalous. The anomaly likelihood is thus a metric defining how anomalous the current state is based on the prediction history of the HTM model. To compute the anomaly likelihood we maintain a window of the last W raw anomaly scores. We model the distribution as a rolling normal distribution where the sample mean and variance are continuously updated from previous anomaly scores as follows:</p><formula xml:id="formula_2">µ t = i=W −1 i=0 s t−i k (3) σ 2 t = i=W −1 i=0 (s t−i − µ t ) 2 k − 1<label>(4)</label></formula><p>We then compute a recent short term average of anomaly scores, and apply a threshold to the Gaussian tail probability (Q-function, <ref type="bibr" target="#b16">(Karagiannidis &amp; Lioumpas, 2007)</ref>) to decide whether or not to declare an anomaly 2 . We define the anomaly likelihood as the complement of the tail probability:</p><formula xml:id="formula_3">L t = 1 − Q μ t − µ t σ t<label>(5)</label></formula><p>where:μ</p><formula xml:id="formula_4">t = i=W −1 i=0 s t−i j<label>(6)</label></formula><p>W here is a window for a short term moving average, where W W . We threshold L t and report an anomaly if it is very close to 1:</p><formula xml:id="formula_5">anomaly detected ≡ L t ≥ 1 −<label>(7)</label></formula><p>It is important to note that this test is applied to the distribution of anomaly scores, not to the distribution of underlying metric values x t . As such, it is a measure of how well the model is able to predict, relative to the recent history. In clean predictable scenarios L t behaves similarly to s t . In these cases the distribution of scores will have very small variance and will be centered near 0. Any spike in s t will similarly lead to a corresponding spike in L t . However in scenarios with some inherent randomness or noise, the variance will be wider and the mean further from 0. A single spike in s t will not lead to a significant increase in L t but a series of spikes will. Interestingly, a scenario that goes from wildly random to completely predictable will also trigger an anomaly.</p><p>Since thresholding L t involves thresholding a tail probability, there is an inherent upper limit on the number of alerts.</p><p>With very close to 0 it would be unlikely to get alerts with probability much higher than . This also imposes an upper bound on the number of false positives. Under the assumption that anomalies themselves are also extremely rare, the hope is that the ratio of true positives to false positives is always in a healthy range (see Results below).</p><p>Although we use HTM as the underlying temporal model, the likelihood technique is not specific to HTMs. It could be used with any other algorithm that outputs a sparse code or scalar anomaly score. The overall quality of the detector will be dependent on the ability of the underlying model to represent the domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Combining Multiple Independent Models</head><p>Many industrial or complex environments contain a large number of sensory data streams. In theory, given sufficient resources, it is possible to create one large complex model with the entire vector stream as input. In practice, it is common to decompose a large system into a number of smaller models. It is easier to train smaller models because the complexity of training and inference grows much faster than linearly with the size of the input dimensionality <ref type="bibr" target="#b5">(Bishop, 2006)</ref>. Thus decomposing the solution into a set of smaller models may lead to improved accuracy and much faster performance. However, even with such a decomposition, it is important to compute a global measure that accumulates the results of individual models and indicates whether those portions of the system are in an unusual state. As an example, consider a datacenter running a production website. An automated alerting system might need to continually decide whether to generate an alarm and possibly wake up the on-call engineer.</p><p>We assume the inputs representing the system are broken up into M distinct models. Let x m t be the input at time t to the m'th model, and s m t be the raw anomaly scores associated with each model. We wish to compute a global metric indicating the overall likelihood of an anomaly in the system (see <ref type="figure" target="#fig_3">Figure 5</ref>).</p><p>One possible approach is to estimate the joint distribution P (s 0 t , . . . , s M −1 t ) and apply a threshold to the tail probability. It can be challenging to model the joint distribution, particularly in a streaming context. If we further assume the models are independent, we could simplify and instead estimate: </p><formula xml:id="formula_6">P (s 0 t , . . . , s M −1 t ) = i=M −1 i=0 P (s i t )<label>(8)</label></formula><p>Given this, a version of our anomaly likelihood can be computed as:</p><formula xml:id="formula_7">1 − i=M −1 i=0 Q μ i t − µ i t σ i t<label>(9)</label></formula><p>There is one flaw with the above methodology. In real-time dynamic scenarios, critical problems in one part of the system can often cascade to other areas. Thus there are often random temporal delays built in, which can in turn lead to different temporal delays between anomaly scores in the various models <ref type="bibr" target="#b19">(Kim et al., 2013)</ref>. For example, a situation where multiple unusual events occur close to one another in different models is far more unlikely and unusual than a single event in a single model. It is precisely these situations which are valuable to detect and capture in a complex system.</p><p>Ideally we would be able to estimate a joint distribution of anomaly scores that go back in time, i.e.</p><formula xml:id="formula_8">P (s 0 t−j , s 1 t−j , . . . , s M −2 t , s M −1 t ).</formula><p>In theory this would capture all the dependencies, but this is even harder to estimate than the earlier joint probability. Alternatively, in situations where the system's topology is relatively clear and under your control, it is possible to create an explicit graph of dependencies, monitor expected behavior between pairs of nodes, and detect anomalies with respect to those expectations. This technique has been shown to enable very precise determination of anomalies in websites where specific calls between services are monitored <ref type="bibr" target="#b19">(Kim et al., 2013)</ref>. However in most applications this technique is also impractical. It may be difficult to model the various dependencies and it is often infeasible to instrument arbitrary systems to create this graph.</p><p>We would like to have a system that is fast to compute, makes relatively few assumptions, and is adaptive. We propose a simple general purpose mechanism for handling multiple models by modifying Eq. (9) to incorporate a smooth temporal window. A windowing mechanism allows the system to incorporate spikes in likelihood that are close in time but not exactly coincident. Let G be a Gaussian convolution kernel:</p><formula xml:id="formula_9">G(x; σ) = 1 √ 2πσ exp − x 2 2σ 2<label>(10)</label></formula><p>We apply this convolution to each individual model to obtain a final anomaly likelihood score 3 :</p><formula xml:id="formula_10">L t = 1 − i=M −1 i=0 2(G * Q)(μ i t − µ i t σ i t )<label>(11)</label></formula><p>As before, we detect an anomaly if the combined anomaly likelihood is greater than a threshold L t ≥ 1− . Eq. 11 represents a principled yet pragmatic approach for detecting anomalies in complex real time streaming applications 4 . As before, L t is an indirect measure, computed on top of the raw anomaly scores from each model. It reflects the underlying predictability of the models at a particular point in time and does not directly model the sensor measurements themselves.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Practical Considerations</head><p>There are three parameters in the single model scenario: W , W , and . W is the duration for computing the distribution of anomaly scores. The system performance is not sensitive to W as long as it is large enough to compute a reliable distribution. The number W controls the short term average of anomaly scores. In all our experiments below, we use a generous value of W = 8000 and W = 10.</p><p>The parameter is perhaps the most important parameter. It controls how often anomalies are reported, and the balance between false positives and false negatives. In practice we have found that = 10 −5 works well across a large range of domains. Intuitively, this should represent one false positive about once every 10,000 records.</p><p>The muliple model scenario introduces one additional parameter, the window width σ. This is somewhat domain dependent but due to the soft Gaussian convolution, the system is not extremely sensitive to this setting. In all our experiments below, σ = 6.</p><p>Computational efficiency is important for real-time applications. In our implementation each model requires less than 10 milliseconds per input vector on a current high end laptop. A server based deployment running multiple models in parallel can run about 5,000 models on a high end server. This figure assumes that each input arrives once every 5 minutes (thus each of the 5,000 models needs to output one score every 5 minutes). As a service to the community, we have released the complete source code to the algorithms as well as the server application codebase as open source 5 . </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Results</head><p>We first show examples from a deployed application that qualitatively demonstrates the behavior of our algorithm. We then show quantitative results on benchmark data.</p><p>We have integrated our anomaly detection algorithm into a live real-time product. The application continuously monitors a large set of financial and social media metrics for a range of securities and alerts users in real time when significant anomalies occur. <ref type="figure" target="#fig_4">Figure 6</ref> shows two screenshots from our application that demonstrate the value of realtime anomaly detection to end users. In this example, an anomaly in the volume of Twitter activity (related to a decrease in dividends) preceded a sharp drop in stock price. The Twitter anomaly occurred well before market opening. The underlying data streams are extremely noisy and many of the important anomalies are temporal in nature. <ref type="figure">Figure 7</ref> shows raw data extracted from our application demonstrating one such anomaly. The figure plots stock trading volume for Facebook for a few hours. Each point represents average trading volume for a period of five minutes. It is normal to see a single spike in trading volume but it is extremely unusual to see two consecutive spikes. Two con-secutive spikes therefore represents a temporal anomaly in this stream. The red dashed line indicates the point at which our algorithm detected the anomaly, i.e. the point in time where L t ≥ 1 − 10 −5 . <ref type="figure">Figure 7</ref>. Stock trading volume for Facebook on Feb 2, 2016. The red dashed line shows the point at which our algorithm detected an anomaly. In this stream two consecutive spikes are highly unusual and represent an anomaly. <ref type="figure" target="#fig_5">Figure 8</ref> shows a more detailed example demonstrating the value of combining multiple metrics. The two solid lines indicate the Q-values in Eq (5) for two separate metrics related to Comcast shares. The lower the curve, the more likely it is that the underlying metric is anomalous. When looking at single models independently, an anomaly would only be detected if one of these values drops below = 10 −5 . In this case no anomaly would be detected since neither one dips below that value. However, as shown by the drops, both metrics are behaving unusually. The red dashed line shows the result of detecting an anomaly based on our combined metric, Eq. (11). Because the blue curve is so close to 10 −5 , incorporating both metrics correctly flags an anomaly as soon as the black curve dips below 10 −1 . As can be appreciated from the chart, it is difficult to line up two metrics precisely, hence the value of the smooth temporal window.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Results on Real-World Benchmark Data</head><p>The above sections demonstrate qualitative results on individual data streams. In this section we provide quantitative benchmark results. NAB is a benchmark containing 58 streams with over 350,000 records of real-time streaming data taken from a variety of different applications <ref type="bibr" target="#b22">(Lavin &amp; Ahmad, 2015)</ref>. The dataset is labeled with anomalies. The first 15% of each data file is reserved for autocalibration. NAB also includes a window around each anomaly, and incorporates a time-sensitive scoring mech-   <ref type="table">Table 1</ref>. Performance on the NAB benchmark. The first column indicates the standard NAB score for each algorithm. The last two columns indicate the score for the "prefer low FP" and "prefer low FN" profiles of NAB, representing two specific points on the ROC curve. For comparison we include a "Perfect" detector, an idealized detector that makes no mistakes.</p><p>anism that favors early detection (as long as detections are within the anomaly windows). "Application profiles" define the weighting for false positives and false negatives to illustrate scenarios where fewer missed detections or fewer erroneous detections are more valued. The benchmark requires models to use a single set of parameters across all streams to mimic automation in real-world deployments.</p><p>We ran our HTM based anomaly detector on NAB. <ref type="table">Table 1</ref> contains our scores as well as scores for several other algorithms, including Etsy Skyline, Twitter AnomalyDetec-tionVec (ADVec), and a variant of Bayesian online change point detection <ref type="bibr">(Adams &amp; Mackay, 2007) 6</ref> . We include the score for a "Perfect" detector, i.e. an idealized detector that detects every anomaly as early as possible and generates no false positives. We also include the scores for "sliding threshold" and "random" detectors as baselines for comparison. The HTM detector achieves the best overall score, followed by Twitter ADVec and Etsy Skyline. However, as can be seen by the performance of the Perfect detector, the benchmark is a challenging one with significant room for future improvements.</p><p>The NAB benchmark doesn't measure an explicit ROC curve but includes two additional "application profiles" that tradeoff the weighting between false positives and false negatives. The "reward low FP" profile applies a higher cost to false positives. Conversely the "reward low FN" profile applies a higher cost to false negatives. The last two columns of <ref type="table">Table 1</ref> show our scores for those two profiles. Although there are individual variations (Twitter in particular improves significantly in the "reward low FN" column), our detector performs best overall indicating that it achieves a good tradeoff between false positives and false negatives.</p><p>A closer look at the errors illustrates some interesting situations that arise in real time applications. <ref type="figure" target="#fig_6">Figure 9</ref>(a) demonstrates the value of continuous learning. This file shows CPU usage on a production server over time and contains two anomalies. The first is a simple spike detected by all algorithms. The second is a sustained shift in the usage. Skyline and HTM both detect the change but then adapt to the new normal (with Skyline adapting quickest). Twitter ADVec however continues to generate anomalies for several days. Skyline scored highest on this stream.  <ref type="figure" target="#fig_6">Figure 9(b)</ref> is an example demonstrating early detection. All three detectors detect the anomaly but HTM detects it three hours earlier due to a subtle shift in metric dynamics. <ref type="figure" target="#fig_6">Figure 9</ref>(c) shows a close up of the results for the machine temperature sensor data shown in <ref type="figure" target="#fig_0">Figure 1</ref>. The anomaly on the left is a somewhat subtle temporal anomaly where the temporal behavior is unusual but individual readings are within the expected range. This anomaly (which preceded the catastrophic failure on February 8) is only detected by HTM. All three detectors detect the anomaly on the right, although Skyline and HTM detect it earlier than ADVec. In this plot HTM and Skyline also each have a false positive.</p><p>We chose these examples because they illustrate common situations that occur in practice. Qualitatively we have found that temporal changes in behavior often precede a larger, easily detectable, shift. Temporal and sequence based anomaly detection techniques may be able to detect anomalies in streaming data before they are easily visible. We speculate that the early detection in <ref type="figure" target="#fig_6">Figure 9</ref>(b) is due to the temporal modeling in HTMs as the earlier shift is difficult to detect through purely spatial means. This provides hope that such algorithms can be used in production to provide early warning and perhaps help avoid problems far more reliably than spatial techniques.</p><p>Low scores for Bayesian change point detection are due to its strong assumptions regarding a Gaussian or Gamma distribution of data points. Real-world streaming data is messy and these assumptions do not hold in many applications. In data where it does hold (e.g. Figs 2, 9a) the algorithm works well but for most streams (e.g. <ref type="figure" target="#fig_0">Figs 1, 4)</ref> it does not. Indeed, it is this lack of any consistent distribution across streaming applications that led us to model the distribution of anomaly scores rather than the distribution of metric values.</p><p>From the standpoint of computational efficiency, on the first author's laptop, it takes 48 minutes to run NAB's complete dataset of 365,558 records. This represents an average of 8 milliseconds per record.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Discussion</head><p>With the increase in connected real-time sensors, the detection of anomalies in streaming data is becoming increasingly important. The use cases cut across a large number of industries; anomaly detection might represent the most significant near-term application for machine learning in IoT.</p><p>In this paper we have discussed a novel anomaly detection algorithm for real-time streaming applications. Based on HTMs, the algorithm is capable of detecting spatial and temporal anomalies in predictable and noisy domains. A probabilistic formulation allows the user to control the rate of false positives, an important consideration in many applications. We have discussed an extension to large systems with multiple independent models that incorporate temporal windows.</p><p>Our results show that the algorithm can achieve best in class results on a benchmark of real world data sources.</p><p>Our system is practical in that it is computationally efficient, automatically adapts to changing statistics, and requires little to no parameter tuning. It is currently in use in commercial applications, and the complete source code to the algorithm is available as open source software 7 .</p><p>There are a number of possible extensions to the algorithm. The error analysis from NAB indicates that the errors from our algorithm are not necessarily correlated with errors from the other two algorithms. As such an ensemble based approach might provide a significant increase in accuracy. The assumption of a Gaussian distribution for anomaly scores is not always correct. Exploring other distributions represents another possible extension that could potentially improve the results.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>The figure shows real-world temperature sensor data from an internal component of a large industrial machine.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>CPU utilization (percent) for an Amazon EC2 instance. A change to the software running on the machine caused the CPU usage to change. Continuous learning is essential for performing anomaly detection on streaming data like this.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>The primary functional steps in our algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 .</head><label>5</label><figDesc>Functional diagram illustrating a complex system with multiple independent models.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 .</head><label>6</label><figDesc>Real-time stock anomalies for Feb 4, 2016.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 8 .</head><label>8</label><figDesc>Q-values derived from two Comcast metrics on Feb 4, 2016. The red dashed line shows the point at which our algorithm detected an anomaly.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 9 .</head><label>9</label><figDesc>Example NAB results for three different data streams. The shapes correspond to different detectors: HTM, Skyline, and ADVec are diamond, square, and plus respectively. True positives are labeled in black, and false positives are colored red. The pink shaded regions denote NAB's anomaly windows; any detection within a window is considered a true positive.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 9</head><label>9</label><figDesc>(b) and (c) demonstrate temporal anomalies and their importance in early detection.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">The Guassian tail probability is the probability that a Gaussian variable will obtain a value larger than x standard deviations above the mean.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">Since this is a real-time system with no look-ahead, the kernel only applies to time ≤ t. As such we use a half-normal distribution as the kernel, hence the additional factor of 2. 4 Due to numerical precision issues with products of probabilities, in our implementation we follow common practice and use summation of log probabilities.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">Please see https://github.com/numenta, specifically the nupic and numenta-apps repositories.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">Please see the NAB repository at https://github. com/numenta/NAB for specific implementation and parameter tuning details.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We thank Alex Lavin, Yuwei Cui, and Jeff Hawkins for many helpful comments and suggestions.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Prescott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">J C</forename><surname>Mackay</surname></persName>
		</author>
		<idno type="arXiv">doi:arXiv:0710.3742v1</idno>
		<ptr target="http://arxiv.org/abs/0710.3742" />
	</analytic>
	<monogr>
		<title level="j">Bayesian Online Changepoint Detection. arXiv.org</title>
		<imprint>
			<biblScope unit="issue">7</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">How do neurons operate on sparse distributed representations? A mathematical theory of sparsity, neurons and active dendrites</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subutai</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Hawkins</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1601.00720[q-bio.NC</idno>
		<ptr target="http://arxiv.org/abs/1601.00720" />
		<imprint>
			<date type="published" when="2016-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Basseville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Nikiforov</surname></persName>
		</author>
		<ptr target="http://numenta.com/nab" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Changes</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Outlier detection in regression models with ARIMA errors using robust estimates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Bianco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>García Ben</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Martínez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">J</forename><surname>Yohai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Forecasting</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="565" to="579" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Pattern Recognition and Machine Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">M</forename><surname>Bishop</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>Springer</publisher>
			<biblScope unit="volume">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Space/time trade-offs in hash coding with allowable errors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Burton</forename><forename type="middle">H</forename><surname>Bloom</surname></persName>
		</author>
		<idno>00010782</idno>
		<imprint>
			<date type="published" when="1970" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Comparative Evaluation of Anomaly Detection Techniques for Sequence Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Chandola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Mithal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kumar</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICDM.2008.151</idno>
	</analytic>
	<monogr>
		<title level="m">Eighth IEEE International Conference on Data Mining</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="743" to="748" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Anomaly detection: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chandola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Varun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys (CSUR)</title>
		<imprint>
			<biblScope unit="page" from="1" to="72" />
			<date type="published" when="2009-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Continuous online sequence learning with an unsupervised neural network model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuwei</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Surpur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chetan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subutai</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Hawkins</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1512.05463</idno>
		<ptr target="http://" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>cs.NE</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Outliers in time series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fox</surname></persName>
		</author>
		<idno>00359246</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society, Series B (Methodological)</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="350" to="363" />
			<date type="published" when="1972" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Toward supervised anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nico</forename><surname>Görnitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kloft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Marius</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konrad</forename><surname>Rieck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulf</forename><surname>Brefeld</surname></persName>
		</author>
		<idno type="DOI">10.1613/jair.3623</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="235" to="262" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Why Neurons Have Thousands of Synapses, a Theory of Sequence Memory in Neocortex</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Hawkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subutai</forename><surname>Ahmad</surname></persName>
		</author>
		<idno type="DOI">http:/journal.frontiersin.org/article/10.3389/fncir.2016.00023/abstract</idno>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Neural Circuits</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">23</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2016-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title/>
		<idno type="DOI">http:/journal.frontiersin.org/article/10.3389/fncir.2016.00023/abstract</idno>
		<ptr target="//journal.frontiersin.org/article/10.3389/fncir.2016.00023/abstract" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">A survey of outlier detection methodologies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victoria</forename><forename type="middle">J</forename><surname>Hodge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jim</forename><surname>Austin</surname></persName>
		</author>
		<idno>02692821</idno>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Automatic time series forecasting : the forecast package for R Automatic time series forecasting : the forecast package for R</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><forename type="middle">J</forename><surname>Hyndman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yeasmin</forename><surname>Khandakar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Journal Of Statistical Software</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="1" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Athanaszsios S. An improved approximation for the Gaussian Q-function</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><forename type="middle">K</forename><surname>Karagiannidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lioumpas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Communications Letters</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="644" to="646" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Twitter Engineering: Introducing practical and robust anomaly detection in a time series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arun</forename><surname>Kejariwal</surname></persName>
		</author>
		<ptr target="http://bit.ly/1xBbX0Z" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>Online blog</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">HOT SAX: Efficiently finding the most unusual time series subsequence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eamonn</forename><surname>Keogh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jessica</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ada</forename><surname>Fu</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICDM.2005.79</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings -IEEE International Conference on Data Mining, ICDM</title>
		<meeting>-IEEE International Conference on Data Mining, ICDM</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="226" to="233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Root cause detection in a service-oriented architecture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myunghwan</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roshan</forename><surname>Sumbaly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Shah</surname></persName>
		</author>
		<idno type="DOI">10.1145/2465529.2465753</idno>
	</analytic>
	<monogr>
		<title level="m">ACM International Conference on Measurement and Modeling of Computer Systems (SIGMETRICS &apos;13)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page">93</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Model-Based Anomaly Detection for Discrete Event Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Klerx</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Anderka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Maik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans</forename><surname>Buning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kleine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steffen</forename><surname>Priesterjahn</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICTAI.2014.105</idno>
	</analytic>
	<monogr>
		<title level="m">2014 IEEE 26th International Conference on Tools with Artificial Intelligence</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014-11" />
			<biblScope unit="page" from="665" to="672" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Generic and Scalable Framework for Automated Time-series Anomaly Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikolay</forename><surname>Laptev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saeed</forename><surname>Amizadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Flint</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1939" to="1947" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Evaluating Realtime Anomaly Detection Algorithms the Numenta Anomaly Benchmark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Lavin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subutai</forename><surname>Ahmad</surname></persName>
		</author>
		<idno>doi: 10.1109/ ICMLA.2015.141</idno>
	</analytic>
	<monogr>
		<title level="m">14th International Conference on Machine Learning and Applications (IEEE ICMLA&apos;15)</title>
		<meeting><address><addrLine>Miami, Florida</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Model-based thermal anomaly detection in cloud datacenters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eun</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kyung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hariharasudhan</forename><surname>Viswanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dario</forename><surname>Pompili</surname></persName>
		</author>
		<idno>doi: 10.1109/ DCOSS.2013.8</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings -IEEE International Conference on Distributed Computing in Sensor Systems</title>
		<meeting>-IEEE International Conference on Distributed Computing in Sensor Systems<address><addrLine>DCoSS</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="191" to="198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Performance of a hierarchical temporal memory network in noisy sequence learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">E</forename><surname>Padilla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Russell</forename><surname>Brinkworth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mcdonnell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mark</surname></persName>
		</author>
		<idno type="DOI">10.1109/CyberneticsCom.2013.6865779</idno>
	</analytic>
	<monogr>
		<title level="m">2013 IEEE International Conference on Computational Intelligence and Cybernetics (CYBERNETICSCOM)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013-12" />
			<biblScope unit="page" from="45" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Finding anomalous periodic time series : An application to catalogs of periodic variable stars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Umaa</forename><surname>Rebbapragada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Protopapas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pavlos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carla</forename><forename type="middle">E</forename><surname>Brodley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Alcock</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10994-008-5093-3</idno>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="page" from="281" to="313" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Extending the bioinspired hierarchical temporal memory paradigm for sign language recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Rozado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><forename type="middle">B</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pablo</forename><surname>Varona</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neucom.2011.10.005</idno>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="75" to="86" />
			<date type="published" when="2012-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">A Model-Based Anomaly Detection Approach for Analyzing Streaming Aircraft Engine Measurement Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donald</forename><forename type="middle">L</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">W</forename><surname>Rinehart</surname></persName>
		</author>
		<idno>2015-218454</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
		<respStmt>
			<orgName>NASA</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Etsy</forename><surname>Stanway</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Skyline</surname></persName>
		</author>
		<ptr target="https://github.com/etsy/skyline" />
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Usage of modified holtwinters method in the anomaly detection of network traffic: Case studies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maciej</forename><surname>Szmit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Szmit</surname></persName>
		</author>
		<idno type="DOI">10.1155/2012/192913</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer Networks and Communications</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Efficient Computer Network Anomaly Detection by Changepoint Detection Methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">G</forename><surname>Tartakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksey</forename><forename type="middle">S</forename><surname>Polunchenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grigory</forename><surname>Sokolov</surname></persName>
		</author>
		<idno type="DOI">10.1109/JSTSP.2012.2233713</idno>
		<ptr target="http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6380529" />
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of Selected Topics in Signal Processing</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="4" to="11" />
			<date type="published" when="2013-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Outliers in multivariate time series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Tsay</surname></persName>
		</author>
		<idno>0006-3444. doi: 10. 1093/biomet/87.4.789</idno>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="789" to="804" />
			<date type="published" when="2000-12" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
