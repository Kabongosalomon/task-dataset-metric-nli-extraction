<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Function Space Pooling For Graph Convolutional Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Padraig</forename><surname>Corcoran</surname></persName>
							<email>corcoranp@cardiff.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Informatics</orgName>
								<orgName type="institution">Cardiff University</orgName>
								<address>
									<settlement>Wales</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Function Space Pooling For Graph Convolutional Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T10:23+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>graph neural network · vertex pooling · function space</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Convolutional layers in graph neural networks are a fundamental type of layer which output a representation or embedding of each graph vertex. The representation typically encodes information about the vertex in question and its neighbourhood. If one wishes to perform a graph centric task, such as graph classification, this set of vertex representations must be integrated or pooled to form a graph representation. In this article we propose a novel pooling method which maps a set of vertex representations to a function space representation. This method is distinct from existing pooling methods which perform a mapping to either a vector or sequence space. Experimental graph classification results demonstrate that the proposed method generally outperforms most baseline pooling methods and in some cases achieves best performance.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Many real world systems have a relational structure which can be modelled as a graph. These include physical systems where the bodies and joints correspond to the vertices and edges respectively <ref type="bibr" target="#b19">[20]</ref>; robot swarms where robots and communication links correspond to the vertices and edges respectively <ref type="bibr" target="#b20">[21]</ref>; and topological maps where locations and paths correspond to the vertices and edges respectively <ref type="bibr" target="#b3">[4]</ref>. Given this, there exists great potential for the application of machine learning to graphs. With the great successes of neural networks and deep learning to the analysis of images and natural language, there has recently been much research considering the application or generalization of neural networks to graphs. In many cases this has resulted in state of the art performance for many tasks <ref type="bibr" target="#b24">[25]</ref>.</p><p>Graph convolutional is a neural network architecture commonly applied to graphs which consists of a sequence of convolutional layers. The output of a sequence of such layers is a set of vertex representations where each element in this set encodes properties of a corresponding vertex and the vertices in its neighbourhood. In their seminal work, Gilmer et al. <ref type="bibr" target="#b8">[9]</ref> showed that many different types of convolutional layers can be formulated in terms of a framework containing two steps. In the first step message passing is performed where each vertex receives messages from adjacent vertices regarding their current representation. In the second step, each vertex performs an update of its representation which is a function of its current representation and the messages it received in the previous step. Graph convolution is fundamentally different to the more commonly used image convolution. Unlike an image where each pixel will have an equal number of adjacent pixels (excluding boundary pixels), each vertex in a graph may have a different number of adjacent vertices. Furthermore, unlike an image where the set of pixels adjacent to a given pixel can be ordered, the set of vertices adjacent to a given vertex cannot be easily ordered. Given these facts, generalizing image convolution methods to graphs is non-trivial.</p><p>If one wishes to perform a vertex centric task such as vertex classification, then one may operate directly on the set of vertex representations output from a sequence of convolutional layers. However, if one wishes to perform a graph centric task such as graph classification, then the set of vertex representations must somehow be integrated to form a graph representation. We refer to this integration step as pooling and it represents the focus of this article. Note that, this step is sometimes referred to as global pooling. Performing pooling represents a challenging problem for a couple of reasons. Firstly, the size of the set of vertex representations will equal the number of vertices in the graph in question and this number will vary from graph to graph. Furthermore, the elements in this set will not be ordered. Therefore the set of vertex representations cannot be directly fed as input to feed-forward or recurrent architecture which require as input an element in a vector space of fixed dimension and an element in a sequence space respectively.</p><p>Commonly employed pooling methods include computing summary statistics of the set of vertex representations such as the mean or sum. However these simple pooling methods are not a complete invariant in the sense that many different sets of vertex representations may result in the same graph representation leading to weak discrimination power <ref type="bibr" target="#b26">[27]</ref>. To overcome this issue and increase discrimination power a number of authors have proposed more sophisticated pooling methods. For example, Ying et al. <ref type="bibr" target="#b28">[29]</ref> proposed a pooling method which performs a hierarchical clustering of the set of vertex representations to produce an element in a vector space of fixed dimension.</p><p>In this article we propose a novel pooling method which maps a set of vertex representations to a function space representation. This method is illustrated in <ref type="figure">Figure 1</ref> in the context of a complete graph classification architecture. The proposed pooling method is parameterized by a single learnable parameter which controls the discrimination power of the method. This makes the method applicable to both finer and coarser classification tasks which require greater and less discrimination power respectively. The proposed pooling method is inspired by related methods in the field of applied topology which map sets of points in R 2 to function space representations <ref type="bibr" target="#b0">[1]</ref>.</p><p>The layout of this paper is as follows. Section 2 reviews related works on graph convolution architectures and pooling methods. Section 3 describes the proposed <ref type="figure">Fig. 1</ref>. The proposed pooling method is illustrated in the context of a complete graph classification architecture. The input graph is first fed to a sequence of graph convolutional layers which outputs a set of vertex representations. The number of elements in this set equals the number of vertices in the original graph. This set is next mapped to a function space representation. This function space representation is then fed to a feed-forward architecture which outputs a predicted graph class.</p><p>pooling method. Section 4 presents an evaluation of this method. Finally section 5 draws some conclusions from this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background &amp; Related Works</head><p>In the following two subsections we review related works on graph convolution architectures and pooling methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Graph Convolution Architectures</head><p>There exist a wide array of graph convolution architectures. In this section we only review those architectures representing theoretical breakthroughs and state of the art. However the interested reader can consult the following review papers for greater details <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b25">26]</ref>. Hamilton et al. <ref type="bibr" target="#b9">[10]</ref> proposed a graph convolution layer known as GraphSAGE which updates a vertex representation by first performing an aggregation of adjacent vertex representations. This aggregation is then concatenated with the current representation of the vertex in question before applying a linear transformation and non-linearity. The authors considered the aggregation functions of mean vertex representation and LSTM (Long Short-Term Memory) applied to a random ordering of vertex presentations. Xu et al. <ref type="bibr" target="#b26">[27]</ref> proposed to apply a multi-layer perceptron, as opposed to a single layer which is most common, to the aggregation of adjacent vertex representations and demonstrated that this improve discrimination power. In a later work the same authors <ref type="bibr" target="#b27">[28]</ref> proposed an architecture known as the jumping knowledge architecture which allows vertices to aggregate information from neighbouring vertices over different ranges. The authors showed that this architecture allows deeper convolutional architectures to be used and outperforms the use of residual connections commonly used in computer vision applications <ref type="bibr" target="#b11">[12]</ref>. Given the successes of attention based architectures in natural language processing <ref type="bibr" target="#b21">[22]</ref>, Velickovic et al. <ref type="bibr" target="#b22">[23]</ref> proposed an attention based architecture for graphs. For a given vertex this architecture allows different weights to be specified for different adjacent vertices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Pooling Methods</head><p>There exist two main categories of pooling methods: those which map the set of vertex representations to a vector space of fixed dimension and those which map the set of vertex representations to a sequence space. The output of these mappings can then be fed as input to a feed-forward or recurrent architecture respectively. We now review pooling methods belonging to each of these categories.</p><p>The simplest pooling methods for mapping to a vector space of fixed dimension involve computing summary statistics such as mean and sum of vertex representations <ref type="bibr" target="#b6">[7]</ref>. Despite the simple nature of these methods, a recent study by Luzhnica et al. <ref type="bibr" target="#b17">[18]</ref> demonstrated that in some cases they can outperform more complex methods. To improve discrimination power more sophisticated pooling methods have been proposed. The SortPooling method proposed by Zhang et al. <ref type="bibr" target="#b29">[30]</ref> first sorts the vertices with respect to structural roles in the graph. The vertex representations corresponding to the first k vertices in this order are then concatenated to give a fixed dimensional vector. The value k is a fixed hyperparameter in the model. Set2Set is a general approach for producing a fixed dimensional vector space representation of a set which is invariant to the order in which the elements are processed <ref type="bibr" target="#b23">[24]</ref>. Gilmer et al. <ref type="bibr" target="#b8">[9]</ref> proposed to use this method to perform pooling. Ying et al. <ref type="bibr" target="#b28">[29]</ref> proposed a pooling method known as DiffPool which performs a hierarchical clustering of vertex representations and returns an element in a fixed dimensional vector space. Kearnes et al. <ref type="bibr" target="#b12">[13]</ref> proposed a pooling method based on fuzzy histograms. This method has similarities to that proposed in this article but is formulated in terms of fuzzy theory as opposed to function spaces. The method proposed in this article is in turn distinct. Tarlow et al. <ref type="bibr" target="#b16">[17]</ref> proposed a pooling method which outputs an element in sequence space. Finally, all of the above pooling methods are supervised methods. Many unsupervised pooling methods have also been proposed but we do not review them here <ref type="bibr" target="#b1">[2]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Function Space Pooling</head><p>In this section we present the proposed pooling method. Let graph G = (V, E) denote a graph we wish to classify where V and E are the corresponding sets of vertices and edges respectively. Let l : V → Σ denote a vertex labelling function that assigns each vertex v ∈ V a label l(v) in the finite set Σ.</p><p>Let D be the set of vertex representations output from a sequence of convolutional layers applied to G. We assume that each element in this set is an element of R n where n is a fixed hyper-parameter. The proposed pooling method takes as input D and returns an element in a function space. That is, the method is a map from the space of sets to the space of functions. It contains two steps which we now describe in turn. The set of vertex representations D is an object in the space of sets which we denote Ω. Let Sigmoid : R n → I be the n-dimensional Sigmoid function defined in Equation</p><formula xml:id="formula_0">1 where I = {(x 1 , . . . , x n ) ∈ [0, 1] n } is the n-dimensional interval.</formula><p>In the first step of the proposed pooling method we apply the n-dimensional Sigmoid elementwise to D to give a map S : Ω → Ω. To illustrate this map consider <ref type="figure" target="#fig_0">Figure 2</ref>(a) which displays an example set D containing three elements in R n where n = 2. The result of applying the map S to this set is illustrated in <ref type="figure" target="#fig_0">Figure 2</ref>(b).</p><formula xml:id="formula_1">Sigmoid(x) = 1 1 + e −x<label>(1)</label></formula><p>Let g u : R n → R be a probability distribution. For the purposes of this work we used the n-dimensional Gaussian distribution defined in Equation 2 with mean u and variance σ 2 .</p><formula xml:id="formula_2">g u (x) = 1 2πσ 2 e −((x−u) T (x−u))/2σ 2<label>(2)</label></formula><p>In the second step of the proposed pooling method we apply a map F : Ω → L p (I) to S(D). Here L p (I) is the space of real valued functions on I equipped with the L p -norm defined in Equation 3 <ref type="bibr" target="#b4">[5]</ref>. Note that, function addition and subtraction is performed pointwise in this space.</p><formula xml:id="formula_3">f p = I |f (x)| p dx 1/p (3)</formula><p>The function resulting from the map F is defined in Definition 1. To illustrate this map consider again the example set S(D) illustrated in <ref type="figure" target="#fig_0">Figure 2</ref>  </p><p>The elements of L p (I), and in turn the function representation ρ : I → R, are infinite dimensional vector spaces. That is, there are an infinite number of elements in the domain I of ρ. We approximate this function as a finite dimensional vector space by discretizing the function domain using a regular grid of elements. For example, the image in <ref type="figure" target="#fig_0">Figure 2</ref> The parameter σ may be interpreted as follows. As the value of σ approaches 0 the function representation ρ : I → R becomes a sum of indicator functions on the set D of vertex representations. In this case distinct sets D map to distinct functions where the distance between these functions as defined by the norm in Equation 3 is greater than zero. On the other hand, as σ approaches ∞, differences between the functions are gradually smoothed out and in turn the distance between the functions gradually reduces. Therefore, one can view the parameter σ as controlling the discrimination power of the method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>To evaluate the proposed pooling method we considered the task of graph classification on a number of datasets. The layout of this section is as follows. Section 4.1 describes the neural network architecture used in all experiments. Section 4.3 describes the datasets considered. Section 4.2 describes the optimization method used to optimize the network parameters. Finally section 4.4 presents the classification accuracy achieved by the proposed pooling method relative to a number of baseline methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Network Architecture</head><p>Recall from section 3 that G = (V, E) denotes a graph we wish to classify and l : V → Σ denotes a vertex labelling function where Σ is a finite set. In order to perform classification of G the following feed-forward neural network architecture was used which consists of six layers.</p><p>The first two layers are convolutional layers similarly to the GraphSAGE convolutional layers <ref type="bibr" target="#b9">[10]</ref>. Only two convolutional layers were used because a number of studies have found that the use of two layers empirically gives best performance <ref type="bibr" target="#b15">[16]</ref>.</p><p>Let · denote matrix multiplication and CONCAT denote horizontal matrix concatenation. The kth convolutional layer is implemented using <ref type="bibr">Equation 5</ref> where A is the adjacency matrix corresponding to G, W k are the layer weights and b k are the layer biases. The weights W k is a matrix of dimension 2d k−1 × d k where d k the dimension of the kth layer. The biases b k is a vector of dimension d k . The term h 0 denotes a matrix of size |V | × |Σ| where each matrix row equals the one-hot-encoding of an individual vertex label. The term h k denotes a matrix of size |V | × d k where each matrix row equals the representation of an individual vertex output from the kth convolutional layer and d k is the dimension of this representation. Note that, since two convolutional layers are used, k takes values in the set {1, 2}. The dimension of the input layer d 0 is equal to the number of vertex types since one-hot encoding was used. The dimensions of the two convolutional layers d 1 and d 2 were both set to 20.</p><formula xml:id="formula_5">h k ←CONCAT(h k−1 , A · h k−1 ) h k ←ReLu (W k · h k + b k )<label>(5)</label></formula><p>The third architecture layer is a fully connected linear layer of dimension 10. The fourth layer is the pooling method used. The fifth layer is another fully connected linear layer of dimension 20. The final layer is a softmax function and returns a probability distribution over the classes. The output of the first linear layer equals the input to the pooling method. Therefore the multi-dimensional interval corresponding to the domain of the function ρ in Definition 1 is of dimension 10. We approximate this function as a finite dimensional vector space by discretizing the function domain using a regular grid with 3 elements in each dimension. This gives a finite dimensional vector space of dimension 3 10 = 59049.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Optimization</head><p>The model parameters to be optimized in the architecture of section 4.1 are the weights and biases of the convolutional layers, the weights and biases of the linear layers and the parameter σ of the pooling method. In all experiments the neural network parameters were initialized as follows. All weight matrices in the convolutional and linear layers were initialized using Kaiming initialization <ref type="bibr" target="#b10">[11]</ref>. All biases in the convolutional and linear layers were initialized to zero. Finally, the parameter σ in Equation 2 of the pooling layer was initialized to 0.125.</p><p>For loss function Cross Entropy plus an L 2 regularization term with weight of 0.2 was used. The Adam optimization algorithm was used to optimize all model parameters with a learning rate of 1 × 10 −3 <ref type="bibr" target="#b14">[15]</ref>. In all experiments optimization was performed for 350 data epochs and the model which achieved the minimum loss during this process was returned. In all cases the optimization procedure converged well before 350 data epochs. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Datasets</head><p>To evaluate the proposed pooling method we used three graph classification datasets. The datasets in question are commonly used to evaluate graph classification methods and were obtained from the TU Dortmund University graph dataset repository <ref type="bibr" target="#b13">[14]</ref>.</p><p>The first dataset was the MUTAG dataset which consists of 188 graphs corresponding to chemical compounds where there are 7 distinct types of vertices. The classification problem is binary and concerns predicting if a chemical compound has mutagenicity or not <ref type="bibr" target="#b5">[6]</ref>.</p><p>The second dataset was the PROTEINS dataset which consists of 1113 graphs corresponding to protein molecules where there are 3 distinct types of vertices. The classification task is binary and concerns predicting if a protein is an enzyme or not <ref type="bibr" target="#b2">[3]</ref>.</p><p>The third dataset was the ENZYMES dataset which consists of 600 graphs corresponding to enzymes where there are 3 distinct types of vertices. The classification task is multi-class and concerns predicting enzyme class where there are 6 distinct classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Classification Accuracy</head><p>The proposed pooling method was benchmarked against the following five baseline pooling methods: mean vertex representation, sum of vertex representations, DiffPool by Ying et al. <ref type="bibr" target="#b28">[29]</ref>, SortPooling by Zhang et al. <ref type="bibr" target="#b29">[30]</ref> and Set2Set by Vinyals et al. <ref type="bibr" target="#b23">[24]</ref>. As described in the background and related works section of this paper, these are some of the most commonly used pooling methods.</p><p>For all baseline models we used a neural network architecture similar to that described in section 4.1 with the exception that the pooling layer was replaced and the dimension of the linear layer before this layer was changed from 10 to 20. All experiments were implemented in Python3 using the PyTorch library <ref type="bibr" target="#b18">[19]</ref> and run on an Nvidia GeForce RTX 2080 GPU. For the baseline pooling methods we used the corresponding implementations available in the PyTorch Geometric Python library <ref type="bibr" target="#b7">[8]</ref>.</p><p>For each dataset considered we computed the mean accuracy of 10-fold cross validation for each pooling method. The results of this analysis are displayed in <ref type="table" target="#tab_0">Table 1</ref>. For each dataset, the proposed pooling method outperformed most baseline methods and achieved equal best performance on two of the three datasets. This demonstrates the utility of the proposed pooling method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>Pooling is a fundamental type of layer in graph neural networks which involves compute a representation of the set of vertex representations output from a sequence of convolutional layers. In this work we proposed a novel pooling method which computes a function space representation of the set of vertex representations. This method is distinct from existing pooling methods which compute either a vector or sequence space representation.</p><p>Experimental results on a number of graph classification benchmark datasets demonstrate that the proposed method generally outperforms most baseline pooling methods and in some cases achieves best performance. The benchmark datasets in question contain graphs corresponding to molecules and chemical compounds which are the most common types of dataset used to evaluate graph classification methods. Despite this fact, the proposed pooling method is general in nature and can be applied to any type of graph. Finally, the authors hope this work will serve as a platform for future work investigating the use of function space representations for pooling.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 .</head><label>2</label><figDesc>A set D of vertex representations output from a sequence of convolutional layers is displayed in (a) where each element is represented by a red dot. The result of applying the map S to the set D is the set s(D) displayed in (b). The result of applying the map F to S(D) with the parameter σ = 0.005 is the function ρ : I → R displayed in (c). The result of applying the map F to S(D) with the parameter σ = 0.0001 is the function ρ : I → R displayed in (d).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>(b).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 (Definition 1</head><label>21</label><figDesc>c) displays the function ρ : I → R resulting from applying the map F to this set with a σ parameter value of 0.005. For D ∈ Ω the corresponding function representation ρ : I → R is defined in Equation 4 ρ(z) = u∈S(D) g u (z)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>(c) corresponds to a discretizing of the function domain using a 250 × 250 grid. The proposed pooling method is parameterized by σ in the probability distribution of Equation 2 where this parameter takes a value in the range [0, ∞]. As the value of σ approaches 0 the probability distribution approaches an indicator function on the domain I. On the other hand, as the value of σ approaches ∞ the probability distribution approaches a uniform function on the domain I. For example, Figures 2(c) and 2(d) display the functions ρ : I → R resulting from applying the map F to the set S(D) in Figure 2(b) with σ parameter values of 0.005 and 0.0001 respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>For each of the MUTAG, PROTEINS and ENZYMES datasets, the mean classification accuracy of 10-fold cross validation for each pooling method are displayed.</figDesc><table><row><cell cols="2">Pooling Method MUTAG PROTEINS ENZYMES</cell></row><row><cell>Sum</cell><cell>0.66 ± 0.60 0.60 ± 0.18 0.26 ± 0.07</cell></row><row><cell>Mean</cell><cell>0.78 ± 0.18 0.58 ± 0.16 0.30 ± 0.05</cell></row><row><cell>DiffPool</cell><cell>0.85 ± 0.11 0.73 ± 0.04 0.32 ± 0.07</cell></row><row><cell>SortPooling</cell><cell>0.74 ± 0.11 0.72 ± 0.05 0.23 ± 0.04</cell></row><row><cell>Set2Set</cell><cell>0.73 ± 0.08 0.72 ± 0.04 0.30 ± 0.07</cell></row><row><cell cols="2">Function Space 0.83 ± 0.11 0.73 ± 0.19 0.32 ± 0.06</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Persistence images: A stable vector representation of persistent homology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Emerson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kirby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Neville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Peterson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Shipman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chepushtanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hanson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Motta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ziegelmeier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="218" to="252" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Unsupervised inductive whole-graph embedding by preserving graph proximity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Marinovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">First International Workshop on Deep Learning on Graphs: Methods and Applications</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Protein function prediction via graph kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Borgwardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">S</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Schönauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vishwanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">P</forename><surname>Kriegel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="47" to="56" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
	<note>suppl</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>De Vicente</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sepulveda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Soto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Vázquez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.00445</idno>
		<title level="m">A behavioral approach to visual navigation with graph localization networks</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Functions, spaces, and expansions: mathematical tools in physics and engineering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Christensen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Structure-activity relationship of mutagenic aromatic and heteroaromatic nitro compounds. correlation with molecular orbital energies and hydrophobicity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Debnath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">L</forename><surname>Lopez De Compadre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Debnath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Shusterman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hansch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of medicinal chemistry</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="786" to="797" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Convolutional networks on graphs for learning molecular fingerprints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Duvenaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Maclaurin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Iparraguirre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bombarell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hirzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Aspuru-Guzik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Adams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2224" to="2232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Fast graph representation learning with PyTorch Geometric</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Lenssen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR Workshop on Representation Learning on Graphs and Manifolds</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Neural message passing for quantum chemistry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gilmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Schoenholz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">F</forename><surname>Riley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Dahl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="1263" to="1272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Inductive representation learning on large graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1024" to="1034" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Delving deep into rectifiers: Surpassing humanlevel performance on imagenet classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1026" to="1034" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Molecular graph convolutions: moving beyond fingerprints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kearnes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mccloskey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Berndl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Pande</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Riley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of computer-aided molecular design</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="595" to="608" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Benchmark data sets for graph kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kersting</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">M</forename><surname>Kriege</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mutzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Neumann</surname></persName>
		</author>
		<ptr target="http://graphkernels.cs.tu-dortmund.de" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Conference on Learning Representations (ICLR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Gated graph sequence neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tarlow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brockschmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Learning Representations</title>
		<meeting>International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">On graph classification networks, datasets and baselines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Luzhnica</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Day</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liò</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICML Workshop on Learning and Reasoning with Graph-Structured Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Automatic differentiation in PyTorch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lerer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS Autodiff Workshop</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Graph networks as learnable physics engines for inference and control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sanchez-Gonzalez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Heess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Springenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Merel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Riedmiller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Battaglia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4467" to="4476" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tolstaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Gama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Paulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Pappas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ribeiro</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.10527</idno>
		<title level="m">Learning decentralized controllers for robot swarms with graph neural networks</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st International Conference on Neural Information Processing Systems</title>
		<meeting>the 31st International Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<publisher>Curran Associates Inc</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6000" to="6010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Veličković</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liò</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<title level="m">Graph Attention Networks. International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Order matters: Sequence to sequence for sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kudlur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.00596</idno>
		<title level="m">A comprehensive survey on graph neural networks</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.00596</idno>
		<title level="m">A comprehensive survey on graph neural networks</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">How powerful are graph neural networks?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jegelka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Representation learning on graphs with jumping knowledge networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Sonobe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">I</forename><surname>Kawarabayashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jegelka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5449" to="5458" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Hierarchical graph representation learning with differentiable pooling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4800" to="4810" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">An end-to-end deep learning architecture for graph classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Second AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.04202</idno>
		<title level="m">Deep learning on graphs: A survey</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
