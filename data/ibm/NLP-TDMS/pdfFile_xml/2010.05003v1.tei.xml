<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Second-Order Neural Dependency Parsing with Message Passing and End-to-End Training</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2020-10-10">10 Oct 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyu</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">School of Information Science and Technology</orgName>
								<orgName type="department" key="dep2">Shanghai Engineering Research Center of Intelligent Vision and Imaging Shanghai Institute of Microsystem and Information Technology</orgName>
								<orgName type="institution" key="instit1">ShanghaiTech University</orgName>
								<orgName type="institution" key="instit2">Chinese Academy of Sciences University of Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kewei</forename><surname>Tu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">School of Information Science and Technology</orgName>
								<orgName type="department" key="dep2">Shanghai Engineering Research Center of Intelligent Vision and Imaging Shanghai Institute of Microsystem and Information Technology</orgName>
								<orgName type="institution" key="instit1">ShanghaiTech University</orgName>
								<orgName type="institution" key="instit2">Chinese Academy of Sciences University of Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Second-Order Neural Dependency Parsing with Message Passing and End-to-End Training</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2020-10-10">10 Oct 2020</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T09:34+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we propose second-order graphbased neural dependency parsing using message passing and end-to-end neural networks. We empirically show that our approaches match the accuracy of very recent state-ofthe-art second-order graph-based neural dependency parsers and have significantly faster speed in both training and testing. We also empirically show the advantage of second-order parsing over first-order parsing and observe that the usefulness of the head-selection structured constraint vanishes when using BERT embedding.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Graph-based dependency parsing is a popular approach to dependency parsing that scores parse components of a sentence and then finds the highest scoring tree through inference. First-order graph-based dependency parsing takes individual dependency edges as the components of a parse tree, while higher-order dependency parsing considers more complex components consisting of multiple edges. There exist both exact inference algorithms <ref type="bibr">(Carreras, 2007;</ref><ref type="bibr" target="#b15">Koo and Collins, 2010;</ref><ref type="bibr" target="#b21">Ma and Zhao, 2012)</ref> and approximate inference algorithms <ref type="bibr" target="#b25">(McDonald and Pereira, 2006;</ref><ref type="bibr" target="#b32">Smith and Eisner, 2008;</ref><ref type="bibr" target="#b11">Gormley et al., 2015)</ref> to find the best parse tree. Recent work focused on neural network based graph dependency parsers <ref type="bibr" target="#b14">(Kiperwasser and Goldberg, 2016;</ref><ref type="bibr" target="#b33">Wang and Chang, 2016;</ref><ref type="bibr" target="#b0">Cheng et al., 2016;</ref><ref type="bibr" target="#b16">Kuncoro et al., 2016;</ref><ref type="bibr" target="#b19">Ma and Hovy, 2017;</ref>.  proposed a first-order graph-based neural dependency parsing approach with a simple head-selection training objective. It uses a biaffine function to score dependency edges and has high * Kewei Tu is the corresponding author. efficiency and good performance. Subsequent work introduced second-order inference into their parser. <ref type="bibr" target="#b12">Ji et al. (2019)</ref> proposed a graph neural network that captures second-order information in token representations, which are then used for first-order parsing. Very recently, <ref type="bibr" target="#b36">Zhang et al. (2020)</ref> proposed an efficient second-order tree CRF model for dependency parsing and achieved state-of-the-art performance.</p><p>In this paper, we first show how a previously proposed second-order semantic dependency parser <ref type="bibr" target="#b34">(Wang et al., 2019)</ref> can be applied to syntactic dependency parsing with simple modifications. The parser is an end-to-end neural network derived from message passing inference on a conditional random field that encodes the secondorder parsing problem. We then propose an alternative conditional random field that incorporates the head-selection constraint of syntactic dependency parsing, and derive a novel second-order dependency parser. We empirically compare the two second-order approaches and the first-order baselines on English Penn Tree Bank 3.0 (PTB), Chinese Penn Tree Bank 5.1 (CTB) and datasets of 12 languages in Universal Dependencies (UD). We show that our approaches achieve state-of-the-art performance on both PTB and CTB and our approaches are significantly faster than recently proposed second-order parsers.</p><p>We also make two interesting observations from our empirical study. First, it is a common belief that contextual word embeddings such as ELMo <ref type="bibr" target="#b29">(Peters et al., 2018)</ref> and BERT <ref type="bibr" target="#b3">(Devlin et al., 2019)</ref> already conveys sufficient high-order information that renders high-order parsing less useful, but we find that second-order decoding is still helpful even with strong contextual embeddings like BERT. Second, while <ref type="bibr" target="#b37">Zhang et al. (2019)</ref> previously found that incoperating the head-selection constraint is helpful in first-order parsing, we find that with a better loss function design and hyper-parameter tuning both first-and second-order parsers without the headselection constraint can match the accuracy of parsers with the head-selection constraint and can even outperform the latter when using BERT embedding.</p><p>Our approaches are closely related to the work of <ref type="bibr" target="#b11">Gormley et al. (2015)</ref>, which proposed a nonneural second-order parser based on Loopy Belief Propagation (LBP). Our work differs from theirs in that: 1) we use Mean Field Variational Inference (MFVI) instead of LBP, which Wang et al. <ref type="bibr" target="#b9">(2019)</ref> found is faster and equally accurate in practice; 2) we add the head-selection constraint and do not include the global tree constraint that is shown to produce only slight improvement <ref type="bibr" target="#b37">(Zhang et al., 2019)</ref> but would complicate our neural network design and implementation; 3) we employ modern neural encoders and achieve much better parsing accuracy. Our approaches are also closely related to the very recent work of <ref type="bibr" target="#b10">Fonseca and Martins (2020)</ref>. The main difference is that we use MFVI while they use the dual decomposition algorithm AD 3 <ref type="bibr" target="#b24">(Martins et al., 2011</ref><ref type="bibr" target="#b23">(Martins et al., , 2013</ref> for approximate inference.</p><p>2 Approach <ref type="bibr" target="#b37">Zhang et al. (2019)</ref> categorized different kinds of graph-based dependency parsers based on their structured output constraints according to the normalization for output scores. A Local approach views dependency parsing as a head-selection problem, in which each word selects exactly one dependency head. A Single approach places no structured constraint, viewing the existence of each possible dependency edge as an independent binary classification problem.</p><p>The second-order semantic dependency parser of <ref type="bibr" target="#b34">Wang et al. (2019)</ref> is an end-to-end neural network derived from message passing inference on a conditional random field that encodes the secondorder parsing problem. It is clearly a Single approach because of the lack of structured constraints in semantic dependency parsing. We can apply this approach to syntactic dependency parsing with two minor modifications. First, coparents, one of the three types of second-order parts, become invalid and hence are removed. Second, for the approach to output valid parse trees during testing, we run maximum spanning tree (MST) <ref type="bibr" target="#b26">(McDonald et al., 2005)</ref> based on the posterior edge probabilities predicted by the approach.</p><p>Inspired by <ref type="bibr" target="#b34">Wang et al. (2019)</ref>, below we propose a Local second-order parsing approach. While the Single approach uses Boolean random variables to represent existence of possible dependency edges, our Local approach defines a discrete random variable for each word specifying its dependency head, thus enforcing the headselection constraint and leading to different formulation of the message passing inference steps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Scoring</head><p>Following , we predict edge existence and edge labels separately. Suppose the input sentence is w = [w 0 , w 1 , w 2 , . . . , w n ] where w 0 is a dummy root. We feed word representations outputted by the BiLSTM encoder into a biaffine function to assign score s (edge) ij to edge w i → w j . We use a Trilinear function to assign score s <ref type="bibr">(sib)</ref> ij,ik to the siblings part consisting of edges w i → w j and w i → w k , and another Trilinear function to assign score s <ref type="bibr">(gp)</ref> ij,jk to the grandparent part consisting of edges w i → w j and w j → w k . For edge labels, we use a biaffine function to predict label scores of each potential edge and use a softmax function to compute the label distribution P (y (label) ij |w), where y (label) ij represents the possible label for edge w i → w j .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Message Passing</head><p>The head-selection structured constraint requires that each word except the root has exactly one head. We define variable X j ∈ {0, 1, 2, . . . , n} to indicate the head of word w j . We then define a conditional random field (CRF) over [X 1 , . . . , X n ]. For each variable X j , the unary potential is defined by:</p><formula xml:id="formula_0">φ u (X j = i) = exp(s (edge) ij )</formula><p>Given two variables X j and X l , the binary potential is defined by:</p><formula xml:id="formula_1">φ p (X j = i, X l = k) =      exp(s (sib) ij,kl ) k = i exp(s (gp) ij,kl ) k = j 1 Otherwise</formula><p>We use MFVI for approximate inference on this CRF. The algorithm updates the factorized poste-rior distribution Q j (X j ) of each word iteratively.</p><formula xml:id="formula_2">M (t−1) j (i) = k =i,j Q (t−1) k (i)s (sib) ij,ik +Q (t−1) k (j)s (gp) ij,jk + Q (t−1) i (k)s (gp) ki,ij Q (t) j (i) = exp{s (edge) ij + M (t−1) j (i)} n k=0 exp{s (edge) kj + M (t−1) j (k)} At t = 0, Q (t) j (X j )</formula><p>is initialized by normalizing the unary potential. The iterative update steps can be unfolded as recurrent neural network layers parameterized by part scores, thus forming an endto-end neural network.</p><p>Compared with the update formula in the Single approach, here the posterior distributions are defined over head-selections and are normalized over all possible heads. The computational complexity remains the same.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Learning</head><p>We define the cross entropy losses by:</p><formula xml:id="formula_3">L (edge) = − i log[Q i (y * (edge) i |w)] L (label) = − i,j ½(y * (edge) j = i) log(P (y * (label) ij |w)) L =λL (label) + (1 − λ)L (edge)</formula><p>where y * (edge) i is the head of word w i and y * (label) ij is the label of edge w i → w j in the golden parse tree, λ is a hyper-parameter and ½(x) is an indicator function that returns 1 when x is true and 0 otherwise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Setups</head><p>Following previous work <ref type="bibr" target="#b20">Ma et al., 2018)</ref>, we use PTB 3.0 <ref type="bibr" target="#b22">(Marcus et al., 1993)</ref>, CTB 5.1 <ref type="bibr" target="#b35">(Xue et al., 2002)</ref> and <ref type="formula">12</ref>   <ref type="formula">(2017)</ref>, , and our two secondorder approaches respectively. For all the approaches, we use the MST algorithm to guarantee tree-structured output in testing. We use the concatenation of word embeddings, characterlevel embeddings and part-of-speech (POS) tag embeddings to represent words and additionally concatenate BERT embeddings for experiments with BERT. For a fair comparison with previous work, we use GloVe <ref type="bibr" target="#b28">(Pennington et al., 2014)</ref> and BERT-Large-Uncased model for PTB, and structured-skipgram <ref type="bibr">(Ling et al., 2015)</ref> and BERT-Base-Chinese model for CTB. For UD, we use fastText embeddings <ref type="bibr">(Bojanowski et al., 2017)</ref> and BERT-Base-Multilingual-Cased model for different languages. We set the default iteration number for our approaches to 3 because we find no improvement on more or less iterations.</p><p>For GNN 1 , we rerun the code based on the official release of Ji et al. <ref type="bibr" target="#b9">(2019)</ref>. For Single1O, Local1O 2 , Single2O 3 , we implement these ap-  <ref type="table">Table 2</ref>: Comparison of our approaches and the previous state-of-the-art approaches on PTB and CTB. We report our results averaged over 5 runs. † : These approaches perform model selection based on the score on the development set. ‡ : These approaches do not use POS tags as input. ⋄ :  uses semisupervised multi-task learning with ELMo embeddings. ♠ : These approaches use structured-skipgram embeddings instead of GloVe embeddings for PTB. ♣ : For reference, <ref type="bibr" target="#b38">Zhou and Zhao (2019)</ref> utilized both dependency and constituency information in their approach. Therefore, the results are not comparable to our results.</p><p>proaches based on the official release code of <ref type="bibr" target="#b34">Wang et al. (2019)</ref> and we implement Local2O based on this code. In speed comparison, we implement the second-order approaches based on an PyTorch implementation biaffine parser 4 implemented by <ref type="bibr" target="#b36">Zhang et al. (2020)</ref> for a fair speed comparison with their approach 5 . Since we find that the accuracy of our approaches based on Py-Torch implementation on PTB does not change, we only report scores based on Wang et al. <ref type="bibr" target="#b9">(2019)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Hyper-parameters</head><p>The hyper-parameters we used in our experiments is shown in <ref type="table">Table 1</ref>. We tune the the hidden size for calculating s (edge) ij (Unary Arc in the table) separately for PTB and CTB. Following <ref type="bibr" target="#b30">Qi et al. (2018)</ref>, we switch to AMSGrad (Reddi et al., 2018) after 5,000 iterations without improvement. We train models for 75,000 iterations with batch sizes of 6000 tokens and stopped the training early after 10,000 iterations without improvements on development sets. Different from previous approaches such as  and <ref type="bibr" target="#b12">Ji et al. (2019)</ref>, we use Adam <ref type="bibr" target="#b13">(Kingma and Ba, 2015)</ref> with a learning rate of 0.01 and anneal the learning rate by 0.85 for every 500 iterations without improvement on the development set for optimization. For GNN, we train the models with the same setting as in <ref type="bibr" target="#b12">Ji et al. (2019)</ref>. We do not use character embeddings and our optimization settings for GNN because we find they do not improve the accuracy.</p><p>For the edge loss of Single approaches, <ref type="bibr" target="#b37">Zhang et al. (2019)</ref> proposed to sample a subset of the negative edges to balance positive and negative examples, but we find that using a relatively small interpolation λ (shown in <ref type="table">Table 1</ref>) on label loss can improve the accuracy and the sampling does not help further improve the accuracy. <ref type="table">Table 2</ref> shows the Unlabeled Attachment Score (UAS) and Labeled Attachment Score (LAS) of all the approaches as well as the reported scores of previous state-of-the-art approaches on PTB and CTB. It can be seen that without BERT, our Local2O achieves state-of-the-art performance on CTB and has almost the same accuracy as the very recent work of <ref type="bibr" target="#b36">Zhang et al. (2020)</ref> on PTB. With BERT embeddings, Local2O performs the best on PTB while Single2O has the best accuracy on CTB. <ref type="table" target="#tab_3">Table 3</ref> shows the results of the five approaches on UD in addition to PTB and CTB. We make the following observations. First, our second-order approaches outperform GNN and the first-order approaches both with and without BERT embeddings, showing that second-order decoders are still helpful in neural parsing even with strong contextual embeddings. Second, without BERT, Local slightly outperforms Single, although the difference between the two is quite small 6 ; when BERT is used, however, Single clearly outperforms Local, which is quite interesting and warrants further investigation in the future. Third, the relative strength of Local and Single approaches varies over treebanks, suggesting varying importance of   the head-selection constraint.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Speed Comparison</head><p>We evaluate the speed of different approaches on a single GeForce GTX 1080 Ti GPU following the setting of <ref type="bibr" target="#b36">Zhang et al. (2020)</ref>. As shown in Table 4, our Local approach and Single approach have almost the same speed. Our second-order approaches only slow down the training and testing speed in comparison with the first-order approaches by 23% and 12% respectively. They are also significantly faster than previous state-of-theart approaches. Our Local approach is 1.2 and 2.3 times faster than GNN in training and testing respectively and is 2.4 and 2.9 times faster than the second-order tree CRF approach of <ref type="bibr" target="#b36">Zhang et al. (2020)</ref>. In terms of time complexity, our second-order decoders have a time complexity of O(n 3 ) 7 ; while the time complexity of GNN is O(n 2 d), the hidden size d (500 by default) is typically much larger than sentence length n; and the decoder of <ref type="bibr" target="#b36">Zhang et al. (2020)</ref> has a time complexity of 7 The MST algorithm has a time complexity of O(n 2 ) and we follow  only using the MST algorithm when the argmax predictions of structured output are not trees. O(n 3 ) as well, but it requires sequential computation over the input sentence while our decoders can be parallelized over words of the input sentence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>We propose second-order graph-based dependency parsing based on message passing and end-to-end neural networks. We modify a previous approach that predicts dependency edges independently and also design a new approach that incorporates the head-selection structured constraint. Our experiments show that our secondorder approaches have better overall performance than the first-order baselines; they achieve competitive accuracy with very recent start-of-the-art second-order graph-based parsers and are significantly faster. Our empirical comparisons also show that second-order decoders still outperform first-order decoders even with BERT embeddings, and that the usefulness of the head-selection constraint is limited, especially when using BERT embeddings. Our code is publicly avilable at https://github.com/wangxinyu0922/Second_Order_Parsing.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>languages in Universal Dependencies (Nivre et al., 2018) (UD) 2.2 to evaluate our parser. Punctuation is ignored in all the evaluations. We use the same treebanks and preprocessing as<ref type="bibr" target="#b20">Ma et al. (2018)</ref> for PTB, CTB, and UD. For all the datasets, we remove sentences longer than 90 words in training sets for faster computation.</figDesc><table><row><cell>Hidden Layer</cell><cell>Hidden Sizes</cell></row><row><cell>Word/GloVe/Char</cell><cell>100</cell></row><row><cell>POS</cell><cell>50</cell></row><row><cell>GloVe Linear</cell><cell>125</cell></row><row><cell>BERT Linear</cell><cell>125</cell></row><row><cell>BiLSTM</cell><cell>3*600</cell></row><row><cell>Char LSTM</cell><cell>1*400</cell></row><row><cell>Unary Arc (UD)</cell><cell>500</cell></row><row><cell>Local1O/Local2O Unary Arc (Others)</cell><cell>450</cell></row><row><cell>Single1O/Single2O Unary Arc (Others)</cell><cell>550</cell></row><row><cell>Label</cell><cell>150</cell></row><row><cell>Binary Arc</cell><cell>150</cell></row><row><cell>Dropouts</cell><cell>Dropout Prob.</cell></row><row><cell>Word/GloVe/POS</cell><cell>20%</cell></row><row><cell>Char LSTM (FF/recur)</cell><cell>33%</cell></row><row><cell>Char Linear</cell><cell>33%</cell></row><row><cell>BiLSTM (FF/recur)</cell><cell>45%/25%</cell></row><row><cell>Unary Arc/Label</cell><cell>25%/33%</cell></row><row><cell>Binary Arc</cell><cell>25%</cell></row><row><cell>Optimizer &amp; Loss</cell><cell>Value</cell></row><row><cell>Local1O/Local2O Interpolation (λ)</cell><cell>0.40</cell></row><row><cell>Single1O/Single2O Interpolation (λ)</cell><cell>0.07</cell></row><row><cell>Adam β1</cell><cell>0</cell></row><row><cell>Adam β2</cell><cell>0.95</cell></row><row><cell>Decay Rate</cell><cell>0.85</cell></row><row><cell>Decay Step (without dev improvement)</cell><cell>500</cell></row><row><cell>Weight Initialization</cell><cell>Mean/Stddev</cell></row><row><cell>Unary weight</cell><cell>0.0/1.0</cell></row><row><cell>Binary weight</cell><cell>0.0/0.25</cell></row><row><cell cols="2">Table 1: Hyper-parameter for Local1O, Single2O and</cell></row><row><cell>Local2O in our experiment.</cell><cell></cell></row></table><note>We use GNN, Local1O, Single1O, Lo- cal2O and Single2O to represent the approachesof Ji et al. (2019), Dozat and Manning</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>GNN  94.15 89.50  † 90.33 92.39 90.95 79.73 88.43 91.56 87.23 92.44 88.57 89.38 85.26 91.20  89.37 Single1O 94.04 89.28 90.05 92.72 † 92.07 81.73 89.55 92.10 88.27 92.64 89.57 91.81 85.39 92.60 90.13 Local1O 94.23 89.28 90.30 92.56 92.15 81.42 89.43 91.99 88.26 92.49 89.76 91.91 85.27 92.72 90.13 Single2O 94.19 89.55 † 90.24 92.82 † 92.13 81.99 † 89.64 † 92.17 † 88.69 92.83 † 89.97 † 91.90 85.53 † 92.58 90.30 † Local2O 94.34 † ‡ 89.57 † 90.53 † 92.83 † 92.12 81.73 89.72 † 92.07 88.53 92.78 90.19 † 91.88 85.88 † ‡ 92.67 90.35 † +BERT Single1O 95.20 91.64 † 90.87 93.55 † 92.01 81.95 † 90.44 † 92.56 † 89.35 93.44 † 90.89 91.78 86.13 † 92.51 90.88 † Local1O 95.32 91.30 91.03 93.17 91.93 81.66 90.09 92.32 89.26 93.05 90.93 91.62 85.67 92.51 90.70 Single2O 95.31 91.69 † ‡ 91.30 † 93.60 † ‡ 92.09 † 82.00 † ‡ 90.75 † ‡ 92.62 † ‡ 89.32 93.66 † 91.21 91.74 86.40 † 92.61 91.02 † ‡ Local2O 95.34 91.38 91.13 93.34 † 92.07 † 81.67 90.43 † 92.45 † 89.26 93.50 † 90.99 91.66 86.09 † 92.66 90.86 †</figDesc><table><row><cell>PTB CTB</cell><cell>bg</cell><cell>ca</cell><cell>cs</cell><cell>de</cell><cell>en</cell><cell>es</cell><cell>fr</cell><cell>it</cell><cell>nl</cell><cell>no</cell><cell>ro</cell><cell>ru</cell><cell>Avg.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>LAS and standard deviations on test sets. We report results averaged over 5 runs. We use ISO 639-1 codes to represent languages from UD. † means that the model is statistically significantly better than the Local1O model by Wilcoxon rank-sum test with a significance level of p &lt; 0.05. We use ‡ to represent winner of the significant test between the Single2O and Local2O models.</figDesc><table><row><cell>System</cell><cell cols="2">Train Test Time Complexity</cell></row><row><cell>GNN</cell><cell>392 464</cell><cell>O(n 2 d)</cell></row><row><cell cols="2">Zhang et al. (2020) 200 400</cell><cell>O(n 3 )</cell></row><row><cell>Single1O</cell><cell>616 1123</cell><cell>O(n 2 )</cell></row><row><cell>Local1O</cell><cell>625 1150</cell><cell>O(n 2 )</cell></row><row><cell>Single2O</cell><cell>481 966</cell><cell>O(n 3 )</cell></row><row><cell>Local2O</cell><cell>486 1006</cell><cell>O(n 3 )</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Comparison of training and testing speed (sentences per second) and the time complexity of the decoders of different approaches on PTB.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/AntNLP/gnn-dep-parsing 2 https://github.com/tdozat/Parser-v3 3 https://github.com/wangxinyu0922/Second_Order_SDP</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">https://github.com/yzhangcs/parser 5 At the time we finished the paper, the official code for the second-order tree CRF parser have not release yet. We believe it is a fair comparison since we use the same settings and GPU as<ref type="bibr" target="#b36">Zhang et al. (2020)</ref>.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">Note that<ref type="bibr" target="#b37">Zhang et al. (2019)</ref> reports higher difference in accuracy between first-order Local and Single approaches. The discrepancy is most likely caused by our better designed loss function and tuned hyper-parameters.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work was supported by the National Natural Science Foundation of China (61976139). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>References</head></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Bi-directional attention with agreement for dependency parsing</title>
		<idno type="DOI">10.18653/v1/D16-1238</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Austin, Texas</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="2204" to="2214" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Semi-supervised sequence modeling with cross-view training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1217</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1914" to="1925" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1423</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Deep biaffine attention for neural dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Dozat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Simpler but more accurate semantic dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Dozat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P18-2077</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="484" to="490" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Dozat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Stanford&apos;s graph-based neural dependency parser at the CoNLL 2017 shared task</title>
		<idno type="DOI">10.18653/v1/K17-3002</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</title>
		<meeting>the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="20" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Fernández</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-</forename><surname>González</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Gómez-Rodríguez</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Left-to-right dependency parsing with pointer networks</title>
		<idno type="DOI">10.18653/v1/N19-1076</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="710" to="716" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Revisiting higher-order dependency parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erick</forename><surname>Fonseca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">T</forename><surname>André</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Martins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Approximation-aware dependency parsing by belief propagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">R</forename><surname>Gormley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Dredze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Eisner</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00153</idno>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="489" to="501" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Graph-based dependency parsing with graph neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanbin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Man</forename><surname>Lan</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1237</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2475" to="2485" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Simple and accurate dependency parsing using bidirectional LSTM fe Transactions of the</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eliyahu</forename><surname>Kiperwasser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00101</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="313" to="327" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Efficient third-order dependency parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terry</forename><surname>Koo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1423</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 48th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Uppsala, Sweden</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Distilling an ensemble of greedy dependency parsers into one MST pa</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adhiguna</forename><surname>Kuncoro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingpeng</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D16-1180</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Austin, Texas</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1744" to="1753" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">W</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabel</forename><surname>Trancoso</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Two/too simple adaptations of Word2Vec for syntax problems</title>
		<idno type="DOI">10.3115/v1/N15-1142</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Denver, Colorado</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="1299" to="1304" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Neural probabilistic model for non-projective MST parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuezhe</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth International Joint Conference on Natural Language Processing</title>
		<meeting>the Eighth International Joint Conference on Natural Language Processing<address><addrLine>Taipei, Taiwan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="59" to="69" />
		</imprint>
	</monogr>
	<note>Asian Federation of Natural Language Processing</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Stack-pointer networks for dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuezhe</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zecong</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingzhou</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nanyun</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P18-1130</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1403" to="1414" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Fourth-order dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuezhe</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The COLING 2012 Organizing Committee</title>
		<meeting><address><addrLine>Mumbai, India</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="785" to="796" />
		</imprint>
	</monogr>
	<note>Proceedings of COLING 2012: Posters</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Building a large annotated corpus of English: The Penn Treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitchell</forename><forename type="middle">P</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beatrice</forename><surname>Santorini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mary</forename><forename type="middle">Ann</forename><surname>Marcinkiewicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="313" to="330" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Turning on the turbo: Fast third-order non-projective turbo parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">André</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P16-1218</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="617" to="622" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Dual decomposition with many overlapping components</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">André</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mário</forename><surname>Figueiredo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pedro</forename><surname>Aguiar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2011 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Edinburgh, Scotland, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="238" to="249" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Online learning of approximate dependency parsing algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">11th Conference of the European Chapter</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kiril</forename><surname>Ribarov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Non-projective dependency parsing using spanning tree algorithms</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing<address><addrLine>Vancouver, British Columbia, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="523" to="530" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)</title>
		<meeting>the 2014 conference on empirical methods in natural language processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Deep contextualized word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N18-1202</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>New Orleans, Louisiana</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2227" to="2237" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Universal dependency parsing from scratch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Dozat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/K18-2016</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</title>
		<meeting>the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="160" to="170" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">On the convergence of adam and beyond</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sashank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satyen</forename><surname>Reddi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjiv</forename><surname>Kale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Dependency parsing by belief propagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Eisner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2008 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Honolulu, Hawaii</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="145" to="156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Graph-based dependency parsing with bidirectional LSTM</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baobao</forename><surname>Chang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P16-1218</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2306" to="2315" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Second-order semantic dependency parsing with end-to-end neural ne</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingxian</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kewei</forename><surname>Tu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1454</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4609" to="4618" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Building a large-scale annotated Chinese corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nianwen</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fu-Dong</forename><surname>Chiou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING 2002: The 19th International Conference on Computational Linguistics</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Efficient second-order treecrf for neural dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenghua</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.00975</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">An empirical investigation of structured output modeling for graph-ba</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhisong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuezhe</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1562</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5592" to="5598" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Head-driven phrase structure grammar parsing on Penn treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junru</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1230</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2396" to="2408" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
