<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Prototype Rectification for Few-Shot Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinlu</forename><surname>Liu</surname></persName>
							<email>liujinlu@ainnovation.com</email>
							<affiliation key="aff0">
								<orgName type="institution">AInnovation Technology Co., Ltd</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Song</surname></persName>
							<email>songliang@ainnovation.com</email>
							<affiliation key="aff0">
								<orgName type="institution">AInnovation Technology Co., Ltd</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongqiang</forename><surname>Qin</surname></persName>
							<email>qinyongqiang@ainnovation.com</email>
							<affiliation key="aff0">
								<orgName type="institution">AInnovation Technology Co., Ltd</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Prototype Rectification for Few-Shot Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T19:23+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Few-Shot Learning · Prototype Rectification · Intra-Class Bias · Cross-Class Bias</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Few-shot learning requires to recognize novel classes with scarce labeled data. Prototypical network is useful in existing researches, however, training on narrow-size distribution of scarce data usually tends to get biased prototypes. In this paper, we figure out two key influencing factors of the process: the intra-class bias and the cross-class bias. We then propose a simple yet effective approach for prototype rectification in transductive setting. The approach utilizes label propagation to diminish the intra-class bias and feature shifting to diminish the crossclass bias. We also conduct theoretical analysis to derive its rationality as well as the lower bound of the performance. Effectiveness is shown on three few-shot benchmarks. Notably, our approach achieves state-of-theart performance on both miniImageNet (70.31% on 1-shot and 81.89% on 5-shot) and tieredImageNet (78.74% on 1-shot and 86.92% on 5-shot).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Many deep learning based methods have achieved significant performance on object recognition tasks with abundant labeled data provided <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b8">9]</ref>. However, these methods generally perform unsatisfactorily if the labeled data is scarce. To reduce the dependency of data annotation, more researchers make efforts to develop powerful methods to learn new concepts from very few samples, which is so-called Few-Shot Learning (FSL) <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b34">35]</ref>. In FSL, we aim to learn prior knowledge on base classes with large amounts of labeled data and utilize the knowledge to recognize few-shot classes with scarce labeled data. It is usually formed as N -way K-shot few-shot tasks where each task consists of N few-shot classes with K labeled samples per class (the support set) and some unlabeled samples (the query set) for test.</p><p>Classifying test samples by matching them to the nearest class prototype <ref type="bibr" target="#b31">[32]</ref> is a common practice in FSL. It is supposed that an expected prototype has the minimal distance to all samples within the same class. However, the prototypes they get are always biased due to the data scarcity in few-shot scenarios. The internal factors that restrict the representation ability of the prototypes should be identified for performance improvement. Hence, we figure out the bias in prototype computation and accordingly propose the diminishing methods for rectification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Basic Prototypes</head><p>Rectified Prototypes</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Features of Query Samples</head><p>Features of Pseudo-Labeled Query Samples Framework of our proposed method for prototype rectification. The cross-class bias diminishing module reduces the bias between the support set and the query set while the intra-class bias diminishing module reduces the bias between the actually computed prototypes and the expected prototypes.</p><p>In this paper, we target to find the expected prototypes which have the maximum cosine similarity to all data points within the same class. The cosine similarity based prototypical network (CSPN) is firstly proposed to extract discriminative features and compute basic prototypes from the limited samples. In CSPN, we firstly train a feature extractor with a cosine classifier on the base classes. The cosine classifier has a strong capability of driving the feature extractor to learn discriminative features. It learns an embedding space where features belonging to the same class cluster more tightly. At the inference stage, we use class means as the basic prototypes of few-shot classes. Classification can be directly performed by nearest prototype matching based on cosine similarity.</p><p>Since the basic prototypes are biased due to data scarcity, we import a bias diminishing module into the network for prototype rectification, which is called BD-CSPN in this paper. We figure out two key factors: the intra-class bias and the cross-class bias, which influence the representativeness of class prototypes. The approach to reduce the bias is accordingly proposed as shown in <ref type="figure">Fig. 1</ref>. The intra-class bias refers to the distance between the expectedly unbiased prototype and the prototype actually computed from the available data. To reduce it, we adopt the pseudo-labeling strategy to add unlabeled samples with high prediction confidence into the support set in transductive setting. Considering that some of the pseudo-labeled samples are possibly misclassified, we use the weighted sum as the modified prototypes instead of simple averaging. It avoids bringing larger bias into prototype computation. The cross-class bias refers to the distance between the representative vectors of training and test datasets, which are commonly represented as the mean vectors. We reduce it by importing a shifting term ξ to the query samples, driving them to distribute closely to the support samples.</p><p>To verify the rationality of our bias diminishing method, we give the theoretical analysis in Section 4. The derivation of the expected performance of cosine-similarity based prototypical network is firstly given. It shows that the lower bound of the expected accuracy is positively correlated with the number of samples. We demonstrate the effectiveness and simplicity of our pseudo-labeling strategy in raising the lower bound, which leads to significant improvement as shown in experiments. Then we give the derivation of shifting term ξ in crossclass bias diminishing. In conclusion, we argue that our method is simpler yet more efficient than many complicated few-shot learning methods. Also, it is mathematically rigorous with the theoretical analysis.</p><p>Our contributions are summarized as:</p><p>1) We figure out the internal factors: the intra-class bias and the cross-class bias which restrict the representational ability of class prototypes in fewshot learning. 2) We propose the bias diminishing module for prototype rectification, which is mainly conducted by pseudo-labeling and feature shifting. It is conceptually simple but practically effective to improve the performance. 3) To verify the rationality of the intra-class bias diminishing method, we theoretically analyze the correlation between the number of sample and the lower bound of the expected performance. Furthermore, we give the derivation of the shifting term in cross-class bias diminishing. 4) We conduct extensive experiments on three popular few-shot benchmarks and achieve the state-of-the-art performance. The experiment results demonstrate that our proposed bias diminishing module can bring in significant improvement by a large margin.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Works</head><p>Few-Shot Learning Few-shot learning methods can be divided into two groups: gradient based methods and metric learning based methods. Gradient based methods focus on fast adapting model parameters to new tasks through gradient descent <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b13">14]</ref>. Typical methods such as MAML <ref type="bibr" target="#b5">[6]</ref> and Reptile <ref type="bibr" target="#b20">[21]</ref> aim to learn a good parameter initialization that enables the model easy to fine-tune. In this section, we focus on metric learning based methods which are more closely to our approach. Metric learning based methods learn an informative metric to indicate the similarity relationship in the embedding space <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b0">1]</ref>. Relation network <ref type="bibr" target="#b32">[33]</ref> learns a distance metric to construct the relation of samples within an episode. The unlabeled samples thus can be classified according to the computed relation scores. Prototypical Networks (PN) <ref type="bibr" target="#b31">[32]</ref> views the mean feature as the class prototype and assigns the points to the nearest class prototype based on Euclidean distance in the embedding space. It is indicated in <ref type="bibr" target="#b13">[14]</ref> that PN shows limited performance in the high-dimensional embedding space. In some recent works, models trained with a cosine-similarity based classifier are more effective in learning discriminative features <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b2">3]</ref>. In this paper, we use cosine classifier to learn a discriminative embedding space and compute the cosine distance to the class prototype (mean) for classification. The prototype computed in the discriminative feature space is more robust to represent a class. According to the test setting, FSL can be divided into two branches: inductive few-shot learning and transductive few-shot learning. The former predicts the test samples one by one while the latter predicts the test samples as a whole. Early proven in <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b38">39]</ref>, transductive inference outperforms inductive inference especially when training data is scarce. Some literatures recently attack fewshot learning problem in transductive setting. In <ref type="bibr" target="#b20">[21]</ref>, the shared information between test samples via normalization is used to improve classification accuracy. Different from <ref type="bibr" target="#b20">[21]</ref>, TPN <ref type="bibr" target="#b16">[17]</ref> adopts transductive inference to alleviate low-data problem in few-shot learning. It constructs a graph using the union of the support set and the query set, where labels are propagated from support to query. Under transductive inference, the edge-labeling graph neural network (EGNN) proposed in <ref type="bibr" target="#b10">[11]</ref> learns more accurate edge-labels through exploring the intra-cluster similarity and the inter-cluster dissimilarity. Our method takes the advantage of transductive inference that samples with higher prediction confidence can be obtained when the test samples are predicted as a whole.</p><p>Semi-Supervised Few-Shot Learning In semi-supervised few-shot learning, an extra unlabeled set not contained in current episode is used to improve classification accuracy <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b14">15]</ref>. In <ref type="bibr" target="#b25">[26]</ref>, the extended versions of Prototypical Networks <ref type="bibr" target="#b31">[32]</ref> are proposed to use unlabeled data to create class prototypes by Soft k -Means. LST <ref type="bibr" target="#b14">[15]</ref> employs pseudo-labeling strategy to the unlabeled set, then it re-trains and fine-tunes the base model based on the pseudo-labeled data. For recognizing the novel classes, it utilizes dynamically sampled data which is not contained in the current episode. Different from these methods, the unlabeled data in our method comes from the query set and we requires no extra datasets besides the support and query set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodology</head><p>We firstly use cosine similarity based prototypical network (CSPN) to learn a discriminative feature space and get the basic prototypes of few-shot classes. Then we figure out two influencing factors in prototype computation: the intraclass bias and the cross-class bias. Accordingly, we propose the bias diminishing (BD) method for prototype rectification in transductive setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Denotation</head><p>At the training stage, a labeled dataset D of base classes C base is given to train the feature extractor F θ (·) and the cosine classifier C(·|W ). At the inference stage, we aim to recognize few-shot classes C f ew with K labeled images per class. Episodic sampling is adopted to form such N -way K-shot tasks. Each episode consists of a support set S and a query set Q. In the support set, all samples x are labeled and we use the extracted features X = F θ (x) to compute the prototypes P of few-shot classes. The samples in the query set are unlabeled for test.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Cosine Similarity Based Prototypical Network</head><p>We propose a metric learning based method: cosine similarity based prototypical network (CSPN) to compute the basic prototypes of few-shot classes. Training a good feature extractor that can extract discriminative features is of great importance. Thus, we firstly train a feature extractor F θ (·) with a cosine similarity based classifier C(·|W ) on the base classes. The cosine classifier C(·|W ) is:</p><formula xml:id="formula_0">C(F θ (x) | W ) = Sof tmax(τ · Cos(F θ (x), W ))<label>(1)</label></formula><p>where W is the learnable weight of the base classes and τ is a scalar parameter. We target to minimize the negative log-likelihood loss on the supervised classification task:</p><formula xml:id="formula_1">L(θ, W | D) = E[−logC(F θ (x) | W )]<label>(2)</label></formula><p>At the inference stage, retraining F θ (·) and classification weights on the scarce data of C f ew classes is likely to run into overfitting. To avoid it, we directly compute the basic prototype P n of class n as follows:</p><formula xml:id="formula_2">P n = 1 K K i=1 X i,n<label>(3)</label></formula><p>where X is the normalized feature of support samples. The query samples can be classified by finding the nearest prototype based on cosine similarity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Bias Diminishing for Prototype Rectification</head><p>In CSPN, we can obtain the basic prototypes by simply averaging the features of support samples. However, the prototypes computed in such low-data regimes are biased against the expected prototypes we want to find. Therefore, we identify two influencing factors: the intra-class bias and the cross-class bias, and accordingly propose the bias diminishing approach.</p><p>The intra-class bias within a class is defined by Eq. <ref type="formula" target="#formula_3">(4)</ref>:</p><formula xml:id="formula_3">B intra = E X ∼p X [X ] − E X∼p X [X]<label>(4)</label></formula><p>where p X is the distribution of all data belonging to a certain class and p X is the distribution of the available labeled data of this class. It is easy to observe the difference between the expectations of the two distributions. The difference becomes more significant in low-data regimes. Since the prototype is computed by feature averaging, the intra-class bias also can be understood as the difference between the expected prototype and the actually computed prototype. The expected prototype is supposed to be represented by the mean feature of all samples within a class. In practice, only a part of samples are available for training which is to say that, it is almost impossible to get the expected prototype. In few-shot scenario, we merely have K samples per few-shot class. The number of available samples are far less than the expected amount. Computed from scarce samples, the prototypes obviously tend to be biased.</p><p>To reduce the bias, we adopt the pseudo-labeling strategy to augment the support set, which assigns temporary labels to the unlabeled data according to their prediction confidence <ref type="bibr" target="#b14">[15]</ref>. Pseudo-labeled samples can be augmented into the support set such that we can compute new prototypes in a 'higherdata' regime. We can simply select top Z confidently predicted query samples per class to augment the support set S with their pseudo labels. We use CSPN as recognition model to get the prediction scores. Then we have an augmented support set with confidently predicted query samples: S = S ∪ Q Z pseudo . Since some pseudo-labeled samples are likely to be misclassified, simple averaging with the same weights is possible to result in larger bias in prototype computation. To compute the new prototypes in a more reasonable way, we use the weighted sum of X as the rectified prototype. We note that X refers to the feature of the sample in S including both original support samples and pseudo-labeled query samples. The rectified prototype of a class is thus computed from the normalized features X :</p><formula xml:id="formula_4">P n = Z+K i=1 w i,n · X i,n<label>(5)</label></formula><p>where w i,n is the weight indicating the relation of the augmented support samples and the basic prototypes. The weight is computed by:</p><formula xml:id="formula_5">w i,n = exp(ε · Cos(X i,n , P n )) K+Z j=1 exp(ε · Cos(X j,n , P n ))<label>(6)</label></formula><p>ε is a scalar parameter and P n is the basic prototype obtained in Section 3.2. Samples with larger cosine similarity to the basic prototypes hold larger proportions in prototype rectification. Compared with the basic prototype P n , the rectified prototype P n distributes closer to the expected prototype.</p><p>The cross-class bias refers to the distance between the mean vectors of support and query datasets. It is derived from the domain adaptation problem where the mean value is used as a type of the first order statistic information to represent a dataset <ref type="bibr" target="#b36">[37]</ref>. Minimizing the distance between different domains is a typical method of mitigating domain gaps. Since the support set and the query set are assumed to distribute in the same domain, the distance between them is the distribution bias rather than the domain gap. The cross-class bias B cross is formulated as:</p><formula xml:id="formula_6">B cross = E Xs∼p S [X s ] − E Xq∼p Q [X q ]<label>(7)</label></formula><p>where p S and p Q respectively represent the distributions of support and query sets. Notably, the support set S and the query set Q include N few-shot classes in Eq. <ref type="bibr" target="#b6">(7)</ref>. To diminish B cross , we can shift the query set towards the support set. In practice, we add a shifting term ξ to each normalized query feature X q and ξ is defined as:</p><formula xml:id="formula_7">ξ = 1 |S| |S| i=1 X i,s − 1 |Q| |Q| j=1 X j,q<label>(8)</label></formula><p>The detailed derivation of ξ is given in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Theoretical Analysis</head><p>We give the theoretical analysis to show the rationality of our proposed bias diminishing method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Lower Bound of the Expected Performance</head><p>We derive the formulation of our expected performance in theory and point out what factors influence the final result. We use X to represent the feature of a class. For clear illustration, the formulation of class prototype we use in this section is given:</p><formula xml:id="formula_8">P = T i X i T<label>(9)</label></formula><p>where T = K + Z, X i ∈ S and S is a subset sampled from X. X is the normalized feature and P is the normalized prototype. For cosine similarity based prototypical network, an expected prototype should have the largest cosine similarity to all samples within its class. Our objective is to maximize the expected cosine similarity which is positively correlated with the classification accuracy. It is formulated as:</p><formula xml:id="formula_9">max E P [E X [Cos(P, X)]]<label>(10)</label></formula><p>And we derive it as:</p><formula xml:id="formula_10">E P [E X [Cos(P, X)]] = E P,X [P · X] = E[X] · E[ P P 2 ]<label>(11)</label></formula><p>From previous works <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b26">27]</ref>, we know that: </p><formula xml:id="formula_11">E[ A B ] = E[A] E[B] + O(n −1 ) (f irst order)<label>(12)</label></formula><formula xml:id="formula_12">E P [E X [Cos(P, X)]] ≈ E[X] · E[P ] E[ P 2 ]<label>(13)</label></formula><p>Based on Cauchy-Schwarz inequality, we have:</p><formula xml:id="formula_13">E[ P 2 ] ≤ E[ P 2 2 ]<label>(14)</label></formula><p>P and X are D-dimensional vectors which can be denoted as P = [p 1 , p 2 , ..., p D ] and X = [x 1 , x 2 , ..., x D ] respectively. In our method, we assume that each dimension of a vector is independent from each other. Then, we can derive that:</p><formula xml:id="formula_14">E[ P 2 2 ] = E[ D i=1 p 2 i ] = D i=1 [V ar[p i ] + E[p i ] 2 ] = D i=1 [V ar[p i ] + E[x i ] 2 ] = D i=1 [ 1 T V ar[x i ] + E[x i ] 2 ]<label>(15)</label></formula><p>Thus, the lower bound of the expected cosine similarity is formulated as:</p><formula xml:id="formula_15">E P [E X [Cos(P, X)]] ≥ E[X] · E[P ] E[ P 2 2 ] = D i=1 E[x i ] 2 1 T D i=1 V ar[x i ] + D i=1 E[x i ] 2<label>(16)</label></formula><p>Maximizing the expected accuracy is approximate to maximize its lower bound of the cosine similarity as shown in Eq. <ref type="bibr" target="#b15">(16)</ref>. It can be seen that the number T of the sample is positively correlated with the lower bound of the expected performance. Thus, we import more pseudo-labeled samples into prototype computation. The rationality of the pseudo-labeling strategy in improving few-shot accuracy is that, it can effectively raise the lower bound of the expected performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Derivation of Shifting Term ξ</head><p>We propose to reduce the cross-class bias by feature shifting and the derivation of shifting term ξ is provided as follows. In N -way K-shot Q-query tasks, the accuracy can be formalized as:</p><formula xml:id="formula_16">Acc = 1 N Q N i Q q 1(y i,q == i)<label>(17)</label></formula><formula xml:id="formula_17">= 1 N Q N i Q q 1(Cos(P i , X i,q ) &gt; max j =i {Cos(P j , X i,q )})<label>(18)</label></formula><p>where y i,q is the predicted label and i is the true class label. 1(b) is an indicator function. 1(b) = 1 if b is true and 0 otherwise. P i is the prototype of class i and X i,q is the q-th query feature of class i. Based on Eq. (18), the accuracy formulation can be further rewritten as:</p><formula xml:id="formula_18">Acc = 1 N Q N i Q q 1(Cos(P i , X i,q ) &gt; t i )<label>(19)</label></formula><p>where t i denotes the cosine similarity threshold of the i-th class. Improving the accuracy is equal to maximize the cosine similarity Cos(·).</p><p>As mentioned above, there is a bias between the support and query set of a class i. We assume that the bias can be diminished by adding a shifting term ξ i to the query samples. Since the class labels are unknown, we approximately add the same term ξ to all query samples. The term ξ should follow the objective:</p><formula xml:id="formula_19">arg max ξ 1 N Q N i Q q Cos(P i , X i,q + ξ)<label>(20)</label></formula><p>We assume that each feature X can be represented as X = P + . Eq. (20) can be further formalized as:</p><formula xml:id="formula_20">arg max ξ 1 N Q N i Q q Cos(P i , P i + i,q + ξ)<label>(21)</label></formula><p>To maximize the cosine similarity, we should minimize the following objective:</p><formula xml:id="formula_21">min 1 N Q N i Q q ( i,q + ξ)<label>(22)</label></formula><p>The term ξ is thus computed:</p><formula xml:id="formula_22">ξ = −E[ ]<label>(23)</label></formula><formula xml:id="formula_23">= 1 N Q N i Q q (P i − X i,q )<label>(24)</label></formula><p>We can see that Eq. (24) is in line with Eq. <ref type="bibr" target="#b7">(8)</ref>. For cosine similarity computation, the shifting term is calculated from the normalized features as displayed in Section 3.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Datasets</head><p>miniImageNet consists of 100 randomly chosen classes from ILSVRC-2012 <ref type="bibr" target="#b27">[28]</ref>. We adopt the split proposed in <ref type="bibr" target="#b24">[25]</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Implementation details</head><p>We train the base recognition model CSPN in the supervised way with SGD optimizer and test the validation set on 5-way 5-shot tasks for model selection. WRN-28-10 <ref type="bibr" target="#b37">[38]</ref> is used as the main backbone. ConvNets <ref type="bibr" target="#b7">[8]</ref> and ResNet-12 <ref type="bibr" target="#b13">[14]</ref> are used for ablation. The results are averaged from 600 randomly sampled episodes. Each episode contains 15 query samples per class. The initial value of τ is 10 and ε is fixed at 10. More details are shown in the supplementary materials. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Results on miniImageNet and tieredImageNet</head><p>The results on miniImageNet and tieredImageNet are shown in <ref type="table" target="#tab_2">Table 1</ref> and <ref type="table" target="#tab_3">Table 2</ref> respectively. It can be seen that we achieve state-of-the-art performance in all cases. Compared with existing transductive methods <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b3">4]</ref>, our proposed BD-CSPN consistently achieves the best performance on both datasets. EGNN <ref type="bibr" target="#b10">[11]</ref> transductively learns edge-labels through exploring the intra-cluster similarity and the inter-cluster dissimilarity. Transductive Fine-Tuning <ref type="bibr" target="#b3">[4]</ref> is newly published, providing a strong baseline by simple fine-tuning techniques. In comparison with TPN <ref type="bibr" target="#b16">[17]</ref>, we achieve better results with a simpler implementation of label propagation technique. Given the similar backbone ConvNet-128 on miniImageNet, BD-CSPN produces good results of 61.74% and 76.12% on 1-shot and 5-shot tasks respectively, surpassing TPN by large margins. Our method also shows superiority compared with existing semi-supervised methods <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b14">15]</ref>. Note that LST <ref type="bibr" target="#b14">[15]</ref> uses extra unlabeled data as auxiliary information in evaluation, which is not contained in current episode. It re-trains and fine-tunes the model on each novel task. We have a simpler technique without re-training and fine-tuning which is more efficient in computation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Results on Meta-Dataset</head><p>To further illustrate the effectiveness of our method, we show 5-shot results on the newly proposed Meta-Dataset <ref type="bibr" target="#b33">[34]</ref> in <ref type="table" target="#tab_4">Table 3</ref>. The average rank of our 5-shot model is 1.9. More details are provided in our supplementary materials. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Ablation Study</head><p>The ablation results are shown in <ref type="table" target="#tab_5">Table 4</ref>. We display the results of CSPN as baselines which are obtained in inductive setting. The network is trained on traditional supervised tasks (64-way), following the setting in <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b6">7]</ref>. It achieves better performance than some complicated meta-trained methods <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b28">29]</ref> with the same backbone, as shown in <ref type="table" target="#tab_2">Table 1</ref>. Based on CSPN, our BD module makes an improvement by large margins up to 9% and 3% on 1-shot and 5-shot tasks respectively. It leads to relatively minor improvements in 5-shot scenarios. Ablation of Intra-Class Bias Diminishing It can be seen in <ref type="table" target="#tab_5">Table 4</ref> that BD i -CSPN brings in significant improvements on both datasets. The intra-class bias diminishing module especially shows its merit in 1-shot scenarios. With intra-class bias diminished, the accuracy on 1-shot miniImageNet increases from 61.84% to 69.81% and the accuracy on 1-shot tieredImageNet raises to 78.12% from 69.20%. Furthermore, to intuitively demonstrate the influence of our proposed intraclass bias diminishing module, we display the 5-way accuracy in <ref type="figure" target="#fig_1">Fig. 2(a)-2(b)</ref>. The results are reported without using cross-class bias diminishing module. It shows a coincident tendency that with more pseudo-labeled samples, there is an obvious growth of classification accuracy. We use the validation set to determine the value of Z and set it to 8 for accuracy comparison in <ref type="table" target="#tab_2">Table 1 and Table 2</ref>.</p><p>Theoretical Value As we know, the expected accuracy Acc(P, X) has a positive correlation with the expected cosine similarity. Then we derive the firstorder estimation of Acc(P, X) from Eq. (16) which is formulated as:</p><formula xml:id="formula_24">Acc(P, X) ≈ η · α λ · 1 K+Z + α<label>(25)</label></formula><p>where η is a coefficient and K + Z = T . λ and α are values correlated with the variance term and the expectation term in Eq. <ref type="bibr" target="#b15">(16)</ref>. The theoretical values of λ and α can be approximately computed from the extracted features. Furthermore, we can compute the value of η by 1-shot and 5-shot accuracies of CSPN. Thus, the number Z is the only variable in Eq. <ref type="bibr" target="#b24">(25)</ref>. The theoretical curves are displayed as the dashed lines in <ref type="figure" target="#fig_1">Fig. 2(c)</ref> to show the impact of Z on classification accuracy. The dashed lines, showing the theoretical lower bound of the expected accuracy, have a consistent tendency with our experiment results in <ref type="figure" target="#fig_1">Fig. 2</ref>(a)-2(b). Since the cosine similarity is continuous and the accuracy is discrete, the accuracy stops increasing when the cosine similarity grows to a certain value. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>T-SNE Visualization</head><p>We show t-SNE visualization of our intra-bias diminishing method in <ref type="figure" target="#fig_2">Fig. 3(a)</ref> for intuitive illustration. The basic prototype of each class is computed from the support set while the rectified prototype is computed from the augmented support set. In this section, the expected prototype refers to the first term in Eq. (4) which is represented by the average vector of all samples (both support and query samples) of a class in an episode. Due to the scarcity of labeled samples, there is a large bias between the basic prototype and the expected prototype. The bias can be reflected by the distance between the stars and the triangles in <ref type="figure" target="#fig_2">Fig. 3(a)</ref>. <ref type="table" target="#tab_5">Table 4</ref> shows the ablative results of the cross-class bias diminishing module. It illustrates an overall improvement as a result of diminishing the cross-class bias. Moving the whole query set towards the support set center by importing the shifting term ξ is an effective approach to reduce the bias between the two datasets. For example, the accuracy increases by 1.64% on 1-shot tieredImageNet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ablation of Cross-Class Bias Diminishing</head><p>T-SNE Visualization In few-shot learning, the support set includes far less samples compared with the query set in an episode. There exists a large distance between the two mean vectors of the datasets. We aim to decrease the distance by shifting the query samples towards the center of the support set as shown in <ref type="figure" target="#fig_2">Fig. 3(b)</ref>. It depicts the spatial changing of the query samples, before and after cross-class bias diminishing. The significant part is zoomed in for clear visualization, where the query samples with BD cross (marked in green) distribute more closely to the center of support set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ablation of Backbone</head><p>The results on miniImageNet are displayed in <ref type="table" target="#tab_6">Table 5</ref> and more ablation results are given in the supplementary materials. Our method also shows good performance based on ConvNet-128 and ResNet-12, which is  better than most approaches in <ref type="table" target="#tab_2">Table 1</ref>. For example, with ResNet-12, we achieve 79.23% in 5-shot scenario, outperforming the strongest baselines: 78.7% <ref type="bibr" target="#b14">[15]</ref> and 78.63% <ref type="bibr" target="#b13">[14]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Comparison with Transductive Fine-Tuning</head><p>We compare our method with TFT <ref type="bibr" target="#b3">[4]</ref> in <ref type="table" target="#tab_6">Table 5</ref>, which is recently proposed as a new baseline for few-shot image classification. BD-CSPN outperforms it given different backbones. For example, we achieve better results which are higher than TFT by 3% to 5% given ResNet-12. Since BD-CSPN and TFT conduct experiments in the same transductive setting, the comparison between these two methods is more persuasive to demonstrate the effectiveness of the approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>In this paper, we propose a powerful method of prototype rectification in fewshot learning, which is to diminish the intra-class bias and the cross-class bias of class prototypes. Our theoretical analysis verifies that, the proposed bias diminishing method is effective in raising the lower bound of the expected performance. Extensive experiments on three few-shot benchmarks demonstrate the effectiveness of our method. The proposed bias diminishing method achieves significant improvements in transductive setting by large margins (e.g. 8.47% on 1-shot miniImageNet and 9.54% on 1-shot tieredImageNet).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Appendix</head><p>A.1 Implementation Details WRN-28-10 <ref type="bibr" target="#b37">[38]</ref>, is used as the main backbone in the experiments. ConvNet-64 <ref type="bibr" target="#b3">[4]</ref>, ConvNet-128 <ref type="bibr" target="#b7">[8]</ref>, ConvNet-256 <ref type="bibr" target="#b10">[11]</ref> and ResNet-12 <ref type="bibr" target="#b13">[14]</ref> are used in ablation study. We remove the last ReLU layer of WRN-28-10 in experiments. The results reported in our experiments are collected by sampling 600 episodes with 95% confidence intervals. We choose SGD as the optimizer with a momentum of 0.9 and a weight decay parameter of 0.0005. The maximum training epoch is set to 60. The initial learning rate is 0.1 and it is reduced after 10, 20, 40 epochs. At the training stage, we use horizontal flip and random crop on the two ImageNet derivatives as in <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b13">14]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Results on Omniglot and CUB</head><p>We conduct extra experiments on another two benchmarks: Omniglot <ref type="bibr" target="#b12">[13]</ref> and CUB <ref type="bibr" target="#b35">[36]</ref>.</p><p>Omniglot Omniglot has 1623 classes of handwritten characters with 20 samples per class. All images are resized to 28 x 28. The data augmentation techniques proposed by <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b31">32]</ref> are used in higher-way test, which rotates each image by 90, 180, 270 degrees to form new classes. Therefore, the dataset has total 6492 classes and we use 4112 classes for training, 688 classes for validation and 1692 classes for test as in <ref type="bibr" target="#b31">[32]</ref>.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Additional Ablation on miniImageNet and tieredImageNet</head><p>We provide supplementary ablation study on miniImageNet and tieredImageNet to show our performance on different backbones. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4 Higher-way Results</head><p>Results on higher-way tasks are given in <ref type="table" target="#tab_2">Table 10</ref> to <ref type="table" target="#tab_2">Table 12</ref> to show the effectiveness of our method in harder tasks. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.5 Robust Test</head><p>We conduct an experiment as follows to test the robustness of the proposed BD-CSPN. In each 5-way K-shot 15-query episode, we randomly add extra 15×N' samples of N' classes that do not belong to the 5 classes. The extra samples are treated as unlabeled data. Our model shows good robustness (aka little performance drop) in 5-shot cases. The accuracy decreases to some extents when the unlabeled data increases.  <ref type="table" target="#tab_2">Table 14</ref> and the ranks of our 5-shot model. For detailed comparison, please refer to <ref type="table" target="#tab_2">Table 1</ref> (top) in <ref type="bibr" target="#b33">[34]</ref>. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Fig. 1. Framework of our proposed method for prototype rectification. The cross-class bias diminishing module reduces the bias between the support set and the query set while the intra-class bias diminishing module reduces the bias between the actually computed prototypes and the expected prototypes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Effectiveness of intra-bias diminishing. Z: the number of pseudo-labeled samples. (a) 5-way 1-shot results. (b) 5-way 5-shot results. (c) Theoretical value on mini-ImageNet. The experiment results (solid lines) show a consistent tendency with the theoretical results (dashed lines).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>T-SNE visualization of BDintra (b) T-SNE visualization of BDcross We randomly sample a 5-way 1-shot episode on tieredImageNet. Different classes are marked in different colors. Best viewed in color with zoom in.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>where the 100 classes are split into 64 training classes, 16 validation classes and 20 test classes. Each class contains 600 images of size 84 × 84. tieredImageNet [26] is also a derivative of ILSVRC-2012 [28] containing 608 low-level categories, which are split into 351, 97, 160 categories for training, validation, test with image size of 84 × 84. Meta-Dataset [34] is a new benchmark that is large-scale and consists of diverse datasets for training and evaluating models.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 .</head><label>1</label><figDesc>Average accuracy (%) comparison on miniImageNet. ‡ Training set and validation set are used for training.</figDesc><table><row><cell>Setting</cell><cell>Methods</cell><cell>Backbone</cell><cell cols="2">miniImageNet</cell></row><row><cell></cell><cell></cell><cell></cell><cell>1-shot</cell><cell>5-shot</cell></row><row><cell></cell><cell>Matching Network [35]</cell><cell cols="3">ConvNet-64 43.56±0.84 55.31±0.73</cell></row><row><cell></cell><cell>MAML [6]</cell><cell cols="3">ConvNet-32 48.70±1.84 63.11±0.92</cell></row><row><cell></cell><cell cols="4">Prototypical Networks ‡ [32] ConvNet-64 49.42±0.78 68.20±0.66</cell></row><row><cell></cell><cell>Relation Net [33]</cell><cell cols="3">ConvNet-256 50.44±0.82 65.32±0.70</cell></row><row><cell></cell><cell>SNAIL [19]</cell><cell cols="3">ResNet-12 55.71±0.99 68.88±0.92</cell></row><row><cell>Inductive</cell><cell>LwoF [8] AdaResNet [20]</cell><cell cols="3">ConvNet-128 56.20±0.86 73.00±0.64 ResNet-12 56.88±0.62 71.94±0.57</cell></row><row><cell></cell><cell>TADAM [23]</cell><cell cols="3">ResNet-12 58.50±0.30 76.70±0.30</cell></row><row><cell></cell><cell cols="4">Activation to Parameter ‡ [24] WRN-28-10 59.60±0.41 73.74±0.19</cell></row><row><cell></cell><cell>LEO ‡ [29]</cell><cell cols="3">WRN-28-10 61.76±0.08 77.59±0.12</cell></row><row><cell></cell><cell>MetaOptNet-SVM [14]</cell><cell cols="3">ResNet-12 62.64±0.61 78.63±0.46</cell></row><row><cell></cell><cell>BFSL [7]</cell><cell cols="3">WRN-28-10 62.93±0.45 79.87±0.33</cell></row><row><cell>Semi-Supervised</cell><cell>ML [26] LST [15]</cell><cell cols="3">ConvNet-128 49.04±0.31 62.96±0.14 ResNet-12 70.1±1.9 78.7±0.8</cell></row><row><cell></cell><cell>TPN [17]</cell><cell cols="3">ConvNet-64 55.51±0.86 69.86±0.65</cell></row><row><cell>Transductive</cell><cell cols="4">EGNN [11] Transductive Fine-Tuning [4] WRN-28-10 65.73±0.68 78.40±0.52 ConvNet-256 -76.37</cell></row><row><cell></cell><cell>BD-CSPN (ours)</cell><cell cols="3">WRN-28-10 70.31±0.93 81.89±0.60</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 .</head><label>2</label><figDesc>Average accuracy (%) comparison on tieredImageNet. * Results by our implementation. ‡ Training set and validation set are used for training.</figDesc><table><row><cell>Setting</cell><cell>Methods</cell><cell>Backbone</cell><cell cols="2">tieredImageNet</cell></row><row><cell></cell><cell></cell><cell></cell><cell>1-shot</cell><cell>5-shot</cell></row><row><cell></cell><cell>MAML [6]</cell><cell cols="3">ConvNet-32 51.67±1.81 70.30±1.75</cell></row><row><cell></cell><cell cols="4">Prototypical Networks ‡ [32] ConvNet-64 53.31±0.89 72.69±0.74</cell></row><row><cell>Inductive</cell><cell>Relation Net [33] LwoF [8]</cell><cell cols="3">ConvNet-256 54.48±0.93 71.32±0.78 ConvNet-128 60.35±0.88* 77.24±0.72*</cell></row><row><cell></cell><cell>LEO ‡ [29]</cell><cell cols="3">WRN-28-10 66.33±0.05 81.44±0.09</cell></row><row><cell></cell><cell>MetaOptNet-SVM [14]</cell><cell cols="3">ResNet-12 65.99±0.72 81.56±0.53</cell></row><row><cell>Semi-Supervised</cell><cell>ML [26] LST [15]</cell><cell cols="3">ConvNet-128 51.38±0.38 69.08±0.25 ResNet-12 77.7±1.6 85.2±0.8</cell></row><row><cell></cell><cell>TPN [17]</cell><cell cols="3">ConvNet-64 59.91±0.94 73.30±0.75</cell></row><row><cell>Transductive</cell><cell cols="4">EGNN [11] Transductive Fine-Tuning [4] WRN-28-10 73.34±0.71 85.50±0.50 ConvNet-256 -80.15</cell></row><row><cell></cell><cell>BD-CSPN (ours)</cell><cell cols="3">WRN-28-10 78.74±0.95 86.92±0.63</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 .</head><label>3</label><figDesc>5-shot results on Meta-Dataset: the model is trained on ILSVRC-2012 only and test on the listed test sources.</figDesc><table><row><cell>Test 5-shot</cell><cell>Test 5-shot</cell><cell>Test 5-shot</cell><cell>Test 5-shot</cell><cell>Test 5-shot</cell></row><row><cell cols="2">ILSVRC 59.80 Omniglot 78.29</cell><cell>Aircraft 43.42</cell><cell cols="2">Birds 67.22 Textures 54.82</cell></row><row><cell>Quick Draw 58.80</cell><cell cols="4">Fungi 61.56 VGG Flower 83.88 Traffic Signs 68.68 MSCOCO 52.69</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 .</head><label>4</label><figDesc>Ablative results of bias diminishing module. CSPN: without bias diminishing modules; BDc-CSPN: with cross-class bias diminishing module; BDi-CSPN: with intra-class bias diminishing module; BD-CSPN: with both modules.</figDesc><table><row><cell>Dataset</cell><cell cols="2">Method 1-shot 5-shot</cell><cell>Dataset</cell><cell>Method 1-shot 5-shot</cell></row><row><cell></cell><cell>CSPN</cell><cell>61.84 78.64</cell><cell></cell><cell>CSPN</cell><cell>69.20 84.31</cell></row><row><cell>miniImageNet</cell><cell cols="2">BDc-CSPN 62.54 79.32 BDi-CSPN 69.81 81.58</cell><cell>tieredImageNet</cell><cell>BDc-CSPN 70.84 84.99 BDi-CSPN 78.12 86.67</cell></row><row><cell></cell><cell cols="2">BD-CSPN 70.31 81.89</cell><cell></cell><cell>BD-CSPN 78.74 86.92</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 .</head><label>5</label><figDesc>Ablation of backbones and result comparison with TFT</figDesc><table><row><cell>(Transductive</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 6 .</head><label>6</label><figDesc>Results on Omniglot.CUB We use the Caltech-UCSD Birds (CUB) 200-2011 dataset<ref type="bibr" target="#b35">[36]</ref> of 200 finegrained bird species. The dataset is split into 100 training classes, 50 validation classes and 50 test classes as provided in<ref type="bibr" target="#b2">[3]</ref>.</figDesc><table><row><cell cols="5">1-shot Omniglot CSPN BD-CSPN CSPN BD-CSPN 5-shot</cell></row><row><cell cols="2">ConvNet-64 97.40</cell><cell>99.62</cell><cell>99.60</cell><cell>99.76</cell></row><row><cell cols="2">ConvNet-128 97.33</cell><cell>99.69</cell><cell>99.63</cell><cell>99.75</cell></row><row><cell cols="2">ConvNet-256 97.85</cell><cell>99.77</cell><cell>99.63</cell><cell>99.76</cell></row><row><cell>ResNet-12</cell><cell>98.70</cell><cell>99.80</cell><cell>99.72</cell><cell>99.77</cell></row><row><cell cols="2">WRN-28-10 99.02</cell><cell>99.08</cell><cell>99.82</cell><cell>99.85</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 7 .</head><label>7</label><figDesc>Results on CUB.</figDesc><table><row><cell>CUB</cell><cell cols="4">1-shot CSPN BD-CSPN CSPN BD-CSPN 5-shot</cell></row><row><cell cols="2">ConvNet-64 64.72</cell><cell>75.10</cell><cell>84.21</cell><cell>87.25</cell></row><row><cell cols="2">ConvNet-128 65.86</cell><cell>76.11</cell><cell>85.97</cell><cell>87.52</cell></row><row><cell cols="2">ConvNet-256 65.99</cell><cell>75.77</cell><cell>84.74</cell><cell>87.76</cell></row><row><cell>ResNet-12</cell><cell>76.24</cell><cell>84.90</cell><cell>88.68</cell><cell>90.22</cell></row><row><cell cols="2">WRN-28-10 77.80</cell><cell>87.45</cell><cell>90.14</cell><cell>91.74</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 8 .Table 9 .</head><label>89</label><figDesc>Backbone ablation on miniImageNet. Backbone ablation on tieredImageNet.</figDesc><table><row><cell cols="2">miniImageNet 1-shot 5-shot</cell></row><row><cell>ConvNet-64</cell><cell>60.48 75.02</cell></row><row><cell>ConvNet-256</cell><cell>60.97 75.19</cell></row><row><cell cols="2">tieredImageNet 1-shot 5-shot</cell></row><row><cell>ConvNet-64</cell><cell>65.08 78.08</cell></row><row><cell>ConvNet-128</cell><cell>66.33 79.57</cell></row><row><cell>ConvNet-256</cell><cell>67.09 80.66</cell></row><row><cell>ResNet-12</cell><cell>76.17 85.70</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 10 .Table 11 .Table 12 .</head><label>101112</label><figDesc>Higher-way test on miniImageNet. Higher-way test on tieredImageNet. Higher-way test on Omniglot.</figDesc><table><row><cell></cell><cell cols="4">miniImageNet 1-shot 5-shot</cell></row><row><cell></cell><cell>10-way</cell><cell></cell><cell cols="2">51.58 69.35</cell></row><row><cell></cell><cell>20-way</cell><cell></cell><cell cols="2">36.00 55.23</cell></row><row><cell></cell><cell cols="4">tieredImageNet 1-shot 5-shot</cell></row><row><cell></cell><cell>10-way</cell><cell></cell><cell cols="2">63.39 77.54</cell></row><row><cell></cell><cell>20-way</cell><cell></cell><cell cols="2">48.48 65.68</cell></row><row><cell></cell><cell>50-way</cell><cell></cell><cell cols="2">31.67 49.50</cell></row><row><cell>Omniglot</cell><cell></cell><cell cols="2">1shot</cell><cell cols="2">5shot</cell></row><row><cell></cell><cell></cell><cell cols="4">CSPN BD-CSPN CSPN BD-CSPN</cell></row><row><cell>10-way</cell><cell cols="2">ConvNet-128 92.83</cell><cell>98.46</cell><cell>98.67</cell><cell>99.02</cell></row><row><cell></cell><cell cols="2">ConvNet-256 93.82</cell><cell>98.65</cell><cell>98.90</cell><cell>99.14</cell></row><row><cell></cell><cell>ResNet-12</cell><cell>96.38</cell><cell>98.97</cell><cell>99.11</cell><cell>99.22</cell></row><row><cell></cell><cell cols="2">WRN-28-10 96.62</cell><cell>99.12</cell><cell>99.35</cell><cell>99.40</cell></row><row><cell>200-way</cell><cell cols="2">ConvNet-64 75.44</cell><cell>89.08</cell><cell>93.21</cell><cell>94.72</cell></row><row><cell cols="3">1000-way ConvNet-64 56.85</cell><cell>71.18</cell><cell>82.72</cell><cell>85.87</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 13 .</head><label>13</label><figDesc>Robust test on miniImageNet. Acc: the accuracy of the labeled 5×15 query data. mAP: it is computed from top-15 confidently predicted data of each class. Results on Meta-Dataset Meta-Dataset<ref type="bibr" target="#b33">[34]</ref> is a new benchmark for few-shot learning. It is large-scale and consists of diverse datasets for training and evaluating models. We show our results in</figDesc><table><row><cell cols="2">miniImageNet N'=1</cell><cell>N'=5</cell></row><row><cell>1-shot Acc</cell><cell cols="2">66.88 (3.43↓) 64.58 (5.73↓)</cell></row><row><cell>5-shot Acc</cell><cell cols="2">80.31 (1.58↓) 79.25 (2.64↓)</cell></row><row><cell>1-shot mAP</cell><cell>76.08</cell><cell>64.35</cell></row><row><cell>5-shot mAP</cell><cell>89.03</cell><cell>81.06</cell></row><row><cell>A.6</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 14 .</head><label>14</label><figDesc>Results on Meta-Dataset. Avg. rank of our 5-shot model is 1.9.</figDesc><table><row><cell cols="2">Test Source 1-shot 5-shot</cell></row><row><cell>ILSVRC</cell><cell>45.57 59.80 (1)</cell></row><row><cell>Omniglot</cell><cell>66.77 78.29 (1)</cell></row><row><cell>Aircraft</cell><cell>32.85 43.42 (7)</cell></row><row><cell>Birds</cell><cell>49.41 67.22 (3)</cell></row><row><cell>Textures</cell><cell>40.64 54.82 (1)</cell></row><row><cell cols="2">Quick Draw 45.52 58.80 (1)</cell></row><row><cell>Fungi</cell><cell>44.65 61.56 (1)</cell></row><row><cell cols="2">VGG Flower 69.97 83.88 (4)</cell></row><row><cell cols="2">Traffic Signs 53.93 68.68 (1)</cell></row><row><cell>MSCOCO</cell><cell>40.06 52.69 (1)</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Infinite mixture prototypes for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tenenbaum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="232" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Learning to learn by gradient descent by gradient descent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Andrychowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Denil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">W</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pfau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schaul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shillingford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>De Freitas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS. pp</title>
		<imprint>
			<biblScope unit="page" from="3981" to="3989" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">A closer look at few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Kira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">C F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Huang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">A baseline for few-shot image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Dhillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chaudhari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ravichandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Soatto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">One-shot learning of object categories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="594" to="611" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Model-agnostic meta-learning for fast adaptation of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1126" to="1135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Boosting few-shot visual learning with self-supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gidaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bursuc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">P</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cord</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8058" to="8067" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Dynamic few-shot visual learning without forgetting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gidaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CVPR</publisher>
			<biblScope unit="page" from="4367" to="4375" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Transductive inference for text classification using support vector machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="200" to="209" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Edge-labeling graph neural network for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Yoo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="11" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">141</biblScope>
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">One shot learning of simple visual concepts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">M</forename><surname>Lake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">33</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Meta-learning with differentiable convex optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ravichandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Soatto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="10657" to="10665" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Learning to self-train for semi-supervised few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Chua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Meta-sgd: Learning to learn quickly for few shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Learning to propagate labels: Transductive propagation network for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning from one example through shared densities on transforms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Matsakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Viola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="464" to="471" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">A simple neural attentive meta-learner</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rohaninejad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Rapid adaptation with conditionally shifted neurons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Munkhdalai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mehri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Trischler</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3661" to="3670" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">On first-order meta-learning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Nichol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Achiam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schulman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Optimal decisions from probabilistic models: The intersection-overunion case</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nowozin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>CVPR</publisher>
			<biblScope unit="page" from="548" to="555" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Tadam: Task dependent adaptive metric for improved few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">N</forename><surname>Oreshkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">R</forename><surname>Lpez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lacoste</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS. pp</title>
		<imprint>
			<biblScope unit="page" from="721" to="731" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Few-shot image recognition by predicting parameters from activations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7229" to="7238" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Optimization as a model for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Meta-learning for semi-supervised few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Triantafillou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">The expected value of the ratio of correlated random variables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">H</forename><surname>Rice</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
		<respStmt>
			<orgName>Texas Tech University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<title level="m">Imagenet large scale visual recognition challenge</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="page" from="211" to="252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Meta-learning with latent embedding optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sygnowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Meta-learning with memory-augmented neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Santoro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bartunov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lillicrap</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1842" to="1850" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Few-shot learning with graph neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">G</forename><surname>Satorras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Estrach</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Prototypical networks for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS. pp</title>
		<imprint>
			<biblScope unit="page" from="4077" to="4087" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Learning to compare: Relation network for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1199" to="1208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Meta-dataset: A dataset of datasets for learning to learn from few examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Triantafillou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Dumoulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lamblin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Evci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Goroshin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gelada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Manzagol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Matching networks for one shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">P</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS. pp</title>
		<imprint>
			<biblScope unit="page" from="3637" to="3645" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">The caltech-ucsd birds-200-2011 dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Welinder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
		<respStmt>
			<orgName>California Institute of Technology</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Deep domain adaptation by geodesic distance minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">V</forename><surname>Gool</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>ICCVW</publisher>
			<biblScope unit="page" from="2651" to="2657" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Wide residual networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zagoruyko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>BMVC</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Learning with local and global consistency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Bousquet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">N</forename><surname>Lal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schlkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS. pp</title>
		<imprint>
			<biblScope unit="page" from="321" to="328" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
