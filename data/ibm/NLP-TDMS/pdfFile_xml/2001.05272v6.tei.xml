<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">FGN: Fusion Glyph Network for Chinese Named Entity Recognition</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenyu</forename><surname>Xuan</surname></persName>
							<email>xuanzhenyu@foxmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">School of Information Science and Technology</orgName>
								<orgName type="institution">Guangdong University of Foreign Studies</orgName>
								<address>
									<settlement>Guangdong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Bao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information Science and Technology</orgName>
								<orgName type="institution">Guangdong University of Foreign Studies</orgName>
								<address>
									<settlement>Guangdong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengyi</forename><surname>Jiang</surname></persName>
							<email>jiangshengyi@163.com</email>
							<affiliation key="aff0">
								<orgName type="department">School of Information Science and Technology</orgName>
								<orgName type="institution">Guangdong University of Foreign Studies</orgName>
								<address>
									<settlement>Guangdong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">FGN: Fusion Glyph Network for Chinese Named Entity Recognition</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T19:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Glyph</term>
					<term>Name Entity Recognition</term>
					<term>Interactive Knowledge</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>As pictographs, Chinese characters contain latent glyph information, which is often overlooked. In this paper, we propose the FGN 1 , Fusion Glyph Network for Chinese NER. Except for encoding glyph information with a novel CNN, this method may extract interactive information between character distributed representation and glyph representation by a fusion mechanism. The major innovations of FGN include: (1) a novel CNN structure called CGS-CNN is proposed to capture glyph information and interactive information between the neighboring graphs. (2) we provide a method with sliding window and attention mechanism to fuse the BERT representation and glyph representation for each character. This method may capture potential interactive knowledge between context and glyph. Experiments are conducted on four NER datasets, showing that FGN with LSTM-CRF as tagger achieves new state-of-the-art performance for Chinese NER. Further, more experiments are conducted to investigate the influences of various components and settings in FGN.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Named entity recognition (NER) is generally treated as sequence tagging problem and solved by statistical methods or neural networks. In the field of Chinese NER, researches generally adopt character-based tagging strategy to label named entities <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>. Some researches <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref> explicitly compared character-based methods and word-based methods for NER, confirming that character-based methods avoid the error from word segmentation stage and perform better. When using character-based methods for NER, the effect of character-level knowledge representation may greatly affect the performance of Chinese NER model. Currently, distributed representation learning has become the mainstream method to represent Chinese characters, especially after the raise of BERT <ref type="bibr" target="#b4">[5]</ref>, which raised the baselines for almost all fields of NLP. However, these methods overlooked the infor-mation inside words or characters like Chinese glyph. There have been studies, focusing on internal components of words or characters. In English field, researchers <ref type="bibr" target="#b5">[6]</ref> used Convolutional Neural Network (CNN) to encode the spelling of words for sequence tagging task. This method is not suitable for Chinese NER, as Chinese is not alphabetical language but hieroglyphic language. Chinese characters can be further segmented into radicals. For example, character "抓"(grasp) is constitutive of "扌"(hand) and "爪"(claw). Study on radical-based character embedding <ref type="bibr" target="#b6">[7]</ref> confirmed the effectiveness of these components in Chinese.</p><p>Further, researchers turned attention to regard Chinese characters as graphs for glyph encoding. Some researchers <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b24">25]</ref> tried running CNNs to capture glyph information in character graphs. However, these works just obtained neglectable improvement on trial. Avoiding the shortcomings of previous works, Meng et al. <ref type="bibr" target="#b1">[2]</ref> proposed a glyphbased BERT model called Glyce, which achieved SOTA performances in various NLP tasks including NER. They adopted Tianzige-CNN to encode seven historical and contemporary scripts of each Chinese character. Tianzige is a traditional form of Chinese calligraphy, which conforms the radical distribution inside a Chinese character. Then Transformer <ref type="bibr" target="#b9">[10]</ref> was used as sequence encoder in Glyce. Further, Sehanobish and Song <ref type="bibr" target="#b10">[11]</ref> proposed a glyph-based NER model called GlyNN, which encoded only Hei Ti font of each character to offer glyph information and used BiLSTM-CRF as sequence tagger. Moreover, representations of non-Chinese characters were taken into consideration carefully in GlyNN. Compared with Glyce, GlyNN with BERT achieved comparable performance in multiple NER datasets, using less glyph resource and smaller CNN. It proved that historical scripts are meaningless for NER to some extent. We suspect this is because the types and numbers of entities in modern Chinese are far more abundant and complex than the ones in ancient times.</p><p>The above works just encoded the glyph and distributed representation independently. They ignored the interactive knowledges between glyphs and contexts, which have been studied in the field of multimodal deep learning <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b13">14]</ref>. Moreover, as the meaning of Chinese character is not complete, we suspect that encoding each character glyph individually is not an appropriate approach. In fact, interactive knowledge between the glyphs of neighboring characters maybe benefit the NER task. For example, characters in tree names like "杨树"(aspen), "柏树"(cypress) and "松树"(pine tree) have the same radical "木"(wood), but characters of an algorithm name "决策树"(decision tree) have no such pattern. There are more similar patterns in Chinese language, which can be differentiated by interactive knowledge between neighboring glyphs. Therefore, we propose the FGN, Fusion Glyph Network for Chinese NER. The major innovations in FGN include: (1) a novel CNN structure called CGS-CNN, Character Graph Sequence CNN is offered for glyph encoding. CGS-CNN may capture potential information between the glyphs of neighboring characters. <ref type="bibr" target="#b1">(2)</ref> We provide a fusion method with out-of-sync sliding window and Slice-Attention to capture interactive knowledge between glyph representation and character representation.</p><p>FGN is found to improve the performance of NER, which outperforms other SOTA models on four NER datasets (Section 4.2). In addition, we verify and discuss the influence of various proposed settings in FGN (Section 4.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Our work is related to neural network for NER. Ronan et al. <ref type="bibr" target="#b14">[15]</ref> proposed the CNN- CRF model, which obtained competitive performance to various best statistical NER models. LSTM-CRF <ref type="bibr" target="#b15">[16]</ref> has been the mainstream component in subsequent NER models at present. To enhance word-level representation, Ma and Hovy <ref type="bibr" target="#b5">[6]</ref> proposed the LSTM-CNN-CRF structure for sequence labeling, which adopted CNNs to encode the spelling of each English word for semantic enhancement. Further, a coreference aware representation learning method <ref type="bibr" target="#b16">[17]</ref> was proposed, which was combined with LSTM-CNN-CRF for English NER. In Chinese field, Dong et al. <ref type="bibr" target="#b17">[18]</ref> organized radicals in each character as sequence and used LSTM network to capture the radical information for Chinese NER. Zhang et al. <ref type="bibr" target="#b18">[19]</ref> proposed a novel NER method called lattice-LSTM, which skillfully encoded Chinese characters as well as all potential words that match a lexicon. Drawing on Lattice-LSTM, Word-Character LSTM (WC-LSTM) <ref type="bibr" target="#b19">[20]</ref> was proposed, which added word information into the start and the end characters of a word to alleviate the influence of word segmentation errors. Our work is also related to some multimodal works. Currently, knowledge from vision has been widely-used in NLP. We simply divide these relative researches into two categories according to the source of vision knowledge: glyph representation learning and multimodal deep learning. The Former is scarce as mentioned earlier. We transform the input sentences to graph sequences for 3D encoding. To our knowledge, we are the first to encode character glyph in sentence-level by 3D convolution <ref type="bibr" target="#b20">[21]</ref>, which was mostly proposed to encode video information. The latter is current hotspot in various NLP fields. Zhang et al. <ref type="bibr" target="#b11">[12]</ref> proposed an adaptive co-attention network for tweets NER, which adaptively balanced the fusion proportions of image representation and text representation from a tweet. With reference of BERT, a multimodal BERT <ref type="bibr" target="#b12">[13]</ref> was proposed for target-oriented sentiment classification. Multiple self-attention layers <ref type="bibr" target="#b8">[9]</ref> were used in this model to capture interactive information after concatenating BERT and visual representation. Further, Mai et al. <ref type="bibr" target="#b13">[14]</ref> proposed a fusion network with local and global perspective for multimodal affective computing. They provided a sliding window to slice multimodal vectors and fused each slice pair by outer product function. And attentive Bi-directional Skip-connected LSTM was used to combine slice pairs. Our method borrows the ideas of above-mentioned methods for multimodal fusion. Different from their work that fused the sentence-level representation, we focus on character-level fusion for Chinese NER.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Model</head><p>In this section, we introduce the FGN in detail. As shown in <ref type="figure" target="#fig_0">Fig. 1</ref>, FGN can be divided into three stages: representation stage, fusion stage and tagging stage. We follow the strategy of character-based sequence tagging for Chinese NER.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Representation Stage</head><p>Here we discuss the representation learning for Chinese character including character representation from BERT and glyph representation form CGS-CNN. Detail of these representations are as followed.</p><p>BERT. BERT is a multi-layer Transformer encoder, which offers distributed representations for words or characters. We use the Chinese pre-trained BERT to encode each character in sentences. Different from the normal fine-tuning strategy, we first finetune BERT on training set with a CRF layer as tagger. Then freeze the BERT parameters and transfer them to FGN. experiment in Section 4.3 shows the effectiveness of this strategy.  <ref type="figure" target="#fig_1">Fig. 2</ref> depicts the architecture of CGS-CNN. We only choose the simple Chinese script to generate glyph vectors, as the past work <ref type="bibr" target="#b10">[11]</ref> showed that using only one Chinese script achieved comparative performance as well as seven scripts. The input format for CGS-CNN is character graph sequence. We first convert sentences to graph sequences, in which characters are replaced with 50×50 gray-scale graphs. Characters which are not Chinese may be given corresponding initialize matrices with parameters between 0 and 1. Then we provide two 3×3×3 3D convolution layers to encode graph sequence and output each 50×50 graph with 8 channels. 3D convolution can extract feature from both spatial and temporal dimensions, which means each glyph vector may obtain additional glyph information from the neighboring graphs. Using padding on the dimension of graph sequence, we may keep the length of graph sequence constant after passing through 3D convolution, which is necessary for character-based tagging. Then the output of 3D convolution may pass through several groups of 2D convolution and 2D max pooling to compress each graph to 2×2 Tianzige-structure with 64 channels. In order to filter noises and blank pixels, we flatten the 2×2 structures and adopt a 1D max pooling to extract glyph vector for each character. The size of glyph vectors is set to 64, which is much smaller than the size of Tianzige-CNN output (1024 dimension).</p><p>Different from Glyce that sets image classification task to learn glyph representation, we learn the parameters of CGS-CNN while training whole NER model in domain datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Fusion Stage</head><p>We provide a sliding window to slide through both BERT and glyph representations. In sliding window, each slice pair is computed by outer product to capture local interactive features. Then Slice-Attention is adopted to balance the importance of each slice pair and combine them to output fusion representation.</p><p>Out-of-sync Sliding Window. Sliding window has been applied in multimodal affective computing <ref type="bibr" target="#b13">[14]</ref> as mentioned above. The reason for using sliding windows is that directly fusing vectors with outer product would exponentially expand vector size, which increases space and time complexity for subsequent network. However, this method requires the multimodal representations to have the same size, which is not suitable to slide through both BERT vector and glyph vector. Because character representations of BERT have richer semantic information than glyph representations, requiring a bigger vector size. Here we provide an out-of-sync sliding window that can satisfy different vector sizes while keeping the same number of slices. Assume that we have one Chinese character with character vector defined as _ ∈ ℝ and glyph vector defined as _ ∈ ℝ . Here and stand for the sizes of two vectors. To keep the same number of the slices of these two vectors after passing through the sliding window, the setting of sliding window needs to meet the following limitation:</p><formula xml:id="formula_0">= − + 1 = − + 1, ∈ N *<label>(1)</label></formula><p>Where is a positive integer, standing for slice number of two vectors; and respectively stand for window size and stride of character vector. and respectively represent window size and stride for glyph vector. The strategy we use to satisfy this condition is to limit the hyper-parameters of sliding window such that , and are respectively an integral multiple of , and . To get slice pairs, we first calculate the left border index of sliding window at each stride:</p><formula xml:id="formula_1">∈ {1,2,3 ⋯ , }<label>(2)</label></formula><formula xml:id="formula_2">( ) = ( − 1)<label>(3)</label></formula><formula xml:id="formula_3">( ) = ( − 1)<label>(4)</label></formula><p>Where ( ) and ( ) represent the boundary index of sliding window respectively for character and glyph vector at the th stride. Then we can obtain each slice during the following formula:</p><formula xml:id="formula_4">_ ( ) = { _ ( ( ) +1) , _ ( ( ) +2) … , _ ( ( ) + ) } (5) _ ( ) = { _ ( ( ) +1) , _ ( ( ) +2) … , _ ( ( ) + ) }<label>(6)</label></formula><p>Where _ ( ) and _ ( ) represent the th slices respectively from two vectors; _ ( ( ) +1) stands for the value at ( ( ) + 1)th dimension of _ .</p><p>In order to fuse two slices in a local perspective, outer product is adopted to generate an interactive tensor, as shown in the formula:</p><formula xml:id="formula_5">= ( _ ( ), _ ( ) ) = [ _ ( ) +1 _ ( ) +1 , ⋯ _ ( ) +1 _ ( ) + ⋮ ⋱ ⋮ _ ( ) + _ ( ) +1 , ⋯ _ ( ) + _ ( ) + ]<label>(7)</label></formula><p>Where ∈ ℝ × stands for fusion tensor of the th slice pair;</p><formula xml:id="formula_6">_ ( ) +1 _ ( ) +1</formula><p>represent product result between the ( ) + 1th value in _ and the ( ) + 1th value in g_ . During outer product, we may obtain all product result among elements from two vectors. Then we flatten each tensor to vector ′ ∈ ℝ . Representation of slices for one character can be represented as:</p><formula xml:id="formula_7">′ ={ 1 ′ , 2 ′ , … −1 ′ , ′ }, ′ ∈ ℝ ×( )<label>(8)</label></formula><p>Where ′ contains fusion vectors of slice pairs. The size of each vector is .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Slice-Attention.</head><p>Outer product offers interactive information for character-level representation at the same time generates more noises, as many features are irrelevant. With reference to attention mechanism, we propose the Slice-Attention, which may adaptively quantify the importance of each slice pair and combined them to represent a character. Importance of slice pair can be quantified as:</p><formula xml:id="formula_8">= ( ( ) ( ′ + )) ∑ ( ( ) ( ′ + )) =1<label>(9)</label></formula><p>Where stands for importance value of the th slice pair; is Sigmoid function. Sigmoid function here may limit the value range in vectors between 0 and 1, which ensures subsequent dot product computing meaningful. ∈ ℝ ( )×( ) and ∈ ℝ stand for initialized weight and bias. ∈ ℝ ( ) imitates the query in self-attention <ref type="bibr" target="#b8">[9]</ref>, which is another initialized weight.</p><p>Finally, we fuse the vectors of slice pairs by weighted average computation and obtain fusion vector for a character:</p><formula xml:id="formula_9">_ = ∑ ′ =1 (10)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Tagging Stage</head><p>We concatenate each vector in character-level before tagging. The final representation of a sentence can be defined as = { 1 , 2 … , }, where stands for the length of sentence. Then BiLSTM is adopted as sequence encoder and CRF is adopted as decoder for named entity tagging.</p><p>BiLSTM. LSTM (Long Short Terms Memory) units contain three specially designed gates to control information transmission along a sequence. To encode sequence information of , we use a forward LSTM network to obtain forward hidden state and a backward LSTM network to obtain backward hidden state. Then the two hidden states are combined as:</p><formula xml:id="formula_10">ℎ = ⃗⃗⃗⃗⃗⃗⃗⃗⃗⃗⃗ ( ) + ⃖⃗⃗⃗⃗⃗⃗⃗⃗⃗⃗⃗ ( )<label>(11)</label></formula><p>Here ℎ = {ℎ 1 , ℎ 2 … , ℎ } is the hidden representation for characters. We sum the corresponding values between two hidden states to create the ℎ.</p><formula xml:id="formula_11">( | ) = (∑ ( ℎ + ( −1 , ) )) =1 ∑ (∑ ( ′ ℎ + ( −1 ′ , ′ ) ) =1 ) ′<label>(12)</label></formula><p>Where ′ represents a possible label sequence; represents the weight for ; and ( −1 , ) is the bias from −1 to .</p><p>After CRF decoding, we use first-order Viterbi algorithm to find the most probable label sequence for a sentence. Assume that there is a labeled set {( , )}| =1 , we minimize the below negative log-likelihood function to train the whole model:</p><formula xml:id="formula_12">= − ∑ ( ( | )) =1<label>(13)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>In Section 4.1 and Section 4.2, we introduce the situation of datasets we use and some setting of the follow-up experiments. The main experiment result can be found in Section 4.2, where we set a comparison of our model and various SOTA models. FGN we proposed are tested for 10 times in each dataset to compute the average Precision (P), Recall (R), F1-socre (F1). In Section 4.3, we test some main components in FGN and each component is also test for 10 times to compute the average metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Settings</head><p>Dataset. Four widely-used NER datasets are chosen for experiments, including Onto-Notes 4 <ref type="bibr" target="#b21">[22]</ref>, MSRA <ref type="bibr" target="#b22">[23]</ref>, Weibo <ref type="bibr" target="#b23">[24]</ref> and Resume <ref type="bibr" target="#b18">[19]</ref>. All of these Dataset is annotated with a BMES tagging scheme. Among them, OntoNotes 4 and MSRA are in news domain; Weibo is annotated from Sina Weibo, a social media in China. These three datasets only contain traditional name entities, such as location, personal name and organization. Resume was annotated from personal resumes with 8 types of named entities.</p><p>Hyper-Parameter Setting. We use dropout mechanism for both character representation and glyph representation. Dropout rate of CGS-CNN is set to 0.2 and the one of radical self-attention is set to 0.5. The hidden size of LSTM is set to 764 and the dropout rate of LSTM is set to 0.5. We used the Chinese BERT which was pre-trained by Google 2 . Following the default configuration, output vector size of each character is set to 764. Character graphs we used are collected from Xinhua Dictionaries 3 with the number of 8630. We covert these graphs to 50×50 gray-scale graph. As mentioned in Section 3.2, window size and stride in sliding window of character vector are respectively an integer multiple of the ones for glyph vectors. Thus, we set size and stride of the former to 96 and 8, and the later to 12 and 1 according to empirical study. Adam is adopted as optimizer for both BERT fine-tuning and NER model training. Learning rates for fine-tuning condition and training condition are different. The former one is set to 0.00001, and the latter one is set to 0.002. <ref type="table">Table 1</ref> and <ref type="table">Table 2</ref> show some detailed statistics of FGN, which is compared with other SOTA models on four NER datasets. Here FGN represents the proposed glyph model with LSTM-CRF as tagger; Lattice LSTM <ref type="bibr" target="#b18">[19]</ref> and WC-LSTM <ref type="bibr" target="#b19">[20]</ref> are the SOTA model without BERT, combining both word embedding and character embedding. BERT-LMCRF represent the BERT model with BiLSTM-CRF as NER tagger. Glyce <ref type="bibr" target="#b1">[2]</ref> is the SOTA BERT-based glyph network as mentioned earlier. GlyNN <ref type="bibr" target="#b10">[11]</ref> is another SOTA BERT-based glyph network. Especially, we select the average F1 of GlyNN for comparison as we also adopt the average F1 as metric. For other baselines, we select their result shown in trial, as they have not illustrated whether they used the average F1 or not.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Main Result</head><p>As can be seen, FGN outperforms other SOTA models in all four datasets. Compared with BERT-LMCRF, F1 of FGN obtains obvious boosts of 3.13%, 2.88%, 1.01% and 0.84% respectively on Weibo, OntoNote 4, MSRA and Resume. Further, FGN outperformed some SOTA glyph-based NER model like Glyce and GlyNN. However, FGN did not achieve significant improvement on Resume and MSRA dataset as BERT-LMCRF can already recognize most of the entities on these two datasets. In fact, the datasets Weibo and OntoNote4 are more difficult for NER, as the entity types and entity mentions are more diverse. For example, some interesting and extraordinary entity words in Weibo and OntoNote4 like "铼德" (company name) and "啊滋猫" (milk tea shop), which were successfully identified only by FGN. We guess the reason is because the character "铼" contain the radical "钅" which means "metal" and the character "滋" contains the radical "氵" which means "water". These radicals are related to the products of their companies. In fact, this phenomenon is common in various Chinese entities including company, personal name and location, which are deeply influenced by the naming culture of Chinese people. Combined the contextual information with the above glyph information, FGN may capture extra feature to recognize some extraordinary named entities in some cases. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Ablation Study</head><p>Here we discuss the influences of various settings and components in FGN. The comp- onents we investigate contain: CNN structure, named entity tagger and fusion method. Weibo dataset is used for these illustrations.</p><p>Effect of CNN structure. As shown in <ref type="table" target="#tab_3">Table 3</ref>, we investigate the performances of various CNN structures while keeping other settings of FGN unchanged. In this table, "2d" represents the CGS-CNN with no 3D convolution layer. "avg" represents that 1D max pooling in CGS-CNN is replaced by 1D average pooling. 2D CNN represents the CNN structure with only 2D convolution and 2D pooling layers. Tianzige-CNN is proposed from Glyce. As can be seen, the common 2D-CNN structure obtains the worse result, as it completely overlooks the information of Tianzige structure and neighbor character glyph. Comparing with Tianzige-CNN, using CGS-CNN introduces a boost of 0.66% in F1,as CGS-CNN may capture interactive information between the character glyph. Compared with 2D convolution, Using FGN with 3D convolution introduces a boost of 1.14% in F1, which confirmed the benefit from adjacent glyph information of phrases or words. Otherwise, max pooling works better than average pooling when capture feature in Tianzige structure. As mentioned earlier, max pooling here may filter some blank pixels and noises in character graphs. Effect of Named Entity Tagger. Some widely-used sequence taggers are chosen to replace BiLSTM-CRF in FGN for discussion. <ref type="table" target="#tab_4">Table 4</ref> shows the performances of various chosen taggers. As can be seen, methods that based on LSTM and CRF outperform Transformer <ref type="bibr" target="#b8">[9]</ref> encoder in NER task. In fact, Most of the SOTA NER methods <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b19">20]</ref> prefer to use BiLSTM rather than Transformer as their sequence encoder. Compared with only CRF, LSTM-CRF introduces a boost of 0.43% in F1. In addition, bidirectional LSTM introduces a further boost of 0.56% in F1. In this experiment, LSTM-CRF performed better than Transformer in NER task. Effect of Fusion Method. We investigate the performances of different setting in fusion stage as shown in <ref type="table" target="#tab_5">Table 5</ref>. In this table, "concat" represents concatenating glyph and BERT representation without any fusion; "no freeze" represents FGN with trainable BERT; "avg pool" and "max pool" represent that Slice-Attention in FGN is respectively replaced by pooling or max pooling. In addition, we reset the window size to <ref type="bibr">(196,</ref><ref type="bibr" target="#b15">16)</ref>, <ref type="bibr">(48,</ref><ref type="bibr" target="#b3">4)</ref> and the stride to <ref type="bibr" target="#b23">(24,</ref><ref type="bibr" target="#b1">2)</ref> in sliding window respectively for character and glyph representations to test the FGN. Compared to directly concatenating vectors from glyph and BERT, FGN introduces a boost of 0.82% in F1, which confirms the effectiveness of our fusion strategy. FGN with the strategy of fine-tuning and freezing BERT in different stages outperforms the FGN with a trainable BERT. We consider is because that fine-tuning BERT only requires minimal gradient values when updating the BERT parameters, but LSTM-CRF need to set a larger learning rate to adjusting the initialized parameter with suitable gradient values. Using Slice-Attention outperforms using average pooling or max pooling in FGN, as Slice-Attention adaptively balances information of each slices and pooling layer only filter information statically. Otherwise, sliding window with the setting in Section 4.1 slightly outperforms the ones with other hyper-parameter settings. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we proposed the FGN for Chinese NER. In FGN, a novel CNN structure called CGS-CNN was applied to capture both glyph information and interactive information between the neighboring graphs. Then a fusion method with out-of-sync sliding window and Slice-Attention were adopted to fuse the output representations from BERT and CGS-CNN, which may offer extra interactive information for NER tasks. Experiments are conducted on four NER datasets, showing that FGN with LSTM-CRF as tagger obtained SOTA performance on four datasets. Further, influences of various settings and components in FGN are discussed during ablation study.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Architecture of the FGN for named entity recognition.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Architecture of CGS-CNN with a input sample "我爱踢球" (I love playing football). "f", "k", "s", "p" stand for kernel number, kernel size, stride, and pooling window size. "g_s" represents the tensor size of output from each layer.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .Table 2 .</head><label>12</label><figDesc>Detailed statistics of FGN on Weibo and OntoNote 4 Detailed statistics of FGN on Resume and MSRA.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 .</head><label>3</label><figDesc>Performances of various CNN structures on Weibo dataset.</figDesc><table><row><cell>CNN-type</cell><cell>P</cell><cell>R</cell><cell>F1</cell></row><row><cell>CGS-CNN 2d</cell><cell>68.56</cell><cell>71.45</cell><cell>70.01</cell></row><row><cell>CGS-CNN avg</cell><cell>69.13</cell><cell>71.35</cell><cell>70.22</cell></row><row><cell>2D-CNN</cell><cell>67.75</cell><cell>72.45</cell><cell>69.93</cell></row><row><cell>Tianzige-CNN</cell><cell>70.94</cell><cell>70.24</cell><cell>70.59</cell></row><row><cell>CGS-CNN</cell><cell>69.02</cell><cell>73.65</cell><cell>71.25</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 .</head><label>4</label><figDesc>Performances of various taggers on Weibo dataset.</figDesc><table><row><cell>tagger-type</cell><cell>P</cell><cell>R</cell><cell>F1</cell></row><row><cell>CRF</cell><cell>7044</cell><cell>70.10</cell><cell>70.26</cell></row><row><cell>LSTM-CRF</cell><cell>70.77</cell><cell>70.60</cell><cell>70.69</cell></row><row><cell>BiLSTM-CRF</cell><cell>69.02</cell><cell>73.65</cell><cell>71.25</cell></row><row><cell>Transformer</cell><cell>72.14</cell><cell>66.08</cell><cell>68.98</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 .</head><label>5</label><figDesc>Performances of different fusion settings on Weibo dataset.</figDesc><table><row><cell>fusion-type</cell><cell>P</cell><cell>R</cell><cell>F1</cell></row><row><cell>concat</cell><cell>69.13</cell><cell>71.35</cell><cell>70.43</cell></row><row><cell>no freeze</cell><cell>66.92</cell><cell>74.87</cell><cell>70.67</cell></row><row><cell>avg pool</cell><cell>69.00</cell><cell>73.61</cell><cell>70.11</cell></row><row><cell>max pool</cell><cell>69.60</cell><cell>71.40</cell><cell>70.64</cell></row><row><cell>w(196, 16)</cell><cell>70.58</cell><cell>71.10</cell><cell>70.84</cell></row><row><cell>w(48, 4)</cell><cell>70.25</cell><cell>71.22</cell><cell>70.73</cell></row><row><cell>s(24, 2)</cell><cell>69.07</cell><cell>73.00</cell><cell>70.98</cell></row><row><cell>FGN</cell><cell>69.02</cell><cell>73.65</cell><cell>71.25</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://github.com/google-research/bert 3 http://zidian.aies.cn/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was supported by the National Natural Science Foundation of China(No. 61572145) and the Major Projects of Guangdong Education Department for Foundation Research and Applied Research (No. 2017KZDXM031). The authors would like to thank the anonymous reviewers for their valuable comments and suggestions.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Multi-prototype Chinese character embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dong-Hong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Language Resources and Evaluation</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Glyce:Glyph-vectors for Chinese Character Representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yuxian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2742" to="2753" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Comparison of the impact of word segmentation on name tagging for Chinese and Japanese</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Haibo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Masato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Language Resources and Evaluation</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2532" to="2536" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Chinese named entity recognition with a sequence labeling approach. based on characters, or based on words</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhangxun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Conghui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tiejun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advanced Intelligent Computing Theories and Applications</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="634" to="640" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jacob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ming-Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Kenton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kristina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">End-to-end Sequence Labeling via Bi-directional LSTM-CNNs-CRF</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Xuezhe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1064" to="1074" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Radical-Enhanced Chinese Character Embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yaming</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Duyu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Neural Information Processing</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="279" to="286" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Glyph-aware embedding of chinese characters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Falcon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cai</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Subword and Character Level Models in NLP</title>
		<meeting>the First Workshop on Subword and Character Level Models in NLP</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="64" to="69" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Character-based joint segmentation and pos tagging for chinese using bidirectional rnn-crf</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Christian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Jorg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Joakim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.01314</idno>
	</analytic>
	<monogr>
		<title level="j">Computer Science</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ashish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Noam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Niki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Using Chinese Glyphs for Named Entity Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Arijit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.09922</idno>
	</analytic>
	<monogr>
		<title level="j">Computer Science</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Adaptive Co-attention Network for Named Entity Recognition in Tweets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Jinlan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xiaoyu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xuanjing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5674" to="5681" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Adapting BERT for Target-Oriented Multimodal Sentiment Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jianfei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Joint Conference on Artificial Intelligence</title>
		<meeting>the International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5408" to="5414" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Divide, Conquer and Combine: Hierarchical Feature Fusion Network with Local and Global Perspectives for Multimodal Affective Computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sijie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Haifeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Songlong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annual Meeting of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="481" to="492" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Natural language processing (almost) from scratch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ronan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Jason</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Leon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2493" to="2537" />
			<date type="published" when="2011-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><forename type="middle">K</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1508.01991</idno>
	</analytic>
	<monogr>
		<title level="m">Bidirectional LSTM-CRF models for sequence tagging</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Coreference aware representation learning for neural named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zeyu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hongliang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Ping</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Joint Conference on Artificial Intelligence</title>
		<meeting>the International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4946" to="4953" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Character-Based LSTM-CRF with Radical-Level Features for Chinese Named Entity Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chuanhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Jiajun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chengqing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Natural Language Processing and Chinese Computing</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="239" to="250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Chinese NER Using Lattice LSTM</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1554" to="1564" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">An Encoding Strategy Based Word-Character LSTM for Chinese NER</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tongge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Qinghua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<meeting>Conference of the North American Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2379" to="2389" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shuiwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ming</surname></persName>
		</author>
		<title level="m">3D convolutional neural networks for human action recognition. IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="221" to="231" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ralph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sameer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Lance</surname></persName>
		</author>
		<title level="m">Ontonotes release 4.0. LDC2011T03</title>
		<meeting><address><addrLine>Philadelphia, Penn</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
	<note>Linguistic Data Consortium</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">L: The third international Chinese language processing bakeoff: Word segmentation and named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gina-Anne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth SIGHAN Workshop on Chinese Language Processing</title>
		<meeting>the Fifth SIGHAN Workshop on Chinese Language Processing</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="108" to="117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Named Entity Recognition for Chinese Social Media with Jointly Trained Embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Nanyun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Empirical Methods in Natural Language Processing</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="548" to="554" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Learning Chinese Word Representations From Glyphs Of Characters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Hungyi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.04755</idno>
	</analytic>
	<monogr>
		<title level="j">Computer Science</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
