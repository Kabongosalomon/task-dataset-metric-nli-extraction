<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Boosting on the shoulders of giants in quantum device calibration</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Wozniakowski</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Physical and Mathematical Sciences</orgName>
								<orgName type="institution">Nanyang Technological University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Complexity Institute</orgName>
								<orgName type="institution">Nanyang Technological University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jayne</forename><surname>Thompson</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Centre for Quantum Technologies</orgName>
								<orgName type="institution">National University of Singapore</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mile</forename><surname>Gu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Physical and Mathematical Sciences</orgName>
								<orgName type="institution">Nanyang Technological University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Complexity Institute</orgName>
								<orgName type="institution">Nanyang Technological University</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Centre for Quantum Technologies</orgName>
								<orgName type="institution">National University of Singapore</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Binder</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Institute for Quantum Optics and Quantum Information -IQOQI Vienna</orgName>
								<orgName type="institution">Austrian Academy of Sciences</orgName>
								<address>
									<addrLine>Boltzmanngasse 3</addrLine>
									<postCode>1090</postCode>
									<settlement>Vienna</settlement>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Boosting on the shoulders of giants in quantum device calibration</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note type="submission">(Dated: May 14, 2020)</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T22:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Multi-target Regression</term>
					<term>Machine Learning</term>
					<term>Quantum Computing</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Traditional machine learning applications, such as optical character recognition, arose from the inability to explicitly program a computer to perform a routine task. In this context, learning algorithms usually derive a model exclusively from the evidence present in a massive dataset. Yet in some scientific disciplines, obtaining an abundance of data is an impractical luxury, however; there is an explicit model of the domain based upon previous scientific discoveries. Here we introduce a new approach to machine learning that is able to leverage prior scientific discoveries in order to improve generalizability over a scientific model. We show its efficacy in predicting the entire energy spectrum of a Hamiltonian on a superconducting quantum device, a key task in present quantum computer calibration. Our accuracy surpasses the current state-of-the-art by over 20%. Our approach thus demonstrates how artificial intelligence can be further enhanced by "standing on the shoulders of giants."</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Prediction is paramount in almost every branch of science. In studying and designing learning systems, we are interested in prediction performance on examples unencountered during training. As machines learn inductively, generalizing training examples into an accurate model requires some restriction on the search space of hypotheses, based upon prior knowledge <ref type="bibr">[1]</ref><ref type="bibr">[2]</ref><ref type="bibr">[3]</ref><ref type="bibr">[4]</ref>. The choice of hypothesis space constitutes the problem of inductive bias <ref type="bibr">[2]</ref><ref type="bibr">[3]</ref><ref type="bibr">[4]</ref><ref type="bibr" target="#b1">[5]</ref><ref type="bibr" target="#b2">[6]</ref>, which is of broad significance in scientific applications.</p><p>Some scientific applications, such as quantum experiments, provide a paucity of data due to experimental cost, but compensate with an explicit model based upon previous discoveries <ref type="bibr" target="#b3">[7]</ref><ref type="bibr" target="#b4">[8]</ref><ref type="bibr" target="#b5">[9]</ref><ref type="bibr" target="#b6">[10]</ref><ref type="bibr" target="#b7">[11]</ref>. In prior work, this prior knowledge has been disregarded, and research has focused on entirely data-driven approaches that reproduce major scientific achievements or learn from toy data <ref type="bibr" target="#b8">[12]</ref><ref type="bibr" target="#b9">[13]</ref><ref type="bibr" target="#b10">[14]</ref><ref type="bibr" target="#b11">[15]</ref><ref type="bibr" target="#b12">[16]</ref><ref type="bibr" target="#b13">[17]</ref><ref type="bibr" target="#b14">[18]</ref><ref type="bibr" target="#b15">[19]</ref>. This leads us to ask if a machine learner can leverage prior scientific knowledge in order to outperform contemporary researchers? Particularly in scenarios with a shortage of experimental data.</p><p>Here, we introduce a new framework that restricts a learning algorithm's search space of hypotheses. It does so by leveraging prior knowledge contained in predictions generated by a scientific model (see <ref type="figure">Fig. 1</ref>). In contrast to conventional supervised learning, we focus on the simultaneous prediction of multiple real variables, which is known as multi-target regression <ref type="bibr" target="#b1">[5,</ref><ref type="bibr" target="#b16">[20]</ref><ref type="bibr" target="#b17">[21]</ref><ref type="bibr" target="#b18">[22]</ref>. This enables the learning algorithm to improve generalizability over the scientific model by discovering relationships among the targets, which the model did not envisage. In prin-ciple, this approach shares similarities with neuroplasticity, whereby the nervous system is able to adapt and optimize its limited resources in response to sensory experiences <ref type="bibr" target="#b19">[23]</ref>.</p><p>To test our learning system, we establish a proxy of expert human-level performance on the calibration benchmark task of simultaneously predicting the entire energy spectrum of a Hamiltonian on a superconducting quantum device <ref type="bibr" target="#b4">[8,</ref><ref type="bibr" target="#b6">10,</ref><ref type="bibr" target="#b7">11,</ref><ref type="bibr" target="#b20">24]</ref>. In this scenario, there is a shortage of data due to operational cost of the experiment <ref type="bibr" target="#b4">[8]</ref>. The explicit scientific model of the device's quantum behavior is state-of-the-art <ref type="bibr" target="#b4">[8,</ref><ref type="bibr" target="#b6">10,</ref><ref type="bibr" target="#b7">11]</ref>. We demonstrate that our learning system surpasses this baseline of expert human-level performance by over 20% (see <ref type="figure">Fig. 2</ref>). Consequently, we advance the current ability to precisely generate Hamiltonians with programmable parameters for a variety of quantum simulation applications. Our result complements other recent applications of machine learning in scientific settings, and more specifically quantum systems <ref type="bibr" target="#b3">[7,</ref><ref type="bibr" target="#b5">9,</ref><ref type="bibr" target="#b8">[12]</ref><ref type="bibr" target="#b9">[13]</ref><ref type="bibr" target="#b10">[14]</ref><ref type="bibr" target="#b11">[15]</ref><ref type="bibr" target="#b12">[16]</ref><ref type="bibr" target="#b13">[17]</ref><ref type="bibr" target="#b14">[18]</ref><ref type="bibr" target="#b15">[19]</ref><ref type="bibr" target="#b21">[25]</ref><ref type="bibr" target="#b22">[26]</ref><ref type="bibr" target="#b23">[27]</ref><ref type="bibr" target="#b24">[28]</ref><ref type="bibr" target="#b25">[29]</ref><ref type="bibr" target="#b26">[30]</ref><ref type="bibr" target="#b27">[31]</ref>. To interpret our results we use techniques from explainable machine learning <ref type="bibr" target="#b28">[32,</ref><ref type="bibr" target="#b29">33]</ref> to uncover parameter dependencies in the original scientific model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Benchmark task -In order to establish a proxy of expert human-level performance for the analysis of our learning system, we study a superconducting qubit architecture <ref type="bibr" target="#b20">[24]</ref>. The quantum device is a nearest-neighbor coupled linear chain of superconducting qubits with tunable qubit frequencies and tunable inter-qubit interactions <ref type="bibr" target="#b4">[8,</ref><ref type="bibr" target="#b6">10,</ref><ref type="bibr" target="#b7">11,</ref><ref type="bibr" target="#b20">24]</ref>. Each qubit is embedded in the subspace spanned by the ground state and first excited state of a nonlinear photonic resonator in the microwave Given a base regressor's initial multi-target predictions and the multi-target observations, we wrangle this data for multitarget supervised learning <ref type="bibr" target="#b16">[20,</ref><ref type="bibr" target="#b17">21]</ref>. Next, the boosting algorithm receives the training examples and acquires an inductive bias from the initial predictions. This compensates for a shortage of training examples, and the boosting algorithm improves generalizability over the base regressor. Given a new example, the boosting algorithm's returned regressor predicts a real vector.</p><p>FIG. 2: Benchmark task. Using the learning framework in <ref type="figure">Fig. 1, our</ref> learning system surpasses the state-of-the-art <ref type="bibr" target="#b4">[8,</ref><ref type="bibr" target="#b6">10,</ref><ref type="bibr" target="#b7">11]</ref> by over 20% on the calibration task of simultaneously predicting the entire energy spectrum of a Hamiltonian Eq. 1 on a nearest-neighbor coupled linear chain of superconducting qubits. Moreover, our learning system outperforms the stateof-the-art on each individual prediction task, i.e., Yj, where j ∈ {1, 2, . . . , 5}.</p><p>regime. The total Hamiltonian of the device is approximately described by the Bose-Hubbard model truncated at two local excitations</p><formula xml:id="formula_0">H = n j=1 δ jâ † jâ j + L 2â † jâ j (â † jâ j − 1) + n−1 j=1 g j,j+1 (â † jâ j+1 +â jâ † j+1 ),<label>(1)</label></formula><p>where n &gt; 1 is the number of qubits,â † (â) is the bosonic creation (annihilation) operator, δ j is the random on-site detuning, L is the on-site Hubbard interaction, and g j,j+1 is the hopping rate between nearest neighbor lattice sites. Quantum evolution is typically realized by allowing the entire system to interact at once, which also admits translation into the prototypical quantum circuit model <ref type="bibr" target="#b6">[10]</ref>.</p><p>In the benchmark task, the device contains 9 qubits. The n = 5 rightmost qubits and 4 interleaving couplers were utilized during experimentation, while the 4 leftmost qubits and couplers were left idle. The device is being calibrated for a many-body localization experiment <ref type="bibr" target="#b4">[8,</ref><ref type="bibr" target="#b7">11]</ref>, where different relaxation dynamics are observed, depending on the extent of random disorder in the system. Probing this quantum phenomenon requires study of the entire energy spectrum, which be achieved experimentally through many-body Ramsey spectroscopy <ref type="bibr" target="#b4">[8]</ref>.</p><p>Here, we focus on the identification of 5 eigenenergies belonging to Eq. 1, when it describes hopping of a single photon in a disordered potential. The energy eigenstates are generally not local and each instance of the manybody Ramsey spectroscopy technique sorts the measured eigenenergies in ascending order: Y 1 , Y 2 , . . . , Y 5 . In the present context of machine learning, we refer to these variables as single-targets and to their collection as a multi-target (details in Methods).</p><p>The calibration is performed in two steps <ref type="bibr" target="#b4">[8,</ref><ref type="bibr" target="#b6">10,</ref><ref type="bibr" target="#b7">11]</ref>, where the benchmark dataset pertains to the second step. In the first step, the room temperature time-dependent pulses that orchestrate the computation are calibrated to arrive at the device: orthogonally, synchronously, and without pulse-distortion <ref type="bibr" target="#b6">[10]</ref>. In the second step, the control pulses are converted to matrix elements of the Hamiltonian Eq. 1. Underlying this conversion is a finitely parameterized model of the device's electronic circuitry, which is directly encoded in the classical control program <ref type="bibr" target="#b4">[8,</ref><ref type="bibr" target="#b6">10,</ref><ref type="bibr" target="#b7">11]</ref>.</p><p>Inferring the physical parameters of the control model entails fitting the two lowest transition energies of each qubit as a function of qubit and coupler flux-biases <ref type="bibr" target="#b6">[10]</ref>. Next, the many-body Ramsey spectroscopy technique benchmarks the collective dynamics of the device, where all of the qubits are coupled and near resonance with each other <ref type="bibr" target="#b4">[8,</ref><ref type="bibr" target="#b7">11]</ref>. Then, minimization of the absolute error loss function, which compares the multi-targets with the multi-target predictions generated by the classical control program, numerically optimizes the physical parameters (see Eq. 5 in Methods). Lastly, the updated classical control program generates 136 multi-target predictions for the 136 multi-targets in the benchmark task. Using 41 of these multi-targets and the corresponding predictions, we compute the mean absolute errors for the single-targets and the average mean absolute error for the multi-targets (see Eq. 8 and Eq. 9 in Methods). We refer to the 1. <ref type="bibr" target="#b30">34</ref> MHz average mean absolute error as the benchmark error in <ref type="figure">Fig. 2</ref>. Using this benchmark error, we establish a proxy of expert human-level performance on the bench-mark task. As the estimated optimal error rate, set by the coherence time of the device, is 1MHz <ref type="bibr" target="#b4">[8]</ref>, we ask the algorithm design question: can we do better?</p><p>Using the classical control program, this would require us to directly write the higher order terms in the Hamiltonian, environmental interactions, manufacturing or operational errors, etc., for every recalibration. Clearly this strategy is impractical within recalibration timescales <ref type="bibr" target="#b30">[34,</ref><ref type="bibr" target="#b31">35]</ref>. Therefore, we propose a paradigm shift, whereby we incorporate the prior knowledge in the classical control program into a boosting algorithm whose primary goal is to discover a more accurate model of the domain (see <ref type="figure">Fig. 2</ref>). In this way, we can feedback improved multi-target predictions to the optimization step in the calibration process and update the physical parameters in the control model <ref type="bibr" target="#b6">[10]</ref>. Thus, enhancing the ability to generate Hamiltonians with programmable parameters for a variety of quantum simulation applications.</p><p>Learning Framework -Multi-target regression aims to simultaneously predict multiple real variables, and research in this direction is intensifying <ref type="bibr" target="#b16">[20,</ref><ref type="bibr" target="#b17">21]</ref>. Here, we introduce a two-step stacking <ref type="bibr" target="#b16">[20,</ref><ref type="bibr" target="#b17">21,</ref><ref type="bibr" target="#b32">[36]</ref><ref type="bibr" target="#b33">[37]</ref><ref type="bibr" target="#b34">[38]</ref> framework that supplies a boosting algorithm with an inductive bias contained in the initial multi-target predictions generated by a base regressor (details in Methods). In essence, the base regressor acts as data preprocessor and the boosting algorithm assays to improve generalization performance by discovering relationships among the single-targets. This approach is related to multi-target regularization, which reduces the problem of overfitting <ref type="bibr" target="#b16">[20,</ref><ref type="bibr" target="#b17">21,</ref><ref type="bibr" target="#b34">38]</ref>, as well as methods in deep learning, such as pre-training <ref type="bibr" target="#b35">[39]</ref> and weight sharing <ref type="bibr" target="#b1">[5]</ref>.</p><p>In applying the learning framework to the benchmark dataset, the first step wrangles the data for multi-target supervised learning <ref type="bibr" target="#b16">[20,</ref><ref type="bibr" target="#b17">21]</ref>. Namely, we regard a multitarget prediction generated by the classical control program <ref type="bibr" target="#b4">[8,</ref><ref type="bibr" target="#b6">10,</ref><ref type="bibr" target="#b7">11]</ref> as an example and the associated instance of the many-body Ramsey spectroscopy technique <ref type="bibr" target="#b4">[8]</ref> as the label. Under the distribution-free setting <ref type="bibr" target="#b36">[40]</ref><ref type="bibr" target="#b37">[41]</ref><ref type="bibr" target="#b38">[42]</ref><ref type="bibr" target="#b39">[43]</ref><ref type="bibr" target="#b40">[44]</ref><ref type="bibr" target="#b41">[45]</ref>, we split the labeled examples into m train = 95 and m test = 41 ordered pairs for training and test data, respectively, where the choice of splitting fraction is a heuristic <ref type="bibr" target="#b41">[45,</ref><ref type="bibr" target="#b42">46]</ref>. In the second step, a boosting algorithm receives the training examples with pairwise correlations shown in <ref type="figure" target="#fig_1">Fig. 3</ref>, and we request a multi-target regressorĥ as output. The boosting algorithm proceeds by reducing the multi-target regression task to 5 independent single-target regression subtasks <ref type="bibr" target="#b16">[20,</ref><ref type="bibr" target="#b17">21]</ref>. For the jth single-target regression subtask, the jth singletarget boosting algorithm induces the single-target regressorĥ j on the jth slice of the training examples, where j = {1, 2, . . . , 5} (see Eq. 11 in Methods). Subsequently, the boosting algorithm concatenates the single-target regressors into a multi-target regressor. Given a new example X, the multi-target regressor predicts a 5-dimensional real vectorŶ =ĥ(X).</p><p>Gradient boosting prior knowledge -Boosting We denote the features in each example by Xj, and the singletargets in each multi-target by Yj, where j ∈ {1, 2, . . . , 5} is the number of superconducting qubits utilized in the benchmark task <ref type="bibr" target="#b4">[8,</ref><ref type="bibr" target="#b6">10,</ref><ref type="bibr" target="#b7">11]</ref>.</p><p>is an algorithmic paradigm for improving the performance of any given learning algorithm, interconnecting machine learning <ref type="bibr" target="#b43">[47]</ref><ref type="bibr" target="#b44">[48]</ref><ref type="bibr">[49]</ref><ref type="bibr">[50]</ref><ref type="bibr">[51]</ref><ref type="bibr">[52]</ref><ref type="bibr">[53]</ref><ref type="bibr">[54]</ref><ref type="bibr">[55]</ref><ref type="bibr">[56]</ref><ref type="bibr">[57]</ref><ref type="bibr">[58]</ref>, statistics <ref type="bibr" target="#b39">[43]</ref><ref type="bibr" target="#b40">[44]</ref><ref type="bibr" target="#b41">[45]</ref><ref type="bibr">59</ref>, 60] and signal processing [61-63] through the study of additive expansions <ref type="bibr" target="#b39">[43,</ref><ref type="bibr" target="#b41">45,</ref><ref type="bibr">49,</ref><ref type="bibr">60]</ref>. Gradient boosting is a generic version of boosting, which is widely used in practice <ref type="bibr">[43-45, 57, 58, 64]</ref>, and the additive expansion is designed to finesse the curse of dimensionality and provide flexibility over linear models <ref type="bibr">[43-45, 49, 60]</ref>. Nonetheless, the standard form of gradient boosting does not allow for the direct incorporation of prior knowledge, which is essential in the benchmark task.</p><p>Here, we propose a modification of the standard additive expansion <ref type="bibr">[43-45, 57, 58, 64]</ref> for the jth single-target regression subtask</p><formula xml:id="formula_1">h j (X; {α j , θ j }) = X j + Kj k=1 α j,k b(X; θ j,k )),<label>(2)</label></formula><p>where the collection of expansion coefficients α j,k and parameter sets θ j,k is given by {α j , θ j } = {α j,1 , . . . , α j,Kj , θ j,1 , . . . , θ j,Kj }, and K j denotes the number of real-valued basis functions b(X; θ j,k ) of the example X (details in Methods). In the standard additive expansion, the first term is a constant offset value that does not depend upon the example, and it is usually determined by maximum likelihood estimation <ref type="bibr">[43-45, 49, 60]</ref>. In the work of Schapire et al, prior knowledge was incorporated into the Gödel prize winning AdaBoost algorithm by modifying the loss function for single-target classification tasks <ref type="bibr">[56]</ref>. In machine learning, the basis function is called a weak learner <ref type="bibr" target="#b44">[48,</ref><ref type="bibr">[50]</ref><ref type="bibr">[51]</ref><ref type="bibr">[52]</ref><ref type="bibr">[53]</ref><ref type="bibr">[54]</ref><ref type="bibr">56]</ref>, and the predominant choice is a shallow decision tree <ref type="bibr">[43-45, 57, 58, 64]</ref>. Taking a reroughing viewpoint [59], Eq. 2 decomposes the jth single-target into a smooth term, i.e., the first term, and a noise term, i.e., the linear sum of basis functions. In the application, the classical control program <ref type="bibr" target="#b4">[8,</ref><ref type="bibr" target="#b6">10,</ref><ref type="bibr" target="#b7">11]</ref> generates the smooth term and the noise term adaptively models the relationships between the single-targets in <ref type="figure" target="#fig_1">Fig. 3</ref> without overwhelming the prior knowledge (see Supplementary Information). In practice, fitting an additive expansion by minimizing the data-based estimate of the jth single-target expected loss is usually infeasible <ref type="bibr" target="#b39">[43]</ref><ref type="bibr" target="#b40">[44]</ref><ref type="bibr" target="#b41">[45]</ref><ref type="bibr">60</ref>-63] (see Eq. 6 in Methods). Here, we employ a greedy stagewise algorithm to approximate this optimization problem, whereby the stagewise algorithm sequentially appends basis functions to the additive expansion without adjusting the previously learned expansion coefficients or parameter sets, as opposed to a stepwise algorithm <ref type="bibr" target="#b39">[43]</ref><ref type="bibr" target="#b40">[44]</ref><ref type="bibr" target="#b41">[45]</ref><ref type="bibr">60</ref>-63] (see Alg. 1 in Methods). As a result of modifying the standard additive expansion in Eq. 2, the learning framework directly incorporates prior knowledge into gradient boosting <ref type="bibr">[43-45, 57, 58, 64]</ref> by changing the initialization step (details in Methods). As an aside, this idea can be applied in compressed sensing by similarly changing the initialization step in matching pursuit and its extensions <ref type="bibr">[61]</ref><ref type="bibr">[62]</ref><ref type="bibr">[63]</ref>.</p><p>Inbuilt model selection -The greedy stagewise algorithm does not always improve performance over the smooth term. Hence, we introduce an augmented version with inbuilt model selection, which scores the incumbent smooth term and the candidate greedy stagewise algorithm with a modification of k-fold cross-validation (details in Methods). If the incumbent performs better or equally well, then the augmented version returns the smooth term as the induced single-target regressor. Otherwise, the augmented version calls the candidate (see Alg. 2 in Methods).</p><p>In <ref type="figure" target="#fig_2">Fig. 4</ref>, we illustrate the model selection step with an augmented learning curve for the single-target regression subtask Y 3 with training sizes varying between 23 to 95 ordered pairs. Here, the augmented learning curve shows the incumbent error (red) in addition to the training and cross-validation errors (blue and yellow) shown in a prototypical learning curve <ref type="bibr" target="#b18">[22,</ref><ref type="bibr" target="#b41">45,</ref><ref type="bibr" target="#b42">46]</ref>. The incumbent error bounds the cross-validation error from above. As the training size increases, the training error tends to increase, the cross-validation error tends to decrease, and both errors exhibit random fluctuations, which typically occur with less than 100 ordered pairs <ref type="bibr" target="#b42">[46]</ref>. When there are less than 51 ordered pairs, the incumbent usually performs better, whereas the candidate always outperforms the incumbent with 51, or more, ordered pairs.</p><p>For the single-target regression subtasks Y 1 , Y 2 , and Y 5 , the candidate always performs better, and in general the candidate always performs better with 60, or more, ordered pairs (see <ref type="figure">Supplementary Information)</ref>. Thus, the boosting algorithm used the greedy stagewise algorithm in each single-target regression subtask in <ref type="figure">Fig. 2</ref>, where the boosting algorithm outperforms the baseline of expert human-level performance <ref type="bibr" target="#b4">[8,</ref><ref type="bibr" target="#b6">10,</ref><ref type="bibr" target="#b7">11]</ref> by over 20%.</p><p>Examining the prior knowledge -Data preprocessing can significantly impact generalization perfor- We show the training, cross-validation, and incumbent errors for varying amounts of training examples in blue, orange, and red, respectively. As a consequence of the inbuilt model selection step, the cross-validation error is bounded from above by 0.87 MHz. With 51, or more, ordered pairs the candidate greedy stagewise algorithm always outperforms the incumbent smooth term <ref type="bibr" target="#b4">[8,</ref><ref type="bibr" target="#b6">10,</ref><ref type="bibr" target="#b7">11]</ref>. mance, especially if there is a shortage of training examples <ref type="bibr" target="#b18">[22,</ref><ref type="bibr" target="#b35">39]</ref>. Here, we examine the classical control program <ref type="bibr" target="#b4">[8,</ref><ref type="bibr" target="#b6">10,</ref><ref type="bibr" target="#b7">11]</ref> as a data preprocessor for the downstream boosting algorithm, whereby the classical control program transforms 5 qubit and 4 coupler bias features from an instance of the spectroscopy protocol <ref type="bibr" target="#b4">[8]</ref> into an initial multi-target prediction (see Supplementary Information). Namely, we regard a collection of 5 qubit and 4 coupler bias features as an example, and we induce a fully-connected neural network <ref type="bibr" target="#b18">[22]</ref> for each single-target. Next, we apply the SHAP framework to approximate each induced neural network with a simpler linear explanation model <ref type="bibr" target="#b28">[32]</ref> (see Eq. 12 in Methods). The linear coefficients, known as SHAP values, allocate the importance of each feature for each single-target training data prediction <ref type="bibr" target="#b28">[32,</ref><ref type="bibr" target="#b29">33]</ref>.</p><p>In <ref type="figure">Fig. 5</ref>, we acquire an overview of each feature's importance and effect in the single-target regression subtask Y 1 <ref type="bibr" target="#b28">[32,</ref><ref type="bibr" target="#b29">33]</ref> (see Eq. 13 in Methods; see Supplementary Information for additional SHAP summary plots). The features are ascendingly ordered from bottom to top according to their importance, a point represents a SHAP value, and the coloring represents the bias value, e.g., a reddish point for the coupler 5/6 bias feature illustrates strong coupling at the coupler between the 5th and 6th qubit sites. As can be clearly seen in <ref type="figure">Fig. 5</ref>, the qubit 8 bias is the most important feature, which corresponds to an interior qubit site near the physical boundary of the linear chain. The coupler 5/6 bias is the only coupler bias in the top 4 features.</p><p>In comparison, the coupler 5/6 bias is the most important feature in the single-target regression subtasks Y 3 and Y 4 , and the coupler 8/9 bias is the most important feature in the single-target regression subtasks Y 2 and Y 5 (see Supplementary Information). The former FIG. 5: SHAP summary plot <ref type="bibr" target="#b28">[32]</ref> for the single-target Y1. Using the collection of 9 qubit and coupler bias features as an example, we induce a fully connected neural network <ref type="bibr" target="#b18">[22]</ref> to predict Y1. The horizontal axis is centered at the average training example prediction, and the vertical axis ascendingly orders the features according to their importance. Each point is a SHAP value for a particular example, the coloring represents the bias value, and overlapping points are randomly jittered along the vertical axis to avoid collisions <ref type="bibr" target="#b28">[32,</ref><ref type="bibr" target="#b29">33]</ref>.</p><p>feature corresponds to a coupler near the experimentally imposed boundary of the linear chain, and the latter feature corresponds to a coupler near the physical boundary of the linear chain. Whereas the qubit biases, which correspond to interior qubit sites, are 3 out of the 4 most important features in the single-target regression subtask Y 1 , the only other single-target regression subtask with a qubit bias in the top 4 features is Y 2 .</p><p>This feature dependence merits some discussion. As each instance of the spectroscopy protocol <ref type="bibr" target="#b4">[8]</ref> ascendingly orders the eigenenergies, one might expect that on average over all runs the feature dependence would be qualitatively the same for each single-target. Indeed, under independent and identically distributed sampling of the input parameters we would expect the data to exhibit a symmetry under permutation among the local bias and coupling parameters in Eq. 1. In line with this intuition, we observe a noticeably marked dependence on the coupler bias features closest to the physical boundaries for all single-targets. However, more generally, the permutation symmetry is broken in the benchmark dataset, not least because the model consists of few sites and is patently not well approximated by closed boundary conditions. Some of the individual single-targets, for instance, have a stronger dependence on specific on-site biases than others. This suggest that different sites correlate more strongly with larger or smaller eigenenergies. An example is the aforementioned strong dependence of the most negative eigenenergy Y 1 on the on-site bias at site 8. We attribute this to the geometry of the physical configuration and note that this asymmetric feature dependence is already present in the initial multi-target predictions generated by the data preprocessor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>While entirely data-driven approaches are successful in machine learning applications with an abundance of data, these machine learning methods break down in scenarios with a shortage of data. Overcoming this obstacle requires some resource that compensates for the lack of data [56]. In quantum device calibration applications, data accumulation is low <ref type="bibr" target="#b4">[8]</ref>, but there is an analytical model of the domain based upon prior scientific discoveries. Our result demonstrates that a machine learner can refine and enhance such discoveries with a minuscule amount of real experimental data. Using this approach, our learning system surpassed its scientific contemporaries <ref type="bibr" target="#b4">[8,</ref><ref type="bibr" target="#b6">10,</ref><ref type="bibr" target="#b7">11]</ref> by over 20% on the superconducting quantum device calibration task, thereby providing a pathway for the successful interface of artificial intelligence and physics. Moreover, we have demonstrated the robustness of our approach by incorporating inbuilt model selection and we have established a diagnostic method to examine the underlying scientific model with SHAP learning techniques <ref type="bibr" target="#b28">[32,</ref><ref type="bibr" target="#b29">33]</ref>.</p><p>Although we have focused on a quantum device calibration application, the presented machine learning approach can have significant impact further afield. We have introduced an additive expansion in Eq. 2 that is a modification of a model at the heart of several function approximation methods in engineering <ref type="bibr" target="#b43">[47]</ref>, machine learning <ref type="bibr">[47, 50, 52-55, 57, 58]</ref>, statistics <ref type="bibr">[43-45, 49, 59</ref>, 60] and signal processing [61-63]. Gradient boosting is one of the most popular learning algorithms in data science and machine learning competitions <ref type="bibr">[57,</ref><ref type="bibr">58]</ref>, and also in real-world production pipelines [64]. Our approach enables it to take advantage of prior knowledge, especially when data is scarce. Other potential applications include compressed sensing, where prior knowledge about sparsity has resulted in an advantage over the Nyquist-Shannon sampling theorem [61-63]. Indeed, physical manifestations of Occam's razor, symmetry and complexity have already significantly influenced the development of learning and prediction <ref type="bibr" target="#b22">[26,</ref><ref type="bibr" target="#b27">31,</ref><ref type="bibr">65</ref>, 66] -and thus a systematic approach to incorporating prior scientific knowledge into a machine learner provides a natural advancement of the mutualistic relationship between human researchers and artificial intelligence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We are grateful to Benjamin Chiaro, who ran the experiment, collected the data, and shared it with us during his time as a graduate student at UC Santa Barbara, and to Pedram Roushan for helpful discussions. This work is supported by the Singapore Ministry of Education Tier 1 grant RG162/19, Singapore National Research Foundation Fellowship NRF-NRFF2016-02 and NRF-ANR grant NRF2017-NRF-ANR004 VanQuTe, and the FQXi large grants: the role of quantum effects in simplifying adaptive agents and are quantum agents more energetically efficient at making predictions? A.W. was partially supported by the Grant TRT 0159 on mathematical picture language from the Templeton Religion Trust and thanks the Academy of Mathematics and Systems Science (AMSS) of the Chinese Academy of Sciences for their hospitality, where part of this work was done. F.C.B. acknowledges funding from the European Unions Horizon 2020 research and innovation programme under the Marie Skodowska-Curie Grant Agreement No. 801110 and the Austrian Federal Ministry of Education, Science and Research (BMBWF).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head><p>Multi-target regression background -In the setting of our learning framework, let X be the domain, where we refer to points in X as examples. Let Y ⊆ R n be the target space of multi-target observations, where we refer to vectors in Y as multi-targets and to components of vectors as single-targets. We refer to an ordered pair in the product of the domain and the target space (X, Y ) ∈ X × Y as a labeled example. Moreover, we are given a finite sequence of labeled examples</p><formula xml:id="formula_2">S = {(X (i) , Y (i) )} m i=1 ∈ (X × Y) m ,<label>(3)</label></formula><p>which is supposed random so that there is an unknown probability distribution on X × Y <ref type="bibr" target="#b36">[40]</ref><ref type="bibr" target="#b37">[41]</ref><ref type="bibr" target="#b38">[42]</ref>. We wish to find some simple pattern in the labeled examples, namely a multi-target regressor h : X → Y. However, there may be no functional relationship between the domain and the target space in this agnostic setting <ref type="bibr" target="#b37">[41,</ref><ref type="bibr" target="#b38">42]</ref>. In order to measure the predictive prowess of a multi-target regressor, we introduce the decision theoretic concept of a loss function <ref type="bibr" target="#b36">[40]</ref><ref type="bibr" target="#b37">[41]</ref><ref type="bibr" target="#b38">[42]</ref><ref type="bibr" target="#b39">[43]</ref><ref type="bibr" target="#b40">[44]</ref><ref type="bibr" target="#b41">[45]</ref>, where we denote a non-negative multi-target loss function by : Y × Y → R ≥0 . Given a labeled example (X, Y ) ∈ X × Y, the loss of some multi-target regressor h on the labeled example is denoted by (Y, h(X)). The multi-target loss function measures the magnitude of error in predicting h(X), when the multi-target is Y.</p><p>Here, we study loss functions that are decomposable over the targets, which provides a joint target view <ref type="bibr" target="#b16">[20,</ref><ref type="bibr" target="#b17">21]</ref>. Let Y j ⊆ R be the single-target space of the jth single-target observations. We denote a single-target regressor by h j : X → Y j . We denote a nonnegative single-target loss function by j : Y j × Y j → R ≥0 . Given a labeled example in the product of the domain and the single-target space (X, Y j ) ∈ X × Y j , the loss of some single-target regressor h j on the labeled example is denoted j (Y j , h j (X)). The single-target loss function measures the magnitude of error in predicting h j (X), when the single-target is Y j . We define a loss function that is decomposable over the targets by</p><formula xml:id="formula_3">(Y, h(X)) = n j=1 j (Y j , h j (X)),<label>(4)</label></formula><p>in accord with <ref type="bibr" target="#b16">[20,</ref><ref type="bibr" target="#b17">21]</ref>. In the application, we study the absolute error loss function, which is decomposable over the targets. Namely,</p><formula xml:id="formula_4">(Y, h(X)) = ||Y − h(X)|| 1 = n j=1 |Y j − h j (X)| = n j=1 j (Y j , h j (X)),<label>(5)</label></formula><p>where || · || p denotes the L p norm. Using the joint view, the multi-target regression task reduces to n independent single-target regression subtasks <ref type="formula">(6)</ref> where the first line follows from the choice of a loss function that is decomposable over the targets, and the second line follows from linearity <ref type="bibr" target="#b16">[20,</ref><ref type="bibr" target="#b17">21]</ref>. In this case, the optimal jth single-target regressor is the one that minimizes the jth single-target expected loss</p><formula xml:id="formula_5">E X,Y [ (Y, h(X))] = E X,Y [ n j=1 j (Y j , h j (X))] = n j=1 E X,Yj [ j (Y j , h j (X))],</formula><formula xml:id="formula_6">h * j = argmin hj E X,Yj [ j (Y j , h j (X))].<label>(7)</label></formula><p>Under the distribution-free setting, the jth singletarget expected loss is not available <ref type="bibr" target="#b36">[40]</ref><ref type="bibr" target="#b37">[41]</ref><ref type="bibr" target="#b38">[42]</ref><ref type="bibr" target="#b39">[43]</ref><ref type="bibr" target="#b40">[44]</ref><ref type="bibr" target="#b41">[45]</ref>. Consequently, we split Eq. 3 into training, validation, and test data, if there is sufficient data for an explicit validation stage. Otherwise, we forgo the validation split. Here, we focus on the case of splitting Eq. 3 into m train and m test ordered pairs for training and test data, respectively, as there is a shortage of labeled examples in the application. Moreover, we isolate the test data from the training data, whereby training data is recyclable and test data is single-use. Using the test data, we approximate the jth single-target expected loss with the mean absolute error</p><formula xml:id="formula_7">1 m test mtest i=1 |Y (i) j − h j (X (i) )|.<label>(8)</label></formula><p>Then, we approximate the expected loss with the average mean absolute error</p><formula xml:id="formula_8">1 n n j=1 1 m test mtest i=1 |Y (i) j − h j (X (i) )|,<label>(9)</label></formula><p>and we refer to this error as the benchmark error in <ref type="figure">Fig. 2</ref>. Two-step stacking framework -In the learning framework, let X ⊆ R n be the domain of initial multitarget predictions generated by a base regressor. We assume the availability of these predictions as well as the associated multi-target observations. In this way, the learning framework can be applied in tandem with scientific models (see the Supplementary Information for a brief review of the traditional two-step stacking approach).</p><p>In the first step, we wrangle the labeled examples Eq. 3, and we represent them with an m × 2n design matrix</p><formula xml:id="formula_9">     X (1) Y (1) X (2) Y (2) . . . . . . X (m) Y (m)      ,<label>(10)</label></formula><p>where m denotes the number of multi-targets and n denotes the number of single-targets. Next, we split Eq. 10 into m train and m test rows for training and test data, respectively. In the second step, the boosting algorithm receives the training data, which has shape m train × 2n, and we request a multi-target regressor as output. In the jth single-target regression subtask, the boosting algorithm slices the jth single-target from the training data</p><formula xml:id="formula_10">      X (1) Y (1) j X (2) Y (2) j . . . . . . X (mtrain) Y (mtrain) j       ,<label>(11)</label></formula><p>where the matrix has shape m train × (n + 1). Next, the single-target boosting algorithm detailed in Alg. 2 induces the jth single-target regressorĥ j on Eq. 11. After completion of each single-target regression subtask, the boosting algorithm concatenates the induced single-target regressors into the multi-target regressor h = (ĥ 1 ,ĥ 2 , . . . ,ĥ n ) T . Given a new example X ∈ X , the multi-target regressor predicts an n-dimensional real vectorŶ =ĥ(X) (see <ref type="figure">Fig. 1</ref>).</p><p>Model selection -As the test data is single-use, we need to simultaneously select the best performing single-target boosting algorithm detailed in Alg. 1 for the jth single-target regression subtask and estimate the jth mean absolute error Eq. 8, where j ∈ {1, 2, . . . , n}. Moreover, we need to ensure that the selected jth single-target boosting algorithm is able to choose the smooth term, if the noise term in Eq. 2 degrades performance (see <ref type="figure" target="#fig_2">Fig. 4</ref>). For this objective, we review nested cross-validation <ref type="bibr" target="#b18">[22,</ref><ref type="bibr" target="#b41">45,</ref><ref type="bibr">67]</ref>, and we describe the modification of k-fold cross-validation utilized in Alg. 2, which is similar to learning algorithms with inbuilt crossvalidation <ref type="bibr" target="#b18">[22]</ref>.</p><p>In <ref type="figure">Fig. 6</ref>, we illustrate k-fold cross-validation, e.g., k = 5, which is a precursor for nested cross-validation <ref type="bibr" target="#b18">[22,</ref><ref type="bibr" target="#b41">45,</ref><ref type="bibr">67</ref>] and the inbuilt model selection step in Alg. 2. The method begins by randomly partitioning Eq. 11 into k non-overlapping folds, and k is typically a natural number between 5 and 10, inclusive. Next, we repeat the following two steps k times with each of the withheld folds used exactly once as the validation data:</p><p>FIG. 6: k-fold cross-validation. We represent the training data as a light grey rectangle, and we illustrate 5-fold crossvalidation on the training data. In each iteration, the withheld fold is colored light green and the 4 training folds are colored light blue. We note that each of the withheld folds is used exactly once as the validation data.</p><p>• Of the k folds, we withhold one for validation.</p><p>A single-target boosting algorithm receives the remaining k −1 folds as training data, and we request a single-target regressor as output.</p><p>• We evaluate the induced single-target regressor on the withheld fold from the previous step by computing the average loss of the single-target regressor.</p><p>Then, we average the k results from the second step, and we refer to this average as cross-validation error. This completes a single loop of the k-fold cross-validation method. In best practices of machine learning, this method is preferred over leave-one-out cross-validation, wherein k = m train <ref type="bibr" target="#b18">[22,</ref><ref type="bibr" target="#b41">45,</ref><ref type="bibr">67</ref>].</p><p>In nested cross-validation, the estimation method utilizes an outer loop of k non-overlapping folds and an inner loop of l non-overlapping folds. The outer loop is utilized to estimate the jth mean absolute error Eq. 8 and the inner loop is utilized to select the (hyper)parameters in Alg. 1, such as the choice of basis function or value of K j in Eq. 2. The method begins by randomly partitioning Eq. 11 into k non-overlapping folds. Next, we repeat the following two steps k times with each of the withheld folds in the outer loop used exactly once as the validation data:</p><p>• Of the k folds, we withhold a fold for validation. In the inner loop, we apply l-fold crossvalidation to the remaining k − 1 folds for multiple single-target boosting algorithms with differing (hyper)parameters. After completing the inner loop, we select the best performing single-target boosting algorithm based on the minimum inner loop cross-validation error.</p><p>• The selected single-target boosting algorithm receives the k−1 folds from the previous step as training data, and we request a single-target regressor as output. We evaluate the induced single-target regressor on the withheld fold from the previous step by computing the average loss of the single-target regressor.</p><p>Then, we average the k results from the second step, and we use this average to approximate the jth mean absolute error Eq. 8. In practice, we usually execute nested crossvalidation within an exhaustive hyperparameter search tool, such as GridSearchCV by scikit-learn <ref type="bibr" target="#b18">[22]</ref> (see Supplementary Information for implementation details). After completing nested cross-validation, we repeat the second step in the learning framework. In the jth singletarget regression subtask, Alg. 2 utilizes Eq. 11 in a modified k-fold cross-validation procedure to select either the incumbent smooth term from the base regressor or the candidate additive expansion Eq. 2 as the induced single-target regressor. This entails modifying the second step in the aforedescribed k-fold cross-validation method, namely</p><p>• We independently evaluate the smooth term and the induced single-target regressor on the withheld fold from the previous step by computing the average loss of the smooth term and the single-target regressor. We note that the smooth term always predicts the jth feature, given an example from the withheld fold.</p><p>Then, we independently average their k results, and we refer to these averages as the incumbent error and the cross-validation error, respectively. The inbuilt model selection step in Alg. 2 selects the better algorithm based on the minimum error. Subsequently, the boosting algorithm completes each single-target regression subtask, and the boosting algorithm returns the induced multitarget regressor for evaluation on the test data.</p><p>Single-target gradient boosting -For the jth single-target regression subtask, the single-target boosting algorithm Alg. 1 takes as input training examples Eq. 11, number of iterations K j , single-target loss functions { j ,˜ j }, and basis function b characterized by parameter set θ. For instance, the parameter set would encode the split features, split locations, and the terminal node means of the individual trees, if the choice of basis function were a shallow decision tree; see for example <ref type="bibr">[43-45, 57, 58]</ref>. In the application, we choose a stacking regressor <ref type="bibr" target="#b18">[22,</ref><ref type="bibr" target="#b32">36,</ref><ref type="bibr" target="#b33">37]</ref> as the basis function, which is a two layer ensemble of single-target regressors (see Supplementary Information).</p><p>In Alg. 1, the first line initializes to the smooth term for each example in Eq. 11. In the for loop, line (a) computes the pseudo-residuals with single-target loss function j , whereby the term pseudo-residual emanates from the term residual in least squares fitting and reroughing <ref type="bibr" target="#b39">[43]</ref><ref type="bibr" target="#b40">[44]</ref><ref type="bibr" target="#b41">[45]</ref><ref type="bibr">59</ref>]. Line (b) enables the boosting algorithm to work for any given single-target learning algorithm <ref type="bibr" target="#b39">[43]</ref><ref type="bibr" target="#b40">[44]</ref><ref type="bibr" target="#b41">[45]</ref>, whereby the labels are the pseudo-residuals from line (a). Line (c) computes the one-dimensional line search with single-target loss function˜ j . Line (d) sequentially appends the basis function to the additive expansion. The output is the induced single-target regressorĥ j .</p><p>In the application, we modify line (c) in Alg. 1 to include L 1 regularization (see the Supplementary Information). In relation to previous work, the initialization step in Alg. 1 depends upon the examples, whereas the standard form of gradient boosting initializes to the optimal constant model: <ref type="bibr" target="#b39">[43]</ref><ref type="bibr" target="#b40">[44]</ref><ref type="bibr" target="#b41">[45]</ref>. In matching pursuit and its extensions, the greedy stagewise algorithms initialize to the zero vector, and they sequentially transform the signal into a negligible residual; see references [61-63] for the algorithmic body differences and further details.</p><formula xml:id="formula_11">argmin c mtrain i=1 j (Y (i) j , c); see ref- erences</formula><p>For the jth single-target regression subtask, the augmented version of the single-target boosting algorithm Alg. 2 takes as input training examples Eq. 11, number of iterations K j , single-target loss functions { j ,˜ j }, basis function b characterized by parameter set θ, number of cross-validation folds k, and k-fold cross-validation single-target loss function. The inbuilt model selection step in Alg. 2 selects the incumbent smooth term as the induced single-target regressor, if the incumbent error is less than or equal to the cross-validation error, otherwise Alg. 2 calls Alg. 1 (k-fold cross-validation details in previous section). The output is the induced single-target regressorĥ j .</p><p>Explainable machine learning -In machine learning competitions and products, complex models, such as ensemble and deep learning models, are omnipresent. Understanding why these models make certain predictions is the focus of explainable machine learning <ref type="bibr" target="#b28">[32,</ref><ref type="bibr" target="#b29">33]</ref>. The SHAP framework unifies several approaches in explainable machine learning to replicate individual predictions generated by a single-target regressor with a simpler linear explanation model whose coefficients measure feature importance <ref type="bibr" target="#b28">[32]</ref>. In the work ofStrumbelj and Kononenko, these coefficients, known as SHAP values <ref type="bibr" target="#b28">[32]</ref>, were shown to be equivalent to the Shapley value in cooperative game theory <ref type="bibr">[68]</ref>. The explanation model is defined as a linear function of binary variables</p><formula xml:id="formula_12">g(z ) = φ 0 + M k=1 φ k z k<label>(12)</label></formula><p>where z ∈ {0, 1} M is a set of binary variables, M is the number of features under consideration, and φ k is a real-valued feature attribution, known as a SHAP value, for the kth feature. As the computation of Shapley values has an exponential time complexity [68], the SHAP software approximates the coefficients with insights from additive feature attribution methods; see <ref type="bibr" target="#b28">[32]</ref>.</p><p>In the application, we utilize the model-agnostic approximation method, known as Kernel SHAP, to compute the SHAP values <ref type="bibr" target="#b28">[32]</ref>. This enables us to ascertain a simpler explanation model to approximate each training data prediction generated by the induced fullyconnected neural networks <ref type="bibr" target="#b18">[22]</ref>, where M = 9 in Eq. 12 for the control voltage features (see the Supplementary Information). The importance I of each feature is defined hj,0(X) = Xj for each example for k = 1 to Kj do (a) for i = 1 to mtrain do Compute pseudo-residuals</p><formula xml:id="formula_13">r (i) j,k = − ∂ j (Y (i) j ,h j (X (i) )) ∂h j (X (i) ) h j (X (i) )=h j,k−1 (X (i) ) end (b) Induce a basis function on {X (i) , r (i) j,k } m train i=1</formula><p>to learn the parameter set θ j,k (c) Solve the one-dimensional optimization problem to learn the expansion coefficient </p><formula xml:id="formula_14">α j,k = argmin α m train i=1˜ j (Y (i) j , h j,k−1 (X (i) ) + αb(X (i) ; θ j,k )) (d)</formula><formula xml:id="formula_15">I k = mtrain i=1 |φ (i) k |,<label>(13)</label></formula><p>which enables an ordering to be defined. The features are sorted in ascending order from bottom to top in each summary plot <ref type="bibr" target="#b28">[32,</ref><ref type="bibr" target="#b29">33]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data Availability</head><p>All data, relevant to the information and figures presented in this manuscript, are available upon reasonable request.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Author Contributions</head><p>A.W. designed the learning approach, implemented the learning system, and performed the data analysis. All authors contributed to the interpretation of the data and to writing the manuscript.  In this section, we briefly review the quantum device and the classical control program utilized in the benchmark task, and we describe the contents in the benchmark dataset. For a detailed introduction to the manybody Ramsey spectroscopy technique, the classical control program, calibration methodologies, and the superconducting quantum device, see for example [S1-S5].</p><p>The quantum device is a nearest-neighbor coupled linear chain of 9 superconducting qubits, wherein the 5 rightmost qubits and 4 interceding couplings were utilized during the benchmark dataset acquisition [S1-S3, S5]; see the main body of reference <ref type="bibr">[S2]</ref> for an optical micrograph of the device and see the Supplementary Materials of reference <ref type="bibr">[S3]</ref> for the corresponding electronic circuit diagram. Each qubit is explicitly modeled as a capacitor, inductor, and tunable junction, all in series (see the Supplementary Materials of reference <ref type="bibr">[S3]</ref> for the physical parameters utilized in the classical control program. For the device architecture, there are 26 control lines used to drive the microwave rotations, set the qubit frequencies, and bias the couplers <ref type="bibr">[S3]</ref>.</p><p>To obtain each multi-target in the benchmark dataset, an instance of the many-body Ramsey spectroscopy technique <ref type="bibr">[S2]</ref> begins by setting the parameters in Eq. 1 such that the on-site detuning is sampled uniformly in [−100, 100] MHz, the hopping rate is sampled uniformly in [0, 50] MHz, and the on-site Hubbard interaction is fixed at 0. Next, the time-domain spectroscopy circuit in <ref type="figure">Fig. S1</ref> is run 5 times with these parameters, and we denote the choice of superposition qubit and readout resonator by the index k, where k ∈ {1, 2, . . . , 5}.</p><p>In the kth run of the time-domain spectroscopy circuit, each qubit starts in the fiducial state |0 , and no photon is present in the system. Next, a microwave pulse is applied to the kth qubit, e.g., k = 1 in <ref type="figure">Fig. S1</ref>, which places the qubit in a superposition of the computational basis and it initializes a single-photon in the system. Then, the system evolves according to the timeindependent Hamiltonian Eq. 1. After the evolution, a microwave pulse is applied to the kth qubit to measure * wozn0001@e.ntu.edu.sg † mgu@quantumcomplexity.org FIG. S1. Time-domain spectroscopy circuit. Initially, each qubit is in the fiducial state |0 . Using a microwave pulse, the kth specified qubit, e.g., k = 1, is placed in a superposition of the computational basis. Next, the system evolves according to the time-independent Hamiltonian Eq. 1 with randomly programmed parameters. After the evolution, a microwave pulse is applied to measure either σ X or σ Y , where σ X and σ Y denote Pauli operators.</p><p>either σ X or σ Y . From the measurement of these observables, the observable σ X + i σ Y is instantiated; and the energy spectrum is fully resolved by completing all 5 runs <ref type="bibr">[S2]</ref>. We note that the choice of the operator is designed to isolate the single-photon manifold, so all of the eigenenergies have the same sign (see the Supplementary Materials in reference <ref type="bibr">[S2]</ref>). Lastly, the peaks in the fast Fourier transform of the observable σ X + i σ Y are identified as the eigenenergies of the Hamiltonian [S2, <ref type="bibr">S5]</ref>, and these eigenenergies are sorted into ascending order, as described in the main body.</p><p>To obtain each multi-target prediction in the benchmark dataset, the classical control program [S2, S3, S5] maps a collection of 5 qubit and 4 coupler bias features to the 5 × 5 single-photon block matrix in the representation of Eq. 1. Next, a numerical eigensolver produces 5 eigenenergy approximations, and they are sorted in ascending order.</p><p>In the benchmark dataset, there are m = 136 of each: qubit and coupler bias examples, multi-target predictions generated by the control program, and multi-targets retrieved by the many-body Ramsey spectroscopy technique <ref type="bibr">[S2]</ref>. In splitting this data for machine learning, we want to preserve the experimental association, i.e., the examples form a triple consisting of 5 qubit bias features, 4 coupler bias features, 5 single-target predictions, and 5 single-targets. Moreover, we split these examples into m train = 95 and m test = 41 indices for training and FIG. S2. Qubit and coupler bias feature boxplots. We depict the qubit bias features utilized in the training data split (top), whereby the label Qubit j denotes the qubit bias corresponding to qubit site j. We depict the coupler bias features utilized in the training data split (bottom), whereby the label Coupler j/j + 1 denotes the coupler bias corresponding to the nearest neighbor coupler for qubit sites j and j + 1. test data, respectively. In the boxplots in <ref type="figure">Fig. S2</ref>, we depict the qubit bias features utilized in the training data split (top), and we depict the coupler bias features utilized in the training data split (bottom). In the boxplot in <ref type="figure" target="#fig_1">Fig. S3</ref>, we jointly depict the single-target predictions and the single-target observations utilized in the training data split.</p><p>FIG. S4. Using the squared error loss function as the criterion, our learning system surpasses the previous state-of-theart [S2, S3, S5] by over 47% on the multi-target regression task. Moreover, our learning system outperforms the previous state-of-the-art [S2, S3, S5] on each single-target regression subtask.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S2. TEST ERROR</head><p>In the application, the jth single-target test error is mean absolute error Eq. 8, and the multi-target test error is average mean absolute error Eq. 9, where n = 5 and m test = 41. In the main body, we plot the mean absolute errors and average mean absolute error of the previous state-of-the-art [S2, S3, S5] and our learning system in <ref type="figure">Fig. 2</ref>.</p><p>In the real world application of machine learning, multiple measures of prediction performance should be studied and reported <ref type="bibr">[S6-S8]</ref>. Here, we utilize the squared error loss function to measure the prediction performance in the application, as we have already generated the test example predictions. Importantly, the squared error loss function is decomposable over the targets, namely</p><formula xml:id="formula_16">(Y, h(X)) = ||Y − h(X)|| 2 2 = n j=1 (Y j − h j (X)) 2 = n j=1 j (Y j , h j (X)).<label>(S1)</label></formula><p>The jth single-target test error is mean squared error</p><formula xml:id="formula_17">1 m test mtest i=1 (Y (i) j − h j (X (i) )) 2 ,<label>(S2)</label></formula><p>and the multi-target test error is the average mean squared error</p><formula xml:id="formula_18">1 n n j=1 1 m test mtest i=1 (Y (i) j − h j (X (i) )) 2 .<label>(S3)</label></formula><p>From left to right in <ref type="figure" target="#fig_2">Fig. S4</ref>, we show the mean squared errors Eq. S2 and the average mean squared error Eq. S2 of the previous state-of-the-art [S2, S3, S5] and our learning system, in blue and orange, respectively. Our learning system outperforms the previous state-of-theart [S2, S3, S5] on each single-target regression subtask and the multi-target regression task. Moreover, our learning system surpasses the previous state-of-theart [S2, S3, S5] by over 47% on the multi-target regression task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S3. MULTI-TARGET STACKING</head><p>Multi-target regression applications pose novel research questions and there is a demand for new methods, which consider not only the underlying relationships between the features and the associated single-targets but also the relationships between the single-targets [S9, S10]. Here, we review the single-target approach, which does not consider the relationship between the single-targets, as well as the prototypical two-step stacking approach, which addends a second layer to the single-target approach in order to exploit dependencies among the singletargets.</p><p>In the single-target approach, a learning algorithm receives training examples and we request a multi-target regressor as output. For each single-target regression subtask, the learning algorithm independently induces a single-target regressor on an appropriate slice of the training data [S9, S10]. After finishing the subtasks, the learning algorithm concatenates each single-target regressor into a multi-target regressor. Given an example, the multi-target regressor predicts a real vector. As many learning algorithms do not natively support multi-target prediction, this approach is widely applied in multi-target regression applications [S8-S10]. However, this approach does not imply simpler single-target regressors than an approach which considers the relationship between the single-targets <ref type="bibr">[S9, S10]</ref>. This leads to the algorithm design question: can we do better by exploiting dependencies among the single-targets?</p><p>Initially introduced in single-target classification [S11] and regression tasks [S12], stacking is a general ensemble learning technique for combining single-target classifiers or regressors to reduce their biases. In the multitarget regression setting, the two-step stacking approach enforces the idea that single-target regressors should behave similarly in order to outperform the independent single-target approach [S9, S10, S13].</p><p>In the two-step stacking approach, a learning algorithm receives training examples and we request a multi-target regressor as output. In the first step, the learning algorithm applies the single-target approach, and it uses the induced multi-target regressor to generate training example predictions. In the second step, the learning algorithm regards these predictions as new examples while retaining the initial labels. In some variations, the learning algorithm regards a concatenation of the original examples with these predictions as new examples while retaining the initial labels [S9, S10]. Next, the learning algorithm applies the single-target approach to induce a second layer of single-target regressors, and the learning algorithm returns a composition of the first and second layer multi-target regressors. In other words, given an example from the domain, the first layer multi-target regressor generates an initial prediction, then the second layer multi-target regressor regularizes this prediction, which reduces the problem of overfitting [S9, S10, S13]. This technique is related to methods in deep learning, such as pre-training [S14] and weight sharing [S10, S15]. Our learning framework is motivated by this two-step stacking approach [S9-S13], as well as multitask learning [S15] (details in Methods).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S4. BOOSTING THE BASE REGRESSOR</head><p>The idea of improving a base regressor by examining the residuals originated in Tukey's work on reroughing <ref type="bibr">[S16]</ref>. In this approach, we assume that an observed single-target can be decomposed into a sum of an underlying process that evolves smoothly, called the smooth term, and of an unsystematic noise component, called the noise term. In the context of the application, the smooth term in Eq. 2 is generated by the implemented approximation of the Hamiltonian model Eq. 1, and the noise term in Eq. 2 aims to capture generalizable physical effects missed by the classical control program (see <ref type="figure" target="#fig_1">Fig. 3</ref>).</p><p>The algorithmic paradigm of boosting originated from a question of Kearns and Valiant, about whether a weak learning algorithm that performs slightly better than random guessing, can be improved into an arbitrarily accurate strong learning algorithm, while working in the probably approximately correct (PAC) learning model [S17, S18]. In the affirmative, Schapire proposed the first provable polynomial-time boosting algorithm [S19], and Freund developed a more efficient boosting algorithm <ref type="bibr">[S20]</ref>. Next, Freund and Schapire introduced AdaBoost <ref type="bibr">[S21]</ref>, which surmounted many of the practical difficulties of the earlier boosting algorithms. Then, Schapire et al. devised a way to incorporate prior knowledge into AdaBoost for single-target classification tasks, whereby prior knowledge is refined and not entirely overwhelmed by the process of learning from examples <ref type="bibr">[S22]</ref>. The modification of the logistic loss function in AdaBoost arose in the development of spoken-dialogue systems at AT&amp;T <ref type="bibr">[S22]</ref>.</p><p>The work of Friedman, Hastie, and Tibshirani linked the original formulation of AdaBoost <ref type="bibr">[S21]</ref> with additive expansions <ref type="bibr">[S23]</ref>, which are typically fit with a backfitting algorithm or a greedy stagewise algorithm <ref type="bibr">[S6, S24, S25]</ref>. Later, Breiman showed that boosting can be interpreted as a form of gradient descent in function space <ref type="bibr">[S26]</ref>. Friedman extended this idea to the gradient boosting machine, which advantageously allows any choice of differentiable loss function <ref type="bibr">[S27]</ref>. Simultaneously, Mason et al. developed an abstract characterization of boosting algorithms as gradient descent on empirical loss func-tionals in an inner-product function space <ref type="bibr">[S28]</ref>. Further connections with statistics were established in the work of Bühlmann and Hothorn <ref type="bibr">[S29]</ref>. In practice, these algorithmic techniques are usually implemented in scikitlearn <ref type="bibr">[S8]</ref>, XGBoost <ref type="bibr">[S30]</ref>, or LightGBM <ref type="bibr">[S31]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Gradient boosting</head><p>In the main body, we devised a way to incorporate prior knowledge into the gradient boosting machine Alg. 1 (details in Methods). In this section, we expand upon this discussion by deriving a generic version of boosting for the jth single-target regression subtask, which follows from similar work in the original gradient boosting machine for single-target regression tasks [S6, <ref type="bibr">S26-S29]</ref>. Let us begin by considering the jth empirical loss functional</p><formula xml:id="formula_19">L j (h j ) = mtrain i=1 j (Y (i) j , h j (X (i) )),<label>(S4)</label></formula><p>where L j is a function of the jth single-target regressor h j . In this abstract characterization of boosting, the goal of a boosting algorithm is to minimize Eq. S4. As L j is a functional, this minimization problem can be viewed as numerical optimization in function space</p><formula xml:id="formula_20">h * j = argmin h j L j (h j ),<label>(S5)</label></formula><p>where the parameter vector h j ∈ R mtrain components are the values of the jth single-target approximating regressor h j (X (i) ) at each of the m train examples in the training data. Namely,</p><formula xml:id="formula_21">h j =      h j (X (1) ) h j (X (2) ) . . . h j (X (mtrain) )      .<label>(S6)</label></formula><p>Typically, numerical optimization procedures solve Eq. S5 by making an initial guess h j,0 = b j,0 ∈ R mtrain , then iteratively updating each successive parameter vector h j,k based on the current parameter vector h j,k−1 , where we denote the number of iterations by K j and the subscript in h j,k denotes the jth single target regression subtask and the kth iteration, respectively. Namely, we posit the solution of Eq. S5 as an additive expansion of parameter vectors</p><formula xml:id="formula_22">h j,K j = Kj k=0 b j,k , b j,k ∈ R mtrain .<label>(S7)</label></formula><p>Here, we choose the stagewise fist-order functional steepest descent as the numerical optimization procedure. We have that each parameter vector is given by</p><formula xml:id="formula_23">b j,k = −ρ j,k g j,k ,<label>(S8)</label></formula><p>where ρ j,k ∈ R is the step length and g j,k ∈ R mtrain is the gradient of the empirical risk functional Eq. S4 evaluated at h j = h j,k−1 ; see reference <ref type="bibr">[S32]</ref> for a derivation with the second-order functional Newton-Raphson update. Next, we compute each component of the gradient</p><formula xml:id="formula_24">g (i) j,k = ∂ j (Y (i) j , h j (X (i) )) ∂h j (X (i) )</formula><p>hj (X (i) )=h j,k−1 (X (i) )</p><p>,</p><p>as well as the step length</p><formula xml:id="formula_26">ρ j,k = argmin ρ L j (h j,k−1 − ρg j,k ).<label>(S10)</label></formula><p>Then, we make the update</p><formula xml:id="formula_27">h j,k = h j,k−1 − ρ j,k g j,k ,<label>(S11)</label></formula><p>and we repeat this process iteratively. We refer to this process as functional gradient descent [S6, S26-S29, S32]. In its current form, functional gradient descent does not address the generalization objective of a machine learning algorithm, as the gradient is only defined at a fixed set of m train examples and it cannot be generalized to other examples in the domain. In accord with the original gradient boosting machine [S6, S25, S27, S28], we resolve this dilemma by inducing a basis function b(X; θ), such as a shallow decision tree [S6, S27, S30, S31], at the kth iteration, which approximates the negative gradient signal. Hereby learning the parameter set θ j,k . We note that the parameter set θ j,k would encode the split features, split locations, and the terminal node means of the individual trees for the jth single-target regression task at the kth iteration, if the choice of basis function were a shallow decision tree; see for example [S6, S27, S30, S31]. Next, we perform a one-dimensional line search</p><formula xml:id="formula_28">α j,k = argmin α mtrain i=1 j (Y (i)</formula><p>j , h j,k−1 (X (i) )+αb(X (i) ; θ j,k )), (S12) where α ∈ R; see reference <ref type="bibr">[S29]</ref> for an argument about the possible omission of this step. Then, we sequentially append the induced basis function to the additive expansion</p><formula xml:id="formula_29">h j,k (X) = h j,k−1 (X) + α j,k b(X; θ j,k ).<label>(S13)</label></formula><p>This leads us to the generic version of the jth singletarget gradient boosting algorithm Alg. 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S5. IMPLEMENTATION</head><p>We use the machine learning approach described in the main body, as well as the scikit-physlearn repository developed by Alex Wozniakowski. The Python based repository will be made publicly available at the cited GitHub link <ref type="bibr">[S33]</ref>. For each single-target regression subtask, the training process takes a few seconds on a standard laptop, and the hyperparameters can be accessed in the repository.</p><p>In obtaining the test error results in <ref type="figure">Fig. 2</ref> and in <ref type="figure" target="#fig_2">Fig. S4</ref>, we evaluate all operations encompassing training data through nested cross-validation, which is executed in GridSearchCV with parameters cv = 5 and scoring = "neg mean absolute error" <ref type="bibr">[S8]</ref>. For each single-target regression subtask, we independently preprocess the examples in Eq. 11 with a normal distribution quantile transformer <ref type="bibr">[S8]</ref>, and the transformer is handled by a modified pipeline object, which inherits from the pipeline object in reference <ref type="bibr">[S8]</ref>. The modified pipeline object induces single-target regressors with Alg. 2, which takes as input the transformed training examples Eq. 11, number of iterations K j = 1, squared error and absolute error single-target loss functions { j ,˜ j }, respectively, stacking regressor [S8, S11, S12] basis function b, number of cross-validation folds k = 5, and 5-fold cross-validation single-target absolute error loss function.</p><p>In the stacking regressor <ref type="bibr">[S8]</ref> with parameters cv = 5 and passthrough = True, the first stacking layer consists of a gradient boosted decision tree [S31] and a fully-connected neural network <ref type="bibr">[S8]</ref>, and the second stacking layer consists of a fully-connected neural network <ref type="bibr">[S8]</ref>. The gradient boosted decision tree <ref type="bibr">[S31]</ref> optimizes absolute error Eq. 5 and the neural networks optimize squared error Eq. S1. Moreover, we restrict the neural networks to one hidden layer in order to avoid overfitting, the activation function is the hyperbolic tangent function, and the optimization algorithm is the limited-memory variant of the Broyden-Fletcher-Goldfarb-Shanno algorithm.</p><p>As noted in the main body, Alg. 1 wins the model selection step in Alg. 2, so Alg. 2 makes a call to Alg. 1, which takes as input transformed training examples Eq. 11, number of iterations K j = 1, squared error and absolute error single-target loss functions { j ,˜ j }, respectively, stacking regressor [S8, S11, S12] basis function b. In line (a) squared error j is used. In line (b) the parameter sets are induced with the stacking regressor <ref type="bibr">[S8]</ref>. In line (c), we appended an L 1 regularization term to the optimization problem</p><formula xml:id="formula_30">argmin α mtrain i=1 j (Y (i) j , h j,k−1 (X (i) ) + αb(X (i) ; θ j,k )) + λ|α|.</formula><p>We solve the optimization problem with the Nelder-Mead method, where λ = 0.1. In future applications, several modifications of Alg. 1 may be of interest: inclusion of other regularization terms, early stopping, out-of-bagerror estimates, or sampling techniques for variance reduction; see references <ref type="bibr">[S6, S8, S25, S27]</ref>.</p><p>In plotting the augmented learning curves in <ref type="figure" target="#fig_2">Fig. 4</ref> and in <ref type="figure" target="#fig_7">Fig. S5</ref>, we modify the source code in reference [S8] to use the same withheld folds for the cross-validation error and the incumbent error. The training sizes in the plots from left to right are <ref type="bibr" target="#b19">23,</ref><ref type="bibr" target="#b21">25,</ref><ref type="bibr" target="#b23">27,</ref><ref type="bibr" target="#b25">29,</ref><ref type="bibr" target="#b27">31,</ref><ref type="bibr" target="#b28">32,</ref><ref type="bibr" target="#b30">34,</ref><ref type="bibr" target="#b32">36,</ref><ref type="bibr" target="#b34">38,</ref><ref type="bibr" target="#b36">40,</ref><ref type="bibr" target="#b38">42,</ref><ref type="bibr" target="#b39">43,</ref><ref type="bibr" target="#b41">45,</ref><ref type="bibr" target="#b43">47,</ref><ref type="bibr">49</ref>, 51, 52, 54, 56, 58, 60, 62, 63, 65, 67, 69, 71, 73, 74, 76, 78, 80, 82, 84, 85, 87, 89, 91, 93, 95, respectively. In plotting the summary plots in <ref type="figure">Fig. 5</ref> and in <ref type="figure">Fig. S8</ref>, we utilize the SHAP framework <ref type="bibr">[S34]</ref>. For each summary plot, we induce a fully-connected neural network <ref type="bibr">[S8]</ref>.</p><p>We restrict the neural network to one hidden layer, the activation function is the rectified linear unit, and the optimization algorithm is the limited-memory variant of the Broyden-Fletcher-Goldfarb-Shanno algorithm. We compute the SHAP values with Kernel SHAP [S34].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S6. AUGMENTED LEARNING CURVES</head><p>In the main body, we illustrated the inbuilt model selection step in Alg. 2 with an augmented learning curve for the single-target regression subtask Y 3 with training sizes varying between 23 to 95 ordered pairs in <ref type="figure" target="#fig_2">Fig. 4</ref>. Here, we illustrate the inbuilt model selection step in Alg. 2 with augmented learning curves for the singletarget regression subtasks Y 1 (top), Y 2 (top middle), Y 4 (bottom middle), and Y 5 (bottom) with training sizes varying between 23 to 95 ordered pairs in <ref type="figure" target="#fig_7">Fig. S5</ref>. For the single-target regression subtasks Y 1 (top), Y 2 (top middle), and Y 5 (bottom), the candidate always performs better than the incumbent. For the single-target regression subtask Y 4 (bottom middle), when there are less than 60 ordered pairs, the incumbent usually performs better, whereas the candidate always outperforms the incumbent with 60, or more, ordered pairs. These augmented learning curves highlight the importance of the inbuilt model selection step in Alg. 2, as the incorporation of prior knowledge into Alg. 1 does not always improve performance over the base regressor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S7. UTILITY OF THE DATA PREPROCESSOR</head><p>In this section, we describe the tabula rasa learning of the multi-targets [S15, S35-S39], which enables our utility study of the classical control program [S2, S3, S5] as a data preprocessor for the downstream boosting algorithm in the learning framework (see <ref type="figure">Fig. 1</ref>). Moreover, we show the summary plots <ref type="bibr">[S34]</ref> for the single-target regression subtasks Y j , where j ∈ {2, 3, 4, 5}.</p><p>In this setting, let X ⊆ R 9 be the domain of qubit and coupler biases [S1-S3, S5] in an instance of the manybody Ramsey spectroscopy technique <ref type="bibr">[S2]</ref>. Let Y ⊆ R 5 be the target space of multi-target observations, as in the main body. We are given a finite sequence of labeled examples Eq. 3, where we regard a collection of 5 qubit and 4 coupler bias features as an example, and the associated multi-target observation as the label. Further, we retain the same data split as in the main body, so there are m train = 95 training examples and m test = 41 test examples.</p><p>We represent the training data with a 95 × 14 design Using the absolute error loss function as the criterion, we compare the best performing single-target regressors without prior knowledge against our learning system with prior knowledge in blue and orange, respectively. Disregarding the prior knowledge degrades performance by over 729% on the benchmark task.</p><formula xml:id="formula_31">matrix      X (1) Y (1) X (2) Y (2) . . . . . . X (mtrain) Y (mtrain)      .</formula><p>(S14) Next, we slice Eq. S14 into single-target training data Eq. 11 for each single-target regression subtask Y j , where j ∈ {1, 2, . . . , 5} and the shape of each matrix is 95 × 10. We employ model selection to choose the best performing single-target regressor for each single-target regression subtask, while restricting the search to a single complex model (details in Methods). We find a fully-connected neural network <ref type="bibr">[S8]</ref> with a single-hidden layer as the best performing single-target regressor for each single-target regression subtask. After inducing each fully-connected neural network on Eq. 11, we evaluate the test error using the absolute error loss function in <ref type="figure">Fig. S6</ref>. Disregarding the prior knowledge degrades performance by over 729% on the benchmark task. As we have already generated the test example predictions, we utilize the squared error loss function to measure the prediction performance in <ref type="figure">Fig. S7</ref>. Disregarding the prior knowledge degrades performance by over 5426% on the multi-target regression task.</p><p>In the main body, we attained an overview of the most important qubit and coupler bias features for the singletarget regression subtask Y 1 in <ref type="figure">Fig. 5</ref>. Here, we show the SHAP summary plots for the remaining single-target regression subtasks in <ref type="figure">Fig. S8</ref>, where Y 2 (top), Y 3 (top middle), Y 4 (top bottom), and Y 5 (bottom).</p><p>FIG. S7. Using the squared error loss function as the criterion, we compare the best performing single-target regressors without prior knowledge against our learning system with prior knowledge in blue and orange, respectively. Disregarding the prior knowledge degrades performance by over 5426% on the multi-target regression task.</p><p>FIG. S8. SHAP summary plots <ref type="bibr">[S34]</ref> for single-targets Y2, Y3, Y4, and Y5, from top-to-bottom respectively. In each plot, we use the collection of 9 qubit and coupler bias features as an example, and we induce a fully connected neural network <ref type="bibr">[S8]</ref> to predict Yj, where j ∈ {2, 3, 4, 5}. The horizontal axis is centered at the average training example prediction, and the vertical axis ascendingly orders the features according to their importance. Each point is a SHAP value for a particular example, the coloring represents the bias value, and overlapping points are randomly jittered along the vertical axis to avoid collisions <ref type="bibr">[S34, S40]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>arXiv:2005.06194v1 [quant-ph] 13 May 2020 FIG. 1: Conceptual representation of the learning framework.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>FIG. 3 :</head><label>3</label><figDesc>Pairwise correlations in the training examples.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>FIG. 4 :</head><label>4</label><figDesc>Augmented learning curve for the single-target Y3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Sequentially append the induced basis function to the additive expansion h j,k (X) = h j,k−1 (X) + α j,k b(X; θ j,k ) end Output: Single-target regressorĥj = hj,K j Algorithm 2: BaseBoostCV Input: training examples number of iterations Kj single-target loss functions { j ,˜ j } basis function b characterized by parameter set θ number of cross-validation folds k k-fold cross-validation single-target loss function Model selection: Perform modified k-fold cross-validation for the incumbent smooth term and the candidate BaseBoost. If the incumbent error is less than or equal to the cross-validation error, then break hj(X) = Xj. Otherwise, call BaseBoost. Output: Single-target regressorĥj as the sum of absolute SHAP values</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>[</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>FIG. S3 .</head><label>S3</label><figDesc>Joint single-target prediction feature and singletarget observation boxplot. We jointly depict the single-target predictions and the single-target observations utilized in the training data split.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>FIG. S5 .</head><label>S5</label><figDesc>Augmented learning curves for the single-target regression subtasks Y1, Y2, Y4, and Y5, from top-to-bottom respectively. We show the training, cross-validation, and incumbent errors for varying amounts of training examples in blue, orange, and red, respectively. FIG. S6.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Algorithm 1 :</head><label>1</label><figDesc>BaseBoost Input: training examples number of iterations Kj single-target loss functions { j ,˜ j } basis function b characterized by parameter set θ Initialize:</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Trevor Hastie and Robert Tibshirani. Generalized Additive Models. Chapman and Hall, London, 1990. [50] Robert Schapire. The strength of weak learnability. Machine Learning, 5:197-227, 1990. [51] Michael Kearns and Leslie Valiant. Cryptographic limitations on learning boolean formulae and finite automata. Knowledge and Information Systems, 41:647-665, 2014.Supplementary Information: Boosting on the shoulders of giants in quantum device calibration Alex Wozniakowski, 1, 2, * Jayne Thompson, 3 Mile Gu, 1, 2, † and Felix Binder 4</figDesc><table><row><cell cols="2">cal Report TR-14-88, Harvard University Aiken Compu-</cell><cell>[68] ErikStrumbelj and Igor Kononenko. Explaining predic-</cell></row><row><cell cols="2">tation Laboratory, 1988.</cell><cell>tion models and individual predictions with feature con-</cell></row><row><cell cols="3">[49] Journal of the Association for Computing Machinery, 41:67-95, 1994. [52] Yoav Freund. Boosting a weak learning algorithm by majority. Information and Computation, 121:256-285, tributions. 1 School of Physical and Mathematical Sciences, Nanyang Technological University 2 Complexity Institute, Nanyang Technological University 3 Centre for Quantum Technologies, National University of Singapore 4 Institute for Quantum Optics and Quantum Information -IQOQI Vienna,</cell></row><row><cell>1995.</cell><cell cols="2">Austrian Academy of Sciences, Boltzmanngasse 3, 1090 Vienna, Austria</cell></row><row><cell cols="2">[53] Yoav Freund and Robert Schapire. A decision-theoretic</cell></row><row><cell cols="2">generalization of on-line learning and an application to</cell></row><row><cell cols="2">boosting. Journal of Computer and System Sciences, 55:119-139, 1997. S1. BENCHMARK DATASET</cell></row><row><cell cols="2">[54] Leo Breiman. Arcing the edge. Technical report, Stanford</cell></row><row><cell cols="2">University, Department of Statistics, 1997.</cell></row><row><cell cols="2">[55] Llew Mason et al. Boosting algorithms as gradient de-</cell></row><row><cell cols="2">scent. In NIPS: Proceedings of the 12th International</cell></row><row><cell cols="2">Conference on Neural Information Processing, pages</cell></row><row><cell>512-518, 1999.</cell><cell></cell></row><row><cell cols="2">[56] Robert Schapire et al. Incorporating prior knowledge into</cell></row><row><cell cols="2">boosting. In ICML'02: Proceedings of the Nineteenth In-</cell></row><row><cell cols="2">ternational Conference on Machine Learning, pages 538-</cell></row><row><cell>545, 2002.</cell><cell></cell></row><row><cell cols="2">[57] Tianqi Chen and Carlos Guestrin. XGBoost: a scalable</cell></row><row><cell cols="2">tree boosting system. In KDD'16: Proceedings of the 22nd</cell></row><row><cell cols="2">ACM SIGKDD International Conference on Knowledge</cell></row><row><cell cols="2">Discovery and Data Mining, pages 785-794, 2016.</cell></row><row><cell cols="2">[58] Guolin ke et al. LightGBM: a highly efficient gradient</cell></row><row><cell cols="2">boosting decision tree. In Advances in Neural Informa-</cell></row><row><cell cols="2">tion Processing Systems 30, pages 3149-3157. Curran As-</cell></row><row><cell>sociates, Inc., 2017.</cell><cell></cell></row><row><cell cols="2">[59] John Tukey. Exploratory Data Analysis. Addison-Wesley,</cell></row><row><cell>1977.</cell><cell></cell></row><row><cell cols="2">[60] Jerome Friedman, Trevor Hastie, and Robert Tibshirani.</cell></row><row><cell cols="2">Additive logistic regression: A statistical view of boost-</cell></row><row><cell cols="2">ing. The Annals of Statistics, 28(2):337-407, 2000.</cell></row><row><cell cols="2">[61] Stéphane Mallat and Zhifeng Zhang. Matching pursuits</cell></row><row><cell cols="2">with time-frequency dictionaries. IEEE Transactions on</cell></row><row><cell cols="2">Signal Processing, 41(12):3397-3415, 1993.</cell></row><row><cell cols="2">[62] Pascal Vincent and Yoshua Bengio. Kernel matching pur-</cell></row><row><cell cols="2">suit. Machine Learning, 48:165-187, 2002.</cell></row><row><cell cols="2">[63] David Donoho et al. Sparse solution of underdeter-</cell></row><row><cell cols="2">mined systems of linear equations by stagewise orthogo-</cell></row><row><cell cols="2">nal matching pursuit. IEEE Transactions on Information</cell></row><row><cell cols="2">Theory, 58(2):1094-1121, 2012.</cell></row><row><cell cols="2">[64] Xinran He et al. Practical lessons from predicting clicks</cell></row><row><cell cols="2">on ads at facebook. In ADKDD'14: Proceedings of the</cell></row><row><cell cols="2">Eighth International Workshop on Data Mining for On-</cell></row><row><cell cols="2">line Advertising, 2014.</cell></row><row><cell cols="2">[65] Cosma Shalizi and James Crutchfield. Computational</cell></row><row><cell cols="2">mechanics: Pattern and prediction, structure and sim-</cell></row><row><cell cols="2">plicity. Journal of Statistical Physics, 104(3-4):817-879,</cell></row><row><cell>2001.</cell><cell></cell></row><row><cell cols="2">[66] Mile Gu et al. Quantum mechanics can reduce the</cell></row><row><cell cols="2">complexity of classical models. Nature communications,</cell></row><row><cell>3(1):1-5, 2012.</cell><cell></cell></row><row><cell cols="2">[67] Gavin Cawley and Nicola Talbot. On over-fitting in</cell></row><row><cell cols="2">model selection and subsequent selection bias in per-</cell></row><row><cell cols="2">formance evaluation. Journal of Machine Learning Re-</cell></row><row><cell cols="2">search, 11:2079-2107, 2010.</cell></row></table><note>1] David Hume. A Treatise of Human Nature. Clarendon Press, 1739. [2] David Haussler. Quantifying inductive bias: AI learning algorithms and Valiant's learning framework. Artificial Intelligence, 36:177-221, 1988.[3] Tom Mitchell. The need for biases in learning generali- sation. In Jude Shavlik and Thomas Dietterich, editors, Readings in Machine Learning. Morgan Kaufmann, 1991. [4] David Wolpert and William Macready. No free lunch theorems for optimization. IEEE Transactions on Evo-</note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Computation</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Multitask learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rich</forename><surname>Caruana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="41" to="75" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A model of inductive bias learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Baxter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="149" to="198" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Discovering governing equations from data by sparse identification of nonlinear dynamical systems. Proceedings of the National Academy of Sciences of the United States of America</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Brunton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><surname>Proctor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">José Nathan</forename><surname>Kutz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="page" from="3932" to="3937" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Spectroscopic signatures of localization with interacting photons in superconducting qubits</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pedram</forename><surname>Roushan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">358</biblScope>
			<biblScope unit="page" from="1175" to="1179" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Machine learning for molecular and materials science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keith</forename><surname>Butler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">559</biblScope>
			<biblScope unit="page" from="547" to="555" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A blueprint for demonstrating quantum supremacy with superconducting qubits</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Neill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">360</biblScope>
			<biblScope unit="page" from="195" to="199" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Growth and preservation of entanglement in a many-body localized system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Chiaro</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.06024</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Distilling free-form natural laws from experimental data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hod</forename><surname>Lipson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">324</biblScope>
			<biblScope unit="page" from="81" to="85" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Machine learning phases of matter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juan</forename><surname>Carrasquilla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger</forename><surname>Melko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Physics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="431" to="434" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Active learning machine learns to create new quantum experiments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Melnikov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the National Academy of Sciences of the United States of America</title>
		<meeting>the National Academy of Sciences of the United States of America</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="page" from="1221" to="1226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Mutual information, neural networks and the renormalization group</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maciej</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-Janusz</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zohar</forename><surname>Ringel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Physics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="578" to="582" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Neural-network quantum state tomography</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giacomo</forename><surname>Torlai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Physics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="447" to="450" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Toward an artificial intelligence physicist for unsupervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tailin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Tegmark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review E</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="page">33311</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Discovering physical concepts with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raban</forename><surname>Iten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review Letters</title>
		<imprint>
			<biblScope unit="volume">124</biblScope>
			<biblScope unit="page">10508</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Discovering symmetry invariants and conserved quantities by interpreting siamese neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Wetzel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.04299</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A survey on multi-output regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanen</forename><surname>Borchani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Multi-target prediction: A unifying view on problems and methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Willem</forename><surname>Waegeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krzysztof</forename><surname>Dembczyński</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eyke</forename><surname>Hüllermeier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Mining and Knowledge Discovery</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="293" to="324" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Scikit-learn: machine learning in python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian</forename><surname>Pedregosa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The plastic human brain cortex</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alvaro</forename><surname>Pascual-Leone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annual Review of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="377" to="401" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Qubit architecture with high coherence and fast tunable coupling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review Letters</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="page">220502</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Designing high-fidelity single-shot three-qubit gates: a machine-learning approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehsan</forename><surname>Zahedinejad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joydip</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Sanders</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review Applied</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">54005</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Why does deep and cheap learning work so well</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henry</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Tegmark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Rolnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Physics</title>
		<imprint>
			<biblScope unit="volume">168</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1223" to="1247" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Quantum machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Biamonte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">549</biblScope>
			<biblScope unit="page" from="195" to="202" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Machine Learning &amp; Artificial Intelligence in the Quantum Domain: A Review of Recent Progress</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vedran</forename><surname>Dunjko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans</forename><surname>Briegel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Reports on Progress in Physics</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="issue">7</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Machine learning and the physical sciences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giuseppe</forename><surname>Carleo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Reviews of Modern Physics</title>
		<imprint>
			<biblScope unit="volume">91</biblScope>
			<biblScope unit="page">45002</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A high-bias, low-variance introduction to Machine Learning for physicists</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pankaj</forename><surname>Mehta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physics Reports</title>
		<imprint>
			<biblScope unit="volume">810</biblScope>
			<biblScope unit="page" from="1" to="124" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">AI Feynman: A physics-inspired method for symbolic regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marian</forename><surname>Silviu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Udrescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tegmark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science Advances</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">16</biblScope>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A unified approach to interpreting model predictions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Lundberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Su-In</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="4765" to="4774" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Interpretable machine learning: a guide for making black box models explainable. christophm.github.io/interpretable-ml-book</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Molnar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Experimental comparison of two quantum computing architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Norbert</forename><surname>Linke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the National Academy of Sciences of the United States of America</title>
		<meeting>the National Academy of Sciences of the United States of America</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="page" from="3305" to="3310" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Physical qubit calibration on a directed acyclic graph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Kelly</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.03226</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Stacked generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Wolpert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="241" to="259" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Stacked regressions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leo</forename><surname>Breiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="49" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Predicting multivariate responses in multiple linear regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leo</forename><surname>Breiman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jerome</forename><surname>Friedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Royal Statistical Society Series B</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="3" to="54" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Why does unsupervised pretraining help deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="625" to="660" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Decision theoretic generalizations of the PAC model for neural net and other learning applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Haussler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information and Computation</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="page" from="78" to="150" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Efficient distribution-free learning of probabilistic concepts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Kearns</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Schapire</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="464" to="497" />
		</imprint>
		<respStmt>
			<orgName>Computer and Systems Science</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Toward efficient agnostic learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Kearns</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Schapire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linda</forename><surname>Sellie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="115" to="141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Greedy function approximation: A gradient boosting machine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jerome</forename><surname>Friedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1189" to="1232" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Importance sampled learning ensembles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jerome</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bogdan</forename><surname>Popescu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
		<respStmt>
			<orgName>Stanford University, Department of Statistics</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">The Elements of Statistical Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Tibshirani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jerome</forename><surname>Friedman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Machine learning yearning. deeplearning.ai project</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Ng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Radial basis functions for multivariable interpolation: a review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Powell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Algorithms for Approximation</title>
		<imprint>
			<publisher>Clarendon Press</publisher>
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Learning boolean formulae or finite automata is as hard as factoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Kearns</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leslie</forename><surname>Valiant</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note type="report_type">Techni-</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Qubit architecture with high coherence and fast tunable coupling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review Letters</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="page">220502</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Spectroscopic signatures of localization with interacting photons in superconducting qubits</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pedram</forename><surname>Roushan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">358</biblScope>
			<biblScope unit="page" from="1175" to="1179" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">A blueprint for demonstrating quantum supremacy with superconducting qubits</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Neill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">360</biblScope>
			<biblScope unit="page" from="195" to="199" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Physical qubit calibration on a directed acyclic graph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Kelly</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.03226</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Growth and preservation of entanglement in a many-body localized system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Chiaro</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.06024</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Tibshirani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jerome</forename><surname>Friedman</surname></persName>
		</author>
		<title level="m">The Elements of Statistical Learning</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">On over-fitting in model selection and subsequent selection bias in performance evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gavin</forename><surname>Cawley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicola</forename><surname>Talbot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="2079" to="2107" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Scikit-learn: machine learning in python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian</forename><surname>Pedregosa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">A survey on multi-output regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanen</forename><surname>Borchani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Multi-target prediction: A unifying view on problems and methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Willem</forename><surname>Waegeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krzysztof</forename><surname>Dembczyński</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eyke</forename><surname>Hüllermeier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Mining and Knowledge Discovery</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="293" to="324" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Stacked generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Wolpert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="241" to="259" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Stacked regressions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leo</forename><surname>Breiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="49" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Predicting multivariate responses in multiple linear regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leo</forename><surname>Breiman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jerome</forename><surname>Friedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Royal Statistical Society Series B</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="3" to="54" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Why does unsupervised pretraining help deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="625" to="660" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Multitask learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rich</forename><surname>Caruana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="41" to="75" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Exploratory Data Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Tukey</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1977" />
			<publisher>Addison-Wesley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Learning boolean formulae or finite automata is as hard as factoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Kearns</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leslie</forename><surname>Valiant</surname></persName>
		</author>
		<idno>TR-14-88</idno>
		<imprint>
			<date type="published" when="1988" />
		</imprint>
		<respStmt>
			<orgName>Harvard University Aiken Computation Laboratory</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Cryptographic limitations on learning boolean formulae and finite automata</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Kearns</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leslie</forename><surname>Valiant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Association for Computing Machinery</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="67" to="95" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">The strength of weak learnability. Machine Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Schapire</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="197" to="227" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Boosting a weak learning algorithm by majority. Information and Computation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Freund</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="volume">121</biblScope>
			<biblScope unit="page" from="256" to="285" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">A decision-theoretic generalization of on-line learning and an application to boosting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Freund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Schapire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer and System Sciences</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="119" to="139" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Incorporating prior knowledge into boosting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Schapire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML&apos;02: Proceedings of the Nineteenth International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="538" to="545" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">Generalized Additive Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Tibshirani</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990" />
			<publisher>Chapman and Hall</publisher>
			<pubPlace>London</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Additive logistic regression: A statistical view of boosting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jerome</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Tibshirani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="337" to="407" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">Importance sampled learning ensembles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jerome</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bogdan</forename><surname>Popescu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
		<respStmt>
			<orgName>Stanford University, Department of Statistics</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<title level="m" type="main">Arcing the edge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leo</forename><surname>Breiman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997" />
		</imprint>
		<respStmt>
			<orgName>Stanford University, Department of Statistics</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Greedy function approximation: A gradient boosting machine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jerome</forename><surname>Friedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1189" to="1232" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Boosting algorithms as gradient descent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llew</forename><surname>Mason</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS: Proceedings of the 12th International Conference on Neural Information Processing</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="512" to="518" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Boosting algorithms: Regularization, prediction and model fitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Bühlmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Torsten</forename><surname>Hothorn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistical Science</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="477" to="505" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">XGBoost: a scalable tree boosting system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Guestrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD&apos;16: Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="785" to="794" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">LightGBM: a highly efficient gradient boosting decision tree</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guolin Ke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="3149" to="3157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<title level="m" type="main">Gradient and newton boosting for classification and regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><surname>Sigrist</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.03064</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Wozniakowski</surname></persName>
		</author>
		<ptr target="Scikit-physlearn.github.com/a-wozniakowski/scikit-physlearn" />
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">A unified approach to interpreting model predictions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Lundberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Su-In</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="4765" to="4774" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<monogr>
		<title level="m" type="main">A Treatise of Human Nature</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Hume</surname></persName>
		</author>
		<imprint>
			<publisher>Clarendon Press</publisher>
			<biblScope unit="page">1739</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Quantifying inductive bias: AI learning algorithms and Valiant&apos;s learning framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Haussler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="177" to="221" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">The need for biases in learning generalisation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Readings in Machine Learning. Morgan Kaufmann</title>
		<editor>Jude Shavlik and Thomas Dietterich</editor>
		<imprint>
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">No free lunch theorems for optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Wolpert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Macready</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">A model of inductive bias learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Baxter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="149" to="198" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<monogr>
		<title level="m" type="main">Interpretable machine learning: a guide for making black box models explainable. christophm.github.io/interpretable-ml-book</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Molnar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
