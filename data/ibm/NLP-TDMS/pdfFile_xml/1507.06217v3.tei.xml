<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Persistence Images: A Stable Vector Representation of Persistent Homology</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henry</forename><surname>Adams</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Mathematics</orgName>
								<orgName type="institution">Colorado State University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sofya</forename><surname>Chepushtanova</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Mathematics and Computer Science</orgName>
								<orgName type="institution">Wilkes University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tegan</forename><surname>Emerson</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Mathematics</orgName>
								<orgName type="institution">Colorado State University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Hanson</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Mathematics</orgName>
								<orgName type="institution">Texas Christian University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Kirby</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Mathematics</orgName>
								<orgName type="institution">Colorado State University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francis</forename><surname>Motta</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Department of Mathematics</orgName>
								<orgName type="institution">Duke University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rachel</forename><surname>Neville</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Mathematics</orgName>
								<orgName type="institution">Colorado State University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Peterson</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Mathematics</orgName>
								<orgName type="institution">Colorado State University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Shipman</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Mathematics</orgName>
								<orgName type="institution">Colorado State University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lori</forename><surname>Ziegelmeier</surname></persName>
							<affiliation key="aff4">
								<orgName type="department">Department of Mathematics, Statistics, and Computer Science</orgName>
								<orgName type="institution">Macalester College</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Persistence Images: A Stable Vector Representation of Persistent Homology</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T17:02+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>topological data analysis</term>
					<term>persistent homology</term>
					<term>persistence images</term>
					<term>machine learn- ing</term>
					<term>dynamical systems</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Many datasets can be viewed as a noisy sampling of an underlying space, and tools from topological data analysis can characterize this structure for the purpose of knowledge discovery. One such tool is persistent homology, which provides a multiscale description of the homological features within a dataset. A useful representation of this homological information is a persistence diagram (PD). Efforts have been made to map PDs into spaces with additional structure valuable to machine learning tasks. We convert a PD to a finite-dimensional vector representation which we call a persistence image (PI), and prove the stability of this transformation with respect to small perturbations in the inputs. The discriminatory power of PIs is compared against existing methods, showing significant performance gains. We explore the use of PIs with vector-based machine learning tools, such as linear sparse support vector machines, which identify features containing discriminating topological information. Finally, high accuracy inference of parameter values from the dynamic output of a discrete dynamical system (the linked twist map) and a partial differential equation (the anisotropic Kuramoto-Sivashinsky equation) provide a novel application of the discriminatory power of PIs.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In recent years, the field of topology has grown to include a large set of computational tools . One of the fundamental tools is persistent homology, which tracks how topological features appear and disappear in a nested sequence of topological spaces <ref type="bibr" target="#b20">(Edelsbrunner and Harer, 2008;</ref><ref type="bibr" target="#b52">Zomorodian and Carlsson, 2005)</ref>. This multiscale information can be represented as a persistence diagram (PD), a collection of points in the plane where each point (x, y) corresponds to a topological feature that appears at scale x and disappears at scale y. We say the feature has a persistence value of y − x. This compact summary of topological characteristics by finite multi-sets of points in the plane is responsible, in part, for the surge of interest in applying persistent homology to the analysis of complex, often high-dimensional data. Computational topology has been successfully applied to a broad range of data-driven disciplines <ref type="bibr" target="#b40">(Perea and Harer, 2013;</ref><ref type="bibr" target="#b16">Dabaghian et al., 2012;</ref><ref type="bibr" target="#b12">Chung et al., 2009;</ref><ref type="bibr" target="#b30">Heath et al., 2010;</ref><ref type="bibr" target="#b43">Singh et al., 2008;</ref><ref type="bibr" target="#b44">Topaz et al., 2015;</ref><ref type="bibr" target="#b39">Pearson et al., 2015)</ref>.</p><p>Concurrent with this revolution in computational topology, a growing general interest in data analysis has driven advances in data mining, pattern recognition, and machine learning (ML). Since the space of PDs can be equipped with a metric structure (bottleneck or Wasserstein <ref type="bibr" target="#b35">(Mileyko et al., 2011;</ref><ref type="bibr" target="#b45">Turner et al., 2014)</ref>), and since these metrics reveal the stability of PDs under small perturbations of the data they summarize <ref type="bibr" target="#b13">(Cohen-Steiner et al., 2007</ref><ref type="bibr" target="#b9">Chazal et al., 2014)</ref>, it is possible to perform a variety of ML techniques using PDs as a statistic for clustering data sets. However, many other useful ML tools and techniques (e.g. support vector machines (SVM), decision tree classification, neural networks, feature selection, and dimension reduction methods) require more than a metric structure. In addition, the cost of computing the bottleneck or Wasserstein distance grows quickly as the number of off-diagonal points in the diagrams increases <ref type="bibr" target="#b17">(Di Fabio and Ferri, 2015)</ref>. To resolve these issues, considerable effort has been made to map PDs into spaces which are suitable for other ML tools <ref type="bibr" target="#b5">(Bubenik, 2015;</ref><ref type="bibr" target="#b41">Reininghaus et al., 2015;</ref><ref type="bibr" target="#b2">Bendich et al., 2014;</ref><ref type="bibr" target="#b0">Adcock et al., 2013;</ref><ref type="bibr" target="#b18">Donatini et al., 1998;</ref><ref type="bibr" target="#b24">Ferri et al., 1997;</ref><ref type="bibr" target="#b12">Chung et al., 2009;</ref><ref type="bibr" target="#b37">Pachauri et al., 2011;</ref><ref type="bibr" target="#b3">Bendich et al., 2015;</ref><ref type="bibr" target="#b10">Chen et al., 2015;</ref><ref type="bibr" target="#b8">Carrière et al., 2015;</ref><ref type="bibr" target="#b17">Di Fabio and Ferri, 2015)</ref>. Each approach has benefits and drawbacks, which we review in §2. With these in mind, we are led to pose the following question:</p><p>Problem Statement: How can we represent a persistence diagram so that:</p><p>(i) the output of the representation is a vector in R n , (ii) the representation is stable with respect to input noise, (iii) the representation is efficient to compute, (iv) the representation maintains an interpretable connection to the original PD, and (v) the representation allows one to adjust the relative importance of points in different regions of the PD?</p><p>The main contribution of this paper is to provide a finite-dimensional-vector representation of a PD called a persistence image (PI). We first map a persistence diagram B to an integrable function ρ B : R 2 → R called a persistence surface. The surface ρ B is defined as a weighted sum of Gaussian functions 1 , one centered at each point in the PD. The idea of persistence surfaces has appeared even prior to the development of persistent homology, in <ref type="bibr" target="#b18">Donatini et al. (1998)</ref> and <ref type="bibr" target="#b24">Ferri et al. (1997)</ref>. Taking a discretization of a subdomain of ρ B defines a grid. A persistence image, i.e. a matrix of pixel values, can be created by computing the integral of ρ B on each grid box. This PI is a "vectorization" of the PD, and provides a solution to the problem statement above.</p><p>Criteria (i) is our primary motivation for developing PIs. A large suite of ML techniques and statistical tools (means and variances) already exist to work with data in R n . Additionally, such a representation allows for the use of various distance metrics (p-norms and angle based metrics) and other measures of (dis)similarity. The remaining criteria of the problem statement (ii-v) further ensure the usefulness of this representation.</p><p>The desired flexibility of (v) is accomplished by allowing one to build a PI as a weighted sum of Gaussians, where the weightings may be chosen from a broad class of weighting functions. 2 For example, a typical interpretation is that points in a PD of high persistence are more important than points of low persistence (which may correspond to noise). One may therefore build a PI as a weighted sum of Gaussians where the weighting function is non-decreasing with respect to the persistence value of each PD point. However, there are situations in which one may prefer different measures of importance. Indeed, <ref type="bibr" target="#b3">Bendich et al. (2015)</ref> find that, in their regression task of identifying a human brain's age from its arterial geometry, it is the points of medium persistence (not high persistence) that best distinguish the data. In such a setting, one may choose a weighting function with largest values for the points of medium persistence. In addition, the Homology Inference Theorem <ref type="bibr" target="#b13">(Cohen-Steiner et al., 2007)</ref> states that when given a sufficiently dense finite sample from a space X, it is the points in the PD with sufficiently small birth times (and sufficiently high persistence) which recover the homology groups of the space; hence one may choose a weighting function that emphasizes points near the death-axis and away from the diagonal, as indicated in the leftmost yellow rectangle of <ref type="bibr">Bendich (2009, Figure 2.4)</ref>. A potential disadvantage of the flexibility in (v) is that it requires a choice; however, prior knowledge of one's particular problem may inform that choice. Moreoever, our examples illustrate the effectiveness of a standard choice of weighting function that is non-decreasing with the persistence value.</p><p>The remainder of this article is organized as follows. Related work connecting topological data analysis and ML is reviewed in §2, and §3 gives a brief introduction to persistent homology, PDs from point cloud data, PDs from functions, and the bottleneck and Wasserstein metrics. PIs are defined in §4 and their stability with respect to the 1-Wasserstein distance between PDs is proved in §5. Lastly, §6 contains examples of ML techniques applied to PIs generated from samples of common topological spaces, an applied dynamical system modeling turbulent mixing, and a partial differential equation describing pattern formation in extended systems driven far from equilibrium. Our code for producing PIs is publicly available at https://github.com/CSU-TDA/ PersistenceImages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>The space of PDs can be equipped with the bottleneck or Wasserstein metric (defined in §3), and one reason for the popularity of PDs is that these metrics are stable with respect to small deviations in the inputs <ref type="bibr" target="#b13">(Cohen-Steiner et al., 2007</ref><ref type="bibr" target="#b9">Chazal et al., 2014)</ref>. Furthermore, the bottleneck metric allows one to define Fréchet means and variances for a collection of PDs <ref type="bibr" target="#b35">(Mileyko et al., 2011;</ref><ref type="bibr" target="#b45">Turner et al., 2014)</ref>. However, the structure of a metric space alone is insufficient for many ML techniques, and a recent area of interest in the topological data analysis community has been encoding PDs in ways that broaden the applicability of persistence. For example, <ref type="bibr" target="#b0">Adcock et al. (2013)</ref> study a ring of algebraic functions on the space of persistence diagrams, and <ref type="bibr" target="#b46">Verovšek (2016)</ref> identifies tropical coordinates on the space of diagrams. <ref type="bibr" target="#b23">Ferri and Landi (1999)</ref> and Di Fabio and Ferri (2015) encode a PD using the coefficients of a complex polynomial that has the points of the PD as its roots. <ref type="bibr" target="#b5">Bubenik (2015)</ref> develops the notion of a persistence landscape, a stable functional representation of a PD that lies in a Banach space. A persistence landscape (PL) is a function λ : N×R → [−∞, ∞], which can equivalently be thought of as a sequence of functions λ k : R → [−∞, ∞]. For 1 ≤ p ≤ ∞ the p-landscape distance between two landscapes λ and λ is defined as λ − λ p ; the ∞-landscape distance is stable with respect to the bottleneck distance on PDs, and the p-landscape distance is continuous with respect to the p-Wasserstein distance on PDs. One of the motivations for defining persistence landscapes is that even though Fréchet means of PDs are not necessarily unique <ref type="bibr" target="#b35">(Mileyko et al., 2011)</ref>, a set of persistence landscapes does have a unique mean. Unique means are also a feature of PIs as they are vector representations. An advantage of PLs over PIs is that the map from a PD to a PL is easily invertible; an advantage of PIs over PLs is that PIs live in Euclidean space and hence are amenable to a broader range of ML techniques. In §6, we compare PDs, PLs, and PIs in a classification task on synthetic data sampled from common topological spaces. We find that PIs behave comparably or better than PDs when using ML techniques available to both representations, but PIs are significantly more efficient to compute. Also, PIs outperform PLs in the majority of the classification tasks and are of comparable computational efficiency.</p><p>A vector representation of a PD, due to <ref type="bibr" target="#b8">Carrière et al. (2015)</ref>, can be obtained by rearranging the entries of the distance matrix between points in a PD. In their Theorem 3.2, they prove that both the L ∞ and L 2 norms between their resulting vectors are stable with respect to the bottleneck distance on PDs. They remark that while the L ∞ norm is useful for nearest-neighbor classifiers, the L 2 norm allows for more elaborate algorithms such as SVM. However, though their stability result for the L ∞ norm is well-behaved, their constant for the L 2 norm scales undesirably with the number of points in the PD. We provide this as motivation for our Theorem 4, in which we prove the L ∞ , L 1 , and L 2 norms for PI vectors are stable with respect to the 1-Wasserstein distance between PDs, and in which none of the constants depend on the number of points in the PD.</p><p>By superimposing a grid over a PD and counting the number of topological features in each bin, <ref type="bibr" target="#b2">Bendich et al. (2014)</ref> create a feature vector representation. An advantage of this approach is that the output is easier to interpret than other more complicated representations, but a disadvantage is that the vectors are not stable for two reasons:</p><p>(i) an arbitrarily small movement of a point in a PD may move it to another bin, and (ii) a PD point emerging from the diagonal creates a discontinuous change.</p><p>Source (i) of instability can be improved by first smoothing a PD into a surface. This idea has appeared multiple times in various forms -even prior to the development of persistent homology, <ref type="bibr" target="#b18">Donatini et al. (1998)</ref> and <ref type="bibr" target="#b24">Ferri et al. (1997)</ref> convert size functions (closely related to 0-dimensional PDs) into surfaces by taking a sum of Gaussians centered on each point in the diagram. This conversion is not stable due to (ii), and we view our work as a continued study of these surfaces, now also in higher homological dimensions, in which we introduce a weighting function 3 to address (ii) and obtain stability. <ref type="bibr" target="#b12">Chung et al. (2009)</ref> produce a surface by convolving a PD with the characteristic function of a disk, and <ref type="bibr" target="#b37">Pachauri et al. (2011)</ref> produce a surface by centering a Gaussian on each point, but both of these methods lack stability again due to (ii). Surfaces produced from random PDs are related to the empirical intensity plots of <ref type="bibr" target="#b21">Edelsbrunner et al. (2012)</ref>. <ref type="bibr" target="#b41">Reininghaus et al. (2015)</ref> produce a stable surface from a PD by taking the sum of a positive Gaussian centered on each PD point together with a negative Gaussian centered on its reflection below the diagonal; the resulting surface is zero along the diagonal. This approach is similar to ours, and indeed we use <ref type="bibr">(Reininghaus et al., 2015, Theorem 3)</ref> to show that our persistence surfaces are stable only with respect to the 1-Wasserstein distance (Remark 1). Nevertheless, we propose our independently-developed surfaces as an alternative stable representation of PDs with the following potential advantages. First, our sum of non-negatively weighted Gaussians may be easier to interpret than a sum including negative Gaussians. Second, we produce vectors from our surfaces with well-behaved stability bounds, allowing one to use vector-based learning methods such as linear SVM. Indeed, <ref type="bibr" target="#b49">Zeppelzauer et al. (2016)</ref> report that while the kernel of <ref type="bibr" target="#b41">Reininghaus et al. (2015)</ref> can be used with nonlinear SVMs, in practice this becomes inefficient for a large number of training vectors because the entire kernel matrix must be computed. Third, while the surface of <ref type="bibr" target="#b41">Reininghaus et al. (2015)</ref> weights persistence points further from the diagonal more heavily, there are situations in which one may prefer different weightings, as discussed in §1 and item (v) of our Problem Statement. Hence, one may want weightings on PD points that are non-increasing or even decreasing when moving away from the diagonal, an option available in our approach.</p><p>We produce a persistence surface from a PD by taking a weighted sum of Gaussians centered at each point. We create vectors, or PIs, by integrating our surfaces over a grid, allowing ML techniques for finite-dimensional vector spaces to be applied to PDs. Our PIs are stable, and distinct homology dimensions may be concatenated together into a single vector to be analyzed simultaneously. Our surfaces are studied from the statistical point of view by <ref type="bibr" target="#b10">Chen et al. (2015)</ref>, who cite a preprint version of our work; their applications in Section 4 use the L 1 norm between these surfaces, which can be justified as a reasonable notion of distance due to our Theorem 3 that proves the L 1 distance between such surfaces is stable. <ref type="bibr" target="#b49">Zeppelzauer et al. (2016)</ref> apply persistent images to 3D surface analysis for archeological data, in which the machine learning task is to distinguish scans of natural rock surfaces from those containing ancient human-made engravings. The authors state they select PIs over other topological methods because PIs are computationally efficient and can be used with a broader set of ML techniques. PIs are compared to an aggregate topological descriptor for a persistence diagram: the first entry of this vector is the number of points in the diagram, and the remaining entries are the minimum, maximum, mean, standard deviation, variance, 1st-quartile, median, 3rd-quartile, sum of square roots, sum, and sum of squares of all the persistence values. In their three experiments, the authors find the following.</p><p>• When classifying natural rock surfaces from engravings using persistent diagrams produced from the sublevel set filtration, PIs outperform the aggregate descriptor.</p><p>• When the natural rock and engraved surfaces are first preprocessed using the completed local binary pattern (CLBP) operator for texture classificiation <ref type="bibr" target="#b28">(Guo et al., 2010)</ref>, PIs outperform the aggregate descriptor.</p><p>• The authors added PIs and the aggregate descriptor to eleven different non-topological baseline descriptors, and found that the classification accuracy of the baseline descriptor was improved more by the addition of PIs than by the addition of the aggregate descriptor.</p><p>Furthermore, <ref type="table">Table 1</ref> of <ref type="bibr" target="#b49">Zeppelzauer et al. (2016)</ref> demonstrates that for their machine learning task, PIs have low sensitivity to the parameter choices of resolution and variance ( §4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Background on Persistent Homology</head><p>Homology is an algebraic topological invariant that, roughly speaking, describes the holes in a space. The k-dimensional holes (connected components, loops, trapped volumes, etc.) of a topological space X are encoded in an algebraic structure called the k-th homology group of X, denoted H k (X). The rank of this group is referred to as the k-th Betti number, β k , and counts the number of independent k-dimensional holes. For a comprehensive study of homology, see <ref type="bibr" target="#b29">Hatcher (2002)</ref>. Given a nested sequence of topological spaces X 1 ⊆ X 2 ⊆ . . . ⊆ X n , the inclusion X i ⊆ X i for i ≤ i induces a linear map H k (X i ) → H k (X i ) on the corresponding k-th homology for all k ≥ 0. The idea of persistent homology is to track elements of H k (X i ) as the scale (or "time") parameter i increases <ref type="bibr" target="#b20">(Edelsbrunner and Harer, 2008;</ref><ref type="bibr" target="#b52">Zomorodian and Carlsson, 2005;</ref>. A standard way to represent persistent homology information is a persistence diagram (PD) 4 , which is a multiset of points in the Cartesian plane R 2 . For a fixed choice of homological dimension k, each homological feature is represented by a point (x, y), whose birth and death indices x and y are the scale parameters at which that feature first appears and disappears, respectively. Since all topological features die after they are born, necessarily each point appears on or above the diagonal line y = x. A PD is a multiset of such points, as distinct topological features may have the same birth and death coordinates. 5 Points near the diagonal are often considered to be noise while those further from the diagonal represent more robust topological features.</p><p>In this paper, we produce PDs from two different types of input data:</p><p>(i) When our data is a a point cloud, i.e. a finite set of points in some space, then we produce PDs using Vietoris-Rips filtration.</p><p>(ii) When our data is a real-valued function, then we produce PDs using the sublevel set filtration. 6</p><p>For setting (i), point cloud data often comes equipped with a metric or a measure of internal similarity and is rich with latent geometric content. One approach to identifying geometric shapes in data is to consider the dataset as the vertices of a simplicial complex and to add edges, triangles, tetrahedra, and higher-dimensional simplices whenever their diameter is less than a fixed choice of scale. This topological space is called the Vietoris-Rips simplicial complex, which we introduce in more detail in §A.2. The homology of the Vietoris-Rips complex depends crucially on the choice of scale, but persistent homology eliminates the need for this choice by computing homology over a range of scales <ref type="bibr" target="#b7">(Carlsson, 2009;</ref><ref type="bibr" target="#b26">Ghrist, 2008)</ref>. In §6.1-6.4.1, we obtain PDs from point cloud data using the Vietoris-Rips filtered simplicial complex, and we use ML techniques to classify the point clouds by their topological features. In setting (ii), our input is a real valued function f : X → R defined on some domain X. One way to understand the behavior of map f is to understand the topology of its sublevel sets f −1 ((−∞, ]). By letting increase, we obtain an increasing sequence of topological spaces, called the sublevel set filtration, which we introduce in more detail in §A.3. In §6.4.2, we obtain PDs from surfaces u : [0, 1] 2 → R produced from the Kuramoto-Sivashinsky equation, and we use ML techniques to perform parameter classification.</p><p>In both settings the output of the persistent homology computation is a collection of PDs encoding homological features of the data across a range of scales. Let D denote the set of all PDs. The space D can be endowed with metrics as studied by <ref type="bibr" target="#b13">Cohen-Steiner et al. (2007)</ref> and <ref type="bibr" target="#b35">Mileyko et al. (2011)</ref>. The p-Wasserstein distance defined between two PDs B and B is given by </p><formula xml:id="formula_0">W p (B, B ) = inf γ:B→B u∈B ||u − γ(u)|| p ∞ 1/p , where 1 ≤ p &lt; ∞</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Persistence Images</head><p>We propose a method for converting a PD into a vector while maintaining an interpretable connection to the original PD. <ref type="figure" target="#fig_1">Figure 1</ref> illustrates the pipeline from data to PI starting with spectral and spatial information in R 5 from an immunofluorescent image of a circulating tumor cell <ref type="bibr" target="#b22">(Emerson et al., 2015)</ref>.</p><formula xml:id="formula_1">Precisely, let B be a PD in birth-death coordinates 7 . Let T : R 2 → R 2 be the linear transforma- tion T (x, y) = (x, y−x), and let T (B) be the transformed multiset in birth-persistence coordinates 8 , where each point (x, y) ∈ B corresponds to a point (x, y − x) ∈ T (B). Let φ u : R 2 → R be a differ- entiable probability distribution with mean u = (u x , u y ) ∈ R 2 .</formula><p>In all of our applications, we choose this distribution to be the normalized symmetric Gaussian φ u = g u with mean u and variance σ 2 defined as</p><formula xml:id="formula_2">g u (x, y) = 1 2πσ 2 e −[(x−ux) 2 +(y−uy) 2 ]/2σ 2 .</formula><p>Fix a nonnegative weighting function f : R 2 → R that is zero along the horizontal axis, continuous, and piecewise differentiable. With these ingredients we transform the PD into a scalar function over the plane.</p><formula xml:id="formula_3">Definition 1. For B a PD, the corresponding persistence surface ρ B : R 2 → R is the function ρ B (z) = u∈T (B) f (u)φ u (z).</formula><p>The weighting function f is critical to ensure the transformation from a PD to a persistence surface is stable, which we prove in §5.</p><p>Finally, the surface ρ B (z) is reduced to a finite-dimensional vector by discretizing a relevant subdomain and integrating ρ B (z) over each region in the discretization. In particular, we fix a grid in the plane with n boxes (pixels) and assign to each the integral of ρ B over that region. PIs provide a convenient way to combine PDs of different homological dimensions into a single object. Indeed, suppose in an experiment the PDs for H 0 , H 1 , . . . , H k are computed. One can concatenate the PI vectors for H 0 , H 1 , . . . , H k into a single vector representing all homological dimensions simultaneously, and then use this concatenated vector as input into ML algorithms.</p><formula xml:id="formula_4">Definition 2. For B a PD, its persistence image is the collection of pixels I(ρ B ) p =˜p ρ B dydx.</formula><p>There are three choices the user makes when generating a PI: the resolution, the distribution (and its associated parameters), and the weighting function.</p><p>Resolution of the image: The resolution of the PI corresponds to the grid being overlaid on the PD. The classification accuracy in the PI framework appears to be fairly robust to choice of resolution, as discussed in §6.2 and <ref type="bibr" target="#b49">(Zeppelzauer et al., 2016)</ref>.</p><p>The Distribution: Our method requires the choice of a probability distribution which is associated to each of the points in the PD. The examples in this paper use a Gaussian centered at each point, but other distributions may be used. The Gaussian distribution depends on a choice of variance: we leave this choice as an open problem, though the experiments in §6.2 and <ref type="bibr" target="#b49">(Zeppelzauer et al., 2016)</ref> show a low sensitivity to the choice of variance.</p><p>The Weighting Function: In order for our stability results in §5 to hold, our weighting function f : R 2 → R must be zero along the horizontal axis (the analogue of the diagonal in birthpersistence coordinates), continuous, and piecewise differentiable. A simple choice is a weighting function that depends only on the vertical persistence coordinate y. In order to weight points of higher persistence more heavily, functions which are nondecreasing in y, such as sigmoidal functions, are a natural choice. However, in certain applications such as <ref type="bibr" target="#b3">Bendich et al. (2015)</ref> it may be points of small or medium persistence that perform best for ML tasks, and hence, one may choose to use more general weighting functions. In our experiments in §6, we use a piecewise linear weighting function f : R 2 → R which only depends on the persistence coordinate y. Given b &gt; 0, define</p><formula xml:id="formula_5">w b : R → R via w b (t) =      0 if t ≤ 0, t b if 0 &lt; t &lt; b, and 1 if t ≥ b.</formula><p>We use f (x, y) = w b (y), where b is the persistence value of the most persistent feature in all trials of the experiment.</p><p>In the event that the birth coordinate is zero for all points in the PD, as is often the case for H 0 , it is possible to generate a 1-dimensional (instead of 2-dimensional) PI using 1-dimensional distributions. This is the approach we adopt. Appendix B displays examples of PIs for the common topological spaces of a circle and a torus with various parameter choices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Stability of Persistence Surfaces and Images</head><p>Due to the unavoidable presence of noise or measurement error, tools for data analysis ought to be stable with respect to small perturbations of the inputs. Indeed, one reason for the popularity of PDs in topological data analysis is that the transformation of a data set to a PD is stable (Lipschitz) with respect to the bottleneck metric and -given some mild assumptions about the underlying data -is also stable with respect to the Wasserstein metrics ). In §5.1, we show that persistence surfaces and images are stable with respect to the 1-Wasserstein distance between PDs. In §5.2, we prove stability with improved constants when the PI is constructed using the Gaussian distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Stability for general distributions</head><p>For h : R 2 → R differentiable, define |∇h| = sup z∈R 2 ∇h(z) 2 to be the maximal norm of the gradient vector of h, i.e. the largest directional derivative of h. It follows by the fundamental theorem of calculus for line integrals that for all u, v ∈ R 2 , we have</p><formula xml:id="formula_6">|h(u) − h(v)| ≤ |∇h| u − v 2 .<label>(1)</label></formula><p>We may safely denote |∇φ u | by |∇φ| and φ u ∞ by φ ∞ since the maximal directional derivative and supremum of a fixed differentiable probability distribution are invariant under translation.</p><formula xml:id="formula_7">Note that φ u − φ v ∞ ≤ |∇φ| u − v 2 (2) since for any z ∈ R 2 we have |φ u (z) − φ v (z)| = |φ u (z) − φ u (z + u − v)| ≤ |∇φ| u − v 2 .</formula><p>Recall that our nonnegative weighting function f : R 2 → R is defined to be zero along the horizontal axis, continuous, and piecewise differentiable.</p><formula xml:id="formula_8">Lemma 1. For u, v ∈ R 2 , we have f (u)φ u − f (v)φ v ∞ ≤ f ∞ |∇φ| + φ ∞ |∇f | u − v 2 . Proof. For any z ∈ R 2 , we have |f (u)φ u (z) − f (v)φ v (z)| = f (u) φ u (z) − φ v (z) + f (u) − f (v) φ v (z) ≤ f ∞ |φ u (z) − φ v (z)| + φ ∞ |f (u) − f (v)| ≤ f ∞ |∇φ| u − v 2 + φ ∞ |∇f | u − v 2</formula><p>by <ref type="formula">(2) and</ref> (1)</p><formula xml:id="formula_9">= f ∞ |∇φ| + φ ∞ |∇f | u − v 2 .</formula><p>Theorem 1. The persistence surface ρ is stable with respect to the 1-Wasserstein distance between diagrams: for B, B ∈ D we have</p><formula xml:id="formula_10">ρ B − ρ B ∞ ≤ √ 10 f ∞ |∇φ| + φ ∞ |∇f | W 1 (B, B ).</formula><p>Proof. Since we assume B and B consist of finitely many points, there exists a matching γ that achieves the infimum in the Wasserstein distance. Then</p><formula xml:id="formula_11">ρ B − ρ B ∞ = u∈T (B) f (u)φ u − u∈T (B) f (γ(u))φ γ(u) ∞ ≤ u∈T (B) f (u)φ u − f (γ(u))φ γ(u) ∞ ≤ f ∞ |∇φ| + φ ∞ |∇f | u∈T (B) u − γ(u) 2 by Lemma 1. ≤ √ 2 f ∞ |∇φ| + φ ∞ |∇f | u∈T (B) u − γ(u) ∞ since · 2 ≤ √ 2 · ∞ in R 2 ≤ √ 10 f ∞ |∇φ| + φ ∞ |∇f | u∈B u − γ(u) ∞ since T (·) 2 ≤ √ 5 · ∞ = √ 10 f ∞ |∇φ| + φ ∞ |∇f | W 1 (B, B ).</formula><p>It follows that persistence images are also stable.</p><p>Theorem 2. The persistence image I(ρ B ) is stable with respect to the 1-Wasserstein distance between diagrams. More precisely, if A is the maximum area of any pixel in the image, A is the total area of the image, and n is the number of pixels in the image, then</p><formula xml:id="formula_12">I(ρ B ) − I(ρ B ) ∞ ≤ √ 10A f ∞ |∇φ| + φ ∞ |∇f | W 1 (B, B ) I(ρ B ) − I(ρ B ) 1 ≤ √ 10A f ∞ |∇φ| + φ ∞ |∇f | W 1 (B, B ) I(ρ B ) − I(ρ B ) 2 ≤ √ 10nA f ∞ |∇φ| + φ ∞ |∇f | W 1 (B, B ).</formula><p>The constant for the L 2 norm bound containing √ n goes to infinity as the resolution of the image increases. For this reason, in Theorem 4 we provide bounds with better constants in the specific case of Gaussian distributions.</p><p>Proof. Note for any pixel p with area A(p) we have</p><formula xml:id="formula_13">|I(ρ B ) p − I(ρ B ) p | = ¨p ρ B dydz −¨p ρ B dydx = ¨p ρ B − ρ B dydx ≤ A(p) ρ B − ρ B ∞ ≤ √ 10A(p) f ∞ |∇φ| + φ ∞ |∇f | W 1 (B, B )</formula><p>by Theorem 1.</p><p>Hence we have</p><formula xml:id="formula_14">I(ρ B ) − I(ρ B ) ∞ ≤ √ 10A f ∞ |∇φ| + φ ∞ |∇f | W 1 (B, B ) I(ρ B ) − I(ρ B ) 1 ≤ √ 10A f ∞ |∇φ| + φ ∞ |∇f | W 1 (B, B ) I(ρ B ) − I(ρ B ) 2 ≤ √ n I(ρ B ) − I(ρ B ) ∞ ≤ √ 10nA f ∞ |∇φ| + φ ∞ |∇f | W 1 (B, B ). Remark 1. Recall D is the set of all PDs. The kernel k : D × D → R defined by k(B, B ) = I(ρ B ), I(ρ B )</formula><p>R n is non-trivial and additive, and hence Theorem 3 of <ref type="bibr" target="#b41">Reininghaus et al. (2015)</ref> implies that k is not stable with respect to W p for any</p><formula xml:id="formula_15">1 &lt; p ≤ ∞. That is, when 1 &lt; p ≤ ∞ there is no constant c such that for all B, B ∈ D we have I(ρ B ) − I(ρ B ) 2 ≤ cW p (B, B ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Stability for Gaussian distributions</head><p>In this section, we provide stability results with better constants in the case of Gaussian distributions. With Gaussian distributions we can control not only the L ∞ distance but also the L 1 distance between two persistence surfaces.</p><p>Our results for 2-dimensional Gaussians will rely on the following lemma for 1-dimensional Gaussians.</p><formula xml:id="formula_16">Lemma 2. For u, v ∈ R, let g u , g v : R → R be the normalized 1-dimensional Gaussians, defined via g u (z) = 1 σ √ 2π e −(z−u) 2 /2σ 2 . If a, b &gt; 0, then ag u − bg v 1 ≤ |a − b| + 2 π min{a, b} σ |u − v|. Proof. Let Erf(t) = 2 √ π´t 0 e −u 2 du. We show in Appendix C that ag u − bg v 1 = F (v − u),<label>(3)</label></formula><p>where F : R → R is defined by</p><formula xml:id="formula_17">F (z) = |a − b| if z = 0 aErf z 2 +2σ 2 ln(a/b) zσ2 √ 2 − bErf −z 2 +2σ 2 ln(a/b) zσ2 √ 2</formula><p>otherwise.</p><p>Furthermore, function F is differentiable for z = 0. By searching for real roots of F , one can show</p><formula xml:id="formula_18">F ∞ = 2 π min{a, b} σ , and hence F (z) ≤ |a − b| + 2 π min{a, b} σ |z|.</formula><p>The result follows by letting z = v − u.</p><formula xml:id="formula_19">Lemma 3. For u, v ∈ R 2 , let g u , g v : R 2 → R be normalized 2-dimensional Gaussians. Then f (u)g u − f (v)g v 1 ≤ |∇f | + 2 π min{f (u), f (v)} σ u − v 2 .</formula><p>The proof of Lemma 3 is shown in Appendix C and uses a similar construction to that of Lemma 2. We are prepared to prove the stability of persistence surfaces with Gaussian distributions.</p><p>Theorem 3. The persistence surface ρ with Gaussian distributions is stable with respect to the 1-Wasserstein distance between diagrams: for B, B ∈ D we have <ref type="figure">B, B )</ref>.</p><formula xml:id="formula_20">ρ B − ρ B 1 ≤ √ 5|∇f | + 10 π f ∞ σ W 1 (</formula><p>Proof. Since we assume B and B consist of finitely many off-diagonal points, there exists a matching γ that achieves the infimum in the Wasserstein distance. Then</p><formula xml:id="formula_21">ρ B − ρ B 1 = u∈T (B) f (u)g u − u∈T (B) f (γ(u))g γ(u) 1 ≤ u∈T (B) f (u)g u − f (γ(u))g γ(u) 1 ≤ |∇f | + 2 π f ∞ σ u∈T (B) u − γ(u) 2 by Lemma 3, where min{f (u), f (v)} ≤ f ∞ ≤ √ 5|∇f | + 10 π f ∞ σ u∈B u − γ(u) ∞ since T (·) 2 ≤ √ 5 · ∞ = √ 5|∇f | + 10 π f ∞ σ W 1 (B, B ).</formula><p>It follows that persistence images are also stable.</p><p>Theorem 4. The persistence image I(ρ B ) with Gaussian distributions is stable with respect to the 1-Wasserstein distance between diagrams. More precisely,</p><formula xml:id="formula_22">I(ρ B ) − I(ρ B ) 1 ≤ √ 5|∇f | + 10 π f ∞ σ W 1 (B, B ) I(ρ B ) − I(ρ B ) 2 ≤ √ 5|∇f | + 10 π f ∞ σ W 1 (B, B ) I(ρ B ) − I(ρ B ) ∞ ≤ √ 5|∇f | + 10 π f ∞ σ W 1 (B, B ).</formula><p>Proof. We have</p><formula xml:id="formula_23">I(ρ B ) − I(ρ B ) 1 = p ¨p ρ B dydz −¨p ρ B dydx ≤¨R 2 |ρ B − ρ B | dydz = ρ B − ρ B 1 ≤ √ 5|∇f | + 10 π f ∞ σ W 1 (B, B )</formula><p>by Theorem 3. The claim follows since · 2 ≤ · 1 and · ∞ ≤ · 1 for vectors in R n .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiments</head><p>In order to assess the addded value of our vector representation of PDs, we compare the performance of PDs, PLs, and PIs in §6.1 in a classification task for a synthetic data set consisting of point clouds sampled from six different topological spaces using K-medoids, which utilizes only the internal dissimilarities of each of the topological data descriptions to classify. We find that PIs produce consistently high classification accuracy and, furthermore, the computation time for PIs is significantly faster than computing bottleneck or Wasserstein distances between PDs. In §6.2, we explore the impact that the choices of parameters determining our PIs have on classification accuracy. We find that the accuracy is insensitive to the particular choices of PI resolution and distribution variance. In §6.3, we combine PIs with a sparse support vector machine classifier to identify the most strongly differentiating pixels for classification; this is an example of a ML task which is facilitated by the fact that PIs are finite vectors. Finally, as a novel machine learning application, we illustrate the utility of PIs to infer dynamical parameter values in both continuous and discrete dynamical systems: a discrete time system called the linked twist map in §6.4.1, and a partial differential equation called the anisotropic Kuramoto-Sivashinsky equation in §6.4.2.</p><p>6.1 Comparison of PDs, PLs, and PIs using K-medoids Classification</p><p>Our synthetic dataset consists of six shape classes: a solid cube, a circle, a sphere, three clusters, three clusters within three clusters, and a torus. Given a level of Gaussian random noise, we produce 25 point clouds of 500 randomly sampled noisy points from each of the six shapes; giving 150 point clouds in total. We then compute the H 0 and H 1 PDs for the Vietoris-Rips filtration ( §A.2) built from each point cloud which have been endowed with the ambient Euclidean metric on R 3 . Our goal is to compare various methods for transforming PDs into distance matrices to be used to establish proximity of topological features extracted from data. We create 3 2 · 2 2 = 36 distance matrices of size 150 × 150, using three choices of representation (PDs, PLs, PIs), three choices of metric (L 1 , L 2 , L ∞ ) 9 , two choices of Gaussian noise (η = 0.05, 0.1), and two homological dimensions (H 0 , H 1 ). For example, the PD, H 1 , L 2 , η = 0.1, distance matrix contains the 2-Wasserstein distances between the H 1 PDs for the random point clouds with noise level 0.1. By contrast, the PI, H 1 , L 2 , η = 0.1 distance matrix contains all pairwise L 2 distances between the PIs 10 produced from the H 1 PDs with noise level 0.1.</p><p>We first compare these distance matrices based on how well they classify the random point clouds into shape classes via K-medoids clustering <ref type="bibr" target="#b33">(Kaufman and Rousseeuw, 1987;</ref><ref type="bibr" target="#b38">Park and Jun, 2009</ref>). K-medoids produces a partition of a metric space into K clusters by choosing K points from the dataset called medoids and assigning each metric space point to its closest medoid. The score of such a clustering is the sum of the distances from each point to its closest medoid. The desired output of K-medoids is the clustering with the minimal clustering score. Unfortunately, an exhaustive search for the global minimum is often prohibitively expensive. A typical approach to search for this global minimum is to choose a large selection of K random initial medoids, improve each selection of medoids iteratively in rounds until the clustering score stabilizes and then return the identified final clustering with the lowest score for each initialization. In our experiments, we choose 1,000 random initial selections of K = 6 medoids (as there are six shape classes) for each distance matrix, improve each selection of medoids using the Voronoi iteration method <ref type="bibr" target="#b38">(Park and Jun, 2009)</ref>, and return the clustering with the lowest classification score. To each K-medoids clustering we assign an accuracy which is equal to the percentage of random point clouds identifed with a medoid of the same shape class. In <ref type="table">Table 1</ref>, we report the classification accuracy of the K-medoids clustering with the lowest clustering score, for each distance matrix.</p><p>Our second criterion for comparing methods to produce distance matrices is computational efficiency. In <ref type="table">Table 1</ref>, we report the time required to produce each distance matrix, starting with 150 precomputed PDs as input. In the case of PLs and PIs, this time includes the intermediate step of transforming each PD into the alternate representation, as well as computing the pairwise distance matrix. All timings are computed on a laptop with a 1.3 GHz Intel Core i5 processor and 4 GB of memory. We compute bottleneck, 1-Wasserstein, and 2-Wasserstein distance matrices using the software of <ref type="bibr" target="#b34">Kerber et al. (2016)</ref>. For PL computations, we use the Persistence Landscapes Toolbox by <ref type="bibr" target="#b6">Bubenik and Dlotko (2016)</ref>. Our MATLAB code for producing PIs is publically available at https://github.com/CSU-TDA/PersistenceImages. <ref type="table">Table 1</ref>: Comparing classification accuracy and times of PDs, PLs, and PIs. The timings contain the computation time in seconds for producing a 150 × 150 distance matrix from 150 precomputed PDs. In the case of PLs and PIs, this requires first transforming each PD into its alternate representation and then computing a distance matrix. We consider 36 distinct distance matrices: three representations (PDs, PLs, PIs), two homological dimensions (H 0 , H 1 ), three choices of metric (L 1 , L 2 , L ∞ ), and two levels of Gaussian noise (η = 0.05, 0.1). We see in <ref type="table">Table 1</ref> that PI distance matrices have higher classification accuracy than nearly every PL distance matrix, and higher classification accuracy than PDs in half of the trials. Furthermore, the computation times for PI distance matrices are significantly lower than the time required to produce distance matrices from PDs using the bottleneck or p-Wasserstein metrics. In this experiment, persistent images provide a representation of persistent diagrams which is both useful for the classification task and also computationally efficient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Distance Matrix</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Effect of PI Parameter Choice</head><p>In any system that relies on multiple parameters, it is important to understand the effect of parameter values on the system. As such, we complete a search of the parameter space used to generate PIs on the shape dataset described in §6.1 and measure K-medoids classification accuracy as a function of the parameters. We explore 20 different resolutions (ranging from 5 × 5 to 100 × 100 in increments of 5), use a Gaussian function with 20 different choices of variance (ranging from 0.01 to 0.2 in increments of 0.01), and the weighting function described in §4. For each set of parameters, we compute the classification accuracy of the K-medoids clustering with the minimum clustering score on the two sets of noise levels for the homology dimensions H 0 and H 1 . We observe that the classification accuracy is insensitive to the choice of resolution and variance. The plots in <ref type="figure" target="#fig_2">Figure 2</ref> are characteristic of the 2-dimensional accuracy surface over all combinations of parameters in the ranges of variances and resolutions we tested. In an application to archeology, <ref type="bibr" target="#b49">Zeppelzauer et al. (2016)</ref> find a similar robustness of PIs to the choices of resolution and variance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Differentiating Homological Features by Sparse Support Vector Machine</head><p>The 1-norm regularized linear support vector machine (SVM), a.k.a. sparse SVM (SSVM) classifies data by generating a separating hyperplane that depends on very few input space features <ref type="bibr" target="#b4">(Bradley and Mangasarian, 1998;</ref><ref type="bibr" target="#b51">Zhu et al., 2004;</ref><ref type="bibr" target="#b50">Zhang and Zhou, 2010)</ref>. Such a model can be used for reducing data dimension or selecting discriminatory features. Note that linear SSVM feature selection is implemented on vectors and, therefore, can be used on our PIs to select discriminatory pixels during classification. Other PD representations in the literature <ref type="bibr" target="#b41">(Reininghaus et al., 2015;</ref><ref type="bibr" target="#b37">Pachauri et al., 2011)</ref> are designed to use kernel ML methods, such as kernel (nonlinear) SVMs. However, constructing kernel SVM classifiers using the 1-norm results in minimizing the number of kernel functions, not the number of features in the input space (i.e. pixels in our application) <ref type="bibr" target="#b25">(Fung and Mangasarian, 2004)</ref>. Hence, for the purpose of feature selection or, more precisely, PI pixel selection, we employ the linear SSVM. We adopt the one-against-all (OAA) SSVM on the sets of H 0 and H 1 PIs from the six class shape data. In a one-against-all SSVM, there is one binary SSVM for each class to separate members of that class from members of all other classes. The PIs were generated using resolution 20 × 20, variance 0.0001, and noise level 0.05. Note that because of the resolution parameter choice of 20 × 20, each PI is a 400-dimensional vector, and the selected features will be a subset of indices corresponding to pixels within the PI. Using 5-fold cross-validated SSVM resulted in 100% accuracy comparing six sparse models with indications of the discriminatory features. Feature selection is performed by retaining the features (again, in this application, pixels) with non-zero SSVM weights, determined by magnitude comparison using weight ratios; for details see <ref type="bibr" target="#b11">Chepushtanova et al. (2014)</ref>. <ref type="figure" target="#fig_3">Figure 3</ref> provides two examples, indicating the pixels of H 1 PIs that discriminate circles and tori from the other classes in the synthetic data set. Feature selection produces highly interpretable results. The discriminatory pixels in the H 1 PIs that separate circles from the other classes correspond to the region where highly persistent H 1 topological features exist across all samples of a noisy circle (highlighted in <ref type="figure" target="#fig_3">Figure 3a</ref>). Alternatively, the discriminatory pixels in H 1 PIs that separate tori from the other classes correspond to points of short to moderate persistence (see <ref type="figure" target="#fig_3">Figure 3b</ref>). In this way, <ref type="figure" target="#fig_3">Figure 3b</ref> reiterates an observation of <ref type="bibr" target="#b3">Bendich et al. (2015)</ref> that points of short to moderate persistence can contain important discriminatory information. Similar conclusions can be drawn from the discriminatory pixels of others classes (Appendix D). Our classification accuracy of 100% is obtained using only those pixels selected by SSVM (a cumulative set of only 10 distinct pixels).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(a) (b)</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Application: Determination of Dynamical System Parameters</head><p>Models of dynamic physical phenomenon rarely agree perfectly with the reality they represent. This is often due to the presence of poorly-resolved (or poorly-understood) processes which are parameterized rather than treated explicitly. As such, determination of the influence of a model parameter -which may itself be an incompletely-described conglomeration of several physical parameters -on model dynamics is a mainstay of dynamical system analysis. In the case of fitting a dynamic model to data, i.e. explicit determination of optimal model parameters, a variety of techniques exist for searching through parameter space, which often necessitate costly simulations. Furthermore, such approaches struggle when applied to models exhibiting sensitivity to initial conditions. We recast this problem as a machine-learning exercise based on the hypotheses that model parameters will be reflected directly in dynamic data in a way made accessible by persistent homology.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4.1">A discrete dynamical model</head><p>We approach a classification problem with data arising from the linked twist map, a discrete dynamical system modeling fluid flow. <ref type="bibr" target="#b31">Hertzsch et al. (2007)</ref> use the linked twist map to model flows in DNA microarrays with a particular interest in understanding turbulent mixing. This demonstrates a primary mechanism giving rise to chaotic advection. The linked twist map is a Poincaré section of eggbeater-type flow <ref type="bibr" target="#b31">(Hertzsch et al., 2007)</ref> in continuous dynamical systems. The Poincaré section captures the behavior of the flow by viewing a particle's location at discrete time intervals. The linked twist map is given by the discrete dynamical system</p><formula xml:id="formula_24">x n+1 = x n + ry n (1 − y n ) mod 1 y n+1 = y n + rx n (1 − x n ) mod 1,</formula><p>where r is a positive parameter. For some values of r, the orbits {(x n , y n ) : n = 0, . . . , ∞} are dense in the domain. However, for other parameter values, voids form. In either case, the truncated orbits {(x n , y n ) : n = 0, . . . , N ∈ N} exhibit complex structure.</p><p>For this experiment, we choose a set of parameter values, r = 2.5, 3.5, 4.0, 4.1 and 4.3, which produce a variety of orbit patterns. For each parameter value, 50 randomly-chosen initial conditions are selected, and 1000 iterations of the linked twist map are used to generate point clouds in R 2 . <ref type="figure" target="#fig_4">Figure 4</ref> shows examples of typical orbits generated for each parameter value. The goal is to classify the trials by parameter value using PIs to capitalize on distinguishing topological features of the data. We use resolution 20 × 20 and a Gaussian with variance σ = 0.005 to generate the PIs. These parameters were chosen after a preliminary parameter search and classification effort. Similar results hold for a range of PI parameter values.  For a fixed r parameter value and a large number of points (many thousands), the patterns in the distributions of iterates show only small visible variations for different choices of the initial condition (x 0 , y 0 ). However, with few points, such as in <ref type="figure" target="#fig_5">Figure 5</ref>, there are more significant variations in the patterns for different choices of initial conditions, making classification more difficult.</p><p>We perform classification and cross-validation with a discriminant subspace ensemble. This ML algorithm trains many "weak" learners on randomly chosen subspaces of the data (of a fixed dimension), and classifies and assigns a score to each point based on the current subspace. The final classification arises from an average of the scores of each data point over all learners <ref type="bibr" target="#b32">(Ho, 1998)</ref>. We perform 10 trials and average the classification accuracies. For the concatenated H 0 and H 1 PIs, this method achieves a classification accuracy of 82.5%; compared to 49.8% when using only H 0 PIs, and 65.7% using H 1 PIs. This experiment highlights two strengths of PIs: they offer flexibility in choosing a ML algorithm that is well suited to the data under consideration, and homological information from multiple dimensions may be leveraged simultaneously for greater discriminatory power.</p><p>This application is a brief example of the utility of PIs in classification of data from dynamical systems and modeling real-world phenomena, which provides a promising direction for further applications of PIs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4.2">A partial differential equation</head><p>The Kuramoto-Sivashinsky (KS) equation is a partial differential equation for a function u(x, y, t) of spatial variables x, y and time t that has been independently derived in a variety of problems involving pattern formation in extended systems driven far from equilibrium. Applications involving surface dynamics include surface nanopatterning by ion-beam erosion <ref type="bibr" target="#b15">(Cuerno and Barabási, 1995;</ref><ref type="bibr" target="#b36">Motta et al., 2012)</ref>, epitaxial growth <ref type="bibr" target="#b47">(Villain, 1991;</ref><ref type="bibr" target="#b48">Wolf, 1991;</ref><ref type="bibr" target="#b42">Rost and Krug, 1995)</ref>, and solidification from a melt <ref type="bibr" target="#b27">(Golovin and Davis, 1998)</ref>. In these applications, the nonlinear term in the KS equation may be anisotropic, resulting in the anisotropic Kuramoto-Sivashinsky (aKS) equation</p><formula xml:id="formula_25">∂ ∂t u = −∇ 2 u − ∇ 2 ∇ 2 u + r ∂ ∂x u 2 + ∂ ∂y u 2 ,<label>(4)</label></formula><p>where ∇ 2 = ∂ 2 ∂x 2 + ∂ 2 ∂y 2 , and the real parameter r controls the degree of anisotropy. At a fixed time t * , u(x, y, t * ) is a patterned surface (periodic in both x and y) defined over the (x, y)-plane. Visibly, the anisotropy appears as a slight tendency for the pattern to be elongated in the vertical or horizontal direction. Numerical simulations of the aKS equation for a range of parameter values (columns) and simulation times (rows) are shown in <ref type="figure" target="#fig_6">Figure 6</ref>. For all simulations, the initial conditions were lowamplitude white noise. We employed a Fourier spectral method with periodic boundary conditions on a 512 × 512 spatial grid, with a fourth-order exponential time differencing Runge-Kutta method for the time stepping. Five values for the parameter r were chosen, namely r = 1, 1.25, 1.5, 1.75 and 2, and thirty trials were performed for each parameter value. <ref type="figure">Figure 7</ref> shows the similarity between surfaces associated to two parameter values r = 1.75 and r = 2 at an early time.</p><p>We aim to identify the anisotropy parameter for each simulation using snapshots of surfaces u(x, y, ·) as they evolve in time. Inference of the parameter using the surface alone proves difficult for several reasons. First, Equation (4) exhibits sensitivity to initial conditions: initially nearby solutions diverge quickly. Second, although the surface u(x, y, t * ) at a fixed time is an approximation due to the finite discretization of its domain, the spatial resolution is still very large: in fact, these surfaces may be thought of as points in R 266144 . We were unable to perform standard classification techniques in this space. It was therefore necessary to perform some sort of dimension reduction. <ref type="figure">Figure 7</ref>: To illustrate the difficulty of our classification task, consider five instances of surfaces u(x, y, 3) for r = 1.75 or r = 2, plotted on the same color axis. These surfaces are found by numerical integration of Equation (4), starting from random initial conditions. Can you group the images by eye?</p><p>Answer: (from left) r = 1.75, 2, 1.75, 2, 2.</p><p>One such method is to simply 'resize' the surface by coarsening the discretization of the spatial domain after computing the simulation at a high resolution by replacing a block of grid elements with their average surface height. The surfaces were resized in this way to a resolution of 10×10 and a subspace discriminant ensemble was used to perform classification. Unsurprisingly, this method performs very poorly at all times (first row of <ref type="table" target="#tab_1">Table 2</ref>).</p><p>The anisotropy parameter also influences the mean and amplitude of the surface pattern. We eliminate differences in the mean by mean-centering each surface after the simulation. To assess the impact of the variance of surface height on our task, classification was performed using a normal distribution-based classifier built on the variances of the surface heights. In this classifier, a normal distribution was fit to a training set of 2/3 of the variances for each parameter value, and the testing data was classified based on a z-test for each of the different models. That is, a p-value for each new variance was computed for membership to the five normal distributions (corresponding to the five parameter choices of r), and the surface was classified based on the model yielding the highest p-value. After the pattern has more fully emerged (by, say, time t = 5) this method of classification yields 75% accuracy 11 , as shown in <ref type="table" target="#tab_1">Table 2</ref>. However, early on in the formation of the pattern, this classifier performs very poorly because height variance is not yet a discriminating feature. <ref type="figure" target="#fig_7">Figure 8</ref> shows the normal distribution fit to the variance of the surfaces for each parameter value at times t = 3 and 5, and illustrates why the variance of surface height is informative only after a surface is allowed to evolve for a sufficiently long time.</p><p>Variance of a surface is reflected in its sublevel set filtration (see §A.3 for more details) PD. Yet, the PD and the subsequent PI contain additional topological structure, which may reveal other influences of the anisotropy parameter on the evolution of the surface. Persistence diagrams were computed using the sublevel set filtration, and PIs were generated with resolution 10 × 10 and a Gaussian with variance σ = 0.01. We think of our pipeline to a PI as a dimensionality reduction in this case, taking a surface which in actuality is a very high-dimensional point and producing a much lower dimensional one that retains meaningful characteristics of the original surface.</p><p>We again use a subspace discriminant ensemble to classify PIs by parameter. <ref type="table" target="#tab_1">Table 2</ref> compares these results to the same technique applied to low dimensional approximations of the raw surfaces and the normal distribution-based classifier built from surface variance alone. At each time in the system evolution, the best classification accuracy results from using PIs, improving accuracies over r = 1.00 r = 1.25 r = 1.50 r = 1.75 r = 2.00  using either low resolution approximations of the surfaces or variance of surface height alone by at least 20%, including at early times in the evolution of the surface when pattern amplitudes are not visibly differentiated (see <ref type="figure">Figure 7</ref>). We postulate that PIs capture more subtle topological information that is useful for identifying the parameter used to generate each surface. As we observed in §6.4.1, concatenating H 0 and H 1 PIs can notably improve the classification accuracy over either feature vector individually. We again note that classification accuracy appears insensitive to the PI parameters. For example, when the variance of the Guassians used to generate the PIs was varied from 0.0001 to 0.1, the classification accuracy of the H 0 PIs, changed by less than one percentage point. The classification accuracy for H 1 fluctuated in a range of approximately five points. For a fixed variance, when the resolution of the image was varied from 5 to 20, the H 0 accuracy varied by little more than three points until the accuracy dropped by six points for a resolution of 25.</p><p>PIs performed remarkably well in this classification task, allowing one to capitalize on subtle structural differences in the patterns and significantly reduce the dimension of the data for classification. There is more to be explored in the realm of pattern formation and persistence that is outside the scope of this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>PIs offer a stable representation of the topological characteristics captured by a PD. Through this vectorization, we open the door to a myriad of ML tools. This serves as a vital bridge between the fields of ML and topological data analysis and enables one to capitalize on topological structure (even in multiple homological dimensions) in the classification of data.</p><p>We have shown PIs yield improved classification accuracy over PLs and PDs on sampled data of common topological spaces at multiple noise levels using K-medoids. Additionally, computing distances between PIs requires significantly less computation time compared to computing distances between PDs, and comparable computation times with PLs. Through PIs, we have gained access to a wide variety of ML tools, such as SSVM which can be used for feature selection. Features (pixels) selected as discriminatory in a PI are interpretable because they correspond to regions of a PD. We have explored datasets derived from dynamical systems and illustrated that topological information of solutions can be used for inference of parameters since PIs encapsulate this information in a form amenable to ML tools, resulting in high accuracy rates for data that is difficult to classify.</p><p>The classification accuracy is robust to the choice of parameters for building PIs, providing evidence that it is not necessary to perform large-scale parameter searches to achieve reasonable classification accuracy. This indicates the utility of PIs even when there is not prior knowledge of the underlying data (i.e. high noise level, expected holes, etc.). The flexibility of PIs allows for customization tailored to a wide variety of real-world data sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Homology and Data</head><p>Homology is an invariant that characterizes the topological properties of a topological space X. In particular, homology measures the number of connected components, loops, trapped volumes, and so on of a topological space, and can be used to distinguish distinct spaces from one another. More explicitly, the k-dimensional holes of a space generate a homology group, H k (X). The rank of this group is referred to as the k-th Betti number, β k , and counts the number of k-dimensional holes of X. For a comprehensive study of homology, see <ref type="bibr" target="#b29">Hatcher (2002)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Simplicial Complexes and Homology</head><p>Simplicial complexes are one way to define topological spaces combinatorially. More precisely, a simplicial complex S consists of vertices (0-simplices), edges (1-simplices), triangles (2-simplices), tetrahedra (3-simplices), and higher-dimensional k-simplices (containing k + 1 vertices), such that</p><p>• if σ is a simplex in S then S contains all lower-dimensional simplices of σ, and</p><p>• the non-empty intersection of any two simplices in S is a simplex in S.</p><p>The following setup is necessary for a rigorous definition of (simplicial) homology. To a simplicial complex, one can associate a chain complex of vector spaces over a field F (often a finite field Z/pZ for p a small prime),</p><formula xml:id="formula_26">· · · → C k+1 ∂ k+1 − −− → C k ∂ k − → C k−1 → · · · .</formula><p>Here, vector space C k consists of all F-linear combinations of the k simplices of S, and has as a basis the set of all k-simplices. The linear map ∂ k : C k → C k−1 , known as the boundary operator, maps a k-simplex to its boundary, a sum of its (k − 1)-faces. More formally, the boundary map acts on a k-simplex</p><formula xml:id="formula_27">[v 0 , v 1 , . . . , v k ] by ∂ k ([v 0 , v 1 , . . . , v k ]) = k i=0 (−1) i [v 0 , . . . ,v i , . . . , v k ],</formula><p>where [v 0 , . . . ,v i , . . . , v k ] is the (k − 1)-simplex obtained from [v 0 , . . . , v k ] by removing vertex v i . We define two subspaces of C k : subspace Z k = ker(δ k ) is known as the k-cycles, and subspace B k = im(δ k+1 ) = δ k+1 (C k+1 ) is known as the k-boundaries. The boundary operator satisfies the property ∂ k • ∂ k+1 = 0, which implies the inclusion B k ⊆ Z k .</p><p>Homology seeks to uncover an equivalence class of cycles that enclose a k-dimensional holethat is, cycles which are not also boundaries of k-simplices. To this end, the k-th order homology is defined as H k (S) = Z k /B k , a quotient of vector spaces. The k-th Betti number β k = dim(H k (S)) is the dimension of this vector space, and counts the number of independent holes of dimension k. More explicitly, β 0 counts the number of connected components, β 1 the number of loops, β 2 the number of trapped volumes, and so on. Betti numbers are a topological invariant, meaning that topologically equivalent spaces have the same Betti number.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Persistence Diagrams from Point Cloud Data</head><p>One way to approximate the topological characteristics of a point cloud dataset is to build a simplicial complex on top of it. Though there are a variety of methods to do so, we restrict attention to the Vietoris-Rips simplicial complex due to its computational tractability <ref type="bibr" target="#b26">(Ghrist, 2008)</ref>. Given a data set Y (equipped with a metric) and a scale parameter ≥ 0, the Vietoris-Rips complex S has Y as its set of vertices and has a k-simplex for every collection of k + 1 vertices whose pairwise distance is at most . However, it is often not apparent how to choose scale . Selecting too small results in a topological space with a large number of connected components, and selecting too large results in a topological space that is contractible (equivalent to a single point).</p><p>The idea of persistent homology is to compute homology at many scales and observe which topological features persist across those scales <ref type="bibr" target="#b26">(Ghrist, 2008;</ref><ref type="bibr" target="#b7">Carlsson, 2009;</ref><ref type="bibr" target="#b20">Edelsbrunner and Harer, 2008)</ref>. Indeed, if 1 ≤ 2 ≤ . . . ≤ m is an increasing sequence of scales, then the corresponding Vietoris-Rips simplicial complexes form a filtered sequence S 1 ⊆ S 2 ⊆ . . . ⊆ S m . As varies, so does the homology of S , and for any homological dimension k we get a sequence of linear maps</p><formula xml:id="formula_28">H k (S 1 ) → H k (S 2 ) → . . . → H k (S m )</formula><p>. Persistent homology tracks the homological features over a range of values of . Those features which persist over a larger range are considered to be true topological characteristics, while short-lived features are often considered as noise.</p><p>For each choice of homological dimension k, the information measured by persistent homology can be presented as a persistence diagram (PD), a multiset of points in the plane. Each point (x, y) = ( , ) corresponds to a topological feature that appears (is 'born') at scale parameter and which no longer remains ('dies') at scale . Since all topological features die after they are born, this is an embedding into the upper half plane, above the diagonal line y = x. Points near the diagonal are considered to be noise while those further from the diagonal represent more robust topological features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Persistence Diagrams from Functions</head><p>Let X be a topological space and let f : X → R be a real-valued function. One way to understand the behavior of map f is to understand the topology of its sublevel sets f −1 ((−∞, ]), where ∈ R. Indeed, given 1 ≤ 2 ≤ . . . ≤ m , one can study map f using the persistent homology of the resulting filtration of topological spaces, known as the sublevel set filtration:</p><formula xml:id="formula_29">f −1 ((−∞, 1 ]) ⊆ f −1 ((−∞, 2 ]) ⊆ . . . ⊆ f −1 ((−∞, m ]).</formula><p>If X is a simplicial complex, then one can produce an increasing sequence of simplicial complexes using a modification of this procedure called the lower star filtration . Similarly, if X is a cubical complex (an analogue of a simplicial complex that is instead a union of vertices, edges, squares, cubes, and higher-dimensional cubes), then one can produce an increasing sequence of cubical complexes.</p><p>In §6.4.2, we study surfaces u : [0, 1] 2 → R produced from the Kuramoto-Sivashinsky equation. The domain [0, 1] 2 is discretized into a grid of 512×512 vertices, i.e. a 2-dimensional cubical complex with 512 2 vertices, 511 · 512 horizontal edges, 511 · 512 vertical edges, and 511 2 squares. We produce an increasing sequence of cubical complexes as follows:</p><p>• A vertex v is included at scale if u(v) ≤ .</p><p>• An edge is included at scale if both of its vertices are present.</p><p>• A square is included at scale if all four of its vertices are present. Our PDs are obtained by taking the persistent homology of this cubical complex sublevel set filtration.</p><p>We remark that PDs from point cloud data in §A.2 can be viewed as a specific case of PDs from functions. Indeed, given a data set X in some metric space (M, d), let d X : M → R be the distance function to set X, defined by d X (m) = inf x∈X d(x, m) for all m ∈ M . Note that d −1 X ((−∞, ]) is the union of the metric balls of radius centered at each point in X. For 1 ≤ 2 ≤ . . . ≤ m , the persistent homology of</p><formula xml:id="formula_30">d −1 X ((−∞, 1 ]) ⊆ d −1 X ((−∞, 2 ]) ⊆ . . . ⊆ d −1 X ((−∞,<label>m</label></formula><p>]) is identical to the persistent homology of a simplicial complex filtration called theČech complex. Furthermore, the persistent homology of the Vietoris-Rips complex is an approximation of the persistent homology of theČech complex <ref type="bibr">(Edelsbrunner and Harer, 2010, Section III.2)</ref>. <ref type="figure">Figure 9</ref>: Examples of PIs for homology dimension H 1 arising from a noisy circle with a variety of resolutions and variances. The first row has resolution 5 × 5 while the second has 50 × 50. The columns have variance σ = 0.01 and σ = 0.2, respectively. Proof. If v = u then the statement follows from the fact that g u and g v are normalized to have unit area under the curve. Hence we may assume u = v.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Examples of Persistence Images</head><p>magnitude and angle of vector u − v when expressed in polar coordinates. The change of variables (z, w) = R θ (x − v x , y − v y ), where R θ is the clockwise rotation of the plane by θ, gives</p><formula xml:id="formula_31">f (u)g u − f (v)g v 1 =ˆ∞ −∞ˆ∞ −∞ f (u) 2πσ 2 e −[(x−ux) 2 +(y−uy) 2 ]/2σ 2 − f (v) 2πσ 2 e −[(x−vx) 2 +(y−vy) 2 ]/2σ 2 dy dx =ˆ∞ −∞ˆ∞ −∞ f (u) 2πσ 2 e −[w 2 +(z−r) 2 ]/2σ 2 − f (v) 2πσ 2 e −[w 2 +z 2 ]/2σ 2 dz dw =ˆ∞ −∞ 1 σ √ 2π e −w 2 /2σ 2 ˆ∞ −∞ f (u) σ √ 2π e −(z−r) 2 /2σ 2 − f (v) σ √ 2π e −z 2 /2σ 2 dz dw = f (u)g r − f (v)g 0 1ˆ∞ −∞ 1 σ √ 2π e −w 2 /2σ 2 dw with g 0 , g r 1-dimensional Gaussians = f (u)g r − f (v)g 0 1 ≤|f (u) − f (v)| + 2 π min{f (u), f (v)} σ u − v 2 by Lemma 2 ≤ |∇f | + 2 π min{f (u), f (v)} σ u − v 2 .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D SSVM-based Feature Selection</head><p>We performed feature selection using one-against-all (OAA) SSVM on the six classes of synthetic data with noise level η = 0.05. The PIs used in the experiments were generated from the H 1 PDs, with the parameter choices of resolution 20 × 20 and variance σ = 0.0001. Note that because of the resolution parameter choice of 20 × 20, each PI is a vector in R 400 , and the selected features will be a subset of indices corresponding to pixels within the PI. We trained an OAA SSVM model for PIs of dimension H 1 . In the experiment, we used 5-fold cross-validation and obtained 100% overall accuracy. Feature selection was performed by retaining the features with non-zero SSVM weights, determined by magnitude comparison using weight ratios <ref type="bibr" target="#b11">(Chepushtanova et al., 2014)</ref>. The resulting six sparse models contain subsets of discriminatory features for each class. Note that one can use only these selected features for classification without loss in accuracy. These features correspond to discriminatory pixels in the persistence images. <ref type="figure" target="#fig_1">Figure 11</ref> shows locations of pixels in the vectorized PIs selected by OAA SSVM that discriminate each class from all the others. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>and γ ranges over bijections between B and B . Another standard choice of distance between diagrams is W ∞ (B, B ) = inf γ:B→B sup u∈B ||u−γ(u)|| ∞ , referred to as the bottleneck distance. These metrics allow us to measure the (dis)similarity between the homological characteristics of two datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Algorithm pipeline to transform data into a persistence image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>K-medoids classification accuracy as a function of resolution and variance for the dataset of six shape classes. First column: noise level η = 0.05. Second column: noise level η = 0.1. First row: fixed variance 0.1 with resolutions ranging from 5 × 5 to 100 × 100 in increments of 5. Second row: fixed resolution 20 × 20 with variances ranging from 0.01 to 0.2 in increments of 0.01.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>SSVM-based feature (pixel) selection for H 1 PIs from two classes of the synthetic data. Selected pixels are marked by blue crosses. (a) A noisy circle with the two selected pixels (indices 21 and 22 out of 400). (b) A noisy torus with the two selected pixels (indices 59 and 98 out of 400). The PI parameters used are resolution 20 × 20 and variance 10 −4 , for noise level 0.05.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Examples of the first 1000 iterations, {(x n , y n ) : n = 0, . . . , 1000}, of the linked twist map with parameter values r = 2, 3.5, 4.0, 4.1 and 4.3, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Truncated orbits, {(x n , y n ) : n = 0, . . . , 1000}, of the linked twist map with fixed r = 4.3 for different initial conditions (x 0 , y 0 ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Plots of height-variance-normalized surfaces u(x, y, ·) resulting from numerical simulations of the aKS equation (4). Each column represents a different parameter value: (from left) r = 1, 1.25, 1.5, 1.75 and 2. Each row represents a different time: t = 3 (top) and t = 5 (bottom). By t = 5 any anisotropic elongation of the surface pattern has visibly stabilized.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 8 :</head><label>8</label><figDesc>Histograms of the variances of surface heights for each parameter value, and the normal distribution fit to each histogram, for times (a) t = 3 and (b) t = 5.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 10 :F</head><label>10</label><figDesc>Examples of PIs for homology dimension H 1 arising from a noisy torus with a variety of resolutions and variances. The first row has resolution 5 × 5 while the second has 50 × 50. The columns have variance σ = 0.01 and σ = 0.2, respectively.C Proofs of Equation (3) and Lemma 3Let u, v ∈ R and a, b &gt; 0. Equation(3)states that ag u − bg v 1 = F (v − u), where F : R → R is defined by</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 11 :</head><label>11</label><figDesc>SSVM-based feature (pixel) selection for H 1 PIs from the six classes of the synthetic data. The parameters used are resolution 20 × 20 and variance 0.0001, for noise level 0.05. Selected pixels are marked by blue crosses. (a) A noisy solid cube with the two selected pixels (indices 59 and 79 out of 400). (b) A noisy torus with the two selected pixels (indices 59 and 98 out of 400). (c) A noisy sphere with the five selected pixels (indices 58, 59, 60, 79, and 98 out of 400). (d) Noisy three clusters with the one selected pixel (index 20 out of 400). (e) Noisy three clusters within three clusters with the seven selected pixels (indices 20, 40, 59, 60, 79, 80, and 98 out of 400). (f) A noisy circle with the two selected pixels (indices 21 and 22 out of 400).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Classification accuracies at different times of the aKS solution, using different classification approaches. Classification of times t = 15 and 20 result in accuracies similar to t =10.</figDesc><table><row><cell></cell><cell>Time</cell><cell>Time</cell><cell>Time</cell></row><row><cell>Classification Approach</cell><cell>t=3</cell><cell>t=5</cell><cell>t=10</cell></row><row><cell cols="3">Subspace Discriminant Ensemble, Resized Surfaces 26.0 % 19.3%</cell><cell>19.3 %</cell></row><row><cell>Variance Normal Distribution Classifier</cell><cell cols="3">20.74% 75.2% 77.62 %</cell></row><row><cell>Subspace Discriminant Ensemble, H 0 PIs</cell><cell cols="3">58.3 % 96.0 % 94.7 %</cell></row><row><cell>Subspace Discriminant Ensemble, H 1 PIs</cell><cell cols="2">67.7 % 87.3 %</cell><cell>93.3%</cell></row><row><cell>Subspace Discriminant Ensemble, H 0 and H 1 PIs</cell><cell cols="3">72.7 % 95.3 % 97.3 %</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Or more generally, a weighted sum of probability density functions</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Weighting functions are restricted only to the extent necessary for our stability results in §5.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">Our weighting function is continuous and zero for points of zero persistence, i.e. points along the diagonal.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">Another standard representation is the barcode<ref type="bibr" target="#b26">(Ghrist, 2008)</ref>. 5 By convention, all points on the diagonal are taken with infinite multiplicity. This facilitates the definitions of the p-Wasserstein and bottleneck distances below.6 As explained in §A.3, (i) can be viewed as a special case of (ii).</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7">We omit points that correspond to features with infinite persistence, e.g. the H0 feature corresponding to the connectedness of the complete simplicial complex.8 Instead of birth-persistence coordinates, one could also use other choices such as birth-death or (average size)persistence coordinates. Our stability results ( §5) still hold with only a slight modification to the constants.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9">The L 1 , L 2 , L ∞ distances on PDs are more commonly known as the 1-Wasserstein, 2-Wasserstein, and bottleneck distances.10 For PIs in this experiment, we use variance σ = 0.1, resolution 20 × 20, and the weighting function defined in §4.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11">Accuracy reported is averaged over 100 different training and testing partitions.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments:</head><p>We would like to acknowledge the research group of Paul Bendich at Duke University for allowing us access to a persistent homology package which greatly reduced computational time and made analysis of large point clouds feasible. This code can be accessed via GitLab after submitting a request to Paul Bendich. This research is partially supported by the National Science Foundation under Grants No. DMS-1228308, DMS-1322508, NSF DMS-1115668, NSF DMS-1412674, and DMR-1305449 as well as the DOD-USAF under Award Number FA9550-12-1-0408.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>For u = v a straightforward calculation shows there is a unique solution z * to ag u (z) = bg v (z), namely</p><p>There are four integrals to compute, and we do each one in turn. We havê</p><p>. Plugging back into <ref type="formula">(5)</ref> gives ag u − bg v 1 = F (v − u).</p><p>We now give the proof of Lemma 3.</p><p>Proof. The result will follow from the observation that we can reduce the two-dimensional case involving Gaussians centered at u, v ∈ R 2 to one-dimensional Gaussians centered at 0 and r = u − v 2 . Let u = (u x , u y ) and v = (v x , v y ); we may assume u x &gt; v x w.l.o.g. Let (r, θ) be the</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">The ring of algebraic functions on persistence bar codes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Adcock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Carlsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gunnar</forename><surname>Carlsson</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1304.0530</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Analyzing Stratified Spaces Using Persistent Versions of Intersection and Local Homology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Bendich</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
		<respStmt>
			<orgName>Duke University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Bendich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sang</forename><surname>Chin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Desena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Harer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1406.0214</idno>
		<title level="m">Topological and statistical behavior classifiers for tracking applications</title>
		<meeting><address><addrLine>Elizabeth Munch, Andrew Newman, David Porter, David Rouse, Nate Strawn, and Adam Watkins</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Persistent homology analysis of brain artery trees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Bendich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ezra</forename><surname>Marron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Pieloch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Skwerer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Applied Statistics</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>To appear</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Feature selection via concave minimization and support vector machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bradley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Olvi L Mangasarian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning Proceedings of the Fifteenth International Conference</title>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="82" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Statistical topological data analysis using persistence landscapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Bubenik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="77" to="102" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A persistence landscapes toolbox for topological statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Bubenik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pawel</forename><surname>Dlotko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Jounral of Symbolic Computations</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>Accepted</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gunnar</forename><surname>Carlsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Topology and data. Bulletin of the American Mathematical Society</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="255" to="308" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Stable topological signatures for points on 3d shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mathieu Carrière</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Steve</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maks</forename><surname>Oudot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ovsjanikov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Forum</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Persistence stability for geometric complexes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frédéric</forename><surname>Chazal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Vin De Silva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Oudot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Geometriae Dedicata</title>
		<imprint>
			<biblScope unit="volume">173</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="193" to="214" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Statistical analysis of persistence intensity functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yen-Chi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daren</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Rinaldo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry</forename><surname>Wasserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1510.02502</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Band selection in hyperspectral imagery using sparse support vector machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sofya</forename><surname>Chepushtanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Gittins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Kirby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings SPIE DSS 2014</title>
		<meeting>SPIE DSS 2014</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">9088</biblScope>
			<biblScope unit="page" from="90881" to="90881" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Persistence diagrams of cortical surface data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Moo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter T</forename><surname>Bubenik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Information Processing in Medical Imaging</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="386" to="397" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Stability of persistence diagrams</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herbert</forename><surname>Edelsbrunner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Harer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Discrete &amp; Computational Geometry</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="103" to="120" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Lipschitz functions have L p -stable persistence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herbert</forename><surname>Edelsbrunner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Harer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuriy</forename><surname>Mileyko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations of computational mathematics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="127" to="139" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Dynamic scaling of ion-sputtered surfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodolfo</forename><surname>Cuerno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert-Lásló</forename><surname>Barabási</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review Letters</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="page">4746</biblScope>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A topological paradigm for hippocampal spatial map formation using persistent homology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Dabaghian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Facundo</forename><surname>Memoli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gunnar</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Carlsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Computational Biology</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">1002581</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Comparing persistence diagrams through complex vectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><forename type="middle">Di</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimo</forename><surname>Ferri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Image Analysis and Processing 2015 Part I; Editors V. Murino, E. Puppo</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">9279</biblScope>
			<biblScope unit="page" from="294" to="305" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Size functions for signature recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Donatini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrizio</forename><surname>Frosini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Lovato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SPIE&apos;s International Symposium on Optical Science, Engineering, and Instrumentation</title>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="178" to="183" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Computational topology: An introduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herbert</forename><surname>Edelsbrunner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Harer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Mathematical Society</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Persistent homology -a survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herbert</forename><surname>Edelsbrunner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Harer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Contemporary Mathematics</title>
		<imprint>
			<biblScope unit="volume">453</biblScope>
			<biblScope unit="page" from="257" to="282" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Current open problems in discrete and computational geometry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herbert</forename><surname>Edelsbrunner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ivanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Karasev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Modelirovanie i Analiz Informats. Sistem</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="5" to="17" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Fourier-ring descriptor to characterize rare circulating cells from images generated using immunofluorescence microscopy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tegan</forename><surname>Emerson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Kirby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kelly</forename><surname>Bethel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anand</forename><surname>Kolatkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Madelyn</forename><surname>Luttgen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O&amp;apos;</forename><surname>Stephen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Hara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Newton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kuhn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computerized Medical Imaging and Graphics</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="70" to="87" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Representing size functions by complex polynomials</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimo</forename><surname>Ferri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claudia</forename><surname>Landi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Math. Met. in Pattern Recognition</title>
		<meeting>Math. Met. in Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="16" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Point selection: A new comparison scheme for size functions (with an application to monogram recognition)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimo</forename><surname>Ferri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrizio</forename><surname>Frosini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Lovato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chiara</forename><surname>Zambelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision ACCV&apos;98</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1997" />
			<biblScope unit="page" from="329" to="337" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A feature selection newton method for support vector machine classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Glenn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">L</forename><surname>Fung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mangasarian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Optimization and Applications</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="185" to="202" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Barcodes: The persistent topology of data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Ghrist</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>American Mathematical Society</publisher>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="61" to="75" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Effect of anisotropy on morphological instability in the freezing of a hypercooled melt</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">A</forename><surname>Golovin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Stephen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physica D: Nonlinear Phenomena</title>
		<imprint>
			<biblScope unit="volume">116</biblScope>
			<biblScope unit="page" from="363" to="391" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A completed modeling of local binary pattern operator for texture classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenhua</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1657" to="1663" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Algebraic Topology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Allen</forename><surname>Hatcher</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Image webs: Computing and exploiting connectivity in image collections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyle</forename><surname>Heath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natasha</forename><surname>Gelfand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maks</forename><surname>Ovsjanikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mridul</forename><surname>Aanjaneya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="3432" to="3439" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">DNA microarrays: Design principles for maximizing ergodic, chaotic mixing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan-Martin</forename><surname>Hertzsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Sturman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Wiggins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Small</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="202" to="218" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">The random subspace method for constructing decision forests</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kam</forename><surname>Tin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="832" to="844" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Clustering by means of medoids</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonard</forename><surname>Kaufman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Rousseeuw</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987" />
			<pubPlace>North-Holland</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Geometry helps to compare persistence diagrams</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Kerber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitriy</forename><surname>Morozov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arnur</forename><surname>Nigmetov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Algorithm Engineering and Experiments</title>
		<meeting>the Workshop on Algorithm Engineering and Experiments</meeting>
		<imprint>
			<publisher>Accepted</publisher>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Probability measures on the space of persistence diagrams</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuriy</forename><surname>Mileyko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sayan</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Harer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inverse Problems</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">124007</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Highly ordered nanoscale surface ripples produced by ion bombardment of binary compounds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Francis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Motta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Patrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R Mark</forename><surname>Shipman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bradley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Physics D: Applied Physics</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">122001</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Topologybased kernels with application to inference problems in Alzheimer&apos;s disease</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deepti</forename><surname>Pachauri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Hinrichs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Moo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sterling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vikas</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Medical Imaging</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1760" to="1770" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A simple and fast algorithm for k-medoids clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hae-Sang</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi-Hyuck</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="3336" to="3341" />
			<date type="published" when="2009-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Producing nanodot arrays with improved hexagonal order by patterning surfaces before ion sputtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">A</forename><surname>Pearson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">Mark</forename><surname>Bradley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francis</forename><forename type="middle">C</forename><surname>Motta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><forename type="middle">D</forename><surname>Shipman</surname></persName>
		</author>
		<idno type="DOI">http:/link.aps.org/doi/10.1103/PhysRevE.92.062401</idno>
		<ptr target="http://link.aps.org/doi/10.1103/PhysRevE.92.062401" />
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. E</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="page">62401</biblScope>
			<date type="published" when="2015-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Sliding windows and persistence: An application of topological methods to signal analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jose</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Perea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Harer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations of Computational Mathematics</title>
		<imprint>
			<biblScope unit="page" from="1" to="40" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">A stable multi-scale kernel for topological machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Reininghaus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Huber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulrich</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roland</forename><surname>Kwitt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="4741" to="4748" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Anisotropic kuramoto-sivashinsky equation for surface growth and erosion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Rost</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joachim</forename><surname>Krug</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review Letters</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="page">3894</biblScope>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Topological analysis of population activity in visual cortex</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gurjeet</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Facundo</forename><surname>Memoli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tigran</forename><surname>Ishkhanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillermo</forename><surname>Sapiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gunnar</forename><surname>Carlsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dario</forename><forename type="middle">L</forename><surname>Ringach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">11</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Topological data analysis of biological aggregation models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lori</forename><surname>Topaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Ziegelmeier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Halverson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PloS One</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">126383</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Fréchet means for distributions of persistence diagrams</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katharine</forename><surname>Turner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuriy</forename><surname>Mileyko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sayan</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Harer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Discrete &amp; Computational Geometry</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="44" to="70" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sara Kališnik</forename><surname>Verovšek</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1604.00113</idno>
		<title level="m">Tropical coordinates on the space of persistence barcodes</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Continuum models of crystal growth from atomic beams with and without desorption</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Villain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Phys. I France</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="19" to="42" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Kinetic roughening of vicinal surfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Dietrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wolf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review Letters</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page">1783</biblScope>
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Topological descriptors for 3d surface analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Zeppelzauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bartosz</forename><surname>Zieliński</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mateusz</forename><surname>Juda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Seidl</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1601.06057</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">On the sparseness of 1-norm support vector machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weida</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="373" to="385" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">1-norm support vector machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saharon</forename><surname>Rosset</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Tibshirani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="49" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Computing persistent homology. Discrete &amp; Computational Geometry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Afra</forename><surname>Zomorodian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gunnar</forename><surname>Carlsson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="249" to="274" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
