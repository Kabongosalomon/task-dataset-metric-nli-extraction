<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Towards Better UD Parsing: Deep Contextualized Word Embeddings, Ensemble, and Treebank Concatenation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanxiang</forename><surname>Che</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Research Center for Social Computing and Information Retrieval</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yijia</forename><surname>Liu</surname></persName>
							<email>yjliu@ir.hit.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Research Center for Social Computing and Information Retrieval</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxuan</forename><surname>Wang</surname></persName>
							<email>yxwang@ir.hit.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Research Center for Social Computing and Information Retrieval</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Zheng</surname></persName>
							<email>bzheng@ir.hit.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Research Center for Social Computing and Information Retrieval</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
							<email>tliu@ir.hit.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Research Center for Social Computing and Information Retrieval</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Towards Better UD Parsing: Deep Contextualized Word Embeddings, Ensemble, and Treebank Concatenation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T18:46+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes our system (HIT-SCIR) submitted to the CoNLL 2018 shared task on Multilingual Parsing from Raw Text to Universal Dependencies. We base our submission on Stanford's winning system for the CoNLL 2017 shared task and make two effective extensions: 1) incorporating deep contextualized word embeddings into both the part of speech tagger and dependency parser; 2) ensembling parsers trained with different initialization. We also explore different ways of concatenating treebanks for further improvements. Experimental results on the development data show the effectiveness of our methods. In the final evaluation, our system was ranked first according to LAS (75.84%) and outperformed the other systems by a large margin.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In this paper, we describe our system (HIT-SCIR) submitted to CoNLL 2018 shared task on Multilingual Parsing from Raw Text to Universal Dependencies <ref type="bibr" target="#b25">(Zeman et al., 2018)</ref>. We base our system on Stanford's winning system <ref type="bibr">(Dozat et al., 2017, §2)</ref> for the CoNLL 2017 shared task <ref type="bibr" target="#b26">(Zeman et al., 2017)</ref>. <ref type="bibr" target="#b5">Dozat and Manning (2016)</ref> and its extension <ref type="bibr" target="#b6">(Dozat et al., 2017)</ref> have shown very competitive performance in both the shared task <ref type="bibr" target="#b6">(Dozat et al., 2017)</ref> and previous parsing works <ref type="bibr" target="#b13">(Ma and Hovy, 2017;</ref><ref type="bibr" target="#b21">Shi et al., 2017a;</ref><ref type="bibr" target="#b12">Liu et al., 2018b;</ref><ref type="bibr" target="#b14">Ma et al., 2018)</ref>. A natural question that arises is how can we further improve their part of speech (POS) tagger and dependency parser via a simple yet effective technique. In our system, we make two noteworthy extensions to their tagger and parser:</p><p>• Incorporating the deep contextualized word embeddings <ref type="bibr" target="#b17">(Peters et al., 2018</ref>, ELMo: Embeddings from Language Models) into the word representaton ( §3);</p><p>• Ensembling parsers trained with different initialization ( §4).</p><p>For some languages in the shared task, multiple treebanks of different domains are provided. Treebanks which are of the same language families are provided as well. Letting these treebanks help each other has been shown an effective way to improve parsing performance in both the crosslingual-cross-domain parsing community and last year's shared tasks <ref type="bibr" target="#b0">(Ammar et al., 2016;</ref><ref type="bibr" target="#b8">Guo et al., 2015;</ref><ref type="bibr" target="#b22">Shi et al., 2017b;</ref><ref type="bibr" target="#b1">Björkelund et al., 2017</ref>). In our system, we apply the simple concatenation to the treebanks that are potentially helpful to each other and explore different ways of concatenation to improve the parser's performance ( §5).</p><p>In dealing with the small treebanks and treebanks from low-resource languages ( §6), we adopt the word embedding transfer idea in the crosslingual dependency parsing <ref type="bibr" target="#b8">(Guo et al., 2015)</ref> and use the bilingual word vectors transformation technique (Smith et al., 2017) 1 to map fasttext 2 word embeddings <ref type="bibr" target="#b2">(Bojanowski et al., 2016)</ref> of the source rich-resource language and target low-resource language into the same space. The transferred parser trained on the source language is used for the target low-resource language.</p><p>We conduct experiments on the development data to study the effects of ELMo, parser ensemble, and treebank concatenation. Experimental results show that these techniques substantially im-prove the parsing performance. Using these techniques, our system achieved an averaged LAS of 75.84 on the official test set and was ranked the first according to LAS <ref type="bibr" target="#b25">(Zeman et al., 2018)</ref>. This result significantly outperforms the others by a large margin. <ref type="bibr">3</ref> We release our pre-trained ELMo for many languages at https://github.com/ HIT-SCIR/ELMoForManyLangs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Deep Biaffine Parser</head><p>We based our system on the tagger and parser of <ref type="bibr" target="#b6">Dozat et al. (2017)</ref>. The core idea of the tagger and parser is using an LSTM network to produce the vector representation for each word and then predict POS tags and dependency relations using the representation. For the tagger whose input is the word alone, this representation is calculated as</p><formula xml:id="formula_0">h i = BiLSTM(h 0 , (v (word) 1 , ..., v (word) n )) i where v (word) i</formula><p>is the word embeddings. After getting h i , the scores of tags are calculated as</p><formula xml:id="formula_1">h (pos) i = MLP (pos) (h i ) s (pos) i = W · h (pos) i + b (pos) y (pos) i = argmax j s (pos) i,j</formula><p>where each element in s (pos) i represents the possibility that i-th word is assigned with corresponding tag.</p><p>For the parser whose inputs are the word and POS tag, such representation is calculated as</p><formula xml:id="formula_2">x i = v (word) i ⊕ v (tag) i h i = BiLSTM(h 0 , (x 1 , ..., x n )) i</formula><p>And a pair of representations are fed into a biaffine classifier to predict the possibility that there is a dependency arc between these two words. The scores over all head words are calculated as</p><formula xml:id="formula_3">s (arc) i = H (arc-head) W (arc) h (arc-dep) i + H (arc-head) b (arc) y (arc) = argmax j s (arc) i,j where h (arc-dep) i</formula><p>is computed by feeding h i into an <ref type="bibr">MLP and H (arc-head)</ref> is the stack of h (arc-head) i 3 http://universaldependencies.org/ conll18/results.html which is calculated in the same way as h (arc-dep) i but using another MLP. After getting the head y (arc) word, its relation with i-th word is decided by calculating</p><formula xml:id="formula_4">s (rel) i = h T (rel−head) y (arc) U (rel) h (rel−dep) i + W (rel) (h (rel−dep) i ⊕ h T (rel−head) y (arc) ) + b (rel) , y (rel) = argmax j s (rel) i,j</formula><p>where h (rel−head) and h <ref type="bibr">(rel−dep)</ref> are calculated in the same way as h . This decoding process can lead to cycles in the result. <ref type="bibr" target="#b6">Dozat et al. (2017)</ref> employed an iterative fixing methods on the cycles. We encourage the reader of this paper to refer to their paper for more details on training and decoding.</p><p>For both the biaffine tagger and parser, the word embedding v (word) i is obtained by summing a finetuned token embedding w i , a fixed word2vec embedding p i , and an LSTM-encoded character rep-</p><formula xml:id="formula_5">resentationv i as v (word) i = w i + p i +v i .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Deep Contextualized Word Embeddings</head><p>Deep contextualized word embeddings <ref type="bibr">(Peters et al., 2018, ELMo)</ref> has shown to be very effective on a range of syntactic and semantic tasks and it's straightforward to obtain ELMo by using an LSTM network to encode words in a sentence and training the LSTM network with language modeling objective on large-scale raw text. More specifically, the ELMo i is computed by first computing the hidden representation h</p><formula xml:id="formula_6">(LM ) i as h (LM ) i = BiLSTM (LM ) (h (LM ) 0 , (ṽ 1 , ...,ṽ n )) i</formula><p>whereṽ i is the output of a CNN over characters, then attentively summing and scaling different layers of h</p><formula xml:id="formula_7">(LM ) i,j</formula><p>with s j and γ as</p><formula xml:id="formula_8">ELMo i = γ L j=0 s j h (LM ) i,j ,</formula><p>where L is the number of layers and h (LM ) i,0 is identical toṽ i . In our system, we follow <ref type="bibr" target="#b17">Peters et al. (2018)</ref> and use a two-layer bidirectional LSTM as our BiLSTM <ref type="bibr">(LM )</ref> .</p><p>In this paper, we study the usage of ELMo for improving both the tagger and parser and make several simplifications. Different from <ref type="bibr" target="#b17">Peters et al. (2018)</ref>, we treat the output of ELMo as a fixed representation and do not tune its parameters during tagger and parser training. Thus, we cancel the layer-wise attention scores s j and the scaling factor γ, which means</p><formula xml:id="formula_9">ELMo i = 2 j=0 h (LM ) i,j .</formula><p>In our preliminary experiments, using h</p><formula xml:id="formula_10">(LM ) i,0</formula><p>for ELMo i yields better performance on some treebanks. In our final submission, we decide using</p><formula xml:id="formula_11">either 2 j=0 h (LM ) i,j or h (LM ) i,0</formula><p>based on their development.</p><p>After getting ELMo i , we project it to the same dimension as v (word) i and use it as an additional word embedding. The calculation of v</p><formula xml:id="formula_12">(word) i be- comes v (word) i = w i + p i +v i + W (ELM o) · ELMo i</formula><p>for both the tagger and parser. We need to note that training the tagger and parser includes W (ELM o) . To avoid overfitting, we impose a dropout function on projected vector W (ELM o) · ELMo i during training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Parser Ensemble</head><p>According to <ref type="bibr" target="#b19">Reimers and Gurevych (2017)</ref>, neural network training can be sensitive to initialization and <ref type="bibr" target="#b11">Liu et al. (2018a)</ref> shows that ensemble neural network trained with different initialization leads to performance improvements. We follow their works and train three parsers with different initialization, then ensemble these parsers by averaging their softmaxed output scores as</p><formula xml:id="formula_13">s (rel) i = 1 3 3 m=1 softmax(s (m,rel) i</formula><p>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Treebank Concatenation</head><p>For 15 out of the 58 languages in the shared task, multiple treebanks from different domains are provided. There are also treebanks that come from the same language family. Taking the advantages of the relation between treebanks has been shown a promising direction in both the research community <ref type="bibr" target="#b0">(Ammar et al., 2016;</ref><ref type="bibr" target="#b8">Guo et al., 2015</ref><ref type="bibr" target="#b7">Guo et al., , 2016a</ref> and in the CoNLL 2017 shared task <ref type="bibr" target="#b1">Björkelund et al., 2017;</ref><ref type="bibr" target="#b22">Shi et al., 2017b</ref>).</p><p>In our system, we adopt the treebank concatenation technique as <ref type="bibr" target="#b0">Ammar et al. (2016)</ref> with one exception: only a group of treebanks from the same language (cross-domain concatenation) or a pair of treebanks that are typologically or geographically correlated (cross-lingual concatenation) is concatenated.</p><p>In our system, we tried cross-domain concatenation on nl, sv, ko, it, en, fr, gl, la, ru, and sl. <ref type="bibr">4</ref> We also tried cross-lingual concatenation on ugtr, uk-ru, ga-en, and sme-fi following . However, due to the variance in vocabulary, grammatical genre, and even annotation, treebank concatenation does not guarantee to improve the model's performance. We decide the usage of concatenation by examining their development set performance. For some small treebanks which do not have development set, whether using treebank concatenation is decided through 5-fold cross validation. <ref type="bibr">5</ref> We show the experimental results of treebank concatenation in Section 9.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Low Resources Languages</head><p>In the shared task, 5 languages are presented with training set of less than 50 sentences. 4 languages do not even have any training data. It's difficult to train reasonable parser on these low-resource languages. We deal with these treebanks by adopting the word embedding transfer idea of <ref type="bibr" target="#b8">Guo et al. (2015)</ref>. We transfer the word embeddings of the rich-resource language to the space of lowresource language using the bilingual word vectors transformation technique <ref type="bibr" target="#b23">(Smith et al., 2017)</ref> and trained a parser using the source treebank with only pretrained word embeddings on the transformed space as v (word) i = p i . The transformation matrix is automatically learned on the fasttext word embeddings using the same tokens shared by two languages (like punctuation). <ref type="table" target="#tab_0">Table 1</ref> shows our source languages for the target low-resource languages. For a treebank with a few training data, its source language is decided by testing the source parser's performance on the target br fo th hy kk bxr kmr hsb source ga no zh et tr hi fa pl training data. 6 For a treebank without any training data, we choose the source language according to their language family. 7 Naija presents an exception for our method since it does not have fasttext word embeddings and embedding transformation is infeasible. Since it's a dialect of English, we use the full pipeline of en ewt for pcm nsc instead.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Preprocessing</head><p>Besides improving the tagger and parser, we also consider the preprocessing as an important factor to the final performance and improve it by using the state-of-the-art system for sentence segmentation, or developing our own word segmentor for languages whose tokenizations are non-trival.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Sentence Segmentation</head><p>For some treebanks, sentence segmentation can be problematic since there is no explicitly sentence delimiters. de Lhoneux et al. <ref type="formula">(2017)</ref> and <ref type="bibr" target="#b20">Shao (2017)</ref> presented a joint tokenization and sentence segmentation model (denoted as Uppsala segmentor) 8 that outperformed the baseline model in last year's shared task <ref type="bibr" target="#b26">(Zeman et al., 2017)</ref>. We select a set of treebanks whose udpipe sentence segmentation F-scores are lower than 95 on the development set and use Uppsala segmentor instead. 9 Using the Uppsala segmentor leads to a development improvement of 7.67 F-score in these treebanks over udpipe baseline and it was ranked the first according to sentence segmentation in the final evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Tokenization for Chinese, Japanese, and Vietnamese</head><p>Tokenization is non-trivial for languages which do not have explicit word boundary markers, like <ref type="bibr">6</ref> We use udpipe for this test. When training the parser, the small set of target training data is also used. 7 Thai does not have a treebank in the same family. We choose Chinese as source language because of geographical closeness and both these two languages are SVO in typology. 8 https://github.com/yanshao9798/ segmenter/ 9 We use Uppsala segmentor for it postwita, got proiel, la poroiel, cu proiel, grc proiel, sl ssj, nl lassysmall, fi tdt, pt bosque, da ddt, id gsd, el gdt, and et edt.</p><p>Chinese, Japanese, and Vietnamese. We develop our own tokenizer (denoted as SCIR tokenizer) for these three languages. Following  and , we model the tokenization as labeling the word boundary tag 10 on characters and use features derived from large-scale unlabeled data to further improve the performance. <ref type="bibr">11</ref> In addition to the pointwise mutual information (PMI), we also incorporate the character ELMo into our tokenizer. Embeddings of these features are concatenated along with a bigram character embeddings as input. These techniques lead to the best tokenization performance on all the related treebanks and the average improvement over udpipe baseline is 7.5 in tokenization F-score. 12</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Preprocessing for Thai</head><p>Thai language presents a unique challenge in the preprocessing. Our survey on the Thai Wikipedia indicates that there is no explicit sentence delimiter and obtaining Thai words requires tokenization. To remedy this, we use the whitespace as sentence delimiter and use the lexicon-based word segmentation -forward maximum matching algorithm for Thai tokenization. Our lexicon is derived from the fasttext word embeddings by preserving the top 10% frequent words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4">Lemmatization and Morphology Tagging</head><p>We did not make an effort on lemmatization and morphology tagging, but only use the baseline model. This lags our performance in the MLAS and BLEX evaluation, in which we were ranked 6th and 2nd correspondingly. However, since our method, especially incorporating ELMo, is not limited to particular task, we expect it to improve both the lemmatization and morphology tagging and achieve better MLAS and BLEX scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Implementation Details</head><p>Pretrained Word Embeddings. We use the 100-dimensional pretrained word embeddings released by the shared task for the large languages. For the small treebanks and treebanks for lowresource languages where cross-lingual transfer is required, we use the 300-dimensional fasttext word embeddings. Old French treebank (fro srcmf ) presents the only exceptions and we use the French embeddings instead. For all the embeddings, we only use 10% of the most frequent words.</p><p>ELMo. We use the same hyperparameter settings as <ref type="bibr" target="#b17">Peters et al. (2018)</ref> for BiLSTM (LM ) and the character CNN. We train their parameters as training a bidirectional language model on a set of 20-million-words data randomly sampled from the raw text released by the shared task for each language. Similar to <ref type="bibr" target="#b17">Peters et al. (2018)</ref>, we use the sample softmax technique to make training on large vocabulary feasible <ref type="bibr" target="#b10">(Jean et al., 2015)</ref>. However, we use a window of 8192 words surrounding the target word as negative samples and it shows better performance in our preliminary experiments. The training of ELMo on one language takes roughly 3 days on an NVIDIA P100 GPU.</p><p>Biaffine Parser. We use the same hyperparameter settings as <ref type="bibr" target="#b6">Dozat et al. (2017)</ref>. When trained with ELMo, we use a dropout of 33% on the projected vectors.</p><p>SCIR Tokenizer. We use a 50-dimensional character bigram embeddings. For the character ELMo whose input is a character, the language model predict next character in the same way as the word ELMo. The final model is an ensemble of five single segmentors.</p><p>Uppsala Segmentor. We use the default settings for the Uppsala segmentor and the final model is an ensemble of three single segmentors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.1">Effects of ELMo</head><p>We study the effect of ELMo on the large treebanks and report the results of a single tagger and parser with and without ELMo. <ref type="figure" target="#fig_1">Figure 1a</ref> shows the tagging results on the development set and <ref type="figure" target="#fig_1">Figure 1b</ref> shows the parsing results. Using ELMo in the tagger leads to a macro-averaged improvement of 0.56% in UPOS and the macro-averaged error reduction is 17.83%. Using ELMo in the parser leads to a macro-averaged improvement of 0.84% in LAS and the macro-averaged error reduction is 7.88%.   ELMo improves the tagging performance almost on every treebank, except for zh gsd and gl ctg. Similar trends are witnessed in the parsing experiments with ko kaist and pl lfg being the only treebanks where ELMo slightly worsens the performance.</p><p>We also study the relative improvements in dependence on the size of the treebank. The line in <ref type="figure" target="#fig_1">Figure 1a</ref> and <ref type="figure" target="#fig_1">Figure 1b</ref> shows the error reduction from using ELMo on each treebank. However, no clear relation is revealed between the treebank size and the gains using ELMo.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.2">Effects of Ensemble</head><p>We also test the effect of ensemble and show the results in <ref type="figure" target="#fig_2">Figure 2</ref>. Parser ensemble leads to an averaged improvement of 0.55% in LAS and the averaged error reduction is 4.0%. These results indicate that ensemble is an effective way to improve the parsing performance. The relationship between gains using ensemble and treebank size is also studied in this figure and the trend is that small treebank benefit more from the ensemble. We address this to the fact that the ensemble im-proves the model's generalization ability in which the parser trained on small treebank is weak due to overfitting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.3">Effects of Treebank Concatenation</head><p>As mentioned in Section 5, we study the effects of both the cross-domain concatenation and crosslingual concatenation.</p><p>Cross-Domain Concatenation. For the treebanks which have development set, the development performances are shown in <ref type="table" target="#tab_2">Table 2</ref>. Numbers of sentences in the training set are also shown in this table. The general trend is that for the treebank with small training set, cross-domain concatenation achieves better performance. While for those with large training set, concatenation does not improve the performance or even worsen the results.</p><p>For the small treebanks which do not have development set, the 5 fold cross validation results are shown in <ref type="table" target="#tab_4">Table 3</ref> in which concatenation improves most of the treebanks except for gl treegal.    <ref type="table">Table 5</ref>: The effects of improved preprocessing on the parsing performance. The first block shows the effects of sentence segmentation improvement. ∆-sent. means the sentence segmentation F-score difference between Uppsala segmentor and udpipe. The second block shows the effects of word segmentation improvement. ∆-word means the word segmentation in F-score difference between SCIR tokenizer and udpipe.</p><p>Cross-Lingual Concatenation. The experimental results of cross-lingual concatenation are shown in <ref type="table" target="#tab_5">Table 4</ref>. Unfortunately, concatenating treebanks from different languages only achieves improved performance on uk iu. This results also indicate that in cross lingual parsing, sophisticated methods like word embeddings transfer <ref type="bibr" target="#b8">(Guo et al., 2015</ref><ref type="bibr" target="#b9">(Guo et al., , 2016b</ref> and treebank transfer <ref type="bibr" target="#b7">(Guo et al., 2016a)</ref> are still necessary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.4">Effects of Better Preprocessing</head><p>We also study how preprocessing contributes to the final parsing performance. The experimental results on the development set are shown in Ta-ble 5. From this table, the performance of word segmentation is almost linearly correlated with the final performance. Similar trends on sentence segmentation performance are witnessed but el gdt and pt bosque presents some exceptions where better preprocess leads drop in the final parsing performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.5">Parsing Strategies and Test Set Evaluation</head><p>Using the development set and cross validation, we choose the best model and data combination and the choices are shown in <ref type="table">Table 6</ref> along with the test evaluation. From this table, we can see that our system gains more improvements when both ELMo and parser ensemble are used. For some treebanks, concatenation also contributes to the improvements. Parsing Japanese, Vietnamese, and Chinese clearly benefits from better word segmentation. Since most of the participant teams use single parser for their system, we also remove the parser ensemble and do a post-contest evaluation. The results are also shown in this table.</p><p>Our system without ensemble achieves an macroaveraged LAS of 75.26, which unofficially ranks the first according to LAS in the shared task. We report the time and memory consumption. A full run over the 82 test sets on the TIRA virtual machine <ref type="bibr" target="#b18">(Potthast et al., 2014)</ref> takes about 40 hours and consumes about 4G RAM memory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10">Conclusion</head><p>Our system submitted to the CoNLL 2018 shared task made several improvements on last year's winning system from <ref type="bibr" target="#b6">Dozat et al. (2017)</ref>, including incorporating deep contextualized word embeddings, parser ensemble, and treebank concatenation. Experimental results on the development set show the effectiveness of our methods. Using these techniques, our system achieved an averaged LAS of 75.84% and obtained the first place in LAS in the final evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11">Credits</head><p>There are a few references we would like to give proper credit, especially to data providers: the core Universal Dependencies paper from LREC 2016 <ref type="bibr" target="#b15">(Nivre et al., 2016)</ref>, the UD version 2.2 datasets , the baseline udpipe model released by <ref type="bibr" target="#b24">Straka et al. (2016)</ref>, the deep contextualized word embeddings code released by <ref type="bibr" target="#b17">Peters et al. (2018)</ref>, the biaffine tagger and parser released by <ref type="bibr" target="#b6">Dozat et al. (2017)</ref>, the joint sentence segmentor and tokenizer released by <ref type="bibr" target="#b4">de Lhoneux et al. (2017)</ref>, and the evaluation platform TIRA <ref type="bibr" target="#b18">(Potthast et al., 2014)</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>The effects of ELMo. Treebanks are sorted from the smallest to the largest.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>The effects of ensemble on dependency parsing. Treebanks are sorted according to the number of training sentences from left to right.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Cross-lingual transfer settings for lowresource target languages.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>The developement performance with cross-domain concatenation for languages which has multiple treebanks. single means training the parser on it own treebank without concatenation. # train shows the number of training sentences in the treebank measured in thousand.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>The 5-fold cross validation results for the cross-domain concatenation of treebank which does not have development set.</figDesc><table><row><cell></cell><cell>ug udt</cell><cell>uk iu</cell><cell>ga idt</cell><cell></cell><cell>sme giella</cell></row><row><cell>ug udt</cell><cell>69.27</cell><cell>uk iu 88.84</cell><cell>ga idt 62.84</cell><cell>sme giella</cell><cell>66.33</cell></row><row><cell>+tr imst</cell><cell>19.27</cell><cell>+ru syntagus 90.74</cell><cell>+en ewt 51.00</cell><cell>+fi ftb</cell><cell>59.86</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Cross-lingual concatenation results. The results for ug udt and uk iu are obtained on the development set. The results for ga idt and sme giella are obtained with udpipe by 5-fold cross validation.</figDesc><table><row><cell></cell><cell cols="3">∆-sent. udpipe uppsala</cell></row><row><cell>fi tdt</cell><cell>+0.69</cell><cell>88.13</cell><cell>88.67</cell></row><row><cell>et edt</cell><cell>+1.22</cell><cell>86.33</cell><cell>86.36</cell></row><row><cell>nl lassysmall</cell><cell>+1.39</cell><cell>88.08</cell><cell>88.60</cell></row><row><cell>da ddt</cell><cell>+1.56</cell><cell>86.21</cell><cell>86.51</cell></row><row><cell>el gdt</cell><cell>+1.57</cell><cell>90.08</cell><cell>89.96</cell></row><row><cell>cu proiel</cell><cell>+1.72</cell><cell>72.79</cell><cell>74.04</cell></row><row><cell>pt bosque</cell><cell>+1.83</cell><cell>90.73</cell><cell>90.20</cell></row><row><cell>id gsd</cell><cell>+2.46</cell><cell>74.14</cell><cell>78.83</cell></row><row><cell>la proiel</cell><cell>+4.82</cell><cell>73.21</cell><cell>74.22</cell></row><row><cell>got proiel</cell><cell>+5.36</cell><cell>67.55</cell><cell>68.40</cell></row><row><cell>grc proiel</cell><cell>+5.86</cell><cell>79.67</cell><cell>80.72</cell></row><row><cell>sl ssj</cell><cell>+18.81</cell><cell>88.43</cell><cell>92.27</cell></row><row><cell>it postwita</cell><cell>+30.40</cell><cell>74.91</cell><cell>79.26</cell></row><row><cell></cell><cell cols="2">∆-word udpipe</cell><cell>scir</cell></row><row><cell>ja gsd</cell><cell>+4.07</cell><cell>80.53</cell><cell>85.23</cell></row><row><cell>zh gsd</cell><cell>+7.16</cell><cell>66.16</cell><cell>75.78</cell></row><row><cell>vi vtb</cell><cell>+9.02</cell><cell>48.58</cell><cell>57.53</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">We opt out cs, fi, and pl because all the treebanks of these languages are relatively large -they have more than 10K training sentences.5  We use udpipe for this part of experiments because we consider the effect of treebank concatenation as being irrelevant to the parser architecture and udpipe has the speed advantage in both training and testing.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10">We use the BIES scheme. 11 For Vietnamese where whitespaces occur both inter-and intra-words, we treat the whitespace-separated token as a character.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank the reviewers for their insightful comments, and the HIT-SCIR colleagues for the coordination on the machine usage. This work was supported by the National Key Basic Research Program of China via grant 2014CB340503 and the National Natural Science Foundation of China (NSFC) via grant 61300113 and 61632011.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>. self denotes that the model is trained with the treebank itself. If the model field is not filled with self, the model is trained with treebank concatenation. The ref. column shows the top performing system if we are not top, or the second-best performing system on LAS. We also show the results without parser ensemble and our unofficial ranks of this system.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Waleed</forename><surname>Ammar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Mulcaire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><surname>Smith</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>Many languages, one parser. TACL 4.</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Ims at the conll 2017 ud shared task: Crfs and perceptrons meet neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Björkelund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agnieszka</forename><surname>Falenska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonas</forename><surname>Kuhn</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/K17-3004" />
	</analytic>
	<monogr>
		<title level="m">Proc. of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</title>
		<meeting>of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Enriching word vectors with subword information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<idno>abs/1607.04606</idno>
		<ptr target="http://arxiv.org/abs/1607.04606" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The hit-scir system for end-toend parsing of universal dependencies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanxiang</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiang</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huaipeng</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dechuan</forename><surname>Teng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/K17-3005" />
	</analytic>
	<monogr>
		<title level="m">Proc. of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</title>
		<meeting>of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">From raw text to universal dependencies -look, no tags!</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Miryam De Lhoneux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eliyahu</forename><surname>Basirat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sara</forename><surname>Kiperwasser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Stymne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nivre</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/K17-3022" />
	</analytic>
	<monogr>
		<title level="m">Proc. of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</title>
		<meeting>of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Deep biaffine attention for neural dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Dozat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<idno>abs/1611.01734</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Stanford&apos;s graph-based neural dependency parser at the conll 2017 shared task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Dozat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</title>
		<meeting>of CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A universal framework for inductive transfer parsing across multi-typed treebanks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiang</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanxiang</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haifeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Coling</title>
		<meeting>of Coling</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Cross-lingual dependency parsing based on distributed representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiang</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanxiang</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yarowsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haifeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A representation learning framework for multi-source transfer parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiang</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanxiang</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yarowsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haifeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2734" to="2740" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">On using very large target vocabulary for neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sébastien</forename><surname>Jean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roland</forename><surname>Memisevic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL</title>
		<meeting>of ACL</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Distilling knowledge for search-based structured prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yijia</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanxiang</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huaipeng</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
		<idno>abs/1805.11224</idno>
		<ptr target="http://arxiv.org/abs/1805.11224" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Parsing tweets into universal dependencies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yijia</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanxiang</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/N18-1088" />
	</analytic>
	<monogr>
		<title level="m">Proc. of NAACL</title>
		<meeting>of NAACL</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Neural probabilistic model for non-projective mst parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuezhe</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IJCNLP</title>
		<meeting>of IJCNLP</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Stackpointer networks for dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuezhe</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zecong</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingzhou</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nanyun</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><forename type="middle">H</forename><surname>Hovy</surname></persName>
		</author>
		<idno>abs/1805.01087</idno>
		<ptr target="http://arxiv.org/abs/1805.01087" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Universal Dependencies v1: A multilingual treebank collection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Catherine</forename><surname>De Marneffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filip</forename><surname>Ginter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Hajič</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sampo</forename><surname>Pyysalo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of LREC-2016</title>
		<meeting>of LREC-2016<address><addrLine>Natalia Silveira, Reut Tsarfaty, and Daniel Zeman</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Universal Dependencies 2.2. LINDAT/CLARIN digital library at the Institute of Formal and Applied Linguistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<ptr target="http://hdl.handle.net/11234/SUPPLYTHENEWPERMANENTIDHERE!" />
	</analytic>
	<monogr>
		<title level="j">Charles University</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Deep contextualized word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NAACL</title>
		<meeting>of NAACL</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Improving the reproducibility of PAN&apos;s shared tasks: Plagiarism detection, author identification, and author profiling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Efstathios</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benno</forename><surname>Stein</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-11382-1_{}22</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-11382-122" />
	</analytic>
	<monogr>
		<title level="m">Information Access Evaluation meets Multilinguality, Multimodality, and Visualization. 5th International Conference of the CLEF Initiative</title>
		<editor>Evangelos Kanoulas, Mihai Lupu</editor>
		<meeting><address><addrLine>Paul Clough, Mark Sanderson, Mark Hall, Allan Hanbury, and Elaine Toms; Berlin Heidelberg New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="268" to="299" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Reporting score distributions makes a difference: Performance study of lstm-networks for sequence tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nils</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Cross-lingual word segmentation and morpheme segmentation as sequence labelling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Shao</surname></persName>
		</author>
		<idno>abs/1709.03756</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Fast(er) exact decoding and global training for transition-based dependency parsing via a minimal feature set</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianze</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP</title>
		<meeting>of EMNLP</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Combining global models for parsing universal dependencies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianze</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><forename type="middle">G</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xilun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yao</forename><surname>Cheng</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/K17-3003" />
	</analytic>
	<monogr>
		<title level="m">Proc. of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</title>
		<meeting>of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Offline bilingual word vectors, orthogonal transformations and the inverted softmax</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">P</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Turban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nils</forename><forename type="middle">Y</forename><surname>Hamblin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hammerla</surname></persName>
		</author>
		<idno>abs/1702.03859</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">UD-Pipe: trainable pipeline for processing CoNLL-U files performing tokenization, morphological analysis, POS tagging and parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milan</forename><surname>Straka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Hajič</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jana</forename><surname>Straková</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of LREC-2016</title>
		<meeting>of LREC-2016</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Zeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filip</forename><surname>Ginter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Hajič</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Popel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milan</forename><surname>Straka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</title>
		<meeting>of the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Zeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Popel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milan</forename><surname>Straka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Hajič</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filip</forename><surname>Ginter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juhani</forename><surname>Luotolahti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sampo</forename><surname>Pyysalo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francis</forename><surname>Tyers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elena</forename><surname>Badmaeva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Memduh</forename><surname>Gökırmak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Nedoluzhko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvie</forename><surname>Cinková</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Hajič Jr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaroslava</forename><surname>Hlaváčová</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Václava</forename><surname>Kettnerová</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zdeňka</forename><surname>Urešová</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenna</forename><surname>Kanerva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stina</forename><surname>Ojala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Missilä</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siva</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dima</forename><surname>Taji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nizar</forename><surname>Habash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herman</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Catherine</forename><surname>De Marneffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manuela</forename><surname>Sanguinetti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Simi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroshi</forename><surname>Kanayama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Jana Strnadova</title>
		<editor>Valeria de Paiva, Kira Droganova, Héctor Martínez Alonso, Ç agrı Çöltekin, Umut Sulubacak, Hans Uszkoreit, Vivien Macketanz, Aljoscha Burchardt, Kim Harris, Katrin Marheinecke, Georg Rehm, Tolga Kayadelen, Mohammed Attia, Ali Elkahky, Zhuoran Yu, Emily Pitler, Saran Lertpradit, Michael Mandl, Jesse Kirchner, Hector Fernandez Alcalde</editor>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Enhancing lstm-based word segmentation using unlabeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanxiang</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiang</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Chinese Computational Linguistics and Natural Language Processing Based on Naturally Annotated Big Data</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
