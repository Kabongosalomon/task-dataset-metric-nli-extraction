<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">How to Train Your Energy-Based Model for Regression</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fredrik</forename><forename type="middle">K</forename><surname>Gustafsson</surname></persName>
							<email>fredrik.gustafsson@it.uu.se</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Information Technology</orgName>
								<orgName type="institution">Uppsala University</orgName>
								<address>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Danelljan</surname></persName>
							<email>martin.danelljan@vision.ee.ethz.ch</email>
							<affiliation key="aff1">
								<orgName type="laboratory">Computer Vision Lab ETH Zürich</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Timofte</surname></persName>
							<email>radu.timofte@vision.ee.ethz.ch</email>
							<affiliation key="aff1">
								<orgName type="laboratory">Computer Vision Lab ETH Zürich</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">B</forename><surname>Schön</surname></persName>
							<email>thomas.schon@it.uu.se</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Information Technology</orgName>
								<orgName type="institution">Uppsala University</orgName>
								<address>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">How to Train Your Energy-Based Model for Regression</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>F.K. GUSTAFSSON ET AL.: HOW TO TRAIN YOUR EBM FOR REGRESSION 1</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T16:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Energy-based models (EBMs) have become increasingly popular within computer vision in recent years. While they are commonly employed for generative image modeling, recent work has applied EBMs also for regression tasks, achieving state-of-the-art performance on object detection and visual tracking. Training EBMs is however known to be challenging. While a variety of different techniques have been explored for generative modeling, the application of EBMs to regression is not a well-studied problem. How EBMs should be trained for best possible regression performance is thus currently unclear. We therefore accept the task of providing the first detailed study of this problem. To that end, we propose a simple yet highly effective extension of noise contrastive estimation, and carefully compare its performance to six popular methods from literature on the tasks of 1D regression and object detection. The results of this comparison suggest that our training method should be considered the go-to approach. We also apply our method to the visual tracking task, achieving state-of-the-art performance on five datasets. Notably, our tracker achieves 63.7% AUC on LaSOT and 78.7% Success on TrackingNet. Code is available at https://github.com/fregu856/ebms_regression.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Energy-based models (EBMs) <ref type="bibr" target="#b28">[29]</ref> have a rich history in machine learning <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b50">51]</ref>. An EBM specifies a probability density p(x; θ ) = e f θ (x) / e f θ (x) dx directly via a parameterized scalar function f θ (x). By defining f θ (x) using a deep neural network (DNN), p(x; θ ) becomes expressive enough to learn practically any density from observed data. EBMs have therefore become increasingly popular within computer vision in recent years, commonly being applied for various generative image modeling tasks <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b56">57]</ref>.</p><p>Recent work <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b14">15]</ref> has also explored conditional EBMs as a general formulation for regression, demonstrating particularly impressive performance on the tasks of object detection <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b58">59]</ref> and visual tracking <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b29">30]</ref>. Regression entails predicting a continuous target y from an input x, given a training set of observed input-target pairs. This was addressed c 2020. The copyright of this document resides with its authors. It may be distributed unchanged freely in print or electronic forms. arXiv:2005.01698v2 [cs.CV] 14 Aug 2020 <ref type="figure">Figure 1</ref>: We propose NCE+ to train EBMs p(y|x; θ ) for tasks such as bounding box regression. NCE+ is a highly effective extension of NCE, accounting for noise in the annotation process of real-world datasets. Given a label y i (red box), the EBM is trained by having to discriminate between y i + ν i (yellow box) and noise samples {y (i,m) } M m=1 (blue boxes).</p><p>in <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b14">15]</ref> by learning a conditional EBM p(y|x; θ ), capturing the distribution of the target value y given the input x. At test time, gradient ascent was then used to maximize p(y|x; θ ) w.r.t. y, producing highly accurate predictions. Regression is a fundamental problem within computer vision with many additional applications <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b57">58]</ref>, which all would benefit from such accurate predictions. In this work, we therefore study the use of EBMs for regression in detail, aiming to further improve its performance and applicability. While the modeling capacity of EBMs makes them highly attractive for many applications, training EBMs is known to be challenging. This is because the EBM p(x; θ ) = e f θ (x) / e f θ (x) dx involves an intractable integral, complicating the use of standard maximum likelihood (ML) learning. A variety of different techniques have therefore been explored in the generative modeling literature, including alternative estimation methods <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b51">52]</ref> and approximations based on Markov chain Monte Carlo (MCMC) <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b41">42]</ref>. The application of EBMs for regression is however not a particularly well-studied problem. <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b14">15]</ref> both applied importance sampling to approximate intractable integrals, an approach known to scale poorly with the data dimensionality, and considered no alternative techniques. How EBMs p(y|x; θ ) should be trained for best possible performance on computer vision regression tasks is thus an open question, which we set out to investigate in this work.</p><p>Contributions We propose a simple yet highly effective extension of noise contrastive estimation (NCE) <ref type="bibr" target="#b15">[16]</ref> to train EBMs p(y|x; θ ) for regression tasks. Our proposed method, termed NCE+, can be understood as a direct generalization of NCE, accounting for noise in the annotation process. We evaluate NCE+ on illustrative 1D regression problems and on the task of bounding box regression in object detection. We also provide a detailed comparison of NCE+ and six popular methods from previous work, the results of which suggest that NCE+ should be considered the go-to training method. Lastly, we apply our proposed NCE+ to the task of visual tracking, achieving state-of-the-art results on five common datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Energy-Based Models for Regression</head><p>We study the application of EBMs to important regression tasks in computer vision, using energy-based models of the conditional density p(y|x). Here, we first define the general regression problem and our employed EBM in Section 2.1. Our prediction strategy based on gradient ascent is then described in Section 2.2. Lastly, we discuss the challenges associated with training EBMs, and describe six popular methods from the literature, in Section 2.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Problem &amp; Model Definition</head><p>In a supervised regression problem, we are given a training set D of i.i.d. input-target pairs,</p><formula xml:id="formula_0">D = {(x i , y i )} N i=1 , (x i , y i ) ∼ p(x, y).</formula><p>The task is then to learn how to predict a target y ∈ Y given a new input x ∈ X . The target space Y is continuous, Y = R K for some K ≥ 1, and the input space X usually corresponds to the space of images.</p><p>As in <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b14">15]</ref>, we address this problem by creating an energy-based model p(y|x; θ ) of the conditional target density p(y|x). To that end, we specify a DNN f θ : X × Y → R with model parameters θ ∈ R P . This DNN directly maps any input-target pair (x, y) ∈ X × Y to a scalar f θ (x, y) ∈ R. The model p(y|x; θ ) of the conditional target density is then defined as,</p><formula xml:id="formula_1">p(y|x; θ ) = e f θ (x,y) Z(x, θ ) , Z(x, θ ) = e f θ (x,ỹ) dỹ,<label>(1)</label></formula><p>where the DNN output f θ (x, y) ∈ R is interpreted as the negative energy of the density, and Z(x, θ ) is the input-dependent normalizing partition function. Since p(y|x; θ ) in (1) is directly defined by the DNN f θ , minimal restricting assumptions are put on the true p(y|x). The predictive power of the DNN can thus be fully exploited, enabling learning of, e.g., multimodal and asymmetric densities directly from data. This expressivity however comes at the cost of Z(x, θ ) being intractable, which complicates evaluating or sampling from p(y|x; θ ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Prediction</head><p>At test time, the problem of predicting a target value y from an input x corresponds to finding a point estimate of the predicted conditional density p(y|x ; θ ). The most natural choice is to select the most likely target under the model, y = arg max y p(y|x ; θ ) = arg max y f θ (x , y). The prediction y is thus obtained by directly maximizing the DNN scalar output f θ (x , y) w.r.t. y, not requiring Z(x , θ ) to be evaluated nor any samples from p(y|x ; θ ) to be generated. Following <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b14">15]</ref>, we estimate y = arg max y f θ (x , y) by performing gradient ascent to refine an initial estimateŷ and find a local maximum of f θ (x , y).</p><p>Starting at y =ŷ, we thus run T gradient ascent iterations, y ← y + λ ∇ y f θ (x , y), with steplength λ . An algorithm for this prediction procedure is found in the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Training</head><p>To train the DNN f θ (x, y) specifying the EBM (1), different techniques for fitting a density p(y|x; θ ) to observed data {(x i , y i )} N i=1 can be used. In general, the most commonly applied such technique is ML learning, which entails minimizing the negative log-likelihood (NLL),</p><formula xml:id="formula_2">− N ∑ i=1 log p(y i |x i ; θ ) = N ∑ i=1 log e f θ (x i ,y) dy − f θ (x i , y i ),<label>(2)</label></formula><p>w.r.t. the parameters θ . The integral in (2) is however intractable, and exact evaluation of the NLL is thus not possible. <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b14">15]</ref> employed importance sampling to approximate such intractable integrals, obtaining state-of-the-art performance on object detection and visual tracking. Recent work <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b47">48]</ref> on generative image modeling has however applied a variety of different training methods not considered in <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b14">15]</ref>, including the ML learning alternatives NCE <ref type="bibr" target="#b15">[16]</ref> and score matching <ref type="bibr" target="#b20">[21]</ref>. How we should train the DNN f θ to obtain best possible regression performance is thus unclear. In this work, we therefore carefully compare our proposed method to six popular training methods from the literature.</p><p>ML with Importance Sampling (ML-IS) A straightforward training method is proposed in <ref type="bibr" target="#b14">[15]</ref>, which we term ML with Importance Sampling (ML-IS). Using ML-IS, <ref type="bibr" target="#b14">[15]</ref> successfully applied the EBM (1) to the regression tasks of object detection, visual tracking, age estimation and head-pose estimation. In ML-IS, the DNN f θ is trained by directly minimizing the NLL (2) w.r.t. θ , using importance sampling to approximate the intractable integral,</p><formula xml:id="formula_3">− log p(y i |x i ; θ ) ≈ log 1 M M ∑ m=1 e f θ (x i ,y (i,m) ) q(y (i,m) |y i ) − f θ (x i , y i ).<label>(3)</label></formula><p>Here, {y (i,m) } M m=1 are M samples drawn from a proposal distribution q(y|y i ) that depends on the ground truth target y i . In <ref type="bibr" target="#b14">[15]</ref>, q(y|y i ) is set to a mixture of K Gaussians centered at y i ,</p><formula xml:id="formula_4">q(y|y i ) = 1 K K ∑ k=1 N (y; y i , σ 2 k I).<label>(4)</label></formula><p>The loss J(θ ) is obtained by averaging over all pairs {(x i , y i )} n i=1 in the current mini-batch,</p><formula xml:id="formula_5">J(θ ) = 1 n n ∑ i=1 log 1 M M ∑ m=1 e f θ (x i ,y (i,m) ) q(y (i,m) |y i ) − f θ (x i , y i ).<label>(5)</label></formula><p>KL Divergence with Importance Sampling (KLD-IS) Instead of minimizing the NLL (2), <ref type="bibr" target="#b8">[9]</ref> considers the Kullback-Leibler (KL) divergence D KL (p(y|y i ) p(y|x i ; θ )) between the EBM p(y|x i ; θ ) and an assumed density p(y|y i ) of the true target y given the label y i . The density p(y|y i ) models noise in the annotation process of our given training set D = {(x i , y i )} N i=1 . In <ref type="bibr" target="#b8">[9]</ref>, p(y|y i ) = N (y; y i , σ 2 I), where σ is a hyperparameter. As shown in <ref type="bibr" target="#b8">[9]</ref>,</p><formula xml:id="formula_6">D KL (p(y|y i ) p(y|x i ; θ )) = log e f θ (x i ,y) dy − f θ (x i , y)p(y|y i )dy +C,<label>(6)</label></formula><p>where C is a constant that does not depend on θ . <ref type="bibr" target="#b8">[9]</ref> approximates the integrals in (6) using importance sampling, employing the ML-IS proposal q(y|y i ) in (4). By then averaging over all pairs {(x i , y i )} n i=1 in the current mini-batch, the loss J(θ ) used to train f θ is obtained as,</p><formula xml:id="formula_7">J(θ ) = 1 n n ∑ i=1 log 1 M M ∑ m=1 e f θ (x i ,y (i,m) ) q(y (i,m) |y i ) − 1 M M ∑ m=1 f θ (x i , y (i,m) ) p(y (i,m) |y i ) q(y (i,m) |y i ) ,<label>(7)</label></formula><p>where {y (i,m) } M m=1 are M samples drawn from the proposal q(y|y i ). We term this training method KL Divergence with Importance Sampling (KLD-IS). When applied to visual tracking in <ref type="bibr" target="#b8">[9]</ref>, KLD-IS outperformed ML-IS and set a new state-of-the-art.</p><p>ML with MCMC (ML-MCMC) To minimize the NLL (2) w.r.t. the parameters θ , the following identity for the expression of the gradient ∇ θ − log p(y i |x i ; θ ) can be utilized <ref type="bibr" target="#b28">[29]</ref>,</p><formula xml:id="formula_8">∇ θ − log p(y i |x i ; θ ) = E p(y|x i ;θ ) ∇ θ f θ (x i , y) − ∇ θ f θ (x i , y i ).<label>(8)</label></formula><p>The expectation in <ref type="formula" target="#formula_8">(8)</ref> is then approximated using samples {y (i,m) } M m=1 drawn from p(y|x i ; θ ), i.e. from the EBM itself. To obtain each sample y (i,m) ∼ p(y|x i ; θ ), MCMC is used. Specifically, we follow recent work <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b56">57]</ref> on generative image modeling and run L ≥ 1 steps of Langevin dynamics <ref type="bibr" target="#b53">[54]</ref>. Starting at y (0) , we thus update y (l) according to,</p><formula xml:id="formula_9">y (l+1) = y (l) + α 2 2 ∇ y f θ (x i , y (l) ) + αε l , ε l ∼ N (0, I),<label>(9)</label></formula><p>and set y (i,m) = y (L) . Here, α &gt; 0 is a small constant step-length. Following the principle of contrastive divergence <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b50">51]</ref>, we start the Markov chain (9) at the ground truth target, y (0) = y i . By approximating (8) with the samples {y (i,m) } M m=1 , and by averaging over all pairs</p><formula xml:id="formula_10">{(x i , y i )} n i=1</formula><p>in the current mini-batch, the loss J(θ ) used to train the DNN f θ is obtained as,</p><formula xml:id="formula_11">J(θ ) = 1 n n ∑ i=1 1 M M ∑ m=1 f θ (x i , y (i,m) ) − f θ (x i , y i ).<label>(10)</label></formula><p>We term this specific training method ML with MCMC (ML-MCMC).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Noise Contrastive Estimation (NCE)</head><p>As an alternative to ML learning, Gutmann and Hyvärinen proposed NCE <ref type="bibr" target="#b15">[16]</ref> for estimating unnormalized parametric models. NCE entails generating samples from some noise distribution p N , and learning to discriminate between these noise samples and observed data examples. It has recently been applied to generative image modeling with EBMs <ref type="bibr" target="#b12">[13]</ref>, and the NCE loss is also utilized in various frameworks for self-supervised learning <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b18">19]</ref>. Moreover, NCE has been applied to train EBMs for supervised classification tasks within language modeling <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b36">37]</ref>, where the target space Y is a large but finite set of possible labels. We adopt NCE for regression by using a noise distribution p N (y|y i ) of the same form as the ML-IS proposal in <ref type="bibr" target="#b3">(4)</ref>,</p><formula xml:id="formula_12">p N (y|y i ) = 1 K K ∑ k=1 N (y; y i , σ 2 k I),<label>(11)</label></formula><p>and by employing the ranking NCE objective <ref type="bibr" target="#b22">[23]</ref>, as described in <ref type="bibr" target="#b33">[34]</ref>. We choose ranking NCE over the binary objective since it is consistent under a weaker assumption <ref type="bibr" target="#b33">[34]</ref>. We thus define y (i,0) y i , and train the DNN f θ by minimizing the following loss,</p><formula xml:id="formula_13">J(θ ) = − 1 n n ∑ i=1 log exp f θ (x i , y (i,0) ) − log p N (y (i,0) |y i ) ∑ M m=0 exp f θ (x i , y (i,m) ) − log p N (y (i,m) |y i ) ,<label>(12)</label></formula><p>where {y (i,m) } M m=1 are M noise samples drawn from p N (y|y i ) in <ref type="bibr" target="#b10">(11)</ref>. Score Matching (SM) Another alternative estimation method is score matching (SM), as proposed by Hyvärinen <ref type="bibr" target="#b20">[21]</ref> and further studied for supervised problems in <ref type="bibr" target="#b48">[49]</ref>. The method focuses on the score of p(y|x; θ ), defined as ∇ y log p(y|x; θ ) = ∇ y f θ (x, y), aiming for it to approximate the score of the true target density p(y|x). Note that the EBM score ∇ y f θ (x, y) does not depend on the intractable Z(x, θ ). SM was applied to simple conditional density estimation problems in <ref type="bibr" target="#b48">[49]</ref>, using a combination of feed-forward networks and reproducing kernels to specify the EBM. Following <ref type="bibr" target="#b48">[49]</ref>, we train the DNN f θ by minimizing the loss,</p><formula xml:id="formula_14">J(θ ) = 1 n n ∑ i=1 tr ∇ 2 y f θ (x i , y i ) + 1 2 ∇ y f θ (x i , y i ) 2 2 ,<label>(13)</label></formula><p>where only the diagonal of ∇ 2 y f θ (x i , y i ) actually is needed to compute the first term. Denoising Score Matching (DSM) By modifying the SM objective, denoising score matching (DSM) was proposed by Vincent <ref type="bibr" target="#b51">[52]</ref>. DSM does not require computation of any second derivatives, improving its scalability to high-dimensional data. The method entails employing SM on noise-corrupted data points. Recently, DSM has been successfully applied to generative image modeling <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b49">50]</ref>. DSM was also extended to train EBMs of conditional densities in <ref type="bibr" target="#b23">[24]</ref>, where it was applied to a transfer learning problem. Following <ref type="bibr" target="#b23">[24]</ref>, we use a Gaussian noise distribution and train the DNN f θ by minimizing the loss,</p><formula xml:id="formula_15">J(θ ) = 1 n n ∑ i=1 1 M M ∑ m=1 ∇ y f θ (x i ,ỹ (i,m) ) +ỹ (i,m) − y i σ 2 2 2 ,<label>(14)</label></formula><p>where</p><formula xml:id="formula_16">{ỹ (i,m) } M m=1 are M samples drawn from the noise distribution p σ (ỹ|y i ) = N (ỹ; y i , σ 2 I).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Proposed Training Method</head><p>To train the DNN f θ specifying our EBM p(y|x; θ ) in <ref type="formula" target="#formula_1">(1)</ref>, we propose a simple yet highly effective extension of NCE <ref type="bibr" target="#b15">[16]</ref>. Motivated by the improved performance of KLD-IS compared to ML-IS on visual tracking <ref type="bibr" target="#b8">[9]</ref>, we extend NCE with the capability to model annotation noise. To that end, we adopt the standard NCE noise distribution p N (11) and loss <ref type="bibr" target="#b11">(12)</ref>, but instead of defining</p><formula xml:id="formula_17">y (i,0) y i , we sample ν i ∼ p β (y) and define y (i,0) y i + ν i . The distribution p β is a zero-centered version of p N in which {σ k } K k=1 are scaled with β &gt; 0, p N (y|y i ) = 1 K K ∑ k=1 N (y; y i , σ 2 k I), p β (y) = 1 K K ∑ k=1 N (y; 0, β σ 2 k I).<label>(15)</label></formula><p>Instead of training the DNN f θ by learning to discriminate between noise samples {y (i,m) } M m=1 and the label y i , it thus has to discriminate between the samples {y (i,m) } M m=1 and y i + ν i . Examples of y i + ν i and {y (i,m) } M m=1 in the task of bounding box regression are visualized in <ref type="figure">Figure 1</ref>. Similar to KLD-IS, in which an assumed density of the true target value y given y i is employed, our approach thus accounts for possible noise and inaccuracies in the provided label y i . Specifically, our proposed training method entails sampling {y (i,m) } M m=1 ∼ p N (y|y i ) and ν i ∼ p β (y), setting y (i,0) y i + ν i , and minimizing the following loss,</p><formula xml:id="formula_18">J(θ ) = − 1 n n ∑ i=1 log exp f θ (x i , y (i,0) ) − log p N (y (i,0) |y i ) ∑ M m=0 exp f θ (x i , y (i,m) ) − log p N (y (i,m) |y i ) .<label>(16)</label></formula><p>As β → 0, samples ν i ∼ p β (y) will concentrate increasingly close to zero, and the standard NCE method is in practice recovered. Our proposed training method can thus be understood as a direct generalization of NCE. Compared to NCE, our method adds no significant training cost and requires tuning of a single additional hyperparameter β . A value for β is selected in a simple two-step procedure. First, we fix y (i,0) = y i and select the standard deviations {σ k } K k=1 based on validation set performance, just as in NCE. We then fix {σ k } K k=1 and vary β to find the value corresponding to maximum validation performance. Typically, we start this ablation with β = 0.1. We term our proposed training method NCE+.    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Comparison of Training Methods</head><p>We provide a detailed comparison of the six training methods from Section 2.3 and our proposed NCE+. To that end, we perform extensive experiments on 1D regression (Section 4.1) and object detection (Section 4.2). Our findings are summarized in Section 4.3. All experiments are implemented in PyTorch <ref type="bibr" target="#b44">[45]</ref> and the code is publically available. For both tasks, further details and results are also provided in the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">1D Regression Experiments</head><p>We first perform experiments on illustrative 1D regression problems. The DNN f θ (x, y) is here a simple feed-forward network, taking x ∈ R and y ∈ R as inputs. We employ two synthetic datasets, and evaluate the training methods by how well the learned model p(y|x; θ ) (1) approximates the known ground truth p(y|x), as measured by the KL divergence D KL .</p><p>Results A comparison of all seven training methods in terms of D KL and training cost (seconds per epoch) is found in <ref type="table" target="#tab_1">Table 1</ref>. For ML-MCMC, we include results for L ∈ {1, 16, 256} Langevin steps <ref type="bibr" target="#b8">(9)</ref>. We observe that ML-IS, KLD-IS, NCE and NCE+ clearly have the best performance. While ML-MCMC is relatively close in terms of D KL for L = 256, this comes at the expense of a massive increase in training cost. DSM outperforms SM in terms of both metrics, but is not close to the top-performing methods. The four best methods are further compared in <ref type="figure" target="#fig_0">Figure 2</ref>, showing D KL as a function of M. Here, we observe that NCE and NCE+ significantly outperform ML-IS and KLD-IS for small number of samples M.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Object Detection Experiments</head><p>Next, we evaluate the methods on the task of bounding box regression in object detection. We employ an identical network architecture for f θ (x, y) as in <ref type="bibr" target="#b14">[15]</ref>. An extra network branch,   <ref type="bibr" target="#b31">[32]</ref>. Our proposed NCE+ achieves the best performance.</p><p>consisting of three fully-connected layers with parameters θ , is thus added onto a pre-trained and fixed FPN Faster-RCNN detector <ref type="bibr" target="#b32">[33]</ref>. Given an image x and bounding box y ∈ R 4 , the image is first processed by the detector backbone network (ResNet50-FPN), outputting image features h 1 (x). Using a differentiable PrRoiPool <ref type="bibr" target="#b21">[22]</ref> layer, h 1 (x) is then pooled to extract features h 2 (x, y). Finally, h 2 (x, y) is processed by the added network branch, outputting f θ (x, y) ∈ R. As in <ref type="bibr" target="#b14">[15]</ref>, predictions y are produced by performing guided NMS <ref type="bibr" target="#b21">[22]</ref> followed by gradient-based refinement (Section 2.2), taking the Faster-RCNN detections as initial estimatesŷ. Experiments are performed on the large-scale COCO dataset <ref type="bibr" target="#b31">[32]</ref>. We use the 2017 train split (≈ 118 000 images) for training, the 2017 val split (≈ 5 000 images) for setting hyperparameters, and report results on the 2017 test-dev split (≈ 20 000 images). The standard COCO metrics AP, AP <ref type="bibr" target="#b49">50</ref> and AP 75 are used, where AP is the primary metric.</p><p>Results A comparison of the training methods in terms of the COCO metrics and training cost (seconds per iteration) is found in <ref type="table" target="#tab_3">Table 2</ref>. Since DSM clearly outperformed SM in the 1D regression experiments, we here only include DSM. For ML-MCMC, results for L ∈ {1, 4, 8} are included. We observe that ML-IS, KLD-IS, NCE and NCE+ clearly have the best performance. In terms of the COCO metrics, NCE+ outperforms NCE and all other methods. ML-IS is also outperformed by KLD-IS. The four top-performing methods are further compared in <ref type="figure" target="#fig_1">Figure 3</ref>, in terms of AP as a function of the number of samples M. NCE and NCE+ here demonstrate clear superior performance for small values of M, and do not experience numerical issues even for M =1. KLD-IS improves this robustness compared ML-IS, but is not close to matching NCE or NCE+. In terms of training cost, the four top-performing methods are virtually identical. For ML-IS, e.g., we observe in <ref type="figure">Figure 4</ref> that setting M =1 decreases the training cost with 23% compared to the standard case of M =128.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analysis of NCE+ Hyperparameters</head><p>How the value of β &gt; 0 in p β (15) affects validation performance is studied in <ref type="figure">Figure 5</ref>. Here, we observe that quite a large range of values improve the performance compared to the NCE baseline (β → 0), before it eventually degrades for β 0.3. We also observe that the performance is optimized for β = 0.1. In <ref type="figure">Figure 5</ref>, the standard deviations {σ k } K k=1 in p N , p β (15) are set to {0.075, 0.15, 0.3}. These values are selected in an initial step based on an ablation study for NCE, which is found in <ref type="table">Table S4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Discussion</head><p>The results on both set of experiments are highly consistent. First of all, ML-IS, KLD-IS, NCE and NCE+ are by far the top-performing training methods. ML-MCMC, the method commonly employed for generative image modeling in recent years, does not come close to matching these top-performing methods, especially not given similar computational budgets. When studying the performance as a function of the number of samples M, NCE and NCE+ are the superior methods by a significant margin. In particular, this study demonstrates that the NCE and NCE+ losses are numerically more stable than those of ML-IS and KLD-IS. In   <ref type="table">Table 3</ref>: Ablation study for NCE, on the 2017 val split of COCO <ref type="bibr" target="#b31">[32]</ref>.</p><p>the 1D regression problems, which employ synthetic datasets without any annotation noise, NCE and NCE+ have virtually identical performance. In the object detection experiments however, where we employ real-world datasets, NCE+ consistently improves the NCE performance. On object detection, NCE+ also improves or matches the performance of KLD-IS, which explicitly models annotation noise and outperforms ML-IS. Overall, the results of the comparison suggest that our proposed NCE+ should be considered the go-to training method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Visual Tracking Experiments</head><p>Lastly, we apply our proposed NCE+ to the task of visual tracking. Specifically, we consider generic visual object tracking, which entails estimating the bounding box y ∈ R 4 of a target object in every frame of a video. The target object does not belong to any pre-specified class, but is instead defined by a given bounding box in the initial video frame. We compare the performance both to NCE and KLD-IS, and to state-of-the-art trackers. Code and trained models are available at <ref type="bibr" target="#b6">[7]</ref>. Further details are also found in the supplementary material.</p><p>Tracking Approach We base our tracker on the recent DiMP <ref type="bibr" target="#b4">[5]</ref> and PrDiMP <ref type="bibr" target="#b8">[9]</ref>. The target object is thus first coarsely localized in the current video frame via 2D image-coordinate regression of its center point, emphasizing robustness over accuracy. Then, the full bounding box y ∈ R 4 of the target is accurately regressed by gradient-based refinement (Section 2.2). The two stages employ separate network branches which are trained jointly end-to-end. As a strong baseline, we combine the DiMP method for center point regression with the PrDiMP bounding box regression approach. We term this resulting tracker DiMP-KLD-IS. By also modifying common training parameters (batch size, data augmentation etc.), DiMP-KLD-IS significantly outperforms both DiMP and PrDiMP. Our proposed tracker, termed DiMP-NCE+, is then obtained simply by using NCE+ instead of KLD-IS to train the bounding box regression branch. In both cases, the number of samples M = 128. As in <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b8">9]</ref>, the training splits of TrackingNet <ref type="bibr" target="#b38">[39]</ref>, LaSOT <ref type="bibr" target="#b10">[11]</ref>, GOT-10k <ref type="bibr" target="#b19">[20]</ref> and COCO <ref type="bibr" target="#b31">[32]</ref>   <ref type="table">Table 4</ref>: Results for the visual tracking experiments. The AUC (Success) metric is reported on five common datasets. Our proposed DiMP-NCE+ tracker significantly outperforms strong baselines and achieves state-of-the-art performance on all five datasets. For SiamRCNN <ref type="bibr" target="#b52">[53]</ref>, results for the ResNet50 version are given in parentheses when available.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>We evaluate DiMP-NCE+ on five commonly used tracking datasets. Tracking-Net <ref type="bibr" target="#b38">[39]</ref> is a large-scale dataset containing videos sampled from YouTube. Results are reported on its test set of 511 videos. We also evaluate on the LaSOT <ref type="bibr" target="#b10">[11]</ref> test set, containing 280 long videos (2 500 frames on average). Moreover, we report results on the UAV123 <ref type="bibr" target="#b37">[38]</ref> dataset, consisting of 123 videos which feature small targets and distractor objects. Results are also reported on the 30 FPS version of the need for speed (NFS) <ref type="bibr" target="#b24">[25]</ref> dataset, containing 100 videos with fast motions. Finally, we evaluate on the 100 videos of OTB-100 <ref type="bibr" target="#b54">[55]</ref>. Our tracker is evaluated in terms of overlap precision (OP). For a threshold T ∈ [0, 1], OP T is the percentage of frames in which the IoU overlap between the estimated and ground truth target bounding box is larger than T . By averaging OP T over T ∈ [0, 1], the AUC score is then obtained. For TrackingNet, the term Success is used in place of AUC. Results in terms of AUC on all five datasets are found in <ref type="table">Table 4</ref>. To ensure significance, the average AUC over 5 runs is reported for our trackers. We observe that DiMP-NCE+ consistently outperforms both our DiMP-KLD-IS baseline, and a variant employing NCE instead of NCE+. Compared to previous approaches, only the very recent SiamRCNN <ref type="bibr" target="#b52">[53]</ref> achieves results competitive with our DiMP-NCE+. SiamRCNN is however slower than DiMP-NCE+ (5 FPS vs 30 FPS) and employs a larger backbone network (ResNet101 vs ResNet50). Results for the ResNet50 version of SiamRCNN are only available on two of the datasets, on which it is outperformed by our DiMP-NCE+. More detailed results are provided in the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We proposed a simple yet highly effective extension of NCE to train EBMs p(y|x; θ ) for computer vision regression tasks. Our proposed method NCE+ can be understood as a direct generalization of NCE, accounting for noise in the annotation process of real-world datasets. We also provided a detailed comparison of NCE+ and six popular methods from literature, the results of which suggest that NCE+ should be considered the go-to training method. This comparison is the first comprehensive study of how EBMs should be trained for best possible regression performance. Finally, we applied our proposed NCE+ to the task of visual tracking, achieving state-of-the-art performance on five commonly used datasets. We hope that our simple training method and promising results will encourage the research community to further explore the application of EBMs to various regression tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1 Datasets</head><p>The ground truth p(y|x) for the first dataset is visualized in <ref type="figure">Figure S1</ref>. It is defined by a mixture of two Gaussian components (with weights 0.2 and 0.8) for x &lt; 0, and a lognormal distribution (with µ = 0.0, σ = 0.25) for x ≥ 0. The training data</p><formula xml:id="formula_19">D 1 = {(x i , y i )} 2000 i=1</formula><p>was generated by uniform random sampling of x in the interval [−3, 3], and is visualized in <ref type="figure" target="#fig_0">Figure S2</ref>. The ground truth p(y|x) for the second dataset is defined according to,</p><formula xml:id="formula_20">p(y|x) = N y; µ(x), σ 2 (x) , µ(x) = sin(x), σ (x) = 0.15(1 + e −x ) −1 .</formula><p>(S1) <ref type="figure">Figure S1</ref>: Visualization of the true p(y|x) for the first 1D regression dataset.  The training data</p><formula xml:id="formula_21">D 2 = {(x i , y i )} 2000</formula><p>i=1 was generated by uniform random sampling of x in the interval [−3, 3], and is visualized in <ref type="figure" target="#fig_1">Figure S3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 Network Architecture</head><p>The DNN f θ (x, y) is a feed-forward network taking x ∈ R and y ∈ R as inputs. It consists of two fully-connected layers (dimensions: 1 → 10, 10 → 10) for x, one fully-connected layer (1 → 10) for y, and four fully-connected layers (20 → 10, 10 → 10, 10 → 10, 10 → 1) processing the concatenated (x, y) feature vector.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.3 Evaluation</head><p>The training methods are evaluated in terms of the KL divergence D KL (p(y|x) p(y|x; θ )) between the learned EBM p(y|x; θ ) = e f θ (x,y) / e f θ (x,ỹ) dỹ and the true conditional density p(y|x). To approximate D KL (p(y|x) p(y|x; θ )), we compute e f θ (x,y) and p(y|x) for all (x, y) pairs in a 2048 × 2048 uniform grid in the region {(x, y) ∈ R 2 : x ∈ [−3, 3], y ∈ [−3, 3]}. We then normalize across all values associated with each x, employ the formula for KL divergence between two discrete distributions q 1 (y) and q 2 (y),</p><formula xml:id="formula_22">D KL (q 1 q 2 ) = ∑ y∈Y q 1 (y) log q 1 (y) q 2 (y) ,<label>(S2)</label></formula><p>and finally average over all 2048 values of x. For each dataset and training method, we independently train the DNN f θ (x, y) and compute D KL (p(y|x) p(y|x; θ )) 20 times. We then take the mean of the 5 best runs, and finally average this value for the two datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.4 Hyperparameters</head><p>The number of samples M = 1024 for all applicable training methods. All other hyperparameters were selected to optimize the performance, evaluated according to Section B.3.</p><p>ML-IS Following <ref type="bibr" target="#b14">[15]</ref>, we set K = 2 in the proposal distribution q(y|y i ) in (4). After ablation, we set σ 1 = 0.2, σ 2 = 1.6.</p><p>KLD-IS We use the same proposal distribution q(y|y i ) as for ML-IS. After ablation, we set σ = 0.025 in p(y|y i ) = N (y; y i , σ 2 I).</p><p>ML-MCMC After ablation, we set the Langevin dynamics step-length α = 0.05.    <ref type="table" target="#tab_1">Table S1</ref>: Used step-lengths λ pos and λ size for the object detection experiments.</p><p>NCE To match ML-IS, we set K = 2 in the noise distribution p N (y|y i ) in <ref type="bibr" target="#b10">(11)</ref>. After ablation, we set σ 1 = 0.1, σ 2 = 0.8.</p><p>DSM After ablation, we set σ = 0.2 in p σ (ỹ|y i ) = N (ỹ; y i , σ 2 I).</p><p>NCE+ We use the same noise distribution p N (y|y i ) as for NCE. After ablation, we set β = 0.025.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.5 Qualitative Results</head><p>An example of p(y|x; θ ) trained using NCE on the first dataset is visualized in <ref type="figure" target="#fig_5">Figure S4</ref>. As can be observed, this is quite close to the true p(y|x) visualized in <ref type="figure">Figure S1</ref>. Similar results are obtained with all four top-performing training methods. Examples of p(y|x; θ ) instead trained using DSM and SM are visualized in <ref type="figure" target="#fig_6">Figure S5</ref> and <ref type="figure" target="#fig_7">Figure S6</ref>, respectively. These do not approximate the true p(y|x) quite as well, matching the worse performance in terms of D KL reported in <ref type="table" target="#tab_1">Table 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix C Object Detection</head><p>Here, we provide details on the prediction procedure and hyperparameters used for our object detection experiments (Section 4.2). We employ an identical network architecture and training procedure as described in <ref type="bibr" target="#b14">[15]</ref>, only modifying the loss when using a different method than ML-IS to train f θ (x, y).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.1 Prediction</head><p>Predictions y are produced by performing guided NMS <ref type="bibr" target="#b21">[22]</ref> followed by gradient-based refinement (Algorithm S1), taking the Faster-RCNN detections as initial estimatesŷ. As in <ref type="bibr" target="#b14">[15]</ref>, we run T = 10 gradient ascent iterations. We fix the step-length decay to η = 0.5, which is the value used in <ref type="bibr" target="#b14">[15]</ref>. For each trained model, we select the gradient ascent steplength λ to optimize performance in terms of AP on the 2017 val split of COCO <ref type="bibr" target="#b31">[32]</ref>. Like <ref type="bibr" target="#b14">[15]</ref>, we use different step-lengths for the bounding box position (λ pos ) and size (λ size ). We    <ref type="table">Table S4</ref>: Ablation study for NCE, on the 2017 val split of COCO <ref type="bibr" target="#b31">[32]</ref>.</p><p>start this ablation with λ pos = 0.0001, λ size = 0.0004. The used step-lengths for all training methods are given in <ref type="table" target="#tab_1">Table S1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2 Hyperparameters</head><p>The number of samples M = 128 for all applicable training methods. All other hyperparameters were selected to optimize performance in terms of AP on the 2017 val split of COCO <ref type="bibr" target="#b31">[32]</ref>.</p><p>ML-IS Following <ref type="bibr" target="#b14">[15]</ref>, we set K = 3 in the proposal distribution q(y|y i ) in (4) with σ 1 = 0.0375, σ 2 = 0.075, σ 3 = 0.15.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>KLD-IS</head><p>We use the same proposal distribution q(y|y i ) as for ML-IS. Based on the ablation study in <ref type="table" target="#tab_3">Table S2</ref>, we set σ = 0.0225 in p(y|y i ) = N (y; y i , σ 2 I).</p><p>ML-MCMC Based on the ablation study in <ref type="table" target="#tab_8">Table S3</ref>, we set the Langevin dynamics steplength α = 0.00001.</p><p>NCE To match ML-IS, we set K = 3 in the noise distribution p N (y|y i ) in <ref type="bibr" target="#b10">(11)</ref>. Based on the ablation study in <ref type="table">Table S4</ref>, we set σ 1 = 0.075, σ 2 = 0.15, σ 3 = 0.3.</p><p>DSM Based on the ablation study in <ref type="table" target="#tab_10">Table S5</ref>, we set σ = 0.075 in p σ (ỹ|y i ) = N (ỹ; y i , σ 2 I).</p><p>NCE+ We use the same noise distribution p N (y|y i ) as for NCE. Based on the ablation study in <ref type="table" target="#tab_11">Table S6</ref>, we set β = 0.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.3 Detailed Results</head><p>A comparison of the training methods on the 2017 val split of COCO <ref type="bibr" target="#b31">[32]</ref> is provided in <ref type="table" target="#tab_12">Table S7</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix D Visual Tracking</head><p>Here, we provide detailed results and hyperparameters for our visual tracking experiments (Section 5). We employ an identical network architecture, training procedure and prediction       <ref type="figure">Figure S8</ref>: Success plot on UAV123 <ref type="bibr" target="#b37">[38]</ref>. procedure for DiMP-KLD-IS, DiMP-NCE and DiMP-NCE+, only the loss is modified.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Success plot</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.1 Training Parameters</head><p>DiMP-KLD-IS is obtained by combining the DiMP <ref type="bibr" target="#b4">[5]</ref> method for center point regression with the PrDiMP <ref type="bibr" target="#b8">[9]</ref> bounding box regression approach, and modifying a few training parameters. Specifically, we change the batch size from 10 to 20, we change the LaSOT sampling weight from 0.25 to 1.0, we change the number of samples per epoch from 26 000 to 40 000, and we add random horizontal flipping with probability 0.5. Since we increase the batch size, we also freeze conv1, layer1 and layer2 of the ResNet backbone to save memory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2 Hyperparameters</head><p>The number of samples M = 128 for all three training methods.</p><p>DiMP-KLD-IS Following PrDiMP, we set K = 2 in the proposal distribution q(y|y i ) in (4) with σ 1 = 0.05, σ 2 = 0.5, and we set σ = 0.05 in p(y|y i ) = N (y; y i , σ 2 I).     <ref type="figure">Figure S10</ref>: Success plot on OTB-100 <ref type="bibr" target="#b54">[55]</ref>.</p><p>DiMP-NCE Matching DiMP-KLD-IS, we set K = 2 in the noise distribution p N (y|y i ) in (11) with σ 1 = 0.05, σ 2 = 0.5. A quick ablation study on the validation set of GOT-10k <ref type="bibr" target="#b19">[20]</ref> did not find values of σ 1 , σ 2 resulting in improved performance.</p><p>DiMP-NCE+ We use the same noise distribution p N (y|y i ) as for NCE. We set β = 0.1, as this corresponded to the best performance on the object detection experiments <ref type="table" target="#tab_11">(Table S6</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.3 Detailed Results</head><p>Full results on the TrackingNet <ref type="bibr" target="#b38">[39]</ref> test set, in terms of all three TrackingNet metrics, are found in <ref type="table" target="#tab_15">Table S8</ref>. Success plots for LaSOT, UAV123, NFS and OTB-100 are found in <ref type="figure" target="#fig_8">Figure S7</ref>-S10, showing the overlap precision OP T as a function of the overlap threshold T .</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Detailed comparison of the top-performing methods for the illustrative 1D regression experiments. NCE and NCE+ here demonstrate clear superior performance for small number of samples M.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Detailed comparison of the topperforming methods for object detection, on the 2017 val split of COCO<ref type="bibr" target="#b31">[32]</ref>. Missing values for ML-IS and KLD-IS correspond to failed training due to numerical issues.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :Figure 5 :</head><label>45</label><figDesc>Effect of the number of samples M on training cost (seconds per iteration), for ML-IS on object detection. Effect of the NCE+ hyperparameter β on object detection performance (↑), on the 2017 val split of COCO [32].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure S2 :</head><label>S2</label><figDesc>Training data {(x i , y i )} 2000 i=1for the first 1D regression dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure S3 :</head><label>S3</label><figDesc>Training data {(x i , y i )} 2000 i=1for the second 1D regression dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure S4 :</head><label>S4</label><figDesc>Example of p(y|x; θ ) trained with NCE.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure S5 :</head><label>S5</label><figDesc>Example of p(y|x; θ ) trained with DSM.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure S6 :</head><label>S6</label><figDesc>Example of p(y|x; θ ) trained with SM. ML-IS ML-MCMC-1 ML-MCMC-4 ML-MCMC-8</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure S7 :</head><label>S7</label><figDesc>Success plot on LaSOT<ref type="bibr" target="#b10">[11]</ref>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure S9 :</head><label>S9</label><figDesc>Success plot on NFS<ref type="bibr" target="#b24">[25]</ref>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>ML-IS ML-MCMC-1 ML-MCMC-16 ML-MCMC-256 KLD-IS NCE SM DSM NCE+</figDesc><table><row><cell>D KL ↓</cell><cell>0.062</cell><cell>0.865</cell><cell>0.449</cell><cell>0.106</cell><cell>0.088</cell><cell cols="4">0.068 0.781 0.395 0.066</cell></row><row><cell cols="2">Training Cost ↓ 0.44</cell><cell>0.54</cell><cell>2.41</cell><cell>30.8</cell><cell>0.44</cell><cell>0.45</cell><cell>0.60</cell><cell>0.47</cell><cell>0.46</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Comparison of training methods for the illustrative 1D regression experiments.</figDesc><table><row><cell>3</cell><cell></cell><cell></cell><cell></cell><cell cols="2">ML-IS KLD-IS</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>NCE</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>NCE+</cell></row><row><cell>2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>DKL</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>1</cell><cell>4</cell><cell>16</cell><cell>64</cell><cell>256</cell><cell>1024</cell></row><row><cell></cell><cell></cell><cell cols="3">Number of samples M</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Comparison of training methods for the object detection experiments, on the 2017 test-dev split of COCO</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>↑ 38.32 39.19 39.38 39.33 39.23</figDesc><table><row><cell>σ</cell><cell>0.0075 0.015 0.0225 0.03 0.0375</cell></row><row><cell>AP (%)</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table S2 :</head><label>S2</label><figDesc>Ablation study for KLD-IS, on the 2017 val split of COCO<ref type="bibr" target="#b31">[32]</ref>.</figDesc><table><row><cell>α</cell><cell cols="3">0.000001 0.00001 0.0001</cell></row><row><cell>AP (%) ↑</cell><cell>36.14</cell><cell>36.19</cell><cell>36.04</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table S3 :</head><label>S3</label><figDesc>Ablation study for ML-MCMC-1, on the 2017 val split of COCO<ref type="bibr" target="#b31">[32]</ref>.{σ k } 3 k=1 {0.0125, 0.025, 0.05} {0.025, 0.05, 0.1} {0.05, 0.1, 0.2} {0.075, 0.15, 0.3} {0.1, 0.2, 0.4}</figDesc><table><row><cell>AP (%) ↑</cell><cell>38.58</cell><cell>38.95</cell><cell>39.12</cell><cell>39.17</cell><cell>39.05</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table S5 :</head><label>S5</label><figDesc>Ablation study for DSM, on the 2017 val split of COCO<ref type="bibr" target="#b31">[32]</ref>.</figDesc><table><row><cell>β</cell><cell>0.05</cell><cell>0.1</cell><cell>0.15</cell></row></table><note>AP (%) ↑ 39.27 39.36 39.32</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table S6 :</head><label>S6</label><figDesc>Ablation study for NCE+, on the 2017 val split of COCO<ref type="bibr" target="#b31">[32]</ref>.</figDesc><table><row><cell></cell><cell cols="8">ML-IS ML-MCMC-1 ML-MCMC-4 ML-MCMC-8 KLD-IS NCE DSM NCE+</cell></row><row><cell>AP (%) ↑</cell><cell>39.11</cell><cell>36.19</cell><cell>36.24</cell><cell>36.25</cell><cell>39.38</cell><cell cols="3">39.17 36.12 39.36</cell></row><row><cell>AP 50 (%) ↑</cell><cell>57.95</cell><cell>57.34</cell><cell>57.45</cell><cell>57.28</cell><cell>58.07</cell><cell cols="3">57.96 57.29 57.99</cell></row><row><cell>AP 75 (%) ↑</cell><cell>41.97</cell><cell>38.77</cell><cell>38.81</cell><cell>38.88</cell><cell>42.47</cell><cell cols="3">42.07 38.84 42.63</cell></row><row><cell>Training Cost ↓</cell><cell>1.03</cell><cell>2.47</cell><cell>7.05</cell><cell>13.3</cell><cell>1.02</cell><cell>1.04</cell><cell>3.84</cell><cell>1.09</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table S7 :</head><label>S7</label><figDesc>Comparison of training methods for the object detection experiments, on the 2017 val split of COCO<ref type="bibr" target="#b31">[32]</ref>. NCE+ and KLD-IS achieve the best performance.</figDesc><table><row><cell cols="2">100</cell><cell>Success plot</cell><cell></cell><cell></cell></row><row><cell>Overlap Precision [%]</cell><cell>0.0 0 20 40 60 80</cell><cell>0.2 DiMP-NCE+ [63.7] 0.4 Overlap threshold 0.6 DiMP-KLD-IS [63.1] DiMP-NCE [62.8] PrDiMP [59.8] DiMP [56.9] ATOM [51.5] SiamRPN++ [49.6] MDNet [39.7] SiamFC [33.6]</cell><cell>0.8</cell><cell>1.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table S8 :</head><label>S8</label><figDesc></figDesc><table><row><cell cols="2">100</cell><cell>Success plot</cell><cell></cell><cell></cell></row><row><cell>Overlap Precision [%]</cell><cell>0.0 0 20 40 60 80</cell><cell>0.2 DiMP-NCE+ [65.0] 0.4 Overlap threshold 0.6 DiMP-KLD-IS [64.7] DiMP-NCE [64.3] PrDiMP [63.4] DiMP [61.8] ATOM [58.3] UPDT [53.5] CCOT [48.7] ECO [46.5]</cell><cell>0.8</cell><cell>1.0</cell></row></table><note>Full results on the TrackingNet [39] test set, in terms of precision, normalized precision, and success (AUC). Our proposed DiMP-NCE+ is here only outperformed by the very recent SiamRCNN [53]. SiamRCNN is however slower than DiMP-NCE+ (5 FPS vs 30 FPS) and employs a larger backbone network (ResNet101 vs ResNet50).</note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgments This research was financially supported by the Swedish Foundation for Strategic Research via the project ASSEMBLE, the Swedish Research Council via the project Learning flexible models for nonlinear dynamics, the ETH Zürich Fund (OK), a Huawei Technologies Oy (Finland) project, an Amazon AWS grant, and Nvidia.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Material</head><p>In this supplementary material, we provide additional details and results. It consists of Appendix A -Appendix D. Appendix A contains a detailed algorithm for our employed prediction strategy. Further experimental details are provided in Appendix B for 1D regression, and in Appendix C for object detection. Lastly, Appendix D contains details and further results for the visual tracking experiments. Note that equations, tables, figures and algorithms in this supplementary document are numbered with the prefix "S". Numbers without this prefix refer to the main paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix A Prediction Algorithm</head><p>Our prediction procedure (Section 2.2) is detailed in Algorithm S1, where λ denotes the gradient ascent step-length, η is a decay of the step-length and T is the number of iterations.</p><p>Algorithm S1 Prediction via gradient-based refinement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5:</head><p>NewValue ← f θ (x ,ỹ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6:</head><p>if NewValue &gt; PrevValue then <ref type="bibr">7:</ref> y ←ỹ. λ ← ηλ . 10: Return y.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix B 1D Regression</head><p>Here, we provide details on the two synthetic datasets, the network architecture, the evaluation procedure, and hyperparameters used for our 1D regression experiments (Section 4.1). For all seven training methods, the DNN f θ (x, y) was trained (by minimizing the associated loss J(θ )) for 75 epochs with a batch size of 32 using the ADAM <ref type="bibr" target="#b25">[26]</ref> optimizer.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Learning representations by maximizing mutual information across views</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devon</forename><surname>Hjelm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Buchwalter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="15509" to="15519" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A neural probabilistic language model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Réjean</forename><surname>Ducharme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Jauvin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1137" to="1155" />
			<date type="published" when="2003-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Fully-convolutional siamese networks for object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Bertinetto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jack</forename><surname>Valmadre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>João</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Henriques</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip Hs</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV) Workshops</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Unveiling the power of deep tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Goutam</forename><surname>Bhat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Johnander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Danelljan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fahad</forename><surname>Shahbaz Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Felsberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="483" to="498" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Learning discriminative model prediction for tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Goutam</forename><surname>Bhat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Danelljan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Timofte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6182" to="6191" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.05709</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">PyTracking: Visual tracking library based on PyTorch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Danelljan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Goutam</forename><surname>Bhat</surname></persName>
		</author>
		<idno>20/04/2020</idno>
		<ptr target="https://github.com/visionml/pytracking" />
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">ATOM: Accurate tracking by overlap maximization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Danelljan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Goutam</forename><surname>Bhat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fahad</forename><surname>Shahbaz Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Felsberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4660" to="4669" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Probabilistic regression for visual tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Danelljan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Timofte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="7183" to="7192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Implicit generation and modeling with energy based models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yilun</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Igor</forename><surname>Mordatch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">LaSOT: A high-quality benchmark for large-scale single object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liting</forename><surname>Heng Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fan</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ge</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sijia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hexin</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyuan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haibin</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5374" to="5383" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning generative convnets via multi-grid modeling and sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruiqi</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junpei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song-Chun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying Nian</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="9155" to="9164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Flow contrastive estimation of energy-based models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruiqi</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Nijkamp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying Nian</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.00589</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Your classifier is secretly an energy based model and you should treat it like one</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Grathwohl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuan-Chieh</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joern-Henrik</forename><surname>Jacobsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Duvenaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Energybased models for deep probabilistic regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Fredrik K Gustafsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Goutam</forename><surname>Danelljan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">B</forename><surname>Bhat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schön</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2020-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Noise-contrastive estimation: A new estimation principle for unnormalized statistical models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Gutmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aapo</forename><surname>Hyvärinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Artificial Intelligence and Statistics (AISTATS)</title>
		<meeting>the International Conference on Artificial Intelligence and Statistics (AISTATS)</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="297" to="304" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Unsupervised discovery of nonlinear structure using contrastive backpropagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee-Whye</forename><surname>Teh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive science</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="725" to="731" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Training products of experts by minimizing contrastive divergence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Geoffrey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1771" to="1800" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Learning deep representations by mutual information estimation and maximization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>R Devon Hjelm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Fedorov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karan</forename><surname>Lavoie-Marchildon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Grewal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Trischler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">GOT-10k: A large high-diversity benchmark for generic object tracking in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lianghua</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiqi</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Estimation of non-normalized statistical models by score matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aapo</forename><surname>Hyvärinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="695" to="709" />
			<date type="published" when="2005-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Acquisition of localization confidence for accurate object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Borui</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruixuan</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiayuan</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tete</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuning</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="784" to="799" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Exploring the limits of language modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rafal</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonghui</forename><surname>Wu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.02410</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilyes</forename><surname>Khemakhem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ricardo</forename><forename type="middle">Pio</forename><surname>Monti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aapo</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hyvärinen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.11537</idno>
		<title level="m">ICE-BeeM: Identifiable conditional energy-based deep models</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Need for speed: A benchmark for higher frame rate object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashton</forename><surname>Hamed Kiani Galoogahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Fagg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lucey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1125" to="1134" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A comprehensive analysis of deep regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stéphane</forename><surname>Lathuilière</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pablo</forename><surname>Mesejo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Alameda-Pineda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Horaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Cornernet: Detecting objects as paired keypoints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hei</forename><surname>Law</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="734" to="750" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A tutorial on energy-based learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raia</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Predicting structured data</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">0</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">SiamRPN++: Evolution of siamese visual tracking with very deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fangyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junliang</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4282" to="4291" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Learning energy-based models in high-dimensional spaces with multi-scale denoising score matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zengyi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yubei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Friedrich T</forename><surname>Sommer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.07762</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Microsoft coco: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="740" to="755" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Feature pyramid networks for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bharath</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2117" to="2125" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Noise contrastive estimation and negative sampling for conditional models: Consistency and statistical efficiency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuang</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3698" to="3707" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Learning nonlinear constraints with contrastive backpropagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andriy</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Joint Conference on Neural Networks</title>
		<meeting>the IEEE International Joint Conference on Neural Networks</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2005" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1302" to="1307" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A fast and simple algorithm for training neural probabilistic language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andriy</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee Whye</forename><surname>Teh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1751" to="1758" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A benchmark and simulator for UAV tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernard</forename><surname>Ghanem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="445" to="461" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">TrackingNet: A large-scale dataset and benchmark for object tracking in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adel</forename><surname>Bibi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Giancola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salman</forename><surname>Alsubaihi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernard</forename><surname>Ghanem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="300" to="317" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Learning multi-domain convolutional neural networks for visual tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyeonseob</forename><surname>Nam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bohyung</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4293" to="4302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Learning nonconvergent non-persistent short-run mcmc toward energy-based model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Nijkamp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitch</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Song-Chun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying Nian</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5233" to="5243" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">On the anatomy of MCMC-based maximum likelihood learning of energy-based models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Nijkamp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitch</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tian</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song-Chun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying Nian</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Fourth AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Synergistic face detection and pose estimation with energy-based models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margarita</forename><surname>Osadchy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann L</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="1017" to="1024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Mean-variance loss for deep age estimation from a face</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyu</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hu</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiguang</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xilin</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5285" to="5294" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">PyTorch: An imperative style, high-performance deep learning library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalia</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8024" to="8035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Faster r-cnn: Towards real-time object detection with region proposal networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>Shaoqing Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><forename type="middle">B</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="1137" to="1149" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Deep expectation of real and apparent age from a single image without facial landmarks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Rasmus Rothe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Timofte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">126</biblScope>
			<biblScope unit="issue">2-4</biblScope>
			<biblScope unit="page" from="144" to="157" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saeed</forename><surname>Saremi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arash</forename><surname>Mehrjou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aapo</forename><surname>Hyvärinen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.08306</idno>
		<title level="m">Deep energy estimator networks</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroaki</forename><surname>Sasaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aapo</forename><surname>Hyvärinen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.01754</idno>
		<title level="m">Neural-kernelized conditional density estimation</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Generative modeling by estimating gradients of the data distribution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Ermon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="11895" to="11907" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Energy-based models for sparse overcomplete representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee Whye</forename><surname>Teh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="1235" to="1260" />
			<date type="published" when="2003-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">A connection between score matching and denoising autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Vincent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1661" to="1674" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Siam R-CNN: Visual tracking by re-detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Voigtlaender</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Luiten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bastian</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Leibe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="6578" to="6588" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Bayesian learning via stochastic gradient Langevin dynamics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee</forename><forename type="middle">W</forename><surname>Teh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="681" to="688" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jongwoo</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
		<title level="m">Object tracking benchmark. IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="1834" to="1848" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Simple baselines for human pose estimation and tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haiping</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="466" to="481" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">A theory of generative convnet</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianwen</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song-Chun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingnian</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2635" to="2644" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">FSA-Net: Learning fine-grained structure aggregation for head pose estimation from a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsun-Yi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yen-Yu</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yung-Yu</forename><surname>Chuang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1087" to="1096" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Bottom-up object detection by grouping extreme and center points</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingyi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiacheng</forename><surname>Zhuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Krahenbuhl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="850" to="859" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Distractoraware siamese networks for visual object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiming</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="101" to="117" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
