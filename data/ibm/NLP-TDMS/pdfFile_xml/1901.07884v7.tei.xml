<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Rank consistent ordinal regression for neural networks with application to age estimation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2020">2020. 140</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenzhi</forename><surname>Cao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Statistics</orgName>
								<orgName type="institution">University of Wisconsin-Madison</orgName>
								<address>
									<addrLine>1300 University Ave</addrLine>
									<postCode>53705</postCode>
									<settlement>Madison</settlement>
									<region>WI</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vahid</forename><surname>Mirjalili</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science &amp; Engineering</orgName>
								<orgName type="institution">Michigan State University</orgName>
								<address>
									<addrLine>428 South Shaw Lane</addrLine>
									<postCode>48824</postCode>
									<settlement>East Lansing</settlement>
									<region>MI</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Raschka</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Statistics</orgName>
								<orgName type="institution">University of Wisconsin-Madison</orgName>
								<address>
									<addrLine>1300 University Ave</addrLine>
									<postCode>53705</postCode>
									<settlement>Madison</settlement>
									<region>WI</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Rank consistent ordinal regression for neural networks with application to age estimation</title>
					</analytic>
					<monogr>
						<title level="j" type="main">Pattern Recognition Letters</title>
						<imprint>
							<biblScope unit="page" from="325" to="331"/>
							<date type="published" when="2020">2020. 140</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1016/j.patrec.2020.11.008</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T05:42+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In many real-world prediction tasks, class labels include information about the relative ordering between labels, which is not captured by commonly-used loss functions such as multi-category cross-entropy. Recently, the deep learning community adopted ordinal regression frameworks to take such ordering information into account. Neural networks were equipped with ordinal regression capabilities by transforming ordinal targets into binary classification subtasks. However, this method suffers from inconsistencies among the different binary classifiers. To resolve these inconsistencies, we propose the COnsistent RAnk Logits (CORAL) framework with strong theoretical guarantees for rank-monotonicity and consistent confidence scores. Moreover, the proposed method is architecture-agnostic and can extend arbitrary state-of-the-art deep neural network classifiers for ordinal regression tasks. The empirical evaluation of the proposed rank-consistent method on a range of face-image datasets for age prediction shows a substantial reduction of the prediction error compared to the reference ordinal regression network.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Ordinal regression (also called ordinal classification), describes the task of predicting labels on an ordinal scale. Here, a ranking rule or classifier h maps each object x i ∈ X into an ordered set h : X → Y, where Y = {r 1 ≺ ... ≺ r K }. In contrast to classification, the labels provide enough information to order objects. However, as opposed to metric regression, the difference between label values is arbitrary.</p><p>While the field of machine learning has developed many powerful algorithms for predictive modeling, most algorithms have been designed for classification tasks. The extended binary classification approach proposed by <ref type="bibr" target="#b12">Li and Lin (2007)</ref> forms the basis of many ordinal regression implementations. However, neural network-based implementations of this approach commonly suffer from classifier inconsistencies among the binary rankings <ref type="bibr" target="#b14">(Niu et al., 2016)</ref>. This inconsistency problem among the predictions of individual binary classifiers is illustrated in <ref type="figure">Figure 1</ref>. We propose a new method and theorem for guaranteed classifier consistency that can easily be implemented in various neural network architectures. Furthermore, along with the theoretical rank-consistency guarantees, this paper presents an empirical analysis of our approach to challenging real-world datasets for predicting the age of individuals from face images using our method with convolutional neural networks (CNNs). Aging can be regarded as a non-stationary process since age progression effects appear differently depending on the person's age. During childhood, facial aging is primarily associated with changes in the shape of the face, whereas aging during adulthood is defined mainly by changes in skin texture <ref type="bibr" target="#b18">(Ramanathan et al., 2009;</ref><ref type="bibr" target="#b14">Niu et al., 2016)</ref>. Based on this assumption, age prediction can be modeled using ordinal regression-based approaches <ref type="bibr" target="#b27">(Yang et al., 2010;</ref><ref type="bibr" target="#b2">Chang et al., 2011;</ref><ref type="bibr" target="#b1">Cao et al., 2012;</ref><ref type="bibr" target="#b11">Li et al., 2012)</ref>.</p><p>The main contributions of this paper are as follows:</p><p>1. The consistent rank logits (CORAL) framework for ordinal regression with theoretical guarantees for classifier consistency; 2. Implementation of CORAL to adapt common CNN architectures, such as ResNet <ref type="bibr" target="#b7">(He et al., 2016)</ref>, for ordinal regression; 3. Experiments on different age estimation datasets showing that CORAL's guaranteed binary classifier consistency improves predictive performance compared to the reference framework for ordinal regression. Note that this work focuses on age estimation to study the proposed method's efficacy for ordinal regression. However, the proposed technique can be used for other ordinal regression problems, such as crowd-counting, depth estimation, biological cell counting, customer satisfaction, and others.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Ordinal regression and ranking</head><p>Several multivariate extensions of generalized linear models have been developed for ordinal regression in the past, including the popular proportional odds and proportional hazards models <ref type="bibr" target="#b13">(McCullagh, 1980)</ref>. Moreover, the machine learning field developed ordinal regression models based on extensions of well-studied classification algorithms, by reformulating the problem to utilize multiple binary classification tasks <ref type="bibr" target="#b0">(Baccianella et al., 2009)</ref>. Early work in this regard includes the use of perceptrons <ref type="bibr" target="#b6">(Crammer and Singer, 2002;</ref><ref type="bibr" target="#b26">Shen and Joshi, 2005)</ref> and support vector machines <ref type="bibr" target="#b8">(Herbrich et al., 1999;</ref><ref type="bibr" target="#b25">Shashua and Levin, 2003;</ref><ref type="bibr" target="#b17">Rajaram et al., 2003;</ref><ref type="bibr" target="#b5">Chu and Keerthi, 2005)</ref>. <ref type="bibr" target="#b12">Li and Lin (2007)</ref> proposed a general reduction framework that unified the view of a number of these existing algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Ordinal regression CNN</head><p>While earlier works on using CNNs for ordinal targets have employed conventional classification approaches <ref type="bibr" target="#b10">(Levi and Hassner, 2015;</ref><ref type="bibr" target="#b23">Rothe et al., 2015)</ref>, the general reduction framework from ordinal regression to binary classification by <ref type="bibr" target="#b12">Li and Lin (2007)</ref> was recently adopted by <ref type="bibr" target="#b14">Niu et al. (2016)</ref> as Ordinal Regression CNN (OR-CNN). In the OR-CNN approach, an ordinal regression problem with K ranks is transformed into K − 1 binary classification problems, with the k-th task predicting whether the age label of a face image exceeds rank r k , k = 1, ..., K − 1. All K −1 tasks share the same intermediate layers but are assigned distinct weight parameters in the output layer.</p><p>While the OR-CNN was able to achieve state-of-the-art performance on benchmark datasets, it does not guarantee consistent predictions, such that predictions for individual binary tasks may disagree. For example, in an age estimation setting, it would be contradictory if the k-th binary task predicted that the age of a person was more than 30, but a previous task predicted the person's age was less than 20. This inconsistency could be suboptimal when the K − 1 task predictions are combined to obtain the estimated age. <ref type="bibr" target="#b14">Niu et al. (2016)</ref> acknowledged the classifier inconsistency as not being ideal and also noted that ensuring the K − 1 binary classifiers are consistent would increase the training complexity substantially <ref type="bibr" target="#b14">(Niu et al., 2016)</ref>. The CORAL method proposed in this paper addresses both these issues with a theoretical guarantee for classifier consistency and without increasing the training complexity. <ref type="bibr" target="#b4">Chen et al. (2017)</ref> proposed a modification of the OR-CNN <ref type="bibr" target="#b14">(Niu et al., 2016)</ref>, known as Ranking-CNN, that uses an ensemble of CNNs for binary classifications and aggregates the predictions to estimate the age label of a given face image. The researchers showed that training an ensemble of CNNs improves the predictive performance over a single CNN with multiple binary outputs <ref type="bibr" target="#b4">(Chen et al., 2017)</ref>, which is consistent with the well-known fact that an ensemble model can achieve better generalization performance than each individual classifier in the ensemble <ref type="bibr" target="#b21">(Raschka and Mirjalili, 2019)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Other CNN architectures for age estimation</head><p>Recent research has also shown that training a multi-task CNN that shares lower-layer parameters for various face analysis tasks (face detection, gender prediction, age estimation, etc.) can improve the overall performance across different tasks compared to a single-task CNN <ref type="bibr" target="#b19">(Ranjan et al., 2017)</ref>.</p><p>Another approach for utilizing binary classifiers for ordinal regression is the siamese CNN architecture proposed by <ref type="bibr" target="#b16">Polania et al. (2019)</ref>, which computes the rank from pair-wise comparisons between the input image and multiple, carefully selected anchor images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Proposed method</head><p>This section describes our proposed CORAL framework that addresses the problem of classifier inconsistency in the OR-CNN by <ref type="bibr" target="#b14">Niu et al. (2016)</ref>, which is based on multiple binary classification tasks for ranking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Preliminaries</head><formula xml:id="formula_0">Let D = {x i , y i } N i=1</formula><p>be the training dataset consisting of N training examples. Here, x i ∈ X denotes the i-th training example and y i the corresponding rank, where y i ∈ Y = {r 1 , r 2 , ...r K } with ordered rank r K r K−1 . . . r 1 . The ordinal regression task is to find a ranking rule h : X → Y such that a loss function L(h) is minimized.</p><p>Let C be a K×K cost matrix, where C y,r k is the cost of predicting an example (x, y) as rank r k <ref type="bibr" target="#b12">(Li and Lin, 2007)</ref>. Typically, C y,y = 0 and C y,r k &gt; 0 for y = r k . In ordinal regression, we generally prefer each row of the cost matrix to be V-shaped, that is, C y,r k−1 ≥ C y,r k if r k ≤ y and C y,r k ≤ C y,r k+1 if r k ≥ y. The classification cost matrix has entries C y,r k = 1{y = r k } that do not consider ordering information. In ordinal regression, where the ranks are treated as numerical values, the absolute cost matrix is commonly defined by C y,r k = |y − r k |.</p><p>Li and Lin <ref type="formula" target="#formula_5">(2007)</ref> proposed a general reduction framework for extending an ordinal regression problem into several binary classification problems. This framework requires a cost matrix that is convex in each row (C y,r k+1 − C y,r k ≥ C y,r k − C y,r k−1 for each y) to obtain a rank-monotonic threshold model. Since the cost-related weighting of each binary task is specific for each training example, this approach is considered as infeasible in practice due to its high training complexity <ref type="bibr" target="#b14">(Niu et al., 2016)</ref>.</p><p>Our proposed CORAL framework does neither require a cost matrix with convex-row conditions nor explicit weighting terms that depend on each training example to obtain a rankmonotonic threshold model and produce consistent predictions for each binary task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Ordinal regression with a consistent rank logits model</head><p>In this section, we describe our proposed consistent rank logits (CORAL) framework for ordinal regression. Subsection 3.2.1 describes the label extension into binary tasks used for rank prediction. The loss function of the CORAL framework is described in Subsection 3.2.2. In subsection 3.2.3, we prove the theorem for rank consistency among the binary classification tasks that guarantee that the binary tasks produce consistently ranked predictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1.">Label extension and rank prediction</head><p>Given</p><formula xml:id="formula_1">a training dataset D = {x i , y i } N i=1 , a rank y i is first extended into K − 1 binary labels y (1) i , . . . , y (K−1) i such that y (k) i ∈ {0, 1} indicates whether y i exceeds rank r k , for instance, y (k) i = 1{y i &gt; r k }. The indicator function 1{·} is 1 if the inner</formula><p>condition is true and 0 otherwise. Using the extended binary labels during model training, we train a single CNN with K − 1 binary classifiers in the output layer, which is illustrated in <ref type="figure">Figure</ref> 2. Based on the binary task responses, the predicted rank label for an input x i is obtained via h(x i ) = r q . The rank index 1 q is given by</p><formula xml:id="formula_2">q = 1 + K−1 k=1 f k (x i ),<label>(1)</label></formula><p>where f k (x i ) ∈ {0, 1} is the prediction of the k-th binary classifier in the output layer. We require that { f k } K−1 k=1 reflect the ordinal information and are rank-monotonic,</p><formula xml:id="formula_3">f 1 (x i ) ≥ f 2 (x i ) ≥ . . . ≥ f K−1 (x i )</formula><p>, which guarantees consistent predictions. To achieve rank-monotonicity and guarantee binary classifier consistency (Theorem 1), the K − 1 binary tasks share the same weight parameters 2 but have independent bias units ( <ref type="figure" target="#fig_0">Figure 2</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2.">Loss function</head><p>Let W denote the weight parameters of the neural network excluding the bias units of the final layer. The penultimate layer, whose output is denoted as g(x i , W), shares a single weight with all nodes in the final output layer; K − 1 independent bias units are then added to g(</p><formula xml:id="formula_4">x i , W) such that {g(x i , W) + b k } K−1 k=1</formula><p>are the inputs to the corresponding binary classifiers in the final layer. Let</p><formula xml:id="formula_5">σ(z) = 1/(1 + exp(−z))<label>(2)</label></formula><p>be the logistic sigmoid function. The predicted empirical probability for task k is defined as</p><formula xml:id="formula_6">(3) P(y (k) i = 1) = σ(g(x i , W) + b k ).</formula><p>For model training, we minimize the loss function</p><formula xml:id="formula_7">(4) L(W, b) = − N i=1 K−1 k=1 λ (k) [ log(σ(g(x i , W) + b k ))y (k) i + log(1 − σ(g(x i , W) + b k ))(1 − y (k) i )],</formula><p>which is the weighted cross-entropy of K − 1 binary classifiers. For rank prediction (Eq. 1), the binary labels are obtained via</p><formula xml:id="formula_8">f k (x i ) = 1{ P(y (k) i = 1) &gt; 0.5}.<label>(5)</label></formula><p>In Eq. 4, λ (k) denotes the weight of the loss associated with the k-th classifier (assuming λ (k) &gt; 0). In the remainder of the paper, we refer to λ (k) as the importance parameter for task k. Some tasks may be less robust or harder to optimize, which can be considered by choosing a non-uniform task weighting scheme. For simplicity, we carried out all experiments with uniform task weighting, that is, ∀k : λ (k) = 1. In the next section, we provide the theoretical guarantee for classifier consistency under uniform and non-uniform task importance weighting given that the task importance weights are positive numbers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3.">Theoretical guarantees for classifier consistency</head><p>The following theorem shows that by minimizing the loss L (Eq. 4), the learned bias units of the output layer are nonincreasing such that</p><formula xml:id="formula_9">b 1 ≥ b 2 ≥ . . . ≥ b K−1 .<label>(6)</label></formula><p>Consequently, the predicted confidence scores or probability estimates of the K − 1 tasks are decreasing, for instance,</p><formula xml:id="formula_10">P y (1) i = 1 ≥ P y (2) i = 1 ≥ . . . ≥ P y (K−1) i = 1<label>(7)</label></formula><p>for all i, ensuring classifier consistency. Consequently, { f k } K−1 k=1 (Eq. 5) are also rank-monotonic.</p><formula xml:id="formula_11">p i = σ(wx + b i ) with a single feature x.</formula><p>If the weight w is not shared across the K − 1 equations, the S-shaped curves of the probability scores p i will intersect, making the p˙i's non-monotone at some given input x. Only if w is shared across the K − 1 equations, the S-shaped curves are horizontally shifted without intersecting.</p><p>Theorem 1 (Ordered bias units). By minimizing the loss function defined in Eq. 4, the optimal solution (W</p><formula xml:id="formula_12">* , b * ) satisfies b * 1 ≥ b * 2 ≥ . . . ≥ b * K−1 . Proof. Suppose (W, b)</formula><p>is an optimal solution and b k &lt; b k+1 for some k. Claim: replacing b k with b k+1 , or replacing b k+1 with b k , decreases the objective value L. Let</p><formula xml:id="formula_13">A 1 = {n : y (k) n = y (k+1) n = 1}, A 2 = {n : y (k) n = y (k+1) n = 0}, A 3 = {n : y (k) n = 1, y (k+1) n = 0}.</formula><p>By the ordering relationship, we have</p><formula xml:id="formula_14">A 1 ∪ A 2 ∪ A 3 = {1, 2, . . . , N}. Denote p n (b k ) = σ(g(x n , W) + b k ) and δ n = log(p n (b k+1 )) − log(p n (b k )), δ n = log(1 − p n (b k )) − log(1 − p n (b k+1 )).</formula><p>Since p n (b k ) is increasing in b k , we have δ n &gt; 0 and δ n &gt; 0. If we replace b k with b k+1 , the loss terms related to the k-th task are updated. The change of loss L (Eq. 4) is given as</p><formula xml:id="formula_15">∆ 1 L = λ (k) − n∈A 1 δ n + n∈A 2 δ n − n∈A 3 δ n .</formula><p>Accordingly, if we replace b k+1 with b k , the change of L is given as</p><formula xml:id="formula_16">∆ 2 L = λ (k+1) n∈A 1 δ n − n∈A 2 δ n − n∈A 3 δ n . By adding 1 λ (k) ∆ 1 L and 1 λ (k+1) ∆ 2 L, we have 1 λ (k) ∆ 1 L + 1 λ (k+1) ∆ 2 L = − n∈A 3 (δ n + δ n ) &lt; 0,</formula><p>and know that either ∆ 1 L &lt; 0 or ∆ 2 L &lt; 0. Thus, our claim is justified. We conclude that any optimal solution (W * , b * ) that minimizes L satisfies</p><formula xml:id="formula_17">b * 1 ≥ b * 2 ≥ . . . ≥ b * K−1 .</formula><p>Note that the theorem for rank-monotonicity proposed by <ref type="bibr" target="#b12">Li and Lin (2007)</ref>, in contrast to Theorem 1, requires a cost matrix C with each row y n being convex. Under this convexity condition, let λ (k) y n = |C y n ,r k − C y n ,r k+1 | be the weight of the loss associated with the k-th task on the n-th training example, which depends on the label y n . <ref type="bibr" target="#b12">Li and Lin (2007)</ref> proved that by using training example-specific task weights λ (k) y n , the optimal thresholds are ordered - <ref type="bibr" target="#b14">Niu et al. (2016)</ref> noted that example-specific task weights are infeasible in practice. Moreover, this assumption requires that λ (k) y n ≥ λ (k+1) y n when r k+1 &lt; y n and λ (k) y n ≤ λ (k+1) y n when r k+1 &gt; y n . Theorem 1 is free from this requirement and allows us to choose a fixed weight for each task that does not depend on the individual training examples, which greatly reduces the training complexity. Also, Theorem 1 allows for choosing either a simple uniform task weighting or taking dataset imbalances into account under the guarantee of non-decreasing predicted probabilities and consistent task predictions. Under Theorem 1, the only requirement for guaranteeing rank monotonicity is that the task weights are non-negative.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Datasets and preprocessing</head><p>The MORPH-2 dataset <ref type="bibr" target="#b22">(Ricanek and Tesafaye, 2006)</ref>, containing 55,608 face images, was downloaded from https: //www.faceaginggroup.com/morph/ and preprocessed by locating the average eye-position in the respective dataset using facial landmark detection <ref type="bibr" target="#b24">(Sagonas et al., 2016)</ref> and then aligning each image in the dataset to the average eye position using EyepadAlign function in MLxtend v0.14 <ref type="bibr" target="#b20">(Raschka, 2018)</ref>. The faces were then re-aligned such that the tip of the nose was located in the center of each image. The age labels used in this study were in the range of 16-70 years.</p><p>The CACD dataset <ref type="bibr" target="#b3">(Chen et al., 2014)</ref> was downloaded from http://bcsiriuschen.github.io/CARC/ and preprocessed similar to MORPH-2 such that the faces spanned the whole image with the nose tip at the center. The total number of images is 159,449 in the age range of 14-62 years.</p><p>The Asian Face Database (AFAD) by <ref type="bibr" target="#b14">Niu et al. (2016)</ref> was obtained from https://github.com/afad-dataset/ tarball. The AFAD database used in this study contained 165,501 faces in the range of 15-40 years. Since the faces were already centered, no further preprocessing was required.</p><p>Following the procedure described in <ref type="bibr" target="#b14">Niu et al. (2016)</ref>, each image database was randomly divided into 80% training data and 20% test data. All images were resized to 128×128×3 pixels and then randomly cropped to 120×120×3 pixels to augment the model training. During model evaluation, the 128×128×3 RGB face images were center-cropped to a model input size of 120×120×3.</p><p>We share the training and test partitions for all datasets, along with all preprocessing code used in this paper in the code repository (Section 4.4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Neural network architectures</head><p>To evaluate the performance of CORAL for age estimation from face images, we chose the ResNet-34 architecture <ref type="bibr" target="#b7">(He et al., 2016)</ref>, which is a modern CNN architecture that achieves good performance on a variety of image classification tasks (?). For the remainder of this paper, we refer to the original ResNet-34 CNN with standard cross-entropy loss as CE-CNN. To implement a ResNet-34 CNN for ordinal regression using the proposed CORAL method, we replaced the last output layer with the corresponding binary tasks <ref type="figure" target="#fig_0">(Figure 2</ref>) and refer to this implementation as CORAL-CNN. Similar to CORAL-CNN, we modified the output layer of ResNet-34 to implement the ordinal regression reference approach described in <ref type="bibr" target="#b14">(Niu et al., 2016)</ref>; we refer to this architecture as OR-CNN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Training and evaluation</head><p>For model evaluation and comparison, we computed the mean absolute error (MAE) and root mean squared error (RMSE), on the test set after the last training epoch:</p><formula xml:id="formula_18">MAE = 1 N N i=1 |y i − h(x i )|, RMSE = 1 N N i=1 (y i − h(x i )) 2 ,</formula><p>where y i is the ground truth rank of the i-th test example and h(x i ) is the predicted rank, respectively. The model training was repeated three times with different random seeds (0, 1, and 2) for model weight initialization, while the random seeds were consistent between the different methods to allow fair comparisons. Since this study focuses on investigating rank consistency, an extensive comparison between optimization algorithms is beyond the scope of this article, so that all CNNs were trained for 200 epochs with stochastic gradient descent via adaptive moment estimation <ref type="bibr" target="#b9">(Kingma and Ba, 2015)</ref> using exponential decay rates β 0 = 0.90 and β 2 = 0.99 (default settings) and a batch size of 256. To avoid introducing empirical bias by designing our own CNN architecture for comparing the ordinal regression approaches, we adopted a standard architecture (ResNet-34 <ref type="bibr" target="#b7">(He et al., 2016)</ref>; Section 4.2) for this comparison. Moreover, we chose a uniform task weighting for the cross-entropy of K − 1 binary classifiers in CORAL-CNN, for instance, we set ∀k : λ (k) = 1 in Eq. 4.</p><p>The learning rate was determined by hyperparameter tuning on the validation set. For the various losses (cross-entropy, ordinal regression CNN <ref type="bibr" target="#b14">(Niu et al., 2016)</ref>, and the proposed CORAL method), we found that a learning rate of α = 5 × 10 −5 performed best across all models, which is likely due to using the same base architecture (ResNet-34). All models were trained for 200 epochs. From those 200 epochs, the best model was selected via MAE performance on the validation set. The selected model was then evaluated on the independent test set, from which the reported MAE and RMSE performance values were obtained. For all reported model performances, we reported the best test set performance within the 200 training epochs. We provide the complete training logs in the source code repository (Section 4.4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Hardware and software</head><p>All loss functions and neural network models were implemented in PyTorch 1.5 <ref type="bibr" target="#b15">(Paszke et al., 2019)</ref> and trained on NVIDIA GeForce RTX 2080Ti and Titan V graphics cards. The source code is available at https://github.com/ Raschka-research-group/coral-cnn.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Results and discussion</head><p>We conducted a series of experiments on three independent face image datasets for age estimation (Section 4.1) to compare the proposed CORAL method (CORAL-CNN) with the ordinal regression approach proposed by <ref type="bibr" target="#b14">Niu et al. (2016)</ref>  <ref type="figure">(OR-CNN)</ref>. All implementations were based on the ResNet-34 architecture, as described in Section 4.2. We include the standard ResNet-34 classification network with cross-entropy loss (CE-CNN) as a performance baseline.  <ref type="figure">Fig. 3</ref>. Graphs of the predicted probabilities for each binary classifier task on four different examples from the MORPH-2 test dataset. In all cases, OR-CNN suffers from one or more inconsistencies (indicated by arrows) in contrast to CORAL-CNN. CORAL-CNN OR-CNN <ref type="bibr" target="#b14">(Niu et al., 2016)</ref> OR-CNN <ref type="bibr" target="#b14">(Niu et al., 2016)</ref> OR-CNN <ref type="bibr" target="#b14">(Niu et al., 2016)</ref>   <ref type="table" target="#tab_1">Table 1)</ref> we found that both OR-CNN and CORAL-CNN outperform the standard cross-entropy classification loss (CE-CNN), which does not utilize the rank ordering information. Similarly, as summarized in <ref type="table" target="#tab_1">Table 1</ref>, the proposed rank-consistent CORAL method shows a substantial performance improvement over OR-CNN <ref type="bibr" target="#b14">(Niu et al., 2016)</ref>, which does not guarantee classifier consistency.</p><p>Moreover, we repeated each experiment three times using different random seeds for model weight initialization and dataset shuffling to ensure that the observed performance improvement of CORAL-CNN over OR-CNN is reproducible and not coincidental. We can conclude that guaranteed classifier consistency via CORAL has a noticeable positive effect on the predictive performance of an ordinal regression CNN (a more detailed analysis of the OR-CNN's rank inconsistency is provided in Section 5.2).</p><p>For all methods (CE-CNN, CORAL-CNN, and OR-CNN), the overall performance on the different datasets appeared in the following order: MORPH-2 &gt; AFAD &gt; CACD <ref type="table" target="#tab_1">(Table 1)</ref>. A possible explanation is that MORPH-2 has the best overall image quality, and the photos were taken under relatively consistent lighting conditions and viewing angles. For instance, we found that AFAD includes images with very low resolutions (for example, 20x20). CACD also contains some lower-quality images. Because CACD has approximately the same size as AFAD, the overall lower performance achieved on this dataset may also be explained by the wider age range that needs to be considered (CACD: 14-62 years, AFAD: 15-40 years).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Empirical rank inconsistency analysis</head><p>By design, our proposed CORAL guarantees rank consistency (Theorem 1). In addition, we analyzed the rank inconsistency empirically for both CORAL-CNN and OR-CNN (an example of rank inconsistency is shown in <ref type="figure">Figure 3)</ref>. <ref type="table" target="#tab_2">Table 2</ref> summarizes the average numbers of rank inconsistencies for the OR-CNN and CORAL-CNN models on each test dataset. As expected, CORAL-CNN has 0 rank inconsistencies. When comparing the average numbers of rank inconsistencies considering only those cases where OR-CNN predicted the age correctly versus incorrectly, the average number of inconsistencies is higher when OR-CNN makes wrong predictions. This observation can be seen as evidence that rank inconsistency harms predictive performance. Consequently, this finding suggests that addressing rank inconsistency via CORAL is beneficial for the predictive performance of ordinal regression CNNs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions</head><p>In this paper, we developed the CORAL framework for ordinal regression via extended binary classification with theoretical guarantees for classifier consistency. Moreover, we proved classifier consistency without requiring rank-or training labeldependent weighting schemes, which permits straightforward implementations and efficient model training. CORAL can be readily implemented to extend common CNN architectures for ordinal regression tasks. The experimental results showed that the CORAL framework substantially improved the predictive performance of CNNs for age estimation on three independent age estimation datasets. Our method can be readily generalized to other ordinal regression problems and different types of neural network architectures, including multilayer perceptrons and recurrent neural networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Supplementary Material</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1.">Generalization Bounds</head><p>Based on well-known generalization bounds for binary classification, we can derive new generalization bounds for our ordinal regression approach that apply to a wide range of practical scenarios as we only require C y,r k = 0 if r k = y and C y,r k &gt; 0 if r k = y. Moreover, Theorem 2 shows that if each binary classification task in our model generalizes well in terms of the standard 0/1-loss, the final rank prediction via h (Eq. 1) also generalizes well.</p><p>Theorem 2 (reduction of generalization error). Suppose C is the cost matrix of the original ordinal label prediction problem, with C y,y = 0 and C y,r k &gt; 0 for k = y. P is the underlying distribution of (x, y), for instance, (x, y) ∼ P. If the binary classification rules { f k } K−1 k=1 obtained by optimizing Eq. 4 are rankmonotonic, then E (x,y)∼P |C y,r k+1 − C y,r k | · 1{ f k (x) = y (k) }.</p><p>In any case, we have C y,h(x) ≤ K−1 k=1 |C y,r k − C y,r k+1 | · 1{ f k (x) = y (k) }.</p><p>By taking the expectation on both sides with (x, y) ∼ P, we arrive at Eq. (8).</p><p>In <ref type="bibr" target="#b12">Li and Lin (2007)</ref>, by assuming the cost matrix to have Vshaped rows, the researchers define generalization bounds by constructing a discrete distribution on {1, 2, . . . , K − 1} conditional on each y, given that the binary classifications are rank-monotonic or every row of C is convex. However, the only case they provided for the existence of rank-monotonic binary classifiers was the ordered threshold model, which requires a cost matrix with convex rows and example-specific task weights. In other words, when the cost matrix is only V-shaped but does not meet the convex row condition, for instance, C y,r k − C y,r k−1 &gt; C y,r k+1 − C y,r k &gt; 0 for some r k &gt; y, the method proposed in <ref type="bibr" target="#b12">Li and Lin (2007)</ref> did not provide a practical way to bound the generalization error. Consequently, our result does not rely on cost matrices with V-shaped or convex rows and can be applied to a broader variety of real-world use cases.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 .</head><label>2</label><figDesc>Illustration of the consistent rank logits CNN (CORAL-CNN) used for age prediction. From the estimated probability values, the binary labels are obtained via Eq. 5 and converted to the age label via Eq. 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>C y,h(x) ≤ K−1 k=1 |C y,r k − C y,r k+1 | E (x,y)∼P 1{ f k (x) = y (k) }.(8) Proof.For any x ∈ X, we havef 1 (x) ≥ f 2 (x) ≥ . . . ≥ f K−1 (x). If h(x) = y, then C y,h(x) = 0. If h(x) = r q ≺ y = r s , then q &lt; s. We have f 1 (x) = f 2 (x) = . . . = f q−1 (x) = 1 and f q (x) = f q+1 (x) = . . . = f K−1 (x) = 0.Also, y (1) = y (2) = . . . = y (s−1) = 1 and y (s) = y (s+1) = . . . = y (K−1) = 0.Thus, 1{ f k (x) = y (k) } = 1 if and only if q ≤ k ≤ s − 1. SinceC y,y = 0, ,r k − C y,r k+1 ) · 1{ f k (x) = y (k) r k − C y,r k+1 | · 1{ f k (x) = y (k) r k − C y,r k+1 | · 1{ f k (x) = y (k) }.Similarly, if h(x) = r q y = r s , then q &gt; s and C y,h(x) = q−1 k=s (C y,r k+1 − C y,r k ) · 1{ f k (x) = y (k)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>Age prediction errors on the test sets. All models are based on the ResNet-34 architecture.</figDesc><table><row><cell>Method</cell><cell>Random Seed</cell><cell cols="2">MORPH-2 MAE RMSE</cell><cell>MAE</cell><cell>AFAD</cell><cell>RMSE</cell><cell>MAE</cell><cell>CACD</cell><cell>RMSE</cell></row><row><cell></cell><cell>0</cell><cell>3.26</cell><cell>4.62</cell><cell>3.58</cell><cell></cell><cell>5.01</cell><cell>5.74</cell><cell></cell><cell>8.20</cell></row><row><cell>CE-CNN</cell><cell>1 2</cell><cell>3.36 3.39</cell><cell>4.77 4.84</cell><cell>3.58 3.62</cell><cell></cell><cell>5.01 5.06</cell><cell>5.68 5.53</cell><cell></cell><cell>8.09 7.92</cell></row><row><cell></cell><cell cols="9">AVG ± SD 3.34 ± 0.07 4.74 ± 0.11 3.60 ± 0.02 5.03 ± 0.03 5.65 ± 0.11 8.07 ± 0.14</cell></row><row><cell></cell><cell>0</cell><cell>2.87</cell><cell>4.08</cell><cell>3.56</cell><cell></cell><cell>4.80</cell><cell>5.36</cell><cell></cell><cell>7.61</cell></row><row><cell>OR-CNN</cell><cell>1</cell><cell>2.81</cell><cell>3.97</cell><cell>3.48</cell><cell></cell><cell>4.68</cell><cell>5.40</cell><cell></cell><cell>7.78</cell></row><row><cell>(Niu et al., 2016)</cell><cell>2</cell><cell>2.82</cell><cell>3.87</cell><cell>3.50</cell><cell></cell><cell>4.78</cell><cell>5.37</cell><cell></cell><cell>7.70</cell></row><row><cell></cell><cell cols="9">AVG ± SD 2.83 ± 0.03 3.97 ± 0.11 3.51 ± 0.04 4.75 ± 0.06 5.38 ± 0.02 7.70 ± 0.09</cell></row><row><cell></cell><cell>0</cell><cell>2.66</cell><cell>3.69</cell><cell>3.42</cell><cell></cell><cell>4.65</cell><cell>5.25</cell><cell></cell><cell>7.41</cell></row><row><cell>CORAL-CNN</cell><cell>1</cell><cell>2.64</cell><cell>3.64</cell><cell>3.51</cell><cell></cell><cell>4.76</cell><cell>5.25</cell><cell></cell><cell>7.50</cell></row><row><cell>(ours)</cell><cell>2</cell><cell>2.62</cell><cell>3.62</cell><cell>3.48</cell><cell></cell><cell>4.73</cell><cell>5.24</cell><cell></cell><cell>7.52</cell></row><row><cell></cell><cell cols="9">AVG ± SD 2.64 ± 0.02 3.65 ± 0.04 3.47 ± 0.05 4.71 ± 0.06 5.25 ± 0.01 7.48 ± 0.06</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Average numbers of inconsistencies occurred on the different test datasets for CORAL-CNN and Niu et al's Ordinal CNN. The penultimate column and last column list the average numbers of inconsistencies focusing only on the correct and incorrect age predictions, respectively.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">While the rank label r q is application-specific and defined by the user, for example r q ∈ {"bad", "okay", "good"} or r q ∈ {18 years, 19 years, ...70 years}, the rank index q is an integer in the range {1, 2, ..., K}.2 To provide further intuition for the weight sharing requirement, we may consider a simplified version, that is, the linear form logit(p i ) = wx + b i or</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Acknowledgments</head><p>This research was supported by the Office of the Vice Chancellor for Research and Graduate Education at the University of Wisconsin-Madison with funding from the Wisconsin Alumni Research Foundation. Also, we thank the NVIDIA Corporation for a GPU grant to support this study.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Evaluation measures for ordinal regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Baccianella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Esuli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sebastiani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Ninth International Conference on Intelligent Systems Design andApplications, IEEE</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="283" to="287" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Human age estimation using ranking SVM</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Chinese Conference on Biometric Recognition</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="324" to="331" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Ordinal hyperplanes ranker with cost sensitivities for age estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Y</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">P</forename><surname>Hung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="585" to="592" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Cross-age reference coding for ageinvariant face recognition and retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">H</forename><surname>Hsu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="768" to="783" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Using Ranking-CNN for age estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5183" to="5192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">New approaches to support vector ordinal regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Keerthi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning, ACM</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="145" to="152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Pranking with ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="641" to="647" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Support vector learning for ordinal regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Herbrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Graepel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Obermayer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IET Conference on Artificial Neural Networks</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="97" to="102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1412.6980" />
	</analytic>
	<monogr>
		<title level="m">3rd International Conference on Learning Representations</title>
		<editor>Bengio, Y., LeCun, Y.</editor>
		<meeting><address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-05-07" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Age and gender classification using convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Levi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hassner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition Workshops</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="34" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning ordinal discriminative features for age estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="2570" to="2577" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Ordinal regression by extended binary classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">T</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="865" to="872" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Regression models for ordinal data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mccullagh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society. Series B (Methodological)</title>
		<imprint>
			<biblScope unit="page" from="109" to="142" />
			<date type="published" when="1980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Ordinal regression with multiple output cnn for age estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4920" to="4928" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Pytorch: An imperative style, high-performance deep learning library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Raison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chilamkurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="8024" to="8035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Ordinal regression using noisy pairwise comparisons for body mass index range estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Polania</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Fung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="782" to="790" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Classification approach towards ranking and sorting problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rajaram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><forename type="middle">S</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Machine Learning</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page" from="301" to="312" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Age progression in human faces: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ramanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Biswas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Visual Languages and Computing</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="3349" to="3361" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">An allin-one convolutional neural network for face analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ranjan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sankaranarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Castillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Automatic Face &amp; Gesture Recognition</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="17" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">MLxtend: Providing machine learning and data science utilities and extensions to Python&apos;s scientific computing stack</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Raschka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Open Source Software</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1" to="2" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Python Machine Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Raschka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Mirjalili</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>Packt Publishing</publisher>
			<pubPlace>Birmingham, UK</pubPlace>
		</imprint>
	</monogr>
	<note>3rd Ed</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Morph: A longitudinal image database of normal adult age-progression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ricanek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tesafaye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Automatic Face and Gesture Recognition</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="341" to="345" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">DEX: Deep expectation of apparent age from a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rothe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Timofte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision Workshops</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="10" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">300 faces in-the-wild challenge: database and results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sagonas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Antonakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tzimiropoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pantic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image and Vision Computing</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="3" to="18" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Ranking with large margin principle: Two approaches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shashua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Levin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="961" to="968" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Ranking and reranking with perceptron</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Joshi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="73" to="96" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Ranking model for facial age estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Metaxas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2010 International Conference on Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="3404" to="3407" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
