<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Controllable Sentence Simplification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Louis</forename><surname>Martin</surname></persName>
							<email>2.louismartin@fb.com</email>
							<affiliation key="aff1">
								<address>
									<addrLine>6 Rue Ménars</addrLine>
									<postCode>75002</postCode>
									<settlement>Paris</settlement>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<address>
									<addrLine>2 rue Simone Iff</addrLine>
									<postCode>75012</postCode>
									<settlement>Paris</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Villemonte</forename><surname>De La Clergerie</surname></persName>
							<email>eric.delaclergerie@inria.fr</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benoît</forename><surname>Sagot</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
							<email>antoine.bordes@fb.com</email>
							<affiliation key="aff2">
								<address>
									<addrLine>2 rue Simone Iff</addrLine>
									<postCode>75012</postCode>
									<settlement>Paris</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Facebook AI Research 1</orgName>
								<orgName type="institution">Sorbonne Université</orgName>
								<address>
									<addrLine>Inria 2</addrLine>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Controllable Sentence Simplification</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T08:59+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Text Simplification</term>
					<term>Sequence-to-Sequence models</term>
					<term>ACCESS</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Text simplification aims at making a text easier to read and understand by simplifying grammar and structure while keeping the underlying information identical. It is often considered an all-purpose generic task where the same simplification is suitable for all; however multiple audiences can benefit from simplified text in different ways. We adapt a discrete parametrization mechanism that provides explicit control on simplification systems based on Sequence-to-Sequence models. As a result, users can condition the simplifications returned by a model on attributes such as length, amount of paraphrasing, lexical complexity and syntactic complexity. We also show that carefully chosen values of these attributes allow out-of-the-box Sequence-to-Sequence models to outperform their standard counterparts on simplification benchmarks. Our model, which we call ACCESS (as shorthand for AudienCe-CEntric Sentence Simplification), establishes the state of the art at 41.87 SARI on the WikiLarge test set, a +1.42 improvement over the best previously reported score.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In Natural Language Processing, the Text Simplification task aims at making a text easier to read and understand. Text simplification can be beneficial for people with cognitive disabilities such as aphasia <ref type="bibr" target="#b1">(Carroll et al., 1998)</ref>, dyslexia <ref type="bibr" target="#b26">(Rello et al., 2013)</ref> and autism <ref type="bibr" target="#b3">(Evans et al., 2014)</ref> but also for second language learners <ref type="bibr" target="#b39">(Xia et al., 2016)</ref> and people with low literacy <ref type="bibr" target="#b35">(Watanabe et al., 2009</ref>). The type of simplification needed for each of these audiences is different. Some aphasic patients struggle to read sentences with a high cognitive load such as long sentences with intricate syntactic structures, whereas second language learners might not understand texts with rare or specific vocabulary. Yet, research in text simplification has been mostly focused on developing models that generate a single generic simplification for a given source text with no possibility to adapt outputs for the needs of various target populations. In this paper, we propose a controllable simplification model that provides explicit ways for users to manipulate and update simplified outputs as they see fit. This work only considers the task of Sentence Simplification (SS) where the input of the model is a single source sentence and the output can be composed of one sentence or split into multiple. Our work builds upon previous work on controllable text generation <ref type="bibr" target="#b11">(Kikuchi et al., 2016;</ref><ref type="bibr" target="#b4">Fan et al., 2017;</ref><ref type="bibr" target="#b27">Scarton and Specia, 2018;</ref><ref type="bibr" target="#b19">Nishihara et al., 2019)</ref> where a Sequence-to-Sequence (Seq2Seq) model is modified to control attributes of the output text. We tailor this mechanism to the task of SS by considering relevant attributes of the output sentence such as the output length, the amount of paraphrasing, lexical complexity, and syntactic complexity. To this end, we condition the model at train time, by feeding control tokens representing these attributes along with the source sentence as additional inputs. Our contributions are the following: (1) We adapt a parametrization mechanism to the specific task of Sentence Simplification by conditioning on relevant attributes; <ref type="formula">(2)</ref> We show through a detailed analysis that our model can indeed control the considered attributes, making the simplifications potentially able to fit the needs of various end audiences; (3) With careful calibration, our controllable parametrization improves the performance of out-of-thebox Seq2Seq models leading to a new state-of-the-art score of 41.87 SARI  on the WikiLarge benchmark , a +1.42 gain over previous scores, without requiring any external resource or modified training objective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Sentence Simplification</head><p>Text simplification has gained increasing interest through the years and has benefited from advances in Natural Language Processing and notably Machine Translation. In recent years, SS was largely treated as a monolingual variant of machine translation (MT), where simplification operations are learned from complex-simple sentence pairs automatically extracted from English Wikipedia and Simple English Wikipedia <ref type="bibr" target="#b43">(Zhu et al., 2010;</ref><ref type="bibr" target="#b38">Wubben et al., 2012)</ref>. Phrase-based and Syntax-based MT was successfully used for SS <ref type="bibr" target="#b43">(Zhu et al., 2010)</ref> and further tailored to the task using deletion models <ref type="bibr" target="#b2">(Coster and Kauchak, 2011)</ref> and candidate reranking <ref type="bibr" target="#b38">(Wubben et al., 2012)</ref>. The candidate reranking method by <ref type="bibr" target="#b38">Wubben et al. (2012)</ref> favors simplifications that are most dissimilar to the source using Levenshtein distance. The authors argue that dissimilarity is a key factor of simplification. Lately, SS has mostly been tackled using Seq2Seq MT models <ref type="bibr" target="#b32">(Sutskever et al., 2014)</ref>. Seq2Seq models were either used as-is <ref type="bibr" target="#b20">(Nisioi et al., 2017)</ref> or combined with reinforcement learning thanks to a specific simplification reward , augmented with an external simplification database as a dynamic memory <ref type="bibr" target="#b42">(Zhao et al., 2018)</ref> or trained with multi-tasking on entailment and paraphrase generation <ref type="bibr" target="#b8">(Guo et al., 2018)</ref>.</p><p>This work builds upon Seq2Seq as well. We prepend additional inputs to the source sentences at train time, in the form of plain text control tokens. Our approach does not require any external data or modified training objective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Controllable Text Generation</head><p>Conditional training with Seq2Seq models was applied to multiple natural language processing tasks such as summarization <ref type="bibr" target="#b11">(Kikuchi et al., 2016;</ref><ref type="bibr" target="#b4">Fan et al., 2017)</ref>, dialog <ref type="bibr" target="#b29">(See et al., 2019)</ref>, sentence compression <ref type="bibr" target="#b5">(Fevry and Phang, 2018;</ref><ref type="bibr" target="#b16">Mallinson et al., 2018)</ref> or poetry generation <ref type="bibr" target="#b7">(Ghazvininejad et al., 2017)</ref>. Most approaches for controllable text generation are either decoding-based or learning-based. Decoding-based methods Decoding-based methods use a standard Seq2Seq training setup but modify the system during decoding to control a given attribute. For instance, the length of summaries was controlled by preventing the decoder from generating the End-Of-Sentence token before reaching the desired length or by only selecting hypotheses of a given length during the beam search <ref type="bibr" target="#b11">(Kikuchi et al., 2016)</ref>. Weighted decoding (i.e. assigning weights to specific words during decoding) was also used with dialog models <ref type="bibr" target="#b29">(See et al., 2019)</ref> or poetry generation models <ref type="bibr" target="#b7">(Ghazvininejad et al., 2017)</ref> to control the number of repetitions, alliterations, sentiment or style. Learning-based methods On the other hand, learningbased methods condition the Seq2Seq model on the considered attribute at train time, and can then be used to control the output at inference time. <ref type="bibr" target="#b11">Kikuchi et al. (2016)</ref> explored learning-based methods to control the length of summaries, e.g. by feeding a target length vector to the neural network. They concluded that learning-based methods worked better than decoding-based methods and allowed finer control on the length without degrading performances. Length control was likewise used in sentence compression by feeding the network a length countdown scalar <ref type="bibr" target="#b5">(Fevry and Phang, 2018)</ref> or a length vector <ref type="bibr" target="#b16">(Mallinson et al., 2018)</ref>. (Ficler and Goldberg, 2017) concatenate a context vector to the hidden state of each time step of their recurrent neural network decoder. This context vector represents the controlled stylistic attributes of the text, where an embedding is learnt for each attribute value. <ref type="bibr" target="#b9">(Hu et al., 2017)</ref> achieved controlled text generation by disentangling the latent space representations of a variational auto-encoder between the text representation and its controlled attributes such as sentiment and tense. They impose the latent space structure during training by using additional discriminators. Our work uses a simpler approach: we condition the generation process by concatenating plain text control tokens to the source text. This method only modifies the source data and not the training procedure. Such mechanism was used to control politeness in <ref type="bibr">MT (Sennrich et al., 2016)</ref>, to control summaries in terms of length, of news source style, or to make the summary more focused on a given named entity <ref type="bibr" target="#b4">(Fan et al., 2017)</ref>. <ref type="bibr" target="#b27">Scarton and Specia (2018)</ref> and <ref type="bibr" target="#b19">Nishihara et al. (2019)</ref> similarly showed that adding control tokens at the beginning of sentences can improve the performance of Seq2Seq models for SS. Plain text control tokens were used to encode attributes such as the target school grade-level (i.e. understanding level) and the type of simplification operation applied between the source and the ground truth simplification (identical, elaboration, one-to-many, manyto-one). Our work goes further by using a more diverse set of control tokens that represent specific grammatical attributes of the text simplification process. Moreover, we investigate the influence of those control tokens on the generated simplification in a detailed analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Adding Control Tokens to Seq2Seq</head><p>In this section we present ACCESS, our approach for AudienCe-CEntric Sentence Simplification. We want to control the process of Sentence Simplification using explicit control tokens. We first identify attributes that cover important aspects of the simplification process and then find explicit control tokens to represent each of those attributes. Parametrization is then achieved by conditioning a Seq2Seq model on those control tokens.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Controlled Attributes</head><p>Based on previous findings, we identify four attributes related to the process of text simplification: amount of compression, amount of paraphrasing, lexical complexity and syntactic complexity,.</p><p>• Amount of compression: The amount of compression is directly dependent on the length of sentences which is itself very correlated to simplicity , and is one of the two variables used in FKGL <ref type="bibr" target="#b12">(Kincaid et al., 1975)</ref>. It also accounts for the amount of content that is preserved between the source and target text, and can therefore control the simplicity-adequacy trade-off that is witnessed in text simplification <ref type="bibr" target="#b28">(Schwarzer and Kauchak, 2018</ref>).</p><p>• Paraphrasing: Paraphrasing is an important aspect for good text simplification systems <ref type="bibr" target="#b38">(Wubben et al., 2012)</ref>, especially because it allows the user from choosing if he prefers very safe simplifications (i.e. close to the source) or to try and simplify the input more at the cost of more mistakes when using imperfect systems. The amount of paraphrasing was also shown to correlate with human jugdment of meaning preservation and simplicity sometimes even more than traditional metrics such as BLEU <ref type="bibr" target="#b23">(Papineni et al., 2002)</ref> and SARI .</p><p>• Lexical and Syntactic complexity: <ref type="bibr" target="#b30">(Shardlow, 2014)</ref> identified lexical simplification and syntactic simplification as core components of SS systems, which often decomposes there approach into these two subcomponents. Audiences also have different simplification needs along these two attributes. In order to understand a text correctly, second language learner will require a text with less complicated words. On the other hand, some specific types of aphasia will make people struggle more with complex syntactic structures, intricated clauses, and long sentence, thus requiring syntactic simplification.</p><p>Other more specific attributes could be considered such as the tense or the use passive-active voice. We only consider the previous attributes for simplicity and leave the rest for future work. We don't consider "readability" measured with FKGL because it is just a linear combination of other attributes, namely sentence length and word complexity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Explicit Control Tokens</head><p>For each of the four aforementioned attributes, we choose an explicit "proxy" control token that can be computed using the source and simplified sentence and used as a plain text token. We describe these for explicit control tokens in this subsection.</p><p>• NbChars: character length ratio between source sentence and target sentence (compression level). This control token accounts for sentence compression, and content deletion. Previous work showed that simplicity is best correlated with length-based metrics, and especially in terms of number of characters . The number of characters indeed accounts for the lengths of words which is itself correlated to lexical complexity.</p><p>• LevSim: normalized character-level Levenshtein similarity <ref type="bibr" target="#b15">(Levenshtein, 1966)</ref> between source and target. LevSim quantifies the amount of modification operated on the source sentence (through paraphrasing, adding and deleting content).</p><p>• WordRank: as a proxy to lexical complexity, we compute a sentence-level measure, that we call WordRank, by taking the third-quartile of log-ranks (inverse frequency order) of all words in a sentence. We subsequently divide the WordRank of the target by that of the source to get a ratio. Word frequencies have shown to be the best indicators of word complexity in the Semeval 2016 task 11 <ref type="bibr" target="#b22">(Paetzold and Specia, 2016)</ref>.</p><p>• DepTreeDepth: maximum depth of the dependency tree of the source divided by that of the target (we do not feed any syntactic information other than this ratio to the model). This control token is designed to approximate syntactic complexity. Deeper dependency trees indicate dependencies that span longer and possibly more intricate sentences. DepTreeDepth proved better in early experiments over other candidates for measuring syntactic complexity such as the maximum length of a dependency relation, or the maximum inter-word dependency flux.</p><p>We parametrize a Seq2Seq model on a given attribute of the target simplification, e.g. its length, by prepending a control token at the beginning of the source sentence. The control token value is the ratio 1 of this control token calculated on the target sentence with respect to its value on the source sentence. For example when trying to control the number of characters of a generated simplification, we compute the compression ratio between the number of characters in the Source &lt;NbChars 0.3&gt; &lt;LevSim 0.4&gt; He settled in London , devoting himself chiefly to practical teaching .</p><p>Target He teaches in London . Here the source and target simplifications respectively contain 71 and 22 characters which gives a compression ratio of 0.3. We prepend the &lt;NbChars 0.3&gt; token to the source sentence. Similarly, the Levenshtein similarity between the source and the sentence is 0.37 which gives the &lt;LevSim 0.4&gt; control token after bucketing.</p><p>source and the number of characters in the target sentence (see <ref type="table" target="#tab_0">Table 1</ref> for an illustration). Ratios are discretized into bins of fixed width of 0.05 in our experiments and capped to a maximum ratio of 2. Control tokens are then included in the vocabulary (40 unique values per control token). At inference time, we just set the ratio to a fixed value for all samples 2 . For instance, to get simplifications that are 80% of the source length, we prepend the token &lt;NbChars 0.8&gt; to each source sentence. This fixed ratio can be userdefined or automatically set. In our setting, we choose fixed ratios that maximize the SARI on the validation set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Experimental Setting</head><p>Architecture details We train a Transformer model <ref type="bibr" target="#b33">(Vaswani et al., 2017)</ref> using the FairSeq toolkit <ref type="bibr" target="#b21">(Ott et al., 2019)</ref>. Our architecture is the base architecture from <ref type="bibr" target="#b33">(Vaswani et al., 2017)</ref>. We used an embedding dimension of 512, fully connected layers of dimension 2048, 8 attention heads, 6 layers in the encoder and 6 layers in the decoder. Dropout is set to 0.2. We use the Adam optimizer <ref type="bibr" target="#b13">(Kingma and Ba, 2014)</ref> with β 1 = 0.9, β 2 = 0.999, = 10 −8 and a learning rate of lr = 0.00011. We add label smoothing with a uniform prior distribution of = 0.54. We use early stopping when SARI does not increase for more than 5 epochs. We tokenize sentences using the NLTK NIST tokenizer and preprocess using Sentence-Piece <ref type="bibr" target="#b14">(Kudo and Richardson, 2018)</ref> with 10k vocabulary size to handle rare and unknown words. For generation we use beam search with a beam size of 8. <ref type="bibr">3</ref> Training and evaluation datasets Our models are trained and evaluated on the WikiLarge dataset  which contains 296,402/2,000/359 samples (train/validation/test). WikiLarge is a set of automatically aligned complex-simple sentence pairs from English Wikipedia (EW) and Simple English Wikipedia (SEW). It is compiled from previous extractions of EW-SEW <ref type="bibr" target="#b43">(Zhu et al., 2010;</ref><ref type="bibr" target="#b37">Woodsend and Lapata, 2011;</ref><ref type="bibr" target="#b10">Kauchak, 2013)</ref>. Its validation and test sets are taken from Turkcorpus <ref type="bibr">(Xu 2</ref> We did not investigate predicting ratios on a per sentence basis as done by <ref type="bibr" target="#b27">Scarton and Specia (2018)</ref>, and leave this for future work. End-users can nonetheless choose the target ratios as they see fit, for each source sentence. <ref type="bibr">3</ref>   <ref type="bibr">, 2016)</ref>, where each complex sentence has 8 human simplifications created by Amazon Mechanical Turk workers. Human annotators were instructed to only paraphrase the source sentences while keeping as much meaning as possible. Hence, no sentence splitting, minimal structural simplification and little content reduction occurs in this test set . We are not able to use the Newsela dataset <ref type="bibr" target="#b45">(Xu et al., 2015)</ref> because of legal constraints related to its limited public availability. The Newsela dataset can only be accessed by signing a one year Data Sharing Agreement and comes with a restrictive non-commercial license. Additionally, all publications using the dataset need to be sent in advance to Newsela for approval. This limited public availability also prevents the research community from agreeing on a public train/validation/test split which hampers reproducibility of results.</p><p>Evaluation metrics We evaluate our methods with FKGL (Flesch-Kincaid Grade Level) <ref type="bibr" target="#b12">(Kincaid et al., 1975)</ref> to account for simplicity and SARI  as an overall score. FKGL is a commonly used metric for measuring readability however it should not be used alone for evaluating systems because it does not account for grammaticality and meaning preservation <ref type="bibr" target="#b38">(Wubben et al., 2012)</ref>. It is computed as a linear combination of the number of words per simple sentence and the number of syllables per word:</p><p>F KGL = 0.39 nb words nb sentences + 11.8 nb syllables nb words − 15.59</p><p>On the other hand SARI compares the predicted simplification with both the source and the target references. It is an average of F1 scores for three n-gram operations: additions, keeps and deletions 4 . For each operation, these scores are then averaged for all n-gram orders (from 1 to 4) to get the overall F1 score.</p><p>ope ∈ [add, keep, del] f ope (n) = 2 × p ope (n) × r ope (n) p ope (n) + r ope (n)</p><formula xml:id="formula_0">F ope = 1 k n=[1,..,k] f ope (n) SARI = F add + F keep + F del 3</formula><p>We compute FKGL and SARI using the EASSE python package for SS (Alva-Manchego et al., 2019). We do not use BLEU because it is not suitable for evaluating SS systems <ref type="bibr" target="#b31">(Sulem et al., 2018)</ref>. BLEU is also misleading because it favors models that do not modify the source sentence     Hybrid <ref type="bibr" target="#b18">(Narayan and Gardent, 2014)</ref> Deep semantics sentence representation fed to a monolingual MT system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Overall Performance</head><p>SBMT+PPDB+SARI  Syntax-based MT model augmented using the PPDB paraphrase database <ref type="bibr" target="#b25">(Pavlick et al., 2015)</ref> and finetuned towards SARI.  Seq2Seq trained with reinforcement learning, combined with a lexical simplification model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DRESS-LS</head><p>Pointer+Ent+Par <ref type="bibr" target="#b8">(Guo et al., 2018)</ref> Seq2Seq model based on the pointer-copy mechanism and trained via multi-task learning on the Entailment and Paraphrase Generation tasks.</p><p>NTS+SARI <ref type="bibr" target="#b20">(Nisioi et al., 2017)</ref> Standard Seq2Seq model. The second beam search hypothesis is selected during decoding; the hypothesis number is an hyper-parameter fine-tuned with SARI.</p><p>NSELSTM-S <ref type="bibr" target="#b34">(Vu et al., 2018)</ref> Seq2Seq with a memory-augmented Neural Semantic Encoder, tuned with SARI.</p><p>DMASS+DCSS <ref type="bibr" target="#b42">(Zhao et al., 2018)</ref> Seq2Seq integrating the simple PPDB simplification database ) as a dynamic memory. The database is also used to modify the loss and re-weight word probabilities to favor simpler words.</p><p>We select the model with the best SARI on the validation set and report its score on the test set. This model uses three control tokens out of four: NbChars 0.95 , LevSim 0.75 and WordRank 0.75 (optimal target ratios in subscript). ACCESS scores best on SARI (41.87), a significant improvement over previous state of the art (40.45), and third to best FKGL (7.22). The second and third models in terms of SARI, DMASS+DCSS (40.45) and SBMT+PPDB+SARI (39.96), both use the external resource Simple PPDB ) that was extracted from 1000 times more data than what we used for training. Our FKGL is also better (lower) than these methods. The Hybrid model scores best on FKGL (4.56) i.e. they generated the simplest (and shortest) sentences, but it was done at the expense of SARI (31.40). Parametrization encourages the model to rely on explicit aspects of the simplification process, and to associate them with the control tokens. The model can then be adapted more precisely to the type of simplification needed. In Wik-iLarge, for instance, the compression ratio distribution is different than that of human simplifications (see <ref type="figure" target="#fig_0">Figure 1)</ref>. The NbChars control token helps the model decorrelate the compression aspect from other attributes of the simplification process. This control token is then adapted to the amount of compression required in a given evaluation dataset, such as a true, human simplified SS dataset. Our best model indeed worked best with a NbChars target ratio set to 0.95 which is the closest bucketed value to the compression ratio of human annotators on the WikiLarge validation set (0.93).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Ablation Studies</head><p>In this section we investigate the contribution of each control token to the final SARI score of ACCESS.  <ref type="table" target="#tab_5">Table 3</ref>: Ablation study on the control tokens using greedy forward selection. We report SARI and FKGL on Wiki-Large validation set. Each score is a mean over 10 runs with a 95% confidence interval. Scores with * are statistically significantly better than the Transformer baseline (pvalue &lt; 0.01 for a Student's T-test).</p><p>performance when combined with previously added control tokens.</p><p>With only one control token, WordRank proves to be best (+2.28 SARI over models without parametrization). As the WikiLarge validation set mostly contains small paraphrases, it seems natural that the control token linked to lexical simplification increases the performance the most. LevSim (+1.23) is the second best control token. This confirms the intuition that hypotheses that are more dissimilar to the source are better simplifications, as claimed in <ref type="bibr" target="#b38">(Wubben et al., 2012;</ref><ref type="bibr" target="#b20">Nisioi et al., 2017)</ref>. There is little content reduction in the WikiLarge validation set (see <ref type="figure" target="#fig_0">Figure 1</ref>), thus control tokens that are closely related to sentence length will be less effective. This is the case for the NbChars and DepTreeDepth control tokens (shorter sentences, will have lower tree depths): they bring more modest improvements, +0.88 and +0.66. The performance boost is nearly additive at first when adding more control tokens (WordRank+LevSim: +4.04) but saturates quickly with 3+ control tokens. In fact, no combination of 3 or more control tokens gets a statistically significant improvement over the WordRank+LevSim setup (p-value &lt; 0.01 for a Student's T-test). This indicates that control tokens are not all useful to improve the scores on this benchmark, and that they might be not independent from one another. The addition of the DepTreeDepth as a final control token even decreases the SARI score slightly, most probably because the considered validation set does not include sentence splitting and structural modifications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Analysis of the Influence of Control Tokens</head><p>Our goal is to give the user control over how the model will simplify sentences on four important attributes of SS: length, paraphrasing, lexical complexity and syntactic complexity. To this end, we introduced four control tokens: NbChars, LevSim, WordRank and DepTreeDepth. Even though the control tokens improve the performance in terms of SARI, it is not sure whether they have the desired effect (a) With the NbChars1.00 constraint.</p><p>(b) Without the NbChars1.00 constraint. <ref type="figure">Figure 2</ref>: Influence of each control token on the corresponding attributes of the output simplifications. Rows represent control tokens (each model is trained either only with one control token or with one control token and the NbChars 1.00 constraint), columns represent output attributes of the predictions and colors represent the fixed target ratio of the control token (yellow=0.25, blue=0.50, violet=0.75, red=1.00, green=Ground truth). We plot the results on the 2000 validation sentences. <ref type="figure">Figure 2a</ref> uses the NbChars 1.00 constraint, whereas <ref type="figure">Figure 2b</ref> doesn't. The trails that are used by people learning about the natural world , because the trails are good trails . LevSim 0.25 +NbChars1.00</p><p>Mechanical trails ( also known as " trail trail " or " trails " ) are trails that are used for trails .</p><p>WordRank  on their associated attribute. In this section we investigate to what extent each control token controls the generated simplification. We first used separate models, each trained with a single control token to isolate their respective influence on the output simplifications. However, we witnessed that with only one control token, the effect of LevSim, Wor-dRank and DepTreeDepth was mainly to reduce the length of the sentence <ref type="figure">(Figure 2b)</ref>. Indeed, shortening the sentence will decrease the Levenshtein similarity, decrease the Wor-dRank (when complex words are deleted) and decrease the dependency tree depth (shorter sentences have shallower dependency trees). Therefore, to clearly study the influence of those control tokens, we also add the NbChars control token during training, and set its ratio to 1.00 at inference time, as a constraint toward not modifying the length. <ref type="figure">Figure 2a</ref> highlights the cross influence of each of the four control tokens on their four associated attributes. Control tokens are successively set to ratios of 0.25 (yellow), 0.50 (blue), 0.75 (violet) and 1.00 (red); the ground truth is displayed in green. Plots located on the diagonal show that control tokens control their respective attributes (e.g. NbChars affects the compression ratio), although not with the same effectiveness.</p><p>The histogram located at (row 1, col 1) shows the effect of the NbChars control token on the compression ratio of the predicted simplifications. The resulting distributions are centered on the 0.25, 0.5, 0.75 and 1 target ratios as expected, and with little overlap. This indicates that the lengths of predictions closely follow what is asked of the model. <ref type="table" target="#tab_8">Table 4</ref> illustrates this with an example. The NbChars control token affects Levenshtein similarity: reducing the length decreases the Levenshtein similarity. Finally, NbChars has a marginal impact on the WordRank ratio distribution, but clearly influences the dependency tree depth. This is natural considered that the depth of a dependency tree is very correlated with the length of the sentence. The LevSim control token also has a clear cut impact on the Levenshtein similarity (row 2, col 2). The first example in <ref type="table" target="#tab_8">Table 4</ref> highlights that LevSim increases the amount of paraphrasing in the simplifications. With an extreme target ratio of 0.25, the model outputs ungrammatical and meaningless predictions, thus indicating that the choice of a target ratio is important for generating proper simplifications. WordRank and DepTreeDepth do not seem to control their respective attribute as well as NbChars and LevSim according to <ref type="figure">Figure 2a</ref>. However we witness more lexical simplifications when using the WordRank ratio than with other control tokens. In <ref type="table" target="#tab_8">Table 4</ref>'s first example, "designated as" is simplified by "called" or "known as" with the Wor-dRank control token. Equivalently, DepTreeDepth splits the source sentence in multiple shorter sentences in Table 4's first example. WordRank and DepTreeDepth control tokens therefore have the desired effect.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusion</head><p>This paper showed that explicitly conditioning Seq2Seq models on control tokens such as length, paraphrasing, lexical complexity or syntactic complexity increases their performance significantly for sentence simplification. We confirmed through an analysis that each control token has the desired effect on the generated simplifications. In addition to being easy to extend to other attributes of text simplification, our method paves the way toward adapting the simplification to audiences with different needs.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Density distribution of the compression ratios between the source sentence and the target sentence. The automatically aligned pairs from WikiLarge train set are spread (red) while human simplifications from the validation and test set (green) are gathered together with a mean ratio of 0.93 (i.e. nearly no compression).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Example of parametrization on the number of characters.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Comparison to the literature. We report the results of the model that performed the best on the validation set among all runs and parametrizations. The ratios used for parametrizations are written as subscripts.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell>compares our best model to state-of-the-art meth-</cell></row><row><cell>ods:</cell></row><row><cell>PBMT-R (Wubben et al., 2012)</cell></row><row><cell>Phrase-Based MT system with candidate reranking.</cell></row><row><cell>Dissimilar candidates are favored based on their Lev-</cell></row><row><cell>enshtein distance to the source.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3</head><label>3</label><figDesc></figDesc><table><row><cell>re-</cell></row></table><note>* ± 0.39</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>Target control tokens Sentence Source Some trails are designated as nature trails , and are used by people learning about the natural world . NbChars 1.00 Some trails are called nature trails , and are used by people about the natural world . NbChars 0.75 Some trails are called nature trails , and are used by people about the natural world . NbChars 0.50 Some trails are used by people about the natural world . NbChars 0.25 Some trails are used by people . LevSim 1.00 +NbChars1.00 Some trails are designated as nature trails , and are used by people learning about the natural world . LevSim 0.75 +NbChars1.00 Some trails are made for nature trails . They are used by people who learn about the natural world . LevSim 0.50 +NbChars1.00</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>1.00 +NbChars1.00 Some trails are designated as nature trails , and are used by people learning about the natural world . WordRank 0.75 +NbChars1.00 Some trails are called nature trails , and are used by people learning about the natural world . WordRank 0.50 +NbChars1.00 Some trails are known as nature trails , and are used by people as well as by people who are in the world . WordRank 0.25 +NbChars1.00 Some trails are also called nature trails , and are used by people learning about the natural world . DepTreeDepth 1.00 +NbChars1.00 Some trails are designated as nature trails , and are used by people learning about the natural world . DepTreeDepth 0.75 +NbChars1.00 Some trails are designated as nature trails . They are used by people learning about the natural world . DepTreeDepth 0.50 +NbChars1.00 Some trails are designated as nature trails . They are used by people learning about the natural world . DepTreeDepth 0.25 +NbChars1.00 Some trails are designated as nature trails . They are used by people to learn about the natural world .</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table /><note>Influence of control tokens on example sentences. Each source sentence is simplified with models trained with each of the four control tokens with varying target ratios; modified words are in bold. The NbChars 1.00 constraint is added for LevSim, WordRank and DepTreeDepth.</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Early experiments showed that using a ratio instead of an absolute value allowed finer control on the respective attributes.</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Source</head><p>Iron Maiden , released on April 14 , 1980 , is the debut album by heavy metal band Iron Maiden .</p><p>NbChars Nocturnes is an orchestral composition in three movements by the French composer Claude Debus . NbChars 0.50</p><p>Nocturnes is an orchestral composition in three movements . NbChars 0.25</p><p>Nocturnes is an orchestral composition .</p><p>LevSim 1.00 +NbChars1.00 Nocturnes is an orchestral composition in three movements by the French composer Claude Debussy . LevSim 0.75 +NbChars1.00</p><p>Nocturnes is a piece of music for orchestra by the French composer Claude Debussy . LevSim 0.50 +NbChars1.00</p><p>Nocturnes is a piece of music for orchestra that was composed by a French composer called Claude Debussy . LevSim 0.25 +NbChars1.00</p><p>Claude Debussy was a French composer who wrote music for the orchestra when he was 17 years old .</p><p>WordRank 1.00 +NbChars1.00 Nocturnes is an orchestral composition in three movements by the French composer Claude Debussy . WordRank 0.75 +NbChars1.00</p><p>Nocturnes is a piece of music for orchestra by the French composer Claude Debussy . WordRank 0.50 +NbChars1. <ref type="bibr">00</ref> Nocturnes is a piece of music by the French composer Claude Debussy . WordRank 0.25 +NbChars1. <ref type="bibr">00</ref> Nocturnes is a piece of music for orchestra by the French composer Claude Debussy .</p><p>DepTreeDepth 1.00 +NbChars1.00 Nocturnes is an orchestral composition in three movements by the French composer Claude Debussy . DepTreeDepth 0.75 +NbChars1.00 Nocturnes is an orchestral composition in three movements by the French composer Claude Debussy . DepTreeDepth 0.50 +NbChars1.00 Nocturnes is an orchestral composition by the French composer Claude Debussy in three movements . DepTreeDepth 0.25 +NbChars1.00 Nocturnes is a French orchestra . It was started by Claude Debussy in three movements .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Source</head><p>It is an F-type asteroid , which means that it is very dark in colouring ( darker than soot ) with a carbonaceous composition .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>NbChars 1.00</head><p>It is an F-type asteroid , which means that it is very dark in colouring ( darker than soot ) with a carbonaceous composition . NbChars 0.75</p><p>It is an F-type asteroid , which means that it is very dark in colouring ( darker than soot ) . NbChars 0.50</p><p>This means that it is very dark in colouring ( darker than soot ) . NbChars 0.25</p><p>It is an F-type asteroid .</p><p>LevSim 1.00 +NbChars1.00 It is an F-type asteroid , which means that it is very dark in colouring ( darker than soot ) with a carbonaceous composition . LevSim 0.75 +NbChars1.00</p><p>It is an F-type asteroid , which means that it is very dark in colouring ( darker than soot ) made up of carbonate metal . LevSim 0.50 +NbChars1.00 F-type asteroids can be made up of darker than soot ( darker than soot ) , or darker ( darker than soot ) , or dark ( darker ) . WordRank 1.00 +NbChars1.00 It is an F-type asteroid , which means that it is very dark in colouring ( darker than soot ) with a carbonaceous composition . WordRank 0.75 +NbChars1. <ref type="bibr">00</ref> It is an F-type asteroid , which means that it is very dark in colouring ( darker than soot ) with a made of carbonate . WordRank 0.50 +NbChars1. <ref type="bibr">00</ref> It is an F-type asteroid , which means that it is very dark in colouring ( darker than soot ) with a very dark made up of . WordRank 0.25 +NbChars1. <ref type="bibr">00</ref> It is an F-type asteroid , which means that it is very dark in colouring ( darker than soot ) with a carbonaceous composition .</p><p>DepTreeDepth 1.00 +NbChars1.00 It is an F-type asteroid , which means that it is very dark in colouring ( darker than soot ) with a carbonaceous composition . DepTreeDepth 0.75 +NbChars1.00 It is an F-type asteroid , which means that it is very dark in colouring ( darker than soot ) with a carbonaceous composition . DepTreeDepth 0.50 +NbChars1.00 It is an F-type asteroid . It means that it is very dark in colouring ( darker than soot ) with a carbonaceous composition . DepTreeDepth 0.25 +NbChars1.00 It is an F-type asteroid . It means that it is very dark in colouring ( darker than soot ) with a carbonaceous composition .</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Easse: Easier automatic sentence simplification evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Alva-Manchego</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Scarton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Specia</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.04567</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Practical simplification of english newspaper text to assist aphasic readers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Carroll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Minnen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Canning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tait</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI-98 Workshop on Integrating Artificial Intelligence and Assistive Technology</title>
		<meeting>the AAAI-98 Workshop on Integrating Artificial Intelligence and Assistive Technology</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="7" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning to simplify sentences using wikipedia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Coster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kauchak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the workshop on monolingual text-to-text generation</title>
		<meeting>the workshop on monolingual text-to-text generation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">An evaluation of syntactic simplification rules for people with autism</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Orasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Dornescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd Workshop on Predicting and Improving Text Readability for Target Reader Populations (PITR)</title>
		<meeting>the 3rd Workshop on Predicting and Improving Text Readability for Target Reader Populations (PITR)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="131" to="140" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Grangier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Auli</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1711.05217</idno>
		<title level="m">Controllable abstractive summarization</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Unsupervised sentence compression using denoising auto-encoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Fevry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Phang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.02669</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Controlling linguistic style aspects in neural language generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ficler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Goldberg</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.02633</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Hafez: an interactive poetry generation system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ghazvininejad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Priyadarshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Knight</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL 2017, System Demonstrations</title>
		<meeting>ACL 2017, System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="43" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Dynamic multi-level multi-task learning for sentence simplification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pasunuru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bansal</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.07304</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Toward controlled generation of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
		<ptr target="JMLR.org" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="1587" to="1596" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Improving text simplification language modeling using unsimplified text data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kauchak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st annual meeting of the association for computational linguistics</title>
		<meeting>the 51st annual meeting of the association for computational linguistics</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1537" to="1546" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kikuchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sasano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Takamura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Okumura</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.09552</idno>
		<title level="m">Controlling output length in neural encoder-decoders</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Derivation of new readability formulas (automated readability index, fog count and flesch reading ease formula) for navy enlisted personnel</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Kincaid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">P</forename><surname>Fishburne</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">L</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">S</forename><surname>Chissom</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Sentencepiece: A simple and language independent subword tokenizer and detokenizer for neural text processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kudo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Richardson</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.06226</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Binary codes capable of correcting deletions, insertions, and reversals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">I</forename><surname>Levenshtein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Soviet physics doklady</title>
		<imprint>
			<date type="published" when="1966" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="707" to="710" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Sentence compression for arbitrary languages via multilingual pivoting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mallinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2453" to="2464" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Referenceless quality estimation of text simplification systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Humeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-E</forename><surname>Mazaré</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">É</forename><forename type="middle">V</forename><surname>De La Clergerie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sagot</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.10746</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Hybrid simplification using deep semantics and machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Narayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gardent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="435" to="445" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Controllable text simplification with lexical constraint loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Nishihara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kajiwara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arase</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Conference of the Association for Computational Linguistics: Student Research Workshop</title>
		<meeting>the 57th Conference of the Association for Computational Linguistics: Student Research Workshop</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="260" to="266" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Exploring neural text simplification models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nisioi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Štajner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">P</forename><surname>Ponzetto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">P</forename><surname>Dinu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Short Papers</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="85" to="91" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">fairseq: A fast, extensible toolkit for sequence modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Edunov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Baevski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Grangier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Auli</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-HLT 2019: Demonstrations</title>
		<meeting>NAACL-HLT 2019: Demonstrations</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Semeval 2016 task 11: Complex word identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Paetzold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Specia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016)</title>
		<meeting>the 10th International Workshop on Semantic Evaluation (SemEval-2016)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="560" to="569" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Bleu: a method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-J</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th annual meeting on association for computational linguistics</title>
		<meeting>the 40th annual meeting on association for computational linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Simple ppdb: A paraphrase database for simplification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Pavlick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Callison-Burch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="143" to="148" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Ppdb 2.0: Better paraphrase ranking, fine-grained entailment relations, word embeddings, and style classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Pavlick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rastogi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ganitkevitch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Van Durme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Callison-Burch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="425" to="430" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Simplify or help?: text simplification strategies for people with dyslexia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Rello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Baeza-Yates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Saggion</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Cross-Disciplinary Conference on Web Accessibility</title>
		<meeting>the 10th International Cross-Disciplinary Conference on Web Accessibility</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page">15</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Learning simplifications for specific target audiences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Scarton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Specia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="712" to="718" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Human evaluation for text simplification: The simplicity-adequacy tradeoff</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schwarzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kauchak</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">What makes a good conversation? how controllable attributes affect human judgments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>See</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Birch</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.08654</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="35" to="40" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Controlling politeness in neural machine translation via side constraints</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A survey of automated text simplification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shardlow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Advanced Computer Science and Applications</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="58" to="70" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Bleu is not suitable for the evaluation of text simplification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Sulem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Abend</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rappoport</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ł</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Munkhdalai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1804.07445</idno>
		<title level="m">Sentence simplification with memory-augmented neural networks</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">M</forename><surname>Watanabe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Junior</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">R</forename><surname>Uzêda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">P D M</forename><surname>Fortes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">A S</forename><surname>Pardo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aluísio</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Facilita: reading assistance for low-literacy readers</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th ACM international conference on Design of communication</title>
		<meeting>the 27th ACM international conference on Design of communication</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<biblScope unit="page" from="29" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Learning to simplify sentences with quasi-synchronous grammar and integer programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Woodsend</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the conference on empirical methods in natural language processing</title>
		<meeting>the conference on empirical methods in natural language processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="409" to="420" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Sentence simplification by monolingual machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wubben</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bosch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Krahmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1015" to="1024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Text readability assessment for second language learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kochmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Briscoe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th Workshop on Innovative Use of NLP for Building Educational Applications</title>
		<meeting>the 11th Workshop on Innovative Use of NLP for Building Educational Applications</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="12" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Optimizing statistical machine translation for text simplification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Napoles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Pavlick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Callison-Burch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="401" to="415" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lapata</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.10931</idno>
		<title level="m">Sentence simplification with deep reinforcement learning</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Integrating transformer and paraphrase rules for sentence simplification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Andi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bambang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.11193</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">A monolingual tree-based translation model for sentence simplification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bernhard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd international conference on computational linguistics</title>
		<meeting>the 23rd international conference on computational linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1353" to="1361" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Language Resource References</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Callison-Burch</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Napoles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Courtney</forename></persName>
		</author>
		<title level="m">Problems in current text simplification research: New data can help</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Optimizing statistical machine translation for text simplification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Courtney</forename><surname>Napoles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellie</forename><surname>Pavlick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quanze</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Sentence simplification with deep reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingxing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
