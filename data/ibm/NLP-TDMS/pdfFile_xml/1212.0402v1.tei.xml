<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="20123-11">November 2012 3 Dec 2012</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khurram</forename><surname>Soomro</surname></persName>
							<email>ksoomro@cs.ucf.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Center for Research in Computer</orgName>
								<orgName type="institution">Vision University of Central Florida</orgName>
								<address>
									<addrLine>4000 Central Florida Blvd. Orlando</addrLine>
									<postCode>32816-2365</postCode>
									<region>FL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Roshan Zamir</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Research in Computer</orgName>
								<orgName type="institution">Vision University of Central Florida</orgName>
								<address>
									<addrLine>4000 Central Florida Blvd. Orlando</addrLine>
									<postCode>32816-2365</postCode>
									<region>FL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mubarak</forename><surname>Shah</surname></persName>
							<email>shah@cs.ucf.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Center for Research in Computer</orgName>
								<orgName type="institution">Vision University of Central Florida</orgName>
								<address>
									<addrLine>4000 Central Florida Blvd. Orlando</addrLine>
									<postCode>32816-2365</postCode>
									<region>FL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khurram</forename><surname>Soomro</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Center for Research in Computer Vision</orgName>
								<address>
									<postCode>32816</postCode>
									<settlement>Orlando</settlement>
									<region>FL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Roshan Zamir</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Center for Research in Computer Vision</orgName>
								<address>
									<postCode>32816</postCode>
									<settlement>Orlando</settlement>
									<region>FL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mubarak</forename><surname>Shah</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Center for Research in Computer Vision</orgName>
								<address>
									<postCode>32816</postCode>
									<settlement>Orlando</settlement>
									<region>FL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="20123-11">November 2012 3 Dec 2012</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T10:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Action Dataset</term>
					<term>UCF101</term>
					<term>UCF50</term>
					<term>Action Recognition</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We introduce UCF101 which is currently the largest dataset of human actions. It consists of 101 action classes, over 13k clips and 27 hours of video data. The database consists of realistic user-uploaded videos containing camera motion and cluttered background. Additionally, we provide baseline action recognition results on this new dataset using standard bag of words approach with overall performance of 44.5%. To the best of our knowledge, UCF101 is currently the most challenging dataset of actions due to its large number of classes, large number of clips and also unconstrained nature of such clips.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Dataset Details</head><p>Action Classes: UCF101 includes total number of 101 action classes which we have divided into five types:</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The majority of existing action recognition datasets suffer from two disadvantages: 1) The number of their classes is typically very low compared to the richness of performed actions by humans in reality, e.g. KTH <ref type="bibr" target="#b10">[11]</ref>, Weizmann <ref type="bibr" target="#b2">[3]</ref>, UCF Sports <ref type="bibr" target="#b9">[10]</ref>, IXMAS <ref type="bibr" target="#b11">[12]</ref> datasets includes only <ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b10">11</ref> classes respectively. 2) The videos are recorded in unrealistically controlled environments. For instance, KTH, Weizmann, IXMAS are staged by actors; HOHA <ref type="bibr" target="#b6">[7]</ref> and UCF Sports are composed of movie clips captured by professional filming crew. Recently, web videos have been used in order to utilize unconstrained user-uploaded data to alleviate the second issue <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b4">5]</ref>. However, the first disadvantage remains unresolved as the largest existing dataset does not include more than 51 actions while several works showed that the number of classes play a crucial role in evaluating an action recognition method <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b8">9]</ref>. Therefore, we have compiled a new dataset with 101 actions and 13320 clips which is nearly twice bigger than the largest existing dataset in terms of number of actions and clips. (HMDB51 <ref type="bibr" target="#b4">[5]</ref> and UCF50 <ref type="bibr" target="#b8">[9]</ref> are the currently the largest ones with 6766 clips of 51 actions and 6681 clips of 50 actions respectively.)</p><p>The dataset is composed of web videos which are recorded in unconstrained environments and typically in-  clude camera motion, various lighting conditions, partial occlusion, low quality frames, etc. <ref type="figure" target="#fig_1">Fig. 1</ref> shows sample frames of 6 action classes from UCF101.  Trampoline Jumping, Volleyball Spiking, Walking with a dog, Yo Yo}. The color class labels specify which predefined action type they belong to.     <ref type="figure" target="#fig_2">Fig. 2</ref> shows a sample frame for each action class of UCF101. Clip Groups: The clips of one action class are divided into 25 groups which contain 4-7 clips each. The clips in one group share some common features, such as the background or actors.</p><p>The bar chart of <ref type="figure" target="#fig_4">Fig. 3</ref> shows the number of clips in each class. The colors on each bar illustrate the durations of different clips included in that class. The chart shown in <ref type="figure" target="#fig_6">Fig. 4</ref> illustrates the average clip length (green) and total duration of clips (blue) for each action class.</p><p>The videos are downloaded from YouTube <ref type="bibr" target="#b1">[2]</ref> and the irrelevant ones are manually removed. All clips have fixed frame rate and resolution of 25 FPS and 320 × 240 respectively. The videos are saved in .avi files compressed using DivX codec available in k-lite package <ref type="bibr" target="#b0">[1]</ref>. The audio is preserved for the clips of the new 51 actions. <ref type="table">Table 1</ref> summarizes the characteristics of the dataset.    where X, Y and Z represent action class label, group and clip number respectively. For instance, v ApplyEyeMakeup g03 c04.avi corresponds to the clip 4 of group 3 of action class ApplyEyeMakeup.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Experimental Results</head><p>We performed an experiment using bag of words approach which is widely accepted as a standard action recognition method to provide baseline results on UCF101.</p><p>From each clip, we extracted Harris3D corners (using the implementation by <ref type="bibr" target="#b6">[7]</ref>) and computed 162 dimensional HOG/HOF descriptors for each. We clustered a randomly selected set of 100,000 space-time interest points (STIP) using k-means to build the codebook. The size of our codebook is k=4000 which is shown to yield good results over a wide range of datasets. The descriptors were assigned to their closest video words using nearest neighbor classifier, and each clip was represented by a 4000-dimensional histogram of its words. Utilizing a leave-one-group-out 25fold cross validation scenario, a SVM was trained using the histogram vectors of the training folds. We employed a nonlinear multiclass SVM with histogram intersection kernel and 101 classes each representing one action. For testing, a similar histogram representation for the query video was computed and classified using the trained SVM. This method yielded an overall accuracy of 44.5%; The confusion matrix for all 101 actions is shown in <ref type="figure" target="#fig_7">Fig. 5</ref>.</p><p>The accuracy for the predefined action types are: Sports (50.54%), Playing Musical Instrument (37.42%), Human-Object Interaction (38.52%), Body-Motion Only (36.26%), Human-Human Interaction (44.14%). Sports actions achieve the highest accuracy since performing sports typically requires distinctive motions which makes the classification easier. Moreover, the background in sports clips are generally less cluttered compared to other action types. Unlike Sports Actions, Human-Object Interaction clips typically have a highly cluttered background. Additionally, the informative motions typically occupy a small portion of the motions in the clips which explains the low recognition accuracy of this action class. We recommend a 25-fold cross validation experimental setup using all the videos in the dataset to keep consistency of the reported tests on UCF101; the baseline results provided in this section were computed using the same scenario.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Related Datasets</head><p>UCF Sports, UCF11, UCF50 and UCF101 are the four action datasets compiled by UCF in chronological order; each one includes its precursor. We made two minor modifications in the portion of UCF101 which includes UCF50 videos: the number of groups is fixed to 25 for all the actions, and each group includes up to 7 clips. <ref type="table">Table 2</ref> shows a list of existing action recognition datasets with detailed characteristics of each. Note that UCF101 is remarkably larger than the rest.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>We introduced UCF101 which is the most challenging dataset for action recognition compared to the existing ones. It includes 101 action classes and over 13k clips which makes it outstandingly larger than other datasets. UCF101 is composed of unconstrained videos downloaded from YouTube which feature challenges such as poor lighting, cluttered background and severe camera motion. We provided baseline action recognition results on this new dataset using standard bag of words method with overall accuracy of 44.5%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Parallel Bars</head><p>Pommel Horse Rafting Shotput Skijet Soccer Penalty Sumo Wrestling  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 .</head><label>1</label><figDesc>Sample frames for 6 action classes of UCF101.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 .</head><label>2</label><figDesc>101 actions included in UCF101 shown with one sample frame. The color of frame borders specifies to which action type they belong: Human-Object Interaction, Body-Motion Only, Human-Human Interaction, Playing Musical Instruments, Sports.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>&gt; 10 . 0</head><label>100</label><figDesc>Sec 5.0 -10.0 Sec 2.0 -5.0 Sec 0.0 -2.0 Sec</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 .</head><label>3</label><figDesc>Number of clips per action class. The distribution of clip durations is illustrated by the colors.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>BlowDryHair BlowingCandles BodyWeightSquats Bowling BoxingPunchingBag BoxingSpeedBag BreastStroke BrushingTeeth CleanAndJerk CliffDiving CricketBowling CricketShot CuttingInKitchen Diving Drumming Fencing FieldHockeyPenalty FloorGymnastics FrisbeeCatch FrontCrawl GolfSwing Haircut Hammering HammerThrow HandstandPushups HandstandWalking HeadMassage HighJump HorseRace HorseRiding HulaHoop IceDancing JavelinThrow JugglingBalls JumpingJack JumpRope Kayaking Knitting</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 4 .</head><label>4</label><figDesc>Total time of videos for each class is illustrated using the blue bars. The average length of the clips for each action is depicted in green.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 5 .</head><label>5</label><figDesc>Confusion table of baseline action recognition results using bag of words approach on UCF101. The drawn lines separate different types of actions; 1-50: Sports, 51-60: Playing Musical Instrument, 61-80: Human-Object Interaction, 81-96: Body-Motion Only, 97-101: Human-Human Interaction.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Billiards BlowDryHair BlowingCandles BodyWeightSquats Bowling BoxingPunchingBag BoxingSpeedBag BreastStroke BrushingTeeth CleanAndJerk CliffDiving CricketBowling CricketShot CuttingInKitchen Diving Drumming Fencing FieldHockeyPenalty FloorGymnastics FrisbeeCatch FrontCrawl GolfSwing Haircut Hammering HammerThrow HandstandPushups HandstandWalking HeadMassage HighJump HorseRace HorseRiding HulaHoop IceDancing JavelinThrow JugglingBalls JumpingJack JumpRope Kayaking Knitting</figDesc><table><row><cell>180</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>150</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="7">0 30 60 BenchPress Biking Number ApplyEyeMakeup ApplyLipstick Archery BabyCrawling BalanceBeam BandMarching BaseballPitch Basketball BasketballDunk 90 120 of Clips</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>180</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>150</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>120</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>90</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>60</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>30</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0</cell><cell>LongJump</cell><cell>Lunges</cell><cell>MilitaryParade Mixing</cell><cell>MoppingFloor Nunchucks</cell><cell>ParallelBars PizzaTossing PlayingCello</cell><cell>PlayingDaf PlayingDhol</cell><cell>PlayingFlute PlayingGuitar PlayingPiano PlayingSitar</cell><cell>PlayingTabla PlayingViolin</cell><cell>PoleVault PommelHorse PullUps</cell><cell>Punch</cell><cell>PushUps Rafting RockClimbi…</cell><cell>RopeClimbing</cell><cell>Rowing SalsaSpin</cell><cell>ShavingBeard Shotput</cell><cell>SkateBoarding Skiing</cell></row></table><note>The following 51 new classes are introduced in UCF101: {Apply Eye Makeup, Apply Lipstick, Archery, Baby Crawl- ing, Balance Beam, Band Marching, Basketball Dunk, Blow Drying Hair, Blowing Candles, Body Weight Squats, Bowl- ing,Boxing-Punching Bag, Boxing-Speed Bag, Brushing Teeth, Cliff Diving, Cricket Bowling, Cricket Shot, Cut- ting In Kitchen, Field Hockey Penalty, Floor Gymnastics, Frisbee Catch, Front Crawl, Hair cut, Hammering, Ham- mer Throw, Handstand Pushups, Handstand Walking, Head Massage, Ice Dancing, Knitting, Long Jump, Mopping Floor, Parallel Bars, Playing Cello, Playing Daf, PlayingSkijet SkyDiving SoccerJuggling SoccerPenalty StillRings SumoWrestling Surfing Swing TableTennis… TaiChi TennisSwing ThrowDiscus TrampolineJ… Typing UnevenBars VolleyballSp… WalkingWit… WallPushups WritingOnB… YoYo Number of Clips</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table Tennis</head><label>Tennis</label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Band Marching</cell><cell>Head Massage</cell><cell>Salsa Spins</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.9</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.8</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.7</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.6</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.5</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.4</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.3</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.2</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.1</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Wall Pushups</cell></row><row><cell>Band Marching</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Head Massage</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Salsa Spins</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0</cell></row><row><cell>Shot</cell><cell>Throw Discus</cell><cell>Volleyball Spiking</cell><cell>Playing Guitar</cell><cell>Playing Tabla</cell><cell>Playing Cello</cell><cell>Playing Dhol</cell><cell>Playing Sitar</cell><cell>Apply Lipstick</cell><cell>Brushing Teeth</cell><cell>'Hammering</cell><cell>Juggling Balls</cell><cell>Knitting</cell><cell>Mopping Floor</cell><cell>Pizza Tossing</cell><cell>Skate Boarding</cell><cell>Typing</cell><cell>Yo Yo</cell><cell>Blowing Candles</cell><cell>Handstand Pushups</cell><cell>Jumping Jack</cell><cell>Pull Ups</cell><cell>Rock Climbing Indoor</cell><cell>Swing</cell><cell>Trampoline Jumping</cell><cell>Wall Pushups</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Archery</head><p>Baseball Pitch</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K-Lite Codec</forename><surname>Package</surname></persName>
		</author>
		<ptr target="http://codecguide.com/.4" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<ptr target="http://www.youtube.com/.4" />
		<title level="m">Youtube</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Actions as space-time shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Blank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Gorelick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shechtman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Irani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Basri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Perceiving events and objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Johansson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bergstrom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Epstein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994" />
			<publisher>Lawrence Erlbaum Associates</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Hmdb: A large video database for human motion recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kuehne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jhuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Garrote</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Poggio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Serre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Recognizing realistic actions from videos in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Actions in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Marszaek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Laptev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Modeling temporal structure of decomposable motion segments for activity classication</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Niebles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Recognizing 50 human action categories of web videos, 2012. Machine Vision and Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal (MVAP)</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Action mach: A spatiotemporal maximum average correlation height lter for action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Recognizing human actions: A local svm approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schuldt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Laptev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Caputo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Pattern Recognition (ICPR)</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Action recognition from arbitrary views using 3d exemplars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Weinland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Boyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ronfard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Still Rings Surfing Tennis Swing Uneven Bars Drumming Playing Piano Playing Violin Playing Daf Playing Flute Apply Eye Makeup Blow Dry Hair Cutting In Kitchen Hula Hoop Jump Rope Mixing Batter Nun chucks Shaving Beard Soccer Juggling Writing On Board Baby Crawling Body Weight Squats</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
